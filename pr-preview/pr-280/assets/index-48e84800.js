function m0(e,t){for(var n=0;n<t.length;n++){const i=t[n];if(typeof i!="string"&&!Array.isArray(i)){for(const a in i)if(a!=="default"&&!(a in e)){const o=Object.getOwnPropertyDescriptor(i,a);o&&Object.defineProperty(e,a,o.get?o:{enumerable:!0,get:()=>i[a]})}}}return Object.freeze(Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}))}(function(){const t=document.createElement("link").relList;if(t&&t.supports&&t.supports("modulepreload"))return;for(const a of document.querySelectorAll('link[rel="modulepreload"]'))i(a);new MutationObserver(a=>{for(const o of a)if(o.type==="childList")for(const r of o.addedNodes)r.tagName==="LINK"&&r.rel==="modulepreload"&&i(r)}).observe(document,{childList:!0,subtree:!0});function n(a){const o={};return a.integrity&&(o.integrity=a.integrity),a.referrerPolicy&&(o.referrerPolicy=a.referrerPolicy),a.crossOrigin==="use-credentials"?o.credentials="include":a.crossOrigin==="anonymous"?o.credentials="omit":o.credentials="same-origin",o}function i(a){if(a.ep)return;a.ep=!0;const o=n(a);fetch(a.href,o)}})();var sn=typeof globalThis<"u"?globalThis:typeof window<"u"?window:typeof global<"u"?global:typeof self<"u"?self:{};function eu(e){return e&&e.__esModule&&Object.prototype.hasOwnProperty.call(e,"default")?e.default:e}function f0(e){if(e.__esModule)return e;var t=e.default;if(typeof t=="function"){var n=function i(){return this instanceof i?Reflect.construct(t,arguments,this.constructor):t.apply(this,arguments)};n.prototype=t.prototype}else n={};return Object.defineProperty(n,"__esModule",{value:!0}),Object.keys(e).forEach(function(i){var a=Object.getOwnPropertyDescriptor(e,i);Object.defineProperty(n,i,a.get?a:{enumerable:!0,get:function(){return e[i]}})}),n}var zh={exports:{}},Cs={},Wh={exports:{}},Y={};/**
 * @license React
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Fo=Symbol.for("react.element"),h0=Symbol.for("react.portal"),y0=Symbol.for("react.fragment"),g0=Symbol.for("react.strict_mode"),_0=Symbol.for("react.profiler"),b0=Symbol.for("react.provider"),v0=Symbol.for("react.context"),w0=Symbol.for("react.forward_ref"),x0=Symbol.for("react.suspense"),T0=Symbol.for("react.memo"),k0=Symbol.for("react.lazy"),$p=Symbol.iterator;function C0(e){return e===null||typeof e!="object"?null:(e=$p&&e[$p]||e["@@iterator"],typeof e=="function"?e:null)}var jh={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},Mh=Object.assign,Lh={};function qa(e,t,n){this.props=e,this.context=t,this.refs=Lh,this.updater=n||jh}qa.prototype.isReactComponent={};qa.prototype.setState=function(e,t){if(typeof e!="object"&&typeof e!="function"&&e!=null)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")};qa.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")};function Fh(){}Fh.prototype=qa.prototype;function tu(e,t,n){this.props=e,this.context=t,this.refs=Lh,this.updater=n||jh}var nu=tu.prototype=new Fh;nu.constructor=tu;Mh(nu,qa.prototype);nu.isPureReactComponent=!0;var Vp=Array.isArray,Uh=Object.prototype.hasOwnProperty,iu={current:null},Gh={key:!0,ref:!0,__self:!0,__source:!0};function $h(e,t,n){var i,a={},o=null,r=null;if(t!=null)for(i in t.ref!==void 0&&(r=t.ref),t.key!==void 0&&(o=""+t.key),t)Uh.call(t,i)&&!Gh.hasOwnProperty(i)&&(a[i]=t[i]);var s=arguments.length-2;if(s===1)a.children=n;else if(1<s){for(var l=Array(s),c=0;c<s;c++)l[c]=arguments[c+2];a.children=l}if(e&&e.defaultProps)for(i in s=e.defaultProps,s)a[i]===void 0&&(a[i]=s[i]);return{$$typeof:Fo,type:e,key:o,ref:r,props:a,_owner:iu.current}}function I0(e,t){return{$$typeof:Fo,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}function au(e){return typeof e=="object"&&e!==null&&e.$$typeof===Fo}function q0(e){var t={"=":"=0",":":"=2"};return"$"+e.replace(/[=:]/g,function(n){return t[n]})}var Hp=/\/+/g;function jl(e,t){return typeof e=="object"&&e!==null&&e.key!=null?q0(""+e.key):t.toString(36)}function Ir(e,t,n,i,a){var o=typeof e;(o==="undefined"||o==="boolean")&&(e=null);var r=!1;if(e===null)r=!0;else switch(o){case"string":case"number":r=!0;break;case"object":switch(e.$$typeof){case Fo:case h0:r=!0}}if(r)return r=e,a=a(r),e=i===""?"."+jl(r,0):i,Vp(a)?(n="",e!=null&&(n=e.replace(Hp,"$&/")+"/"),Ir(a,t,n,"",function(c){return c})):a!=null&&(au(a)&&(a=I0(a,n+(!a.key||r&&r.key===a.key?"":(""+a.key).replace(Hp,"$&/")+"/")+e)),t.push(a)),1;if(r=0,i=i===""?".":i+":",Vp(e))for(var s=0;s<e.length;s++){o=e[s];var l=i+jl(o,s);r+=Ir(o,t,n,l,a)}else if(l=C0(e),typeof l=="function")for(e=l.call(e),s=0;!(o=e.next()).done;)o=o.value,l=i+jl(o,s++),r+=Ir(o,t,n,l,a);else if(o==="object")throw t=String(e),Error("Objects are not valid as a React child (found: "+(t==="[object Object]"?"object with keys {"+Object.keys(e).join(", ")+"}":t)+"). If you meant to render a collection of children, use an array instead.");return r}function nr(e,t,n){if(e==null)return e;var i=[],a=0;return Ir(e,i,"","",function(o){return t.call(n,o,a++)}),i}function D0(e){if(e._status===-1){var t=e._result;t=t(),t.then(function(n){(e._status===0||e._status===-1)&&(e._status=1,e._result=n)},function(n){(e._status===0||e._status===-1)&&(e._status=2,e._result=n)}),e._status===-1&&(e._status=0,e._result=t)}if(e._status===1)return e._result.default;throw e._result}var rt={current:null},qr={transition:null},P0={ReactCurrentDispatcher:rt,ReactCurrentBatchConfig:qr,ReactCurrentOwner:iu};Y.Children={map:nr,forEach:function(e,t,n){nr(e,function(){t.apply(this,arguments)},n)},count:function(e){var t=0;return nr(e,function(){t++}),t},toArray:function(e){return nr(e,function(t){return t})||[]},only:function(e){if(!au(e))throw Error("React.Children.only expected to receive a single React element child.");return e}};Y.Component=qa;Y.Fragment=y0;Y.Profiler=_0;Y.PureComponent=tu;Y.StrictMode=g0;Y.Suspense=x0;Y.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=P0;Y.cloneElement=function(e,t,n){if(e==null)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+e+".");var i=Mh({},e.props),a=e.key,o=e.ref,r=e._owner;if(t!=null){if(t.ref!==void 0&&(o=t.ref,r=iu.current),t.key!==void 0&&(a=""+t.key),e.type&&e.type.defaultProps)var s=e.type.defaultProps;for(l in t)Uh.call(t,l)&&!Gh.hasOwnProperty(l)&&(i[l]=t[l]===void 0&&s!==void 0?s[l]:t[l])}var l=arguments.length-2;if(l===1)i.children=n;else if(1<l){s=Array(l);for(var c=0;c<l;c++)s[c]=arguments[c+2];i.children=s}return{$$typeof:Fo,type:e.type,key:a,ref:o,props:i,_owner:r}};Y.createContext=function(e){return e={$$typeof:v0,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null},e.Provider={$$typeof:b0,_context:e},e.Consumer=e};Y.createElement=$h;Y.createFactory=function(e){var t=$h.bind(null,e);return t.type=e,t};Y.createRef=function(){return{current:null}};Y.forwardRef=function(e){return{$$typeof:w0,render:e}};Y.isValidElement=au;Y.lazy=function(e){return{$$typeof:k0,_payload:{_status:-1,_result:e},_init:D0}};Y.memo=function(e,t){return{$$typeof:T0,type:e,compare:t===void 0?null:t}};Y.startTransition=function(e){var t=qr.transition;qr.transition={};try{e()}finally{qr.transition=t}};Y.unstable_act=function(){throw Error("act(...) is not supported in production builds of React.")};Y.useCallback=function(e,t){return rt.current.useCallback(e,t)};Y.useContext=function(e){return rt.current.useContext(e)};Y.useDebugValue=function(){};Y.useDeferredValue=function(e){return rt.current.useDeferredValue(e)};Y.useEffect=function(e,t){return rt.current.useEffect(e,t)};Y.useId=function(){return rt.current.useId()};Y.useImperativeHandle=function(e,t,n){return rt.current.useImperativeHandle(e,t,n)};Y.useInsertionEffect=function(e,t){return rt.current.useInsertionEffect(e,t)};Y.useLayoutEffect=function(e,t){return rt.current.useLayoutEffect(e,t)};Y.useMemo=function(e,t){return rt.current.useMemo(e,t)};Y.useReducer=function(e,t,n){return rt.current.useReducer(e,t,n)};Y.useRef=function(e){return rt.current.useRef(e)};Y.useState=function(e){return rt.current.useState(e)};Y.useSyncExternalStore=function(e,t,n){return rt.current.useSyncExternalStore(e,t,n)};Y.useTransition=function(){return rt.current.useTransition()};Y.version="18.2.0";Wh.exports=Y;var v=Wh.exports;const Zt=eu(v),Ur=m0({__proto__:null,default:Zt},[v]);/**
 * @license React
 * react-jsx-runtime.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var S0=v,E0=Symbol.for("react.element"),A0=Symbol.for("react.fragment"),N0=Object.prototype.hasOwnProperty,R0=S0.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,B0={key:!0,ref:!0,__self:!0,__source:!0};function Vh(e,t,n){var i,a={},o=null,r=null;n!==void 0&&(o=""+n),t.key!==void 0&&(o=""+t.key),t.ref!==void 0&&(r=t.ref);for(i in t)N0.call(t,i)&&!B0.hasOwnProperty(i)&&(a[i]=t[i]);if(e&&e.defaultProps)for(i in t=e.defaultProps,t)a[i]===void 0&&(a[i]=t[i]);return{$$typeof:E0,type:e,key:o,ref:r,props:a,_owner:R0.current}}Cs.Fragment=A0;Cs.jsx=Vh;Cs.jsxs=Vh;zh.exports=Cs;var m=zh.exports,Nc={},Hh={exports:{}},It={},Zh={exports:{}},Qh={};/**
 * @license React
 * scheduler.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */(function(e){function t(D,N){var W=D.length;D.push(N);e:for(;0<W;){var te=W-1>>>1,Q=D[te];if(0<a(Q,N))D[te]=N,D[W]=Q,W=te;else break e}}function n(D){return D.length===0?null:D[0]}function i(D){if(D.length===0)return null;var N=D[0],W=D.pop();if(W!==N){D[0]=W;e:for(var te=0,Q=D.length,Re=Q>>>1;te<Re;){var J=2*(te+1)-1,we=D[J],le=J+1,$e=D[le];if(0>a(we,W))le<Q&&0>a($e,we)?(D[te]=$e,D[le]=W,te=le):(D[te]=we,D[J]=W,te=J);else if(le<Q&&0>a($e,W))D[te]=$e,D[le]=W,te=le;else break e}}return N}function a(D,N){var W=D.sortIndex-N.sortIndex;return W!==0?W:D.id-N.id}if(typeof performance=="object"&&typeof performance.now=="function"){var o=performance;e.unstable_now=function(){return o.now()}}else{var r=Date,s=r.now();e.unstable_now=function(){return r.now()-s}}var l=[],c=[],d=1,h=null,y=3,p=!1,f=!1,u=!1,T=typeof setTimeout=="function"?setTimeout:null,g=typeof clearTimeout=="function"?clearTimeout:null,_=typeof setImmediate<"u"?setImmediate:null;typeof navigator<"u"&&navigator.scheduling!==void 0&&navigator.scheduling.isInputPending!==void 0&&navigator.scheduling.isInputPending.bind(navigator.scheduling);function b(D){for(var N=n(c);N!==null;){if(N.callback===null)i(c);else if(N.startTime<=D)i(c),N.sortIndex=N.expirationTime,t(l,N);else break;N=n(c)}}function w(D){if(u=!1,b(D),!f)if(n(l)!==null)f=!0,z(C);else{var N=n(c);N!==null&&L(w,N.startTime-D)}}function C(D,N){f=!1,u&&(u=!1,g(q),q=-1),p=!0;var W=y;try{for(b(N),h=n(l);h!==null&&(!(h.expirationTime>N)||D&&!R());){var te=h.callback;if(typeof te=="function"){h.callback=null,y=h.priorityLevel;var Q=te(h.expirationTime<=N);N=e.unstable_now(),typeof Q=="function"?h.callback=Q:h===n(l)&&i(l),b(N)}else i(l);h=n(l)}if(h!==null)var Re=!0;else{var J=n(c);J!==null&&L(w,J.startTime-N),Re=!1}return Re}finally{h=null,y=W,p=!1}}var I=!1,x=null,q=-1,S=5,P=-1;function R(){return!(e.unstable_now()-P<S)}function O(){if(x!==null){var D=e.unstable_now();P=D;var N=!0;try{N=x(!0,D)}finally{N?M():(I=!1,x=null)}}else I=!1}var M;if(typeof _=="function")M=function(){_(O)};else if(typeof MessageChannel<"u"){var A=new MessageChannel,B=A.port2;A.port1.onmessage=O,M=function(){B.postMessage(null)}}else M=function(){T(O,0)};function z(D){x=D,I||(I=!0,M())}function L(D,N){q=T(function(){D(e.unstable_now())},N)}e.unstable_IdlePriority=5,e.unstable_ImmediatePriority=1,e.unstable_LowPriority=4,e.unstable_NormalPriority=3,e.unstable_Profiling=null,e.unstable_UserBlockingPriority=2,e.unstable_cancelCallback=function(D){D.callback=null},e.unstable_continueExecution=function(){f||p||(f=!0,z(C))},e.unstable_forceFrameRate=function(D){0>D||125<D?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):S=0<D?Math.floor(1e3/D):5},e.unstable_getCurrentPriorityLevel=function(){return y},e.unstable_getFirstCallbackNode=function(){return n(l)},e.unstable_next=function(D){switch(y){case 1:case 2:case 3:var N=3;break;default:N=y}var W=y;y=N;try{return D()}finally{y=W}},e.unstable_pauseExecution=function(){},e.unstable_requestPaint=function(){},e.unstable_runWithPriority=function(D,N){switch(D){case 1:case 2:case 3:case 4:case 5:break;default:D=3}var W=y;y=D;try{return N()}finally{y=W}},e.unstable_scheduleCallback=function(D,N,W){var te=e.unstable_now();switch(typeof W=="object"&&W!==null?(W=W.delay,W=typeof W=="number"&&0<W?te+W:te):W=te,D){case 1:var Q=-1;break;case 2:Q=250;break;case 5:Q=1073741823;break;case 4:Q=1e4;break;default:Q=5e3}return Q=W+Q,D={id:d++,callback:N,priorityLevel:D,startTime:W,expirationTime:Q,sortIndex:-1},W>te?(D.sortIndex=W,t(c,D),n(l)===null&&D===n(c)&&(u?(g(q),q=-1):u=!0,L(w,W-te))):(D.sortIndex=Q,t(l,D),f||p||(f=!0,z(C))),D},e.unstable_shouldYield=R,e.unstable_wrapCallback=function(D){var N=y;return function(){var W=y;y=N;try{return D.apply(this,arguments)}finally{y=W}}}})(Qh);Zh.exports=Qh;var O0=Zh.exports;/**
 * @license React
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Kh=v,Ct=O0;function E(e){for(var t="https://reactjs.org/docs/error-decoder.html?invariant="+e,n=1;n<arguments.length;n++)t+="&args[]="+encodeURIComponent(arguments[n]);return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}var Xh=new Set,bo={};function Oi(e,t){ya(e,t),ya(e+"Capture",t)}function ya(e,t){for(bo[e]=t,e=0;e<t.length;e++)Xh.add(t[e])}var Cn=!(typeof window>"u"||typeof window.document>"u"||typeof window.document.createElement>"u"),Rc=Object.prototype.hasOwnProperty,z0=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,Zp={},Qp={};function W0(e){return Rc.call(Qp,e)?!0:Rc.call(Zp,e)?!1:z0.test(e)?Qp[e]=!0:(Zp[e]=!0,!1)}function j0(e,t,n,i){if(n!==null&&n.type===0)return!1;switch(typeof t){case"function":case"symbol":return!0;case"boolean":return i?!1:n!==null?!n.acceptsBooleans:(e=e.toLowerCase().slice(0,5),e!=="data-"&&e!=="aria-");default:return!1}}function M0(e,t,n,i){if(t===null||typeof t>"u"||j0(e,t,n,i))return!0;if(i)return!1;if(n!==null)switch(n.type){case 3:return!t;case 4:return t===!1;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}function st(e,t,n,i,a,o,r){this.acceptsBooleans=t===2||t===3||t===4,this.attributeName=i,this.attributeNamespace=a,this.mustUseProperty=n,this.propertyName=e,this.type=t,this.sanitizeURL=o,this.removeEmptyString=r}var Ke={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(e){Ke[e]=new st(e,0,!1,e,null,!1,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(e){var t=e[0];Ke[t]=new st(t,1,!1,e[1],null,!1,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(e){Ke[e]=new st(e,2,!1,e.toLowerCase(),null,!1,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(e){Ke[e]=new st(e,2,!1,e,null,!1,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(e){Ke[e]=new st(e,3,!1,e.toLowerCase(),null,!1,!1)});["checked","multiple","muted","selected"].forEach(function(e){Ke[e]=new st(e,3,!0,e,null,!1,!1)});["capture","download"].forEach(function(e){Ke[e]=new st(e,4,!1,e,null,!1,!1)});["cols","rows","size","span"].forEach(function(e){Ke[e]=new st(e,6,!1,e,null,!1,!1)});["rowSpan","start"].forEach(function(e){Ke[e]=new st(e,5,!1,e.toLowerCase(),null,!1,!1)});var ou=/[\-:]([a-z])/g;function ru(e){return e[1].toUpperCase()}"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(e){var t=e.replace(ou,ru);Ke[t]=new st(t,1,!1,e,null,!1,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(e){var t=e.replace(ou,ru);Ke[t]=new st(t,1,!1,e,"http://www.w3.org/1999/xlink",!1,!1)});["xml:base","xml:lang","xml:space"].forEach(function(e){var t=e.replace(ou,ru);Ke[t]=new st(t,1,!1,e,"http://www.w3.org/XML/1998/namespace",!1,!1)});["tabIndex","crossOrigin"].forEach(function(e){Ke[e]=new st(e,1,!1,e.toLowerCase(),null,!1,!1)});Ke.xlinkHref=new st("xlinkHref",1,!1,"xlink:href","http://www.w3.org/1999/xlink",!0,!1);["src","href","action","formAction"].forEach(function(e){Ke[e]=new st(e,1,!1,e.toLowerCase(),null,!0,!0)});function su(e,t,n,i){var a=Ke.hasOwnProperty(t)?Ke[t]:null;(a!==null?a.type!==0:i||!(2<t.length)||t[0]!=="o"&&t[0]!=="O"||t[1]!=="n"&&t[1]!=="N")&&(M0(t,n,a,i)&&(n=null),i||a===null?W0(t)&&(n===null?e.removeAttribute(t):e.setAttribute(t,""+n)):a.mustUseProperty?e[a.propertyName]=n===null?a.type===3?!1:"":n:(t=a.attributeName,i=a.attributeNamespace,n===null?e.removeAttribute(t):(a=a.type,n=a===3||a===4&&n===!0?"":""+n,i?e.setAttributeNS(i,t,n):e.setAttribute(t,n))))}var An=Kh.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,ir=Symbol.for("react.element"),Qi=Symbol.for("react.portal"),Ki=Symbol.for("react.fragment"),lu=Symbol.for("react.strict_mode"),Bc=Symbol.for("react.profiler"),Yh=Symbol.for("react.provider"),Jh=Symbol.for("react.context"),cu=Symbol.for("react.forward_ref"),Oc=Symbol.for("react.suspense"),zc=Symbol.for("react.suspense_list"),du=Symbol.for("react.memo"),Mn=Symbol.for("react.lazy"),ey=Symbol.for("react.offscreen"),Kp=Symbol.iterator;function Oa(e){return e===null||typeof e!="object"?null:(e=Kp&&e[Kp]||e["@@iterator"],typeof e=="function"?e:null)}var Se=Object.assign,Ml;function Ya(e){if(Ml===void 0)try{throw Error()}catch(n){var t=n.stack.trim().match(/\n( *(at )?)/);Ml=t&&t[1]||""}return`
`+Ml+e}var Ll=!1;function Fl(e,t){if(!e||Ll)return"";Ll=!0;var n=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,"props",{set:function(){throw Error()}}),typeof Reflect=="object"&&Reflect.construct){try{Reflect.construct(t,[])}catch(c){var i=c}Reflect.construct(e,[],t)}else{try{t.call()}catch(c){i=c}e.call(t.prototype)}else{try{throw Error()}catch(c){i=c}e()}}catch(c){if(c&&i&&typeof c.stack=="string"){for(var a=c.stack.split(`
`),o=i.stack.split(`
`),r=a.length-1,s=o.length-1;1<=r&&0<=s&&a[r]!==o[s];)s--;for(;1<=r&&0<=s;r--,s--)if(a[r]!==o[s]){if(r!==1||s!==1)do if(r--,s--,0>s||a[r]!==o[s]){var l=`
`+a[r].replace(" at new "," at ");return e.displayName&&l.includes("<anonymous>")&&(l=l.replace("<anonymous>",e.displayName)),l}while(1<=r&&0<=s);break}}}finally{Ll=!1,Error.prepareStackTrace=n}return(e=e?e.displayName||e.name:"")?Ya(e):""}function L0(e){switch(e.tag){case 5:return Ya(e.type);case 16:return Ya("Lazy");case 13:return Ya("Suspense");case 19:return Ya("SuspenseList");case 0:case 2:case 15:return e=Fl(e.type,!1),e;case 11:return e=Fl(e.type.render,!1),e;case 1:return e=Fl(e.type,!0),e;default:return""}}function Wc(e){if(e==null)return null;if(typeof e=="function")return e.displayName||e.name||null;if(typeof e=="string")return e;switch(e){case Ki:return"Fragment";case Qi:return"Portal";case Bc:return"Profiler";case lu:return"StrictMode";case Oc:return"Suspense";case zc:return"SuspenseList"}if(typeof e=="object")switch(e.$$typeof){case Jh:return(e.displayName||"Context")+".Consumer";case Yh:return(e._context.displayName||"Context")+".Provider";case cu:var t=e.render;return e=e.displayName,e||(e=t.displayName||t.name||"",e=e!==""?"ForwardRef("+e+")":"ForwardRef"),e;case du:return t=e.displayName||null,t!==null?t:Wc(e.type)||"Memo";case Mn:t=e._payload,e=e._init;try{return Wc(e(t))}catch{}}return null}function F0(e){var t=e.type;switch(e.tag){case 24:return"Cache";case 9:return(t.displayName||"Context")+".Consumer";case 10:return(t._context.displayName||"Context")+".Provider";case 18:return"DehydratedFragment";case 11:return e=t.render,e=e.displayName||e.name||"",t.displayName||(e!==""?"ForwardRef("+e+")":"ForwardRef");case 7:return"Fragment";case 5:return t;case 4:return"Portal";case 3:return"Root";case 6:return"Text";case 16:return Wc(t);case 8:return t===lu?"StrictMode":"Mode";case 22:return"Offscreen";case 12:return"Profiler";case 21:return"Scope";case 13:return"Suspense";case 19:return"SuspenseList";case 25:return"TracingMarker";case 1:case 0:case 17:case 2:case 14:case 15:if(typeof t=="function")return t.displayName||t.name||null;if(typeof t=="string")return t}return null}function ni(e){switch(typeof e){case"boolean":case"number":case"string":case"undefined":return e;case"object":return e;default:return""}}function ty(e){var t=e.type;return(e=e.nodeName)&&e.toLowerCase()==="input"&&(t==="checkbox"||t==="radio")}function U0(e){var t=ty(e)?"checked":"value",n=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),i=""+e[t];if(!e.hasOwnProperty(t)&&typeof n<"u"&&typeof n.get=="function"&&typeof n.set=="function"){var a=n.get,o=n.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return a.call(this)},set:function(r){i=""+r,o.call(this,r)}}),Object.defineProperty(e,t,{enumerable:n.enumerable}),{getValue:function(){return i},setValue:function(r){i=""+r},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}function ar(e){e._valueTracker||(e._valueTracker=U0(e))}function ny(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var n=t.getValue(),i="";return e&&(i=ty(e)?e.checked?"true":"false":e.value),e=i,e!==n?(t.setValue(e),!0):!1}function Gr(e){if(e=e||(typeof document<"u"?document:void 0),typeof e>"u")return null;try{return e.activeElement||e.body}catch{return e.body}}function jc(e,t){var n=t.checked;return Se({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:n??e._wrapperState.initialChecked})}function Xp(e,t){var n=t.defaultValue==null?"":t.defaultValue,i=t.checked!=null?t.checked:t.defaultChecked;n=ni(t.value!=null?t.value:n),e._wrapperState={initialChecked:i,initialValue:n,controlled:t.type==="checkbox"||t.type==="radio"?t.checked!=null:t.value!=null}}function iy(e,t){t=t.checked,t!=null&&su(e,"checked",t,!1)}function Mc(e,t){iy(e,t);var n=ni(t.value),i=t.type;if(n!=null)i==="number"?(n===0&&e.value===""||e.value!=n)&&(e.value=""+n):e.value!==""+n&&(e.value=""+n);else if(i==="submit"||i==="reset"){e.removeAttribute("value");return}t.hasOwnProperty("value")?Lc(e,t.type,n):t.hasOwnProperty("defaultValue")&&Lc(e,t.type,ni(t.defaultValue)),t.checked==null&&t.defaultChecked!=null&&(e.defaultChecked=!!t.defaultChecked)}function Yp(e,t,n){if(t.hasOwnProperty("value")||t.hasOwnProperty("defaultValue")){var i=t.type;if(!(i!=="submit"&&i!=="reset"||t.value!==void 0&&t.value!==null))return;t=""+e._wrapperState.initialValue,n||t===e.value||(e.value=t),e.defaultValue=t}n=e.name,n!==""&&(e.name=""),e.defaultChecked=!!e._wrapperState.initialChecked,n!==""&&(e.name=n)}function Lc(e,t,n){(t!=="number"||Gr(e.ownerDocument)!==e)&&(n==null?e.defaultValue=""+e._wrapperState.initialValue:e.defaultValue!==""+n&&(e.defaultValue=""+n))}var Ja=Array.isArray;function la(e,t,n,i){if(e=e.options,t){t={};for(var a=0;a<n.length;a++)t["$"+n[a]]=!0;for(n=0;n<e.length;n++)a=t.hasOwnProperty("$"+e[n].value),e[n].selected!==a&&(e[n].selected=a),a&&i&&(e[n].defaultSelected=!0)}else{for(n=""+ni(n),t=null,a=0;a<e.length;a++){if(e[a].value===n){e[a].selected=!0,i&&(e[a].defaultSelected=!0);return}t!==null||e[a].disabled||(t=e[a])}t!==null&&(t.selected=!0)}}function Fc(e,t){if(t.dangerouslySetInnerHTML!=null)throw Error(E(91));return Se({},t,{value:void 0,defaultValue:void 0,children:""+e._wrapperState.initialValue})}function Jp(e,t){var n=t.value;if(n==null){if(n=t.children,t=t.defaultValue,n!=null){if(t!=null)throw Error(E(92));if(Ja(n)){if(1<n.length)throw Error(E(93));n=n[0]}t=n}t==null&&(t=""),n=t}e._wrapperState={initialValue:ni(n)}}function ay(e,t){var n=ni(t.value),i=ni(t.defaultValue);n!=null&&(n=""+n,n!==e.value&&(e.value=n),t.defaultValue==null&&e.defaultValue!==n&&(e.defaultValue=n)),i!=null&&(e.defaultValue=""+i)}function em(e){var t=e.textContent;t===e._wrapperState.initialValue&&t!==""&&t!==null&&(e.value=t)}function oy(e){switch(e){case"svg":return"http://www.w3.org/2000/svg";case"math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function Uc(e,t){return e==null||e==="http://www.w3.org/1999/xhtml"?oy(t):e==="http://www.w3.org/2000/svg"&&t==="foreignObject"?"http://www.w3.org/1999/xhtml":e}var or,ry=function(e){return typeof MSApp<"u"&&MSApp.execUnsafeLocalFunction?function(t,n,i,a){MSApp.execUnsafeLocalFunction(function(){return e(t,n,i,a)})}:e}(function(e,t){if(e.namespaceURI!=="http://www.w3.org/2000/svg"||"innerHTML"in e)e.innerHTML=t;else{for(or=or||document.createElement("div"),or.innerHTML="<svg>"+t.valueOf().toString()+"</svg>",t=or.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}});function vo(e,t){if(t){var n=e.firstChild;if(n&&n===e.lastChild&&n.nodeType===3){n.nodeValue=t;return}}e.textContent=t}var ao={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},G0=["Webkit","ms","Moz","O"];Object.keys(ao).forEach(function(e){G0.forEach(function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),ao[t]=ao[e]})});function sy(e,t,n){return t==null||typeof t=="boolean"||t===""?"":n||typeof t!="number"||t===0||ao.hasOwnProperty(e)&&ao[e]?(""+t).trim():t+"px"}function ly(e,t){e=e.style;for(var n in t)if(t.hasOwnProperty(n)){var i=n.indexOf("--")===0,a=sy(n,t[n],i);n==="float"&&(n="cssFloat"),i?e.setProperty(n,a):e[n]=a}}var $0=Se({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function Gc(e,t){if(t){if($0[e]&&(t.children!=null||t.dangerouslySetInnerHTML!=null))throw Error(E(137,e));if(t.dangerouslySetInnerHTML!=null){if(t.children!=null)throw Error(E(60));if(typeof t.dangerouslySetInnerHTML!="object"||!("__html"in t.dangerouslySetInnerHTML))throw Error(E(61))}if(t.style!=null&&typeof t.style!="object")throw Error(E(62))}}function $c(e,t){if(e.indexOf("-")===-1)return typeof t.is=="string";switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var Vc=null;function uu(e){return e=e.target||e.srcElement||window,e.correspondingUseElement&&(e=e.correspondingUseElement),e.nodeType===3?e.parentNode:e}var Hc=null,ca=null,da=null;function tm(e){if(e=$o(e)){if(typeof Hc!="function")throw Error(E(280));var t=e.stateNode;t&&(t=Ss(t),Hc(e.stateNode,e.type,t))}}function cy(e){ca?da?da.push(e):da=[e]:ca=e}function dy(){if(ca){var e=ca,t=da;if(da=ca=null,tm(e),t)for(e=0;e<t.length;e++)tm(t[e])}}function uy(e,t){return e(t)}function py(){}var Ul=!1;function my(e,t,n){if(Ul)return e(t,n);Ul=!0;try{return uy(e,t,n)}finally{Ul=!1,(ca!==null||da!==null)&&(py(),dy())}}function wo(e,t){var n=e.stateNode;if(n===null)return null;var i=Ss(n);if(i===null)return null;n=i[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(i=!i.disabled)||(e=e.type,i=!(e==="button"||e==="input"||e==="select"||e==="textarea")),e=!i;break e;default:e=!1}if(e)return null;if(n&&typeof n!="function")throw Error(E(231,t,typeof n));return n}var Zc=!1;if(Cn)try{var za={};Object.defineProperty(za,"passive",{get:function(){Zc=!0}}),window.addEventListener("test",za,za),window.removeEventListener("test",za,za)}catch{Zc=!1}function V0(e,t,n,i,a,o,r,s,l){var c=Array.prototype.slice.call(arguments,3);try{t.apply(n,c)}catch(d){this.onError(d)}}var oo=!1,$r=null,Vr=!1,Qc=null,H0={onError:function(e){oo=!0,$r=e}};function Z0(e,t,n,i,a,o,r,s,l){oo=!1,$r=null,V0.apply(H0,arguments)}function Q0(e,t,n,i,a,o,r,s,l){if(Z0.apply(this,arguments),oo){if(oo){var c=$r;oo=!1,$r=null}else throw Error(E(198));Vr||(Vr=!0,Qc=c)}}function zi(e){var t=e,n=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do t=e,t.flags&4098&&(n=t.return),e=t.return;while(e)}return t.tag===3?n:null}function fy(e){if(e.tag===13){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function nm(e){if(zi(e)!==e)throw Error(E(188))}function K0(e){var t=e.alternate;if(!t){if(t=zi(e),t===null)throw Error(E(188));return t!==e?null:e}for(var n=e,i=t;;){var a=n.return;if(a===null)break;var o=a.alternate;if(o===null){if(i=a.return,i!==null){n=i;continue}break}if(a.child===o.child){for(o=a.child;o;){if(o===n)return nm(a),e;if(o===i)return nm(a),t;o=o.sibling}throw Error(E(188))}if(n.return!==i.return)n=a,i=o;else{for(var r=!1,s=a.child;s;){if(s===n){r=!0,n=a,i=o;break}if(s===i){r=!0,i=a,n=o;break}s=s.sibling}if(!r){for(s=o.child;s;){if(s===n){r=!0,n=o,i=a;break}if(s===i){r=!0,i=o,n=a;break}s=s.sibling}if(!r)throw Error(E(189))}}if(n.alternate!==i)throw Error(E(190))}if(n.tag!==3)throw Error(E(188));return n.stateNode.current===n?e:t}function hy(e){return e=K0(e),e!==null?yy(e):null}function yy(e){if(e.tag===5||e.tag===6)return e;for(e=e.child;e!==null;){var t=yy(e);if(t!==null)return t;e=e.sibling}return null}var gy=Ct.unstable_scheduleCallback,im=Ct.unstable_cancelCallback,X0=Ct.unstable_shouldYield,Y0=Ct.unstable_requestPaint,Oe=Ct.unstable_now,J0=Ct.unstable_getCurrentPriorityLevel,pu=Ct.unstable_ImmediatePriority,_y=Ct.unstable_UserBlockingPriority,Hr=Ct.unstable_NormalPriority,e1=Ct.unstable_LowPriority,by=Ct.unstable_IdlePriority,Is=null,cn=null;function t1(e){if(cn&&typeof cn.onCommitFiberRoot=="function")try{cn.onCommitFiberRoot(Is,e,void 0,(e.current.flags&128)===128)}catch{}}var Qt=Math.clz32?Math.clz32:a1,n1=Math.log,i1=Math.LN2;function a1(e){return e>>>=0,e===0?32:31-(n1(e)/i1|0)|0}var rr=64,sr=4194304;function eo(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return e&4194240;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return e&130023424;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function Zr(e,t){var n=e.pendingLanes;if(n===0)return 0;var i=0,a=e.suspendedLanes,o=e.pingedLanes,r=n&268435455;if(r!==0){var s=r&~a;s!==0?i=eo(s):(o&=r,o!==0&&(i=eo(o)))}else r=n&~a,r!==0?i=eo(r):o!==0&&(i=eo(o));if(i===0)return 0;if(t!==0&&t!==i&&!(t&a)&&(a=i&-i,o=t&-t,a>=o||a===16&&(o&4194240)!==0))return t;if(i&4&&(i|=n&16),t=e.entangledLanes,t!==0)for(e=e.entanglements,t&=i;0<t;)n=31-Qt(t),a=1<<n,i|=e[n],t&=~a;return i}function o1(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return-1;case 134217728:case 268435456:case 536870912:case 1073741824:return-1;default:return-1}}function r1(e,t){for(var n=e.suspendedLanes,i=e.pingedLanes,a=e.expirationTimes,o=e.pendingLanes;0<o;){var r=31-Qt(o),s=1<<r,l=a[r];l===-1?(!(s&n)||s&i)&&(a[r]=o1(s,t)):l<=t&&(e.expiredLanes|=s),o&=~s}}function Kc(e){return e=e.pendingLanes&-1073741825,e!==0?e:e&1073741824?1073741824:0}function vy(){var e=rr;return rr<<=1,!(rr&4194240)&&(rr=64),e}function Gl(e){for(var t=[],n=0;31>n;n++)t.push(e);return t}function Uo(e,t,n){e.pendingLanes|=t,t!==536870912&&(e.suspendedLanes=0,e.pingedLanes=0),e=e.eventTimes,t=31-Qt(t),e[t]=n}function s1(e,t){var n=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var i=e.eventTimes;for(e=e.expirationTimes;0<n;){var a=31-Qt(n),o=1<<a;t[a]=0,i[a]=-1,e[a]=-1,n&=~o}}function mu(e,t){var n=e.entangledLanes|=t;for(e=e.entanglements;n;){var i=31-Qt(n),a=1<<i;a&t|e[i]&t&&(e[i]|=t),n&=~a}}var ce=0;function wy(e){return e&=-e,1<e?4<e?e&268435455?16:536870912:4:1}var xy,fu,Ty,ky,Cy,Xc=!1,lr=[],Hn=null,Zn=null,Qn=null,xo=new Map,To=new Map,Fn=[],l1="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit".split(" ");function am(e,t){switch(e){case"focusin":case"focusout":Hn=null;break;case"dragenter":case"dragleave":Zn=null;break;case"mouseover":case"mouseout":Qn=null;break;case"pointerover":case"pointerout":xo.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":To.delete(t.pointerId)}}function Wa(e,t,n,i,a,o){return e===null||e.nativeEvent!==o?(e={blockedOn:t,domEventName:n,eventSystemFlags:i,nativeEvent:o,targetContainers:[a]},t!==null&&(t=$o(t),t!==null&&fu(t)),e):(e.eventSystemFlags|=i,t=e.targetContainers,a!==null&&t.indexOf(a)===-1&&t.push(a),e)}function c1(e,t,n,i,a){switch(t){case"focusin":return Hn=Wa(Hn,e,t,n,i,a),!0;case"dragenter":return Zn=Wa(Zn,e,t,n,i,a),!0;case"mouseover":return Qn=Wa(Qn,e,t,n,i,a),!0;case"pointerover":var o=a.pointerId;return xo.set(o,Wa(xo.get(o)||null,e,t,n,i,a)),!0;case"gotpointercapture":return o=a.pointerId,To.set(o,Wa(To.get(o)||null,e,t,n,i,a)),!0}return!1}function Iy(e){var t=xi(e.target);if(t!==null){var n=zi(t);if(n!==null){if(t=n.tag,t===13){if(t=fy(n),t!==null){e.blockedOn=t,Cy(e.priority,function(){Ty(n)});return}}else if(t===3&&n.stateNode.current.memoizedState.isDehydrated){e.blockedOn=n.tag===3?n.stateNode.containerInfo:null;return}}}e.blockedOn=null}function Dr(e){if(e.blockedOn!==null)return!1;for(var t=e.targetContainers;0<t.length;){var n=Yc(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(n===null){n=e.nativeEvent;var i=new n.constructor(n.type,n);Vc=i,n.target.dispatchEvent(i),Vc=null}else return t=$o(n),t!==null&&fu(t),e.blockedOn=n,!1;t.shift()}return!0}function om(e,t,n){Dr(e)&&n.delete(t)}function d1(){Xc=!1,Hn!==null&&Dr(Hn)&&(Hn=null),Zn!==null&&Dr(Zn)&&(Zn=null),Qn!==null&&Dr(Qn)&&(Qn=null),xo.forEach(om),To.forEach(om)}function ja(e,t){e.blockedOn===t&&(e.blockedOn=null,Xc||(Xc=!0,Ct.unstable_scheduleCallback(Ct.unstable_NormalPriority,d1)))}function ko(e){function t(a){return ja(a,e)}if(0<lr.length){ja(lr[0],e);for(var n=1;n<lr.length;n++){var i=lr[n];i.blockedOn===e&&(i.blockedOn=null)}}for(Hn!==null&&ja(Hn,e),Zn!==null&&ja(Zn,e),Qn!==null&&ja(Qn,e),xo.forEach(t),To.forEach(t),n=0;n<Fn.length;n++)i=Fn[n],i.blockedOn===e&&(i.blockedOn=null);for(;0<Fn.length&&(n=Fn[0],n.blockedOn===null);)Iy(n),n.blockedOn===null&&Fn.shift()}var ua=An.ReactCurrentBatchConfig,Qr=!0;function u1(e,t,n,i){var a=ce,o=ua.transition;ua.transition=null;try{ce=1,hu(e,t,n,i)}finally{ce=a,ua.transition=o}}function p1(e,t,n,i){var a=ce,o=ua.transition;ua.transition=null;try{ce=4,hu(e,t,n,i)}finally{ce=a,ua.transition=o}}function hu(e,t,n,i){if(Qr){var a=Yc(e,t,n,i);if(a===null)ec(e,t,i,Kr,n),am(e,i);else if(c1(a,e,t,n,i))i.stopPropagation();else if(am(e,i),t&4&&-1<l1.indexOf(e)){for(;a!==null;){var o=$o(a);if(o!==null&&xy(o),o=Yc(e,t,n,i),o===null&&ec(e,t,i,Kr,n),o===a)break;a=o}a!==null&&i.stopPropagation()}else ec(e,t,i,null,n)}}var Kr=null;function Yc(e,t,n,i){if(Kr=null,e=uu(i),e=xi(e),e!==null)if(t=zi(e),t===null)e=null;else if(n=t.tag,n===13){if(e=fy(t),e!==null)return e;e=null}else if(n===3){if(t.stateNode.current.memoizedState.isDehydrated)return t.tag===3?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Kr=e,null}function qy(e){switch(e){case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 1;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"toggle":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 4;case"message":switch(J0()){case pu:return 1;case _y:return 4;case Hr:case e1:return 16;case by:return 536870912;default:return 16}default:return 16}}var Gn=null,yu=null,Pr=null;function Dy(){if(Pr)return Pr;var e,t=yu,n=t.length,i,a="value"in Gn?Gn.value:Gn.textContent,o=a.length;for(e=0;e<n&&t[e]===a[e];e++);var r=n-e;for(i=1;i<=r&&t[n-i]===a[o-i];i++);return Pr=a.slice(e,1<i?1-i:void 0)}function Sr(e){var t=e.keyCode;return"charCode"in e?(e=e.charCode,e===0&&t===13&&(e=13)):e=t,e===10&&(e=13),32<=e||e===13?e:0}function cr(){return!0}function rm(){return!1}function qt(e){function t(n,i,a,o,r){this._reactName=n,this._targetInst=a,this.type=i,this.nativeEvent=o,this.target=r,this.currentTarget=null;for(var s in e)e.hasOwnProperty(s)&&(n=e[s],this[s]=n?n(o):o[s]);return this.isDefaultPrevented=(o.defaultPrevented!=null?o.defaultPrevented:o.returnValue===!1)?cr:rm,this.isPropagationStopped=rm,this}return Se(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var n=this.nativeEvent;n&&(n.preventDefault?n.preventDefault():typeof n.returnValue!="unknown"&&(n.returnValue=!1),this.isDefaultPrevented=cr)},stopPropagation:function(){var n=this.nativeEvent;n&&(n.stopPropagation?n.stopPropagation():typeof n.cancelBubble!="unknown"&&(n.cancelBubble=!0),this.isPropagationStopped=cr)},persist:function(){},isPersistent:cr}),t}var Da={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},gu=qt(Da),Go=Se({},Da,{view:0,detail:0}),m1=qt(Go),$l,Vl,Ma,qs=Se({},Go,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:_u,button:0,buttons:0,relatedTarget:function(e){return e.relatedTarget===void 0?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==Ma&&(Ma&&e.type==="mousemove"?($l=e.screenX-Ma.screenX,Vl=e.screenY-Ma.screenY):Vl=$l=0,Ma=e),$l)},movementY:function(e){return"movementY"in e?e.movementY:Vl}}),sm=qt(qs),f1=Se({},qs,{dataTransfer:0}),h1=qt(f1),y1=Se({},Go,{relatedTarget:0}),Hl=qt(y1),g1=Se({},Da,{animationName:0,elapsedTime:0,pseudoElement:0}),_1=qt(g1),b1=Se({},Da,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),v1=qt(b1),w1=Se({},Da,{data:0}),lm=qt(w1),x1={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},T1={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},k1={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function C1(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):(e=k1[e])?!!t[e]:!1}function _u(){return C1}var I1=Se({},Go,{key:function(e){if(e.key){var t=x1[e.key]||e.key;if(t!=="Unidentified")return t}return e.type==="keypress"?(e=Sr(e),e===13?"Enter":String.fromCharCode(e)):e.type==="keydown"||e.type==="keyup"?T1[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:_u,charCode:function(e){return e.type==="keypress"?Sr(e):0},keyCode:function(e){return e.type==="keydown"||e.type==="keyup"?e.keyCode:0},which:function(e){return e.type==="keypress"?Sr(e):e.type==="keydown"||e.type==="keyup"?e.keyCode:0}}),q1=qt(I1),D1=Se({},qs,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0}),cm=qt(D1),P1=Se({},Go,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:_u}),S1=qt(P1),E1=Se({},Da,{propertyName:0,elapsedTime:0,pseudoElement:0}),A1=qt(E1),N1=Se({},qs,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),R1=qt(N1),B1=[9,13,27,32],bu=Cn&&"CompositionEvent"in window,ro=null;Cn&&"documentMode"in document&&(ro=document.documentMode);var O1=Cn&&"TextEvent"in window&&!ro,Py=Cn&&(!bu||ro&&8<ro&&11>=ro),dm=String.fromCharCode(32),um=!1;function Sy(e,t){switch(e){case"keyup":return B1.indexOf(t.keyCode)!==-1;case"keydown":return t.keyCode!==229;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function Ey(e){return e=e.detail,typeof e=="object"&&"data"in e?e.data:null}var Xi=!1;function z1(e,t){switch(e){case"compositionend":return Ey(t);case"keypress":return t.which!==32?null:(um=!0,dm);case"textInput":return e=t.data,e===dm&&um?null:e;default:return null}}function W1(e,t){if(Xi)return e==="compositionend"||!bu&&Sy(e,t)?(e=Dy(),Pr=yu=Gn=null,Xi=!1,e):null;switch(e){case"paste":return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return Py&&t.locale!=="ko"?null:t.data;default:return null}}var j1={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function pm(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t==="input"?!!j1[e.type]:t==="textarea"}function Ay(e,t,n,i){cy(i),t=Xr(t,"onChange"),0<t.length&&(n=new gu("onChange","change",null,n,i),e.push({event:n,listeners:t}))}var so=null,Co=null;function M1(e){Uy(e,0)}function Ds(e){var t=ea(e);if(ny(t))return e}function L1(e,t){if(e==="change")return t}var Ny=!1;if(Cn){var Zl;if(Cn){var Ql="oninput"in document;if(!Ql){var mm=document.createElement("div");mm.setAttribute("oninput","return;"),Ql=typeof mm.oninput=="function"}Zl=Ql}else Zl=!1;Ny=Zl&&(!document.documentMode||9<document.documentMode)}function fm(){so&&(so.detachEvent("onpropertychange",Ry),Co=so=null)}function Ry(e){if(e.propertyName==="value"&&Ds(Co)){var t=[];Ay(t,Co,e,uu(e)),my(M1,t)}}function F1(e,t,n){e==="focusin"?(fm(),so=t,Co=n,so.attachEvent("onpropertychange",Ry)):e==="focusout"&&fm()}function U1(e){if(e==="selectionchange"||e==="keyup"||e==="keydown")return Ds(Co)}function G1(e,t){if(e==="click")return Ds(t)}function $1(e,t){if(e==="input"||e==="change")return Ds(t)}function V1(e,t){return e===t&&(e!==0||1/e===1/t)||e!==e&&t!==t}var Xt=typeof Object.is=="function"?Object.is:V1;function Io(e,t){if(Xt(e,t))return!0;if(typeof e!="object"||e===null||typeof t!="object"||t===null)return!1;var n=Object.keys(e),i=Object.keys(t);if(n.length!==i.length)return!1;for(i=0;i<n.length;i++){var a=n[i];if(!Rc.call(t,a)||!Xt(e[a],t[a]))return!1}return!0}function hm(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function ym(e,t){var n=hm(e);e=0;for(var i;n;){if(n.nodeType===3){if(i=e+n.textContent.length,e<=t&&i>=t)return{node:n,offset:t-e};e=i}e:{for(;n;){if(n.nextSibling){n=n.nextSibling;break e}n=n.parentNode}n=void 0}n=hm(n)}}function By(e,t){return e&&t?e===t?!0:e&&e.nodeType===3?!1:t&&t.nodeType===3?By(e,t.parentNode):"contains"in e?e.contains(t):e.compareDocumentPosition?!!(e.compareDocumentPosition(t)&16):!1:!1}function Oy(){for(var e=window,t=Gr();t instanceof e.HTMLIFrameElement;){try{var n=typeof t.contentWindow.location.href=="string"}catch{n=!1}if(n)e=t.contentWindow;else break;t=Gr(e.document)}return t}function vu(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(t==="input"&&(e.type==="text"||e.type==="search"||e.type==="tel"||e.type==="url"||e.type==="password")||t==="textarea"||e.contentEditable==="true")}function H1(e){var t=Oy(),n=e.focusedElem,i=e.selectionRange;if(t!==n&&n&&n.ownerDocument&&By(n.ownerDocument.documentElement,n)){if(i!==null&&vu(n)){if(t=i.start,e=i.end,e===void 0&&(e=t),"selectionStart"in n)n.selectionStart=t,n.selectionEnd=Math.min(e,n.value.length);else if(e=(t=n.ownerDocument||document)&&t.defaultView||window,e.getSelection){e=e.getSelection();var a=n.textContent.length,o=Math.min(i.start,a);i=i.end===void 0?o:Math.min(i.end,a),!e.extend&&o>i&&(a=i,i=o,o=a),a=ym(n,o);var r=ym(n,i);a&&r&&(e.rangeCount!==1||e.anchorNode!==a.node||e.anchorOffset!==a.offset||e.focusNode!==r.node||e.focusOffset!==r.offset)&&(t=t.createRange(),t.setStart(a.node,a.offset),e.removeAllRanges(),o>i?(e.addRange(t),e.extend(r.node,r.offset)):(t.setEnd(r.node,r.offset),e.addRange(t)))}}for(t=[],e=n;e=e.parentNode;)e.nodeType===1&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for(typeof n.focus=="function"&&n.focus(),n=0;n<t.length;n++)e=t[n],e.element.scrollLeft=e.left,e.element.scrollTop=e.top}}var Z1=Cn&&"documentMode"in document&&11>=document.documentMode,Yi=null,Jc=null,lo=null,ed=!1;function gm(e,t,n){var i=n.window===n?n.document:n.nodeType===9?n:n.ownerDocument;ed||Yi==null||Yi!==Gr(i)||(i=Yi,"selectionStart"in i&&vu(i)?i={start:i.selectionStart,end:i.selectionEnd}:(i=(i.ownerDocument&&i.ownerDocument.defaultView||window).getSelection(),i={anchorNode:i.anchorNode,anchorOffset:i.anchorOffset,focusNode:i.focusNode,focusOffset:i.focusOffset}),lo&&Io(lo,i)||(lo=i,i=Xr(Jc,"onSelect"),0<i.length&&(t=new gu("onSelect","select",null,t,n),e.push({event:t,listeners:i}),t.target=Yi)))}function dr(e,t){var n={};return n[e.toLowerCase()]=t.toLowerCase(),n["Webkit"+e]="webkit"+t,n["Moz"+e]="moz"+t,n}var Ji={animationend:dr("Animation","AnimationEnd"),animationiteration:dr("Animation","AnimationIteration"),animationstart:dr("Animation","AnimationStart"),transitionend:dr("Transition","TransitionEnd")},Kl={},zy={};Cn&&(zy=document.createElement("div").style,"AnimationEvent"in window||(delete Ji.animationend.animation,delete Ji.animationiteration.animation,delete Ji.animationstart.animation),"TransitionEvent"in window||delete Ji.transitionend.transition);function Ps(e){if(Kl[e])return Kl[e];if(!Ji[e])return e;var t=Ji[e],n;for(n in t)if(t.hasOwnProperty(n)&&n in zy)return Kl[e]=t[n];return e}var Wy=Ps("animationend"),jy=Ps("animationiteration"),My=Ps("animationstart"),Ly=Ps("transitionend"),Fy=new Map,_m="abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");function ri(e,t){Fy.set(e,t),Oi(t,[e])}for(var Xl=0;Xl<_m.length;Xl++){var Yl=_m[Xl],Q1=Yl.toLowerCase(),K1=Yl[0].toUpperCase()+Yl.slice(1);ri(Q1,"on"+K1)}ri(Wy,"onAnimationEnd");ri(jy,"onAnimationIteration");ri(My,"onAnimationStart");ri("dblclick","onDoubleClick");ri("focusin","onFocus");ri("focusout","onBlur");ri(Ly,"onTransitionEnd");ya("onMouseEnter",["mouseout","mouseover"]);ya("onMouseLeave",["mouseout","mouseover"]);ya("onPointerEnter",["pointerout","pointerover"]);ya("onPointerLeave",["pointerout","pointerover"]);Oi("onChange","change click focusin focusout input keydown keyup selectionchange".split(" "));Oi("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" "));Oi("onBeforeInput",["compositionend","keypress","textInput","paste"]);Oi("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" "));Oi("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" "));Oi("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var to="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),X1=new Set("cancel close invalid load scroll toggle".split(" ").concat(to));function bm(e,t,n){var i=e.type||"unknown-event";e.currentTarget=n,Q0(i,t,void 0,e),e.currentTarget=null}function Uy(e,t){t=(t&4)!==0;for(var n=0;n<e.length;n++){var i=e[n],a=i.event;i=i.listeners;e:{var o=void 0;if(t)for(var r=i.length-1;0<=r;r--){var s=i[r],l=s.instance,c=s.currentTarget;if(s=s.listener,l!==o&&a.isPropagationStopped())break e;bm(a,s,c),o=l}else for(r=0;r<i.length;r++){if(s=i[r],l=s.instance,c=s.currentTarget,s=s.listener,l!==o&&a.isPropagationStopped())break e;bm(a,s,c),o=l}}}if(Vr)throw e=Qc,Vr=!1,Qc=null,e}function be(e,t){var n=t[od];n===void 0&&(n=t[od]=new Set);var i=e+"__bubble";n.has(i)||(Gy(t,e,2,!1),n.add(i))}function Jl(e,t,n){var i=0;t&&(i|=4),Gy(n,e,i,t)}var ur="_reactListening"+Math.random().toString(36).slice(2);function qo(e){if(!e[ur]){e[ur]=!0,Xh.forEach(function(n){n!=="selectionchange"&&(X1.has(n)||Jl(n,!1,e),Jl(n,!0,e))});var t=e.nodeType===9?e:e.ownerDocument;t===null||t[ur]||(t[ur]=!0,Jl("selectionchange",!1,t))}}function Gy(e,t,n,i){switch(qy(t)){case 1:var a=u1;break;case 4:a=p1;break;default:a=hu}n=a.bind(null,t,n,e),a=void 0,!Zc||t!=="touchstart"&&t!=="touchmove"&&t!=="wheel"||(a=!0),i?a!==void 0?e.addEventListener(t,n,{capture:!0,passive:a}):e.addEventListener(t,n,!0):a!==void 0?e.addEventListener(t,n,{passive:a}):e.addEventListener(t,n,!1)}function ec(e,t,n,i,a){var o=i;if(!(t&1)&&!(t&2)&&i!==null)e:for(;;){if(i===null)return;var r=i.tag;if(r===3||r===4){var s=i.stateNode.containerInfo;if(s===a||s.nodeType===8&&s.parentNode===a)break;if(r===4)for(r=i.return;r!==null;){var l=r.tag;if((l===3||l===4)&&(l=r.stateNode.containerInfo,l===a||l.nodeType===8&&l.parentNode===a))return;r=r.return}for(;s!==null;){if(r=xi(s),r===null)return;if(l=r.tag,l===5||l===6){i=o=r;continue e}s=s.parentNode}}i=i.return}my(function(){var c=o,d=uu(n),h=[];e:{var y=Fy.get(e);if(y!==void 0){var p=gu,f=e;switch(e){case"keypress":if(Sr(n)===0)break e;case"keydown":case"keyup":p=q1;break;case"focusin":f="focus",p=Hl;break;case"focusout":f="blur",p=Hl;break;case"beforeblur":case"afterblur":p=Hl;break;case"click":if(n.button===2)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":p=sm;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":p=h1;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":p=S1;break;case Wy:case jy:case My:p=_1;break;case Ly:p=A1;break;case"scroll":p=m1;break;case"wheel":p=R1;break;case"copy":case"cut":case"paste":p=v1;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":p=cm}var u=(t&4)!==0,T=!u&&e==="scroll",g=u?y!==null?y+"Capture":null:y;u=[];for(var _=c,b;_!==null;){b=_;var w=b.stateNode;if(b.tag===5&&w!==null&&(b=w,g!==null&&(w=wo(_,g),w!=null&&u.push(Do(_,w,b)))),T)break;_=_.return}0<u.length&&(y=new p(y,f,null,n,d),h.push({event:y,listeners:u}))}}if(!(t&7)){e:{if(y=e==="mouseover"||e==="pointerover",p=e==="mouseout"||e==="pointerout",y&&n!==Vc&&(f=n.relatedTarget||n.fromElement)&&(xi(f)||f[In]))break e;if((p||y)&&(y=d.window===d?d:(y=d.ownerDocument)?y.defaultView||y.parentWindow:window,p?(f=n.relatedTarget||n.toElement,p=c,f=f?xi(f):null,f!==null&&(T=zi(f),f!==T||f.tag!==5&&f.tag!==6)&&(f=null)):(p=null,f=c),p!==f)){if(u=sm,w="onMouseLeave",g="onMouseEnter",_="mouse",(e==="pointerout"||e==="pointerover")&&(u=cm,w="onPointerLeave",g="onPointerEnter",_="pointer"),T=p==null?y:ea(p),b=f==null?y:ea(f),y=new u(w,_+"leave",p,n,d),y.target=T,y.relatedTarget=b,w=null,xi(d)===c&&(u=new u(g,_+"enter",f,n,d),u.target=b,u.relatedTarget=T,w=u),T=w,p&&f)t:{for(u=p,g=f,_=0,b=u;b;b=Mi(b))_++;for(b=0,w=g;w;w=Mi(w))b++;for(;0<_-b;)u=Mi(u),_--;for(;0<b-_;)g=Mi(g),b--;for(;_--;){if(u===g||g!==null&&u===g.alternate)break t;u=Mi(u),g=Mi(g)}u=null}else u=null;p!==null&&vm(h,y,p,u,!1),f!==null&&T!==null&&vm(h,T,f,u,!0)}}e:{if(y=c?ea(c):window,p=y.nodeName&&y.nodeName.toLowerCase(),p==="select"||p==="input"&&y.type==="file")var C=L1;else if(pm(y))if(Ny)C=$1;else{C=U1;var I=F1}else(p=y.nodeName)&&p.toLowerCase()==="input"&&(y.type==="checkbox"||y.type==="radio")&&(C=G1);if(C&&(C=C(e,c))){Ay(h,C,n,d);break e}I&&I(e,y,c),e==="focusout"&&(I=y._wrapperState)&&I.controlled&&y.type==="number"&&Lc(y,"number",y.value)}switch(I=c?ea(c):window,e){case"focusin":(pm(I)||I.contentEditable==="true")&&(Yi=I,Jc=c,lo=null);break;case"focusout":lo=Jc=Yi=null;break;case"mousedown":ed=!0;break;case"contextmenu":case"mouseup":case"dragend":ed=!1,gm(h,n,d);break;case"selectionchange":if(Z1)break;case"keydown":case"keyup":gm(h,n,d)}var x;if(bu)e:{switch(e){case"compositionstart":var q="onCompositionStart";break e;case"compositionend":q="onCompositionEnd";break e;case"compositionupdate":q="onCompositionUpdate";break e}q=void 0}else Xi?Sy(e,n)&&(q="onCompositionEnd"):e==="keydown"&&n.keyCode===229&&(q="onCompositionStart");q&&(Py&&n.locale!=="ko"&&(Xi||q!=="onCompositionStart"?q==="onCompositionEnd"&&Xi&&(x=Dy()):(Gn=d,yu="value"in Gn?Gn.value:Gn.textContent,Xi=!0)),I=Xr(c,q),0<I.length&&(q=new lm(q,e,null,n,d),h.push({event:q,listeners:I}),x?q.data=x:(x=Ey(n),x!==null&&(q.data=x)))),(x=O1?z1(e,n):W1(e,n))&&(c=Xr(c,"onBeforeInput"),0<c.length&&(d=new lm("onBeforeInput","beforeinput",null,n,d),h.push({event:d,listeners:c}),d.data=x))}Uy(h,t)})}function Do(e,t,n){return{instance:e,listener:t,currentTarget:n}}function Xr(e,t){for(var n=t+"Capture",i=[];e!==null;){var a=e,o=a.stateNode;a.tag===5&&o!==null&&(a=o,o=wo(e,n),o!=null&&i.unshift(Do(e,o,a)),o=wo(e,t),o!=null&&i.push(Do(e,o,a))),e=e.return}return i}function Mi(e){if(e===null)return null;do e=e.return;while(e&&e.tag!==5);return e||null}function vm(e,t,n,i,a){for(var o=t._reactName,r=[];n!==null&&n!==i;){var s=n,l=s.alternate,c=s.stateNode;if(l!==null&&l===i)break;s.tag===5&&c!==null&&(s=c,a?(l=wo(n,o),l!=null&&r.unshift(Do(n,l,s))):a||(l=wo(n,o),l!=null&&r.push(Do(n,l,s)))),n=n.return}r.length!==0&&e.push({event:t,listeners:r})}var Y1=/\r\n?/g,J1=/\u0000|\uFFFD/g;function wm(e){return(typeof e=="string"?e:""+e).replace(Y1,`
`).replace(J1,"")}function pr(e,t,n){if(t=wm(t),wm(e)!==t&&n)throw Error(E(425))}function Yr(){}var td=null,nd=null;function id(e,t){return e==="textarea"||e==="noscript"||typeof t.children=="string"||typeof t.children=="number"||typeof t.dangerouslySetInnerHTML=="object"&&t.dangerouslySetInnerHTML!==null&&t.dangerouslySetInnerHTML.__html!=null}var ad=typeof setTimeout=="function"?setTimeout:void 0,ev=typeof clearTimeout=="function"?clearTimeout:void 0,xm=typeof Promise=="function"?Promise:void 0,tv=typeof queueMicrotask=="function"?queueMicrotask:typeof xm<"u"?function(e){return xm.resolve(null).then(e).catch(nv)}:ad;function nv(e){setTimeout(function(){throw e})}function tc(e,t){var n=t,i=0;do{var a=n.nextSibling;if(e.removeChild(n),a&&a.nodeType===8)if(n=a.data,n==="/$"){if(i===0){e.removeChild(a),ko(t);return}i--}else n!=="$"&&n!=="$?"&&n!=="$!"||i++;n=a}while(n);ko(t)}function Kn(e){for(;e!=null;e=e.nextSibling){var t=e.nodeType;if(t===1||t===3)break;if(t===8){if(t=e.data,t==="$"||t==="$!"||t==="$?")break;if(t==="/$")return null}}return e}function Tm(e){e=e.previousSibling;for(var t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="$"||n==="$!"||n==="$?"){if(t===0)return e;t--}else n==="/$"&&t++}e=e.previousSibling}return null}var Pa=Math.random().toString(36).slice(2),on="__reactFiber$"+Pa,Po="__reactProps$"+Pa,In="__reactContainer$"+Pa,od="__reactEvents$"+Pa,iv="__reactListeners$"+Pa,av="__reactHandles$"+Pa;function xi(e){var t=e[on];if(t)return t;for(var n=e.parentNode;n;){if(t=n[In]||n[on]){if(n=t.alternate,t.child!==null||n!==null&&n.child!==null)for(e=Tm(e);e!==null;){if(n=e[on])return n;e=Tm(e)}return t}e=n,n=e.parentNode}return null}function $o(e){return e=e[on]||e[In],!e||e.tag!==5&&e.tag!==6&&e.tag!==13&&e.tag!==3?null:e}function ea(e){if(e.tag===5||e.tag===6)return e.stateNode;throw Error(E(33))}function Ss(e){return e[Po]||null}var rd=[],ta=-1;function si(e){return{current:e}}function ve(e){0>ta||(e.current=rd[ta],rd[ta]=null,ta--)}function _e(e,t){ta++,rd[ta]=e.current,e.current=t}var ii={},it=si(ii),mt=si(!1),Pi=ii;function ga(e,t){var n=e.type.contextTypes;if(!n)return ii;var i=e.stateNode;if(i&&i.__reactInternalMemoizedUnmaskedChildContext===t)return i.__reactInternalMemoizedMaskedChildContext;var a={},o;for(o in n)a[o]=t[o];return i&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=a),a}function ft(e){return e=e.childContextTypes,e!=null}function Jr(){ve(mt),ve(it)}function km(e,t,n){if(it.current!==ii)throw Error(E(168));_e(it,t),_e(mt,n)}function $y(e,t,n){var i=e.stateNode;if(t=t.childContextTypes,typeof i.getChildContext!="function")return n;i=i.getChildContext();for(var a in i)if(!(a in t))throw Error(E(108,F0(e)||"Unknown",a));return Se({},n,i)}function es(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||ii,Pi=it.current,_e(it,e),_e(mt,mt.current),!0}function Cm(e,t,n){var i=e.stateNode;if(!i)throw Error(E(169));n?(e=$y(e,t,Pi),i.__reactInternalMemoizedMergedChildContext=e,ve(mt),ve(it),_e(it,e)):ve(mt),_e(mt,n)}var vn=null,Es=!1,nc=!1;function Vy(e){vn===null?vn=[e]:vn.push(e)}function ov(e){Es=!0,Vy(e)}function li(){if(!nc&&vn!==null){nc=!0;var e=0,t=ce;try{var n=vn;for(ce=1;e<n.length;e++){var i=n[e];do i=i(!0);while(i!==null)}vn=null,Es=!1}catch(a){throw vn!==null&&(vn=vn.slice(e+1)),gy(pu,li),a}finally{ce=t,nc=!1}}return null}var na=[],ia=0,ts=null,ns=0,Rt=[],Bt=0,Si=null,wn=1,xn="";function fi(e,t){na[ia++]=ns,na[ia++]=ts,ts=e,ns=t}function Hy(e,t,n){Rt[Bt++]=wn,Rt[Bt++]=xn,Rt[Bt++]=Si,Si=e;var i=wn;e=xn;var a=32-Qt(i)-1;i&=~(1<<a),n+=1;var o=32-Qt(t)+a;if(30<o){var r=a-a%5;o=(i&(1<<r)-1).toString(32),i>>=r,a-=r,wn=1<<32-Qt(t)+a|n<<a|i,xn=o+e}else wn=1<<o|n<<a|i,xn=e}function wu(e){e.return!==null&&(fi(e,1),Hy(e,1,0))}function xu(e){for(;e===ts;)ts=na[--ia],na[ia]=null,ns=na[--ia],na[ia]=null;for(;e===Si;)Si=Rt[--Bt],Rt[Bt]=null,xn=Rt[--Bt],Rt[Bt]=null,wn=Rt[--Bt],Rt[Bt]=null}var Tt=null,xt=null,Ce=!1,Ht=null;function Zy(e,t){var n=Ot(5,null,null,0);n.elementType="DELETED",n.stateNode=t,n.return=e,t=e.deletions,t===null?(e.deletions=[n],e.flags|=16):t.push(n)}function Im(e,t){switch(e.tag){case 5:var n=e.type;return t=t.nodeType!==1||n.toLowerCase()!==t.nodeName.toLowerCase()?null:t,t!==null?(e.stateNode=t,Tt=e,xt=Kn(t.firstChild),!0):!1;case 6:return t=e.pendingProps===""||t.nodeType!==3?null:t,t!==null?(e.stateNode=t,Tt=e,xt=null,!0):!1;case 13:return t=t.nodeType!==8?null:t,t!==null?(n=Si!==null?{id:wn,overflow:xn}:null,e.memoizedState={dehydrated:t,treeContext:n,retryLane:1073741824},n=Ot(18,null,null,0),n.stateNode=t,n.return=e,e.child=n,Tt=e,xt=null,!0):!1;default:return!1}}function sd(e){return(e.mode&1)!==0&&(e.flags&128)===0}function ld(e){if(Ce){var t=xt;if(t){var n=t;if(!Im(e,t)){if(sd(e))throw Error(E(418));t=Kn(n.nextSibling);var i=Tt;t&&Im(e,t)?Zy(i,n):(e.flags=e.flags&-4097|2,Ce=!1,Tt=e)}}else{if(sd(e))throw Error(E(418));e.flags=e.flags&-4097|2,Ce=!1,Tt=e}}}function qm(e){for(e=e.return;e!==null&&e.tag!==5&&e.tag!==3&&e.tag!==13;)e=e.return;Tt=e}function mr(e){if(e!==Tt)return!1;if(!Ce)return qm(e),Ce=!0,!1;var t;if((t=e.tag!==3)&&!(t=e.tag!==5)&&(t=e.type,t=t!=="head"&&t!=="body"&&!id(e.type,e.memoizedProps)),t&&(t=xt)){if(sd(e))throw Qy(),Error(E(418));for(;t;)Zy(e,t),t=Kn(t.nextSibling)}if(qm(e),e.tag===13){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(E(317));e:{for(e=e.nextSibling,t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="/$"){if(t===0){xt=Kn(e.nextSibling);break e}t--}else n!=="$"&&n!=="$!"&&n!=="$?"||t++}e=e.nextSibling}xt=null}}else xt=Tt?Kn(e.stateNode.nextSibling):null;return!0}function Qy(){for(var e=xt;e;)e=Kn(e.nextSibling)}function _a(){xt=Tt=null,Ce=!1}function Tu(e){Ht===null?Ht=[e]:Ht.push(e)}var rv=An.ReactCurrentBatchConfig;function $t(e,t){if(e&&e.defaultProps){t=Se({},t),e=e.defaultProps;for(var n in e)t[n]===void 0&&(t[n]=e[n]);return t}return t}var is=si(null),as=null,aa=null,ku=null;function Cu(){ku=aa=as=null}function Iu(e){var t=is.current;ve(is),e._currentValue=t}function cd(e,t,n){for(;e!==null;){var i=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,i!==null&&(i.childLanes|=t)):i!==null&&(i.childLanes&t)!==t&&(i.childLanes|=t),e===n)break;e=e.return}}function pa(e,t){as=e,ku=aa=null,e=e.dependencies,e!==null&&e.firstContext!==null&&(e.lanes&t&&(pt=!0),e.firstContext=null)}function jt(e){var t=e._currentValue;if(ku!==e)if(e={context:e,memoizedValue:t,next:null},aa===null){if(as===null)throw Error(E(308));aa=e,as.dependencies={lanes:0,firstContext:e}}else aa=aa.next=e;return t}var Ti=null;function qu(e){Ti===null?Ti=[e]:Ti.push(e)}function Ky(e,t,n,i){var a=t.interleaved;return a===null?(n.next=n,qu(t)):(n.next=a.next,a.next=n),t.interleaved=n,qn(e,i)}function qn(e,t){e.lanes|=t;var n=e.alternate;for(n!==null&&(n.lanes|=t),n=e,e=e.return;e!==null;)e.childLanes|=t,n=e.alternate,n!==null&&(n.childLanes|=t),n=e,e=e.return;return n.tag===3?n.stateNode:null}var Ln=!1;function Du(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function Xy(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function kn(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function Xn(e,t,n){var i=e.updateQueue;if(i===null)return null;if(i=i.shared,ne&2){var a=i.pending;return a===null?t.next=t:(t.next=a.next,a.next=t),i.pending=t,qn(e,n)}return a=i.interleaved,a===null?(t.next=t,qu(i)):(t.next=a.next,a.next=t),i.interleaved=t,qn(e,n)}function Er(e,t,n){if(t=t.updateQueue,t!==null&&(t=t.shared,(n&4194240)!==0)){var i=t.lanes;i&=e.pendingLanes,n|=i,t.lanes=n,mu(e,n)}}function Dm(e,t){var n=e.updateQueue,i=e.alternate;if(i!==null&&(i=i.updateQueue,n===i)){var a=null,o=null;if(n=n.firstBaseUpdate,n!==null){do{var r={eventTime:n.eventTime,lane:n.lane,tag:n.tag,payload:n.payload,callback:n.callback,next:null};o===null?a=o=r:o=o.next=r,n=n.next}while(n!==null);o===null?a=o=t:o=o.next=t}else a=o=t;n={baseState:i.baseState,firstBaseUpdate:a,lastBaseUpdate:o,shared:i.shared,effects:i.effects},e.updateQueue=n;return}e=n.lastBaseUpdate,e===null?n.firstBaseUpdate=t:e.next=t,n.lastBaseUpdate=t}function os(e,t,n,i){var a=e.updateQueue;Ln=!1;var o=a.firstBaseUpdate,r=a.lastBaseUpdate,s=a.shared.pending;if(s!==null){a.shared.pending=null;var l=s,c=l.next;l.next=null,r===null?o=c:r.next=c,r=l;var d=e.alternate;d!==null&&(d=d.updateQueue,s=d.lastBaseUpdate,s!==r&&(s===null?d.firstBaseUpdate=c:s.next=c,d.lastBaseUpdate=l))}if(o!==null){var h=a.baseState;r=0,d=c=l=null,s=o;do{var y=s.lane,p=s.eventTime;if((i&y)===y){d!==null&&(d=d.next={eventTime:p,lane:0,tag:s.tag,payload:s.payload,callback:s.callback,next:null});e:{var f=e,u=s;switch(y=t,p=n,u.tag){case 1:if(f=u.payload,typeof f=="function"){h=f.call(p,h,y);break e}h=f;break e;case 3:f.flags=f.flags&-65537|128;case 0:if(f=u.payload,y=typeof f=="function"?f.call(p,h,y):f,y==null)break e;h=Se({},h,y);break e;case 2:Ln=!0}}s.callback!==null&&s.lane!==0&&(e.flags|=64,y=a.effects,y===null?a.effects=[s]:y.push(s))}else p={eventTime:p,lane:y,tag:s.tag,payload:s.payload,callback:s.callback,next:null},d===null?(c=d=p,l=h):d=d.next=p,r|=y;if(s=s.next,s===null){if(s=a.shared.pending,s===null)break;y=s,s=y.next,y.next=null,a.lastBaseUpdate=y,a.shared.pending=null}}while(1);if(d===null&&(l=h),a.baseState=l,a.firstBaseUpdate=c,a.lastBaseUpdate=d,t=a.shared.interleaved,t!==null){a=t;do r|=a.lane,a=a.next;while(a!==t)}else o===null&&(a.shared.lanes=0);Ai|=r,e.lanes=r,e.memoizedState=h}}function Pm(e,t,n){if(e=t.effects,t.effects=null,e!==null)for(t=0;t<e.length;t++){var i=e[t],a=i.callback;if(a!==null){if(i.callback=null,i=n,typeof a!="function")throw Error(E(191,a));a.call(i)}}}var Yy=new Kh.Component().refs;function dd(e,t,n,i){t=e.memoizedState,n=n(i,t),n=n==null?t:Se({},t,n),e.memoizedState=n,e.lanes===0&&(e.updateQueue.baseState=n)}var As={isMounted:function(e){return(e=e._reactInternals)?zi(e)===e:!1},enqueueSetState:function(e,t,n){e=e._reactInternals;var i=ot(),a=Jn(e),o=kn(i,a);o.payload=t,n!=null&&(o.callback=n),t=Xn(e,o,a),t!==null&&(Kt(t,e,a,i),Er(t,e,a))},enqueueReplaceState:function(e,t,n){e=e._reactInternals;var i=ot(),a=Jn(e),o=kn(i,a);o.tag=1,o.payload=t,n!=null&&(o.callback=n),t=Xn(e,o,a),t!==null&&(Kt(t,e,a,i),Er(t,e,a))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var n=ot(),i=Jn(e),a=kn(n,i);a.tag=2,t!=null&&(a.callback=t),t=Xn(e,a,i),t!==null&&(Kt(t,e,i,n),Er(t,e,i))}};function Sm(e,t,n,i,a,o,r){return e=e.stateNode,typeof e.shouldComponentUpdate=="function"?e.shouldComponentUpdate(i,o,r):t.prototype&&t.prototype.isPureReactComponent?!Io(n,i)||!Io(a,o):!0}function Jy(e,t,n){var i=!1,a=ii,o=t.contextType;return typeof o=="object"&&o!==null?o=jt(o):(a=ft(t)?Pi:it.current,i=t.contextTypes,o=(i=i!=null)?ga(e,a):ii),t=new t(n,o),e.memoizedState=t.state!==null&&t.state!==void 0?t.state:null,t.updater=As,e.stateNode=t,t._reactInternals=e,i&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=a,e.__reactInternalMemoizedMaskedChildContext=o),t}function Em(e,t,n,i){e=t.state,typeof t.componentWillReceiveProps=="function"&&t.componentWillReceiveProps(n,i),typeof t.UNSAFE_componentWillReceiveProps=="function"&&t.UNSAFE_componentWillReceiveProps(n,i),t.state!==e&&As.enqueueReplaceState(t,t.state,null)}function ud(e,t,n,i){var a=e.stateNode;a.props=n,a.state=e.memoizedState,a.refs=Yy,Du(e);var o=t.contextType;typeof o=="object"&&o!==null?a.context=jt(o):(o=ft(t)?Pi:it.current,a.context=ga(e,o)),a.state=e.memoizedState,o=t.getDerivedStateFromProps,typeof o=="function"&&(dd(e,t,o,n),a.state=e.memoizedState),typeof t.getDerivedStateFromProps=="function"||typeof a.getSnapshotBeforeUpdate=="function"||typeof a.UNSAFE_componentWillMount!="function"&&typeof a.componentWillMount!="function"||(t=a.state,typeof a.componentWillMount=="function"&&a.componentWillMount(),typeof a.UNSAFE_componentWillMount=="function"&&a.UNSAFE_componentWillMount(),t!==a.state&&As.enqueueReplaceState(a,a.state,null),os(e,n,a,i),a.state=e.memoizedState),typeof a.componentDidMount=="function"&&(e.flags|=4194308)}function La(e,t,n){if(e=n.ref,e!==null&&typeof e!="function"&&typeof e!="object"){if(n._owner){if(n=n._owner,n){if(n.tag!==1)throw Error(E(309));var i=n.stateNode}if(!i)throw Error(E(147,e));var a=i,o=""+e;return t!==null&&t.ref!==null&&typeof t.ref=="function"&&t.ref._stringRef===o?t.ref:(t=function(r){var s=a.refs;s===Yy&&(s=a.refs={}),r===null?delete s[o]:s[o]=r},t._stringRef=o,t)}if(typeof e!="string")throw Error(E(284));if(!n._owner)throw Error(E(290,e))}return e}function fr(e,t){throw e=Object.prototype.toString.call(t),Error(E(31,e==="[object Object]"?"object with keys {"+Object.keys(t).join(", ")+"}":e))}function Am(e){var t=e._init;return t(e._payload)}function eg(e){function t(g,_){if(e){var b=g.deletions;b===null?(g.deletions=[_],g.flags|=16):b.push(_)}}function n(g,_){if(!e)return null;for(;_!==null;)t(g,_),_=_.sibling;return null}function i(g,_){for(g=new Map;_!==null;)_.key!==null?g.set(_.key,_):g.set(_.index,_),_=_.sibling;return g}function a(g,_){return g=ei(g,_),g.index=0,g.sibling=null,g}function o(g,_,b){return g.index=b,e?(b=g.alternate,b!==null?(b=b.index,b<_?(g.flags|=2,_):b):(g.flags|=2,_)):(g.flags|=1048576,_)}function r(g){return e&&g.alternate===null&&(g.flags|=2),g}function s(g,_,b,w){return _===null||_.tag!==6?(_=cc(b,g.mode,w),_.return=g,_):(_=a(_,b),_.return=g,_)}function l(g,_,b,w){var C=b.type;return C===Ki?d(g,_,b.props.children,w,b.key):_!==null&&(_.elementType===C||typeof C=="object"&&C!==null&&C.$$typeof===Mn&&Am(C)===_.type)?(w=a(_,b.props),w.ref=La(g,_,b),w.return=g,w):(w=zr(b.type,b.key,b.props,null,g.mode,w),w.ref=La(g,_,b),w.return=g,w)}function c(g,_,b,w){return _===null||_.tag!==4||_.stateNode.containerInfo!==b.containerInfo||_.stateNode.implementation!==b.implementation?(_=dc(b,g.mode,w),_.return=g,_):(_=a(_,b.children||[]),_.return=g,_)}function d(g,_,b,w,C){return _===null||_.tag!==7?(_=Di(b,g.mode,w,C),_.return=g,_):(_=a(_,b),_.return=g,_)}function h(g,_,b){if(typeof _=="string"&&_!==""||typeof _=="number")return _=cc(""+_,g.mode,b),_.return=g,_;if(typeof _=="object"&&_!==null){switch(_.$$typeof){case ir:return b=zr(_.type,_.key,_.props,null,g.mode,b),b.ref=La(g,null,_),b.return=g,b;case Qi:return _=dc(_,g.mode,b),_.return=g,_;case Mn:var w=_._init;return h(g,w(_._payload),b)}if(Ja(_)||Oa(_))return _=Di(_,g.mode,b,null),_.return=g,_;fr(g,_)}return null}function y(g,_,b,w){var C=_!==null?_.key:null;if(typeof b=="string"&&b!==""||typeof b=="number")return C!==null?null:s(g,_,""+b,w);if(typeof b=="object"&&b!==null){switch(b.$$typeof){case ir:return b.key===C?l(g,_,b,w):null;case Qi:return b.key===C?c(g,_,b,w):null;case Mn:return C=b._init,y(g,_,C(b._payload),w)}if(Ja(b)||Oa(b))return C!==null?null:d(g,_,b,w,null);fr(g,b)}return null}function p(g,_,b,w,C){if(typeof w=="string"&&w!==""||typeof w=="number")return g=g.get(b)||null,s(_,g,""+w,C);if(typeof w=="object"&&w!==null){switch(w.$$typeof){case ir:return g=g.get(w.key===null?b:w.key)||null,l(_,g,w,C);case Qi:return g=g.get(w.key===null?b:w.key)||null,c(_,g,w,C);case Mn:var I=w._init;return p(g,_,b,I(w._payload),C)}if(Ja(w)||Oa(w))return g=g.get(b)||null,d(_,g,w,C,null);fr(_,w)}return null}function f(g,_,b,w){for(var C=null,I=null,x=_,q=_=0,S=null;x!==null&&q<b.length;q++){x.index>q?(S=x,x=null):S=x.sibling;var P=y(g,x,b[q],w);if(P===null){x===null&&(x=S);break}e&&x&&P.alternate===null&&t(g,x),_=o(P,_,q),I===null?C=P:I.sibling=P,I=P,x=S}if(q===b.length)return n(g,x),Ce&&fi(g,q),C;if(x===null){for(;q<b.length;q++)x=h(g,b[q],w),x!==null&&(_=o(x,_,q),I===null?C=x:I.sibling=x,I=x);return Ce&&fi(g,q),C}for(x=i(g,x);q<b.length;q++)S=p(x,g,q,b[q],w),S!==null&&(e&&S.alternate!==null&&x.delete(S.key===null?q:S.key),_=o(S,_,q),I===null?C=S:I.sibling=S,I=S);return e&&x.forEach(function(R){return t(g,R)}),Ce&&fi(g,q),C}function u(g,_,b,w){var C=Oa(b);if(typeof C!="function")throw Error(E(150));if(b=C.call(b),b==null)throw Error(E(151));for(var I=C=null,x=_,q=_=0,S=null,P=b.next();x!==null&&!P.done;q++,P=b.next()){x.index>q?(S=x,x=null):S=x.sibling;var R=y(g,x,P.value,w);if(R===null){x===null&&(x=S);break}e&&x&&R.alternate===null&&t(g,x),_=o(R,_,q),I===null?C=R:I.sibling=R,I=R,x=S}if(P.done)return n(g,x),Ce&&fi(g,q),C;if(x===null){for(;!P.done;q++,P=b.next())P=h(g,P.value,w),P!==null&&(_=o(P,_,q),I===null?C=P:I.sibling=P,I=P);return Ce&&fi(g,q),C}for(x=i(g,x);!P.done;q++,P=b.next())P=p(x,g,q,P.value,w),P!==null&&(e&&P.alternate!==null&&x.delete(P.key===null?q:P.key),_=o(P,_,q),I===null?C=P:I.sibling=P,I=P);return e&&x.forEach(function(O){return t(g,O)}),Ce&&fi(g,q),C}function T(g,_,b,w){if(typeof b=="object"&&b!==null&&b.type===Ki&&b.key===null&&(b=b.props.children),typeof b=="object"&&b!==null){switch(b.$$typeof){case ir:e:{for(var C=b.key,I=_;I!==null;){if(I.key===C){if(C=b.type,C===Ki){if(I.tag===7){n(g,I.sibling),_=a(I,b.props.children),_.return=g,g=_;break e}}else if(I.elementType===C||typeof C=="object"&&C!==null&&C.$$typeof===Mn&&Am(C)===I.type){n(g,I.sibling),_=a(I,b.props),_.ref=La(g,I,b),_.return=g,g=_;break e}n(g,I);break}else t(g,I);I=I.sibling}b.type===Ki?(_=Di(b.props.children,g.mode,w,b.key),_.return=g,g=_):(w=zr(b.type,b.key,b.props,null,g.mode,w),w.ref=La(g,_,b),w.return=g,g=w)}return r(g);case Qi:e:{for(I=b.key;_!==null;){if(_.key===I)if(_.tag===4&&_.stateNode.containerInfo===b.containerInfo&&_.stateNode.implementation===b.implementation){n(g,_.sibling),_=a(_,b.children||[]),_.return=g,g=_;break e}else{n(g,_);break}else t(g,_);_=_.sibling}_=dc(b,g.mode,w),_.return=g,g=_}return r(g);case Mn:return I=b._init,T(g,_,I(b._payload),w)}if(Ja(b))return f(g,_,b,w);if(Oa(b))return u(g,_,b,w);fr(g,b)}return typeof b=="string"&&b!==""||typeof b=="number"?(b=""+b,_!==null&&_.tag===6?(n(g,_.sibling),_=a(_,b),_.return=g,g=_):(n(g,_),_=cc(b,g.mode,w),_.return=g,g=_),r(g)):n(g,_)}return T}var ba=eg(!0),tg=eg(!1),Vo={},dn=si(Vo),So=si(Vo),Eo=si(Vo);function ki(e){if(e===Vo)throw Error(E(174));return e}function Pu(e,t){switch(_e(Eo,t),_e(So,e),_e(dn,Vo),e=t.nodeType,e){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:Uc(null,"");break;default:e=e===8?t.parentNode:t,t=e.namespaceURI||null,e=e.tagName,t=Uc(t,e)}ve(dn),_e(dn,t)}function va(){ve(dn),ve(So),ve(Eo)}function ng(e){ki(Eo.current);var t=ki(dn.current),n=Uc(t,e.type);t!==n&&(_e(So,e),_e(dn,n))}function Su(e){So.current===e&&(ve(dn),ve(So))}var De=si(0);function rs(e){for(var t=e;t!==null;){if(t.tag===13){var n=t.memoizedState;if(n!==null&&(n=n.dehydrated,n===null||n.data==="$?"||n.data==="$!"))return t}else if(t.tag===19&&t.memoizedProps.revealOrder!==void 0){if(t.flags&128)return t}else if(t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var ic=[];function Eu(){for(var e=0;e<ic.length;e++)ic[e]._workInProgressVersionPrimary=null;ic.length=0}var Ar=An.ReactCurrentDispatcher,ac=An.ReactCurrentBatchConfig,Ei=0,Pe=null,Me=null,Fe=null,ss=!1,co=!1,Ao=0,sv=0;function Je(){throw Error(E(321))}function Au(e,t){if(t===null)return!1;for(var n=0;n<t.length&&n<e.length;n++)if(!Xt(e[n],t[n]))return!1;return!0}function Nu(e,t,n,i,a,o){if(Ei=o,Pe=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,Ar.current=e===null||e.memoizedState===null?uv:pv,e=n(i,a),co){o=0;do{if(co=!1,Ao=0,25<=o)throw Error(E(301));o+=1,Fe=Me=null,t.updateQueue=null,Ar.current=mv,e=n(i,a)}while(co)}if(Ar.current=ls,t=Me!==null&&Me.next!==null,Ei=0,Fe=Me=Pe=null,ss=!1,t)throw Error(E(300));return e}function Ru(){var e=Ao!==0;return Ao=0,e}function tn(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return Fe===null?Pe.memoizedState=Fe=e:Fe=Fe.next=e,Fe}function Mt(){if(Me===null){var e=Pe.alternate;e=e!==null?e.memoizedState:null}else e=Me.next;var t=Fe===null?Pe.memoizedState:Fe.next;if(t!==null)Fe=t,Me=e;else{if(e===null)throw Error(E(310));Me=e,e={memoizedState:Me.memoizedState,baseState:Me.baseState,baseQueue:Me.baseQueue,queue:Me.queue,next:null},Fe===null?Pe.memoizedState=Fe=e:Fe=Fe.next=e}return Fe}function No(e,t){return typeof t=="function"?t(e):t}function oc(e){var t=Mt(),n=t.queue;if(n===null)throw Error(E(311));n.lastRenderedReducer=e;var i=Me,a=i.baseQueue,o=n.pending;if(o!==null){if(a!==null){var r=a.next;a.next=o.next,o.next=r}i.baseQueue=a=o,n.pending=null}if(a!==null){o=a.next,i=i.baseState;var s=r=null,l=null,c=o;do{var d=c.lane;if((Ei&d)===d)l!==null&&(l=l.next={lane:0,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null}),i=c.hasEagerState?c.eagerState:e(i,c.action);else{var h={lane:d,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null};l===null?(s=l=h,r=i):l=l.next=h,Pe.lanes|=d,Ai|=d}c=c.next}while(c!==null&&c!==o);l===null?r=i:l.next=s,Xt(i,t.memoizedState)||(pt=!0),t.memoizedState=i,t.baseState=r,t.baseQueue=l,n.lastRenderedState=i}if(e=n.interleaved,e!==null){a=e;do o=a.lane,Pe.lanes|=o,Ai|=o,a=a.next;while(a!==e)}else a===null&&(n.lanes=0);return[t.memoizedState,n.dispatch]}function rc(e){var t=Mt(),n=t.queue;if(n===null)throw Error(E(311));n.lastRenderedReducer=e;var i=n.dispatch,a=n.pending,o=t.memoizedState;if(a!==null){n.pending=null;var r=a=a.next;do o=e(o,r.action),r=r.next;while(r!==a);Xt(o,t.memoizedState)||(pt=!0),t.memoizedState=o,t.baseQueue===null&&(t.baseState=o),n.lastRenderedState=o}return[o,i]}function ig(){}function ag(e,t){var n=Pe,i=Mt(),a=t(),o=!Xt(i.memoizedState,a);if(o&&(i.memoizedState=a,pt=!0),i=i.queue,Bu(sg.bind(null,n,i,e),[e]),i.getSnapshot!==t||o||Fe!==null&&Fe.memoizedState.tag&1){if(n.flags|=2048,Ro(9,rg.bind(null,n,i,a,t),void 0,null),Ue===null)throw Error(E(349));Ei&30||og(n,t,a)}return a}function og(e,t,n){e.flags|=16384,e={getSnapshot:t,value:n},t=Pe.updateQueue,t===null?(t={lastEffect:null,stores:null},Pe.updateQueue=t,t.stores=[e]):(n=t.stores,n===null?t.stores=[e]:n.push(e))}function rg(e,t,n,i){t.value=n,t.getSnapshot=i,lg(t)&&cg(e)}function sg(e,t,n){return n(function(){lg(t)&&cg(e)})}function lg(e){var t=e.getSnapshot;e=e.value;try{var n=t();return!Xt(e,n)}catch{return!0}}function cg(e){var t=qn(e,1);t!==null&&Kt(t,e,1,-1)}function Nm(e){var t=tn();return typeof e=="function"&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:No,lastRenderedState:e},t.queue=e,e=e.dispatch=dv.bind(null,Pe,e),[t.memoizedState,e]}function Ro(e,t,n,i){return e={tag:e,create:t,destroy:n,deps:i,next:null},t=Pe.updateQueue,t===null?(t={lastEffect:null,stores:null},Pe.updateQueue=t,t.lastEffect=e.next=e):(n=t.lastEffect,n===null?t.lastEffect=e.next=e:(i=n.next,n.next=e,e.next=i,t.lastEffect=e)),e}function dg(){return Mt().memoizedState}function Nr(e,t,n,i){var a=tn();Pe.flags|=e,a.memoizedState=Ro(1|t,n,void 0,i===void 0?null:i)}function Ns(e,t,n,i){var a=Mt();i=i===void 0?null:i;var o=void 0;if(Me!==null){var r=Me.memoizedState;if(o=r.destroy,i!==null&&Au(i,r.deps)){a.memoizedState=Ro(t,n,o,i);return}}Pe.flags|=e,a.memoizedState=Ro(1|t,n,o,i)}function Rm(e,t){return Nr(8390656,8,e,t)}function Bu(e,t){return Ns(2048,8,e,t)}function ug(e,t){return Ns(4,2,e,t)}function pg(e,t){return Ns(4,4,e,t)}function mg(e,t){if(typeof t=="function")return e=e(),t(e),function(){t(null)};if(t!=null)return e=e(),t.current=e,function(){t.current=null}}function fg(e,t,n){return n=n!=null?n.concat([e]):null,Ns(4,4,mg.bind(null,t,e),n)}function Ou(){}function hg(e,t){var n=Mt();t=t===void 0?null:t;var i=n.memoizedState;return i!==null&&t!==null&&Au(t,i[1])?i[0]:(n.memoizedState=[e,t],e)}function yg(e,t){var n=Mt();t=t===void 0?null:t;var i=n.memoizedState;return i!==null&&t!==null&&Au(t,i[1])?i[0]:(e=e(),n.memoizedState=[e,t],e)}function gg(e,t,n){return Ei&21?(Xt(n,t)||(n=vy(),Pe.lanes|=n,Ai|=n,e.baseState=!0),t):(e.baseState&&(e.baseState=!1,pt=!0),e.memoizedState=n)}function lv(e,t){var n=ce;ce=n!==0&&4>n?n:4,e(!0);var i=ac.transition;ac.transition={};try{e(!1),t()}finally{ce=n,ac.transition=i}}function _g(){return Mt().memoizedState}function cv(e,t,n){var i=Jn(e);if(n={lane:i,action:n,hasEagerState:!1,eagerState:null,next:null},bg(e))vg(t,n);else if(n=Ky(e,t,n,i),n!==null){var a=ot();Kt(n,e,i,a),wg(n,t,i)}}function dv(e,t,n){var i=Jn(e),a={lane:i,action:n,hasEagerState:!1,eagerState:null,next:null};if(bg(e))vg(t,a);else{var o=e.alternate;if(e.lanes===0&&(o===null||o.lanes===0)&&(o=t.lastRenderedReducer,o!==null))try{var r=t.lastRenderedState,s=o(r,n);if(a.hasEagerState=!0,a.eagerState=s,Xt(s,r)){var l=t.interleaved;l===null?(a.next=a,qu(t)):(a.next=l.next,l.next=a),t.interleaved=a;return}}catch{}finally{}n=Ky(e,t,a,i),n!==null&&(a=ot(),Kt(n,e,i,a),wg(n,t,i))}}function bg(e){var t=e.alternate;return e===Pe||t!==null&&t===Pe}function vg(e,t){co=ss=!0;var n=e.pending;n===null?t.next=t:(t.next=n.next,n.next=t),e.pending=t}function wg(e,t,n){if(n&4194240){var i=t.lanes;i&=e.pendingLanes,n|=i,t.lanes=n,mu(e,n)}}var ls={readContext:jt,useCallback:Je,useContext:Je,useEffect:Je,useImperativeHandle:Je,useInsertionEffect:Je,useLayoutEffect:Je,useMemo:Je,useReducer:Je,useRef:Je,useState:Je,useDebugValue:Je,useDeferredValue:Je,useTransition:Je,useMutableSource:Je,useSyncExternalStore:Je,useId:Je,unstable_isNewReconciler:!1},uv={readContext:jt,useCallback:function(e,t){return tn().memoizedState=[e,t===void 0?null:t],e},useContext:jt,useEffect:Rm,useImperativeHandle:function(e,t,n){return n=n!=null?n.concat([e]):null,Nr(4194308,4,mg.bind(null,t,e),n)},useLayoutEffect:function(e,t){return Nr(4194308,4,e,t)},useInsertionEffect:function(e,t){return Nr(4,2,e,t)},useMemo:function(e,t){var n=tn();return t=t===void 0?null:t,e=e(),n.memoizedState=[e,t],e},useReducer:function(e,t,n){var i=tn();return t=n!==void 0?n(t):t,i.memoizedState=i.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},i.queue=e,e=e.dispatch=cv.bind(null,Pe,e),[i.memoizedState,e]},useRef:function(e){var t=tn();return e={current:e},t.memoizedState=e},useState:Nm,useDebugValue:Ou,useDeferredValue:function(e){return tn().memoizedState=e},useTransition:function(){var e=Nm(!1),t=e[0];return e=lv.bind(null,e[1]),tn().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,n){var i=Pe,a=tn();if(Ce){if(n===void 0)throw Error(E(407));n=n()}else{if(n=t(),Ue===null)throw Error(E(349));Ei&30||og(i,t,n)}a.memoizedState=n;var o={value:n,getSnapshot:t};return a.queue=o,Rm(sg.bind(null,i,o,e),[e]),i.flags|=2048,Ro(9,rg.bind(null,i,o,n,t),void 0,null),n},useId:function(){var e=tn(),t=Ue.identifierPrefix;if(Ce){var n=xn,i=wn;n=(i&~(1<<32-Qt(i)-1)).toString(32)+n,t=":"+t+"R"+n,n=Ao++,0<n&&(t+="H"+n.toString(32)),t+=":"}else n=sv++,t=":"+t+"r"+n.toString(32)+":";return e.memoizedState=t},unstable_isNewReconciler:!1},pv={readContext:jt,useCallback:hg,useContext:jt,useEffect:Bu,useImperativeHandle:fg,useInsertionEffect:ug,useLayoutEffect:pg,useMemo:yg,useReducer:oc,useRef:dg,useState:function(){return oc(No)},useDebugValue:Ou,useDeferredValue:function(e){var t=Mt();return gg(t,Me.memoizedState,e)},useTransition:function(){var e=oc(No)[0],t=Mt().memoizedState;return[e,t]},useMutableSource:ig,useSyncExternalStore:ag,useId:_g,unstable_isNewReconciler:!1},mv={readContext:jt,useCallback:hg,useContext:jt,useEffect:Bu,useImperativeHandle:fg,useInsertionEffect:ug,useLayoutEffect:pg,useMemo:yg,useReducer:rc,useRef:dg,useState:function(){return rc(No)},useDebugValue:Ou,useDeferredValue:function(e){var t=Mt();return Me===null?t.memoizedState=e:gg(t,Me.memoizedState,e)},useTransition:function(){var e=rc(No)[0],t=Mt().memoizedState;return[e,t]},useMutableSource:ig,useSyncExternalStore:ag,useId:_g,unstable_isNewReconciler:!1};function wa(e,t){try{var n="",i=t;do n+=L0(i),i=i.return;while(i);var a=n}catch(o){a=`
Error generating stack: `+o.message+`
`+o.stack}return{value:e,source:t,stack:a,digest:null}}function sc(e,t,n){return{value:e,source:null,stack:n??null,digest:t??null}}function pd(e,t){try{console.error(t.value)}catch(n){setTimeout(function(){throw n})}}var fv=typeof WeakMap=="function"?WeakMap:Map;function xg(e,t,n){n=kn(-1,n),n.tag=3,n.payload={element:null};var i=t.value;return n.callback=function(){ds||(ds=!0,xd=i),pd(e,t)},n}function Tg(e,t,n){n=kn(-1,n),n.tag=3;var i=e.type.getDerivedStateFromError;if(typeof i=="function"){var a=t.value;n.payload=function(){return i(a)},n.callback=function(){pd(e,t)}}var o=e.stateNode;return o!==null&&typeof o.componentDidCatch=="function"&&(n.callback=function(){pd(e,t),typeof i!="function"&&(Yn===null?Yn=new Set([this]):Yn.add(this));var r=t.stack;this.componentDidCatch(t.value,{componentStack:r!==null?r:""})}),n}function Bm(e,t,n){var i=e.pingCache;if(i===null){i=e.pingCache=new fv;var a=new Set;i.set(t,a)}else a=i.get(t),a===void 0&&(a=new Set,i.set(t,a));a.has(n)||(a.add(n),e=Dv.bind(null,e,t,n),t.then(e,e))}function Om(e){do{var t;if((t=e.tag===13)&&(t=e.memoizedState,t=t!==null?t.dehydrated!==null:!0),t)return e;e=e.return}while(e!==null);return null}function zm(e,t,n,i,a){return e.mode&1?(e.flags|=65536,e.lanes=a,e):(e===t?e.flags|=65536:(e.flags|=128,n.flags|=131072,n.flags&=-52805,n.tag===1&&(n.alternate===null?n.tag=17:(t=kn(-1,1),t.tag=2,Xn(n,t,1))),n.lanes|=1),e)}var hv=An.ReactCurrentOwner,pt=!1;function at(e,t,n,i){t.child=e===null?tg(t,null,n,i):ba(t,e.child,n,i)}function Wm(e,t,n,i,a){n=n.render;var o=t.ref;return pa(t,a),i=Nu(e,t,n,i,o,a),n=Ru(),e!==null&&!pt?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,Dn(e,t,a)):(Ce&&n&&wu(t),t.flags|=1,at(e,t,i,a),t.child)}function jm(e,t,n,i,a){if(e===null){var o=n.type;return typeof o=="function"&&!Gu(o)&&o.defaultProps===void 0&&n.compare===null&&n.defaultProps===void 0?(t.tag=15,t.type=o,kg(e,t,o,i,a)):(e=zr(n.type,null,i,t,t.mode,a),e.ref=t.ref,e.return=t,t.child=e)}if(o=e.child,!(e.lanes&a)){var r=o.memoizedProps;if(n=n.compare,n=n!==null?n:Io,n(r,i)&&e.ref===t.ref)return Dn(e,t,a)}return t.flags|=1,e=ei(o,i),e.ref=t.ref,e.return=t,t.child=e}function kg(e,t,n,i,a){if(e!==null){var o=e.memoizedProps;if(Io(o,i)&&e.ref===t.ref)if(pt=!1,t.pendingProps=i=o,(e.lanes&a)!==0)e.flags&131072&&(pt=!0);else return t.lanes=e.lanes,Dn(e,t,a)}return md(e,t,n,i,a)}function Cg(e,t,n){var i=t.pendingProps,a=i.children,o=e!==null?e.memoizedState:null;if(i.mode==="hidden")if(!(t.mode&1))t.memoizedState={baseLanes:0,cachePool:null,transitions:null},_e(ra,bt),bt|=n;else{if(!(n&1073741824))return e=o!==null?o.baseLanes|n:n,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,_e(ra,bt),bt|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},i=o!==null?o.baseLanes:n,_e(ra,bt),bt|=i}else o!==null?(i=o.baseLanes|n,t.memoizedState=null):i=n,_e(ra,bt),bt|=i;return at(e,t,a,n),t.child}function Ig(e,t){var n=t.ref;(e===null&&n!==null||e!==null&&e.ref!==n)&&(t.flags|=512,t.flags|=2097152)}function md(e,t,n,i,a){var o=ft(n)?Pi:it.current;return o=ga(t,o),pa(t,a),n=Nu(e,t,n,i,o,a),i=Ru(),e!==null&&!pt?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,Dn(e,t,a)):(Ce&&i&&wu(t),t.flags|=1,at(e,t,n,a),t.child)}function Mm(e,t,n,i,a){if(ft(n)){var o=!0;es(t)}else o=!1;if(pa(t,a),t.stateNode===null)Rr(e,t),Jy(t,n,i),ud(t,n,i,a),i=!0;else if(e===null){var r=t.stateNode,s=t.memoizedProps;r.props=s;var l=r.context,c=n.contextType;typeof c=="object"&&c!==null?c=jt(c):(c=ft(n)?Pi:it.current,c=ga(t,c));var d=n.getDerivedStateFromProps,h=typeof d=="function"||typeof r.getSnapshotBeforeUpdate=="function";h||typeof r.UNSAFE_componentWillReceiveProps!="function"&&typeof r.componentWillReceiveProps!="function"||(s!==i||l!==c)&&Em(t,r,i,c),Ln=!1;var y=t.memoizedState;r.state=y,os(t,i,r,a),l=t.memoizedState,s!==i||y!==l||mt.current||Ln?(typeof d=="function"&&(dd(t,n,d,i),l=t.memoizedState),(s=Ln||Sm(t,n,s,i,y,l,c))?(h||typeof r.UNSAFE_componentWillMount!="function"&&typeof r.componentWillMount!="function"||(typeof r.componentWillMount=="function"&&r.componentWillMount(),typeof r.UNSAFE_componentWillMount=="function"&&r.UNSAFE_componentWillMount()),typeof r.componentDidMount=="function"&&(t.flags|=4194308)):(typeof r.componentDidMount=="function"&&(t.flags|=4194308),t.memoizedProps=i,t.memoizedState=l),r.props=i,r.state=l,r.context=c,i=s):(typeof r.componentDidMount=="function"&&(t.flags|=4194308),i=!1)}else{r=t.stateNode,Xy(e,t),s=t.memoizedProps,c=t.type===t.elementType?s:$t(t.type,s),r.props=c,h=t.pendingProps,y=r.context,l=n.contextType,typeof l=="object"&&l!==null?l=jt(l):(l=ft(n)?Pi:it.current,l=ga(t,l));var p=n.getDerivedStateFromProps;(d=typeof p=="function"||typeof r.getSnapshotBeforeUpdate=="function")||typeof r.UNSAFE_componentWillReceiveProps!="function"&&typeof r.componentWillReceiveProps!="function"||(s!==h||y!==l)&&Em(t,r,i,l),Ln=!1,y=t.memoizedState,r.state=y,os(t,i,r,a);var f=t.memoizedState;s!==h||y!==f||mt.current||Ln?(typeof p=="function"&&(dd(t,n,p,i),f=t.memoizedState),(c=Ln||Sm(t,n,c,i,y,f,l)||!1)?(d||typeof r.UNSAFE_componentWillUpdate!="function"&&typeof r.componentWillUpdate!="function"||(typeof r.componentWillUpdate=="function"&&r.componentWillUpdate(i,f,l),typeof r.UNSAFE_componentWillUpdate=="function"&&r.UNSAFE_componentWillUpdate(i,f,l)),typeof r.componentDidUpdate=="function"&&(t.flags|=4),typeof r.getSnapshotBeforeUpdate=="function"&&(t.flags|=1024)):(typeof r.componentDidUpdate!="function"||s===e.memoizedProps&&y===e.memoizedState||(t.flags|=4),typeof r.getSnapshotBeforeUpdate!="function"||s===e.memoizedProps&&y===e.memoizedState||(t.flags|=1024),t.memoizedProps=i,t.memoizedState=f),r.props=i,r.state=f,r.context=l,i=c):(typeof r.componentDidUpdate!="function"||s===e.memoizedProps&&y===e.memoizedState||(t.flags|=4),typeof r.getSnapshotBeforeUpdate!="function"||s===e.memoizedProps&&y===e.memoizedState||(t.flags|=1024),i=!1)}return fd(e,t,n,i,o,a)}function fd(e,t,n,i,a,o){Ig(e,t);var r=(t.flags&128)!==0;if(!i&&!r)return a&&Cm(t,n,!1),Dn(e,t,o);i=t.stateNode,hv.current=t;var s=r&&typeof n.getDerivedStateFromError!="function"?null:i.render();return t.flags|=1,e!==null&&r?(t.child=ba(t,e.child,null,o),t.child=ba(t,null,s,o)):at(e,t,s,o),t.memoizedState=i.state,a&&Cm(t,n,!0),t.child}function qg(e){var t=e.stateNode;t.pendingContext?km(e,t.pendingContext,t.pendingContext!==t.context):t.context&&km(e,t.context,!1),Pu(e,t.containerInfo)}function Lm(e,t,n,i,a){return _a(),Tu(a),t.flags|=256,at(e,t,n,i),t.child}var hd={dehydrated:null,treeContext:null,retryLane:0};function yd(e){return{baseLanes:e,cachePool:null,transitions:null}}function Dg(e,t,n){var i=t.pendingProps,a=De.current,o=!1,r=(t.flags&128)!==0,s;if((s=r)||(s=e!==null&&e.memoizedState===null?!1:(a&2)!==0),s?(o=!0,t.flags&=-129):(e===null||e.memoizedState!==null)&&(a|=1),_e(De,a&1),e===null)return ld(t),e=t.memoizedState,e!==null&&(e=e.dehydrated,e!==null)?(t.mode&1?e.data==="$!"?t.lanes=8:t.lanes=1073741824:t.lanes=1,null):(r=i.children,e=i.fallback,o?(i=t.mode,o=t.child,r={mode:"hidden",children:r},!(i&1)&&o!==null?(o.childLanes=0,o.pendingProps=r):o=Os(r,i,0,null),e=Di(e,i,n,null),o.return=t,e.return=t,o.sibling=e,t.child=o,t.child.memoizedState=yd(n),t.memoizedState=hd,e):zu(t,r));if(a=e.memoizedState,a!==null&&(s=a.dehydrated,s!==null))return yv(e,t,r,i,s,a,n);if(o){o=i.fallback,r=t.mode,a=e.child,s=a.sibling;var l={mode:"hidden",children:i.children};return!(r&1)&&t.child!==a?(i=t.child,i.childLanes=0,i.pendingProps=l,t.deletions=null):(i=ei(a,l),i.subtreeFlags=a.subtreeFlags&14680064),s!==null?o=ei(s,o):(o=Di(o,r,n,null),o.flags|=2),o.return=t,i.return=t,i.sibling=o,t.child=i,i=o,o=t.child,r=e.child.memoizedState,r=r===null?yd(n):{baseLanes:r.baseLanes|n,cachePool:null,transitions:r.transitions},o.memoizedState=r,o.childLanes=e.childLanes&~n,t.memoizedState=hd,i}return o=e.child,e=o.sibling,i=ei(o,{mode:"visible",children:i.children}),!(t.mode&1)&&(i.lanes=n),i.return=t,i.sibling=null,e!==null&&(n=t.deletions,n===null?(t.deletions=[e],t.flags|=16):n.push(e)),t.child=i,t.memoizedState=null,i}function zu(e,t){return t=Os({mode:"visible",children:t},e.mode,0,null),t.return=e,e.child=t}function hr(e,t,n,i){return i!==null&&Tu(i),ba(t,e.child,null,n),e=zu(t,t.pendingProps.children),e.flags|=2,t.memoizedState=null,e}function yv(e,t,n,i,a,o,r){if(n)return t.flags&256?(t.flags&=-257,i=sc(Error(E(422))),hr(e,t,r,i)):t.memoizedState!==null?(t.child=e.child,t.flags|=128,null):(o=i.fallback,a=t.mode,i=Os({mode:"visible",children:i.children},a,0,null),o=Di(o,a,r,null),o.flags|=2,i.return=t,o.return=t,i.sibling=o,t.child=i,t.mode&1&&ba(t,e.child,null,r),t.child.memoizedState=yd(r),t.memoizedState=hd,o);if(!(t.mode&1))return hr(e,t,r,null);if(a.data==="$!"){if(i=a.nextSibling&&a.nextSibling.dataset,i)var s=i.dgst;return i=s,o=Error(E(419)),i=sc(o,i,void 0),hr(e,t,r,i)}if(s=(r&e.childLanes)!==0,pt||s){if(i=Ue,i!==null){switch(r&-r){case 4:a=2;break;case 16:a=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:a=32;break;case 536870912:a=268435456;break;default:a=0}a=a&(i.suspendedLanes|r)?0:a,a!==0&&a!==o.retryLane&&(o.retryLane=a,qn(e,a),Kt(i,e,a,-1))}return Uu(),i=sc(Error(E(421))),hr(e,t,r,i)}return a.data==="$?"?(t.flags|=128,t.child=e.child,t=Pv.bind(null,e),a._reactRetry=t,null):(e=o.treeContext,xt=Kn(a.nextSibling),Tt=t,Ce=!0,Ht=null,e!==null&&(Rt[Bt++]=wn,Rt[Bt++]=xn,Rt[Bt++]=Si,wn=e.id,xn=e.overflow,Si=t),t=zu(t,i.children),t.flags|=4096,t)}function Fm(e,t,n){e.lanes|=t;var i=e.alternate;i!==null&&(i.lanes|=t),cd(e.return,t,n)}function lc(e,t,n,i,a){var o=e.memoizedState;o===null?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:i,tail:n,tailMode:a}:(o.isBackwards=t,o.rendering=null,o.renderingStartTime=0,o.last=i,o.tail=n,o.tailMode=a)}function Pg(e,t,n){var i=t.pendingProps,a=i.revealOrder,o=i.tail;if(at(e,t,i.children,n),i=De.current,i&2)i=i&1|2,t.flags|=128;else{if(e!==null&&e.flags&128)e:for(e=t.child;e!==null;){if(e.tag===13)e.memoizedState!==null&&Fm(e,n,t);else if(e.tag===19)Fm(e,n,t);else if(e.child!==null){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;e.sibling===null;){if(e.return===null||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}i&=1}if(_e(De,i),!(t.mode&1))t.memoizedState=null;else switch(a){case"forwards":for(n=t.child,a=null;n!==null;)e=n.alternate,e!==null&&rs(e)===null&&(a=n),n=n.sibling;n=a,n===null?(a=t.child,t.child=null):(a=n.sibling,n.sibling=null),lc(t,!1,a,n,o);break;case"backwards":for(n=null,a=t.child,t.child=null;a!==null;){if(e=a.alternate,e!==null&&rs(e)===null){t.child=a;break}e=a.sibling,a.sibling=n,n=a,a=e}lc(t,!0,n,null,o);break;case"together":lc(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function Rr(e,t){!(t.mode&1)&&e!==null&&(e.alternate=null,t.alternate=null,t.flags|=2)}function Dn(e,t,n){if(e!==null&&(t.dependencies=e.dependencies),Ai|=t.lanes,!(n&t.childLanes))return null;if(e!==null&&t.child!==e.child)throw Error(E(153));if(t.child!==null){for(e=t.child,n=ei(e,e.pendingProps),t.child=n,n.return=t;e.sibling!==null;)e=e.sibling,n=n.sibling=ei(e,e.pendingProps),n.return=t;n.sibling=null}return t.child}function gv(e,t,n){switch(t.tag){case 3:qg(t),_a();break;case 5:ng(t);break;case 1:ft(t.type)&&es(t);break;case 4:Pu(t,t.stateNode.containerInfo);break;case 10:var i=t.type._context,a=t.memoizedProps.value;_e(is,i._currentValue),i._currentValue=a;break;case 13:if(i=t.memoizedState,i!==null)return i.dehydrated!==null?(_e(De,De.current&1),t.flags|=128,null):n&t.child.childLanes?Dg(e,t,n):(_e(De,De.current&1),e=Dn(e,t,n),e!==null?e.sibling:null);_e(De,De.current&1);break;case 19:if(i=(n&t.childLanes)!==0,e.flags&128){if(i)return Pg(e,t,n);t.flags|=128}if(a=t.memoizedState,a!==null&&(a.rendering=null,a.tail=null,a.lastEffect=null),_e(De,De.current),i)break;return null;case 22:case 23:return t.lanes=0,Cg(e,t,n)}return Dn(e,t,n)}var Sg,gd,Eg,Ag;Sg=function(e,t){for(var n=t.child;n!==null;){if(n.tag===5||n.tag===6)e.appendChild(n.stateNode);else if(n.tag!==4&&n.child!==null){n.child.return=n,n=n.child;continue}if(n===t)break;for(;n.sibling===null;){if(n.return===null||n.return===t)return;n=n.return}n.sibling.return=n.return,n=n.sibling}};gd=function(){};Eg=function(e,t,n,i){var a=e.memoizedProps;if(a!==i){e=t.stateNode,ki(dn.current);var o=null;switch(n){case"input":a=jc(e,a),i=jc(e,i),o=[];break;case"select":a=Se({},a,{value:void 0}),i=Se({},i,{value:void 0}),o=[];break;case"textarea":a=Fc(e,a),i=Fc(e,i),o=[];break;default:typeof a.onClick!="function"&&typeof i.onClick=="function"&&(e.onclick=Yr)}Gc(n,i);var r;n=null;for(c in a)if(!i.hasOwnProperty(c)&&a.hasOwnProperty(c)&&a[c]!=null)if(c==="style"){var s=a[c];for(r in s)s.hasOwnProperty(r)&&(n||(n={}),n[r]="")}else c!=="dangerouslySetInnerHTML"&&c!=="children"&&c!=="suppressContentEditableWarning"&&c!=="suppressHydrationWarning"&&c!=="autoFocus"&&(bo.hasOwnProperty(c)?o||(o=[]):(o=o||[]).push(c,null));for(c in i){var l=i[c];if(s=a!=null?a[c]:void 0,i.hasOwnProperty(c)&&l!==s&&(l!=null||s!=null))if(c==="style")if(s){for(r in s)!s.hasOwnProperty(r)||l&&l.hasOwnProperty(r)||(n||(n={}),n[r]="");for(r in l)l.hasOwnProperty(r)&&s[r]!==l[r]&&(n||(n={}),n[r]=l[r])}else n||(o||(o=[]),o.push(c,n)),n=l;else c==="dangerouslySetInnerHTML"?(l=l?l.__html:void 0,s=s?s.__html:void 0,l!=null&&s!==l&&(o=o||[]).push(c,l)):c==="children"?typeof l!="string"&&typeof l!="number"||(o=o||[]).push(c,""+l):c!=="suppressContentEditableWarning"&&c!=="suppressHydrationWarning"&&(bo.hasOwnProperty(c)?(l!=null&&c==="onScroll"&&be("scroll",e),o||s===l||(o=[])):(o=o||[]).push(c,l))}n&&(o=o||[]).push("style",n);var c=o;(t.updateQueue=c)&&(t.flags|=4)}};Ag=function(e,t,n,i){n!==i&&(t.flags|=4)};function Fa(e,t){if(!Ce)switch(e.tailMode){case"hidden":t=e.tail;for(var n=null;t!==null;)t.alternate!==null&&(n=t),t=t.sibling;n===null?e.tail=null:n.sibling=null;break;case"collapsed":n=e.tail;for(var i=null;n!==null;)n.alternate!==null&&(i=n),n=n.sibling;i===null?t||e.tail===null?e.tail=null:e.tail.sibling=null:i.sibling=null}}function et(e){var t=e.alternate!==null&&e.alternate.child===e.child,n=0,i=0;if(t)for(var a=e.child;a!==null;)n|=a.lanes|a.childLanes,i|=a.subtreeFlags&14680064,i|=a.flags&14680064,a.return=e,a=a.sibling;else for(a=e.child;a!==null;)n|=a.lanes|a.childLanes,i|=a.subtreeFlags,i|=a.flags,a.return=e,a=a.sibling;return e.subtreeFlags|=i,e.childLanes=n,t}function _v(e,t,n){var i=t.pendingProps;switch(xu(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return et(t),null;case 1:return ft(t.type)&&Jr(),et(t),null;case 3:return i=t.stateNode,va(),ve(mt),ve(it),Eu(),i.pendingContext&&(i.context=i.pendingContext,i.pendingContext=null),(e===null||e.child===null)&&(mr(t)?t.flags|=4:e===null||e.memoizedState.isDehydrated&&!(t.flags&256)||(t.flags|=1024,Ht!==null&&(Cd(Ht),Ht=null))),gd(e,t),et(t),null;case 5:Su(t);var a=ki(Eo.current);if(n=t.type,e!==null&&t.stateNode!=null)Eg(e,t,n,i,a),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!i){if(t.stateNode===null)throw Error(E(166));return et(t),null}if(e=ki(dn.current),mr(t)){i=t.stateNode,n=t.type;var o=t.memoizedProps;switch(i[on]=t,i[Po]=o,e=(t.mode&1)!==0,n){case"dialog":be("cancel",i),be("close",i);break;case"iframe":case"object":case"embed":be("load",i);break;case"video":case"audio":for(a=0;a<to.length;a++)be(to[a],i);break;case"source":be("error",i);break;case"img":case"image":case"link":be("error",i),be("load",i);break;case"details":be("toggle",i);break;case"input":Xp(i,o),be("invalid",i);break;case"select":i._wrapperState={wasMultiple:!!o.multiple},be("invalid",i);break;case"textarea":Jp(i,o),be("invalid",i)}Gc(n,o),a=null;for(var r in o)if(o.hasOwnProperty(r)){var s=o[r];r==="children"?typeof s=="string"?i.textContent!==s&&(o.suppressHydrationWarning!==!0&&pr(i.textContent,s,e),a=["children",s]):typeof s=="number"&&i.textContent!==""+s&&(o.suppressHydrationWarning!==!0&&pr(i.textContent,s,e),a=["children",""+s]):bo.hasOwnProperty(r)&&s!=null&&r==="onScroll"&&be("scroll",i)}switch(n){case"input":ar(i),Yp(i,o,!0);break;case"textarea":ar(i),em(i);break;case"select":case"option":break;default:typeof o.onClick=="function"&&(i.onclick=Yr)}i=a,t.updateQueue=i,i!==null&&(t.flags|=4)}else{r=a.nodeType===9?a:a.ownerDocument,e==="http://www.w3.org/1999/xhtml"&&(e=oy(n)),e==="http://www.w3.org/1999/xhtml"?n==="script"?(e=r.createElement("div"),e.innerHTML="<script><\/script>",e=e.removeChild(e.firstChild)):typeof i.is=="string"?e=r.createElement(n,{is:i.is}):(e=r.createElement(n),n==="select"&&(r=e,i.multiple?r.multiple=!0:i.size&&(r.size=i.size))):e=r.createElementNS(e,n),e[on]=t,e[Po]=i,Sg(e,t,!1,!1),t.stateNode=e;e:{switch(r=$c(n,i),n){case"dialog":be("cancel",e),be("close",e),a=i;break;case"iframe":case"object":case"embed":be("load",e),a=i;break;case"video":case"audio":for(a=0;a<to.length;a++)be(to[a],e);a=i;break;case"source":be("error",e),a=i;break;case"img":case"image":case"link":be("error",e),be("load",e),a=i;break;case"details":be("toggle",e),a=i;break;case"input":Xp(e,i),a=jc(e,i),be("invalid",e);break;case"option":a=i;break;case"select":e._wrapperState={wasMultiple:!!i.multiple},a=Se({},i,{value:void 0}),be("invalid",e);break;case"textarea":Jp(e,i),a=Fc(e,i),be("invalid",e);break;default:a=i}Gc(n,a),s=a;for(o in s)if(s.hasOwnProperty(o)){var l=s[o];o==="style"?ly(e,l):o==="dangerouslySetInnerHTML"?(l=l?l.__html:void 0,l!=null&&ry(e,l)):o==="children"?typeof l=="string"?(n!=="textarea"||l!=="")&&vo(e,l):typeof l=="number"&&vo(e,""+l):o!=="suppressContentEditableWarning"&&o!=="suppressHydrationWarning"&&o!=="autoFocus"&&(bo.hasOwnProperty(o)?l!=null&&o==="onScroll"&&be("scroll",e):l!=null&&su(e,o,l,r))}switch(n){case"input":ar(e),Yp(e,i,!1);break;case"textarea":ar(e),em(e);break;case"option":i.value!=null&&e.setAttribute("value",""+ni(i.value));break;case"select":e.multiple=!!i.multiple,o=i.value,o!=null?la(e,!!i.multiple,o,!1):i.defaultValue!=null&&la(e,!!i.multiple,i.defaultValue,!0);break;default:typeof a.onClick=="function"&&(e.onclick=Yr)}switch(n){case"button":case"input":case"select":case"textarea":i=!!i.autoFocus;break e;case"img":i=!0;break e;default:i=!1}}i&&(t.flags|=4)}t.ref!==null&&(t.flags|=512,t.flags|=2097152)}return et(t),null;case 6:if(e&&t.stateNode!=null)Ag(e,t,e.memoizedProps,i);else{if(typeof i!="string"&&t.stateNode===null)throw Error(E(166));if(n=ki(Eo.current),ki(dn.current),mr(t)){if(i=t.stateNode,n=t.memoizedProps,i[on]=t,(o=i.nodeValue!==n)&&(e=Tt,e!==null))switch(e.tag){case 3:pr(i.nodeValue,n,(e.mode&1)!==0);break;case 5:e.memoizedProps.suppressHydrationWarning!==!0&&pr(i.nodeValue,n,(e.mode&1)!==0)}o&&(t.flags|=4)}else i=(n.nodeType===9?n:n.ownerDocument).createTextNode(i),i[on]=t,t.stateNode=i}return et(t),null;case 13:if(ve(De),i=t.memoizedState,e===null||e.memoizedState!==null&&e.memoizedState.dehydrated!==null){if(Ce&&xt!==null&&t.mode&1&&!(t.flags&128))Qy(),_a(),t.flags|=98560,o=!1;else if(o=mr(t),i!==null&&i.dehydrated!==null){if(e===null){if(!o)throw Error(E(318));if(o=t.memoizedState,o=o!==null?o.dehydrated:null,!o)throw Error(E(317));o[on]=t}else _a(),!(t.flags&128)&&(t.memoizedState=null),t.flags|=4;et(t),o=!1}else Ht!==null&&(Cd(Ht),Ht=null),o=!0;if(!o)return t.flags&65536?t:null}return t.flags&128?(t.lanes=n,t):(i=i!==null,i!==(e!==null&&e.memoizedState!==null)&&i&&(t.child.flags|=8192,t.mode&1&&(e===null||De.current&1?Le===0&&(Le=3):Uu())),t.updateQueue!==null&&(t.flags|=4),et(t),null);case 4:return va(),gd(e,t),e===null&&qo(t.stateNode.containerInfo),et(t),null;case 10:return Iu(t.type._context),et(t),null;case 17:return ft(t.type)&&Jr(),et(t),null;case 19:if(ve(De),o=t.memoizedState,o===null)return et(t),null;if(i=(t.flags&128)!==0,r=o.rendering,r===null)if(i)Fa(o,!1);else{if(Le!==0||e!==null&&e.flags&128)for(e=t.child;e!==null;){if(r=rs(e),r!==null){for(t.flags|=128,Fa(o,!1),i=r.updateQueue,i!==null&&(t.updateQueue=i,t.flags|=4),t.subtreeFlags=0,i=n,n=t.child;n!==null;)o=n,e=i,o.flags&=14680066,r=o.alternate,r===null?(o.childLanes=0,o.lanes=e,o.child=null,o.subtreeFlags=0,o.memoizedProps=null,o.memoizedState=null,o.updateQueue=null,o.dependencies=null,o.stateNode=null):(o.childLanes=r.childLanes,o.lanes=r.lanes,o.child=r.child,o.subtreeFlags=0,o.deletions=null,o.memoizedProps=r.memoizedProps,o.memoizedState=r.memoizedState,o.updateQueue=r.updateQueue,o.type=r.type,e=r.dependencies,o.dependencies=e===null?null:{lanes:e.lanes,firstContext:e.firstContext}),n=n.sibling;return _e(De,De.current&1|2),t.child}e=e.sibling}o.tail!==null&&Oe()>xa&&(t.flags|=128,i=!0,Fa(o,!1),t.lanes=4194304)}else{if(!i)if(e=rs(r),e!==null){if(t.flags|=128,i=!0,n=e.updateQueue,n!==null&&(t.updateQueue=n,t.flags|=4),Fa(o,!0),o.tail===null&&o.tailMode==="hidden"&&!r.alternate&&!Ce)return et(t),null}else 2*Oe()-o.renderingStartTime>xa&&n!==1073741824&&(t.flags|=128,i=!0,Fa(o,!1),t.lanes=4194304);o.isBackwards?(r.sibling=t.child,t.child=r):(n=o.last,n!==null?n.sibling=r:t.child=r,o.last=r)}return o.tail!==null?(t=o.tail,o.rendering=t,o.tail=t.sibling,o.renderingStartTime=Oe(),t.sibling=null,n=De.current,_e(De,i?n&1|2:n&1),t):(et(t),null);case 22:case 23:return Fu(),i=t.memoizedState!==null,e!==null&&e.memoizedState!==null!==i&&(t.flags|=8192),i&&t.mode&1?bt&1073741824&&(et(t),t.subtreeFlags&6&&(t.flags|=8192)):et(t),null;case 24:return null;case 25:return null}throw Error(E(156,t.tag))}function bv(e,t){switch(xu(t),t.tag){case 1:return ft(t.type)&&Jr(),e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 3:return va(),ve(mt),ve(it),Eu(),e=t.flags,e&65536&&!(e&128)?(t.flags=e&-65537|128,t):null;case 5:return Su(t),null;case 13:if(ve(De),e=t.memoizedState,e!==null&&e.dehydrated!==null){if(t.alternate===null)throw Error(E(340));_a()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 19:return ve(De),null;case 4:return va(),null;case 10:return Iu(t.type._context),null;case 22:case 23:return Fu(),null;case 24:return null;default:return null}}var yr=!1,nt=!1,vv=typeof WeakSet=="function"?WeakSet:Set,j=null;function oa(e,t){var n=e.ref;if(n!==null)if(typeof n=="function")try{n(null)}catch(i){Ne(e,t,i)}else n.current=null}function _d(e,t,n){try{n()}catch(i){Ne(e,t,i)}}var Um=!1;function wv(e,t){if(td=Qr,e=Oy(),vu(e)){if("selectionStart"in e)var n={start:e.selectionStart,end:e.selectionEnd};else e:{n=(n=e.ownerDocument)&&n.defaultView||window;var i=n.getSelection&&n.getSelection();if(i&&i.rangeCount!==0){n=i.anchorNode;var a=i.anchorOffset,o=i.focusNode;i=i.focusOffset;try{n.nodeType,o.nodeType}catch{n=null;break e}var r=0,s=-1,l=-1,c=0,d=0,h=e,y=null;t:for(;;){for(var p;h!==n||a!==0&&h.nodeType!==3||(s=r+a),h!==o||i!==0&&h.nodeType!==3||(l=r+i),h.nodeType===3&&(r+=h.nodeValue.length),(p=h.firstChild)!==null;)y=h,h=p;for(;;){if(h===e)break t;if(y===n&&++c===a&&(s=r),y===o&&++d===i&&(l=r),(p=h.nextSibling)!==null)break;h=y,y=h.parentNode}h=p}n=s===-1||l===-1?null:{start:s,end:l}}else n=null}n=n||{start:0,end:0}}else n=null;for(nd={focusedElem:e,selectionRange:n},Qr=!1,j=t;j!==null;)if(t=j,e=t.child,(t.subtreeFlags&1028)!==0&&e!==null)e.return=t,j=e;else for(;j!==null;){t=j;try{var f=t.alternate;if(t.flags&1024)switch(t.tag){case 0:case 11:case 15:break;case 1:if(f!==null){var u=f.memoizedProps,T=f.memoizedState,g=t.stateNode,_=g.getSnapshotBeforeUpdate(t.elementType===t.type?u:$t(t.type,u),T);g.__reactInternalSnapshotBeforeUpdate=_}break;case 3:var b=t.stateNode.containerInfo;b.nodeType===1?b.textContent="":b.nodeType===9&&b.documentElement&&b.removeChild(b.documentElement);break;case 5:case 6:case 4:case 17:break;default:throw Error(E(163))}}catch(w){Ne(t,t.return,w)}if(e=t.sibling,e!==null){e.return=t.return,j=e;break}j=t.return}return f=Um,Um=!1,f}function uo(e,t,n){var i=t.updateQueue;if(i=i!==null?i.lastEffect:null,i!==null){var a=i=i.next;do{if((a.tag&e)===e){var o=a.destroy;a.destroy=void 0,o!==void 0&&_d(t,n,o)}a=a.next}while(a!==i)}}function Rs(e,t){if(t=t.updateQueue,t=t!==null?t.lastEffect:null,t!==null){var n=t=t.next;do{if((n.tag&e)===e){var i=n.create;n.destroy=i()}n=n.next}while(n!==t)}}function bd(e){var t=e.ref;if(t!==null){var n=e.stateNode;switch(e.tag){case 5:e=n;break;default:e=n}typeof t=="function"?t(e):t.current=e}}function Ng(e){var t=e.alternate;t!==null&&(e.alternate=null,Ng(t)),e.child=null,e.deletions=null,e.sibling=null,e.tag===5&&(t=e.stateNode,t!==null&&(delete t[on],delete t[Po],delete t[od],delete t[iv],delete t[av])),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function Rg(e){return e.tag===5||e.tag===3||e.tag===4}function Gm(e){e:for(;;){for(;e.sibling===null;){if(e.return===null||Rg(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;e.tag!==5&&e.tag!==6&&e.tag!==18;){if(e.flags&2||e.child===null||e.tag===4)continue e;e.child.return=e,e=e.child}if(!(e.flags&2))return e.stateNode}}function vd(e,t,n){var i=e.tag;if(i===5||i===6)e=e.stateNode,t?n.nodeType===8?n.parentNode.insertBefore(e,t):n.insertBefore(e,t):(n.nodeType===8?(t=n.parentNode,t.insertBefore(e,n)):(t=n,t.appendChild(e)),n=n._reactRootContainer,n!=null||t.onclick!==null||(t.onclick=Yr));else if(i!==4&&(e=e.child,e!==null))for(vd(e,t,n),e=e.sibling;e!==null;)vd(e,t,n),e=e.sibling}function wd(e,t,n){var i=e.tag;if(i===5||i===6)e=e.stateNode,t?n.insertBefore(e,t):n.appendChild(e);else if(i!==4&&(e=e.child,e!==null))for(wd(e,t,n),e=e.sibling;e!==null;)wd(e,t,n),e=e.sibling}var He=null,Vt=!1;function On(e,t,n){for(n=n.child;n!==null;)Bg(e,t,n),n=n.sibling}function Bg(e,t,n){if(cn&&typeof cn.onCommitFiberUnmount=="function")try{cn.onCommitFiberUnmount(Is,n)}catch{}switch(n.tag){case 5:nt||oa(n,t);case 6:var i=He,a=Vt;He=null,On(e,t,n),He=i,Vt=a,He!==null&&(Vt?(e=He,n=n.stateNode,e.nodeType===8?e.parentNode.removeChild(n):e.removeChild(n)):He.removeChild(n.stateNode));break;case 18:He!==null&&(Vt?(e=He,n=n.stateNode,e.nodeType===8?tc(e.parentNode,n):e.nodeType===1&&tc(e,n),ko(e)):tc(He,n.stateNode));break;case 4:i=He,a=Vt,He=n.stateNode.containerInfo,Vt=!0,On(e,t,n),He=i,Vt=a;break;case 0:case 11:case 14:case 15:if(!nt&&(i=n.updateQueue,i!==null&&(i=i.lastEffect,i!==null))){a=i=i.next;do{var o=a,r=o.destroy;o=o.tag,r!==void 0&&(o&2||o&4)&&_d(n,t,r),a=a.next}while(a!==i)}On(e,t,n);break;case 1:if(!nt&&(oa(n,t),i=n.stateNode,typeof i.componentWillUnmount=="function"))try{i.props=n.memoizedProps,i.state=n.memoizedState,i.componentWillUnmount()}catch(s){Ne(n,t,s)}On(e,t,n);break;case 21:On(e,t,n);break;case 22:n.mode&1?(nt=(i=nt)||n.memoizedState!==null,On(e,t,n),nt=i):On(e,t,n);break;default:On(e,t,n)}}function $m(e){var t=e.updateQueue;if(t!==null){e.updateQueue=null;var n=e.stateNode;n===null&&(n=e.stateNode=new vv),t.forEach(function(i){var a=Sv.bind(null,e,i);n.has(i)||(n.add(i),i.then(a,a))})}}function Gt(e,t){var n=t.deletions;if(n!==null)for(var i=0;i<n.length;i++){var a=n[i];try{var o=e,r=t,s=r;e:for(;s!==null;){switch(s.tag){case 5:He=s.stateNode,Vt=!1;break e;case 3:He=s.stateNode.containerInfo,Vt=!0;break e;case 4:He=s.stateNode.containerInfo,Vt=!0;break e}s=s.return}if(He===null)throw Error(E(160));Bg(o,r,a),He=null,Vt=!1;var l=a.alternate;l!==null&&(l.return=null),a.return=null}catch(c){Ne(a,t,c)}}if(t.subtreeFlags&12854)for(t=t.child;t!==null;)Og(t,e),t=t.sibling}function Og(e,t){var n=e.alternate,i=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(Gt(t,e),en(e),i&4){try{uo(3,e,e.return),Rs(3,e)}catch(u){Ne(e,e.return,u)}try{uo(5,e,e.return)}catch(u){Ne(e,e.return,u)}}break;case 1:Gt(t,e),en(e),i&512&&n!==null&&oa(n,n.return);break;case 5:if(Gt(t,e),en(e),i&512&&n!==null&&oa(n,n.return),e.flags&32){var a=e.stateNode;try{vo(a,"")}catch(u){Ne(e,e.return,u)}}if(i&4&&(a=e.stateNode,a!=null)){var o=e.memoizedProps,r=n!==null?n.memoizedProps:o,s=e.type,l=e.updateQueue;if(e.updateQueue=null,l!==null)try{s==="input"&&o.type==="radio"&&o.name!=null&&iy(a,o),$c(s,r);var c=$c(s,o);for(r=0;r<l.length;r+=2){var d=l[r],h=l[r+1];d==="style"?ly(a,h):d==="dangerouslySetInnerHTML"?ry(a,h):d==="children"?vo(a,h):su(a,d,h,c)}switch(s){case"input":Mc(a,o);break;case"textarea":ay(a,o);break;case"select":var y=a._wrapperState.wasMultiple;a._wrapperState.wasMultiple=!!o.multiple;var p=o.value;p!=null?la(a,!!o.multiple,p,!1):y!==!!o.multiple&&(o.defaultValue!=null?la(a,!!o.multiple,o.defaultValue,!0):la(a,!!o.multiple,o.multiple?[]:"",!1))}a[Po]=o}catch(u){Ne(e,e.return,u)}}break;case 6:if(Gt(t,e),en(e),i&4){if(e.stateNode===null)throw Error(E(162));a=e.stateNode,o=e.memoizedProps;try{a.nodeValue=o}catch(u){Ne(e,e.return,u)}}break;case 3:if(Gt(t,e),en(e),i&4&&n!==null&&n.memoizedState.isDehydrated)try{ko(t.containerInfo)}catch(u){Ne(e,e.return,u)}break;case 4:Gt(t,e),en(e);break;case 13:Gt(t,e),en(e),a=e.child,a.flags&8192&&(o=a.memoizedState!==null,a.stateNode.isHidden=o,!o||a.alternate!==null&&a.alternate.memoizedState!==null||(Mu=Oe())),i&4&&$m(e);break;case 22:if(d=n!==null&&n.memoizedState!==null,e.mode&1?(nt=(c=nt)||d,Gt(t,e),nt=c):Gt(t,e),en(e),i&8192){if(c=e.memoizedState!==null,(e.stateNode.isHidden=c)&&!d&&e.mode&1)for(j=e,d=e.child;d!==null;){for(h=j=d;j!==null;){switch(y=j,p=y.child,y.tag){case 0:case 11:case 14:case 15:uo(4,y,y.return);break;case 1:oa(y,y.return);var f=y.stateNode;if(typeof f.componentWillUnmount=="function"){i=y,n=y.return;try{t=i,f.props=t.memoizedProps,f.state=t.memoizedState,f.componentWillUnmount()}catch(u){Ne(i,n,u)}}break;case 5:oa(y,y.return);break;case 22:if(y.memoizedState!==null){Hm(h);continue}}p!==null?(p.return=y,j=p):Hm(h)}d=d.sibling}e:for(d=null,h=e;;){if(h.tag===5){if(d===null){d=h;try{a=h.stateNode,c?(o=a.style,typeof o.setProperty=="function"?o.setProperty("display","none","important"):o.display="none"):(s=h.stateNode,l=h.memoizedProps.style,r=l!=null&&l.hasOwnProperty("display")?l.display:null,s.style.display=sy("display",r))}catch(u){Ne(e,e.return,u)}}}else if(h.tag===6){if(d===null)try{h.stateNode.nodeValue=c?"":h.memoizedProps}catch(u){Ne(e,e.return,u)}}else if((h.tag!==22&&h.tag!==23||h.memoizedState===null||h===e)&&h.child!==null){h.child.return=h,h=h.child;continue}if(h===e)break e;for(;h.sibling===null;){if(h.return===null||h.return===e)break e;d===h&&(d=null),h=h.return}d===h&&(d=null),h.sibling.return=h.return,h=h.sibling}}break;case 19:Gt(t,e),en(e),i&4&&$m(e);break;case 21:break;default:Gt(t,e),en(e)}}function en(e){var t=e.flags;if(t&2){try{e:{for(var n=e.return;n!==null;){if(Rg(n)){var i=n;break e}n=n.return}throw Error(E(160))}switch(i.tag){case 5:var a=i.stateNode;i.flags&32&&(vo(a,""),i.flags&=-33);var o=Gm(e);wd(e,o,a);break;case 3:case 4:var r=i.stateNode.containerInfo,s=Gm(e);vd(e,s,r);break;default:throw Error(E(161))}}catch(l){Ne(e,e.return,l)}e.flags&=-3}t&4096&&(e.flags&=-4097)}function xv(e,t,n){j=e,zg(e)}function zg(e,t,n){for(var i=(e.mode&1)!==0;j!==null;){var a=j,o=a.child;if(a.tag===22&&i){var r=a.memoizedState!==null||yr;if(!r){var s=a.alternate,l=s!==null&&s.memoizedState!==null||nt;s=yr;var c=nt;if(yr=r,(nt=l)&&!c)for(j=a;j!==null;)r=j,l=r.child,r.tag===22&&r.memoizedState!==null?Zm(a):l!==null?(l.return=r,j=l):Zm(a);for(;o!==null;)j=o,zg(o),o=o.sibling;j=a,yr=s,nt=c}Vm(e)}else a.subtreeFlags&8772&&o!==null?(o.return=a,j=o):Vm(e)}}function Vm(e){for(;j!==null;){var t=j;if(t.flags&8772){var n=t.alternate;try{if(t.flags&8772)switch(t.tag){case 0:case 11:case 15:nt||Rs(5,t);break;case 1:var i=t.stateNode;if(t.flags&4&&!nt)if(n===null)i.componentDidMount();else{var a=t.elementType===t.type?n.memoizedProps:$t(t.type,n.memoizedProps);i.componentDidUpdate(a,n.memoizedState,i.__reactInternalSnapshotBeforeUpdate)}var o=t.updateQueue;o!==null&&Pm(t,o,i);break;case 3:var r=t.updateQueue;if(r!==null){if(n=null,t.child!==null)switch(t.child.tag){case 5:n=t.child.stateNode;break;case 1:n=t.child.stateNode}Pm(t,r,n)}break;case 5:var s=t.stateNode;if(n===null&&t.flags&4){n=s;var l=t.memoizedProps;switch(t.type){case"button":case"input":case"select":case"textarea":l.autoFocus&&n.focus();break;case"img":l.src&&(n.src=l.src)}}break;case 6:break;case 4:break;case 12:break;case 13:if(t.memoizedState===null){var c=t.alternate;if(c!==null){var d=c.memoizedState;if(d!==null){var h=d.dehydrated;h!==null&&ko(h)}}}break;case 19:case 17:case 21:case 22:case 23:case 25:break;default:throw Error(E(163))}nt||t.flags&512&&bd(t)}catch(y){Ne(t,t.return,y)}}if(t===e){j=null;break}if(n=t.sibling,n!==null){n.return=t.return,j=n;break}j=t.return}}function Hm(e){for(;j!==null;){var t=j;if(t===e){j=null;break}var n=t.sibling;if(n!==null){n.return=t.return,j=n;break}j=t.return}}function Zm(e){for(;j!==null;){var t=j;try{switch(t.tag){case 0:case 11:case 15:var n=t.return;try{Rs(4,t)}catch(l){Ne(t,n,l)}break;case 1:var i=t.stateNode;if(typeof i.componentDidMount=="function"){var a=t.return;try{i.componentDidMount()}catch(l){Ne(t,a,l)}}var o=t.return;try{bd(t)}catch(l){Ne(t,o,l)}break;case 5:var r=t.return;try{bd(t)}catch(l){Ne(t,r,l)}}}catch(l){Ne(t,t.return,l)}if(t===e){j=null;break}var s=t.sibling;if(s!==null){s.return=t.return,j=s;break}j=t.return}}var Tv=Math.ceil,cs=An.ReactCurrentDispatcher,Wu=An.ReactCurrentOwner,zt=An.ReactCurrentBatchConfig,ne=0,Ue=null,We=null,Qe=0,bt=0,ra=si(0),Le=0,Bo=null,Ai=0,Bs=0,ju=0,po=null,ut=null,Mu=0,xa=1/0,bn=null,ds=!1,xd=null,Yn=null,gr=!1,$n=null,us=0,mo=0,Td=null,Br=-1,Or=0;function ot(){return ne&6?Oe():Br!==-1?Br:Br=Oe()}function Jn(e){return e.mode&1?ne&2&&Qe!==0?Qe&-Qe:rv.transition!==null?(Or===0&&(Or=vy()),Or):(e=ce,e!==0||(e=window.event,e=e===void 0?16:qy(e.type)),e):1}function Kt(e,t,n,i){if(50<mo)throw mo=0,Td=null,Error(E(185));Uo(e,n,i),(!(ne&2)||e!==Ue)&&(e===Ue&&(!(ne&2)&&(Bs|=n),Le===4&&Un(e,Qe)),ht(e,i),n===1&&ne===0&&!(t.mode&1)&&(xa=Oe()+500,Es&&li()))}function ht(e,t){var n=e.callbackNode;r1(e,t);var i=Zr(e,e===Ue?Qe:0);if(i===0)n!==null&&im(n),e.callbackNode=null,e.callbackPriority=0;else if(t=i&-i,e.callbackPriority!==t){if(n!=null&&im(n),t===1)e.tag===0?ov(Qm.bind(null,e)):Vy(Qm.bind(null,e)),tv(function(){!(ne&6)&&li()}),n=null;else{switch(wy(i)){case 1:n=pu;break;case 4:n=_y;break;case 16:n=Hr;break;case 536870912:n=by;break;default:n=Hr}n=$g(n,Wg.bind(null,e))}e.callbackPriority=t,e.callbackNode=n}}function Wg(e,t){if(Br=-1,Or=0,ne&6)throw Error(E(327));var n=e.callbackNode;if(ma()&&e.callbackNode!==n)return null;var i=Zr(e,e===Ue?Qe:0);if(i===0)return null;if(i&30||i&e.expiredLanes||t)t=ps(e,i);else{t=i;var a=ne;ne|=2;var o=Mg();(Ue!==e||Qe!==t)&&(bn=null,xa=Oe()+500,qi(e,t));do try{Iv();break}catch(s){jg(e,s)}while(1);Cu(),cs.current=o,ne=a,We!==null?t=0:(Ue=null,Qe=0,t=Le)}if(t!==0){if(t===2&&(a=Kc(e),a!==0&&(i=a,t=kd(e,a))),t===1)throw n=Bo,qi(e,0),Un(e,i),ht(e,Oe()),n;if(t===6)Un(e,i);else{if(a=e.current.alternate,!(i&30)&&!kv(a)&&(t=ps(e,i),t===2&&(o=Kc(e),o!==0&&(i=o,t=kd(e,o))),t===1))throw n=Bo,qi(e,0),Un(e,i),ht(e,Oe()),n;switch(e.finishedWork=a,e.finishedLanes=i,t){case 0:case 1:throw Error(E(345));case 2:hi(e,ut,bn);break;case 3:if(Un(e,i),(i&130023424)===i&&(t=Mu+500-Oe(),10<t)){if(Zr(e,0)!==0)break;if(a=e.suspendedLanes,(a&i)!==i){ot(),e.pingedLanes|=e.suspendedLanes&a;break}e.timeoutHandle=ad(hi.bind(null,e,ut,bn),t);break}hi(e,ut,bn);break;case 4:if(Un(e,i),(i&4194240)===i)break;for(t=e.eventTimes,a=-1;0<i;){var r=31-Qt(i);o=1<<r,r=t[r],r>a&&(a=r),i&=~o}if(i=a,i=Oe()-i,i=(120>i?120:480>i?480:1080>i?1080:1920>i?1920:3e3>i?3e3:4320>i?4320:1960*Tv(i/1960))-i,10<i){e.timeoutHandle=ad(hi.bind(null,e,ut,bn),i);break}hi(e,ut,bn);break;case 5:hi(e,ut,bn);break;default:throw Error(E(329))}}}return ht(e,Oe()),e.callbackNode===n?Wg.bind(null,e):null}function kd(e,t){var n=po;return e.current.memoizedState.isDehydrated&&(qi(e,t).flags|=256),e=ps(e,t),e!==2&&(t=ut,ut=n,t!==null&&Cd(t)),e}function Cd(e){ut===null?ut=e:ut.push.apply(ut,e)}function kv(e){for(var t=e;;){if(t.flags&16384){var n=t.updateQueue;if(n!==null&&(n=n.stores,n!==null))for(var i=0;i<n.length;i++){var a=n[i],o=a.getSnapshot;a=a.value;try{if(!Xt(o(),a))return!1}catch{return!1}}}if(n=t.child,t.subtreeFlags&16384&&n!==null)n.return=t,t=n;else{if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}function Un(e,t){for(t&=~ju,t&=~Bs,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var n=31-Qt(t),i=1<<n;e[n]=-1,t&=~i}}function Qm(e){if(ne&6)throw Error(E(327));ma();var t=Zr(e,0);if(!(t&1))return ht(e,Oe()),null;var n=ps(e,t);if(e.tag!==0&&n===2){var i=Kc(e);i!==0&&(t=i,n=kd(e,i))}if(n===1)throw n=Bo,qi(e,0),Un(e,t),ht(e,Oe()),n;if(n===6)throw Error(E(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,hi(e,ut,bn),ht(e,Oe()),null}function Lu(e,t){var n=ne;ne|=1;try{return e(t)}finally{ne=n,ne===0&&(xa=Oe()+500,Es&&li())}}function Ni(e){$n!==null&&$n.tag===0&&!(ne&6)&&ma();var t=ne;ne|=1;var n=zt.transition,i=ce;try{if(zt.transition=null,ce=1,e)return e()}finally{ce=i,zt.transition=n,ne=t,!(ne&6)&&li()}}function Fu(){bt=ra.current,ve(ra)}function qi(e,t){e.finishedWork=null,e.finishedLanes=0;var n=e.timeoutHandle;if(n!==-1&&(e.timeoutHandle=-1,ev(n)),We!==null)for(n=We.return;n!==null;){var i=n;switch(xu(i),i.tag){case 1:i=i.type.childContextTypes,i!=null&&Jr();break;case 3:va(),ve(mt),ve(it),Eu();break;case 5:Su(i);break;case 4:va();break;case 13:ve(De);break;case 19:ve(De);break;case 10:Iu(i.type._context);break;case 22:case 23:Fu()}n=n.return}if(Ue=e,We=e=ei(e.current,null),Qe=bt=t,Le=0,Bo=null,ju=Bs=Ai=0,ut=po=null,Ti!==null){for(t=0;t<Ti.length;t++)if(n=Ti[t],i=n.interleaved,i!==null){n.interleaved=null;var a=i.next,o=n.pending;if(o!==null){var r=o.next;o.next=a,i.next=r}n.pending=i}Ti=null}return e}function jg(e,t){do{var n=We;try{if(Cu(),Ar.current=ls,ss){for(var i=Pe.memoizedState;i!==null;){var a=i.queue;a!==null&&(a.pending=null),i=i.next}ss=!1}if(Ei=0,Fe=Me=Pe=null,co=!1,Ao=0,Wu.current=null,n===null||n.return===null){Le=1,Bo=t,We=null;break}e:{var o=e,r=n.return,s=n,l=t;if(t=Qe,s.flags|=32768,l!==null&&typeof l=="object"&&typeof l.then=="function"){var c=l,d=s,h=d.tag;if(!(d.mode&1)&&(h===0||h===11||h===15)){var y=d.alternate;y?(d.updateQueue=y.updateQueue,d.memoizedState=y.memoizedState,d.lanes=y.lanes):(d.updateQueue=null,d.memoizedState=null)}var p=Om(r);if(p!==null){p.flags&=-257,zm(p,r,s,o,t),p.mode&1&&Bm(o,c,t),t=p,l=c;var f=t.updateQueue;if(f===null){var u=new Set;u.add(l),t.updateQueue=u}else f.add(l);break e}else{if(!(t&1)){Bm(o,c,t),Uu();break e}l=Error(E(426))}}else if(Ce&&s.mode&1){var T=Om(r);if(T!==null){!(T.flags&65536)&&(T.flags|=256),zm(T,r,s,o,t),Tu(wa(l,s));break e}}o=l=wa(l,s),Le!==4&&(Le=2),po===null?po=[o]:po.push(o),o=r;do{switch(o.tag){case 3:o.flags|=65536,t&=-t,o.lanes|=t;var g=xg(o,l,t);Dm(o,g);break e;case 1:s=l;var _=o.type,b=o.stateNode;if(!(o.flags&128)&&(typeof _.getDerivedStateFromError=="function"||b!==null&&typeof b.componentDidCatch=="function"&&(Yn===null||!Yn.has(b)))){o.flags|=65536,t&=-t,o.lanes|=t;var w=Tg(o,s,t);Dm(o,w);break e}}o=o.return}while(o!==null)}Fg(n)}catch(C){t=C,We===n&&n!==null&&(We=n=n.return);continue}break}while(1)}function Mg(){var e=cs.current;return cs.current=ls,e===null?ls:e}function Uu(){(Le===0||Le===3||Le===2)&&(Le=4),Ue===null||!(Ai&268435455)&&!(Bs&268435455)||Un(Ue,Qe)}function ps(e,t){var n=ne;ne|=2;var i=Mg();(Ue!==e||Qe!==t)&&(bn=null,qi(e,t));do try{Cv();break}catch(a){jg(e,a)}while(1);if(Cu(),ne=n,cs.current=i,We!==null)throw Error(E(261));return Ue=null,Qe=0,Le}function Cv(){for(;We!==null;)Lg(We)}function Iv(){for(;We!==null&&!X0();)Lg(We)}function Lg(e){var t=Gg(e.alternate,e,bt);e.memoizedProps=e.pendingProps,t===null?Fg(e):We=t,Wu.current=null}function Fg(e){var t=e;do{var n=t.alternate;if(e=t.return,t.flags&32768){if(n=bv(n,t),n!==null){n.flags&=32767,We=n;return}if(e!==null)e.flags|=32768,e.subtreeFlags=0,e.deletions=null;else{Le=6,We=null;return}}else if(n=_v(n,t,bt),n!==null){We=n;return}if(t=t.sibling,t!==null){We=t;return}We=t=e}while(t!==null);Le===0&&(Le=5)}function hi(e,t,n){var i=ce,a=zt.transition;try{zt.transition=null,ce=1,qv(e,t,n,i)}finally{zt.transition=a,ce=i}return null}function qv(e,t,n,i){do ma();while($n!==null);if(ne&6)throw Error(E(327));n=e.finishedWork;var a=e.finishedLanes;if(n===null)return null;if(e.finishedWork=null,e.finishedLanes=0,n===e.current)throw Error(E(177));e.callbackNode=null,e.callbackPriority=0;var o=n.lanes|n.childLanes;if(s1(e,o),e===Ue&&(We=Ue=null,Qe=0),!(n.subtreeFlags&2064)&&!(n.flags&2064)||gr||(gr=!0,$g(Hr,function(){return ma(),null})),o=(n.flags&15990)!==0,n.subtreeFlags&15990||o){o=zt.transition,zt.transition=null;var r=ce;ce=1;var s=ne;ne|=4,Wu.current=null,wv(e,n),Og(n,e),H1(nd),Qr=!!td,nd=td=null,e.current=n,xv(n),Y0(),ne=s,ce=r,zt.transition=o}else e.current=n;if(gr&&(gr=!1,$n=e,us=a),o=e.pendingLanes,o===0&&(Yn=null),t1(n.stateNode),ht(e,Oe()),t!==null)for(i=e.onRecoverableError,n=0;n<t.length;n++)a=t[n],i(a.value,{componentStack:a.stack,digest:a.digest});if(ds)throw ds=!1,e=xd,xd=null,e;return us&1&&e.tag!==0&&ma(),o=e.pendingLanes,o&1?e===Td?mo++:(mo=0,Td=e):mo=0,li(),null}function ma(){if($n!==null){var e=wy(us),t=zt.transition,n=ce;try{if(zt.transition=null,ce=16>e?16:e,$n===null)var i=!1;else{if(e=$n,$n=null,us=0,ne&6)throw Error(E(331));var a=ne;for(ne|=4,j=e.current;j!==null;){var o=j,r=o.child;if(j.flags&16){var s=o.deletions;if(s!==null){for(var l=0;l<s.length;l++){var c=s[l];for(j=c;j!==null;){var d=j;switch(d.tag){case 0:case 11:case 15:uo(8,d,o)}var h=d.child;if(h!==null)h.return=d,j=h;else for(;j!==null;){d=j;var y=d.sibling,p=d.return;if(Ng(d),d===c){j=null;break}if(y!==null){y.return=p,j=y;break}j=p}}}var f=o.alternate;if(f!==null){var u=f.child;if(u!==null){f.child=null;do{var T=u.sibling;u.sibling=null,u=T}while(u!==null)}}j=o}}if(o.subtreeFlags&2064&&r!==null)r.return=o,j=r;else e:for(;j!==null;){if(o=j,o.flags&2048)switch(o.tag){case 0:case 11:case 15:uo(9,o,o.return)}var g=o.sibling;if(g!==null){g.return=o.return,j=g;break e}j=o.return}}var _=e.current;for(j=_;j!==null;){r=j;var b=r.child;if(r.subtreeFlags&2064&&b!==null)b.return=r,j=b;else e:for(r=_;j!==null;){if(s=j,s.flags&2048)try{switch(s.tag){case 0:case 11:case 15:Rs(9,s)}}catch(C){Ne(s,s.return,C)}if(s===r){j=null;break e}var w=s.sibling;if(w!==null){w.return=s.return,j=w;break e}j=s.return}}if(ne=a,li(),cn&&typeof cn.onPostCommitFiberRoot=="function")try{cn.onPostCommitFiberRoot(Is,e)}catch{}i=!0}return i}finally{ce=n,zt.transition=t}}return!1}function Km(e,t,n){t=wa(n,t),t=xg(e,t,1),e=Xn(e,t,1),t=ot(),e!==null&&(Uo(e,1,t),ht(e,t))}function Ne(e,t,n){if(e.tag===3)Km(e,e,n);else for(;t!==null;){if(t.tag===3){Km(t,e,n);break}else if(t.tag===1){var i=t.stateNode;if(typeof t.type.getDerivedStateFromError=="function"||typeof i.componentDidCatch=="function"&&(Yn===null||!Yn.has(i))){e=wa(n,e),e=Tg(t,e,1),t=Xn(t,e,1),e=ot(),t!==null&&(Uo(t,1,e),ht(t,e));break}}t=t.return}}function Dv(e,t,n){var i=e.pingCache;i!==null&&i.delete(t),t=ot(),e.pingedLanes|=e.suspendedLanes&n,Ue===e&&(Qe&n)===n&&(Le===4||Le===3&&(Qe&130023424)===Qe&&500>Oe()-Mu?qi(e,0):ju|=n),ht(e,t)}function Ug(e,t){t===0&&(e.mode&1?(t=sr,sr<<=1,!(sr&130023424)&&(sr=4194304)):t=1);var n=ot();e=qn(e,t),e!==null&&(Uo(e,t,n),ht(e,n))}function Pv(e){var t=e.memoizedState,n=0;t!==null&&(n=t.retryLane),Ug(e,n)}function Sv(e,t){var n=0;switch(e.tag){case 13:var i=e.stateNode,a=e.memoizedState;a!==null&&(n=a.retryLane);break;case 19:i=e.stateNode;break;default:throw Error(E(314))}i!==null&&i.delete(t),Ug(e,n)}var Gg;Gg=function(e,t,n){if(e!==null)if(e.memoizedProps!==t.pendingProps||mt.current)pt=!0;else{if(!(e.lanes&n)&&!(t.flags&128))return pt=!1,gv(e,t,n);pt=!!(e.flags&131072)}else pt=!1,Ce&&t.flags&1048576&&Hy(t,ns,t.index);switch(t.lanes=0,t.tag){case 2:var i=t.type;Rr(e,t),e=t.pendingProps;var a=ga(t,it.current);pa(t,n),a=Nu(null,t,i,e,a,n);var o=Ru();return t.flags|=1,typeof a=="object"&&a!==null&&typeof a.render=="function"&&a.$$typeof===void 0?(t.tag=1,t.memoizedState=null,t.updateQueue=null,ft(i)?(o=!0,es(t)):o=!1,t.memoizedState=a.state!==null&&a.state!==void 0?a.state:null,Du(t),a.updater=As,t.stateNode=a,a._reactInternals=t,ud(t,i,e,n),t=fd(null,t,i,!0,o,n)):(t.tag=0,Ce&&o&&wu(t),at(null,t,a,n),t=t.child),t;case 16:i=t.elementType;e:{switch(Rr(e,t),e=t.pendingProps,a=i._init,i=a(i._payload),t.type=i,a=t.tag=Av(i),e=$t(i,e),a){case 0:t=md(null,t,i,e,n);break e;case 1:t=Mm(null,t,i,e,n);break e;case 11:t=Wm(null,t,i,e,n);break e;case 14:t=jm(null,t,i,$t(i.type,e),n);break e}throw Error(E(306,i,""))}return t;case 0:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:$t(i,a),md(e,t,i,a,n);case 1:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:$t(i,a),Mm(e,t,i,a,n);case 3:e:{if(qg(t),e===null)throw Error(E(387));i=t.pendingProps,o=t.memoizedState,a=o.element,Xy(e,t),os(t,i,null,n);var r=t.memoizedState;if(i=r.element,o.isDehydrated)if(o={element:i,isDehydrated:!1,cache:r.cache,pendingSuspenseBoundaries:r.pendingSuspenseBoundaries,transitions:r.transitions},t.updateQueue.baseState=o,t.memoizedState=o,t.flags&256){a=wa(Error(E(423)),t),t=Lm(e,t,i,n,a);break e}else if(i!==a){a=wa(Error(E(424)),t),t=Lm(e,t,i,n,a);break e}else for(xt=Kn(t.stateNode.containerInfo.firstChild),Tt=t,Ce=!0,Ht=null,n=tg(t,null,i,n),t.child=n;n;)n.flags=n.flags&-3|4096,n=n.sibling;else{if(_a(),i===a){t=Dn(e,t,n);break e}at(e,t,i,n)}t=t.child}return t;case 5:return ng(t),e===null&&ld(t),i=t.type,a=t.pendingProps,o=e!==null?e.memoizedProps:null,r=a.children,id(i,a)?r=null:o!==null&&id(i,o)&&(t.flags|=32),Ig(e,t),at(e,t,r,n),t.child;case 6:return e===null&&ld(t),null;case 13:return Dg(e,t,n);case 4:return Pu(t,t.stateNode.containerInfo),i=t.pendingProps,e===null?t.child=ba(t,null,i,n):at(e,t,i,n),t.child;case 11:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:$t(i,a),Wm(e,t,i,a,n);case 7:return at(e,t,t.pendingProps,n),t.child;case 8:return at(e,t,t.pendingProps.children,n),t.child;case 12:return at(e,t,t.pendingProps.children,n),t.child;case 10:e:{if(i=t.type._context,a=t.pendingProps,o=t.memoizedProps,r=a.value,_e(is,i._currentValue),i._currentValue=r,o!==null)if(Xt(o.value,r)){if(o.children===a.children&&!mt.current){t=Dn(e,t,n);break e}}else for(o=t.child,o!==null&&(o.return=t);o!==null;){var s=o.dependencies;if(s!==null){r=o.child;for(var l=s.firstContext;l!==null;){if(l.context===i){if(o.tag===1){l=kn(-1,n&-n),l.tag=2;var c=o.updateQueue;if(c!==null){c=c.shared;var d=c.pending;d===null?l.next=l:(l.next=d.next,d.next=l),c.pending=l}}o.lanes|=n,l=o.alternate,l!==null&&(l.lanes|=n),cd(o.return,n,t),s.lanes|=n;break}l=l.next}}else if(o.tag===10)r=o.type===t.type?null:o.child;else if(o.tag===18){if(r=o.return,r===null)throw Error(E(341));r.lanes|=n,s=r.alternate,s!==null&&(s.lanes|=n),cd(r,n,t),r=o.sibling}else r=o.child;if(r!==null)r.return=o;else for(r=o;r!==null;){if(r===t){r=null;break}if(o=r.sibling,o!==null){o.return=r.return,r=o;break}r=r.return}o=r}at(e,t,a.children,n),t=t.child}return t;case 9:return a=t.type,i=t.pendingProps.children,pa(t,n),a=jt(a),i=i(a),t.flags|=1,at(e,t,i,n),t.child;case 14:return i=t.type,a=$t(i,t.pendingProps),a=$t(i.type,a),jm(e,t,i,a,n);case 15:return kg(e,t,t.type,t.pendingProps,n);case 17:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:$t(i,a),Rr(e,t),t.tag=1,ft(i)?(e=!0,es(t)):e=!1,pa(t,n),Jy(t,i,a),ud(t,i,a,n),fd(null,t,i,!0,e,n);case 19:return Pg(e,t,n);case 22:return Cg(e,t,n)}throw Error(E(156,t.tag))};function $g(e,t){return gy(e,t)}function Ev(e,t,n,i){this.tag=e,this.key=n,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=i,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Ot(e,t,n,i){return new Ev(e,t,n,i)}function Gu(e){return e=e.prototype,!(!e||!e.isReactComponent)}function Av(e){if(typeof e=="function")return Gu(e)?1:0;if(e!=null){if(e=e.$$typeof,e===cu)return 11;if(e===du)return 14}return 2}function ei(e,t){var n=e.alternate;return n===null?(n=Ot(e.tag,t,e.key,e.mode),n.elementType=e.elementType,n.type=e.type,n.stateNode=e.stateNode,n.alternate=e,e.alternate=n):(n.pendingProps=t,n.type=e.type,n.flags=0,n.subtreeFlags=0,n.deletions=null),n.flags=e.flags&14680064,n.childLanes=e.childLanes,n.lanes=e.lanes,n.child=e.child,n.memoizedProps=e.memoizedProps,n.memoizedState=e.memoizedState,n.updateQueue=e.updateQueue,t=e.dependencies,n.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext},n.sibling=e.sibling,n.index=e.index,n.ref=e.ref,n}function zr(e,t,n,i,a,o){var r=2;if(i=e,typeof e=="function")Gu(e)&&(r=1);else if(typeof e=="string")r=5;else e:switch(e){case Ki:return Di(n.children,a,o,t);case lu:r=8,a|=8;break;case Bc:return e=Ot(12,n,t,a|2),e.elementType=Bc,e.lanes=o,e;case Oc:return e=Ot(13,n,t,a),e.elementType=Oc,e.lanes=o,e;case zc:return e=Ot(19,n,t,a),e.elementType=zc,e.lanes=o,e;case ey:return Os(n,a,o,t);default:if(typeof e=="object"&&e!==null)switch(e.$$typeof){case Yh:r=10;break e;case Jh:r=9;break e;case cu:r=11;break e;case du:r=14;break e;case Mn:r=16,i=null;break e}throw Error(E(130,e==null?e:typeof e,""))}return t=Ot(r,n,t,a),t.elementType=e,t.type=i,t.lanes=o,t}function Di(e,t,n,i){return e=Ot(7,e,i,t),e.lanes=n,e}function Os(e,t,n,i){return e=Ot(22,e,i,t),e.elementType=ey,e.lanes=n,e.stateNode={isHidden:!1},e}function cc(e,t,n){return e=Ot(6,e,null,t),e.lanes=n,e}function dc(e,t,n){return t=Ot(4,e.children!==null?e.children:[],e.key,t),t.lanes=n,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function Nv(e,t,n,i,a){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=Gl(0),this.expirationTimes=Gl(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=Gl(0),this.identifierPrefix=i,this.onRecoverableError=a,this.mutableSourceEagerHydrationData=null}function $u(e,t,n,i,a,o,r,s,l){return e=new Nv(e,t,n,s,l),t===1?(t=1,o===!0&&(t|=8)):t=0,o=Ot(3,null,null,t),e.current=o,o.stateNode=e,o.memoizedState={element:i,isDehydrated:n,cache:null,transitions:null,pendingSuspenseBoundaries:null},Du(o),e}function Rv(e,t,n){var i=3<arguments.length&&arguments[3]!==void 0?arguments[3]:null;return{$$typeof:Qi,key:i==null?null:""+i,children:e,containerInfo:t,implementation:n}}function Vg(e){if(!e)return ii;e=e._reactInternals;e:{if(zi(e)!==e||e.tag!==1)throw Error(E(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(ft(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(t!==null);throw Error(E(171))}if(e.tag===1){var n=e.type;if(ft(n))return $y(e,n,t)}return t}function Hg(e,t,n,i,a,o,r,s,l){return e=$u(n,i,!0,e,a,o,r,s,l),e.context=Vg(null),n=e.current,i=ot(),a=Jn(n),o=kn(i,a),o.callback=t??null,Xn(n,o,a),e.current.lanes=a,Uo(e,a,i),ht(e,i),e}function zs(e,t,n,i){var a=t.current,o=ot(),r=Jn(a);return n=Vg(n),t.context===null?t.context=n:t.pendingContext=n,t=kn(o,r),t.payload={element:e},i=i===void 0?null:i,i!==null&&(t.callback=i),e=Xn(a,t,r),e!==null&&(Kt(e,a,r,o),Er(e,a,r)),r}function ms(e){if(e=e.current,!e.child)return null;switch(e.child.tag){case 5:return e.child.stateNode;default:return e.child.stateNode}}function Xm(e,t){if(e=e.memoizedState,e!==null&&e.dehydrated!==null){var n=e.retryLane;e.retryLane=n!==0&&n<t?n:t}}function Vu(e,t){Xm(e,t),(e=e.alternate)&&Xm(e,t)}function Bv(){return null}var Zg=typeof reportError=="function"?reportError:function(e){console.error(e)};function Hu(e){this._internalRoot=e}Ws.prototype.render=Hu.prototype.render=function(e){var t=this._internalRoot;if(t===null)throw Error(E(409));zs(e,t,null,null)};Ws.prototype.unmount=Hu.prototype.unmount=function(){var e=this._internalRoot;if(e!==null){this._internalRoot=null;var t=e.containerInfo;Ni(function(){zs(null,e,null,null)}),t[In]=null}};function Ws(e){this._internalRoot=e}Ws.prototype.unstable_scheduleHydration=function(e){if(e){var t=ky();e={blockedOn:null,target:e,priority:t};for(var n=0;n<Fn.length&&t!==0&&t<Fn[n].priority;n++);Fn.splice(n,0,e),n===0&&Iy(e)}};function Zu(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11)}function js(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11&&(e.nodeType!==8||e.nodeValue!==" react-mount-point-unstable "))}function Ym(){}function Ov(e,t,n,i,a){if(a){if(typeof i=="function"){var o=i;i=function(){var c=ms(r);o.call(c)}}var r=Hg(t,i,e,0,null,!1,!1,"",Ym);return e._reactRootContainer=r,e[In]=r.current,qo(e.nodeType===8?e.parentNode:e),Ni(),r}for(;a=e.lastChild;)e.removeChild(a);if(typeof i=="function"){var s=i;i=function(){var c=ms(l);s.call(c)}}var l=$u(e,0,!1,null,null,!1,!1,"",Ym);return e._reactRootContainer=l,e[In]=l.current,qo(e.nodeType===8?e.parentNode:e),Ni(function(){zs(t,l,n,i)}),l}function Ms(e,t,n,i,a){var o=n._reactRootContainer;if(o){var r=o;if(typeof a=="function"){var s=a;a=function(){var l=ms(r);s.call(l)}}zs(t,r,e,a)}else r=Ov(n,t,e,a,i);return ms(r)}xy=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var n=eo(t.pendingLanes);n!==0&&(mu(t,n|1),ht(t,Oe()),!(ne&6)&&(xa=Oe()+500,li()))}break;case 13:Ni(function(){var i=qn(e,1);if(i!==null){var a=ot();Kt(i,e,1,a)}}),Vu(e,1)}};fu=function(e){if(e.tag===13){var t=qn(e,134217728);if(t!==null){var n=ot();Kt(t,e,134217728,n)}Vu(e,134217728)}};Ty=function(e){if(e.tag===13){var t=Jn(e),n=qn(e,t);if(n!==null){var i=ot();Kt(n,e,t,i)}Vu(e,t)}};ky=function(){return ce};Cy=function(e,t){var n=ce;try{return ce=e,t()}finally{ce=n}};Hc=function(e,t,n){switch(t){case"input":if(Mc(e,n),t=n.name,n.type==="radio"&&t!=null){for(n=e;n.parentNode;)n=n.parentNode;for(n=n.querySelectorAll("input[name="+JSON.stringify(""+t)+'][type="radio"]'),t=0;t<n.length;t++){var i=n[t];if(i!==e&&i.form===e.form){var a=Ss(i);if(!a)throw Error(E(90));ny(i),Mc(i,a)}}}break;case"textarea":ay(e,n);break;case"select":t=n.value,t!=null&&la(e,!!n.multiple,t,!1)}};uy=Lu;py=Ni;var zv={usingClientEntryPoint:!1,Events:[$o,ea,Ss,cy,dy,Lu]},Ua={findFiberByHostInstance:xi,bundleType:0,version:"18.2.0",rendererPackageName:"react-dom"},Wv={bundleType:Ua.bundleType,version:Ua.version,rendererPackageName:Ua.rendererPackageName,rendererConfig:Ua.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:An.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return e=hy(e),e===null?null:e.stateNode},findFiberByHostInstance:Ua.findFiberByHostInstance||Bv,findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:"18.2.0-next-9e3b772b8-20220608"};if(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__<"u"){var _r=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!_r.isDisabled&&_r.supportsFiber)try{Is=_r.inject(Wv),cn=_r}catch{}}It.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=zv;It.createPortal=function(e,t){var n=2<arguments.length&&arguments[2]!==void 0?arguments[2]:null;if(!Zu(t))throw Error(E(200));return Rv(e,t,null,n)};It.createRoot=function(e,t){if(!Zu(e))throw Error(E(299));var n=!1,i="",a=Zg;return t!=null&&(t.unstable_strictMode===!0&&(n=!0),t.identifierPrefix!==void 0&&(i=t.identifierPrefix),t.onRecoverableError!==void 0&&(a=t.onRecoverableError)),t=$u(e,1,!1,null,null,n,!1,i,a),e[In]=t.current,qo(e.nodeType===8?e.parentNode:e),new Hu(t)};It.findDOMNode=function(e){if(e==null)return null;if(e.nodeType===1)return e;var t=e._reactInternals;if(t===void 0)throw typeof e.render=="function"?Error(E(188)):(e=Object.keys(e).join(","),Error(E(268,e)));return e=hy(t),e=e===null?null:e.stateNode,e};It.flushSync=function(e){return Ni(e)};It.hydrate=function(e,t,n){if(!js(t))throw Error(E(200));return Ms(null,e,t,!0,n)};It.hydrateRoot=function(e,t,n){if(!Zu(e))throw Error(E(405));var i=n!=null&&n.hydratedSources||null,a=!1,o="",r=Zg;if(n!=null&&(n.unstable_strictMode===!0&&(a=!0),n.identifierPrefix!==void 0&&(o=n.identifierPrefix),n.onRecoverableError!==void 0&&(r=n.onRecoverableError)),t=Hg(t,null,e,1,n??null,a,!1,o,r),e[In]=t.current,qo(e),i)for(e=0;e<i.length;e++)n=i[e],a=n._getVersion,a=a(n._source),t.mutableSourceEagerHydrationData==null?t.mutableSourceEagerHydrationData=[n,a]:t.mutableSourceEagerHydrationData.push(n,a);return new Ws(t)};It.render=function(e,t,n){if(!js(t))throw Error(E(200));return Ms(null,e,t,!1,n)};It.unmountComponentAtNode=function(e){if(!js(e))throw Error(E(40));return e._reactRootContainer?(Ni(function(){Ms(null,null,e,!1,function(){e._reactRootContainer=null,e[In]=null})}),!0):!1};It.unstable_batchedUpdates=Lu;It.unstable_renderSubtreeIntoContainer=function(e,t,n,i){if(!js(n))throw Error(E(200));if(e==null||e._reactInternals===void 0)throw Error(E(38));return Ms(e,t,n,!1,i)};It.version="18.2.0-next-9e3b772b8-20220608";function Qg(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(Qg)}catch(e){console.error(e)}}Qg(),Hh.exports=It;var Ls=Hh.exports;const br=eu(Ls);var Jm=Ls;Nc.createRoot=Jm.createRoot,Nc.hydrateRoot=Jm.hydrateRoot;/**
 * @remix-run/router v1.9.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function Oo(){return Oo=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},Oo.apply(this,arguments)}var Vn;(function(e){e.Pop="POP",e.Push="PUSH",e.Replace="REPLACE"})(Vn||(Vn={}));const ef="popstate";function jv(e){e===void 0&&(e={});function t(i,a){let{pathname:o,search:r,hash:s}=i.location;return Id("",{pathname:o,search:r,hash:s},a.state&&a.state.usr||null,a.state&&a.state.key||"default")}function n(i,a){return typeof a=="string"?a:fs(a)}return Lv(t,n,null,e)}function je(e,t){if(e===!1||e===null||typeof e>"u")throw new Error(t)}function Qu(e,t){if(!e){typeof console<"u"&&console.warn(t);try{throw new Error(t)}catch{}}}function Mv(){return Math.random().toString(36).substr(2,8)}function tf(e,t){return{usr:e.state,key:e.key,idx:t}}function Id(e,t,n,i){return n===void 0&&(n=null),Oo({pathname:typeof e=="string"?e:e.pathname,search:"",hash:""},typeof t=="string"?Sa(t):t,{state:n,key:t&&t.key||i||Mv()})}function fs(e){let{pathname:t="/",search:n="",hash:i=""}=e;return n&&n!=="?"&&(t+=n.charAt(0)==="?"?n:"?"+n),i&&i!=="#"&&(t+=i.charAt(0)==="#"?i:"#"+i),t}function Sa(e){let t={};if(e){let n=e.indexOf("#");n>=0&&(t.hash=e.substr(n),e=e.substr(0,n));let i=e.indexOf("?");i>=0&&(t.search=e.substr(i),e=e.substr(0,i)),e&&(t.pathname=e)}return t}function Lv(e,t,n,i){i===void 0&&(i={});let{window:a=document.defaultView,v5Compat:o=!1}=i,r=a.history,s=Vn.Pop,l=null,c=d();c==null&&(c=0,r.replaceState(Oo({},r.state,{idx:c}),""));function d(){return(r.state||{idx:null}).idx}function h(){s=Vn.Pop;let T=d(),g=T==null?null:T-c;c=T,l&&l({action:s,location:u.location,delta:g})}function y(T,g){s=Vn.Push;let _=Id(u.location,T,g);n&&n(_,T),c=d()+1;let b=tf(_,c),w=u.createHref(_);try{r.pushState(b,"",w)}catch(C){if(C instanceof DOMException&&C.name==="DataCloneError")throw C;a.location.assign(w)}o&&l&&l({action:s,location:u.location,delta:1})}function p(T,g){s=Vn.Replace;let _=Id(u.location,T,g);n&&n(_,T),c=d();let b=tf(_,c),w=u.createHref(_);r.replaceState(b,"",w),o&&l&&l({action:s,location:u.location,delta:0})}function f(T){let g=a.location.origin!=="null"?a.location.origin:a.location.href,_=typeof T=="string"?T:fs(T);return je(g,"No window.location.(origin|href) available to create URL for href: "+_),new URL(_,g)}let u={get action(){return s},get location(){return e(a,r)},listen(T){if(l)throw new Error("A history only accepts one active listener");return a.addEventListener(ef,h),l=T,()=>{a.removeEventListener(ef,h),l=null}},createHref(T){return t(a,T)},createURL:f,encodeLocation(T){let g=f(T);return{pathname:g.pathname,search:g.search,hash:g.hash}},push:y,replace:p,go(T){return r.go(T)}};return u}var nf;(function(e){e.data="data",e.deferred="deferred",e.redirect="redirect",e.error="error"})(nf||(nf={}));function Fv(e,t,n){n===void 0&&(n="/");let i=typeof t=="string"?Sa(t):t,a=Ku(i.pathname||"/",n);if(a==null)return null;let o=Kg(e);Uv(o);let r=null;for(let s=0;r==null&&s<o.length;++s)r=Yv(o[s],tw(a));return r}function Kg(e,t,n,i){t===void 0&&(t=[]),n===void 0&&(n=[]),i===void 0&&(i="");let a=(o,r,s)=>{let l={relativePath:s===void 0?o.path||"":s,caseSensitive:o.caseSensitive===!0,childrenIndex:r,route:o};l.relativePath.startsWith("/")&&(je(l.relativePath.startsWith(i),'Absolute route path "'+l.relativePath+'" nested under path '+('"'+i+'" is not valid. An absolute child route path ')+"must start with the combined path of all its parent routes."),l.relativePath=l.relativePath.slice(i.length));let c=ti([i,l.relativePath]),d=n.concat(l);o.children&&o.children.length>0&&(je(o.index!==!0,"Index routes must not have child routes. Please remove "+('all child routes from route path "'+c+'".')),Kg(o.children,t,d,c)),!(o.path==null&&!o.index)&&t.push({path:c,score:Kv(c,o.index),routesMeta:d})};return e.forEach((o,r)=>{var s;if(o.path===""||!((s=o.path)!=null&&s.includes("?")))a(o,r);else for(let l of Xg(o.path))a(o,r,l)}),t}function Xg(e){let t=e.split("/");if(t.length===0)return[];let[n,...i]=t,a=n.endsWith("?"),o=n.replace(/\?$/,"");if(i.length===0)return a?[o,""]:[o];let r=Xg(i.join("/")),s=[];return s.push(...r.map(l=>l===""?o:[o,l].join("/"))),a&&s.push(...r),s.map(l=>e.startsWith("/")&&l===""?"/":l)}function Uv(e){e.sort((t,n)=>t.score!==n.score?n.score-t.score:Xv(t.routesMeta.map(i=>i.childrenIndex),n.routesMeta.map(i=>i.childrenIndex)))}const Gv=/^:\w+$/,$v=3,Vv=2,Hv=1,Zv=10,Qv=-2,af=e=>e==="*";function Kv(e,t){let n=e.split("/"),i=n.length;return n.some(af)&&(i+=Qv),t&&(i+=Vv),n.filter(a=>!af(a)).reduce((a,o)=>a+(Gv.test(o)?$v:o===""?Hv:Zv),i)}function Xv(e,t){return e.length===t.length&&e.slice(0,-1).every((i,a)=>i===t[a])?e[e.length-1]-t[t.length-1]:0}function Yv(e,t){let{routesMeta:n}=e,i={},a="/",o=[];for(let r=0;r<n.length;++r){let s=n[r],l=r===n.length-1,c=a==="/"?t:t.slice(a.length)||"/",d=Jv({path:s.relativePath,caseSensitive:s.caseSensitive,end:l},c);if(!d)return null;Object.assign(i,d.params);let h=s.route;o.push({params:i,pathname:ti([a,d.pathname]),pathnameBase:ow(ti([a,d.pathnameBase])),route:h}),d.pathnameBase!=="/"&&(a=ti([a,d.pathnameBase]))}return o}function Jv(e,t){typeof e=="string"&&(e={path:e,caseSensitive:!1,end:!0});let[n,i]=ew(e.path,e.caseSensitive,e.end),a=t.match(n);if(!a)return null;let o=a[0],r=o.replace(/(.)\/+$/,"$1"),s=a.slice(1);return{params:i.reduce((c,d,h)=>{if(d==="*"){let y=s[h]||"";r=o.slice(0,o.length-y.length).replace(/(.)\/+$/,"$1")}return c[d]=nw(s[h]||"",d),c},{}),pathname:o,pathnameBase:r,pattern:e}}function ew(e,t,n){t===void 0&&(t=!1),n===void 0&&(n=!0),Qu(e==="*"||!e.endsWith("*")||e.endsWith("/*"),'Route path "'+e+'" will be treated as if it were '+('"'+e.replace(/\*$/,"/*")+'" because the `*` character must ')+"always follow a `/` in the pattern. To get rid of this warning, "+('please change the route path to "'+e.replace(/\*$/,"/*")+'".'));let i=[],a="^"+e.replace(/\/*\*?$/,"").replace(/^\/*/,"/").replace(/[\\.*+^$?{}|()[\]]/g,"\\$&").replace(/\/:(\w+)/g,(r,s)=>(i.push(s),"/([^\\/]+)"));return e.endsWith("*")?(i.push("*"),a+=e==="*"||e==="/*"?"(.*)$":"(?:\\/(.+)|\\/*)$"):n?a+="\\/*$":e!==""&&e!=="/"&&(a+="(?:(?=\\/|$))"),[new RegExp(a,t?void 0:"i"),i]}function tw(e){try{return decodeURI(e)}catch(t){return Qu(!1,'The URL path "'+e+'" could not be decoded because it is is a malformed URL segment. This is probably due to a bad percent '+("encoding ("+t+").")),e}}function nw(e,t){try{return decodeURIComponent(e)}catch(n){return Qu(!1,'The value for the URL param "'+t+'" will not be decoded because'+(' the string "'+e+'" is a malformed URL segment. This is probably')+(" due to a bad percent encoding ("+n+").")),e}}function Ku(e,t){if(t==="/")return e;if(!e.toLowerCase().startsWith(t.toLowerCase()))return null;let n=t.endsWith("/")?t.length-1:t.length,i=e.charAt(n);return i&&i!=="/"?null:e.slice(n)||"/"}function iw(e,t){t===void 0&&(t="/");let{pathname:n,search:i="",hash:a=""}=typeof e=="string"?Sa(e):e;return{pathname:n?n.startsWith("/")?n:aw(n,t):t,search:rw(i),hash:sw(a)}}function aw(e,t){let n=t.replace(/\/+$/,"").split("/");return e.split("/").forEach(a=>{a===".."?n.length>1&&n.pop():a!=="."&&n.push(a)}),n.length>1?n.join("/"):"/"}function uc(e,t,n,i){return"Cannot include a '"+e+"' character in a manually specified "+("`to."+t+"` field ["+JSON.stringify(i)+"].  Please separate it out to the ")+("`to."+n+"` field. Alternatively you may provide the full path as ")+'a string in <Link to="..."> and the router will parse it for you.'}function Yg(e){return e.filter((t,n)=>n===0||t.route.path&&t.route.path.length>0)}function Jg(e,t,n,i){i===void 0&&(i=!1);let a;typeof e=="string"?a=Sa(e):(a=Oo({},e),je(!a.pathname||!a.pathname.includes("?"),uc("?","pathname","search",a)),je(!a.pathname||!a.pathname.includes("#"),uc("#","pathname","hash",a)),je(!a.search||!a.search.includes("#"),uc("#","search","hash",a)));let o=e===""||a.pathname==="",r=o?"/":a.pathname,s;if(i||r==null)s=n;else{let h=t.length-1;if(r.startsWith("..")){let y=r.split("/");for(;y[0]==="..";)y.shift(),h-=1;a.pathname=y.join("/")}s=h>=0?t[h]:"/"}let l=iw(a,s),c=r&&r!=="/"&&r.endsWith("/"),d=(o||r===".")&&n.endsWith("/");return!l.pathname.endsWith("/")&&(c||d)&&(l.pathname+="/"),l}const ti=e=>e.join("/").replace(/\/\/+/g,"/"),ow=e=>e.replace(/\/+$/,"").replace(/^\/*/,"/"),rw=e=>!e||e==="?"?"":e.startsWith("?")?e:"?"+e,sw=e=>!e||e==="#"?"":e.startsWith("#")?e:"#"+e;function lw(e){return e!=null&&typeof e.status=="number"&&typeof e.statusText=="string"&&typeof e.internal=="boolean"&&"data"in e}const e_=["post","put","patch","delete"];new Set(e_);const cw=["get",...e_];new Set(cw);/**
 * React Router v6.16.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function hs(){return hs=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},hs.apply(this,arguments)}const Xu=v.createContext(null),dw=v.createContext(null),Ea=v.createContext(null),Fs=v.createContext(null),ci=v.createContext({outlet:null,matches:[],isDataRoute:!1}),t_=v.createContext(null);function uw(e,t){let{relative:n}=t===void 0?{}:t;Ho()||je(!1);let{basename:i,navigator:a}=v.useContext(Ea),{hash:o,pathname:r,search:s}=i_(e,{relative:n}),l=r;return i!=="/"&&(l=r==="/"?i:ti([i,r])),a.createHref({pathname:l,search:s,hash:o})}function Ho(){return v.useContext(Fs)!=null}function Us(){return Ho()||je(!1),v.useContext(Fs).location}function n_(e){v.useContext(Ea).static||v.useLayoutEffect(e)}function pw(){let{isDataRoute:e}=v.useContext(ci);return e?Iw():mw()}function mw(){Ho()||je(!1);let e=v.useContext(Xu),{basename:t,navigator:n}=v.useContext(Ea),{matches:i}=v.useContext(ci),{pathname:a}=Us(),o=JSON.stringify(Yg(i).map(l=>l.pathnameBase)),r=v.useRef(!1);return n_(()=>{r.current=!0}),v.useCallback(function(l,c){if(c===void 0&&(c={}),!r.current)return;if(typeof l=="number"){n.go(l);return}let d=Jg(l,JSON.parse(o),a,c.relative==="path");e==null&&t!=="/"&&(d.pathname=d.pathname==="/"?t:ti([t,d.pathname])),(c.replace?n.replace:n.push)(d,c.state,c)},[t,n,o,a,e])}function fw(){let{matches:e}=v.useContext(ci),t=e[e.length-1];return t?t.params:{}}function i_(e,t){let{relative:n}=t===void 0?{}:t,{matches:i}=v.useContext(ci),{pathname:a}=Us(),o=JSON.stringify(Yg(i).map(r=>r.pathnameBase));return v.useMemo(()=>Jg(e,JSON.parse(o),a,n==="path"),[e,o,a,n])}function hw(e,t){return yw(e,t)}function yw(e,t,n){Ho()||je(!1);let{navigator:i}=v.useContext(Ea),{matches:a}=v.useContext(ci),o=a[a.length-1],r=o?o.params:{};o&&o.pathname;let s=o?o.pathnameBase:"/";o&&o.route;let l=Us(),c;if(t){var d;let u=typeof t=="string"?Sa(t):t;s==="/"||(d=u.pathname)!=null&&d.startsWith(s)||je(!1),c=u}else c=l;let h=c.pathname||"/",y=s==="/"?h:h.slice(s.length)||"/",p=Fv(e,{pathname:y}),f=ww(p&&p.map(u=>Object.assign({},u,{params:Object.assign({},r,u.params),pathname:ti([s,i.encodeLocation?i.encodeLocation(u.pathname).pathname:u.pathname]),pathnameBase:u.pathnameBase==="/"?s:ti([s,i.encodeLocation?i.encodeLocation(u.pathnameBase).pathname:u.pathnameBase])})),a,n);return t&&f?v.createElement(Fs.Provider,{value:{location:hs({pathname:"/",search:"",hash:"",state:null,key:"default"},c),navigationType:Vn.Pop}},f):f}function gw(){let e=Cw(),t=lw(e)?e.status+" "+e.statusText:e instanceof Error?e.message:JSON.stringify(e),n=e instanceof Error?e.stack:null,a={padding:"0.5rem",backgroundColor:"rgba(200,200,200, 0.5)"},o=null;return v.createElement(v.Fragment,null,v.createElement("h2",null,"Unexpected Application Error!"),v.createElement("h3",{style:{fontStyle:"italic"}},t),n?v.createElement("pre",{style:a},n):null,o)}const _w=v.createElement(gw,null);class bw extends v.Component{constructor(t){super(t),this.state={location:t.location,revalidation:t.revalidation,error:t.error}}static getDerivedStateFromError(t){return{error:t}}static getDerivedStateFromProps(t,n){return n.location!==t.location||n.revalidation!=="idle"&&t.revalidation==="idle"?{error:t.error,location:t.location,revalidation:t.revalidation}:{error:t.error||n.error,location:n.location,revalidation:t.revalidation||n.revalidation}}componentDidCatch(t,n){console.error("React Router caught the following error during render",t,n)}render(){return this.state.error?v.createElement(ci.Provider,{value:this.props.routeContext},v.createElement(t_.Provider,{value:this.state.error,children:this.props.component})):this.props.children}}function vw(e){let{routeContext:t,match:n,children:i}=e,a=v.useContext(Xu);return a&&a.static&&a.staticContext&&(n.route.errorElement||n.route.ErrorBoundary)&&(a.staticContext._deepestRenderedBoundaryId=n.route.id),v.createElement(ci.Provider,{value:t},i)}function ww(e,t,n){var i;if(t===void 0&&(t=[]),n===void 0&&(n=null),e==null){var a;if((a=n)!=null&&a.errors)e=n.matches;else return null}let o=e,r=(i=n)==null?void 0:i.errors;if(r!=null){let s=o.findIndex(l=>l.route.id&&(r==null?void 0:r[l.route.id]));s>=0||je(!1),o=o.slice(0,Math.min(o.length,s+1))}return o.reduceRight((s,l,c)=>{let d=l.route.id?r==null?void 0:r[l.route.id]:null,h=null;n&&(h=l.route.errorElement||_w);let y=t.concat(o.slice(0,c+1)),p=()=>{let f;return d?f=h:l.route.Component?f=v.createElement(l.route.Component,null):l.route.element?f=l.route.element:f=s,v.createElement(vw,{match:l,routeContext:{outlet:s,matches:y,isDataRoute:n!=null},children:f})};return n&&(l.route.ErrorBoundary||l.route.errorElement||c===0)?v.createElement(bw,{location:n.location,revalidation:n.revalidation,component:h,error:d,children:p(),routeContext:{outlet:null,matches:y,isDataRoute:!0}}):p()},null)}var a_=function(e){return e.UseBlocker="useBlocker",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e}(a_||{}),ys=function(e){return e.UseBlocker="useBlocker",e.UseLoaderData="useLoaderData",e.UseActionData="useActionData",e.UseRouteError="useRouteError",e.UseNavigation="useNavigation",e.UseRouteLoaderData="useRouteLoaderData",e.UseMatches="useMatches",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e.UseRouteId="useRouteId",e}(ys||{});function xw(e){let t=v.useContext(Xu);return t||je(!1),t}function Tw(e){let t=v.useContext(dw);return t||je(!1),t}function kw(e){let t=v.useContext(ci);return t||je(!1),t}function o_(e){let t=kw(),n=t.matches[t.matches.length-1];return n.route.id||je(!1),n.route.id}function Cw(){var e;let t=v.useContext(t_),n=Tw(ys.UseRouteError),i=o_(ys.UseRouteError);return t||((e=n.errors)==null?void 0:e[i])}function Iw(){let{router:e}=xw(a_.UseNavigateStable),t=o_(ys.UseNavigateStable),n=v.useRef(!1);return n_(()=>{n.current=!0}),v.useCallback(function(a,o){o===void 0&&(o={}),n.current&&(typeof a=="number"?e.navigate(a):e.navigate(a,hs({fromRouteId:t},o)))},[e,t])}function qd(e){je(!1)}function qw(e){let{basename:t="/",children:n=null,location:i,navigationType:a=Vn.Pop,navigator:o,static:r=!1}=e;Ho()&&je(!1);let s=t.replace(/^\/*/,"/"),l=v.useMemo(()=>({basename:s,navigator:o,static:r}),[s,o,r]);typeof i=="string"&&(i=Sa(i));let{pathname:c="/",search:d="",hash:h="",state:y=null,key:p="default"}=i,f=v.useMemo(()=>{let u=Ku(c,s);return u==null?null:{location:{pathname:u,search:d,hash:h,state:y,key:p},navigationType:a}},[s,c,d,h,y,p,a]);return f==null?null:v.createElement(Ea.Provider,{value:l},v.createElement(Fs.Provider,{children:n,value:f}))}function Dw(e){let{children:t,location:n}=e;return hw(Dd(t),n)}new Promise(()=>{});function Dd(e,t){t===void 0&&(t=[]);let n=[];return v.Children.forEach(e,(i,a)=>{if(!v.isValidElement(i))return;let o=[...t,a];if(i.type===v.Fragment){n.push.apply(n,Dd(i.props.children,o));return}i.type!==qd&&je(!1),!i.props.index||!i.props.children||je(!1);let r={id:i.props.id||o.join("-"),caseSensitive:i.props.caseSensitive,element:i.props.element,Component:i.props.Component,index:i.props.index,path:i.props.path,loader:i.props.loader,action:i.props.action,errorElement:i.props.errorElement,ErrorBoundary:i.props.ErrorBoundary,hasErrorBoundary:i.props.ErrorBoundary!=null||i.props.errorElement!=null,shouldRevalidate:i.props.shouldRevalidate,handle:i.props.handle,lazy:i.props.lazy};i.props.children&&(r.children=Dd(i.props.children,o)),n.push(r)}),n}/**
 * React Router DOM v6.16.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function Pd(){return Pd=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},Pd.apply(this,arguments)}function Pw(e,t){if(e==null)return{};var n={},i=Object.keys(e),a,o;for(o=0;o<i.length;o++)a=i[o],!(t.indexOf(a)>=0)&&(n[a]=e[a]);return n}function Sw(e){return!!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey)}function Ew(e,t){return e.button===0&&(!t||t==="_self")&&!Sw(e)}const Aw=["onClick","relative","reloadDocument","replace","state","target","to","preventScrollReset"],Nw="startTransition",of=Ur[Nw];function Rw(e){let{basename:t,children:n,future:i,window:a}=e,o=v.useRef();o.current==null&&(o.current=jv({window:a,v5Compat:!0}));let r=o.current,[s,l]=v.useState({action:r.action,location:r.location}),{v7_startTransition:c}=i||{},d=v.useCallback(h=>{c&&of?of(()=>l(h)):l(h)},[l,c]);return v.useLayoutEffect(()=>r.listen(d),[r,d]),v.createElement(qw,{basename:t,children:n,location:s.location,navigationType:s.action,navigator:r})}const Bw=typeof window<"u"&&typeof window.document<"u"&&typeof window.document.createElement<"u",Ow=/^(?:[a-z][a-z0-9+.-]*:|\/\/)/i,Ri=v.forwardRef(function(t,n){let{onClick:i,relative:a,reloadDocument:o,replace:r,state:s,target:l,to:c,preventScrollReset:d}=t,h=Pw(t,Aw),{basename:y}=v.useContext(Ea),p,f=!1;if(typeof c=="string"&&Ow.test(c)&&(p=c,Bw))try{let _=new URL(window.location.href),b=c.startsWith("//")?new URL(_.protocol+c):new URL(c),w=Ku(b.pathname,y);b.origin===_.origin&&w!=null?c=w+b.search+b.hash:f=!0}catch{}let u=uw(c,{relative:a}),T=zw(c,{replace:r,state:s,target:l,preventScrollReset:d,relative:a});function g(_){i&&i(_),_.defaultPrevented||T(_)}return v.createElement("a",Pd({},h,{href:p||u,onClick:f||o?i:g,ref:n,target:l}))});var rf;(function(e){e.UseScrollRestoration="useScrollRestoration",e.UseSubmit="useSubmit",e.UseSubmitFetcher="useSubmitFetcher",e.UseFetcher="useFetcher"})(rf||(rf={}));var sf;(function(e){e.UseFetchers="useFetchers",e.UseScrollRestoration="useScrollRestoration"})(sf||(sf={}));function zw(e,t){let{target:n,replace:i,state:a,preventScrollReset:o,relative:r}=t===void 0?{}:t,s=pw(),l=Us(),c=i_(e,{relative:r});return v.useCallback(d=>{if(Ew(d,n)){d.preventDefault();let h=i!==void 0?i:fs(l)===fs(c);s(e,{replace:h,state:a,preventScrollReset:o,relative:r})}},[l,s,c,i,a,n,e,o,r])}const Ww="/aiida-registry/pr-preview/pr-280/assets/logo-white-text-16948862.svg",jw="/aiida-registry/pr-preview/pr-280/assets/MARVEL-32e738c9.png",Mw="/aiida-registry/pr-preview/pr-280/assets/MaX-099f261c.png";const Lw={"aiida-QECpWorkChain":{code_home:"https://github.com/rikigigi/aiida-QECpWorkChain",development_status:"beta",entry_point_prefix:"qecpworkchain",pip_url:"git+https://github.com/rikigigi/aiida-QECpWorkChain",name:"aiida-QECpWorkChain",package_name:"aiida_QECpWorkChain",hosted_on:"github.com",metadata:{author:"Riccardo Bertossa",author_email:"rbertoss@sissa.it",version:"0.2.0a0",description:"Car-Parrinello Work Chain with Quantum Espresso. This workchain does a full CP simulation, from the choice of the electronic mass and the timestep, to the choice of the best parallelization options, and then it does the NPT equilibration and a final NVE simulation at the prescribed P and T. Automates as much as possible.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: GNU General Public License v3 (GPLv3)","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.workflows":{"qecpworkchain.cp":{description:["No description available"],spec:{inputs:[{name:"cp_code",required:!0,valid_types:"Code",info:""},{name:"cp_resources_cg_list",required:!0,valid_types:"List",info:"Same as cp_resources_cp_list but when doing a CG. The CG uses a different amount of resource and can use no band or task group parallelization."},{name:"cp_resources_cp_list",required:!0,valid_types:"List",info:`List of dictionary like the following:
{
 'resources' : {
   'num_machines' : 2,
   'num_mpiprocs_per_machine' : 48,
 },
 'wallclock' : 3600,
 'queue' : 'queue_name',
 'account': 'account_name',
}
c,porturrently only the first element of the list is used.
'wallclock' is the maximum time that can be requested to the scheduler. This code can decide to ask for less.
`},{name:"ecutwfc",required:!0,valid_types:"Float",info:"wavefunction cutoff (Ry), like in the QE input"},{name:"pseudo_family",required:!0,valid_types:"Str",info:"pseudopotential family to use, as in usual aiida operations"},{name:"pw_code",required:!0,valid_types:"Code",info:"input pw code (used to calculate force ratio)"},{name:"pw_resources_list",required:!0,valid_types:"List",info:"Same as cp_resources_cp_list but for pw.x code."},{name:"structure",required:!0,valid_types:"StructureData, TrajectoryData",info:"Input structure. If a trajectory is given, the workchain will use its last step to start the CG. If velocities are present, they will be used to initialize the simulation. Note that if you use a trajectory, usually kind information (like mass) are not included, so default values will be used. If you want to include kind information or override those provided with the input structure, use the input structure_kinds"},{name:"thermobarostat_points",required:!0,valid_types:"List",info:'List of dicts, each with the format [ { "temperature_K": 1000, "pressure_KBar": 10 , "equilibration_time_ps": 5.0, "thermostat_time_ps": 5.0} ]. The simulation will loop over this list of dictionaries, in the same order, equilibrating for the specified time at the given P,T point. Every point is repeated if the average T and P are not within the specified ranges'},{name:"additional_parameters_cp",required:!1,valid_types:"Dict",info:"parameters that will be included in the settings input of the QE CP plugin. These settings will be added on top of the default one. Same format as plugin input"},{name:"adjust_ionic_mass",required:!1,valid_types:"Bool",info:"Multiply the mass of the ions by the corresponding force ration between the cp forces and pw forces -- that is less than 1. Note that averages of static properties do not depend on the ionic masses."},{name:"benchmark_emass_dt_walltime_s",required:!1,valid_types:"Float",info:"same as benchmark_parallel_walltime_s but for dermining the best electronic mass and timestep."},{name:"benchmark_parallel_walltime_s",required:!1,valid_types:"Float",info:"time requested to the scheduler during the test for finding the best parallelization parameters."},{name:"cmdline_cp",required:!1,valid_types:"List, NoneType",info:"additional command line parameters of the cp verlet caclulations only (for example parallelization options)"},{name:"default_nose_frequency",required:!1,valid_types:"Float",info:"default nose frequency when a frequency cannot be estimated from the vibrational spectrum"},{name:"dt",required:!1,valid_types:"Float, NoneType",info:"timestep in atomic units, if not automatically chosen."},{name:"dt_start_stop_step",required:!1,valid_types:"List",info:"list of timesteps to try. Timesteps are changed to better integrate the equation of motion. When a new electronic mass is selected by this workchain timesteps are automatically adjusted."},{name:"emass",required:!1,valid_types:"Float, NoneType",info:"electronic mass, atomic mass units, if not automatically chosen"},{name:"emass_list",required:!1,valid_types:"List",info:"list of electronic masses to try. The emass is selected in order to satisfy the requested CP/DFT force ratio."},{name:"initial_atomic_velocities_A_ps",required:!1,valid_types:"ArrayData, NoneType",info:"optional input initial velocities in angstrom over picoseconds"},{name:"max_slope_const",required:!1,valid_types:"Float",info:"max slope in K/ps of the constant of motion linear fit."},{name:"max_slope_ekinc",required:!1,valid_types:"Float",info:"max slope in K/ps of the ekinc linear fit. If not satisfied try to change emass"},{name:"max_slope_min_emass",required:!1,valid_types:"Float",info:"minimum possible value of electronic mass that can be set by the max_slope correction routine. Will not go lower than that."},{name:"max_slope_min_ps",required:!1,valid_types:"Float",info:"minimum required lenght in ps of the last trajectory to do the linear fit on ekinc and const of motion"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_traj_steps_vdos",required:!1,valid_types:"Int",info:"minimum number of steps to consider the calculated vibrational spectrum maximum valid, to set the thermostat frequency"},{name:"minimum_nose_frequency",required:!1,valid_types:"Float",info:"minimum nose frequency: if the frequency estimated from the vibrational spectrum is lower than this value, this value is used"},{name:"nstep_initial_cg",required:!1,valid_types:"Int",info:"At the beginning of the simulation the CP algorithm is not used. This is the number of steps to do using Born-Oppenheimer molecular dynamics algorithm with a conjugate gradient minimization of the electronic ground state."},{name:"nstep_parallel_test",required:!1,valid_types:"Int",info:"the benchmark simulations will be that long, if performed"},{name:"number_of_pw_per_trajectory",required:!1,valid_types:"Int",info:"Number of pw submitted for every trajectory during calculation of force ratio."},{name:"nve_required_picoseconds",required:!1,valid_types:"Float",info:"The equilibrated NVE simulation will last at least this number of picoseconds. How much picoseconds do you want?"},{name:"pressure_tolerance",required:!1,valid_types:"Float",info:"Pressure tolerance in kBar used to say if the npt is equilibrated. If not setted, use the standard deviation of the P time series"},{name:"skip_emass_dt_test",required:!1,valid_types:"Bool",info:""},{name:"skip_parallel_test",required:!1,valid_types:"Bool",info:"do not run run benchmarks to discover a good internal Quantum Espresso parallelization scheme for the current system"},{name:"skip_thermobarostat",required:!1,valid_types:"Bool",info:""},{name:"structure_kinds",required:!1,valid_types:"List, NoneType",info:'These kinds will be used to override or set the masses of the various atomic types. Note that the workflow, if skip_emass_dt_test is True, will calculate the ratio between cp forces and pw forces and adjust the provided masses automatically according to this ratio. So if you provide this input, make sure to set skip_emass_dt_test to True and set also the inputs emass and dt, or "bad things can happen"'},{name:"target_force_ratio",required:!1,valid_types:"Float",info:"The forces calculated by the Car-Parrinello method are affected by two types of error: one is due to the oscillations of the electrons around the DFT energy minimum, and the second is due to the finite mass of the electronic fluid that produces a _sistematic_ error in the forces, as if the electrons add mass to the ionic core. This second kind of error is can be controlled by this parameter, that tries to adjust the electronic mass to obtain the desidered ratio between CP forces and true DFT forces. Then you may want to modify the ionic mass to correct the leading factor of this error."},{name:"temperature_tolerance",required:!1,valid_types:"Float",info:"Temperature tolerance in K used to say if the npt is equilibrated. If not setted, use the standard deviation of the T time series"},{name:"tempw_initial_random",required:!1,valid_types:"Float, NoneType",info:"If provided, sets the initial temperature when randomly initializing the starting velocities."}],outputs:[{name:"cmdline_cp",required:!0,valid_types:"",info:""},{name:"dt",required:!0,valid_types:"",info:""},{name:"emass",required:!0,valid_types:"",info:""},{name:"full_traj",required:!0,valid_types:"",info:""},{name:"kinds",required:!0,valid_types:"",info:""},{name:"nve_prod_traj",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The initial cg steps failed. I cannot start to work."},{status:402,message:"Nose-Hoover thermostat failed."},{status:403,message:"Final cg after Nose-Hoover failed."},{status:404,message:"Error in the NVE simulation"},{status:405,message:"The simulations are calculating very expensive random numbers. There is something wrong (cutoff? metal? boo?)"},{status:406,message:"Wrong input parameters"},{status:407,message:"Parallel test was not succesful, maybe there is something more wrong."},{status:408,message:"Multiple errors in the simulation that cannot fix."},{status:409,message:"This is a bug in the workchain."}]},class:"aiida_QECpWorkChain.workflow:CpWorkChain"}}},commits_count:5,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/rikigigi/aiida-QECpWorkChain",is_installable:"True"},"aiida-abinit":{code_home:"https://github.com/sponce24/aiida-abinit",entry_point_prefix:"abinit",pip_url:"aiida-abinit",plugin_info:"https://raw.github.com/sponce24/aiida-abinit/master/setup.json",name:"aiida-abinit",package_name:"aiida_abinit",hosted_on:"github.com",metadata:{release_date:"2023-02-03",description:"The AiiDA plugin for ABINIT.",author_email:"Samuel Ponce <samuel.pon@gmail.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"0.4.0"},aiida_version:">=1.6.3,<1.7.0",entry_points:{"aiida.calculations":{abinit:{description:["AiiDA calculation plugin wrapping the abinit executable."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The k-point mesh or path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The ABINIT input parameters."},{name:"pseudos",required:!0,valid_types:"Psp8Data, JthXmlData",info:"The pseudopotentials."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData",info:"A remote folder used for restarts."},{name:"settings",required:!1,valid_types:"Dict",info:"Various special settings."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Various output quantities."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Final electronic bands if present."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final structure of the calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:"Trajectory of various output quantities over the calculation if present."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"Calculation did not produce all expected output files."},{status:101,message:"Calculation did not produce the expected `[prefix]o_GSR.nc` output file."},{status:102,message:"Calculation did not produce the expected `[prefix]o_HIST.nc` output file."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the `stdout` output file."},{status:301,message:"The `stdout` output file could not be read."},{status:302,message:"The `stdout` output file could not be parsed."},{status:303,message:"The `abipy` `EventsParser` reports that the runw as not completed."},{status:304,message:"The output file contains one or more error messages."},{status:305,message:"The output file contains one or more warning messages."},{status:312,message:"The output structure could not be parsed."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:500,message:"The SCF minimization cycle did not converge."},{status:501,message:"The ionic minimization cycle did not converge."}]},class:"aiida_abinit.calculations:AbinitCalculation"}},"aiida.parsers":{abinit:"aiida_abinit.parsers:AbinitParser"},"aiida.workflows":{"abinit.base":{description:["Base Abinit Workchain to perform a DFT calculation. Validates parameters and restart."],spec:{inputs:[{name:"abinit",required:!0,valid_types:"",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"An explicit k-points mesh or list. Either this or `kpoints_distance` must be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-point mesh will be generated automatically by a calculation function based on the input structure."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Various output quantities."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Final electronic bands if present."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final structure of the calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:"Trajectory of various output quantities over the calculation if present."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"`pseudos` could not be used to get the necessary pseudos."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:203,message:"Neither the `options` nor `automatic_parallelization` input was specified."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_abinit.workflows.base:AbinitBaseWorkChain"}}},commits_count:11,development_status:"beta",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-abinit",is_installable:"True"},"aiida-aenet":{code_home:"https://gitlab.com/lattice737/aiida-aenet",development_status:"planning",entry_point_prefix:"aenet",pip_url:"https://gitlab.com/lattice737/aiida-aenet",name:"aiida-aenet",package_name:"aiida_aenet",hosted_on:"gitlab.com",metadata:{author:"Nicholas Martinez",author_email:"nicholasmartinez@my.unt.edu",version:"0.1.0",description:"AiiDA plugin to construct machine-learning potentials using aenet",classifiers:["Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Development Status :: 0 - Alpha"]},aiida_version:"~=1.2",entry_points:{"aiida.data":{"aenet.algorithm":"aiida_aenet.data.algorithm:AenetAlgorithm","aenet.potential":"aiida_aenet.data.potentials:AenetPotential"},"aiida.calculations":{"aenet.cur":"aiida_aenet.calculations.cur:CurCalculation","aenet.generate":"aiida_aenet.calculations.generate:AenetGenerateCalculation","aenet.predict":"aiida_aenet.calculations.predict:AenetPredictCalculation","aenet.simulate":"aiida_aenet.calculations.simulate:AenetLammpsMdCalculation","aenet.train":"aiida_aenet.calculations.train:AenetTrainCalculation","aenet.transform":"aiida_aenet.calculations.transform:TransformCalculation"},"aiida.parsers":{"aenet.generate":"aiida_aenet.parsers.generate:AenetGenerateParser","aenet.predict":"aiida_aenet.parsers.predict:AenetPredictParser","aenet.simulate":"aiida_aenet.parsers.simulate:AenetLammpsMdParser","aenet.train":"aiida_aenet.parsers.train:AenetTrainParser"},"aiida.workflows":{"aenet.build_reference":"aiida_aenet.workflows.build_reference:BuildReferenceWorkChain","aenet.compare_simulations":"aiida_aenet.workflows.compare_simulations:CompareSimulationsWorkChain","aenet.make_potential":"aiida_aenet.workflows.make_potential:MakePotentialWorkChain","aenet.make_structures":"aiida_aenet.workflows.make_structures:MakeStructuresWorkChain"},"aenet.potentials":{"lammps.ann":"aiida_aenet.data.potentials.lammps:ANN"}},commits_count:0,errors:[],warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:4},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:4},{colorclass:"orange",text:"Other (Aenet potentials)",count:1}],pip_install_cmd:"pip install https://gitlab.com/lattice737/aiida-aenet"},"aiida-alloy":{code_home:"https://github.com/DanielMarchand/aiida-alloy",development_status:"beta",entry_point_prefix:"alloy",pip_url:"git+https://github.com/DanielMarchand/aiida-alloy",name:"aiida-alloy",package_name:"aiida_alloy",hosted_on:"github.com",metadata:{author:"The AiiDA developers group",author_email:"",version:"0.1.0a0",description:"Aiida Workflows for Elastic Constants using Quantum Espresso",classifiers:["Programming Language :: Python"]},aiida_version:">=1.0.0a0",entry_points:{"aiida.workflows":{elastic:"aiida_alloy.workflows.ElasticWorkChain:ElasticWorkChain"}},commits_count:1,errors:[`Failed to install plugin aiida-alloy</br><pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-9bejax41
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-9bejax41
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-9bejax41/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`],warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'elastic' does not start with prefix 'alloy.'"],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/DanielMarchand/aiida-alloy",is_installable:"False"},"aiida-ase":{code_home:"https://github.com/aiidateam/aiida-ase",documentation_url:"https://aiida-ase.readthedocs.io/",entry_point_prefix:"ase",pip_url:"aiida-ase",plugin_info:"https://raw.github.com/aiidateam/aiida-ase/master/setup.json",name:"aiida-ase",package_name:"aiida_ase",hosted_on:"github.com",metadata:{release_date:"2023-03-17",description:"The official AiiDA plugin for ASE.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"2.0.0"},aiida_version:">=1.6,<2.0",entry_points:{"aiida.calculations":{"ase.ase":{description:["`CalcJob` implementation that can be used to wrap around the ASE calculators."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the namelists."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The k-points to use for the calculation."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"settings",required:!1,valid_types:"Dict",info:"Optional settings that control the plugin."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array",required:!1,valid_types:"ArrayData",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:""},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"One of the expected output files was missing."},{status:301,message:"The log file from the DFT code was not written out."},{status:302,message:"Relaxation did not complete."},{status:303,message:"SCF Failed."},{status:305,message:"Cannot identify what went wrong."},{status:306,message:"gpaw could not find the PAW potentials."},{status:307,message:"Attribute Error found in the stderr file."},{status:308,message:"Fermi level is infinite."},{status:400,message:"The calculation ran out of walltime."}]},class:"aiida_ase.calculations.ase:AseCalculation"}},"aiida.parsers":{"ase.ase":"aiida_ase.parsers.ase:AseParser","ase.gpaw":"aiida_ase.parsers.gpaw:GpawParser"},"aiida.workflows":{"ase.gpaw.base":{description:["Workchain to run a GPAW calculation with automated error handling and restarts."],spec:{inputs:[{name:"gpaw",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"k-points to use for the calculation."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array",required:!1,valid_types:"ArrayData",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:""},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_ase.workflows.base:GpawBaseWorkChain"}}},commits_count:7,development_status:"beta",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-ase",is_installable:"True"},"aiida-autocas":{entry_point_prefix:"autocas",code_home:"https://github.com/microsoft/aiida-autocas",version_file:"https://raw.githubusercontent.com/microsoft/aiida-autocas/main/aiida_autocas/__init__.py",pip_url:"git+https://github.com/microsoft/aiida-autocas",name:"aiida-autocas",package_name:"aiida_autocas",hosted_on:"github.com",metadata:{version:"0.1.0",description:"AiiDA AutoCAS Plugin",classifiers:[]},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{autocas:"aiida_autocas.calculations:AutoCASCalculation"},"aiida.parsers":{autocas:"aiida_autocas.parsers:AutoCASParser"}},commits_count:11,development_status:"planning",errors:[],warnings:["Missing classifier 'Framework :: AiiDA'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/microsoft/aiida-autocas"},"aiida-bands-inspect":{code_home:"https://github.com/greschd/aiida-bands-inspect",documentation_url:"https://aiida-bands-inspect.readthedocs.io",entry_point_prefix:"bands_inspect",pip_url:"aiida-bands-inspect",name:"aiida-bands-inspect",package_name:"aiida_bands_inspect",hosted_on:"github.com",metadata:{release_date:"2020-03-26",description:"AiiDA Plugin for running bands_inspect",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-bands-inspect.readthedocs.io",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.4.0"},aiida_version:null,entry_points:{"aiida.calculations":{"bands_inspect.align":{description:["Calculation class for the ``bands-inspect align`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.data.array.bands.BandsData","        First band structure to compare.","    bands2 : aiida.orm.data.array.bands.BandsData","        Second band structure to compare."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be aligned"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be aligned"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands1_shifted",required:!0,valid_types:"BandsData",info:""},{name:"bands2_shifted",required:!0,valid_types:"BandsData",info:""},{name:"difference",required:!0,valid_types:"Float",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"shift",required:!0,valid_types:"Float",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"At least one of the expected output files is missing from the retrieved folder."},{status:220,message:"The text output file content is not in the expected format."}]},class:"aiida_bands_inspect.calculations.align:AlignCalculation"},"bands_inspect.difference":{description:["Calculation class for the ``bands-inspect difference`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.nodes.data.array.bands.BandsData","        First band structure to compare.","    bands2 : aiida.orm.nodes.data.array.bands.BandsData","        Second band structure to compare."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be compared"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be compared"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"difference",required:!0,valid_types:"Float",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder does not contain the difference output file."}]},class:"aiida_bands_inspect.calculations.difference:DifferenceCalculation"},"bands_inspect.plot":{description:["Calculation class for the ``bands_inspect plot`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.nodes.data.array.bands.BandsData","        First band structure to plot.","    bands2 : aiida.orm.nodes.data.array.bands.BandsData","        Second band structure to plot."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be plotted"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be plotted"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"plot",required:!0,valid_types:"SinglefileData",info:"The created band-structure comparison plot."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder does not contain the plot output file."}]},class:"aiida_bands_inspect.calculations.plot:PlotCalculation"}},"aiida.parsers":{"bands_inspect.bands":"aiida_bands_inspect.parsers.bands:BandsParser","bands_inspect.difference":"aiida_bands_inspect.parsers.difference:DifferenceParser","bands_inspect.align":"aiida_bands_inspect.parsers.align:AlignParser","bands_inspect.plot":"aiida_bands_inspect.parsers.plot:PlotParser"}},commits_count:0,development_status:"beta",errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:4}],pip_install_cmd:"pip install aiida-bands-inspect",is_installable:"True"},"aiida-bigdft":{code_home:"https://github.com/BigDFT-group/aiida-bigdft-plugin",development_status:"beta",entry_point_prefix:"bigdft",pip_url:"aiida-bigdft",plugin_info:"https://raw.github.com/BigDFT-group/aiida-bigdft-plugin/master/setup.json",name:"aiida-bigdft",package_name:"aiida_bigdft",hosted_on:"github.com",metadata:{release_date:"2021-03-16",description:"Aiida plugin for BigDFT code",author:"The BigDFT Team",author_email:"bigdft-developers@lists.launchpad.net",license:"MIT",home_page:"https://github.com/BigDFT-group/aiida-bigdft-plugin",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.6"},aiida_version:">=1.1.1,<2.0.0",entry_points:{"aiida.calculations":{bigdft:{description:["AiiDA calculation plugin wrapping the BigDFT python interface."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"BigDFTParameters",info:"Command line parameters for BigDFT"},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:100,message:"Calculation did not produce all expected output files."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_bigdft.calculations.bigdft:BigDFTCalculation"},"bigdft.postscript":{description:["AiiDA calculation to add post treatments to a computation workcahin.","    post treatment scripts are to be registered as codes in aiida.","    They are python scripts accepting one argument : a remotefolder where data is stored","    Output files are not specified and can be added to the extra_retrieved_files list"],spec:{inputs:[{name:"bigdft_data_folder",required:!0,valid_types:"RemoteData",info:"Folder to the BigDFT data folder"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"retrieved_files",required:!1,valid_types:"List",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"Script execution failed"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_bigdft.calculations.postscript:ScriptCalculation"}},"aiida.cmdline.data":{bigdft:"aiida_bigdft.cli:data_cli"},"aiida.data":{bigdft:"aiida_bigdft.data:BigDFTParameters",bigdft_logfile:"aiida_bigdft.data:BigDFTLogfile"},"aiida.parsers":{bigdft:"aiida_bigdft.parsers:BigDFTParser"},"aiida.workflows":{bigdft:{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"BigDFTParameters",info:"Command line parameters for BigDFT"},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"run_opts",required:!1,valid_types:"Dict",info:"metadata"},{name:"show_warnings",required:!1,valid_types:"Bool",info:"turn the warnings on/off."},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"BigDFT input error"},{status:200,message:"BigDFT runtime error"},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_bigdft.workflows.base:BigDFTBaseWorkChain"},"bigdft.relax":{description:["Structure relaxation workchain."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"relax",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"BigDFTParameters",info:"param dictionary"},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"run_opts",required:!1,valid_types:"Dict",info:"metadata"},{name:"show_warnings",required:!1,valid_types:"Bool",info:"turn the warnings on/off."},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"forces",required:!1,valid_types:"ArrayData",info:""},{name:"relaxed_structure",required:!1,valid_types:"StructureData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"total_energy",required:!1,valid_types:"Float",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess failed for relaxation"}]},class:"aiida_bigdft.workflows.relax:BigDFTRelaxWorkChain"}}},commits_count:0,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:2},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-bigdft",is_installable:"True"},"aiida-castep":{code_home:"https://gitlab.com/bz1/aiida-castep",development_status:"stable",documentation_url:"https://aiida-castep.readthedocs.io/",entry_point_prefix:"castep",pip_url:"aiida-castep",plugin_info:"https://gitlab.com/bz1/aiida-castep/raw/master/setup.json",name:"aiida-castep",package_name:"aiida_castep",hosted_on:"gitlab.com",metadata:{release_date:"2022-05-26",description:"AiiDA plugin for CASTEP",author:"Bonan Zhu",author_email:"zhubonan@outlook.com",license:"MIT License",home_page:"https://github.com/zhubonan/aiida-castep",classifiers:["Framework :: AiiDA","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.1"},aiida_version:">=2.0,<3.0",entry_points:{"aiida.calculations":{"castep.castep":{description:["Class representing a generic CASTEP calculation -","    This class should work for all types of calculations."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"A node that defines the input parameters"},{name:"pseudos",required:!0,valid_types:"",info:"Use nodes for the pseudopotentails of one ofthe element in the structure. You should pass aa dictionary specifying the pseudpotential node foreach kind such as {O: <PsudoNode>}"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bs_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: bandstructure"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"elnes_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: elnes"},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Use a node defining the kpoints for the calculation"},{name:"magres_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: magres"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"optics_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: optics"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"phonon_fine_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"phonon_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"A node for additional settings"},{name:"spectral_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: spectral"},{name:"supercell_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Parsed results in a dictionary format."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation terminated gracefully, end found"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"SCF Cycles failed to reach convergence"},{status:103,message:"Stopped execuation due to detection of 'stop ' keyword in param file."},{status:104,message:"CASTEP generate error files. Check them for details"},{status:105,message:"Cannot find the end of calculation"},{status:106,message:"No output .castep files found"},{status:107,message:"Calculation self-terminated due to time limit"},{status:108,message:"No retrieve folder is found"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"UNKOWN ERROR"},{status:501,message:"At least one kpoints/spin has no empty bands - please rerun with increased nextra_bands."}]},class:"aiida_castep.calculations.castep:CastepCalculation"},"castep.ts":{description:["CASTEP calculation for transition state search. Use an extra input product structure."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"A node that defines the input parameters"},{name:"product_structure",required:!0,valid_types:"StructureData",info:"Product structure for transition state search."},{name:"pseudos",required:!0,valid_types:"",info:"Use nodes for the pseudopotentails of one ofthe element in the structure. You should pass aa dictionary specifying the pseudpotential node foreach kind such as {O: <PsudoNode>}"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bs_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: bandstructure"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"elnes_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: elnes"},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Use a node defining the kpoints for the calculation"},{name:"magres_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: magres"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"optics_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: optics"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"phonon_fine_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"phonon_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"A node for additional settings"},{name:"spectral_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: spectral"},{name:"supercell_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Parsed results in a dictionary format."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation terminated gracefully, end found"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"SCF Cycles failed to reach convergence"},{status:103,message:"Stopped execuation due to detection of 'stop ' keyword in param file."},{status:104,message:"CASTEP generate error files. Check them for details"},{status:105,message:"Cannot find the end of calculation"},{status:106,message:"No output .castep files found"},{status:107,message:"Calculation self-terminated due to time limit"},{status:108,message:"No retrieve folder is found"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"UNKOWN ERROR"},{status:501,message:"At least one kpoints/spin has no empty bands - please rerun with increased nextra_bands."}]},class:"aiida_castep.calculations.castep:CastepTSCalculation"}},"aiida.cmdline.data":{"castep-helper":"aiida_castep.cmdline.helper_cmd:helper_cmd","castep-pseudos":"aiida_castep.cmdline.otfg_cmd:pseudos_cmd"},"aiida.data":{"castep.otfgdata":"aiida_castep.data.otfg:OTFGData","castep.uspdata":"aiida_castep.data.usp:UspData"},"aiida.groups":{"castep.otfg":"aiida_castep.data.otfg:OTFGGroup"},"aiida.parsers":{"castep.castep":"aiida_castep.parsers.castep:CastepParser"},"aiida.tests":{"castep.calculation":"aiida_castep.tests.dbtests.dbtestcalculation"},"aiida.tools.calculations":{"castep.castep":"aiida_castep.calculations.tools:CastepCalcTools"},"aiida.workflows":{"castep.altrelax":{description:["A relaxation workflow that alternates between fixed cell and unfixed cell","    This is meidate the problem in CASTEP where if the cell is partially constraints","    the convergence would be very slow.","","    To overcome this problem, the structure should be relaxed with cell constraints","    then restart with fixed cell and repeat.","","    Following fields can be used in ``relax_options``","","    :var_cell_iter_max: Maximum iterations in variable cell relaxation, default to 10","","    :fix_cell_iter_max: Maximum iterations in fixed cell relaxation, default to 20"],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:""},{name:"calc",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for relaxation."},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations at the end of the workchain. The default is not performing any cleaning."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax_options",required:!1,valid_types:"Dict, NoneType",info:"Options for relaxation."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess lauched has failed in the relax stage"},{status:102,message:"Geometry optimisation is not converged but the maximum iteration is exceeded."},{status:201,message:"NO cell_constraints find in the input"}]},class:"aiida_castep.workflows.relax:CastepAlterRelaxWorkChain"},"castep.bands":{description:["Workchain for running bands calculation.","","    This workchain does the following:","","    1. Relax the structure if requested (eg. inputs passed to the relax namespace).","    2. Optionally: Do a SCF singlepoint calculation","    3. Do combined SCF + non-SCF calculation for bands and dos.","","    Inputs must be passed for the SCF calculation (dispatched to bands and DOS),","    others are optional.","","    Input for bands and dos calculations are optional. However, if they are needed, the full list of inputs must","    be passed. For the `parameters` node, one may choose to only specify those fields that need to be updated."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:"Inputs for SCF workchain, mandatory. Used as template for bands/dos if not supplied separately"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bands",required:!1,valid_types:"Data",info:"Inputs for bands calculation, if needed"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Explicit kpoints for the bands"},{name:"bands_kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"Spacing for band distances, used by seekpath"},{name:"clean_children_workdir",required:!1,valid_types:"Str, NoneType",info:"What part of the called children to clean"},{name:"dos",required:!1,valid_types:"Data",info:"Inputs for DOS calculation, if needed"},{name:"dos_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Kpoints for running DOS calculations"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"only_dos",required:!1,valid_types:"",info:"Flag for running only DOS calculations"},{name:"options",required:!1,valid_types:"",info:"Options for this workchain. Supported keywords: dos_smearing, dos_npoints."},{name:"relax",required:!1,valid_types:"Data",info:"Inputs for Relaxation workchain, if needed"},{name:"run_separate_scf",required:!1,valid_types:"",info:"Flag for running a separate SCF calculation, default to False"}],outputs:[{name:"band_structure",required:!0,valid_types:"",info:"Computed band structure with labels"},{name:"dos_bands",required:!1,valid_types:"",info:"Bands from the DOS calculation"},{name:"primitive_structure",required:!1,valid_types:"",info:"Primitive structure used for band structure calculations"},{name:"seekpath_parameters",required:!1,valid_types:"",info:"Parameters used by seekpath"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:501,message:"Relaxation workchain failed"},{status:502,message:"SCF workchain failed"},{status:503,message:"Band structure workchain failed"},{status:504,message:"DOS workchain failed"}]},class:"aiida_castep.workflows.bands:CastepBandsWorkChain"},"castep.base":{description:["A basic workchain for generic CASTEP calculations.","    We try to handle erros such as walltime exceeded or SCF not converged"],spec:{inputs:[{name:"calc",required:!0,valid_types:"Data",info:""},{name:"calc_options",required:!1,valid_types:"Dict, NoneType",info:"Options to be passed to calculations's metadata.options"},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations or not, the default is not clean."},{name:"continuation_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"ensure_gamma_centering",required:!1,valid_types:"Bool, NoneType",info:"Ensure the kpoint grid is gamma centred."},{name:"kpoints_spacing",required:!1,valid_types:"Float, NoneType",info:"Kpoint spacing"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of restarts"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Options specific to the workchain.Avaliable options: queue_wallclock_limit, use_castep_bin"},{name:"pseudos_family",required:!1,valid_types:"Str, NoneType",info:"Pseudopotential family to be used"},{name:"reuse_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"The maximum number of iterations has been exceeded"},{status:201,message:"The maximum length of the wallclocks has been exceeded"},{status:301,message:"CASTEP generated error files and is not recoverable"},{status:302,message:"Cannot reach SCF convergence despite restart efforts"},{status:400,message:"The stop flag has been put in the .param file to request termination of the calculation."},{status:900,message:"Input validate is failed"},{status:901,message:"Completed one iteration but found not calculation returned"},{status:1e3,message:"Error is not known"}]},class:"aiida_castep.workflows.base:CastepBaseWorkChain"},"castep.relax":{description:["WorkChain to relax structures.","    Restart the relaxation calculation until the structure is fully relaxed.","    Each CASTEP relaxation may finish without error with not fully relaxed structure","    if the number of iteration is exceeded (*geom_max_iter*).","    This workchain try to restart such calculations (wrapped in CastepBaseWorkChain)","    until the structure is fully relaxed","","    ``relax_options`` is a Dict of the options avaliable fields are:","","    - restart_mode: mode of restart, choose from ``reuse`` (default), ``structure``,","      ``continuation``.","    - bypass: Bypass relaxation control - e.g. no checking of the convergence.","      Can be used for doing singlepoint calculation."],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:""},{name:"calc",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for relaxation."},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations at the end of the workchain. The default is not performing any cleaning."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax_options",required:!1,valid_types:"Dict, NoneType",info:"Options for relaxation."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess lauched has failed in the relax stage"},{status:102,message:"Geometry optimisation is not converged but the maximum iteration is exceeded."}]},class:"aiida_castep.workflows.relax:CastepRelaxWorkChain"}},console_scripts:{"castep.mock":"aiida_castep.cmdline.mock_castep:mock_castep"}},commits_count:4,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:4},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Groups, Tests, ...)",count:5}],pip_install_cmd:"pip install aiida-castep",is_installable:"True"},"aiida-catmap":{code_home:"https://github.com/sudarshanv01/aiida-catmap",entry_point_prefix:"catmap",name:"aiida-catmap",package_name:"aiida_catmap",hosted_on:"github.com",metadata:{author:"Sudarshan Vijay",author_email:"vijays@fysik.dtu.dk",version:"0.2.0a0",description:"AiiDA package that interfaces with Kinetic modelling code CatMAP",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.calculations":{catmap:"aiida_catmap.calculations.catmap:CatMAPCalculation"},"aiida.parsers":{catmap:"aiida_catmap.parsers.catmap:CatMAPParser"}},commits_count:0,development_status:"planning",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"See source code repository."},"aiida-catmat":{code_home:"https://github.com/pzarabadip/aiida-catmat",entry_point_prefix:"catmat",development_status:"beta",documentation_url:"https://aiida-catmat.readthedocs.io/",pip_url:"aiida-catmat",name:"aiida-catmat",package_name:"aiida_catmat",hosted_on:"github.com",metadata:{release_date:"2022-07-21",description:"Collection of AiiDA WorkChains Developed in Morgan Group",author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",license:"MIT License",home_page:"https://github.com/pzarabadip/aiida-catmat",classifiers:["Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.0.0b0"},aiida_version:null,entry_points:{"aiida.parsers":{vasp_base_parser:"aiida_catmat.parsers:VaspBaseParser"},"aiida.workflows":{"vasp.base":"aiida_catmat.workchains:VaspBaseWorkChain","catmat.vasp_multistage":"aiida_catmat.workchains:VaspMultiStageWorkChain","catmat.vasp_converge":"aiida_catmat.workchains:VaspConvergeWorkChain","catmat.vasp_catmat":"aiida_catmat.workchains:VaspCatMatWorkChain","catmat.vasp_multistage_ddec":"aiida_catmat.workchains:VaspMultiStageDdecWorkChain"}},commits_count:0,errors:[`Failed to install plugin aiida-catmat</br><pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'vasp_base_parser' does not start with prefix 'catmat.'","Entry point 'vasp.base' does not start with prefix 'catmat.'"],summaryinfo:[{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:5}],pip_install_cmd:"pip install --pre aiida-catmat",is_installable:"False"},"aiida-ce":{code_home:"https://github.com/unkcpz/aiida-ce",development_status:"beta",entry_point_prefix:"ce",pip_url:"git+https://github.com/unkcpz/aiida-ce",name:"aiida-ce",package_name:"aiida_ce",hosted_on:"github.com",metadata:{author:"unkcpz",author_email:"morty.yu@yahoo.com",version:"0.1.0a0",description:"AiiDA plugin for running cluster expansion using icet.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.0.0,<2.0.0",entry_points:{"aiida.data":{ce:"aiida_ce.data:DiffParameters","ce.structures":"aiida_ce.data.structure_set:StructureSet","ce.cluster":"aiida_ce.data.cluster:ClusterSpaceData"},"aiida.calculations":{"ce.genenum":"aiida_ce.calculations.genenum:EnumCalculation","ce.gensqs":"aiida_ce.calculations.gensqs:SqsCalculation","ce.train":"aiida_ce.calculations.train:TrainCalculation"},"aiida.parsers":{"ce.genenum":"aiida_ce.parsers.genenum:EnumParser","ce.gensqs":"aiida_ce.parsers.gensqs:SqsParser","ce.train":"aiida_ce.parsers.train:TrainParser"},"aiida.cmdline.data":{ce:"aiida_ce.cli:data_cli"}},commits_count:0,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:3},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/unkcpz/aiida-ce",is_installable:"True"},"aiida-champ":{code_home:"https://github.com/TREX-CoE/aiida-champ",development_status:"beta",documentation_url:"http://aiida-champ.readthedocs.io/",entry_point_prefix:"champ",pip_url:"aiida-champ",name:"aiida-champ",package_name:"aiida_champ",hosted_on:"github.com",metadata:{release_date:"2021-12-27",description:"AiiDA plugin that wraps the vmc executable of CHAMP code for computing the total energy and much more stuff.",author:"Ravindra Shinde",author_email:"r.l.shinde@utwente.nl",license:"MIT",home_page:"https://github.com/neelravi/aiida-champ",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"1.2.6"},aiida_version:null,entry_points:{"aiida.data":{CHAMP:"aiida_champ.data:CHAMPParameters"},"aiida.calculations":{CHAMP:{description:["AiiDA calculation plugin wrapping the CHAMP's vmc executable.","","    aiida-champ can be used to manage the workflow of a vmc/dmc calculation of the CHAMP code.","","    Author :: Ravindra Shinde","    Email  :: r.l.shinde@utwente.nl"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"determinants",required:!0,valid_types:"SinglefileData",info:"Input determinants file"},{name:"filemain",required:!0,valid_types:"SinglefileData",info:"Input File"},{name:"molecule",required:!0,valid_types:"SinglefileData",info:"Molecule structure File"},{name:"ecp1",required:!1,valid_types:"SinglefileData",info:"Input ECP file for atom type 1"},{name:"ecp2",required:!1,valid_types:"SinglefileData",info:"Input ECP file for atom type 2"},{name:"jastrow",required:!1,valid_types:"SinglefileData",info:"Input jastrow file"},{name:"jastrowder",required:!1,valid_types:"SinglefileData",info:"Input jastrowder file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"numericalbasis1",required:!1,valid_types:"SinglefileData",info:"Input numerical basis file atom 1"},{name:"numericalbasis2",required:!1,valid_types:"SinglefileData",info:"Input numerical basis file atom 2"},{name:"numericalbasisinfo",required:!1,valid_types:"SinglefileData",info:"Input numerical basis information file"},{name:"orbitals",required:!1,valid_types:"SinglefileData",info:"Input orbitals file"},{name:"symmetry",required:!1,valid_types:"SinglefileData",info:"Input symmetry file"},{name:"trexio",required:!1,valid_types:"SinglefileData",info:"Input trexio hdf5 file"}],outputs:[{name:"Output",required:!0,valid_types:"SinglefileData",info:"Output file of the VMC/DMC calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"Energy",required:!1,valid_types:"Float",info:"Output total energy of the VMC/DMC calculation"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_champ.calculations:CHAMPCalculation"}},"aiida.parsers":{CHAMP:"aiida_champ.parsers:CHAMPParser"},"aiida.cmdline.data":{CHAMP:"aiida_champ.cli:data_cli"}},commits_count:0,errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-champ",is_installable:"True"},"aiida-codtools":{code_home:"https://github.com/aiidateam/aiida-codtools",documentation_url:"https://aiida-codtools.readthedocs.io/",entry_point_prefix:"codtools",pip_url:"aiida-codtools",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-codtools/master/setup.json",name:"aiida-codtools",package_name:"aiida_codtools",hosted_on:"github.com",metadata:{release_date:"2023-02-02",description:"The Official AiiDA plugin for the cod-tools package.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"3.1.0"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.calculations":{"codtools.cif_base":{description:["Generic `CalcJob` implementation that can easily be extended to work with any of the `cod-tools` scripts."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_base:CifBaseCalculation"},"codtools.cif_cell_contents":{description:["CalcJob plugin for the `cif_cell_contents` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"formulae",required:!0,valid_types:"Dict",info:"A dictionary of formulae present in the CIF."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cell_contents:CifCellContentsCalculation"},"codtools.cif_cod_check":{description:["CalcJob plugin for the `cif_cod_check` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"messages",required:!0,valid_types:"Dict",info:"Warning and error messages returned by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cod_check:CifCodCheckCalculation"},"codtools.cif_cod_deposit":{description:["CalcJob plugin for the `cif_cod_deposit` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:300,message:"The deposition failed for unknown reasons."},{status:310,message:"The deposition failed because the input was invalid."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."},{status:410,message:"The deposition failed because one or more CIFs already exist in the COD."},{status:420,message:"The structure is unchanged and so deposition is unnecessary."}]},class:"aiida_codtools.calculations.cif_cod_deposit:CifCodDepositCalculation"},"codtools.cif_cod_numbers":{description:["CalcJob plugin for the `cif_cod_numbers` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"numbers",required:!0,valid_types:"Dict",info:"Mapping of COD IDs found with their formula and count."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cod_numbers:CifCodNumbersCalculation"},"codtools.cif_filter":{description:["CalcJob plugin for the `cif_filter` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_filter:CifFilterCalculation"},"codtools.cif_select":{description:["CalcJob plugin for the `cif_select` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_select:CifSelectCalculation"},"codtools.cif_split_primitive":{description:["CalcJob plugin for the `cif_split_primitive` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cifs",required:!0,valid_types:"CifData",info:"The CIFs produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_split_primitive:CifSplitPrimitiveCalculation"},"codtools.primitive_structure_from_cif":{description:["Attempt to parse the given `CifData` and create a `StructureData` from it.","","    First the raw CIF file is parsed with the given `parse_engine`. The resulting `StructureData` is then passed through","    SeeKpath to try and get the primitive cell. If that is successful, important structural parameters as determined by","    SeeKpath will be set as extras on the structure node which is then returned as output.","","    :param cif: the `CifData` node","    :param parse_engine: the parsing engine, supported libraries 'ase' and 'pymatgen'","    :param symprec: a `Float` node with symmetry precision for determining primitive cell in SeeKpath","    :param site_tolerance: a `Float` node with the fractional coordinate distance tolerance for finding overlapping","        sites. This will only be used if the parse_engine is pymatgen","    :return: the primitive `StructureData` as determined by SeeKpath"],spec:{inputs:[{name:"cif",required:!0,valid_types:"Data",info:"the `CifData` node"},{name:"parse_engine",required:!0,valid_types:"Data",info:"the parsing engine, supported libraries 'ase' and 'pymatgen'"},{name:"site_tolerance",required:!0,valid_types:"Data",info:"a `Float` node with the fractional coordinate distance tolerance for finding overlapping\nsites. This will only be used if the parse_engine is pymatgen"},{name:"symprec",required:!0,valid_types:"Data",info:"a `Float` node with symmetry precision for determining primitive cell in SeeKpath"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_codtools.calculations.functions.primitive_structure_from_cif:primitive_structure_from_cif"}},"aiida.parsers":{"codtools.cif_base":"aiida_codtools.parsers.cif_base:CifBaseParser","codtools.cif_cell_contents":"aiida_codtools.parsers.cif_cell_contents:CifCellContentsParser","codtools.cif_cod_check":"aiida_codtools.parsers.cif_cod_check:CifCodCheckParser","codtools.cif_cod_deposit":"aiida_codtools.parsers.cif_cod_deposit:CifCodDepositParser","codtools.cif_cod_numbers":"aiida_codtools.parsers.cif_cod_numbers:CifCodNumbersParser","codtools.cif_split_primitive":"aiida_codtools.parsers.cif_split_primitive:CifSplitPrimitiveParser"},"aiida.workflows":{"codtools.cif_clean":{description:["WorkChain to clean a `CifData` node using the `cif_filter` and `cif_select` scripts of `cod-tools`.","","    It will first run `cif_filter` to correct syntax errors, followed by `cif_select` which will canonicalize the tags.","    If a group is passed for the `group_structure` input, the atomic structure library defined by the `engine` input","    will be used to parse the final cleaned `CifData` to construct a `StructureData` object, which will then be passed","    to the `SeeKpath` library to analyze it and return the primitive structure"],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CifData node that is to be cleaned."},{name:"cif_filter",required:!0,valid_types:"Data",info:""},{name:"cif_select",required:!0,valid_types:"Data",info:""},{name:"group_cif",required:!1,valid_types:"Group, NoneType",info:"An optional Group to which the final cleaned CifData node will be added."},{name:"group_structure",required:!1,valid_types:"Group, NoneType",info:"An optional Group to which the final reduced StructureData node will be added."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parse_engine",required:!1,valid_types:"Str",info:"The atomic structure engine to parse the cif and create the structure."},{name:"site_tolerance",required:!1,valid_types:"Float",info:"The fractional coordinate distance tolerance for finding overlapping sites (pymatgen only)."},{name:"symprec",required:!1,valid_types:"Float",info:"The symmetry precision used by SeeKpath for crystal symmetry refinement."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The cleaned CifData node."},{name:"structure",required:!1,valid_types:"StructureData",info:"The primitive cell structure created with SeeKpath from the cleaned CifData."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The CifFilterCalculation step failed."},{status:402,message:"The CifSelectCalculation step failed."},{status:410,message:"The cleaned CifData contains sites with unknown species."},{status:411,message:"The cleaned CifData defines no atomic sites."},{status:412,message:"The cleaned CifData defines sites with attached hydrogens with incomplete positional data."},{status:413,message:"The cleaned CifData defines sites with invalid atomic occupancies."},{status:414,message:"Failed to parse a StructureData from the cleaned CifData."},{status:420,message:"SeeKpath failed to determine the primitive structure."},{status:421,message:"SeeKpath detected inconsistent symmetry operations."}]},class:"aiida_codtools.workflows.cif_clean:CifCleanWorkChain"}},console_scripts:{"aiida-codtools":"aiida_codtools.cli:cmd_root"}},commits_count:4,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:9},{colorclass:"brown",text:"Parsers",count:6},{colorclass:"green",text:"Workflows",count:1},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-codtools",is_installable:"True"},"aiida-core":{code_home:"https://github.com/aiidateam/aiida-core",development_status:"stable",documentation_url:"https://aiida-core.readthedocs.io/",entry_point_prefix:"",package_name:"aiida",pip_url:"aiida-core",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-core/master/setup.json",name:"aiida-core",hosted_on:"github.com",metadata:{release_date:"2023-06-23",description:"AiiDA is a workflow manager for computational science with a strong focus on provenance, performance and extensibility.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"2.4.0"},aiida_version:"==2.4.0",entry_points:{"aiida.calculations":{"core.arithmetic.add":{description:["`CalcJob` implementation to add two numbers using bash for testing and demonstration purposes."],spec:{inputs:[{name:"x",required:!0,valid_types:"Int, Float",info:"The left operand."},{name:"y",required:!0,valid_types:"Int, Float",info:"The right operand."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"sum",required:!0,valid_types:"Int, Float",info:"The sum of the left and right operand."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:310,message:"The output file could not be read."},{status:320,message:"The output file contains invalid output."},{status:410,message:"The sum of the operands is a negative number."}]},class:"aiida.calculations.arithmetic.add:ArithmeticAddCalculation"},"core.templatereplacer":{description:["Simple stub of a plugin that can be used to replace some text in a given template.","    Can be used for many different codes, or as a starting point to develop a new plugin.","","    This simple plugin takes two node inputs, both of type Dict, with the labels","    'parameters' and 'template'","","    You can also add other SinglefileData nodes as input, that will be copied according to","    what is written in 'template' (see below).","","    * parameters: a set of parameters that will be used for substitution.","","    * template: can contain the following parameters:","","        * input_file_template: a string with substitutions to be managed with the format()","          function of python, i.e. if you want to substitute a variable called 'varname', you write","          {varname} in the text. See http://www.python.org/dev/peps/pep-3101/ for more","          details. The replaced file will be the input file.","","        * input_file_name: a string with the file name for the input. If it is not provided, no","          file will be created.","","        * output_file_name: a string with the file name for the output. If it is not provided, no","          redirection will be done and the output will go in the scheduler output file.","","        * cmdline_params: a list of strings, to be passed as command line parameters.","          Each one is substituted with the same rule of input_file_template. Optional","","        * input_through_stdin: if True, the input file name is passed via stdin. Default is False if missing.","","        * files_to_copy: if defined, a list of tuple pairs, with format ('link_name', 'dest_rel_path');","            for each tuple, an input link to this calculation is looked for, with link labeled 'link_label',","            and with file type 'Singlefile', and the content is copied to a remote file named 'dest_rel_path'","            Errors are raised in the input links are non-existent, or of the wrong type, or if there are","            unused input files.","","        * retrieve_temporary_files: a list of relative filepaths, that if defined, will be retrieved and","            temporarily stored in an unstored FolderData node that will be available during the","            Parser.parser_with_retrieved call under the key specified by the Parser.retrieved_temporary_folder key"],spec:{inputs:[{name:"template",required:!0,valid_types:"Dict",info:"A template for the input file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"files",required:!1,valid_types:"RemoteData, SinglefileData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters used to replace placeholders in the template."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The temporary retrieved folder data node could not be accessed."},{status:305,message:"The `template` input node did not specify the key `output_file_name`."},{status:310,message:"The output file could not be read from the retrieved folder."},{status:311,message:"A temporary retrieved file could not be read from the temporary retrieved folder."},{status:320,message:"The output file contains invalid output."}]},class:"aiida.calculations.templatereplacer:TemplatereplacerCalculation"},"core.transfer":{description:["Utility to copy files from different FolderData and RemoteData nodes into a single place.","","    The final destination for these files can be either the local repository (by creating a","    new FolderData node to store them) or in the remote computer (by leaving the files in a","    new remote folder saved in a RemoteData node).","","    Only files from the local computer and from remote folders in the same external computer","    can be moved at the same time with a single instance of this CalcJob.","","    The user needs to provide three inputs:","","        * ``instructions``: a dict node specifying which files to copy from which nodes.","        * ``source_nodes``: a dict of nodes, each with a unique identifier label as its key.","        * ``metadata.computer``: the computer that contains the remote files and will contain","          the final RemoteData node.","","    The ``instructions`` dict must have the ``retrieve_files`` flag. The CalcJob will create a","    new folder in the remote machine (``RemoteData``) and put all the files there and will either:","","        (1) leave them there (``retrieve_files = False``) or ...","        (2) retrieve all the files and store them locally in a ``FolderData``  (``retrieve_files = True``)","","    The `instructions` dict must also contain at least one list with specifications of which files","    to copy and from where. All these lists take tuples of 3 that have the following format:","","    .. code-block:: python","","        ( source_node_key, path_to_file_in_source, path_to_file_in_target)","","    where the ``source_node_key`` has to be the respective one used when providing the node in the","    ``source_nodes`` input nodes dictionary.","","","    The two main lists to include are ``local_files`` (for files to be taken from FolderData nodes)","    and ``remote_files`` (for files to be taken from RemoteData nodes). Alternatively, files inside","    of RemoteData nodes can instead be put in the ``symlink_files`` list: the only difference is that","    files from the first list will be fully copied in the target RemoteData folder, whereas for the","    files in second list only a symlink to the original file will be created there. This will only","    affect the content of the final RemoteData target folder, but in both cases the full file will","    be copied back in the local target FolderData (if ``retrieve_files = True``)."],spec:{inputs:[{name:"instructions",required:!0,valid_types:"Dict",info:"A dictionary containing the `retrieve_files` flag and at least one of the file lists:`local_files`, `remote_files` and/or `symlink_files`."},{name:"source_nodes",required:!0,valid_types:"FolderData, RemoteData",info:"All the nodes that contain files referenced in the instructions."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida.calculations.transfer:TransferCalculation"}},"aiida.calculations.importers":{"core.arithmetic.add":"aiida.calculations.importers.arithmetic.add:ArithmeticAddCalculationImporter"},"aiida.calculations.monitors":{"core.always_kill":"aiida.calculations.monitors.base:always_kill"},"aiida.cmdline.computer.configure":{"core.local":"aiida.transports.plugins.local:CONFIGURE_LOCAL_CMD","core.ssh":"aiida.transports.plugins.ssh:CONFIGURE_SSH_CMD"},"aiida.cmdline.data":{"core.array":"aiida.cmdline.commands.cmd_data.cmd_array:array","core.bands":"aiida.cmdline.commands.cmd_data.cmd_bands:bands","core.cif":"aiida.cmdline.commands.cmd_data.cmd_cif:cif","core.dict":"aiida.cmdline.commands.cmd_data.cmd_dict:dictionary","core.remote":"aiida.cmdline.commands.cmd_data.cmd_remote:remote","core.singlefile":"aiida.cmdline.commands.cmd_data.cmd_singlefile:singlefile","core.structure":"aiida.cmdline.commands.cmd_data.cmd_structure:structure","core.trajectory":"aiida.cmdline.commands.cmd_data.cmd_trajectory:trajectory","core.upf":"aiida.cmdline.commands.cmd_data.cmd_upf:upf"},"aiida.cmdline.data.structure.import":{},"aiida.data":{"core.array":"aiida.orm.nodes.data.array.array:ArrayData","core.array.bands":"aiida.orm.nodes.data.array.bands:BandsData","core.array.kpoints":"aiida.orm.nodes.data.array.kpoints:KpointsData","core.array.projection":"aiida.orm.nodes.data.array.projection:ProjectionData","core.array.trajectory":"aiida.orm.nodes.data.array.trajectory:TrajectoryData","core.array.xy":"aiida.orm.nodes.data.array.xy:XyData","core.base":"aiida.orm.nodes.data:BaseType","core.bool":"aiida.orm.nodes.data.bool:Bool","core.cif":"aiida.orm.nodes.data.cif:CifData","core.code":"aiida.orm.nodes.data.code.legacy:Code","core.code.containerized":"aiida.orm.nodes.data.code.containerized:ContainerizedCode","core.code.installed":"aiida.orm.nodes.data.code.installed:InstalledCode","core.code.portable":"aiida.orm.nodes.data.code.portable:PortableCode","core.dict":"aiida.orm.nodes.data.dict:Dict","core.enum":"aiida.orm.nodes.data.enum:EnumData","core.float":"aiida.orm.nodes.data.float:Float","core.folder":"aiida.orm.nodes.data.folder:FolderData","core.int":"aiida.orm.nodes.data.int:Int","core.jsonable":"aiida.orm.nodes.data.jsonable:JsonableData","core.list":"aiida.orm.nodes.data.list:List","core.numeric":"aiida.orm.nodes.data.numeric:NumericType","core.orbital":"aiida.orm.nodes.data.orbital:OrbitalData","core.remote":"aiida.orm.nodes.data.remote.base:RemoteData","core.remote.stash":"aiida.orm.nodes.data.remote.stash.base:RemoteStashData","core.remote.stash.folder":"aiida.orm.nodes.data.remote.stash.folder:RemoteStashFolderData","core.singlefile":"aiida.orm.nodes.data.singlefile:SinglefileData","core.str":"aiida.orm.nodes.data.str:Str","core.structure":"aiida.orm.nodes.data.structure:StructureData","core.upf":"aiida.orm.nodes.data.upf:UpfData"},"aiida.groups":{core:"aiida.orm.groups:Group","core.auto":"aiida.orm.groups:AutoGroup","core.import":"aiida.orm.groups:ImportGroup","core.upf":"aiida.orm.groups:UpfFamily"},"aiida.node":{data:"aiida.orm.nodes.data.data:Data",process:"aiida.orm.nodes.process.process:ProcessNode","process.calculation":"aiida.orm.nodes.process.calculation.calculation:CalculationNode","process.calculation.calcfunction":"aiida.orm.nodes.process.calculation.calcfunction:CalcFunctionNode","process.calculation.calcjob":"aiida.orm.nodes.process.calculation.calcjob:CalcJobNode","process.workflow":"aiida.orm.nodes.process.workflow.workflow:WorkflowNode","process.workflow.workchain":"aiida.orm.nodes.process.workflow.workchain:WorkChainNode","process.workflow.workfunction":"aiida.orm.nodes.process.workflow.workfunction:WorkFunctionNode"},"aiida.parsers":{"core.arithmetic.add":"aiida.parsers.plugins.arithmetic.add:ArithmeticAddParser","core.templatereplacer":"aiida.parsers.plugins.templatereplacer.parser:TemplatereplacerParser"},"aiida.schedulers":{"core.direct":"aiida.schedulers.plugins.direct:DirectScheduler","core.lsf":"aiida.schedulers.plugins.lsf:LsfScheduler","core.pbspro":"aiida.schedulers.plugins.pbspro:PbsproScheduler","core.sge":"aiida.schedulers.plugins.sge:SgeScheduler","core.slurm":"aiida.schedulers.plugins.slurm:SlurmScheduler","core.torque":"aiida.schedulers.plugins.torque:TorqueScheduler"},"aiida.storage":{"core.psql_dos":"aiida.storage.psql_dos.backend:PsqlDosBackend","core.sqlite_temp":"aiida.storage.sqlite_temp.backend:SqliteTempBackend","core.sqlite_zip":"aiida.storage.sqlite_zip.backend:SqliteZipBackend"},"aiida.tools.calculations":{},"aiida.tools.data.orbitals":{"core.orbital":"aiida.tools.data.orbital.orbital:Orbital","core.realhydrogen":"aiida.tools.data.orbital.realhydrogen:RealhydrogenOrbital"},"aiida.tools.dbexporters":{},"aiida.tools.dbimporters":{"core.cod":"aiida.tools.dbimporters.plugins.cod:CodDbImporter","core.icsd":"aiida.tools.dbimporters.plugins.icsd:IcsdDbImporter","core.materialsproject":"aiida.tools.dbimporters.plugins.materialsproject:MaterialsProjectImporter","core.mpds":"aiida.tools.dbimporters.plugins.mpds:MpdsDbImporter","core.mpod":"aiida.tools.dbimporters.plugins.mpod:MpodDbImporter","core.nninc":"aiida.tools.dbimporters.plugins.nninc:NnincDbImporter","core.oqmd":"aiida.tools.dbimporters.plugins.oqmd:OqmdDbImporter","core.pcod":"aiida.tools.dbimporters.plugins.pcod:PcodDbImporter","core.tcod":"aiida.tools.dbimporters.plugins.tcod:TcodDbImporter"},"aiida.transports":{"core.local":"aiida.transports.plugins.local:LocalTransport","core.ssh":"aiida.transports.plugins.ssh:SshTransport"},"aiida.workflows":{"core.arithmetic.add_multiply":{description:["Add two numbers and multiply it with a third."],spec:{inputs:[{name:"x",required:!0,valid_types:"Data",info:""},{name:"y",required:!0,valid_types:"Data",info:""},{name:"z",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida.workflows.arithmetic.add_multiply:add_multiply"},"core.arithmetic.multiply_add":{description:["WorkChain to multiply two numbers and add a third, for testing and demonstration purposes."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:""},{name:"x",required:!0,valid_types:"Int",info:""},{name:"y",required:!0,valid_types:"Int",info:""},{name:"z",required:!0,valid_types:"Int",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"result",required:!0,valid_types:"Int",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The result is a negative number."}]},class:"aiida.workflows.arithmetic.multiply_add:MultiplyAddWorkChain"}},console_scripts:{runaiida:"aiida.cmdline.commands.cmd_run:run",verdi:"aiida.cmdline.commands.cmd_verdi:verdi"}},commits_count:351,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:29},{colorclass:"green",text:"Workflows",count:2},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Calculations importers, Calculations monitors, Cmdline computer configure, ...)",count:47}],pip_install_cmd:"pip install aiida-core",is_installable:"True"},"aiida-cp2k":{code_home:"https://github.com/cp2k/aiida-cp2k",entry_point_prefix:"cp2k",pip_url:"aiida-cp2k",plugin_info:"https://raw.githubusercontent.com/cp2k/aiida-cp2k/master/setup.json",name:"aiida-cp2k",package_name:"aiida_cp2k",hosted_on:"github.com",metadata:{release_date:"2023-03-06",description:"The official AiiDA plugin for CP2K.",author:"The AiiDA team",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3"],version:"2.0.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{cp2k:{description:["This is a Cp2kCalculation, subclass of JobCalculation, to prepare input for an ab-initio CP2K calculation.","","    For information on CP2K, refer to: https://www.cp2k.org."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters."},{name:"basissets",required:!1,valid_types:"",info:"A dictionary of basissets to be used in the calculations: key is the atomic symbol, value is either a single basisset or a list of basissets. If multiple basissets for a single symbol are passed, it is mandatory to specify a KIND section with a BASIS_SET keyword matching the names (or aliases) of the basissets."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"file",required:!1,valid_types:"SinglefileData, StructureData",info:"Additional input files."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Input kpoint mesh."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Working directory of a previously ran calculation to restart from."},{name:"pseudos",required:!1,valid_types:"",info:"A dictionary of pseudopotentials to be used in the calculations: key is the atomic symbol, value is either a single pseudopotential or a list of pseudopotentials. If multiple pseudos for a single symbol are passed, it is mandatory to specify a KIND section with a PSEUDOPOTENTIAL keyword matching the names (or aliases) of the pseudopotentials."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional input parameters."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"The main input structure."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output dictionary containing results of the calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Computed electronic band structure."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required output file."},{status:301,message:"The output file could not be read."},{status:302,message:"The output file could not be parsed."},{status:303,message:"The output file was incomplete."},{status:304,message:'The output file contains the word "ABORT".'},{status:312,message:"The output structure could not be parsed."},{status:350,message:"The parser raised an unexpected exception."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"The maximum number of optimization steps reached."}]},class:"aiida_cp2k.calculations:Cp2kCalculation"}},"aiida.parsers":{cp2k_advanced_parser:"aiida_cp2k.parsers:Cp2kAdvancedParser",cp2k_base_parser:"aiida_cp2k.parsers:Cp2kBaseParser",cp2k_tools_parser:"aiida_cp2k.parsers:Cp2kToolsParser"},"aiida.workflows":{"cp2k.base":{description:["Workchain to run a CP2K calculation with automated error handling and restarts."],spec:{inputs:[{name:"cp2k",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output dictionary containing results of the calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"final_input_parameters",required:!1,valid_types:"Dict",info:"The input parameters used for the final calculation."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Computed electronic band structure."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed with a known unrecoverable error."},{status:400,message:"The calculation didn't produce any data to restart from."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_cp2k.workchains:Cp2kBaseWorkChain"}}},commits_count:24,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-cp2k",is_installable:"True"},"aiida-crystal-dft":{code_home:"https://github.com/tilde-lab/aiida-crystal-dft",development_status:"beta",documentation_url:"https://github.com/tilde-lab/aiida-crystal-dft",entry_point_prefix:"crystal_dft",pip_url:"git+https://github.com/tilde-lab/aiida-crystal-dft",name:"aiida-crystal-dft",package_name:"aiida_crystal_dft",hosted_on:"github.com",metadata:{description:`Yet another AiiDA plugin for CRYSTAL code, mainly intended for use with the cloud infrastructures
(currently, MPDS)`,classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Intended Audience :: Science/Research","Operating System :: OS Independent","Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Python :: 3.10","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Information Analysis"],author:"Andrey Sobolev, based on aiida-crystal17 plugin by Chris Sewell",author_email:"as@tilde.pro"},aiida_version:">=2.0.2",entry_points:{"aiida.data":{"crystal_dft.basis":"aiida_crystal_dft.data.basis:CrystalBasisData","crystal_dft.basis_family":"aiida_crystal_dft.data.basis_family:CrystalBasisFamilyData"},"aiida.calculations":{"crystal_dft.serial":{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"basis",required:!1,valid_types:"CrystalBasisData",info:""},{name:"basis_family",required:!1,valid_types:"CrystalBasisFamilyData, NoneType",info:""},{name:"guess_oxistates",required:!1,valid_types:"Bool, NoneType",info:""},{name:"high_spin_preferred",required:!1,valid_types:"Bool, NoneType",info:""},{name:"is_magnetic",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"spinlock_steps",required:!1,valid_types:"Int, NoneType",info:""},{name:"use_oxistates",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"oxidation_states",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"SCF calculation not converged"},{status:301,message:"Geometry optimization failed"},{status:302,message:"Unit cell not neutral"},{status:303,message:"Basis set linearly dependent"},{status:304,message:"Neighbour list too large"},{status:305,message:"No G-vectors left"},{status:306,message:"Collapsed geometry"},{status:307,message:"Closed shell run - spin polarization not allowed"},{status:308,message:"Parameters for model hessian not defined"},{status:309,message:"Fermi energy not in interval"},{status:310,message:"Insufficient indices for Madelung sums"},{status:350,message:"Internal memory error"},{status:360,message:"Inadequate elastic calculation: additional optimization needed"},{status:400,message:"Unknown error"},{status:401,message:"The retrieved folder data node could not be accessed"}]},class:"aiida_crystal_dft.calculations.serial:CrystalSerialCalculation"},"crystal_dft.parallel":{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"basis",required:!1,valid_types:"CrystalBasisData",info:""},{name:"basis_family",required:!1,valid_types:"CrystalBasisFamilyData, NoneType",info:""},{name:"guess_oxistates",required:!1,valid_types:"Bool, NoneType",info:""},{name:"high_spin_preferred",required:!1,valid_types:"Bool, NoneType",info:""},{name:"is_magnetic",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"spinlock_steps",required:!1,valid_types:"Int, NoneType",info:""},{name:"use_oxistates",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"oxidation_states",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"SCF calculation not converged"},{status:301,message:"Geometry optimization failed"},{status:302,message:"Unit cell not neutral"},{status:303,message:"Basis set linearly dependent"},{status:304,message:"Neighbour list too large"},{status:305,message:"No G-vectors left"},{status:306,message:"Collapsed geometry"},{status:307,message:"Closed shell run - spin polarization not allowed"},{status:308,message:"Parameters for model hessian not defined"},{status:309,message:"Fermi energy not in interval"},{status:310,message:"Insufficient indices for Madelung sums"},{status:350,message:"Internal memory error"},{status:360,message:"Inadequate elastic calculation: additional optimization needed"},{status:400,message:"Unknown error"},{status:401,message:"The retrieved folder data node could not be accessed"}]},class:"aiida_crystal_dft.calculations.parallel:CrystalParallelCalculation"},"crystal_dft.properties":{description:["AiiDA calculation plugin wrapping the properties executable."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"wavefunction",required:!0,valid_types:"SinglefileData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:""},{name:"output_bands_down",required:!1,valid_types:"BandsData",info:""},{name:"output_dos",required:!1,valid_types:"ArrayData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_crystal_dft.calculations.properties:PropertiesCalculation"}},"aiida.parsers":{crystal_dft:"aiida_crystal_dft.parsers.cry_pycrystal:CrystalParser","crystal_dft.properties":"aiida_crystal_dft.parsers.properties:PropertiesParser"},"aiida.workflows":{"crystal_dft.base":{description:["Run CRYSTAL calculation"],spec:{inputs:[{name:"basis_family",required:!0,valid_types:"CrystalBasisFamilyData",info:""},{name:"code",required:!0,valid_types:"Code",info:""},{name:"options",required:!0,valid_types:"Dict",info:"Calculation options"},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_params",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"oxidation_states",required:!1,valid_types:"Dict",info:""},{name:"primitive_structure",required:!1,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"CRYSTAL error"},{status:400,message:"Unknown error"}]},class:"aiida_crystal_dft.workflows.base:BaseCrystalWorkChain"}},"aiida.cmdline.data":{crystal_dft:"aiida_crystal_dft.cli.basis:basis_set"}},commits_count:18,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/tilde-lab/aiida-crystal-dft",is_installable:"True"},"aiida-crystal17":{code_home:"https://github.com/aiidaplugins/aiida-crystal17",development_status:"beta",documentation_url:"https://aiida-crystal17.readthedocs.io",entry_point_prefix:"crystal17",pip_url:"aiida-crystal17",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-crystal17/master/setup.json",name:"aiida-crystal17",package_name:"aiida_crystal17",hosted_on:"github.com",metadata:{release_date:"2020-09-29",description:"AiiDA plugin for running the CRYSTAL17 code",author:"Chris Sewell",author_email:"chrisj_sewell@hotmail.com",license:"MIT",home_page:"https://github.com/chrisjsewell/aiida-crystal17",classifiers:["Framework :: AiiDA","Programming Language :: Python","Programming Language :: Python :: 2.7","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"0.11.0"},aiida_version:">=1.4.0,<2.0.0",entry_points:{"aiida.calculations":{"crystal17.basic":{description:["AiiDA calculation plugin to run the crystal17 executable,","    by supplying a normal .d12 input file and (optional) .gui file"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"input_file",required:!0,valid_types:"SinglefileData",info:"the input .d12 file content."},{name:"input_external",required:!1,valid_types:"SinglefileData",info:"optional input fort.34 (gui) file content (for use with EXTERNAL keyword)."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:301,message:"An error occurred parsing the 'opta'/'optc' geometry files"},{status:302,message:"The crystal exec stdout file denoted that the run was a testgeom"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:411,message:"SCF convergence did not finalise (usually due to reaching step limit)"},{status:412,message:"Geometry convergence did not finalise (usually due to reaching step limit)"},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"},{status:510,message:"inconsistency in the input and output symmetry"},{status:520,message:"primitive symmops were not found in the output file"}]},class:"aiida_crystal17.calculations.cry_basic:CryBasicCalculation"},"crystal17.doss":{description:["AiiDA calculation plugin to run the ``properties`` executable,","    for DOSS calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"arrays",required:!1,valid_types:"ArrayData",info:"energies and DoS arrays"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output isovalue (fort.25) file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output isovalue (fort.25) file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_doss:CryDossCalculation"},"crystal17.ech3":{description:["AiiDA calculation plugin to run the ``properties`` executable, for 3D charge density (ECH3)."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"charge",required:!0,valid_types:"GaussianCube",info:"The charge density cube"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"spin",required:!1,valid_types:"GaussianCube",info:"The spin density cube"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output density file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output density file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_ech3:CryEch3Calculation"},"crystal17.main":{description:["AiiDA calculation plugin to run the crystal17 executable,","    by supplying aiida nodes, with data sufficient to create the","    .d12 input file and .gui file"],spec:{inputs:[{name:"basissets",required:!0,valid_types:"BasisSetData",info:"Use a node for the basis set of one of the elements in the structure. You have to pass an additional parameter ('element') specifying the atomic element symbol for which you want to use this basis set."},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"CryInputParamsData",info:"the input parameters to create the .d12 file content."},{name:"structure",required:!0,valid_types:"StructureData",info:"structure used to construct the input fort.34 (gui) file"},{name:"kinds",required:!1,valid_types:"KindData",info:"additional structure kind specific data (e.g. initial spin)"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry of the structure, used to construct the input .gui file (fort.34)"},{name:"wf_folder",required:!1,valid_types:"RemoteData",info:"An optional working directory, of a previously completed calculation, containing a fort.9 wavefunction file to restart from"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"optimisation",required:!1,valid_types:"TrajectoryData",info:"atomic configurations, for each optimisation step"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:301,message:"An error occurred parsing the 'opta'/'optc' geometry files"},{status:302,message:"The crystal exec stdout file denoted that the run was a testgeom"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:411,message:"SCF convergence did not finalise (usually due to reaching step limit)"},{status:412,message:"Geometry convergence did not finalise (usually due to reaching step limit)"},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"},{status:510,message:"inconsistency in the input and output symmetry"},{status:520,message:"primitive symmops were not found in the output file"}]},class:"aiida_crystal17.calculations.cry_main:CryMainCalculation"},"crystal17.newk":{description:["AiiDA calculation plugin to run the properties17 executable,","    for NEWK calculations (to return the fermi energy)"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_newk:CryNewkCalculation"},"crystal17.ppan":{description:["AiiDA calculation plugin to run the ``properties`` executable,","    for PPAN (Mulliken population analysis) calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output PPAN.dat file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output PPAN.dat file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_ppan:CryPpanCalculation"}},"aiida.cmdline.data":{"crystal17.basis":"aiida_crystal17.cmndline.basis_set:basisset","crystal17.parse":"aiida_crystal17.cmndline.cmd_parser:parse","crystal17.symmetry":"aiida_crystal17.cmndline.symmetry:symmetry"},"aiida.data":{"crystal17.basisset":"aiida_crystal17.data.basis_set:BasisSetData","crystal17.gcube":"aiida_crystal17.data.gcube:GaussianCube","crystal17.kinds":"aiida_crystal17.data.kinds:KindData","crystal17.parameters":"aiida_crystal17.data.input_params:CryInputParamsData","crystal17.symmetry":"aiida_crystal17.data.symmetry:SymmetryData"},"aiida.groups":{"crystal17.basisset":"aiida_crystal17.data.basis_set:BasisSetFamily"},"aiida.parsers":{"crystal17.doss":"aiida_crystal17.parsers.cry_doss:CryDossParser","crystal17.ech3":"aiida_crystal17.parsers.cry_ech3:CryEch3Parser","crystal17.main":"aiida_crystal17.parsers.cry_main:CryMainParser","crystal17.newk":"aiida_crystal17.parsers.cry_newk:CryNewkParser","crystal17.ppan":"aiida_crystal17.parsers.cry_ppan:CryPpanParser"},"aiida.workflows":{"crystal17.main.base":{description:["Workchain to run a standard CRYSTAL17 calculation,","    with automated error handling and restarts."],spec:{inputs:[{name:"cry",required:!0,valid_types:"",info:""},{name:"basis_family",required:!1,valid_types:"Str",info:"An alternative to specifying the basis sets manually: one can specify the name of an existing basis set family and the work chain will generate the basis sets automatically based on the input structure."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints_distance",required:!1,valid_types:"Float",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by the input structure, and will replace the SHRINK IS value in the input parameters.Note: This methods assumes the PRIMITIVE unit cell is provided"},{name:"kpoints_force_parity",required:!1,valid_types:"Bool",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"The parameters could not be validated against the jsonschema."},{status:202,message:"The explicit `basis_sets` or `basis_family` could not be used to get the necessary basis sets."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:320,message:"The initialization calculation failed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_crystal17.workflows.crystal_main.base:CryMainBaseWorkChain"},"crystal17.properties":{description:["A WorkChain to compute properties of a structure, using CRYSTAL.","","    Either a pre-computed wavefunction (fort.9) file,","    or inputs for a CryMainCalculation, should be supplied.","    Inputs for property calculations can then be added","    (currently available; doss, ech3)."],spec:{inputs:[{name:"check_remote",required:!1,valid_types:"Bool",info:"If a RemoteData wf_folder is input, check it contains the wavefunction file, before launching calculations. Note, this will fail if the remote computer is not immediately available"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"doss",required:!1,valid_types:"",info:""},{name:"ech3",required:!1,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"ppan",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"",info:""},{name:"test_run",required:!1,valid_types:"Bool",info:"break off the workchain before submitting a calculation"},{name:"wf_folder",required:!1,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"}],outputs:[{name:"doss",required:!1,valid_types:"",info:""},{name:"ech3",required:!1,valid_types:"",info:""},{name:"ppan",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"Workchain ended before submitting calculation."},{status:201,message:"Neither a wf_folder nor scf calculation was supplied."},{status:202,message:"No property calculation inputs were supplied."},{status:203,message:"The supplied folder does contain the wavefunction file."},{status:210,message:"The SCF calculation submission failed."},{status:301,message:"The SCF calculation failed."},{status:302,message:"One or more property calculations failed."}]},class:"aiida_crystal17.workflows.crystal_props.base:CryPropertiesWorkChain"},"crystal17.sym3d":{description:["modify an AiiDa structure instance and compute its symmetry","","    Inequivalent atomic sites are dictated by atom kinds"],spec:{inputs:[{name:"settings",required:!0,valid_types:"Dict",info:""},{name:"cif",required:!1,valid_types:"CifData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"structure",required:!1,valid_types:"StructureData",info:""}],outputs:[{name:"symmetry",required:!0,valid_types:"SymmetryData",info:""},{name:"structure",required:!1,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"one of either a structure or cif input must be supplied"},{status:301,message:'the supplied structure must be 3D (i.e. have all dimensions pbc=True)"'},{status:302,message:"idealize can only be used when standardize=True"},{status:303,message:"the kind names supplied are not compatible with the structure"},{status:304,message:"error creating new structure"},{status:305,message:"error computing symmetry operations"}]},class:"aiida_crystal17.workflows.symmetrise_3d_struct:Symmetrise3DStructure"}},console_scripts:{mock_crystal17:"aiida_crystal17.tests.mock_crystal17:main",mock_properties17:"aiida_crystal17.tests.mock_properties17:main"}},commits_count:0,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:5},{colorclass:"red",text:"Data",count:5},{colorclass:"green",text:"Workflows",count:3},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:4}],pip_install_cmd:"pip install aiida-crystal17",is_installable:"True"},"aiida-cusp":{code_home:"https://github.com/aiida-cusp/aiida-cusp",documentation_url:"https://aiida-cusp.readthedocs.io",entry_point_prefix:"cusp",pip_url:"https://pypi.org/project/aiida-cusp",name:"aiida-cusp",package_name:"aiida_cusp",hosted_on:"github.com",metadata:{author:"Andreas Stamminger",author_email:"stammingera@gmail.com",version:"0.1.0b2",description:"Custodian based VASP Plugin for AiiDA",classifiers:["Development Status :: 4 - Beta","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Chemistry","Environment :: Plugins","Framework :: AiiDA"]},aiida_version:">=1.3.0,<2.0.0",entry_points:{"aiida.data":{"cusp.kpoints":"aiida_cusp.data.inputs.vasp_kpoint:VaspKpointData","cusp.poscar":"aiida_cusp.data.inputs.vasp_poscar:VaspPoscarData","cusp.incar":"aiida_cusp.data.inputs.vasp_incar:VaspIncarData","cusp.potcar":"aiida_cusp.data.inputs.vasp_potcar:VaspPotcarData","cusp.vasprun":"aiida_cusp.data.outputs.vasp_vasprun:VaspVasprunData","cusp.outcar":"aiida_cusp.data.outputs.vasp_outcar:VaspOutcarData","cusp.contcar":"aiida_cusp.data.outputs.vasp_contcar:VaspContcarData","cusp.chgcar":"aiida_cusp.data.outputs.vasp_chgcar:VaspChgcarData","cusp.wavecar":"aiida_cusp.data.outputs.vasp_wavecar:VaspWavecarData","cusp.generic":"aiida_cusp.data.outputs.vasp_generic:VaspGenericData","cusp.potcarfile":"aiida_cusp.data.inputs.vasp_potcar:VaspPotcarFile"},"aiida.calculations":{"cusp.vasp":"aiida_cusp.calculators.vasp_calculation:VaspCalculation"},"aiida.parsers":{"cusp.default":"aiida_cusp.parsers.vasp_file_parser:VaspFileParser"},"aiida.cmdline.data":{potcar:"aiida_cusp.cli.potcar_cmd:potcar"}},commits_count:28,development_status:"beta",errors:[`Failed to install plugin aiida-cusp</br><pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 16.2 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-3cl9eji8/aiida-cusp (downloaded from /tmp/pip-req-build-ons9dt1r, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-ons9dt1r
</pre>`],warnings:["Entry point 'potcar' does not start with prefix 'cusp.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:11},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install https://pypi.org/project/aiida-cusp",is_installable:"False"},"aiida-dataframe":{entry_point_prefix:"dataframe",plugin_info:"https://raw.github.com/janssenhenning/aiida-dataframe/main/pyproject.toml",code_home:"https://github.com/janssenhenning/aiida-dataframe",version_file:"https://raw.githubusercontent.com/janssenhenning/aiida-dataframe/main/aiida_dataframe/__init__.py",pip_url:"aiida-dataframe",documentation_url:"https://aiida-dataframe.readthedocs.io/en/latest/",name:"aiida-dataframe",package_name:"aiida_dataframe",hosted_on:"github.com",metadata:{release_date:"2023-05-05",description:"AiiDA data plugin for pandas DataFrame objects",author_email:"Henning Janßen <henning.janssen@gmx.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"0.1.3"},aiida_version:">=1.0,<3",entry_points:{"aiida.cmdline.data":{dataframe:"aiida_dataframe.cli:data_cli"},"aiida.data":{"dataframe.frame":"aiida_dataframe.data.dataframe:PandasFrameData"}},commits_count:11,development_status:"beta",errors:[],warnings:[],summaryinfo:[{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-dataframe",is_installable:"True"},"aiida-ddec":{code_home:"https://github.com/lsmo-epfl/aiida-ddec",entry_point_prefix:"ddec",pip_url:"git+https://github.com/yakutovicha/aiida-ddec",name:"aiida-ddec",package_name:"aiida_ddec",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:13,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/lsmo-epfl/aiida-ddec/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/yakutovicha/aiida-ddec"},"aiida-defects":{code_home:"https://github.com/epfl-theos/aiida-defects",entry_point_prefix:"defects",pip_url:"aiida-defects",plugin_info:"https://raw.githubusercontent.com/epfl-theos/aiida-defects/master/pyproject.toml",name:"aiida-defects",package_name:"aiida_defects",hosted_on:"github.com",metadata:{release_date:"2023-03-29",description:"AiiDA-Defects is a plugin for the AiiDA computational materials science framework, and provides tools and automated workflows for the study of defects in materials.",author:"The AiiDA-Defects developers",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"1.0.1"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{"defects.array.stability":"aiida_defects.data.data:StabilityData"},"aiida.workflows":{"defects.formation_energy.chemical_potential":"aiida_defects.formation_energy.chemical_potential.chemical_potential:ChemicalPotentialWorkchain","defects.formation_energy.corrections.gaussian_countercharge":"aiida_defects.formation_energy.corrections.gaussian_countercharge.gaussian_countercharge:GaussianCounterChargeWorkchain","defects.formation_energy.corrections.gaussian_countercharge.model_potential":"aiida_defects.formation_energy.corrections.gaussian_countercharge.model_potential.model_potential:ModelPotentialWorkchain","defects.formation_energy.corrections.point_countercharge":"aiida_defects.formation_energy.corrections.point_countercharge.point_countercharge:PointCounterChargeWorkchain","defects.formation_energy.potential_alignment":"aiida_defects.formation_energy.potential_alignment.potential_alignment:PotentialAlignmentWorkchain","defects.formation_energy.qe":"aiida_defects.formation_energy.formation_energy_qe:FormationEnergyWorkchainQE","defects.formation_energy.siesta":"aiida_defects.formation_energy.formation_energy_siesta:FormatonEnergyWorkchainSiesta"}},commits_count:10,development_status:"beta",errors:[`Failed to fetch entry point metadata for package aiida_defects</br><pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.9/site-packages/aiida/plugins/entry_point.py", line 239, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.9/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/conda/lib/python3.9/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.9/site-packages/aiida/plugins/entry_point.py", line 239, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.9/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`],warnings:[],summaryinfo:[{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:7}],pip_install_cmd:"pip install aiida-defects",is_installable:"True"},"aiida-diff":{code_home:"https://github.com/aiidateam/aiida-diff",development_status:"stable",documentation_url:"https://aiida-diff.readthedocs.io/",entry_point_prefix:"diff",pip_url:"git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0",name:"aiida-diff",package_name:"aiida_diff",hosted_on:"github.com",metadata:{description:"AiiDA demo plugin that wraps the `diff` executable for computing the difference between two files.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 3 - Alpha","Framework :: AiiDA"],author:"The AiiDA Team"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{diff:"aiida_diff.data:DiffParameters"},"aiida.calculations":{diff:"aiida_diff.calculations:DiffCalculation"},"aiida.parsers":{diff:"aiida_diff.parsers:DiffParser"},"aiida.cmdline.data":{diff:"aiida_diff.cli:data_cli"}},commits_count:0,errors:[`Failed to install plugin aiida-diff</br><pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-zd7_jn8f/aiida-diff-0-1-0a0_ee1e51ce1f3b4fc09733b9ae0e376389
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-zd7_jn8f/aiida-diff-0-1-0a0_ee1e51ce1f3b4fc09733b9ae0e376389
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: expected 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`],warnings:["Development status in classifiers (alpha) does not match development_status in metadata (stable)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0",is_installable:"False"},"aiida-donothing":{code_home:"https://github.com/atztogo/aiida-donothing",entry_point_prefix:"donothing",name:"aiida-donothing",package_name:"aiida_donothing",hosted_on:"github.com",metadata:{author:"Atsushi Togo",author_email:"atz.togo@gmail.com",version:"0.1",description:"AiiDA calculation plugin for doing nothing",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.5,<2.0.0",entry_points:{"aiida.calculations":{"donothing.donothing":"aiida_donothing.calculations.donothing:DoNothingCalculation"},"aiida.parsers":{"donothing.donothing":"aiida_donothing.parsers.donothing:DoNothingParser"}},commits_count:1,development_status:"planning",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"See source code repository."},"aiida-dynamic-workflows":{code_home:"https://github.com/microsoft/aiida-dynamic-workflows",entry_point_prefix:"dynamic_workflows",name:"aiida-dynamic-workflows",package_name:"aiida_dynamic_workflows",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",errors:[],warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-environ":{code_home:"https://github.com/environ-developers/aiida-environ",entry_point_prefix:"environ",pip_url:"git+https://github.com/environ-developers/aiida-environ",name:"aiida-environ",package_name:"aiida_environ",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.github.com/environ-developers/aiida-environ/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/environ-developers/aiida-environ"},"aiida-eon":{code_home:"https://github.com/HaoZeke/aiida-eon",entry_point_prefix:"eon",name:"aiida-eon",package_name:"aiida_eon",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",errors:[],warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-eonclient":{code_home:"https://github.com/HaoZeke/aiida-eonclient",entry_point_prefix:"eonclient",name:"aiida-eonclient",package_name:"aiida_eonclient",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",errors:[],warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-fenics":{code_home:"https://github.com/sphuber/aiida-fenics/tree/master",entry_point_prefix:"fenics",pip_url:"git+https://github.com/sphuber/aiida-fenics",name:"aiida-fenics",package_name:"aiida_fenics",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:-1,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.github.com/sphuber/aiida-fenics/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/sphuber/aiida-fenics"},"aiida-firecrest":{code_home:"https://github.com/aiidateam/aiida-firecrest",entry_point_prefix:"firecrest",pip_url:"aiida-firecrest",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-firecrest/main/pyproject.toml",name:"aiida-firecrest",package_name:"aiida_firecrest",hosted_on:"github.com",metadata:{release_date:"2022-01-14",description:"AiiDA Transport/Scheduler plugins for interfacing with FirecREST.",author_email:"Chris Sewell <chrisj_sewell@hotmail.com>",classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Python :: Implementation :: CPython","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.1.0a1"},aiida_version:"<2",entry_points:{"aiida.schedulers":{firecrest:"aiida_firecrest.scheduler:FirecrestScheduler"},"aiida.transports":{firecrest:"aiida_firecrest.transport:FirecrestTransport"},console_scripts:{"aiida-firecrest-cli":"aiida_firecrest.cli:main"}},commits_count:19,development_status:"alpha",errors:[],warnings:[],summaryinfo:[{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Schedulers, Transports)",count:2}],pip_install_cmd:"pip install --pre aiida-firecrest",is_installable:"True"},"aiida-fireworks-scheduler":{code_home:"https://github.com/zhubonan/aiida-fireworks-scheduler",development_status:"beta",documentation_url:"https://aiida-fireworks-scheduler.readthedocs.io",entry_point_prefix:"fireworks_scheduler",pip_url:"git+https://github.com/zhubonan/aiida-fireworks-scheduler",name:"aiida-fireworks-scheduler",package_name:"aiida_fireworks_scheduler",hosted_on:"github.com",metadata:{author:"Bonan Zhu",author_email:"zhubonan@outlook.com",version:"1.2.0",description:"AiiDA plugin to allow using `fireworks` as the execution engine for `CalcJob`.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:null,entry_points:{"aiida.schedulers":{fireworks:"aiida_fireworks_scheduler.fwscheduler:FwScheduler","fireworks_scheduler.default":"aiida_fireworks_scheduler.fwscheduler:FwScheduler","fireworks_scheduler.keepenv":"aiida_fireworks_scheduler.fwscheduler:FwSchedulerKeepEnv"},"aiida.cmdline.data":{"fireworks-scheduler":"aiida_fireworks_scheduler.cmdline:fw_cli"},console_scripts:{arlaunch:"aiida_fireworks_scheduler.scripts.arlaunch_run:arlaunch"}},commits_count:0,errors:[],warnings:["AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'fireworks' does not start with prefix 'fireworks_scheduler.'","Entry point 'fireworks-scheduler' does not start with prefix 'fireworks_scheduler.'"],summaryinfo:[{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Schedulers)",count:4}],pip_install_cmd:"pip install git+https://github.com/zhubonan/aiida-fireworks-scheduler",is_installable:"True"},"aiida-fleur":{code_home:"https://github.com/JuDFTteam/aiida-fleur/tree/develop",development_status:"stable",documentation_url:"https://aiida-fleur.readthedocs.io/",entry_point_prefix:"fleur",pip_url:"aiida-fleur",plugin_info:"https://raw.github.com/JuDFTteam/aiida-fleur/develop/setup.json",name:"aiida-fleur",package_name:"aiida_fleur",hosted_on:"github.com",metadata:{release_date:"2023-05-03",description:"AiiDA Plugin for running the FLEUR code and its input generator. Also includes high-level workchains and utilities",author_email:"The JuDFT team <j.broeder@fz-juelich.de>",classifiers:["Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.0.0"},aiida_version:">=2.0.1,<3.0.0",entry_points:{"aiida.calculations":{"fleur.fleur":{description:["A CalcJob class that represents FLEUR DFT calculation.","    For more information about the FLEUR-code family go to http://www.flapw.de/"],spec:{inputs:[{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:"Use a FleurinpData node that specifies the input parametersusually copy from the parent calculation, basically makesthe inp.xml file visible in the db and makes sure it has the files needed."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote or local repository folder as parent folder (also for restarts and similar). It should contain all the needed files for a Fleur calc, only edited files should be uploaded from the repository."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"error_params",required:!1,valid_types:"Dict",info:""},{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_params_complex",required:!1,valid_types:"Dict",info:""},{name:"relax_parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"No retrieved folder found."},{status:301,message:"One of the output files can not be opened."},{status:302,message:"FLEUR calculation failed for unknown reason."},{status:303,message:"XML output file was not found."},{status:304,message:"Parsing of XML output file failed."},{status:305,message:"Parsing of relax XML output file failed."},{status:310,message:"FLEUR calculation failed due to lack of memory."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:312,message:"FLEUR calculation failed due to MT overlap."},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:314,message:"Problem with cdn is suspected. Consider removing cdn"},{status:315,message:"The LDA+U density matrix contains invalid elements."},{status:316,message:"Calculation failed due to time limits."},{status:318,message:"Calculation failed due to missing dependency ({name}) for given calculation."}]},class:"aiida_fleur.calculation.fleur:FleurCalculation"},"fleur.inpgen":{description:["JobCalculationClass for the inpgen, which is a preprocessor for a FLEUR calculation.","    For more information about produced files and the FLEUR-code family, go to http://www.flapw.de/."],spec:{inputs:[{name:"structure",required:!0,valid_types:"StructureData",info:"Choose the input structure to use"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Use a node that specifies the input parameters for the namelists"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"fleurinp",required:!0,valid_types:"FleurinpData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"No retrieved folder found."},{status:301,message:"One of the output files can not be opened."},{status:306,message:"XML input file was not found."},{status:307,message:"Some required files were not retrieved."},{status:308,message:"During parsing: FleurinpData could not be initialized, see log. "},{status:309,message:"During parsing: FleurinpData failed validation."},{status:310,message:"The profile {profile} is not known to the used inpgen code"}]},class:"aiida_fleur.calculation.fleurinputgen:FleurinputgenCalculation"}},"aiida.data":{"fleur.fleurinp":"aiida_fleur.data.fleurinp:FleurinpData"},"aiida.parsers":{"fleur.fleurinpgenparser":"aiida_fleur.parsers.fleur_inputgen:Fleur_inputgenParser","fleur.fleurparser":"aiida_fleur.parsers.fleur:FleurParser"},"aiida.workflows":{"fleur.banddos":{description:["This workflow calculated a bandstructure from a Fleur calculation","","    :Params: a Fleurcalculation node","    :returns: Success, last result node, list with convergence behavior"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"banddos_calc",required:!0,valid_types:"",info:""},{name:"output_banddos_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_banddos_wc_bands",required:!1,valid_types:"BandsData",info:""},{name:"output_banddos_wc_dos",required:!1,valid_types:"XyData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"SCF calculation failed."},{status:335,message:"Found no SCF calculation remote repository."}]},class:"aiida_fleur.workflows.banddos:FleurBandDosWorkChain"},"fleur.base":{description:["Workchain to run a FLEUR calculation with automated error handling and restarts"],spec:{inputs:[{name:"options",required:!0,valid_types:"Dict",info:"Optional parameters to set up computational details."},{name:"add_comp_para",required:!1,valid_types:"Dict",info:"Gives additional control over computational parametersonly_even_MPI: set to true if you want to suppress odd number of MPI processes in parallelisation.This might speedup a calculation for machines having even number of sockets per node.max_queue_nodes: maximal number of nodes allowed on the remote machine. Used only to automatically solve some FLEUR failures.max_queue_wallclock_sec: maximal wallclock time allowed on the remote machine. Used only to automatically solve some FLEUR failures."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"description",required:!1,valid_types:"str, NoneType",info:"Calculation description."},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:"Use a FleurinpData node that specifies the input parametersusually copy from the parent calculation, basically makesthe inp.xml file visible in the db and makes sure it has the files needed."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"label",required:!1,valid_types:"str, NoneType",info:"Calculation label."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote or local repository folder as parent folder (also for restarts and similar). It should contain all the needed files for a Fleur calc, only edited files should be uploaded from the repository."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"error_params",required:!1,valid_types:"Dict",info:""},{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_params_complex",required:!1,valid_types:"Dict",info:""},{name:"relax_parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:388,message:"Computational resources are not optimal."},{status:389,message:"Computational resources are not optimal."},{status:390,message:"Computational resources are not optimal."},{status:399,message:"FleurCalculation failed and FleurBaseWorkChain has no strategy to resolve this"},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_fleur.workflows.base_fleur:FleurBaseWorkChain"},"fleur.base_relax":{description:["Workchain to run Relax WorkChain with automated error handling and restarts"],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"description",required:!1,valid_types:"str, NoneType",info:"Calculation description."},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"label",required:!1,valid_types:"str, NoneType",info:"Calculation label."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"last_scf",required:!0,valid_types:"",info:""},{name:"optimized_structure",required:!0,valid_types:"StructureData",info:""},{name:"output_relax_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:399,message:"FleurRelaxWorkChain failed and FleurBaseRelaxWorkChain has no strategy to resolve this"},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_fleur.workflows.base_relax:FleurBaseRelaxWorkChain"},"fleur.cfcoeff":{description:["Workflow for calculating rare-earth crystal field coefficients"],spec:{inputs:[{name:"metadata",required:!1,valid_types:"",info:""},{name:"orbcontrol",required:!1,valid_types:"Data",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"scf_rare_earth_analogue",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_cfcoeff_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_cfcoeff_wc_charge_densities",required:!1,valid_types:"XyData",info:""},{name:"output_cfcoeff_wc_potentials",required:!1,valid_types:"XyData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:345,message:"Convergence scf workflow failed."},{status:451,message:"Convergence orbcontrol workflow failed."},{status:452,message:"CF calculation failed."}]},class:"aiida_fleur.workflows.cfcoeff:FleurCFCoeffWorkChain"},"fleur.corehole":{description:["Turn key solution for a corehole calculation with the FLEUR code.","    Has different protocols for different core-hole types (valence, charge).","","    Calculates supercells. Extracts binding energies","    for certain corelevels from the total energy differences a the calculation with","    corehole and without.","","    Documentation:","    See help for details.","","    Two paths are possible:","","    (1) Start from a structure -> workchains run inpgen first (recommended)","    (2) Start from a Fleurinp data object","","    Also it is recommended to provide a calc parameter node for the structure","","    :param wf_parameters: Dict node, specify, resources and what should be calculated","    :param structure: structureData node, crystal structure","    :param calc_parameters: Dict node, inpgen parameters for the crystal structure","    :param fleurinp:  fleurinpData node,","    :param inpgen: Code node,","    :param fleur: Code node,","","    :return: output_corehole_wc_para Dict node,  successful=True if no error","","    :uses workchains: fleur_scf_wc, fleur_relax_wc","    :uses calcfunctions: supercell, create_corehole_result_node, prepare_struc_corehole_wf"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"inpgen",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_corehole_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:1,message:"The input resources are invalid."},{status:2,message:"The process failed with legacy failure mode."},{status:2,message:"Input resources are missing."},{status:3,message:"The code provided is invalid, or not of the right kind."},{status:4,message:"Inpgen calculation FAILED, check output"},{status:5,message:"Changing of the FLEURINP data went wrong, check log."},{status:6,message:"The FLEUR input file for the calculation did not validate."},{status:7,message:"At least one FLEUR calculation FAILED, check the output and log."},{status:8,message:"At least one FLEUR calculation did not/could not reach thedesired convergece Criteria, with the current parameters."},{status:9,message:"Something went wrong in the determiation what coreholes to calculate, probably the input format was not correct. Check log."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.corehole:FleurCoreholeWorkChain"},"fleur.create_magnetic":{description:["This workflow creates relaxed magnetic film on a substrate."],spec:{inputs:[{name:"distance_suggestion",required:!1,valid_types:"Dict, NoneType",info:""},{name:"eos",required:!1,valid_types:"Data",info:""},{name:"eos_output",required:!1,valid_types:"Dict, NoneType",info:""},{name:"interlayer_dist",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"optimized_structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"relax",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"magnetic_structure",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:380,message:"Specified substrate has to be bcc or fcc."},{status:382,message:"Relaxation calculation failed."},{status:383,message:"EOS WorkChain failed."}]},class:"aiida_fleur.workflows.create_magnetic_film:FleurCreateMagneticWorkChain"},"fleur.dmi":{description:["This workflow calculates DMI energy dispersion of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_dmi_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.dmi:FleurDMIWorkChain"},"fleur.dos":{description:["DEPRECATED: Use FleurBandDosWorkChain instead (entrypoint fleur.banddos)","    This workflow calculated a DOS from a Fleur calculation","","    :Params: a Fleurcalculation node","    :returns: Success, last result node, list with convergence behavior","","    wf_parameters: {  'tria', 'nkpts', 'sigma', 'emin', 'emax'}","    defaults : tria = True, nkpts = 800, sigma=0.005, emin= -0.3, emax = 0.8"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_data",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.dos:fleur_dos_wc"},"fleur.eos":{description:["This workflow calculates the equation of states of a structure.","    Calculates several unit cells with different volumes.","    A Birch_Murnaghan  equation of states fit determines the Bulk modulus and the","    groundstate volume of the cell.","","    :params wf_parameters: Dict node, optional 'wf_parameters', protocol specifying parameter dict","    :params structure: StructureData node, 'structure' crystal structure","    :params calc_parameters: Dict node, optional 'calc_parameters' parameters for inpgen","    :params inpgen: Code node,","    :params fleur: Code node,","","","    :return output_eos_wc_para: Dict node, contains relevant output information.","                                about general succeed, fit results and so on."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_eos_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_eos_wc_structure",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:400,message:"At least one of the SCF sub processes did not finish successfully."}]},class:"aiida_fleur.workflows.eos:FleurEosWorkChain"},"fleur.init_cls":{description:["Turn key solution for the calculation of core level shift"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_initial_cls_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.initial_cls:FleurInitialCLSWorkChain"},"fleur.mae":{description:["This workflow calculates the Magnetic Anisotropy Energy of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_mae_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.mae:FleurMaeWorkChain"},"fleur.mae_conv":{description:["This workflow calculates the Magnetic Anisotropy Energy of a structure."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_mae_conv_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:343,message:"Convergence MAE calculation failed for all SQAs."},{status:344,message:"Convergence MAE calculation failed for some SQAs."}]},class:"aiida_fleur.workflows.mae_conv:FleurMaeConvWorkChain"},"fleur.orbcontrol":{description:["Workchain for determining the groundstate density matrix in an DFT+U","    calculation. This is done in 2 or 3 steps:","","        1. Converge the system without DFT+U (a converged calculation can be","           provided to skip this step)","        2. A fixed number of iterations is run with fixed density matrices","           either generated as all distinct permutations for the given occupations","           or the explicitly given configurations","        3. The system and density matrix is relaxed","","    :param wf_parameters: (Dict), Workchain Specifications","    :param scf_no_ldau: (Dict), Inputs to a FleurScfWorkChain providing the initial system","                                either converged or staring from a structure","    :param scf_with_ldau: (Dict), Inputs to a FleurScfWorkChain. Only the wf_parameters are valid","    :param fleurinp: (FleurinpData) FleurinpData to start from if no SCF should be done","    :param remote: (RemoteData) RemoteData to start from if no SCF should be done","    :param structure: (StructureData) Structure to start from if no SCF should be done","    :param calc_parameters: (Dict), Inpgen Parameters","    :param settings: (Dict), additional settings for e.g retrieving files","    :param options: (Dict), Options for the submission of the jobs","    :param inpgen: (Code)","    :param fleur: (Code)"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fixed_remotes",required:!1,valid_types:"RemoteData",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"options_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"relaxed_remotes",required:!1,valid_types:"RemoteData",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf_no_ldau",required:!1,valid_types:"Data",info:"Inputs for SCF Workchain before adding LDA+U"},{name:"scf_with_ldau",required:!1,valid_types:"Data",info:"Inputs for SCF Workchain after the LDA+U matrix was fixed"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"groundstate_scf",required:!0,valid_types:"",info:""},{name:"output_orbcontrol_wc_para",required:!0,valid_types:"Dict",info:""},{name:"groundstate_denmat",required:!1,valid_types:"SinglefileData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Input codes do not correspond to fleur or inpgen respectively."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:342,message:"Convergence LDA+U calculation failed for some Initial configurations."},{status:343,message:"Convergence LDA+U calculation failed for all Initial configurations."},{status:360,message:"Inpgen calculation failed."},{status:450,message:"Convergence workflow without LDA+U failed."}]},class:"aiida_fleur.workflows.orbcontrol:FleurOrbControlWorkChain"},"fleur.relax":{description:["This workflow performs structure optimization."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"last_scf",required:!0,valid_types:"",info:""},{name:"optimized_structure",required:!0,valid_types:"StructureData",info:""},{name:"output_relax_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"If you want to run a final scf inpgen has to be there."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:350,message:"Optimization cycle did not lead to convergence of forces."},{status:351,message:"SCF Workchains failed for some reason."},{status:352,message:"Found no relaxed structure info in the output of SCF"},{status:353,message:"Found no SCF output"},{status:354,message:"Force is small, switch to BFGS"}]},class:"aiida_fleur.workflows.relax:FleurRelaxWorkChain"},"fleur.relax_torque":{description:["This workflow performs spin structure optimization."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_relax_torque_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"If you want to run a final scf inpgen has to be there."},{status:350,message:"Optimization cycle did not lead to convergence."},{status:351,message:"An SCF Workchain failed for some reason."}]},class:"aiida_fleur.workflows.relax_torque:FleurRelaxTorqueWorkChain"},"fleur.scf":{description:["Workchain for converging a FLEUR calculation (SCF).","","    It converges the charge density, total energy or the largest force.","    Two paths are possible:","","    (1) Start from a structure and run the inpgen first optional with calc_parameters","    (2) Start from a Fleur calculation, with optional remoteData","","    :param wf_parameters: (Dict), Workchain Specifications","    :param structure: (StructureData), Crystal structure","    :param calc_parameters: (Dict), Inpgen Parameters","    :param fleurinp: (FleurinpData), to start with a Fleur calculation","    :param remote_data: (RemoteData), from a Fleur calculation","    :param inpgen: (Code)","    :param fleur: (Code)","","    :return: output_scf_wc_para (Dict), Information of workflow results","        like Success, last result node, list with convergence behavior"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_data",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"fleurinp",required:!0,valid_types:"FleurinpData",info:""},{name:"last_calc",required:!0,valid_types:"",info:""},{name:"output_scf_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Input codes do not correspond to fleur or inpgen respectively."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:360,message:"Inpgen calculation failed."},{status:361,message:"Fleur calculation failed."},{status:362,message:"SCF cycle did not lead to convergence."}]},class:"aiida_fleur.workflows.scf:FleurScfWorkChain"},"fleur.ssdisp":{description:["This workflow calculates spin spiral dispersion of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_ssdisp_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.ssdisp:FleurSSDispWorkChain"},"fleur.ssdisp_conv":{description:["This workflow calculates the Spin Spiral Dispersion of a structure."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_ssdisp_conv_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:340,message:"Convergence SSDisp calculation failed for all q-vectors."},{status:341,message:"Convergence SSDisp calculation failed for some q-vectors."}]},class:"aiida_fleur.workflows.ssdisp_conv:FleurSSDispConvWorkChain"},"fleur.strain":{description:["This workflow calculates the deformation potential a structure = -BdEg/dP = d(Eg)/d(ln(V)).","    Calculates several unit cells with different volumes.","    A Birch_Murnaghan  equation of states fit determines the Bulk modulus(B) and the","    ground-state volume of the cell.","","    :params wf_parameters: Dict node, optional 'wf_parameters', protocol specifying parameter dict","    :params structure: StructureData node, 'structure' crystal structure","    :params calc_parameters: Dict node, optional 'calc_parameters' parameters for inpgen","    :params inpgen: Code node,","    :params fleur: Code node,","","","    :return output_strain_wc_para: Dict node, contains relevant output information.","                                about general succeed, fit results and so on."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"inpgen",required:!0,valid_types:"Code",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_strain_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:331,message:"Invalid code node specified, check inpgen and fleur code nodes."}]},class:"aiida_fleur.workflows.strain:FleurStrainWorkChain"}},console_scripts:{"aiida-fleur":"aiida_fleur.cmdline:cmd_root"}},commits_count:200,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:19},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-fleur",is_installable:"True"},"aiida-flexpart":{code_home:"https://github.com/aiidaplugins/aiida-flexpart",entry_point_prefix:"flexpart",pip_url:"git+https://github.com/aiidaplugins/aiida-flexpart",name:"aiida-flexpart",package_name:"aiida_flexpart",hosted_on:"github.com",metadata:{author:"The AiiDA Team",author_email:"aliaksandr.yakutovich@empa.ch",version:"0.1.0a0",description:"AiiDA plugin for the FLEXPART code (simulation of atmospheric transport processes).",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.5,<3.0.0",entry_points:{"aiida.calculations":{"flexpart.cosmo":"aiida_flexpart.calculations.cosmo:FlexpartCosmoCalculation"},"aiida.parsers":{"flexpart.cosmo":"aiida_flexpart.parsers.cosmo:FlexpartCosmoParser"},"aiida.workflows":{"flexpart.multi_dates":"aiida_flexpart.workflows.multi_dates_workflow:FlexpartMultipleDatesWorkflow"}},commits_count:0,development_status:"planning",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidaplugins/aiida-flexpart"},"aiida-gaussian":{code_home:"https://github.com/nanotech-empa/aiida-gaussian",entry_point_prefix:"gaussian",pip_url:"aiida-gaussian",plugin_info:"https://raw.githubusercontent.com/nanotech-empa/aiida-gaussian/master/pyproject.toml",name:"aiida-gaussian",package_name:"aiida_gaussian",hosted_on:"github.com",metadata:{release_date:"2023-08-31",description:"AiiDA plugin for the Gaussian quantum chemistry software.",author:"Kristjan Eimre, Pezhman Zarabadi-Poor, Aliaksandr Yakutovich",license:"MIT",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: OS Independent","Programming Language :: Python :: 3","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Software Development :: Libraries :: Python Modules"],version:"2.1.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{gaussian:{description:["AiiDA calculation plugin wrapping Gaussian","","    Template:","","    parameters = Dict(dict={","        'link0_parameters': {","            '%chk':'aiida.chk',","            '%mem': '1024MB',","            '%nprocshared': '2',","        },","        'functional':'PBE1PBE',","        'basis_set':'6-31g',","        'charge': 0,","        'multiplicity': 1,","        'route_parameters': {","            'scf': {'cdiis': None}","            'nosymm': None,","            'opt': 'tight',","        },","    })"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"the folder of a completed gaussian calculation"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"additional input parameters"},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"Input structure; will be converted to pymatgen object"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The result parameters of the calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"energy_ev",required:!1,valid_types:"Float",info:"Final energy in electronvolts"},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final optimized structure, if available"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the output file."},{status:211,message:"The retrieved output log could not be read."},{status:220,message:"The output file could not be parsed."},{status:301,message:"The SCF did not converge and the calculation was terminated."},{status:302,message:"The calculation was terminated due to a logic error in ASyTop."},{status:303,message:"The calculation was terminated due to an inaccurate quadrature in CalDSu."},{status:390,message:"The calculation was terminated due to an error."},{status:391,message:"The log did not contain 'Normal termination' (probably out of time)."}]},class:"aiida_gaussian.calculations:GaussianCalculation"},"gaussian.cubegen":{description:["Plugin to run the cubegen utility","","    Example:","","    parameters = {",'        "homo-5": {','            "kind": "AMO=16",','            "npts": -2,',"        },",'        "spin": {','            "kind": "Spin=SCF",','            "npts": 0,',"        },","    }","    Each key corresponds to one produced cube.","    key specifies the name of the output node","",'    In case of "npts": -1, you have to use the stencil file input:',"","        IFlag X0 Y0 Z0  # Output unit number and initial point.","        N1 X1 Y1 Z1     # Number of points and step-size in the X-direction.","        N2 X2 Y2 Z2     # Number of points and step-size in the Y-direction.","        N3 X3 Y3 Z3     # Number of points and step-size in the Z-direction.","","    See more details at https://gaussian.com/cubegen/"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"dictionary containing entries for cubes to be printed."},{name:"parent_calc_folder",required:!0,valid_types:"RemoteData",info:"the folder of a containing the .fchk"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"gauss_memdef",required:!1,valid_types:"Int, NoneType",info:"Set the GAUSS_MEMDEF env variable to set the max memory in MB."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieve_cubes",required:!1,valid_types:"Bool, NoneType",info:"should the cubes be retrieved?"},{name:"stencil",required:!1,valid_types:"SinglefileData, NoneType",info:"In case of npts=-1, use this cube specification."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"The retrieved folder could not be accessed."},{status:301,message:"The retrieved temporary folder could not be accessed."}]},class:"aiida_gaussian.calculations:CubegenCalculation"},"gaussian.formchk":{description:["Very simple plugin to run the formchk utility"],spec:{inputs:[{name:"parent_calc_folder",required:!0,valid_types:"RemoteData",info:"the folder of a containing the .chk"},{name:"chk_name",required:!1,valid_types:"Str, NoneType",info:"name of the checkpoint file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieve_fchk",required:!1,valid_types:"Bool, NoneType",info:"retrieve the fchk file"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_gaussian.calculations:FormchkCalculation"}},"aiida.parsers":{"gaussian.advanced":"aiida_gaussian.parsers.gaussian:GaussianAdvancedParser","gaussian.base":"aiida_gaussian.parsers.gaussian:GaussianBaseParser","gaussian.cubegen_base":"aiida_gaussian.parsers.cubegen:CubegenBaseParser"},"aiida.workflows":{"gaussian.base":{description:["Workchain to run a Gaussian calculation with automated error handling and restarts."],spec:{inputs:[{name:"gaussian",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:350,message:"The calculation failed with an unrecoverable SCF convergence error."},{status:399,message:"The calculation failed with an unrecoverable error."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_gaussian.workchains:GaussianBaseWorkChain"},"gaussian.cubes":{description:["No description available"],spec:{inputs:[{name:"cubegen_code",required:!0,valid_types:"Code",info:""},{name:"formchk_code",required:!0,valid_types:"Code",info:""},{name:"gaussian_calc_folder",required:!0,valid_types:"RemoteData",info:"The gaussian calculation output folder."},{name:"gaussian_output_params",required:!0,valid_types:"Dict",info:"The gaussian calculation output parameters."},{name:"cubegen_parser_name",required:!1,valid_types:"str",info:""},{name:"cubegen_parser_params",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters to cubegen parser."},{name:"dx",required:!1,valid_types:"Float, NoneType",info:"Cube file spacing [ang]."},{name:"edge_space",required:!1,valid_types:"Float, NoneType",info:"Extra cube space in addition to molecule bounding box [ang]."},{name:"generate_density",required:!1,valid_types:"Bool, NoneType",info:"Generate density cube."},{name:"generate_spin_density",required:!1,valid_types:"Bool, NoneType",info:"Generate spin density cube (if applicable)."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"natural_orbitals",required:!1,valid_types:"Bool, NoneType",info:"The cube files are natural orbitals."},{name:"orbital_index_ref",required:!1,valid_types:"Str, NoneType",info:"Reference index, possible choices: 'half_num_el', 'abs'."},{name:"orbital_indexes",required:!1,valid_types:"List, NoneType",info:"Indexes of the orbital cubes to generate."},{name:"retrieve_cubes",required:!1,valid_types:"Bool, NoneType",info:"should the cubes be retrieved?"}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:302,message:"Input options are invalid."},{status:390,message:"One or more steps of the work chain failed."}]},class:"aiida_gaussian.workchains:GaussianCubesWorkChain"}}},commits_count:23,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"green",text:"Workflows",count:2}],pip_install_cmd:"pip install aiida-gaussian",is_installable:"True"},"aiida-gaussian-datatypes":{code_home:"https://github.com/dev-zero/aiida-gaussian-datatypes",documentation_url:"https://github.com/dev-zero/aiida-gaussian-datatypes/blob/master/README.md",entry_point_prefix:"gaussian",pip_url:"aiida-gaussian-datatypes",plugin_info:"https://raw.github.com/dev-zero/aiida-gaussian-datatypes/master/setup.json",name:"aiida-gaussian-datatypes",package_name:"aiida_gaussian_datatypes",hosted_on:"github.com",metadata:{release_date:"2022-07-22",description:"AiiDA data plugin to manage gaussian datatypes (basis sets and pseudopotentials) as first-class citizens",author:"Tiziano Müller",author_email:"tiziano.mueller@chem.uzh.ch",license:"MIT License",home_page:"https://github.com/dev-zero/aiida-gaussian-datatypes",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.5.1"},aiida_version:">=1.6.2",entry_points:{"aiida.cmdline.data":{"gaussian.basisset":"aiida_gaussian_datatypes.basisset.cli:cli","gaussian.pseudo":"aiida_gaussian_datatypes.pseudopotential.cli:cli"},"aiida.data":{"gaussian.basisset":"aiida_gaussian_datatypes.basisset.data:BasisSet","gaussian.pseudo":"aiida_gaussian_datatypes.pseudopotential.data:Pseudopotential"},"aiida.groups":{"gaussian.basisset":"aiida_gaussian_datatypes.groups:BasisSetGroup","gaussian.pseudo":"aiida_gaussian_datatypes.groups:PseudopotentialGroup"}},commits_count:0,development_status:"beta",errors:[],warnings:["Prefix 'gaussian' does not follow naming convention."],summaryinfo:[{colorclass:"red",text:"Data",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:4}],pip_install_cmd:"pip install aiida-gaussian-datatypes",is_installable:"True"},"aiida-gollum":{code_home:"https://github.com/garsua/aiida-gollum/",documentation_url:"https://aiida-gollum.readthedocs.io/",entry_point_prefix:"gollum",pip_url:"git+https://github.com/garsua/aiida-gollum",name:"aiida-gollum",package_name:"aiida_gollum",hosted_on:"github.com",metadata:{author:"Victor M. Garcia-Suarez",author_email:"vm.garcia@cinn.es",version:"0.12.0",description:"A plugin for Gollum functionality within AiiDA framework.",classifiers:["License :: OSI Approved :: MIT License","Framework :: AiiDA","Programming Language :: Python :: 2.7","Development Status :: 1 - Alpha"]},aiida_version:">=0.12.0",entry_points:{"aiida.calculations":{"gollum.gollum":"aiida_gollum.calculations.gollum:GollumCalculation"},"aiida.parsers":{"gollum.parser":"aiida_gollum.parsers.gollum:GollumParser"}},commits_count:0,development_status:"planning",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/garsua/aiida-gollum"},"aiida-graphql":{code_home:"https://github.com/dev-zero/aiida-graphql",entry_point_prefix:"graphql",pip_url:"aiida-graphql",name:"aiida-graphql",package_name:"aiida_graphql",hosted_on:"github.com",metadata:{release_date:"2019-10-28",description:"Strawberry-based GraphQL API Server for AiiDA",author:"Tiziano Müller",author_email:"tiziano.mueller@chem.uzh.ch",license:"MIT",home_page:"https://github.com/dev-zero/aiida-graphql",classifiers:["Development Status :: 3 - Alpha","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.0.2"},aiida_version:">=1.0.0b6,<2.0.0",entry_points:{},commits_count:0,development_status:"alpha",errors:[`Failed to install plugin aiida-graphql</br><pre>Collecting aiida-graphql
  Downloading aiida_graphql-0.0.2-py3-none-any.whl (6.6 kB)
Collecting aiida<2.0.0,>=1.0.0b6 (from aiida-graphql)
  Downloading aiida-1.0.1.tar.gz (2.8 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting strawberry-graphql<0.17.0,>=0.16.7 (from aiida-graphql)
  Downloading strawberry_graphql-0.16.10-py3-none-any.whl (29 kB)
Requirement already satisfied: aiida-core in /opt/conda/lib/python3.9/site-packages (from aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.4.0.post0)
Collecting click<8.0,>=7.0 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 9.8 MB/s eta 0:00:00
Collecting graphql-core<4.0.0,>=3.0.0a0 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Obtaining dependency information for graphql-core<4.0.0,>=3.0.0a0 from https://files.pythonhosted.org/packages/95/74/5ec674eb611ba6d70a8622a58ffe9c087afee079f8688ef2b836adca8616/graphql_core-3.3.0a3-py3-none-any.whl.metadata
  Downloading graphql_core-3.3.0a3-py3-none-any.whl.metadata (11 kB)
Collecting hupper<2.0,>=1.5 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading hupper-1.12-py3-none-any.whl (22 kB)
Requirement already satisfied: pygments<3.0,>=2.3 in /opt/conda/lib/python3.9/site-packages (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql) (2.16.1)
Collecting starlette==0.12.10 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading starlette-0.12.10.tar.gz (46 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.3/46.3 kB 17.7 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting uvicorn==0.10.0 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading uvicorn-0.10.0.tar.gz (26 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting h11==0.8.* (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading h11-0.8.1-py2.py3-none-any.whl (55 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 19.3 MB/s eta 0:00:00
Collecting websockets==8.* (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading websockets-8.1.tar.gz (58 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.9/58.9 kB 27.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting httptools==0.0.13 (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading httptools-0.0.13.tar.gz (104 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 104.2/104.2 kB 40.4 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting uvloop==0.14.0rc2 (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading uvloop-0.14.0rc2.tar.gz (2.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 73.4 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: typing-extensions<5.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from graphql-core<4.0.0,>=3.0.0a0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql) (4.8.0)
Requirement already satisfied: alembic~=1.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.12.0)
Requirement already satisfied: archive-path~=0.4.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.4.2)
Requirement already satisfied: aio-pika~=6.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (6.8.1)
Requirement already satisfied: circus~=0.18.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.18.0)
Requirement already satisfied: click-spinner~=0.1.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.1.10)
INFO: pip is looking at multiple versions of aiida-core to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Obtaining dependency information for aiida-core from https://files.pythonhosted.org/packages/2b/ec/a99338a82592fb94c5741288143d34281162fe4e19228e059cfec67d5589/aiida_core-2.4.0-py3-none-any.whl.metadata
  Downloading aiida_core-2.4.0-py3-none-any.whl.metadata (10 kB)
  Obtaining dependency information for aiida-core from https://files.pythonhosted.org/packages/d9/96/c88f1af662144765c15acdbada6d33f92e57a0c2311f6aa09fa8fcc7c91a/aiida_core-2.3.1-py3-none-any.whl.metadata
  Downloading aiida_core-2.3.1-py3-none-any.whl.metadata (11 kB)
  Downloading aiida_core-2.3.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 56.8 MB/s eta 0:00:00
  Downloading aiida_core-2.2.2-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 82.6 MB/s eta 0:00:00
Collecting click-config-file~=0.6.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading click_config_file-0.6.0-py2.py3-none-any.whl (6.0 kB)
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aiida_core-2.2.1-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 79.1 MB/s eta 0:00:00
  Downloading aiida_core-2.2.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 66.7 MB/s eta 0:00:00
  Downloading aiida_core-2.1.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 87.0 MB/s eta 0:00:00
Collecting circus~=0.17.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading circus-0.17.2-py3-none-any.whl (204 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 204.2/204.2 kB 58.7 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of aiida-core to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aiida_core-2.1.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 45.3 MB/s eta 0:00:00
  Downloading aiida_core-2.1.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 99.5 MB/s eta 0:00:00
  Downloading aiida_core-2.0.4-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 53.4 MB/s eta 0:00:00
  Downloading aiida_core-2.0.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 117.3 MB/s eta 0:00:00
  Downloading aiida_core-2.0.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 117.7 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading aiida_core-2.0.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 115.1 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 119.2 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0b1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 60.6 MB/s eta 0:00:00
Collecting archive-path~=0.3.6 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading archive_path-0.3.6-py3-none-any.whl (18 kB)
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aiida_core-1.6.9-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 122.2 MB/s eta 0:00:00
Collecting aldjemy~=0.9.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aldjemy-0.9.1-py3-none-any.whl (26 kB)
Collecting archive-path~=0.2.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading archive_path-0.2.1-py3-none-any.whl (17 kB)
Collecting click-completion~=0.5.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading click-completion-0.5.2.tar.gz (10 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting django~=2.2 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading Django-2.2.28-py3-none-any.whl (7.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.5/7.5 MB 121.2 MB/s eta 0:00:00
Collecting ete3~=3.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading ete3-3.1.3.tar.gz (4.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 98.3 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: graphviz~=0.13 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.20.1)
Collecting ipython~=7.20 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 793.8/793.8 kB 94.2 MB/s eta 0:00:00
Collecting jinja2~=2.10 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 45.6 MB/s eta 0:00:00
Requirement already satisfied: jsonschema~=3.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.2.0)
Requirement already satisfied: kiwipy[rmq]~=0.7.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.7.7)
Collecting markupsafe<2.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading MarkupSafe-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)
Requirement already satisfied: numpy~=1.17 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.26.0)
Requirement already satisfied: pamqp~=2.3 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.3.0)
Requirement already satisfied: paramiko>=2.7.2,~=2.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.12.0)
Collecting plumpy~=0.20.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading plumpy-0.20.0-py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 23.4 MB/s eta 0:00:00
Requirement already satisfied: pgsu~=0.2.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.2.4)
Requirement already satisfied: psutil~=5.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (5.9.5)
Collecting psycopg2-binary~=2.8.3 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading psycopg2_binary-2.8.6-cp39-cp39-manylinux1_x86_64.whl (3.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 121.6 MB/s eta 0:00:00
Collecting python-dateutil~=2.8 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 69.5 MB/s eta 0:00:00
Collecting pytz~=2019.3 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 kB 95.7 MB/s eta 0:00:00
Collecting pyyaml~=5.4 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 630.1/630.1 kB 104.3 MB/s eta 0:00:00
Collecting reentry~=1.3 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading reentry-1.3.3-py3-none-any.whl (17 kB)
Collecting simplejson~=3.16 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading simplejson-3.19.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.4/137.4 kB 46.5 MB/s eta 0:00:00
Collecting sqlalchemy-utils~=0.36.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading SQLAlchemy-Utils-0.36.5.tar.gz (131 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.2/131.2 kB 47.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sqlalchemy~=1.3.10 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading SQLAlchemy-1.3.24-cp39-cp39-manylinux2010_x86_64.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 116.0 MB/s eta 0:00:00
Requirement already satisfied: tabulate~=0.8.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.8.10)
Requirement already satisfied: tqdm~=4.45 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (4.66.1)
Collecting tzlocal~=2.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: upf-to-json~=0.9.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.9.5)
Collecting wrapt~=1.11.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading wrapt-1.11.2.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: aiormq<4,>=3.2.3 in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.3.1)
Requirement already satisfied: yarl in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.9.2)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.2.4)
Requirement already satisfied: pyzmq>=17.0 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (25.1.1)
Requirement already satisfied: tornado>=5.0.2 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (6.3.3)
Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from click-completion~=0.5.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.16.0)
Collecting shellingham (from click-completion~=0.5.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Obtaining dependency information for shellingham from https://files.pythonhosted.org/packages/57/70/0265437683625b2e6491736706d3d679d90e2a26f6bff59f4e46e09872b9/shellingham-1.5.3-py2.py3-none-any.whl.metadata
  Downloading shellingham-1.5.3-py2.py3-none-any.whl.metadata (3.4 kB)
Collecting configobj>=5.0.6 (from click-config-file~=0.6.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)
Collecting sqlparse>=0.2.2 (from django~=2.2->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 16.6 MB/s eta 0:00:00
Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (68.2.2)
Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.19.0)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (5.1.1)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.7.5)
Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (5.10.0)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.0.39)
Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.2.0)
Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.1.6)
Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (4.8.0)
Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (23.1.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.19.3)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.0.11)
Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.10)
Requirement already satisfied: pytray<0.4.0,>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.3.4)
Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.1.0)
INFO: pip is looking at multiple versions of kiwipy[rmq] to determine which version is compatible with other requirements. This could take a while.
Collecting kiwipy[rmq]~=0.7.5 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading kiwipy-0.7.6-py3-none-any.whl (29 kB)
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (4.0.1)
Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (41.0.4)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.5.0)
Collecting nest-asyncio~=1.4.0 (from plumpy~=0.20.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.15.1)
Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.8.3)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.7.0)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.2.6)
Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from deprecation->kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (23.1)
Requirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (6.0.4)
Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.4)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.21)
Downloading graphql_core-3.3.0a3-py3-none-any.whl (209 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.9/209.9 kB 57.2 MB/s eta 0:00:00
Downloading shellingham-1.5.3-py2.py3-none-any.whl (9.7 kB)
Building wheels for collected packages: aiida, starlette, uvicorn, httptools, uvloop, websockets, click-completion, ete3, sqlalchemy-utils, wrapt
  Building wheel for aiida (setup.py): started
  Building wheel for aiida (setup.py): finished with status 'done'
  Created wheel for aiida: filename=aiida-1.0.1-py3-none-any.whl size=2647 sha256=ed3f5e9038610b4ce7835bf8c4f0eb215933b295e0f3ce070aa22808b448cf15
  Stored in directory: /home/aiida/.cache/pip/wheels/6a/40/75/657e47e83c88bd0540e6c7cf1011f86f2ebe801418960774ae
  Building wheel for starlette (setup.py): started
  Building wheel for starlette (setup.py): finished with status 'done'
  Created wheel for starlette: filename=starlette-0.12.10-py3-none-any.whl size=57408 sha256=5e3330a4ec967bc9a9d2af27b81afa91b6988c7d5721ef7f3cfb2f589f77b29d
  Stored in directory: /home/aiida/.cache/pip/wheels/61/a2/3b/69592c9f46018f222ed7231684cb01dcd01e154c421612e6cf
  Building wheel for uvicorn (setup.py): started
  Building wheel for uvicorn (setup.py): finished with status 'done'
  Created wheel for uvicorn: filename=uvicorn-0.10.0-py3-none-any.whl size=40800 sha256=4929079d6c5b8eaec921fb52c5c83c54175287f3ce7e90f5180de8e9702a5a14
  Stored in directory: /home/aiida/.cache/pip/wheels/3f/eb/c3/f5bb5247cf7f29c58eedd827460b2c3d186be85ad2f4bfeaf5
  Building wheel for httptools (setup.py): started
  Building wheel for httptools (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [160 lines of output]
      running bdist_wheel
      running build
      running build_py
      creating build
      creating build/lib.linux-x86_64-cpython-39
      creating build/lib.linux-x86_64-cpython-39/httptools
      copying httptools/__init__.py -> build/lib.linux-x86_64-cpython-39/httptools
      creating build/lib.linux-x86_64-cpython-39/httptools/parser
      copying httptools/parser/errors.py -> build/lib.linux-x86_64-cpython-39/httptools/parser
      copying httptools/parser/__init__.py -> build/lib.linux-x86_64-cpython-39/httptools/parser
      running egg_info
      writing httptools.egg-info/PKG-INFO
      writing dependency_links to httptools.egg-info/dependency_links.txt
      writing top-level names to httptools.egg-info/top_level.txt
      reading manifest file 'httptools.egg-info/SOURCES.txt'
      reading manifest template 'MANIFEST.in'
      adding license file 'LICENSE'
      writing manifest file 'httptools.egg-info/SOURCES.txt'
      copying httptools/parser/parser.c -> build/lib.linux-x86_64-cpython-39/httptools/parser
      running build_ext
      building 'httptools.parser.parser' extension
      creating build/temp.linux-x86_64-cpython-39
      creating build/temp.linux-x86_64-cpython-39/httptools
      creating build/temp.linux-x86_64-cpython-39/httptools/parser
      creating build/temp.linux-x86_64-cpython-39/vendor
      creating build/temp.linux-x86_64-cpython-39/vendor/http-parser
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.9 -c httptools/parser/parser.c -o build/temp.linux-x86_64-cpython-39/httptools/parser/parser.o -O2
      httptools/parser/parser.c: In function ‘__Pyx_modinit_type_init_code’:
      httptools/parser/parser.c:8977:51: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       8977 |   __pyx_type_9httptools_6parser_6parser_HttpParser.tp_print = 0;
            |                                                   ^
      httptools/parser/parser.c:8988:58: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       8988 |   __pyx_type_9httptools_6parser_6parser_HttpRequestParser.tp_print = 0;
            |                                                          ^
      httptools/parser/parser.c:9000:59: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       9000 |   __pyx_type_9httptools_6parser_6parser_HttpResponseParser.tp_print = 0;
            |                                                           ^
      httptools/parser/parser.c:9009:44: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       9009 |   __pyx_type_9httptools_6parser_6parser_URL.tp_print = 0;
            |                                            ^
      httptools/parser/parser.c: In function ‘__Pyx_ParseOptionalKeywords’:
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c: In function ‘__Pyx_decode_c_bytes’:
      httptools/parser/parser.c:10316:9: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
      10316 |         return PyUnicode_FromUnicode(NULL, 0);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      error: command '/usr/bin/gcc' failed with exit code 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for httptools
  Running setup.py clean for httptools
  Building wheel for uvloop (setup.py): started
  Building wheel for uvloop (setup.py): finished with status 'done'
  Created wheel for uvloop: filename=uvloop-0.14.0rc2-cp39-cp39-linux_x86_64.whl size=1832544 sha256=9227877d55bcde12f098574a5d5b8cc383d1edd913d63cc85b447fa336472282
  Stored in directory: /home/aiida/.cache/pip/wheels/1a/97/63/2785095a0e950600bf7a9c8b0b047da9b4fd04c8b6ba2dd5d8
  Building wheel for websockets (setup.py): started
  Building wheel for websockets (setup.py): finished with status 'done'
  Created wheel for websockets: filename=websockets-8.1-cp39-cp39-linux_x86_64.whl size=66218 sha256=ae08e612a654811006987e85bae6eeeeeb8bc82ed817953d34d3d42be25a1000
  Stored in directory: /home/aiida/.cache/pip/wheels/d8/b9/a0/b97b211aeda2ebd6ac2e43fc300d308dbf1f9df520ed390cae
  Building wheel for click-completion (setup.py): started
  Building wheel for click-completion (setup.py): finished with status 'done'
  Created wheel for click-completion: filename=click_completion-0.5.2-py3-none-any.whl size=11189 sha256=1ab48b7ad56fef4c48004ccb1b22be8fdf71b8d6cc28699e4220f789c1e93883
  Stored in directory: /home/aiida/.cache/pip/wheels/f1/23/55/8287077a0e274c8d7ddf94fb623cb481cd0f4512d1a5062603
  Building wheel for ete3 (setup.py): started
  Building wheel for ete3 (setup.py): finished with status 'done'
  Created wheel for ete3: filename=ete3-3.1.3-py3-none-any.whl size=2273785 sha256=c74186504e01473474832bdea50e92792b063043aa08564135fd47fb0961f5c1
  Stored in directory: /home/aiida/.cache/pip/wheels/ad/2e/cc/edcca721b423e1604c84f480a1e8e0547a223bfc068d373259
  Building wheel for sqlalchemy-utils (setup.py): started
  Building wheel for sqlalchemy-utils (setup.py): finished with status 'done'
  Created wheel for sqlalchemy-utils: filename=SQLAlchemy_Utils-0.36.5-py2.py3-none-any.whl size=93140 sha256=546e4cdec959a6bdc0220aacc6f137671d4b92dbe02007de30be5360e6230bd3
  Stored in directory: /home/aiida/.cache/pip/wheels/09/42/92/638b45c458a59b25b1b83e8771a9744f4219512a683c76af15
  Building wheel for wrapt (setup.py): started
  Building wheel for wrapt (setup.py): finished with status 'done'
  Created wheel for wrapt: filename=wrapt-1.11.2-cp39-cp39-linux_x86_64.whl size=36723 sha256=43a18cd114f55b4001a196639e9cfbf11835c8f22c8056c831b772e8bc314598
  Stored in directory: /home/aiida/.cache/pip/wheels/76/e9/66/d4e35bfa6cde3925ff1c497043d7a2ccb305c07ac51fef0e31
Successfully built aiida starlette uvicorn uvloop websockets click-completion ete3 sqlalchemy-utils wrapt
Failed to build httptools
ERROR: Could not build wheels for httptools, which is required to install pyproject.toml-based projects
</pre>`],warnings:["Unable to read wheel file from PyPI release: No entry_points.txt found in wheel","Missing classifier 'Framework :: AiiDA'"],summaryinfo:[],pip_install_cmd:"pip install aiida-graphql",is_installable:"False"},"aiida-gromacs":{code_home:"https://github.com/jimboid/aiida-gromacs",documentation_url:"https://aiida-gromacs.readthedocs.io/",entry_point_prefix:"gromacs",pip_url:"git+https://github.com/jimboid/aiida-gromacs",name:"aiida-gromacs",package_name:"aiida_gromacs",hosted_on:"github.com",metadata:{description:"A plugin for using GROMACS with AiiDA for molecular dymanics simulations.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 3 - Alpha","Framework :: AiiDA"],author:"James Gebbie-Rayet",author_email:"james.gebbie@stfc.ac.uk"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{"gromacs.pdb2gmx":"aiida_gromacs.data.pdb2gmx:Pdb2gmxParameters","gromacs.editconf":"aiida_gromacs.data.editconf:EditconfParameters","gromacs.genion":"aiida_gromacs.data.genion:GenionParameters","gromacs.grompp":"aiida_gromacs.data.grompp:GromppParameters","gromacs.mdrun":"aiida_gromacs.data.mdrun:MdrunParameters","gromacs.solvate":"aiida_gromacs.data.solvate:SolvateParameters"},"aiida.calculations":{"gromacs.pdb2gmx":{description:["AiiDA calculation plugin wrapping the 'gmx pdb2gmx' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Pdb2gmxParameters",info:"Command line parameters for gmx pdb2gmx"},{name:"pdbfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"itpfile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"n_file",required:!1,valid_types:"SinglefileData",info:"Output index file"},{name:"q_file",required:!1,valid_types:"SinglefileData",info:"Output Structure file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.pdb2gmx:Pdb2gmxCalculation"},"gromacs.editconf":{description:["AiiDA calculation plugin wrapping the 'gmx editconf' executable.","","    AiiDA plugin wrapper for adding a simulation box to structure file."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure file."},{name:"parameters",required:!0,valid_types:"EditconfParameters",info:"Command line parameters for gmx editconf."},{name:"bf_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Generic data file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output file containing simulation box."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"mead_file",required:!1,valid_types:"SinglefileData",info:"Coordination file for MEAD"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.editconf:EditconfCalculation"},"gromacs.genion":{description:["AiiDA calculation plugin wrapping the 'gmx genion' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"GenionParameters",info:"Command line parameters for gmx genion"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology file."},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Input tpr file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output gro file with ions added."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output topology with ions added."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.genion:GenionCalculation"},"gromacs.grompp":{description:["AiiDA calculation plugin wrapping the 'gmx grompp' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure"},{name:"mdpfile",required:!0,valid_types:"SinglefileData",info:"grompp run file."},{name:"parameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"e_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Energy file"},{name:"itpfile",required:!1,valid_types:"SinglefileData, NoneType",info:"Restraint file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file"},{name:"qmi_file",required:!1,valid_types:"SinglefileData, NoneType",info:"QM input file"},{name:"r_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Structure file"},{name:"rb_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Structure file"},{name:"ref_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Full precision trajectory file"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"t_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Full precision trajectory file"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Output gro file ready for adding ions."},{name:"imd_file",required:!1,valid_types:"SinglefileData",info:"Coordinate file in Gromos-87 format"},{name:"po_file",required:!1,valid_types:"SinglefileData",info:"grompp input file with MD parameters"},{name:"pp_file",required:!1,valid_types:"SinglefileData",info:"Topology file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.grompp:GromppCalculation"},"gromacs.mdrun":{description:["AiiDA calculation plugin wrapping the 'gmx mdrun' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun"},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"awh_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"cpi_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Checkpoint file"},{name:"ei_file",required:!1,valid_types:"SinglefileData, NoneType",info:"ED sampling input"},{name:"membed_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Generic data file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"mn_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file"},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"mp_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Topology file"},{name:"multidir_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Run directory"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"rerun_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Trajectory: xtc trr cpt gro g96 pdb tng"},{name:"table_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"tableb_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"tablep_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"}],outputs:[{name:"enfile",required:!0,valid_types:"SinglefileData",info:"Output energy file."},{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output structure file."},{name:"logfile",required:!0,valid_types:"SinglefileData",info:"Output log file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"trrfile",required:!0,valid_types:"SinglefileData",info:"Output trajectory."},{name:"cpo_file",required:!1,valid_types:"SinglefileData",info:"Checkpoint file."},{name:"dhdl_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"eo_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"field_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"if_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"mtx_file",required:!1,valid_types:"SinglefileData",info:"Hessian Matrix"},{name:"pf_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"px_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"ra_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"ro_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"rs_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"rt_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"swap_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"tpi_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"tpid_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"x_file",required:!1,valid_types:"SinglefileData",info:"Compressed trajectory (tng format or portable xdr format)"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.mdrun:MdrunCalculation"},"gromacs.solvate":{description:["AiiDA calculation plugin wrapping the 'gmx solvate' executable.","","    AiiDA plugin wrapper for solvating a molecular system."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure"},{name:"parameters",required:!0,valid_types:"SolvateParameters",info:"Command line parameters for gmx solvate."},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output solvated gro file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output topology file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.solvate:SolvateCalculation"},genericMD:{description:["AiiDA calculation plugin wrapping an executable with user defined","    input and output files."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"command",required:!1,valid_types:"Str, NoneType",info:"The command used to execute the job."},{name:"input_files",required:!1,valid_types:"SinglefileData",info:"Dictionary of input files."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"output_files",required:!1,valid_types:"List, NoneType",info:"List of output file names."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"log",required:!1,valid_types:"SinglefileData",info:"link to the default file.out."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."},{status:301,message:"Specified output file not produced by command."}]},class:"aiida_gromacs.calculations.genericMD:GenericCalculation"}},"aiida.parsers":{"gromacs.pdb2gmx":"aiida_gromacs.parsers.pdb2gmx:Pdb2gmxParser","gromacs.editconf":"aiida_gromacs.parsers.editconf:EditconfParser","gromacs.genion":"aiida_gromacs.parsers.genion:GenionParser","gromacs.grompp":"aiida_gromacs.parsers.grompp:GromppParser","gromacs.mdrun":"aiida_gromacs.parsers.mdrun:MdrunParser","gromacs.solvate":"aiida_gromacs.parsers.solvate:SolvateParser",genericMD:"aiida_gromacs.parsers.genericMD:GenericParser"},"aiida.workflows":{"gromacs.setup":{description:["WorkChain for setting up a gromacs simulation automatically."],spec:{inputs:[{name:"editconfparameters",required:!0,valid_types:"EditconfParameters",info:"Command line parameters for gmx editconf"},{name:"genionparameters",required:!0,valid_types:"GenionParameters",info:"Command line parameters for gmx genion"},{name:"gromppionsparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp"},{name:"gromppminparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp minimisation run"},{name:"gromppnptparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp npt equilibration run"},{name:"gromppnvtparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp nvt equilibration run"},{name:"gromppprodparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp production run"},{name:"ionsmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for adding ions."},{name:"local_code",required:!0,valid_types:"Code",info:""},{name:"mdrunparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun production run"},{name:"minimiseparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun minimisation run"},{name:"minmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for minimisation."},{name:"nptmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for NPT equilibration."},{name:"nptparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun npt equilibration run"},{name:"nvtmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for NVT equilibration."},{name:"nvtparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun nvt equilibration run"},{name:"pdb2gmxparameters",required:!0,valid_types:"Pdb2gmxParameters",info:"Command line parameters for gmx pdb2gmx"},{name:"pdbfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"prodmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for production run."},{name:"solvateparameters",required:!0,valid_types:"SolvateParameters",info:"Command line parameters for gmx solvate"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"remote_code",required:!1,valid_types:"Code, NoneType",info:""}],outputs:[{name:"result",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_gromacs.workflows.simsetup:SetupWorkChain"}}},commits_count:187,development_status:"alpha",errors:[],warnings:["Entry point 'genericMD' does not start with prefix 'gromacs.'","Entry point 'genericMD' does not start with prefix 'gromacs.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:7},{colorclass:"brown",text:"Parsers",count:7},{colorclass:"red",text:"Data",count:6},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/jimboid/aiida-gromacs",is_installable:"True"},"aiida-grouppathx":{code_home:"https://github.com/zhubonan/aiida-grouppathx",development_status:"beta",entry_point_prefix:"grouppathx",pip_url:"aiida-grouppathx",name:"aiida-grouppathx",package_name:"aiida_grouppathx",hosted_on:"github.com",metadata:{release_date:"2022-05-25",description:"AiiDA plugin provides the GroupPathX class",author_email:"Bonan Zhu <zhubonan@outlook.com>",classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.0"},aiida_version:">=1.6.4,<3",entry_points:{"aiida.cmdline.data":{gpx:"aiida_grouppathx.cli:grouppathx_cli"}},commits_count:3,errors:[`Failed to import package aiida_grouppathx</br><pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.9/site-packages/aiida_grouppathx/__init__.py", line 6, in <module>
    from aiida_grouppathx.pathx import *
  File "/opt/conda/lib/python3.9/site-packages/aiida_grouppathx/pathx.py", line 122, in <module>
    class GroupPathX(GroupPath):
  File "/opt/conda/lib/python3.9/site-packages/aiida_grouppathx/pathx.py", line 130, in GroupPathX
    cls: orm.groups.GroupMeta = orm.Group,
AttributeError: module 'aiida.orm.groups' has no attribute 'GroupMeta'
</pre>`],warnings:["Unable to read wheel file from PyPI release: No entry_points.txt found in wheel","Development status in classifiers (alpha) does not match development_status in metadata (beta)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'gpx' does not start with prefix 'grouppathx.'"],summaryinfo:[{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-grouppathx",is_installable:"True"},"aiida-gudhi":{code_home:"https://github.com/ltalirz/aiida-gudhi",development_status:"beta",entry_point_prefix:"gudhi",pip_url:"aiida-gudhi",plugin_info:"https://raw.github.com/ltalirz/aiida-gudhi/master/setup.json",name:"aiida-gudhi",package_name:"aiida_gudhi",hosted_on:"github.com",metadata:{release_date:"2018-06-21",description:"AiiDA plugin for the [GUDHI](http://gudhi.gforge.inria.fr/) library for topological data analysis.",author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-gudhi",classifiers:["Programming Language :: Python"],version:"0.1.0a3"},aiida_version:"*",entry_points:{"aiida.calculations":{"gudhi.rdm":"aiida_gudhi.calculations.rips:RipsDistanceMatrixCalculation"},"aiida.data":{"gudhi.rdm":"aiida_gudhi.data.rips:RipsDistanceMatrixParameters"},"aiida.parsers":{"gudhi.rdm":"aiida_gudhi.parsers.rips:RipsParser"}},commits_count:0,errors:[],warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install --pre aiida-gudhi",is_installable:"True"},"aiida-gulp":{code_home:"https://github.com/aiidaplugins/aiida-gulp",development_status:"beta",documentation_url:"https://aiida-gulp.readthedocs.io",entry_point_prefix:"gulp",pip_url:"aiida-gulp",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-gulp/master/setup.json",name:"aiida-gulp",package_name:"aiida_gulp",hosted_on:"github.com",metadata:{release_date:"2019-10-30",description:"AiiDA plugin for running the GULP MD code",author:"Chris Sewell",author_email:"chrisj_sewell@hotmail.com",license:"MIT",home_page:"https://github.com/chrisjsewell/aiida-gulp",classifiers:["Framework :: AiiDA","Programming Language :: Python","Programming Language :: Python :: 2.7","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"0.10.0b5"},aiida_version:"1.0.0b5",entry_points:{"aiida.calculations":{"gulp.fitting":"aiida_gulp.calculations.gulp_fitting:GulpFittingCalculation","gulp.optimize":"aiida_gulp.calculations.gulp_optimize:GulpOptCalculation","gulp.single":"aiida_gulp.calculations.gulp_single:GulpSingleCalculation"},"aiida.cmdline.data":{"gulp.potentials":"aiida_gulp.cmndline.potentials:potentials"},"aiida.data":{"gulp.potential":"aiida_gulp.data.potential:EmpiricalPotential","gulp.symmetry":"aiida_gulp.data.symmetry:SymmetryData"},"aiida.parsers":{"gulp.fitting":"aiida_gulp.parsers.parse_fitting:GulpFittingParser","gulp.optimize":"aiida_gulp.parsers.parse_opt:GulpOptParser","gulp.single":"aiida_gulp.parsers.parse_single:GulpSingleParser"},"aiida.workflows":{},console_scripts:{gulp_mock:"aiida_gulp.tests.mock_gulp:main"},"gulp.potentials":{lj:"aiida_gulp.potentials.lj:PotentialWriterLJ",reaxff:"aiida_gulp.potentials.reaxff:PotentialWriterReaxff"}},commits_count:0,errors:[`Failed to install plugin aiida-gulp</br><pre>Collecting aiida-gulp
  Downloading aiida_gulp-0.10.0b5-py3-none-any.whl (287 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.6/287.6 kB 12.1 MB/s eta 0:00:00
Collecting aiida-core==1.0.0b5 (from aiida-gulp)
  Downloading aiida-core-1.0.0b5.tar.gz (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 28.8 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from aiida-gulp) (1.16.0)
Requirement already satisfied: ruamel.yaml in /opt/conda/lib/python3.9/site-packages (from aiida-gulp) (0.17.32)
Collecting jsonextended>=0.7.10 (from aiida-gulp)
  Downloading jsonextended-0.7.11-py2.py3-none-any.whl (466 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 466.9/466.9 kB 31.5 MB/s eta 0:00:00
Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from aiida-gulp) (3.2.0)
Collecting spglib<2.0.0,>=1.10.0 (from aiida-gulp)
  Downloading spglib-1.16.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 325.5/325.5 kB 36.9 MB/s eta 0:00:00
Collecting importlib-resources (from aiida-gulp)
  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/65/6e/09d8816b5cb7a4006ef8ad1717a2703ad9f331dae9717d9f22488a2d6469/importlib_resources-6.1.0-py3-none-any.whl.metadata
  Downloading importlib_resources-6.1.0-py3-none-any.whl.metadata (4.1 kB)
Collecting ase<4.0.0,>=3.12.0 (from aiida-gulp)
  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 42.5 MB/s eta 0:00:00
Collecting PyCifRW==4.4 (from aiida-gulp)
  Downloading PyCifRW-4.4.tar.gz (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 51.8 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting reentry>=1.3.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Collecting python-dateutil==2.8.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading python_dateutil-2.8.0-py2.py3-none-any.whl (226 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.8/226.8 kB 59.9 MB/s eta 0:00:00
Collecting django==1.11.20 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading Django-1.11.20-py2.py3-none-any.whl (6.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 75.8 MB/s eta 0:00:00
Collecting tzlocal==1.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading tzlocal-1.5.1.tar.gz (16 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting pytz==2018.9 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading pytz-2018.9-py2.py3-none-any.whl (510 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.7/510.7 kB 93.9 MB/s eta 0:00:00
Collecting PyYAML==3.13 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading PyYAML-3.13.tar.gz (270 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 270.6/270.6 kB 73.7 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting six>=1.12.0 (from aiida-gulp)
  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)
Collecting psutil==5.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading psutil-5.5.1.tar.gz (426 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 426.8/426.8 kB 90.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mock==2.0.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading mock-2.0.0-py2.py3-none-any.whl (56 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 23.3 MB/s eta 0:00:00
Collecting numpy==1.16.4 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading numpy-1.16.4.zip (5.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 105.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting SQLAlchemy==1.3.3 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading SQLAlchemy-1.3.3.tar.gz (5.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 119.9 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting SQLAlchemy-Utils==0.33.11 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading SQLAlchemy-Utils-0.33.11.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.0/128.0 kB 44.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting alembic==1.0.7 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading alembic-1.0.7.tar.gz (1.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 115.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aldjemy==0.9.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading aldjemy-0.9.1-py3-none-any.whl (26 kB)
Collecting passlib==1.7.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading passlib-1.7.1-py2.py3-none-any.whl (498 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 498.8/498.8 kB 92.3 MB/s eta 0:00:00
Collecting click==7.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.3/81.3 kB 32.9 MB/s eta 0:00:00
Collecting click-completion==0.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading click-completion-0.5.1.tar.gz (9.9 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting click-config-file==0.5.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading click_config_file-0.5.0-py2.py3-none-any.whl (5.8 kB)
Collecting click-spinner==0.1.8 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading click-spinner-0.1.8.tar.gz (18 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting tabulate==0.8.3 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading tabulate-0.8.3.tar.gz (46 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.2/46.2 kB 17.0 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting ete3==3.1.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading ete3-3.1.1.tar.gz (10.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.5/10.5 MB 110.5 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting uritools==2.2.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading uritools-2.2.0-py2.py3-none-any.whl (14 kB)
Collecting psycopg2-binary==2.8 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading psycopg2-binary-2.8.tar.gz (368 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 368.4/368.4 kB 84.5 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting paramiko==2.6.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading paramiko-2.6.0-py2.py3-none-any.whl (199 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.9/199.9 kB 58.8 MB/s eta 0:00:00
Collecting ipython<6.0,>=4.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading ipython-5.10.0-py3-none-any.whl (760 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760.3/760.3 kB 105.5 MB/s eta 0:00:00
Collecting plumpy==0.14.2 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading plumpy-0.14.2-py2.py3-none-any.whl (55 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.5/55.5 kB 21.0 MB/s eta 0:00:00
Collecting kiwipy[rmq]==0.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading kiwipy-0.5.1-py2.py3-none-any.whl (21 kB)
Collecting pika==1.0.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading pika-1.0.0-py2.py3-none-any.whl (148 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.5/148.5 kB 50.2 MB/s eta 0:00:00
Collecting circus==0.15.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading circus-0.15.0-py3-none-any.whl (190 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.8/190.8 kB 61.2 MB/s eta 0:00:00
Collecting tornado<5.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading tornado-4.5.3.tar.gz (484 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 484.2/484.2 kB 92.7 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting wrapt==1.11.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading wrapt-1.11.1.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting simplejson==3.16.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading simplejson-3.16.0.tar.gz (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.2/81.2 kB 28.4 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting graphviz==0.10.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading graphviz-0.10.1-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic==1.0.7->aiida-core==1.0.0b5->aiida-gulp) (1.2.4)
Collecting python-editor>=0.3 (from alembic==1.0.7->aiida-core==1.0.0b5->aiida-gulp)
  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)
Collecting pyzmq<17.0,>=13.1.0 (from circus==0.15.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading pyzmq-16.0.4.tar.gz (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 118.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from click-completion==0.5.1->aiida-core==1.0.0b5->aiida-gulp) (3.1.2)
Collecting shellingham (from click-completion==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Obtaining dependency information for shellingham from https://files.pythonhosted.org/packages/57/70/0265437683625b2e6491736706d3d679d90e2a26f6bff59f4e46e09872b9/shellingham-1.5.3-py2.py3-none-any.whl.metadata
  Downloading shellingham-1.5.3-py2.py3-none-any.whl.metadata (3.4 kB)
Collecting configobj>=5.0.6 (from click-config-file==0.5.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp) (1.0.11)
Collecting topika<0.3.0,>=0.2.0 (from kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Downloading topika-0.2.2-py2.py3-none-any.whl (36 kB)
Collecting pbr>=0.11 (from mock==2.0.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.7/112.7 kB 42.3 MB/s eta 0:00:00
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (4.0.1)
Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (41.0.4)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (1.5.0)
Collecting frozendict (from plumpy==0.14.2->aiida-core==1.0.0b5->aiida-gulp)
  Downloading frozendict-2.3.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.8/114.8 kB 41.9 MB/s eta 0:00:00
Collecting matplotlib>=3.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/e0/8b/b62bc50b01bb2d4af96bc0045c39d60209e2701e172789ceace20a0866b2/matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)
Collecting scipy>=1.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 23.1 MB/s eta 0:00:00
Collecting pathlib2 (from jsonextended>=0.7.10->aiida-gulp)
  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)
Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from importlib-resources->aiida-gulp) (3.17.0)
Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->aiida-gulp) (23.1.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->aiida-gulp) (0.19.3)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from jsonschema->aiida-gulp) (68.2.2)
Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.9/site-packages (from ruamel.yaml->aiida-gulp) (0.2.7)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (5.1.1)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (0.7.5)
Collecting simplegeneric>0.8 (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading simplegeneric-0.8.1.zip (12 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (5.10.0)
Collecting prompt-toolkit<2.0.0,>=1.0.4 (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 245.4/245.4 kB 69.9 MB/s eta 0:00:00
Collecting pygments<2.6 (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading Pygments-2.5.2-py2.py3-none-any.whl (896 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 896.1/896.1 kB 109.4 MB/s eta 0:00:00
Requirement already satisfied: pexpect in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (4.8.0)
Collecting contourpy>=1.0.1 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/2b/c0/24c34c41a180f875419b536125799c61e2330b997d77a5a818a3bc3e08cd/contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)
Collecting cycler>=0.10 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/49/50/2e31753c088d364756daa5bed0dab6a5928ebfd6e6d26f975c8b6d6f754a/fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.0/151.0 kB 52.8 MB/s eta 0:00:00
Collecting kiwisolver>=1.0.1 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata
  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)
INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.
Collecting matplotlib>=3.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/51/ce/5d08045689fbf933cb4481913e1320f8d9a8a1da8674ce2fb4a0cf020c52/matplotlib-3.8.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/ae/13/e2e86809b8d080a346aaaae78c89005b142683ec0af04acc4311837fc1c6/matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/47/b9/6c0daa9b953a80b4e6933bf6a11a2d0633f257e84ee5995c5fd35de564c9/matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)
  Downloading matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 117.5 MB/s eta 0:00:00
  Downloading matplotlib-3.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 117.7 MB/s eta 0:00:00
  Downloading matplotlib-3.7.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 16.6 MB/s eta 0:00:00
  Downloading matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 113.4 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.
  Downloading matplotlib-3.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 103.0 MB/s eta 0:00:00
  Downloading matplotlib-3.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 114.7 MB/s eta 0:00:00
  Downloading matplotlib-3.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 119.1 MB/s eta 0:00:00
  Downloading matplotlib-3.6.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 33.0 MB/s eta 0:00:00
  Downloading matplotlib-3.6.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 16.7 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading matplotlib-3.5.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 131.6 MB/s eta 0:00:00
  Downloading matplotlib-3.5.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 122.9 MB/s eta 0:00:00
  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 120.3 MB/s eta 0:00:00
  Downloading matplotlib-3.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 77.5 MB/s eta 0:00:00
  Downloading matplotlib-3.5.0rc1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.3/10.3 MB 38.3 MB/s eta 0:00:00
  Downloading matplotlib-3.5.0b1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.3/10.3 MB 125.8 MB/s eta 0:00:00
  Downloading matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.3/10.3 MB 129.0 MB/s eta 0:00:00
Collecting pillow>=6.2.0 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/0a/20/a94a0462495de73e248643fb24667270f2e67f44792456ab7207764e80cc/Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata
  Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
Collecting pyparsing>=2.2.1 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for pyparsing>=2.2.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata
  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)
INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.
Collecting scipy>=1.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/08/25/035fe07fc32c5a8b314f882faa9d4817223fa5faf524d3fedcf17a4b9d22/scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 23.0 MB/s eta 0:00:00
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/4f/fa/fc40251f769228ce4c74166cd6c1c9dc67a726d3ec178cf45ff8b39f4125/scipy-1.11.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 18.6 MB/s eta 0:00:00
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/2b/f3/d8e1860f67fbc2c0967f9d5465abf8aa4a9c85cf7d2d38d8bbae9d732d61/scipy-1.11.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 25.1 MB/s eta 0:00:00
  Downloading scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 73.9 MB/s eta 0:00:00
  Downloading scipy-1.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 74.5 MB/s eta 0:00:00
  Downloading scipy-1.10.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 49.7 MB/s eta 0:00:00
  Downloading scipy-1.10.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 69.9 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.
  Downloading scipy-1.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.8/33.8 MB 44.8 MB/s eta 0:00:00
  Downloading scipy-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.8/33.8 MB 52.2 MB/s eta 0:00:00
  Downloading scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 12.1 MB/s eta 0:00:00
  Downloading scipy-1.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 36.8 MB/s eta 0:00:00
  Downloading scipy-1.9.0rc3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 36.4 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading scipy-1.9.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 27.4 MB/s eta 0:00:00
  Downloading scipy-1.9.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 30.3 MB/s eta 0:00:00
  Downloading scipy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.2/42.2 MB 56.1 MB/s eta 0:00:00
  Downloading scipy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 61.2 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 23.7 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.5/42.5 MB 18.6 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.5/42.5 MB 6.0 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.0/103.0 MB 20.9 MB/s eta 0:00:00
  Downloading scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.8/39.8 MB 53.3 MB/s eta 0:00:00
  Downloading scipy-1.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.8/39.8 MB 54.4 MB/s eta 0:00:00
  Downloading scipy-1.7.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.5/28.5 MB 62.3 MB/s eta 0:00:00
  Downloading scipy-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.4/28.4 MB 71.3 MB/s eta 0:00:00
  Downloading scipy-1.6.3-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 76.1 MB/s eta 0:00:00
  Downloading scipy-1.6.2-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 77.3 MB/s eta 0:00:00
  Downloading scipy-1.6.1-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 76.7 MB/s eta 0:00:00
  Downloading scipy-1.6.0-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 75.0 MB/s eta 0:00:00
  Downloading scipy-1.5.4-cp39-cp39-manylinux1_x86_64.whl (25.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.8/25.8 MB 74.4 MB/s eta 0:00:00
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (1.15.1)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (0.2.6)
Collecting furl (from topika<0.3.0,>=0.2.0->kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Downloading furl-2.1.3-py2.py3-none-any.whl (20 kB)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->click-completion==0.5.1->aiida-core==1.0.0b5->aiida-gulp) (2.1.3)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect->ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (0.7.0)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (2.21)
Collecting orderedmultidict>=1.0.1 (from furl->topika<0.3.0,>=0.2.0->kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)
Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)
Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 112.7 MB/s eta 0:00:00
Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl (3.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 130.3 MB/s eta 0:00:00
Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 36.6 MB/s eta 0:00:00
Downloading shellingham-1.5.3-py2.py3-none-any.whl (9.7 kB)
Building wheels for collected packages: aiida-core, PyCifRW, alembic, click-completion, click-spinner, ete3, numpy, psutil, psycopg2-binary, PyYAML, simplejson, SQLAlchemy, SQLAlchemy-Utils, tabulate, tzlocal, wrapt, tornado, pyzmq, simplegeneric
  Building wheel for aiida-core (pyproject.toml): started
  Building wheel for aiida-core (pyproject.toml): finished with status 'done'
  Created wheel for aiida-core: filename=aiida_core-1.0.0b5-py3-none-any.whl size=1644687 sha256=66f9fc11904ad410e7a8d96ab1c61d11bdf13536026fac6327093e40979318ba
  Stored in directory: /home/aiida/.cache/pip/wheels/8a/72/83/372726a098884bcb5312014dd9afea8d656001214d9cf1f87e
  Building wheel for PyCifRW (setup.py): started
  Building wheel for PyCifRW (setup.py): finished with status 'done'
  Created wheel for PyCifRW: filename=PyCifRW-4.4-cp39-cp39-linux_x86_64.whl size=140950 sha256=b666361d835361e1f5a15fdf149117f3a0c61d5903daad96b3163a1904fd4cba
  Stored in directory: /home/aiida/.cache/pip/wheels/0f/58/a7/cc7faa4fb4aca4aa925bb632cd9ede3f97520dbdceb7975b49
  Building wheel for alembic (setup.py): started
  Building wheel for alembic (setup.py): finished with status 'done'
  Created wheel for alembic: filename=alembic-1.0.7-py2.py3-none-any.whl size=159962 sha256=b050ddbfda984e39cb28a5e8a55c947053b742b5ae93bdbbf8774f240d35e695
  Stored in directory: /home/aiida/.cache/pip/wheels/82/b8/9e/c185107e13961fb24d40591e1462184822350e9e1726256548
  Building wheel for click-completion (setup.py): started
  Building wheel for click-completion (setup.py): finished with status 'done'
  Created wheel for click-completion: filename=click_completion-0.5.1-py3-none-any.whl size=11139 sha256=d9a8f5c8367a8a5ce6c1673af8a7260f58e302b78ddd48d9949bd2e91230fdf5
  Stored in directory: /home/aiida/.cache/pip/wheels/ca/96/9b/cbfb172bf9db477384dc8a81aeb271c9a3f8823014518c4a1e
  Building wheel for click-spinner (setup.py): started
  Building wheel for click-spinner (setup.py): finished with status 'done'
  Created wheel for click-spinner: filename=click_spinner-0.1.8-py2.py3-none-any.whl size=3090 sha256=174f5d3e9a1806c125136f1f089ee16f6e93f0ca29fb983e8fe4b4f001f96509
  Stored in directory: /home/aiida/.cache/pip/wheels/ef/24/c6/ce0be37cb054b4accfee5709b8673ebe6b728e560a20ec0347
  Building wheel for ete3 (setup.py): started
  Building wheel for ete3 (setup.py): finished with status 'done'
  Created wheel for ete3: filename=ete3-3.1.1-py3-none-any.whl size=2226275 sha256=806fbbe2cd0e92da2cbba11fb54a979bf0870f4212e35e42c72a67596e47bf45
  Stored in directory: /home/aiida/.cache/pip/wheels/a2/cc/4d/a94e20c2d23e79a31e217bbc5fb0c6d1b0ab0bf90ffe04cd26
  Building wheel for numpy (setup.py): started
  Building wheel for numpy (setup.py): still running...
  Building wheel for numpy (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [3102 lines of output]
      Running from numpy source directory.
      /tmp/pip-install-co8fipfm/numpy_b3aa5591c7cf4753a7288626636208ac/numpy/distutils/misc_util.py:476: SyntaxWarning: "is" with a literal. Did you mean "=="?
        return is_string(s) and ('*' in s or '?' is s)
      blas_opt_info:
      blas_mkl_info:
      customize UnixCCompiler
        libraries mkl_rt not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      blis_info:
      customize UnixCCompiler
        libraries blis not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      openblas_info:
      customize UnixCCompiler
      customize UnixCCompiler
        libraries openblas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_3_10_blas_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries tatlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_3_10_blas_info:
      customize UnixCCompiler
        libraries satlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_blas_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_blas_info:
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      accelerate_info:
        NOT AVAILABLE
      
      /tmp/pip-install-co8fipfm/numpy_b3aa5591c7cf4753a7288626636208ac/numpy/distutils/system_info.py:639: UserWarning:
          Atlas (http://math-atlas.sourceforge.net/) libraries not found.
          Directories to search for the libraries can be specified in the
          numpy/distutils/site.cfg file (section [atlas]) or by setting
          the ATLAS environment variable.
        self.calc_info()
      blas_info:
      customize UnixCCompiler
        libraries blas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      /tmp/pip-install-co8fipfm/numpy_b3aa5591c7cf4753a7288626636208ac/numpy/distutils/system_info.py:639: UserWarning:
          Blas (http://www.netlib.org/blas/) libraries not found.
          Directories to search for the libraries can be specified in the
          numpy/distutils/site.cfg file (section [blas]) or by setting
          the BLAS environment variable.
        self.calc_info()
      blas_src_info:
        NOT AVAILABLE
      
      /tmp/pip-install-co8fipfm/numpy_b3aa5591c7cf4753a7288626636208ac/numpy/distutils/system_info.py:639: UserWarning:
          Blas (http://www.netlib.org/blas/) sources not found.
          Directories to search for the sources can be specified in the
          numpy/distutils/site.cfg file (section [blas_src]) or by setting
          the BLAS_SRC environment variable.
        self.calc_info()
        NOT AVAILABLE
      
      /bin/sh: 1: svnversion: not found
      non-existing path in 'numpy/distutils': 'site.cfg'
      lapack_opt_info:
      lapack_mkl_info:
      customize UnixCCompiler
        libraries mkl_rt not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      openblas_lapack_info:
      customize UnixCCompiler
      customize UnixCCompiler
        libraries openblas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      openblas_clapack_info:
      customize UnixCCompiler
      customize UnixCCompiler
        libraries openblas,lapack not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_3_10_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>
        NOT AVAILABLE
      
      atlas_3_10_info:
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries satlas,satlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_3_10_info'>
        NOT AVAILABLE
      
      atlas_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_threads_info'>
        NOT AVAILABLE
      
      atlas_info:
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_info'>
        NOT AVAILABLE
      
      lapack_info:
      customize UnixCCompiler
        libraries lapack not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      /tmp/pip-install-co8fipfm/numpy_b3aa5591c7cf4753a7288626636208ac/numpy/distutils/system_info.py:639: UserWarning:
          Lapack (http://www.netlib.org/lapack/) libraries not found.
          Directories to search for the libraries can be specified in the
          numpy/distutils/site.cfg file (section [lapack]) or by setting
          the LAPACK environment variable.
        self.calc_info()
      lapack_src_info:
        NOT AVAILABLE
      
      /tmp/pip-install-co8fipfm/numpy_b3aa5591c7cf4753a7288626636208ac/numpy/distutils/system_info.py:639: UserWarning:
          Lapack (http://www.netlib.org/lapack/) sources not found.
          Directories to search for the sources can be specified in the
          numpy/distutils/site.cfg file (section [lapack_src]) or by setting
          the LAPACK_SRC environment variable.
        self.calc_info()
        NOT AVAILABLE
      
      /opt/conda/lib/python3.9/site-packages/setuptools/_distutils/dist.py:265: UserWarning: Unknown distribution option: 'define_macros'
        warnings.warn(msg)
      running bdist_wheel
      running build
      running config_cc
      unifing config_cc, config, build_clib, build_ext, build commands --compiler options
      running config_fc
      unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options
      running build_src
      build_src
      building py_modules sources
      creating build
      creating build/src.linux-x86_64-3.9
      creating build/src.linux-x86_64-3.9/numpy
      creating build/src.linux-x86_64-3.9/numpy/distutils
      building library "npymath" sources
      get_default_fcompiler: matching types: '['gnu95', 'intel', 'lahey', 'pg', 'absoft', 'nag', 'vast', 'compaq', 'intele', 'intelem', 'gnu', 'g95', 'pathf95', 'nagfor']'
      customize Gnu95FCompiler
      Could not locate executable gfortran
      Could not locate executable f95
      customize IntelFCompiler
      Could not locate executable ifort
      Could not locate executable ifc
      customize LaheyFCompiler
      Could not locate executable lf95
      customize PGroupFCompiler
      Could not locate executable pgfortran
      customize AbsoftFCompiler
      Could not locate executable f90
      Could not locate executable f77
      customize NAGFCompiler
      customize VastFCompiler
      customize CompaqFCompiler
      Could not locate executable fort
      customize IntelItaniumFCompiler
      Could not locate executable efort
      Could not locate executable efc
      customize IntelEM64TFCompiler
      customize GnuFCompiler
      Could not locate executable g77
      customize G95FCompiler
      Could not locate executable g95
      customize PathScaleFCompiler
      Could not locate executable pathf95
      customize NAGFORCompiler
      Could not locate executable nagfor
      don't know how to compile Fortran code on platform 'posix'
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      /opt/conda/compiler_compat/ld: _configtest.o: in function \`main':
      _configtest.c:(.text.startup+0x9): undefined reference to \`exp'
      collect2: error: ld returned 1 exit status
      failure.
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      creating build/src.linux-x86_64-3.9/numpy/core
      creating build/src.linux-x86_64-3.9/numpy/core/src
      creating build/src.linux-x86_64-3.9/numpy/core/src/npymath
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_internal.h
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/npymath' to include_dirs.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.c
      None - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_internal.h']
      building library "npysort" sources
      creating build/src.linux-x86_64-3.9/numpy/core/src/common
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/npy_sort.h
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/common' to include_dirs.
      creating build/src.linux-x86_64-3.9/numpy/core/src/npysort
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/mergesort.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/heapsort.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/npy_partition.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/selection.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/npy_binsearch.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/binsearch.c
      None - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/src/common/npy_sort.h', 'build/src.linux-x86_64-3.9/numpy/core/src/common/npy_partition.h', 'build/src.linux-x86_64-3.9/numpy/core/src/common/npy_binsearch.h']
      building extension "numpy.core._dummy" sources
      Generating build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:10: fatal error: sys/endian.h: No such file or directory
          1 | #include <sys/endian.h>
            |          ^~~~~~~~~~~~~~
      compilation terminated.
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 4)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 16)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:12: error: ‘SIZEOF_LONGDOUBLE’ undeclared (first use in this function); did you mean ‘SIZEOF_LONG_DOUBLE’?
          7 |     (void) SIZEOF_LONGDOUBLE;
            |            ^~~~~~~~~~~~~~~~~
            |            SIZEOF_LONG_DOUBLE
      _configtest.c:7:12: note: each undeclared identifier is reported only once for each function it appears in
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 16)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 32)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      /opt/conda/compiler_compat/ld: _configtest.o: in function \`main':
      _configtest.c:(.text.startup+0x9): undefined reference to \`exp'
      collect2: error: ld returned 1 exit status
      failure.
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘sin’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int sin (void);
            |     ^~~
      _configtest.c:1:1: note: ‘sin’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int sin (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cos’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cos (void);
            |     ^~~
      _configtest.c:2:5: note: ‘cos’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘tan’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          3 | int tan (void);
            |     ^~~
      _configtest.c:3:5: note: ‘tan’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘sinh’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          4 | int sinh (void);
            |     ^~~~
      _configtest.c:4:5: note: ‘sinh’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘cosh’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          5 | int cosh (void);
            |     ^~~~
      _configtest.c:5:5: note: ‘cosh’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘tanh’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          6 | int tanh (void);
            |     ^~~~
      _configtest.c:6:5: note: ‘tanh’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘fabs’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          7 | int fabs (void);
            |     ^~~~
      _configtest.c:7:5: note: ‘fabs’ is declared in header ‘<math.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘floor’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          8 | int floor (void);
            |     ^~~~~
      _configtest.c:8:5: note: ‘floor’ is declared in header ‘<math.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ceil’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ceil (void);
            |     ^~~~
      _configtest.c:9:5: note: ‘ceil’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘sqrt’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         10 | int sqrt (void);
            |     ^~~~
      _configtest.c:10:5: note: ‘sqrt’ is declared in header ‘<math.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘log10’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         11 | int log10 (void);
            |     ^~~~~
      _configtest.c:11:5: note: ‘log10’ is declared in header ‘<math.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘log’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         12 | int log (void);
            |     ^~~
      _configtest.c:12:5: note: ‘log’ is declared in header ‘<math.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         13 | int exp (void);
            |     ^~~
      _configtest.c:13:5: note: ‘exp’ is declared in header ‘<math.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘asin’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         14 | int asin (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘asin’ is declared in header ‘<math.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘acos’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         15 | int acos (void);
            |     ^~~~
      _configtest.c:15:5: note: ‘acos’ is declared in header ‘<math.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘atan’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         16 | int atan (void);
            |     ^~~~
      _configtest.c:16:5: note: ‘atan’ is declared in header ‘<math.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘fmod’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
         17 | int fmod (void);
            |     ^~~~
      _configtest.c:17:5: note: ‘fmod’ is declared in header ‘<math.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘modf’; expected ‘double(double,  double *)’ [-Wbuiltin-declaration-mismatch]
         18 | int modf (void);
            |     ^~~~
      _configtest.c:18:5: note: ‘modf’ is declared in header ‘<math.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘frexp’; expected ‘double(double,  int *)’ [-Wbuiltin-declaration-mismatch]
         19 | int frexp (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘frexp’ is declared in header ‘<math.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘ldexp’; expected ‘double(double,  int)’ [-Wbuiltin-declaration-mismatch]
         20 | int ldexp (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘ldexp’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘rint’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int rint (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘rint’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int rint (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘trunc’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          2 | int trunc (void);
            |     ^~~~~
      _configtest.c:2:5: note: ‘trunc’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘exp2’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          3 | int exp2 (void);
            |     ^~~~
      _configtest.c:3:5: note: ‘exp2’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘log2’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          4 | int log2 (void);
            |     ^~~~
      _configtest.c:4:5: note: ‘log2’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘atan2’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
          5 | int atan2 (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘atan2’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘pow’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
          6 | int pow (void);
            |     ^~~
      _configtest.c:6:5: note: ‘pow’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘nextafter’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
          7 | int nextafter (void);
            |     ^~~~~~~~~
      _configtest.c:7:5: note: ‘nextafter’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘cbrt’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         10 | int cbrt (void);
            |     ^~~~
      _configtest.c:10:5: note: ‘cbrt’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:10: fatal error: xlocale.h: No such file or directory
          1 | #include <xlocale.h>
            |          ^~~~~~~~~~~
      compilation terminated.
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_isnan(5.);
            |   ^~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_isinf(5.);
            |   ^~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_isfinite(5.);
            |   ^~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_bswap32(5u);
            |   ^~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_bswap64(5u);
            |   ^~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_expect(5, 0);
            |   ^~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: right-hand operand of comma expression has no effect [-Wunused-value]
          5 |   __builtin_mul_overflow(5, 5, (int*)5);
            |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: unused variable ‘r’ [-Wunused-variable]
          7 |   volatile int r = __builtin_cpu_supports("sse");
            |                ^
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      _configtest.c: In function ‘__declspec’:
      _configtest.c:5:24: error: expected declaration specifiers before ‘foo’
          5 | int __declspec(thread) foo;
            |                        ^~~
      _configtest.c:9:1: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘{’ token
          9 | {
            | ^
      _configtest.c:5:5: warning: type of ‘thread’ defaults to ‘int’ [-Wimplicit-int]
          5 | int __declspec(thread) foo;
            |     ^~~~~~~~~~
      _configtest.c:12: error: expected ‘{’ at end of input
      _configtest.c:12: warning: control reaches end of non-void function [-Wreturn-type]
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘sinf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          1 | int sinf (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘sinf’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int sinf (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cosf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          2 | int cosf (void);
            |     ^~~~
      _configtest.c:2:5: note: ‘cosf’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘tanf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          3 | int tanf (void);
            |     ^~~~
      _configtest.c:3:5: note: ‘tanf’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘sinhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          4 | int sinhf (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘sinhf’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘coshf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          5 | int coshf (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘coshf’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘tanhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          6 | int tanhf (void);
            |     ^~~~~
      _configtest.c:6:5: note: ‘tanhf’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘fabsf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          7 | int fabsf (void);
            |     ^~~~~
      _configtest.c:7:5: note: ‘fabsf’ is declared in header ‘<math.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘floorf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          8 | int floorf (void);
            |     ^~~~~~
      _configtest.c:8:5: note: ‘floorf’ is declared in header ‘<math.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ceilf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          9 | int ceilf (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ceilf’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘rintf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         10 | int rintf (void);
            |     ^~~~~
      _configtest.c:10:5: note: ‘rintf’ is declared in header ‘<math.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘truncf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         11 | int truncf (void);
            |     ^~~~~~
      _configtest.c:11:5: note: ‘truncf’ is declared in header ‘<math.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘sqrtf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         12 | int sqrtf (void);
            |     ^~~~~
      _configtest.c:12:5: note: ‘sqrtf’ is declared in header ‘<math.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘log10f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         13 | int log10f (void);
            |     ^~~~~~
      _configtest.c:13:5: note: ‘log10f’ is declared in header ‘<math.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘logf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         14 | int logf (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘logf’ is declared in header ‘<math.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘log1pf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         15 | int log1pf (void);
            |     ^~~~~~
      _configtest.c:15:5: note: ‘log1pf’ is declared in header ‘<math.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘expf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         16 | int expf (void);
            |     ^~~~
      _configtest.c:16:5: note: ‘expf’ is declared in header ‘<math.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘expm1f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         17 | int expm1f (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘expm1f’ is declared in header ‘<math.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘asinf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         18 | int asinf (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘asinf’ is declared in header ‘<math.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘acosf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         19 | int acosf (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘acosf’ is declared in header ‘<math.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘atanf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         20 | int atanf (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘atanf’ is declared in header ‘<math.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘asinhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         21 | int asinhf (void);
            |     ^~~~~~
      _configtest.c:21:5: note: ‘asinhf’ is declared in header ‘<math.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘acoshf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         22 | int acoshf (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘acoshf’ is declared in header ‘<math.h>’
      _configtest.c:23:5: warning: conflicting types for built-in function ‘atanhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         23 | int atanhf (void);
            |     ^~~~~~
      _configtest.c:23:5: note: ‘atanhf’ is declared in header ‘<math.h>’
      _configtest.c:24:5: warning: conflicting types for built-in function ‘hypotf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         24 | int hypotf (void);
            |     ^~~~~~
      _configtest.c:24:5: note: ‘hypotf’ is declared in header ‘<math.h>’
      _configtest.c:25:5: warning: conflicting types for built-in function ‘atan2f’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         25 | int atan2f (void);
            |     ^~~~~~
      _configtest.c:25:5: note: ‘atan2f’ is declared in header ‘<math.h>’
      _configtest.c:26:5: warning: conflicting types for built-in function ‘powf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         26 | int powf (void);
            |     ^~~~
      _configtest.c:26:5: note: ‘powf’ is declared in header ‘<math.h>’
      _configtest.c:27:5: warning: conflicting types for built-in function ‘fmodf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         27 | int fmodf (void);
            |     ^~~~~
      _configtest.c:27:5: note: ‘fmodf’ is declared in header ‘<math.h>’
      _configtest.c:28:5: warning: conflicting types for built-in function ‘modff’; expected ‘float(float,  float *)’ [-Wbuiltin-declaration-mismatch]
         28 | int modff (void);
            |     ^~~~~
      _configtest.c:28:5: note: ‘modff’ is declared in header ‘<math.h>’
      _configtest.c:29:5: warning: conflicting types for built-in function ‘frexpf’; expected ‘float(float,  int *)’ [-Wbuiltin-declaration-mismatch]
         29 | int frexpf (void);
            |     ^~~~~~
      _configtest.c:29:5: note: ‘frexpf’ is declared in header ‘<math.h>’
      _configtest.c:30:5: warning: conflicting types for built-in function ‘ldexpf’; expected ‘float(float,  int)’ [-Wbuiltin-declaration-mismatch]
         30 | int ldexpf (void);
            |     ^~~~~~
      _configtest.c:30:5: note: ‘ldexpf’ is declared in header ‘<math.h>’
      _configtest.c:31:5: warning: conflicting types for built-in function ‘exp2f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         31 | int exp2f (void);
            |     ^~~~~
      _configtest.c:31:5: note: ‘exp2f’ is declared in header ‘<math.h>’
      _configtest.c:32:5: warning: conflicting types for built-in function ‘log2f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         32 | int log2f (void);
            |     ^~~~~
      _configtest.c:32:5: note: ‘log2f’ is declared in header ‘<math.h>’
      _configtest.c:33:5: warning: conflicting types for built-in function ‘copysignf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         33 | int copysignf (void);
            |     ^~~~~~~~~
      _configtest.c:33:5: note: ‘copysignf’ is declared in header ‘<math.h>’
      _configtest.c:34:5: warning: conflicting types for built-in function ‘nextafterf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         34 | int nextafterf (void);
            |     ^~~~~~~~~~
      _configtest.c:34:5: note: ‘nextafterf’ is declared in header ‘<math.h>’
      _configtest.c:35:5: warning: conflicting types for built-in function ‘cbrtf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         35 | int cbrtf (void);
            |     ^~~~~
      _configtest.c:35:5: note: ‘cbrtf’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘sinl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          1 | int sinl (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘sinl’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int sinl (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cosl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cosl (void);
            |     ^~~~
      _configtest.c:2:5: note: ‘cosl’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘tanl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          3 | int tanl (void);
            |     ^~~~
      _configtest.c:3:5: note: ‘tanl’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘sinhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          4 | int sinhl (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘sinhl’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘coshl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          5 | int coshl (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘coshl’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘tanhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          6 | int tanhl (void);
            |     ^~~~~
      _configtest.c:6:5: note: ‘tanhl’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘fabsl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          7 | int fabsl (void);
            |     ^~~~~
      _configtest.c:7:5: note: ‘fabsl’ is declared in header ‘<math.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘floorl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          8 | int floorl (void);
            |     ^~~~~~
      _configtest.c:8:5: note: ‘floorl’ is declared in header ‘<math.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ceill’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ceill (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ceill’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘rintl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         10 | int rintl (void);
            |     ^~~~~
      _configtest.c:10:5: note: ‘rintl’ is declared in header ‘<math.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘truncl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         11 | int truncl (void);
            |     ^~~~~~
      _configtest.c:11:5: note: ‘truncl’ is declared in header ‘<math.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘sqrtl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         12 | int sqrtl (void);
            |     ^~~~~
      _configtest.c:12:5: note: ‘sqrtl’ is declared in header ‘<math.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘log10l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         13 | int log10l (void);
            |     ^~~~~~
      _configtest.c:13:5: note: ‘log10l’ is declared in header ‘<math.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘logl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         14 | int logl (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘logl’ is declared in header ‘<math.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘log1pl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         15 | int log1pl (void);
            |     ^~~~~~
      _configtest.c:15:5: note: ‘log1pl’ is declared in header ‘<math.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘expl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         16 | int expl (void);
            |     ^~~~
      _configtest.c:16:5: note: ‘expl’ is declared in header ‘<math.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘expm1l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         17 | int expm1l (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘expm1l’ is declared in header ‘<math.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘asinl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         18 | int asinl (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘asinl’ is declared in header ‘<math.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘acosl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         19 | int acosl (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘acosl’ is declared in header ‘<math.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘atanl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         20 | int atanl (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘atanl’ is declared in header ‘<math.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘asinhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         21 | int asinhl (void);
            |     ^~~~~~
      _configtest.c:21:5: note: ‘asinhl’ is declared in header ‘<math.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘acoshl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         22 | int acoshl (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘acoshl’ is declared in header ‘<math.h>’
      _configtest.c:23:5: warning: conflicting types for built-in function ‘atanhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         23 | int atanhl (void);
            |     ^~~~~~
      _configtest.c:23:5: note: ‘atanhl’ is declared in header ‘<math.h>’
      _configtest.c:24:5: warning: conflicting types for built-in function ‘hypotl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         24 | int hypotl (void);
            |     ^~~~~~
      _configtest.c:24:5: note: ‘hypotl’ is declared in header ‘<math.h>’
      _configtest.c:25:5: warning: conflicting types for built-in function ‘atan2l’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         25 | int atan2l (void);
            |     ^~~~~~
      _configtest.c:25:5: note: ‘atan2l’ is declared in header ‘<math.h>’
      _configtest.c:26:5: warning: conflicting types for built-in function ‘powl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         26 | int powl (void);
            |     ^~~~
      _configtest.c:26:5: note: ‘powl’ is declared in header ‘<math.h>’
      _configtest.c:27:5: warning: conflicting types for built-in function ‘fmodl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         27 | int fmodl (void);
            |     ^~~~~
      _configtest.c:27:5: note: ‘fmodl’ is declared in header ‘<math.h>’
      _configtest.c:28:5: warning: conflicting types for built-in function ‘modfl’; expected ‘long double(long double,  long double *)’ [-Wbuiltin-declaration-mismatch]
         28 | int modfl (void);
            |     ^~~~~
      _configtest.c:28:5: note: ‘modfl’ is declared in header ‘<math.h>’
      _configtest.c:29:5: warning: conflicting types for built-in function ‘frexpl’; expected ‘long double(long double,  int *)’ [-Wbuiltin-declaration-mismatch]
         29 | int frexpl (void);
            |     ^~~~~~
      _configtest.c:29:5: note: ‘frexpl’ is declared in header ‘<math.h>’
      _configtest.c:30:5: warning: conflicting types for built-in function ‘ldexpl’; expected ‘long double(long double,  int)’ [-Wbuiltin-declaration-mismatch]
         30 | int ldexpl (void);
            |     ^~~~~~
      _configtest.c:30:5: note: ‘ldexpl’ is declared in header ‘<math.h>’
      _configtest.c:31:5: warning: conflicting types for built-in function ‘exp2l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         31 | int exp2l (void);
            |     ^~~~~
      _configtest.c:31:5: note: ‘exp2l’ is declared in header ‘<math.h>’
      _configtest.c:32:5: warning: conflicting types for built-in function ‘log2l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         32 | int log2l (void);
            |     ^~~~~
      _configtest.c:32:5: note: ‘log2l’ is declared in header ‘<math.h>’
      _configtest.c:33:5: warning: conflicting types for built-in function ‘copysignl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         33 | int copysignl (void);
            |     ^~~~~~~~~
      _configtest.c:33:5: note: ‘copysignl’ is declared in header ‘<math.h>’
      _configtest.c:34:5: warning: conflicting types for built-in function ‘nextafterl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         34 | int nextafterl (void);
            |     ^~~~~~~~~~
      _configtest.c:34:5: note: ‘nextafterl’ is declared in header ‘<math.h>’
      _configtest.c:35:5: warning: conflicting types for built-in function ‘cbrtl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         35 | int cbrtl (void);
            |     ^~~~~
      _configtest.c:35:5: note: ‘cbrtl’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:8:12: error: ‘HAVE_DECL_SIGNBIT’ undeclared (first use in this function); did you mean ‘HAVE_DECL_ISNAN’?
          8 |     (void) HAVE_DECL_SIGNBIT;
            |            ^~~~~~~~~~~~~~~~~
            |            HAVE_DECL_ISNAN
      _configtest.c:8:12: note: each undeclared identifier is reported only once for each function it appears in
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘cabs’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          1 | int cabs (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘cabs’ is declared in header ‘<complex.h>’
        +++ |+#include <complex.h>
          1 | int cabs (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cacos’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cacos (void);
            |     ^~~~~
      _configtest.c:2:5: note: ‘cacos’ is declared in header ‘<complex.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘cacosh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          3 | int cacosh (void);
            |     ^~~~~~
      _configtest.c:3:5: note: ‘cacosh’ is declared in header ‘<complex.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘carg’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          4 | int carg (void);
            |     ^~~~
      _configtest.c:4:5: note: ‘carg’ is declared in header ‘<complex.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘casin’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          5 | int casin (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘casin’ is declared in header ‘<complex.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘casinh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          6 | int casinh (void);
            |     ^~~~~~
      _configtest.c:6:5: note: ‘casinh’ is declared in header ‘<complex.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘catan’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          7 | int catan (void);
            |     ^~~~~
      _configtest.c:7:5: note: ‘catan’ is declared in header ‘<complex.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘catanh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          8 | int catanh (void);
            |     ^~~~~~
      _configtest.c:8:5: note: ‘catanh’ is declared in header ‘<complex.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ccos’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ccos (void);
            |     ^~~~
      _configtest.c:9:5: note: ‘ccos’ is declared in header ‘<complex.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘ccosh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         10 | int ccosh (void);
            |     ^~~~~
      _configtest.c:10:5: note: ‘ccosh’ is declared in header ‘<complex.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘cexp’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         11 | int cexp (void);
            |     ^~~~
      _configtest.c:11:5: note: ‘cexp’ is declared in header ‘<complex.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘cimag’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         12 | int cimag (void);
            |     ^~~~~
      _configtest.c:12:5: note: ‘cimag’ is declared in header ‘<complex.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘clog’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         13 | int clog (void);
            |     ^~~~
      _configtest.c:13:5: note: ‘clog’ is declared in header ‘<complex.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘conj’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         14 | int conj (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘conj’ is declared in header ‘<complex.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘cpow’; expected ‘_Complex double(_Complex double,  _Complex double)’ [-Wbuiltin-declaration-mismatch]
         15 | int cpow (void);
            |     ^~~~
      _configtest.c:15:5: note: ‘cpow’ is declared in header ‘<complex.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘cproj’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         16 | int cproj (void);
            |     ^~~~~
      _configtest.c:16:5: note: ‘cproj’ is declared in header ‘<complex.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘creal’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         17 | int creal (void);
            |     ^~~~~
      _configtest.c:17:5: note: ‘creal’ is declared in header ‘<complex.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘csin’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         18 | int csin (void);
            |     ^~~~
      _configtest.c:18:5: note: ‘csin’ is declared in header ‘<complex.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘csinh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         19 | int csinh (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘csinh’ is declared in header ‘<complex.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘csqrt’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         20 | int csqrt (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘csqrt’ is declared in header ‘<complex.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘ctan’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         21 | int ctan (void);
            |     ^~~~
      _configtest.c:21:5: note: ‘ctan’ is declared in header ‘<complex.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘ctanh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         22 | int ctanh (void);
            |     ^~~~~
      _configtest.c:22:5: note: ‘ctanh’ is declared in header ‘<complex.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘cabsf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          1 | int cabsf (void);
            |     ^~~~~
      _configtest.c:1:1: note: ‘cabsf’ is declared in header ‘<complex.h>’
        +++ |+#include <complex.h>
          1 | int cabsf (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cacosf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          2 | int cacosf (void);
            |     ^~~~~~
      _configtest.c:2:5: note: ‘cacosf’ is declared in header ‘<complex.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘cacoshf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          3 | int cacoshf (void);
            |     ^~~~~~~
      _configtest.c:3:5: note: ‘cacoshf’ is declared in header ‘<complex.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘cargf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          4 | int cargf (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘cargf’ is declared in header ‘<complex.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘casinf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          5 | int casinf (void);
            |     ^~~~~~
      _configtest.c:5:5: note: ‘casinf’ is declared in header ‘<complex.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘casinhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          6 | int casinhf (void);
            |     ^~~~~~~
      _configtest.c:6:5: note: ‘casinhf’ is declared in header ‘<complex.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘catanf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          7 | int catanf (void);
            |     ^~~~~~
      _configtest.c:7:5: note: ‘catanf’ is declared in header ‘<complex.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘catanhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          8 | int catanhf (void);
            |     ^~~~~~~
      _configtest.c:8:5: note: ‘catanhf’ is declared in header ‘<complex.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ccosf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          9 | int ccosf (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ccosf’ is declared in header ‘<complex.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘ccoshf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         10 | int ccoshf (void);
            |     ^~~~~~
      _configtest.c:10:5: note: ‘ccoshf’ is declared in header ‘<complex.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘cexpf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         11 | int cexpf (void);
            |     ^~~~~
      _configtest.c:11:5: note: ‘cexpf’ is declared in header ‘<complex.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘cimagf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         12 | int cimagf (void);
            |     ^~~~~~
      _configtest.c:12:5: note: ‘cimagf’ is declared in header ‘<complex.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘clogf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         13 | int clogf (void);
            |     ^~~~~
      _configtest.c:13:5: note: ‘clogf’ is declared in header ‘<complex.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘conjf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         14 | int conjf (void);
            |     ^~~~~
      _configtest.c:14:5: note: ‘conjf’ is declared in header ‘<complex.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘cpowf’; expected ‘_Complex float(_Complex float,  _Complex float)’ [-Wbuiltin-declaration-mismatch]
         15 | int cpowf (void);
            |     ^~~~~
      _configtest.c:15:5: note: ‘cpowf’ is declared in header ‘<complex.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘cprojf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         16 | int cprojf (void);
            |     ^~~~~~
      _configtest.c:16:5: note: ‘cprojf’ is declared in header ‘<complex.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘crealf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         17 | int crealf (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘crealf’ is declared in header ‘<complex.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘csinf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         18 | int csinf (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘csinf’ is declared in header ‘<complex.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘csinhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         19 | int csinhf (void);
            |     ^~~~~~
      _configtest.c:19:5: note: ‘csinhf’ is declared in header ‘<complex.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘csqrtf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         20 | int csqrtf (void);
            |     ^~~~~~
      _configtest.c:20:5: note: ‘csqrtf’ is declared in header ‘<complex.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘ctanf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         21 | int ctanf (void);
            |     ^~~~~
      _configtest.c:21:5: note: ‘ctanf’ is declared in header ‘<complex.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘ctanhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         22 | int ctanhf (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘ctanhf’ is declared in header ‘<complex.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘cabsl’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          1 | int cabsl (void);
            |     ^~~~~
      _configtest.c:1:1: note: ‘cabsl’ is declared in header ‘<complex.h>’
        +++ |+#include <complex.h>
          1 | int cabsl (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cacosl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cacosl (void);
            |     ^~~~~~
      _configtest.c:2:5: note: ‘cacosl’ is declared in header ‘<complex.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘cacoshl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          3 | int cacoshl (void);
            |     ^~~~~~~
      _configtest.c:3:5: note: ‘cacoshl’ is declared in header ‘<complex.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘cargl’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          4 | int cargl (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘cargl’ is declared in header ‘<complex.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘casinl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          5 | int casinl (void);
            |     ^~~~~~
      _configtest.c:5:5: note: ‘casinl’ is declared in header ‘<complex.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘casinhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          6 | int casinhl (void);
            |     ^~~~~~~
      _configtest.c:6:5: note: ‘casinhl’ is declared in header ‘<complex.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘catanl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          7 | int catanl (void);
            |     ^~~~~~
      _configtest.c:7:5: note: ‘catanl’ is declared in header ‘<complex.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘catanhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          8 | int catanhl (void);
            |     ^~~~~~~
      _configtest.c:8:5: note: ‘catanhl’ is declared in header ‘<complex.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ccosl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ccosl (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ccosl’ is declared in header ‘<complex.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘ccoshl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         10 | int ccoshl (void);
            |     ^~~~~~
      _configtest.c:10:5: note: ‘ccoshl’ is declared in header ‘<complex.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘cexpl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         11 | int cexpl (void);
            |     ^~~~~
      _configtest.c:11:5: note: ‘cexpl’ is declared in header ‘<complex.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘cimagl’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         12 | int cimagl (void);
            |     ^~~~~~
      _configtest.c:12:5: note: ‘cimagl’ is declared in header ‘<complex.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘clogl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         13 | int clogl (void);
            |     ^~~~~
      _configtest.c:13:5: note: ‘clogl’ is declared in header ‘<complex.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘conjl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         14 | int conjl (void);
            |     ^~~~~
      _configtest.c:14:5: note: ‘conjl’ is declared in header ‘<complex.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘cpowl’; expected ‘_Complex long double(_Complex long double,  _Complex long double)’ [-Wbuiltin-declaration-mismatch]
         15 | int cpowl (void);
            |     ^~~~~
      _configtest.c:15:5: note: ‘cpowl’ is declared in header ‘<complex.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘cprojl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         16 | int cprojl (void);
            |     ^~~~~~
      _configtest.c:16:5: note: ‘cprojl’ is declared in header ‘<complex.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘creall’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         17 | int creall (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘creall’ is declared in header ‘<complex.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘csinl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         18 | int csinl (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘csinl’ is declared in header ‘<complex.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘csinhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         19 | int csinhl (void);
            |     ^~~~~~
      _configtest.c:19:5: note: ‘csinhl’ is declared in header ‘<complex.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘csqrtl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         20 | int csqrtl (void);
            |     ^~~~~~
      _configtest.c:20:5: note: ‘csqrtl’ is declared in header ‘<complex.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘ctanl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         21 | int ctanl (void);
            |     ^~~~~
      _configtest.c:21:5: note: ‘ctanl’ is declared in header ‘<complex.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘ctanhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         22 | int ctanhl (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘ctanhl’ is declared in header ‘<complex.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:2:12: warning: ‘static_func’ defined but not used [-Wunused-function]
          2 | static int static_func (char * restrict a)
            |            ^~~~~~~~~~~
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      File: build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h
      #define HAVE_ENDIAN_H 1
      #define SIZEOF_PY_INTPTR_T 8
      #define SIZEOF_OFF_T 8
      #define SIZEOF_PY_LONG_LONG 8
      #define MATHLIB m
      #define HAVE_SIN 1
      #define HAVE_COS 1
      #define HAVE_TAN 1
      #define HAVE_SINH 1
      #define HAVE_COSH 1
      #define HAVE_TANH 1
      #define HAVE_FABS 1
      #define HAVE_FLOOR 1
      #define HAVE_CEIL 1
      #define HAVE_SQRT 1
      #define HAVE_LOG10 1
      #define HAVE_LOG 1
      #define HAVE_EXP 1
      #define HAVE_ASIN 1
      #define HAVE_ACOS 1
      #define HAVE_ATAN 1
      #define HAVE_FMOD 1
      #define HAVE_MODF 1
      #define HAVE_FREXP 1
      #define HAVE_LDEXP 1
      #define HAVE_RINT 1
      #define HAVE_TRUNC 1
      #define HAVE_EXP2 1
      #define HAVE_LOG2 1
      #define HAVE_ATAN2 1
      #define HAVE_POW 1
      #define HAVE_NEXTAFTER 1
      #define HAVE_STRTOLL 1
      #define HAVE_STRTOULL 1
      #define HAVE_CBRT 1
      #define HAVE_STRTOLD_L 1
      #define HAVE_FALLOCATE 1
      #define HAVE_BACKTRACE 1
      #define HAVE_MADVISE 1
      #define HAVE_XMMINTRIN_H 1
      #define HAVE_EMMINTRIN_H 1
      #define HAVE_FEATURES_H 1
      #define HAVE_DLFCN_H 1
      #define HAVE_SYS_MMAN_H 1
      #define HAVE___BUILTIN_ISNAN 1
      #define HAVE___BUILTIN_ISINF 1
      #define HAVE___BUILTIN_ISFINITE 1
      #define HAVE___BUILTIN_BSWAP32 1
      #define HAVE___BUILTIN_BSWAP64 1
      #define HAVE___BUILTIN_EXPECT 1
      #define HAVE___BUILTIN_MUL_OVERFLOW 1
      #define HAVE___BUILTIN_CPU_SUPPORTS 1
      #define HAVE__M_FROM_INT64 1
      #define HAVE__MM_LOAD_PS 1
      #define HAVE__MM_PREFETCH 1
      #define HAVE__MM_LOAD_PD 1
      #define HAVE___BUILTIN_PREFETCH 1
      #define HAVE_LINK_AVX 1
      #define HAVE_LINK_AVX2 1
      #define HAVE_XGETBV 1
      #define HAVE_ATTRIBUTE_OPTIMIZE_UNROLL_LOOPS 1
      #define HAVE_ATTRIBUTE_OPTIMIZE_OPT_3 1
      #define HAVE_ATTRIBUTE_NONNULL 1
      #define HAVE_ATTRIBUTE_TARGET_AVX 1
      #define HAVE_ATTRIBUTE_TARGET_AVX2 1
      #define HAVE___THREAD 1
      #define HAVE_SINF 1
      #define HAVE_COSF 1
      #define HAVE_TANF 1
      #define HAVE_SINHF 1
      #define HAVE_COSHF 1
      #define HAVE_TANHF 1
      #define HAVE_FABSF 1
      #define HAVE_FLOORF 1
      #define HAVE_CEILF 1
      #define HAVE_RINTF 1
      #define HAVE_TRUNCF 1
      #define HAVE_SQRTF 1
      #define HAVE_LOG10F 1
      #define HAVE_LOGF 1
      #define HAVE_LOG1PF 1
      #define HAVE_EXPF 1
      #define HAVE_EXPM1F 1
      #define HAVE_ASINF 1
      #define HAVE_ACOSF 1
      #define HAVE_ATANF 1
      #define HAVE_ASINHF 1
      #define HAVE_ACOSHF 1
      #define HAVE_ATANHF 1
      #define HAVE_HYPOTF 1
      #define HAVE_ATAN2F 1
      #define HAVE_POWF 1
      #define HAVE_FMODF 1
      #define HAVE_MODFF 1
      #define HAVE_FREXPF 1
      #define HAVE_LDEXPF 1
      #define HAVE_EXP2F 1
      #define HAVE_LOG2F 1
      #define HAVE_COPYSIGNF 1
      #define HAVE_NEXTAFTERF 1
      #define HAVE_CBRTF 1
      #define HAVE_SINL 1
      #define HAVE_COSL 1
      #define HAVE_TANL 1
      #define HAVE_SINHL 1
      #define HAVE_COSHL 1
      #define HAVE_TANHL 1
      #define HAVE_FABSL 1
      #define HAVE_FLOORL 1
      #define HAVE_CEILL 1
      #define HAVE_RINTL 1
      #define HAVE_TRUNCL 1
      #define HAVE_SQRTL 1
      #define HAVE_LOG10L 1
      #define HAVE_LOGL 1
      #define HAVE_LOG1PL 1
      #define HAVE_EXPL 1
      #define HAVE_EXPM1L 1
      #define HAVE_ASINL 1
      #define HAVE_ACOSL 1
      #define HAVE_ATANL 1
      #define HAVE_ASINHL 1
      #define HAVE_ACOSHL 1
      #define HAVE_ATANHL 1
      #define HAVE_HYPOTL 1
      #define HAVE_ATAN2L 1
      #define HAVE_POWL 1
      #define HAVE_FMODL 1
      #define HAVE_MODFL 1
      #define HAVE_FREXPL 1
      #define HAVE_LDEXPL 1
      #define HAVE_EXP2L 1
      #define HAVE_LOG2L 1
      #define HAVE_COPYSIGNL 1
      #define HAVE_NEXTAFTERL 1
      #define HAVE_CBRTL 1
      #define HAVE_DECL_SIGNBIT
      #define HAVE_COMPLEX_H 1
      #define HAVE_CABS 1
      #define HAVE_CACOS 1
      #define HAVE_CACOSH 1
      #define HAVE_CARG 1
      #define HAVE_CASIN 1
      #define HAVE_CASINH 1
      #define HAVE_CATAN 1
      #define HAVE_CATANH 1
      #define HAVE_CCOS 1
      #define HAVE_CCOSH 1
      #define HAVE_CEXP 1
      #define HAVE_CIMAG 1
      #define HAVE_CLOG 1
      #define HAVE_CONJ 1
      #define HAVE_CPOW 1
      #define HAVE_CPROJ 1
      #define HAVE_CREAL 1
      #define HAVE_CSIN 1
      #define HAVE_CSINH 1
      #define HAVE_CSQRT 1
      #define HAVE_CTAN 1
      #define HAVE_CTANH 1
      #define HAVE_CABSF 1
      #define HAVE_CACOSF 1
      #define HAVE_CACOSHF 1
      #define HAVE_CARGF 1
      #define HAVE_CASINF 1
      #define HAVE_CASINHF 1
      #define HAVE_CATANF 1
      #define HAVE_CATANHF 1
      #define HAVE_CCOSF 1
      #define HAVE_CCOSHF 1
      #define HAVE_CEXPF 1
      #define HAVE_CIMAGF 1
      #define HAVE_CLOGF 1
      #define HAVE_CONJF 1
      #define HAVE_CPOWF 1
      #define HAVE_CPROJF 1
      #define HAVE_CREALF 1
      #define HAVE_CSINF 1
      #define HAVE_CSINHF 1
      #define HAVE_CSQRTF 1
      #define HAVE_CTANF 1
      #define HAVE_CTANHF 1
      #define HAVE_CABSL 1
      #define HAVE_CACOSL 1
      #define HAVE_CACOSHL 1
      #define HAVE_CARGL 1
      #define HAVE_CASINL 1
      #define HAVE_CASINHL 1
      #define HAVE_CATANL 1
      #define HAVE_CATANHL 1
      #define HAVE_CCOSL 1
      #define HAVE_CCOSHL 1
      #define HAVE_CEXPL 1
      #define HAVE_CIMAGL 1
      #define HAVE_CLOGL 1
      #define HAVE_CONJL 1
      #define HAVE_CPOWL 1
      #define HAVE_CPROJL 1
      #define HAVE_CREALL 1
      #define HAVE_CSINL 1
      #define HAVE_CSINHL 1
      #define HAVE_CSQRTL 1
      #define HAVE_CTANL 1
      #define HAVE_CTANHL 1
      #define NPY_RESTRICT restrict
      #define NPY_RELAXED_STRIDES_CHECKING 1
      #define HAVE_LDOUBLE_INTEL_EXTENDED_16_BYTES_LE 1
      #define NPY_PY3K 1
      #ifndef __cplusplus
      /* #undef inline */
      #endif
      
      #ifndef _NPY_NPY_CONFIG_H_
      #error config.h should never be included directly, include npy_config.h instead
      #endif
      
      EOF
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h' to sources.
      Generating build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      /opt/conda/compiler_compat/ld: _configtest.o: in function \`main':
      _configtest.c:(.text.startup+0x9): undefined reference to \`exp'
      collect2: error: ld returned 1 exit status
      failure.
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      File: build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h
      #define NPY_HAVE_ENDIAN_H 1
      #define NPY_SIZEOF_SHORT SIZEOF_SHORT
      #define NPY_SIZEOF_INT SIZEOF_INT
      #define NPY_SIZEOF_LONG SIZEOF_LONG
      #define NPY_SIZEOF_FLOAT 4
      #define NPY_SIZEOF_COMPLEX_FLOAT 8
      #define NPY_SIZEOF_DOUBLE 8
      #define NPY_SIZEOF_COMPLEX_DOUBLE 16
      #define NPY_SIZEOF_LONGDOUBLE 16
      #define NPY_SIZEOF_COMPLEX_LONGDOUBLE 32
      #define NPY_SIZEOF_PY_INTPTR_T 8
      #define NPY_SIZEOF_OFF_T 8
      #define NPY_SIZEOF_PY_LONG_LONG 8
      #define NPY_SIZEOF_LONGLONG 8
      #define NPY_NO_SMP 0
      #define NPY_HAVE_DECL_ISNAN
      #define NPY_HAVE_DECL_ISINF
      #define NPY_HAVE_DECL_ISFINITE
      #define NPY_HAVE_DECL_SIGNBIT
      #define NPY_USE_C99_COMPLEX 1
      #define NPY_HAVE_COMPLEX_DOUBLE 1
      #define NPY_HAVE_COMPLEX_FLOAT 1
      #define NPY_HAVE_COMPLEX_LONG_DOUBLE 1
      #define NPY_RELAXED_STRIDES_CHECKING 1
      #define NPY_USE_C99_FORMATS 1
      #define NPY_VISIBILITY_HIDDEN __attribute__((visibility("hidden")))
      #define NPY_ABI_VERSION 0x01000009
      #define NPY_API_VERSION 0x0000000D
      
      #ifndef __STDC_FORMAT_MACROS
      #define __STDC_FORMAT_MACROS 1
      #endif
      
      EOF
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h' to sources.
      executing numpy/core/code_generators/generate_numpy_api.py
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h' to sources.
      numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h']
      building extension "numpy.core._multiarray_tests" sources
      creating build/src.linux-x86_64-3.9/numpy/core/src/multiarray
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/_multiarray_tests.c
      building extension "numpy.core._multiarray_umath" sources
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h' to sources.
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h' to sources.
      executing numpy/core/code_generators/generate_numpy_api.py
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h' to sources.
      executing numpy/core/code_generators/generate_ufunc_api.py
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__ufunc_api.h' to sources.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/arraytypes.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/einsum.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/lowlevel_strided_loops.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/nditer_templ.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/scalartypes.c
      creating build/src.linux-x86_64-3.9/numpy/core/src/umath
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/funcs.inc
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/umath' to include_dirs.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/simd.inc
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/scalarmath.c
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/npymath' to include_dirs.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/templ_common.h
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/common' to include_dirs.
      numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/src/umath/funcs.inc', 'build/src.linux-x86_64-3.9/numpy/core/src/umath/simd.inc', 'build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.h', 'build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.h', 'build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_internal.h', 'build/src.linux-x86_64-3.9/numpy/core/src/common/templ_common.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__ufunc_api.h']
      building extension "numpy.core._umath_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_umath_tests.c
      building extension "numpy.core._rational_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_rational_tests.c
      building extension "numpy.core._struct_ufunc_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_struct_ufunc_tests.c
      building extension "numpy.core._operand_flag_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_operand_flag_tests.c
      building extension "numpy.fft.fftpack_lite" sources
      building extension "numpy.linalg.lapack_lite" sources
      creating build/src.linux-x86_64-3.9/numpy/linalg
      ### Warning:  Using unoptimized lapack ###
        adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_z_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_d_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_s_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_blas.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_config.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c.c' to sources.
      building extension "numpy.linalg._umath_linalg" sources
      ### Warning:  Using unoptimized lapack ###
        adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_z_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_d_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_s_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_blas.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_config.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c.c' to sources.
      conv_template:> build/src.linux-x86_64-3.9/numpy/linalg/umath_linalg.c
      building extension "numpy.random.mtrand" sources
      creating build/src.linux-x86_64-3.9/numpy/random
      building data_files sources
      build_src: building npy-pkg config files
      /opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
      !!
      
              ********************************************************************************
              Please avoid running \`\`setup.py\`\` directly.
              Instead, use pypa/build, pypa/installer or other
              standards-based tools.
      
              See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
              ********************************************************************************
      
      !!
        self.initialize_options()
      running build_py
      creating build/lib.linux-x86_64-cpython-39
      creating build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/matlib.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/ctypeslib.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/_pytesttester.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/version.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/dual.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/_globals.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/setup.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/conftest.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/_distributor_init.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying build/src.linux-x86_64-3.9/numpy/__config__.py -> build/lib.linux-x86_64-cpython-39/numpy
      creating build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/_inspect.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/py3k.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      creating build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/multiarray.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_dtype_ctypes.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_type_aliases.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_aliased_types.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_methods.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/arrayprint.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/cversions.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_dtype.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_string_helpers.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/records.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/numeric.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/machar.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/umath.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/umath_tests.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/numerictypes.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/info.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/getlimits.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/einsumfunc.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/memmap.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/overrides.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/function_base.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_internal.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/setup_common.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/defchararray.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/shape_base.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/fromnumeric.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_add_newdocs.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/code_generators/generate_numpy_api.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      creating build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/pathccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/msvccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/log.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/conv_template.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/npy_pkg_config.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/ccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/numpy_distribution.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/misc_util.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/intelccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/core.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/mingw32ccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/info.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/lib2def.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/_shell_utils.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/system_info.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/exec_command.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/compat.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/from_template.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/cpuinfo.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/__version__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/msvc9compiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/unixccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/line_endings.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/extension.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying build/src.linux-x86_64-3.9/numpy/distutils/__config__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      creating build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/config_compiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_scripts.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/sdist.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_ext.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/bdist_rpm.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_clib.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install_headers.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/config.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/develop.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_src.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_py.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install_data.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/egg_info.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install_clib.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/autodist.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      creating build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/absoft.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/pg.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/environment.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/intel.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/pathf95.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/compaq.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/nag.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/mips.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/lahey.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/gnu.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/none.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/g95.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/vast.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/sun.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/ibm.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/hpux.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      creating build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/basics.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/glossary.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/structured_arrays.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/byteswapping.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/internals.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/ufuncs.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/indexing.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/creation.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/broadcasting.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/misc.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/constants.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/subclassing.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      creating build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/diagnose.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/cfuncs.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/cb_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/common_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/f2py2e.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/use_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/func2subr.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/info.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/__main__.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/f2py_testing.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/__version__.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/crackfortran.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/auxfuncs.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/capi_maps.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/f90mod_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      creating build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/fftpack.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/helper.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/info.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      creating build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/index_tricks.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/format.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/npyio.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/mixins.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/scimath.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/arrayterator.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/info.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/histograms.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/_iotools.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/_version.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/arraysetops.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/user_array.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/function_base.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/financial.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/polynomial.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/stride_tricks.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/shape_base.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/ufunclike.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/_datasource.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/twodim_base.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/arraypad.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/recfunctions.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/type_check.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/utils.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/nanfunctions.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      creating build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/info.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/linalg.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      creating build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/mrecords.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/timer_comparison.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/extras.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/version.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/core.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/bench.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/testutils.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      creating build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      copying numpy/matrixlib/defmatrix.py -> build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      copying numpy/matrixlib/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      copying numpy/matrixlib/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      creating build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/legendre.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/laguerre.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/chebyshev.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/polyutils.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/_polybase.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/polynomial.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/hermite_e.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/hermite.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      creating build/lib.linux-x86_64-cpython-39/numpy/random
      copying numpy/random/info.py -> build/lib.linux-x86_64-cpython-39/numpy/random
      copying numpy/random/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/random
      copying numpy/random/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/random
      creating build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/decorators.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/nosetester.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/print_coercion_tables.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/noseclasses.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/utils.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      creating build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/decorators.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/parameterized.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/nosetester.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/noseclasses.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/utils.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      running build_clib
      customize UnixCCompiler
      customize UnixCCompiler using build_clib
      building 'npymath' library
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39
      creating build/temp.linux-x86_64-cpython-39/numpy
      creating build/temp.linux-x86_64-cpython-39/numpy/core
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/npymath
      creating build/temp.linux-x86_64-cpython-39/build
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npymath
      compile options: '-Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/core/src/npymath/npy_math.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.c
      gcc: numpy/core/src/npymath/halffloat.c
      ar: adding 4 object files to build/temp.linux-x86_64-cpython-39/libnpymath.a
      building 'npysort' library
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npysort
      compile options: '-Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/mergesort.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/heapsort.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/selection.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/binsearch.c
      ar: adding 5 object files to build/temp.linux-x86_64-cpython-39/libnpysort.a
      running build_ext
      customize UnixCCompiler
      customize UnixCCompiler using build_ext
      building 'numpy.core._dummy' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/core/src/dummymodule.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/core/src/dummymodule.o -Lbuild/temp.linux-x86_64-cpython-39 -lm -o build/lib.linux-x86_64-cpython-39/numpy/core/_dummy.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._multiarray_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/common
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/_multiarray_tests.c
      gcc: numpy/core/src/common/mem_overlap.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/_multiarray_tests.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/mem_overlap.o -Lbuild/temp.linux-x86_64-cpython-39 -lnpymath -o build/lib.linux-x86_64-cpython-39/numpy/core/_multiarray_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._multiarray_umath' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/umath
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/core/src/multiarray/alloc.c
      gcc: numpy/core/src/multiarray/common.c
      numpy/core/src/multiarray/common.c: In function ‘PyArray_DTypeFromObjectHelper’:
      numpy/core/src/multiarray/common.c:187:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        187 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:187:17: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        187 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:187:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        187 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:239:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        239 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:239:17: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        239 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:239:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        239 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:282:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        282 |         int itemsize = PyUnicode_GET_DATA_SIZE(obj);
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:282:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        282 |         int itemsize = PyUnicode_GET_DATA_SIZE(obj);
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:282:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        282 |         int itemsize = PyUnicode_GET_DATA_SIZE(obj);
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/arrayobject.c
      gcc: numpy/core/src/multiarray/convert.c
      gcc: numpy/core/src/multiarray/convert_datatype.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/arraytypes.c
      numpy/core/src/multiarray/arraytypes.c.src: In function ‘UNICODE_setitem’:
      numpy/core/src/multiarray/arraytypes.c.src:489:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        489 |     ptr = PyUnicode_AS_UNICODE(temp);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/arraytypes.c.src:494:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        494 |     datalen = PyUnicode_GET_DATA_SIZE(temp);
            |     ^~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/arraytypes.c.src:494:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        494 |     datalen = PyUnicode_GET_DATA_SIZE(temp);
            |     ^~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/arraytypes.c.src:494:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        494 |     datalen = PyUnicode_GET_DATA_SIZE(temp);
            |     ^~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/conversion_utils.c
      gcc: numpy/core/src/multiarray/ctors.c
      numpy/core/src/multiarray/ctors.c: In function ‘_is_default_descr’:
      numpy/core/src/multiarray/ctors.c:2263:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       2263 |     if (!(PyUString_Check(name) && PyUString_GET_SIZE(name) == 0)) {
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/ctors.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/ctors.c:2263:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       2263 |     if (!(PyUString_Check(name) && PyUString_GET_SIZE(name) == 0)) {
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/ctors.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/ctors.c:2263:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       2263 |     if (!(PyUString_Check(name) && PyUString_GET_SIZE(name) == 0)) {
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/ctors.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/datetime.c
      gcc: numpy/core/src/multiarray/datetime_strings.c
      gcc: numpy/core/src/multiarray/datetime_busday.c
      gcc: numpy/core/src/multiarray/datetime_busdaycal.c
      gcc: numpy/core/src/multiarray/descriptor.c
      numpy/core/src/multiarray/descriptor.c: In function ‘_convert_from_array_descr’:
      numpy/core/src/multiarray/descriptor.c:440:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        440 |         if (PyUString_GET_SIZE(name) == 0) {
            |         ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:440:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        440 |         if (PyUString_GET_SIZE(name) == 0) {
            |         ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:440:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        440 |         if (PyUString_GET_SIZE(name) == 0) {
            |         ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:447:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        447 |             else if (PyUString_Check(title) && PyUString_GET_SIZE(title) > 0) {
            |             ^~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:447:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        447 |             else if (PyUString_Check(title) && PyUString_GET_SIZE(title) > 0) {
            |             ^~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:447:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        447 |             else if (PyUString_Check(title) && PyUString_GET_SIZE(title) > 0) {
            |             ^~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/dragon4.c
      gcc: numpy/core/src/multiarray/dtype_transfer.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/einsum.c
      gcc: numpy/core/src/multiarray/array_assign_scalar.c
      gcc: numpy/core/src/multiarray/array_assign_array.c
      gcc: numpy/core/src/multiarray/arrayfunction_override.c
      gcc: numpy/core/src/multiarray/buffer.c
      gcc: numpy/core/src/multiarray/calculation.c
      gcc: numpy/core/src/multiarray/compiled_base.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/lowlevel_strided_loops.c
      gcc: numpy/core/src/multiarray/flagsobject.c
      gcc: numpy/core/src/multiarray/getset.c
      gcc: numpy/core/src/multiarray/hashdescr.c
      gcc: numpy/core/src/multiarray/item_selection.c
      gcc: numpy/core/src/multiarray/iterators.c
      gcc: numpy/core/src/multiarray/refcount.c
      gcc: numpy/core/src/multiarray/sequence.c
      gcc: numpy/core/src/multiarray/shape.c
      gcc: numpy/core/src/multiarray/scalarapi.c
      numpy/core/src/multiarray/scalarapi.c: In function ‘scalar_value’:
      numpy/core/src/multiarray/scalarapi.c:74:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
         74 |             return (void *)PyUnicode_AS_DATA(scalar);
            |             ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c:135:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        135 |             return (void *)PyUnicode_AS_DATA(scalar);
            |             ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c: In function ‘PyArray_DescrFromScalar’:
      numpy/core/src/multiarray/scalarapi.c:568:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        568 |             descr->elsize = PyUnicode_GET_DATA_SIZE(sc);
            |             ^~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c:568:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        568 |             descr->elsize = PyUnicode_GET_DATA_SIZE(sc);
            |             ^~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c:568:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        568 |             descr->elsize = PyUnicode_GET_DATA_SIZE(sc);
            |             ^~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/scalartypes.c
      numpy/core/src/multiarray/scalartypes.c.src: In function ‘unicodetype_repr’:
      numpy/core/src/multiarray/scalartypes.c.src:475:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        475 |     ip = dptr = Py@Name@_AS_@NAME@(self);
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:481:5: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
        481 |     new = Py@Name@_From@Name@@extra@(ip, len);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src: In function ‘unicodetype_str’:
      numpy/core/src/multiarray/scalartypes.c.src:475:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        475 |     ip = dptr = Py@Name@_AS_@NAME@(self);
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:481:5: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
        481 |     new = Py@Name@_From@Name@@extra@(ip, len);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src: In function ‘gentype_reduce’:
      numpy/core/src/multiarray/scalartypes.c.src:1849:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       1849 |         buffer = PyUnicode_AS_DATA(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/strfuncs.c
      numpy/core/src/multiarray/strfuncs.c: In function ‘array_repr’:
      numpy/core/src/multiarray/strfuncs.c:178:9: warning: ‘PyEval_CallObjectWithKeywords’ is deprecated [-Wdeprecated-declarations]
        178 |         s = PyEval_CallObject(PyArray_ReprFunction, arglist);
            |         ^
      In file included from /opt/conda/include/python3.9/Python.h:140,
                       from numpy/core/src/multiarray/strfuncs.c:4:
      /opt/conda/include/python3.9/ceval.h:17:43: note: declared here
         17 | Py_DEPRECATED(3.9) PyAPI_FUNC(PyObject *) PyEval_CallObjectWithKeywords(
            |                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/strfuncs.c: In function ‘array_str’:
      numpy/core/src/multiarray/strfuncs.c:195:9: warning: ‘PyEval_CallObjectWithKeywords’ is deprecated [-Wdeprecated-declarations]
        195 |         s = PyEval_CallObject(PyArray_StrFunction, arglist);
            |         ^
      In file included from /opt/conda/include/python3.9/Python.h:140,
                       from numpy/core/src/multiarray/strfuncs.c:4:
      /opt/conda/include/python3.9/ceval.h:17:43: note: declared here
         17 | Py_DEPRECATED(3.9) PyAPI_FUNC(PyObject *) PyEval_CallObjectWithKeywords(
            |                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/temp_elide.c
      gcc: numpy/core/src/multiarray/typeinfo.c
      gcc: numpy/core/src/multiarray/usertypes.c
      gcc: numpy/core/src/multiarray/vdot.c
      gcc: numpy/core/src/umath/umathmodule.c
      gcc: numpy/core/src/umath/reduction.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.c
      numpy/core/src/umath/loops.c.src: In function ‘PyUFunc_On_Om’:
      numpy/core/src/umath/loops.c.src:655:9: warning: ‘PyEval_CallObjectWithKeywords’ is deprecated [-Wdeprecated-declarations]
        655 |         result = PyEval_CallObject(tocall, arglist);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/Python.h:140,
                       from numpy/core/src/umath/loops.c.src:7:
      /opt/conda/include/python3.9/ceval.h:17:43: note: declared here
         17 | Py_DEPRECATED(3.9) PyAPI_FUNC(PyObject *) PyEval_CallObjectWithKeywords(
            |                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/mapping.c
      gcc: numpy/core/src/multiarray/methods.c
      gcc: numpy/core/src/multiarray/multiarraymodule.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/nditer_templ.c
      gcc: numpy/core/src/multiarray/nditer_api.c
      gcc: numpy/core/src/multiarray/nditer_constr.c
      gcc: numpy/core/src/multiarray/nditer_pywrap.c
      gcc: numpy/core/src/multiarray/number.c
      gcc: numpy/core/src/umath/ufunc_type_resolution.c
      gcc: numpy/core/src/umath/override.c
      gcc: numpy/core/src/npymath/npy_math.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.c
      gcc: numpy/core/src/npymath/halffloat.c
      gcc: numpy/core/src/common/array_assign.c
      gcc: numpy/core/src/common/mem_overlap.c
      gcc: numpy/core/src/common/npy_longdouble.c
      gcc: numpy/core/src/common/ucsnarrow.c
      numpy/core/src/common/ucsnarrow.c: In function ‘PyUnicode_FromUCS4’:
      numpy/core/src/common/ucsnarrow.c:139:9: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
        139 |         ret = (PyUnicodeObject *)PyUnicode_FromUnicode((Py_UNICODE*)buf,
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/common/ucsnarrow.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/common/ufunc_override.c
      gcc: numpy/core/src/common/numpyos.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.c
      gcc: numpy/core/src/umath/ufunc_object.c
      numpy/core/src/umath/ufunc_object.c: In function ‘_parse_signature’:
      numpy/core/src/umath/ufunc_object.c:657:19: warning: comparison of integer expressions of different signedness: ‘int’ and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]
        657 |     for (i = 0; i < len; i++) {
            |                   ^
      gcc: numpy/core/src/umath/extobj.c
      gcc: numpy/core/src/umath/cpuid.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/scalarmath.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/alloc.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/arrayobject.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/arraytypes.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/array_assign_scalar.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/array_assign_array.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/arrayfunction_override.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/buffer.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/calculation.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/compiled_base.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/common.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/convert.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/convert_datatype.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/conversion_utils.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/ctors.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime_strings.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime_busday.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime_busdaycal.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/descriptor.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/dragon4.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/dtype_transfer.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/einsum.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/flagsobject.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/getset.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/hashdescr.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/item_selection.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/iterators.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/lowlevel_strided_loops.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/mapping.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/methods.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/multiarraymodule.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/nditer_templ.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/nditer_api.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/nditer_constr.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/nditer_pywrap.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/number.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/refcount.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/sequence.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/shape.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/scalarapi.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/scalartypes.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/strfuncs.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/temp_elide.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/typeinfo.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/usertypes.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/vdot.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/umathmodule.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/reduction.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/ufunc_object.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/extobj.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/cpuid.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/scalarmath.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/ufunc_type_resolution.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/override.o build/temp.linux-x86_64-cpython-39/numpy/core/src/npymath/npy_math.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.o build/temp.linux-x86_64-cpython-39/numpy/core/src/npymath/halffloat.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/array_assign.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/mem_overlap.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/npy_longdouble.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/ucsnarrow.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/ufunc_override.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/numpyos.o -Lbuild/temp.linux-x86_64-cpython-39 -lnpymath -lnpysort -lm -o build/lib.linux-x86_64-cpython-39/numpy/core/_multiarray_umath.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._umath_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_umath_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_umath_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_umath_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._rational_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_rational_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_rational_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_rational_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._struct_ufunc_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_struct_ufunc_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_struct_ufunc_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_struct_ufunc_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._operand_flag_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_operand_flag_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_operand_flag_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_operand_flag_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.fft.fftpack_lite' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/fft
      compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/fft/fftpack_litemodule.c
      gcc: numpy/fft/fftpack.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/fft/fftpack_litemodule.o build/temp.linux-x86_64-cpython-39/numpy/fft/fftpack.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/fft/fftpack_lite.cpython-39-x86_64-linux-gnu.so
      building 'numpy.linalg.lapack_lite' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/linalg
      creating build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite
      compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/linalg/lapack_litemodule.c
      gcc: numpy/linalg/lapack_lite/f2c_z_lapack.c
      gcc: numpy/linalg/lapack_lite/python_xerbla.c
      gcc: numpy/linalg/lapack_lite/f2c_d_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_c_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_s_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_blas.c
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘cgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:383:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
        383 |     static integer ncola;
            |                    ^~~~~
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘dgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:6853:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
       6853 |     static integer ncola;
            |                    ^~~~~
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘sgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:11457:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
      11457 |     static integer ncola;
            |                    ^~~~~
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘zgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:15670:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
      15670 |     static integer ncola;
            |                    ^~~~~
      gcc: numpy/linalg/lapack_lite/f2c_config.c
      gcc: numpy/linalg/lapack_lite/f2c.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_litemodule.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/python_xerbla.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_z_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_d_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_s_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_blas.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_config.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/linalg/lapack_lite.cpython-39-x86_64-linux-gnu.so
      building 'numpy.linalg._umath_linalg' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/linalg
      compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/linalg/umath_linalg.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/linalg/umath_linalg.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/python_xerbla.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_z_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_d_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_s_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_blas.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_config.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c.o -Lbuild/temp.linux-x86_64-cpython-39 -lnpymath -o build/lib.linux-x86_64-cpython-39/numpy/linalg/_umath_linalg.cpython-39-x86_64-linux-gnu.so
      building 'numpy.random.mtrand' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/random
      creating build/temp.linux-x86_64-cpython-39/numpy/random/mtrand
      compile options: '-D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/random/mtrand/mtrand.c
      gcc: numpy/random/mtrand/randomkit.c
      gcc: numpy/random/mtrand/initarray.c
      gcc: numpy/random/mtrand/distributions.c
      numpy/random/mtrand/mtrand.c: In function ‘__Pyx_modinit_type_init_code’:
      numpy/random/mtrand/mtrand.c:40560:33: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
      40560 |   __pyx_type_6mtrand_RandomState.tp_print = 0;
            |                                 ^
      numpy/random/mtrand/mtrand.c: In function ‘__Pyx_ParseOptionalKeywords’:
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      error: Command "gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c numpy/random/mtrand/mtrand.c -o build/temp.linux-x86_64-cpython-39/numpy/random/mtrand/mtrand.o -MMD -MF build/temp.linux-x86_64-cpython-39/numpy/random/mtrand/mtrand.o.d" failed with exit status 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for numpy
  Running setup.py clean for numpy
  error: subprocess-exited-with-error
  
  × python setup.py clean did not run successfully.
  │ exit code: 1
  ╰─> [10 lines of output]
      Running from numpy source directory.
      
      \`setup.py clean\` is not supported, use one of the following instead:
      
        - \`git clean -xdf\` (cleans all files)
        - \`git clean -Xdf\` (cleans all versioned files, doesn't touch
                            files that aren't checked into the git repo)
      
      Add \`--force\` to your command to use it anyway if you must (unsupported).
      
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed cleaning build dir for numpy
  Building wheel for psutil (setup.py): started
  Building wheel for psutil (setup.py): finished with status 'done'
  Created wheel for psutil: filename=psutil-5.5.1-cp39-cp39-linux_x86_64.whl size=214935 sha256=c4d57300565059f5abf74fa7645af9fe511e25cd1d5f073e4020f89c55cae92c
  Stored in directory: /home/aiida/.cache/pip/wheels/8c/76/71/81b1aeeea8b23c1f889efe5662e3230bd511aaee41a636cb6d
  Building wheel for psycopg2-binary (setup.py): started
  Building wheel for psycopg2-binary (setup.py): finished with status 'done'
  Created wheel for psycopg2-binary: filename=psycopg2_binary-2.8-cp39-cp39-linux_x86_64.whl size=154718 sha256=e0351051965c5153e0e2a2079a95f2cd73550891544b814bd08397a3f1f48d13
  Stored in directory: /home/aiida/.cache/pip/wheels/59/8c/3c/53082ac2b0135e96329263c06547dc0bfb8d53e55fba549dd6
  Building wheel for PyYAML (setup.py): started
  Building wheel for PyYAML (setup.py): finished with status 'done'
  Created wheel for PyYAML: filename=PyYAML-3.13-cp39-cp39-linux_x86_64.whl size=43099 sha256=d10fdb47b893e318b412adf2b842894dc07ff353ae88018247b2c9f5a140f82b
  Stored in directory: /home/aiida/.cache/pip/wheels/81/6e/87/725bed1db7f86e1c7091ef5f4a4f11b0fcf7023c2be4fc29db
  Building wheel for simplejson (setup.py): started
  Building wheel for simplejson (setup.py): finished with status 'done'
  Created wheel for simplejson: filename=simplejson-3.16.0-cp39-cp39-linux_x86_64.whl size=75790 sha256=2370a97eaf3b1108babd6d3175cf3095d47d9ae6f0aca6486a392691f9037b69
  Stored in directory: /home/aiida/.cache/pip/wheels/32/25/4a/a4c110dbbef9e26e7813c89a1e66b3f8b14dbf0d4f5012c98f
  Building wheel for SQLAlchemy (setup.py): started
  Building wheel for SQLAlchemy (setup.py): finished with status 'done'
  Created wheel for SQLAlchemy: filename=SQLAlchemy-1.3.3-cp39-cp39-linux_x86_64.whl size=1140156 sha256=21ab5ca57353194d008752d16b82da68bc442576c27a9efc3125268b3648d912
  Stored in directory: /home/aiida/.cache/pip/wheels/66/01/59/e60921afa861ef0f7365a03208aac0c1fd70b748f3c6a6f345
  Building wheel for SQLAlchemy-Utils (setup.py): started
  Building wheel for SQLAlchemy-Utils (setup.py): finished with status 'done'
  Created wheel for SQLAlchemy-Utils: filename=SQLAlchemy_Utils-0.33.11-py2.py3-none-any.whl size=89352 sha256=326820716e8205d8f6ed83afb6c02459cf70a036f159843b076ae3162405baf9
  Stored in directory: /home/aiida/.cache/pip/wheels/7f/0d/38/0e28b2368702114374c9e1bc47e40a32c335687130ba2d07ac
  Building wheel for tabulate (setup.py): started
  Building wheel for tabulate (setup.py): finished with status 'done'
  Created wheel for tabulate: filename=tabulate-0.8.3-py3-none-any.whl size=23372 sha256=255dd6484196b9ea6a07949c40ea4150639fa995b60d6573c70ad05f38157c13
  Stored in directory: /home/aiida/.cache/pip/wheels/6a/27/1a/19cd0775f6cda4160ca55ce3eb4c968e7f41b253b068adf037
  Building wheel for tzlocal (setup.py): started
  Building wheel for tzlocal (setup.py): finished with status 'done'
  Created wheel for tzlocal: filename=tzlocal-1.5.1-py3-none-any.whl size=17543 sha256=060e0e9902abd743c45d10986ad839d6b709d91c85c0c82f365834294e0453d0
  Stored in directory: /home/aiida/.cache/pip/wheels/7d/2a/d3/9b83608fd158b23f4d04b92572b93ab2d643faa2a3c46b6f34
  Building wheel for wrapt (setup.py): started
  Building wheel for wrapt (setup.py): finished with status 'done'
  Created wheel for wrapt: filename=wrapt-1.11.1-cp39-cp39-linux_x86_64.whl size=36666 sha256=406dcbb2cdc2f4a0126fcd001914a3e0bb713caa688316f6593a2250f711db43
  Stored in directory: /home/aiida/.cache/pip/wheels/c8/6a/06/a9a8e9bf8ad2e6cc4fccdc713f67593cb7e1f5117212b0d8b5
  Building wheel for tornado (setup.py): started
  Building wheel for tornado (setup.py): finished with status 'done'
  Created wheel for tornado: filename=tornado-4.5.3-cp39-cp39-linux_x86_64.whl size=423442 sha256=3cbafbc1451ceb2011764e53f7d42e7a1fdb0a4df00f42f6c3d53c5efbb2407c
  Stored in directory: /home/aiida/.cache/pip/wheels/83/38/94/6e1e08dd9ed83e2fc92914d24bf950c39e622dfbb12bf753d8
  Building wheel for pyzmq (setup.py): started
  Building wheel for pyzmq (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [705 lines of output]
      running bdist_wheel
      running build
      running build_py
      creating build
      creating build/lib.linux-x86_64-cpython-39
      creating build/lib.linux-x86_64-cpython-39/zmq
      copying zmq/error.py -> build/lib.linux-x86_64-cpython-39/zmq
      copying zmq/decorators.py -> build/lib.linux-x86_64-cpython-39/zmq
      copying zmq/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq
      creating build/lib.linux-x86_64-cpython-39/zmq/log
      copying zmq/log/handlers.py -> build/lib.linux-x86_64-cpython-39/zmq/log
      copying zmq/log/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/log
      creating build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/context.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/stopwatch.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/socket.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/version.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/attrsettr.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/tracker.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/frame.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/poll.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/constants.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      creating build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/monitoredqueuedevice.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/basedevice.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/monitoredqueue.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/proxydevice.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      creating build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/thread.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/certs.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/base.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      creating build/lib.linux-x86_64-cpython-39/zmq/auth/asyncio
      copying zmq/auth/asyncio/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/auth/asyncio
      creating build/lib.linux-x86_64-cpython-39/zmq/asyncio
      copying zmq/asyncio/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/asyncio
      creating build/lib.linux-x86_64-cpython-39/zmq/ssh
      copying zmq/ssh/tunnel.py -> build/lib.linux-x86_64-cpython-39/zmq/ssh
      copying zmq/ssh/forward.py -> build/lib.linux-x86_64-cpython-39/zmq/ssh
      copying zmq/ssh/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/ssh
      creating build/lib.linux-x86_64-cpython-39/zmq/backend
      copying zmq/backend/select.py -> build/lib.linux-x86_64-cpython-39/zmq/backend
      copying zmq/backend/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/backend
      creating build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/message.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/error.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/context.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/socket.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/devices.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/_cffi.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/constants.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/_poll.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/utils.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      creating build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      creating build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/device.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/core.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/poll.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      creating build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      copying zmq/green/eventloop/zmqstream.py -> build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      copying zmq/green/eventloop/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      copying zmq/green/eventloop/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      creating build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/strtypes.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/win32.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/sixcerpt.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/monitor.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/garbage.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/z85.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/constant_names.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/jsonapi.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/interop.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      creating build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/zmqstream.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/future.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      creating build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/concurrent.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/log.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/stack_context.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/util.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      creating build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/common.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/interface.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/windows.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/posix.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/auto.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      creating build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_pubsub.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_device.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_socket.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_log.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_version.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_retry_eintr.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_zmqstream.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_reqrep.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_pair.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_z85.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_monitor.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_security.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_etc.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_decorators.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_ssh.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_multipart.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_cffi_backend.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_context.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_error.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_includes.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_imports.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_win32_shim.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_message.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_poll.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_auth.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_future.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_monqueue.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_constants.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      creating build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/tests/asyncio/test_asyncio.py -> build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/tests/asyncio/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/tests/asyncio/_test_asyncio.py -> build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/devices/monitoredqueue.pxd -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/backend/cffi/_cdefs.h -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/_verify.c -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cython/checkrc.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/message.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/libzmq.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/context.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/socket.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/constant_enums.pxi -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/constants.pxi -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/utils/buffers.pxd -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/zmq_compat.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/ipcmaxlen.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/pyversion_compat.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/getpid_compat.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/zmq_constants.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      running build_ext
      running configure
      pkg-config not found
      {'libraries': ['zmq'], 'include_dirs': [], 'library_dirs': [], 'runtime_library_dirs': [], 'extra_link_args': []}
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c build/temp.linux-x86_64-cpython-39/scratch/check_sys_un.c -o build/temp.linux-x86_64-cpython-39/scratch/check_sys_un.o
      gcc -pthread -B /opt/conda/compiler_compat build/temp.linux-x86_64-cpython-39/scratch/check_sys_un.o -o build/temp.linux-x86_64-cpython-39/scratch/check_sys_un
      ************************************************
      Configure: Autodetecting ZMQ settings...
          Custom ZMQ dir:
      creating build/temp.linux-x86_64-cpython-39/scratch/tmp
      cc -c /tmp/timer_createt2mtyokg.c -o build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_createt2mtyokg.o
      cc build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_createt2mtyokg.o -o build/temp.linux-x86_64-cpython-39/scratch/a.out
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -Izmq/utils -Izmq/backend/cython -Izmq/devices -c build/temp.linux-x86_64-cpython-39/scratch/vers.c -o build/temp.linux-x86_64-cpython-39/scratch/vers.o
      build/temp.linux-x86_64-cpython-39/scratch/vers.c:4:10: fatal error: zmq.h: No such file or directory
          4 | #include "zmq.h"
            |          ^~~~~~~
      compilation terminated.
      
      error: command '/usr/bin/gcc' failed with exit code 1
      
      Failed with default libzmq, trying again with /usr/local
      {'libraries': ['zmq'], 'include_dirs': ['/usr/local/include'], 'library_dirs': ['/usr/local/lib'], 'runtime_library_dirs': [], 'extra_link_args': []}
      ************************************************
      Configure: Autodetecting ZMQ settings...
          Custom ZMQ dir:       /usr/local
      cc -c /tmp/timer_create2fvdgdnw.c -o build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_create2fvdgdnw.o
      Assembler messages:
      Fatal error: can't create build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_create2fvdgdnw.o: No such file or directory
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/usr/local/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -c build/temp.linux-x86_64-cpython-39/scratch/vers.c -o build/temp.linux-x86_64-cpython-39/scratch/vers.o
      build/temp.linux-x86_64-cpython-39/scratch/vers.c:4:10: fatal error: zmq.h: No such file or directory
          4 | #include "zmq.h"
            |          ^~~~~~~
      compilation terminated.
      
      error: command '/usr/bin/gcc' failed with exit code 1
      
      ************************************************
      Warning: Couldn't find an acceptable libzmq on the system.
      
      If you expected pyzmq to link against an installed libzmq, please check to make sure:
      
          * You have a C compiler installed
          * A development version of Python is installed (including headers)
          * A development version of ZMQ >= 3.2 is installed (including headers)
          * If ZMQ is not in a default location, supply the argument --zmq=<path>
          * If you did recently install ZMQ to a default location,
            try rebuilding the ld cache with \`sudo ldconfig\`
            or specify zmq's location with \`--zmq=/usr/local\`
      
      You can skip all this detection/waiting nonsense if you know
      you want pyzmq to bundle libzmq as an extension by passing:
      
          \`--zmq=bundled\`
      
      I will now try to build libzmq as a Python extension
      unless you interrupt me (^C) in the next 10 seconds...
      
      
      10...
       9...
       8...
       7...
       6...
       5...
       4...
       3...
       2...
       1...
      ************************************************
      Using bundled libzmq
      already have bundled/zeromq
      attempting ./configure to generate platform.hpp
      Warning: failed to configure libzmq:
      b'/bin/sh: 1: ./configure: not found\\n'
      staging platform.hpp from: /tmp/pip-install-co8fipfm/pyzmq_29e491904611432fb711d7b095e2c876/buildutils/include_linux
      ************************************************
      checking for timer_create
      creating build/temp.linux-x86_64-cpython-39/tmp
      cc -c /tmp/timer_created41gg942.c -o build/temp.linux-x86_64-cpython-39/tmp/timer_created41gg942.o
      cc build/temp.linux-x86_64-cpython-39/tmp/timer_created41gg942.o -o build/temp.linux-x86_64-cpython-39/a.out
      ok
      ************************************************
      building 'zmq.libzmq' extension
      creating build/temp.linux-x86_64-cpython-39/buildutils
      creating build/temp.linux-x86_64-cpython-39/bundled
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/src
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib/randombytes
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/src
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c buildutils/initlibzmq.c -o build/temp.linux-x86_64-cpython-39/buildutils/initlibzmq.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/clock.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/clock.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ctx.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ctx.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/curve_client.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_client.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/curve_server.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_server.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/dealer.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dealer.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/devpoll.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/devpoll.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/dist.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dist.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/epoll.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/epoll.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/err.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/err.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/fq.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/fq.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/gssapi_client.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_client.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/gssapi_mechanism_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_mechanism_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/gssapi_server.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_server.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/io_object.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_object.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/io_thread.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_thread.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ip.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ip.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ipc_address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ipc_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ipc_listener.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_listener.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/kqueue.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/kqueue.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/lb.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/lb.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/mailbox.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mailbox.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/mechanism.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mechanism.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/metadata.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/metadata.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/msg.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/msg.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/mtrie.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mtrie.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/norm_engine.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/norm_engine.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/null_mechanism.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/null_mechanism.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/object.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/object.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/options.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/options.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/own.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/own.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pair.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pair.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pgm_receiver.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_receiver.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pgm_sender.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_sender.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pgm_socket.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_socket.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pipe.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pipe.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/plain_client.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_client.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/plain_server.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_server.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/poll.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poll.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/poller_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poller_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/precompiled.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/precompiled.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/proxy.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/proxy.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pull.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pull.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/push.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/push.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/random.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/random.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/raw_decoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_decoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/raw_encoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_encoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/reaper.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/reaper.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/rep.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/rep.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/req.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/req.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/router.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/router.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/select.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/select.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/session_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/session_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/signaler.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/signaler.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/socket_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socket_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/socks.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/socks_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/stream.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/stream_engine.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream_engine.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/sub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/sub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp_address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp_listener.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_listener.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/thread.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/thread.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tipc_address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tipc_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tipc_listener.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_listener.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/trie.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/trie.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v1_decoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_decoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v1_encoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_encoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v2_decoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_decoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v2_encoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_encoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/xpub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xpub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/xsub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xsub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/zmq.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/zmq_utils.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq_utils.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/tweetnacl/contrib/randombytes/devurandom.c -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib/randombytes/devurandom.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/tweetnacl/src/tweetnacl.c -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/src/tweetnacl.o
      bundled/zeromq/tweetnacl/src/tweetnacl.c: In function ‘vn’:
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘u32’ {aka ‘long unsigned int’} and ‘int’ [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:66:3: note: in expansion of macro ‘FOR’
         66 |   FOR(i,n) d |= x[i]^y[i];
            |   ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c: In function ‘crypto_sign’:
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘i64’ {aka ‘long long int’} and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:732:3: note: in expansion of macro ‘FOR’
        732 |   FOR(i,n) sm[64 + i] = m[i];
            |   ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c: In function ‘crypto_sign_open’:
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:799:3: note: in expansion of macro ‘FOR’
        799 |   FOR(i,n) m[i] = sm[i];
            |   ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:811:5: note: in expansion of macro ‘FOR’
        811 |     FOR(i,n) m[i] = 0;
            |     ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:815:3: note: in expansion of macro ‘FOR’
        815 |   FOR(i,n) m[i] = sm[i + 64];
            |   ^~~
      g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/buildutils/initlibzmq.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/clock.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ctx.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_client.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_server.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dealer.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/devpoll.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dist.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/epoll.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/err.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/fq.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_client.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_mechanism_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_server.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_object.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_thread.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ip.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_listener.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/kqueue.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/lb.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mailbox.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mechanism.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/metadata.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/msg.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mtrie.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/norm_engine.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/null_mechanism.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/object.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/options.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/own.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pair.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_receiver.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_sender.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_socket.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pipe.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_client.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_server.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poll.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poller_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/precompiled.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/proxy.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pull.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/push.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/random.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_decoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_encoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/reaper.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/rep.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/req.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/router.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/select.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/session_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/signaler.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socket_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream_engine.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/sub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_listener.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/thread.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_listener.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/trie.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_decoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_encoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_decoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_encoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xpub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xsub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq_utils.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib/randombytes/devurandom.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/src/tweetnacl.o -o build/lib.linux-x86_64-cpython-39/zmq/libzmq.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython._device' extension
      creating build/temp.linux-x86_64-cpython-39/zmq
      creating build/temp.linux-x86_64-cpython-39/zmq/backend
      creating build/temp.linux-x86_64-cpython-39/zmq/backend/cython
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/_device.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_device.o
      zmq/backend/cython/_device.c: In function ‘__Pyx_ParseOptionalKeywords’:
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_device.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/_device.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython._poll' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/_poll.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_poll.o
      zmq/backend/cython/_poll.c: In function ‘__Pyx_ParseOptionalKeywords’:
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_poll.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/_poll.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython._version' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/_version.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_version.o
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_version.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/_version.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython.constants' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/constants.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/constants.o
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/constants.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/constants.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython.context' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/context.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/context.o
      zmq/backend/cython/context.c: In function ‘PyInit_context’:
      zmq/backend/cython/context.c:4483:52: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       4483 |   __pyx_type_3zmq_7backend_6cython_7context_Context.tp_print = 0;
            |                                                    ^
      zmq/backend/cython/context.c: In function ‘__Pyx_ParseOptionalKeywords’:
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      error: command '/usr/bin/gcc' failed with exit code 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for pyzmq
  Running setup.py clean for pyzmq
  Building wheel for simplegeneric (setup.py): started
  Building wheel for simplegeneric (setup.py): finished with status 'done'
  Created wheel for simplegeneric: filename=simplegeneric-0.8.1-py3-none-any.whl size=5057 sha256=0498450fb3c4d5607f03f11705fd09289473e526e497fa08b745cfdfbeb75ba6
  Stored in directory: /home/aiida/.cache/pip/wheels/a7/bd/0d/d95b629ee4a7368830202858e45ac76cd837a42cafa50da81e
Successfully built aiida-core PyCifRW alembic click-completion click-spinner ete3 psutil psycopg2-binary PyYAML simplejson SQLAlchemy SQLAlchemy-Utils tabulate tzlocal wrapt tornado simplegeneric
Failed to build numpy pyzmq
ERROR: Could not build wheels for numpy, pyzmq, which is required to install pyproject.toml-based projects
</pre>`],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:2},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Gulp potentials)",count:3}],pip_install_cmd:"pip install --pre aiida-gulp",is_installable:"False"},"aiida-kkr":{code_home:"https://github.com/JuDFTteam/aiida-kkr/tree/develop",development_status:"stable",documentation_url:"https://aiida-kkr.readthedocs.io/",entry_point_prefix:"kkr",pip_url:"aiida-kkr",name:"aiida-kkr",package_name:"aiida_kkr",hosted_on:"github.com",metadata:{release_date:"2023-04-05",description:"AiiDA plugin for the JuKKR codes",author_email:"Philipp Ruessmann <p.ruessmann@fz-juelich.de>, Jens Broeder <j.broeder@fz-juelich.de>, Fabian Bertoldo <f.bertoldo@fz-juelich.de>",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.0.0"},aiida_version:null,entry_points:{},commits_count:78,errors:["Unable to retrieve plugin info from: https://raw.github.com/JuDFTteam/aiida-kkr/develop/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","Development status in classifiers (beta) does not match development_status in metadata (stable)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install aiida-kkr",is_installable:"True"},"aiida-lammps":{code_home:"https://github.com/aiidaplugins/aiida-lammps",development_status:"beta",entry_point_prefix:"lammps",pip_url:"git+https://github.com/aiidaplugins/aiida-lammps",name:"aiida-lammps",package_name:"aiida_lammps",hosted_on:"github.com",metadata:{author:"Abel Carreras, Chris Sewell",author_email:"chrisj_sewell@hotmail.com",version:"0.8.0",description:"AiiDA plugin for LAMMPS",classifiers:["Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Framework :: AiiDA"]},aiida_version:">=1.4.0,<2.0.0",entry_points:{"aiida.calculations":{"lammps.combinate":"aiida_lammps.calculations.lammps.combinate:CombinateCalculation","lammps.force":"aiida_lammps.calculations.lammps.force:ForceCalculation","lammps.md":"aiida_lammps.calculations.lammps.md:MdCalculation","lammps.md.multi":"aiida_lammps.calculations.lammps.md_multi:MdMultiCalculation","lammps.optimize":"aiida_lammps.calculations.lammps.optimize:OptimizeCalculation",dynaphopy:"aiida_lammps.calculations.dynaphopy: DynaphopyCalculation"},"aiida.parsers":{"lammps.force":"aiida_lammps.parsers.lammps.force:ForceParser","lammps.md":"aiida_lammps.parsers.lammps.md:MdParser","lammps.md.multi":"aiida_lammps.parsers.lammps.md_multi:MdMultiParser","lammps.optimize":"aiida_lammps.parsers.lammps.optimize:OptimizeParser",dynaphopy:"aiida_lammps.parsers.dynaphopy: DynaphopyParser"},"aiida.data":{"lammps.potential":"aiida_lammps.data.potential:EmpiricalPotential","lammps.trajectory":"aiida_lammps.data.trajectory:LammpsTrajectory"},"lammps.potentials":{eam:"aiida_lammps.data.pot_plugins.eam:EAM",lennard_jones:"aiida_lammps.data.pot_plugins.lennard_jones:LennardJones",reaxff:"aiida_lammps.data.pot_plugins.reaxff:Reaxff",tersoff:"aiida_lammps.data.pot_plugins.tersoff:Tersoff"}},commits_count:0,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'dynaphopy' does not start with prefix 'lammps.'","Entry point 'dynaphopy' does not start with prefix 'lammps.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:5},{colorclass:"red",text:"Data",count:2},{colorclass:"orange",text:"Other (Lammps potentials)",count:4}],pip_install_cmd:"pip install git+https://github.com/aiidaplugins/aiida-lammps",is_installable:"True"},"aiida-lsmo":{code_home:"https://github.com/lsmo-epfl/aiida-lsmo",development_status:"stable",entry_point_prefix:"lsmo",pip_url:"git+https://github.com/lsmo-epfl/aiida-lsmo",name:"aiida-lsmo",package_name:"aiida_lsmo",hosted_on:"github.com",metadata:{author:"Aliaksandr Yakutovich, Daniele Ongari, Leopold Talirz",author_email:"aliaksandr.yakutovich@epfl.ch",version:"1.0.0",description:"AiiDA workflows for the LSMO laboratory at EPFL",classifiers:["Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7"]},aiida_version:">=1.0.0",entry_points:{"aiida.calculations":{"lsmo.ff_builder":"aiida_lsmo.calcfunctions:ff_builder","lsmo.calc_ch4_working_cap":"aiida_lsmo.calcfunctions:calc_ch4_working_cap","lsmo.calc_h2_working_cap":"aiida_lsmo.calcfunctions:calc_h2_working_cap","lsmo.calc_o2_working_cap":"aiida_lsmo.calcfunctions:calc_o2_working_cap","lsmo.calc_selectivity":"aiida_lsmo.calcfunctions:calc_selectivity"},"aiida.parsers":{"lsmo.cp2k_bsse_parser":"aiida_lsmo.parsers:Cp2kBsseParser","lsmo.cp2k_advanced_parser":"aiida_lsmo.parsers:Cp2kAdvancedParser"},"aiida.workflows":{"lsmo.binding_site":"aiida_lsmo.workchains:BindingSiteWorkChain","lsmo.cp2k_binding_energy":"aiida_lsmo.workchains.cp2k_binding_energy:Cp2kBindingEnergyWorkChain","lsmo.cp2k_multistage":"aiida_lsmo.workchains:Cp2kMultistageWorkChain","lsmo.cp2k_multistage_ddec":"aiida_lsmo.workchains:Cp2kMultistageDdecWorkChain","lsmo.isotherm":"aiida_lsmo.workchains:IsothermWorkChain","lsmo.isotherm_multi_temp":"aiida_lsmo.workchains:IsothermMultiTempWorkChain","lsmo.isotherm_calc_pe":"aiida_lsmo.workchains:IsothermCalcPEWorkChain","lsmo.zeopp_multistage_ddec":"aiida_lsmo.workchains:ZeoppMultistageDdecWorkChain","lsmo.sim_annealing":"aiida_lsmo.workchains.sim_annealing:SimAnnealingWorkChain","lsmo.nanoporous_screening_1":"aiida_lsmo.workchains:NanoporousScreening1WorkChain"}},commits_count:17,errors:[`Failed to install plugin aiida-lsmo</br><pre>Collecting git+https://github.com/lsmo-epfl/aiida-lsmo
  Cloning https://github.com/lsmo-epfl/aiida-lsmo to /tmp/pip-req-build-lzs9yz_5
  Running command git clone --filter=blob:none --quiet https://github.com/lsmo-epfl/aiida-lsmo /tmp/pip-req-build-lzs9yz_5
  Resolved https://github.com/lsmo-epfl/aiida-lsmo to commit 6bf08fa42e545dadf889ea8095d7fcdd8d1be15c
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting aiida-core~=1.0 (from aiida-lsmo==1.0.0)
  Downloading aiida_core-1.6.9-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 35.8 MB/s eta 0:00:00
Collecting aiida-cp2k~=1.4 (from aiida-lsmo==1.0.0)
  Obtaining dependency information for aiida-cp2k~=1.4 from https://files.pythonhosted.org/packages/65/a8/8024bfb7c10760806b6d0d2aa09589898cda7ec7d391eef946d1609bb6c5/aiida_cp2k-1.6.0-py3-none-any.whl.metadata
  Downloading aiida_cp2k-1.6.0-py3-none-any.whl.metadata (3.9 kB)
Collecting aiida-ddec~=1.0 (from aiida-lsmo==1.0.0)
  Downloading aiida-ddec-1.1.0.tar.gz (12 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Installing backend dependencies: started
  Installing backend dependencies: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting aiida-zeopp>=1.0.3,~=1.0 (from aiida-lsmo==1.0.0)
  Downloading aiida-zeopp-1.1.2.tar.gz (17 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Installing backend dependencies: started
  Installing backend dependencies: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting aiida-raspa~=1.1 (from aiida-lsmo==1.0.0)
  Downloading aiida-raspa-1.2.0.tar.gz (15 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting calc-pe>=1.0.1,~=1.0 (from aiida-lsmo==1.0.0)
  Downloading calc_pe-1.0.1-py2.py3-none-any.whl (9.9 kB)
Collecting ruamel.yaml~=0.16.5 (from aiida-lsmo==1.0.0)
  Downloading ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 111.9/111.9 kB 39.9 MB/s eta 0:00:00
Collecting ase<3.20 (from aiida-lsmo==1.0.0)
  Downloading ase-3.19.3-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 118.6 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of aiida-lsmo to determine which version is compatible with other requirements. This could take a while.
ERROR: Ignored the following versions that require a different python version: 0.1a0 Requires-Python >=3.6.0,<3.8.0; 0.2.1 Requires-Python >=3.6.0,<3.8.0; 0.2.5 Requires-Python >=3.6.0,<3.8.0; 0.2a0 Requires-Python >=3.6.0,<3.8.0; 1.0.2 Requires-Python >=3.6.0,<3.8.0; 1.1.0 Requires-Python >=3.6,<3.9; 1.1.2 Requires-Python >=3.6,<3.9; 1.1.3 Requires-Python >=3.6,<3.9; 1.2.0 Requires-Python >=3.6,<3.9; 1.3.0 Requires-Python >=3.6,<3.9; 1.4.0 Requires-Python >=3.7,<3.9
ERROR: Could not find a version that satisfies the requirement oximachinerunner~=1.4.0 (from aiida-lsmo) (from versions: none)
ERROR: No matching distribution found for oximachinerunner~=1.4.0
</pre>`],warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:5},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:10}],pip_install_cmd:"pip install git+https://github.com/lsmo-epfl/aiida-lsmo",is_installable:"False"},"aiida-metavo-scheduler":{code_home:"https://github.com/pzarabadip/aiida-metavo-scheduler",development_status:"stable",entry_point_prefix:"metavo_scheduler",pip_url:"git+https://github.com/pzarabadip/aiida-metavo-scheduler",name:"aiida-metavo-scheduler",package_name:"aiida_metavo_scheduler",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"1.0.0",description:"",classifiers:["Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering"]},aiida_version:">=1.0.0,<1.6",entry_points:{"aiida.cmdline.computer.configure":{sshmetavo:"aiida_metavo_scheduler.metavo.ssh_metavo:CONFIGURE_SSH_CMD"},"aiida.schedulers":{pbsprometavo:"aiida_metavo_scheduler.metavo.pbspro_metavo:PbsproSchedulerMetaVO"},"aiida.transports":{sshmetavo:"aiida_metavo_scheduler.metavo.ssh_metavo:SshTransport"}},commits_count:0,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'sshmetavo' does not start with prefix 'metavo_scheduler.'","Entry point 'pbsprometavo' does not start with prefix 'metavo_scheduler.'","Entry point 'sshmetavo' does not start with prefix 'metavo_scheduler.'"],summaryinfo:[{colorclass:"orange",text:"Other (Cmdline computer configure, Schedulers, Transports)",count:3}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-metavo-scheduler",is_installable:"True"},"aiida-mpds":{code_home:"https://github.com/mpds-io/mpds-aiida",development_status:"beta",documentation_url:"https://github.com/mpds-io/mpds-aiida",entry_point_prefix:"mpds",pip_url:"git+https://github.com/mpds-io/mpds-aiida",name:"aiida-mpds",package_name:"aiida_mpds",hosted_on:"github.com",metadata:{author:"Andrey Sobolev",author_email:"as@tilde.pro",version:"",description:"Aiida workflows for MPDS based on CRYSTAL",classifiers:["Programming Language :: Python","Programming Language :: Python :: 3.5","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Information Analysis","Framework :: AiiDA"]},aiida_version:">=1.0.1",entry_points:{"aiida.workflows":{"crystal.mpds":"mpds_aiida.workflows.mpds:MPDSStructureWorkchain","crystal.cif":"mpds_aiida.workflows.cif:CIFStructureWorkchain","crystal.aiida":"mpds_aiida.workflows.aiida:AiidaStructureWorkchain"}},commits_count:6,errors:[`Failed to install plugin aiida-mpds</br><pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-xrwg7nfk
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-xrwg7nfk
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs (from mpds-aiida==0.10.0)
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-jwnpiujj/mpds-ml-labs_edcaadbfcbfa4cd88518a1c603810edf
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-jwnpiujj/mpds-ml-labs_edcaadbfcbfa4cd88518a1c603810edf
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft (from mpds-aiida==0.10.0)
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-jwnpiujj/aiida-crystal-dft_3b7ecc81de70417883cf3e63be03175a
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-jwnpiujj/aiida-crystal-dft_3b7ecc81de70417883cf3e63be03175a
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1 (from mpds-aiida==0.10.0)
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.9/site-packages (from mpds-aiida==0.10.0) (1.26.0)
Collecting ase>=3.19 (from mpds-aiida==0.10.0)
  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 23.0 MB/s eta 0:00:00
Collecting yascheduler>=1.0.12 (from mpds-aiida==0.10.0)
  Obtaining dependency information for yascheduler>=1.0.12 from https://files.pythonhosted.org/packages/ce/1d/8be161fa909c5f81282cc83c7c18e7030bcc9eb6e057ec7992b49b4770d1/yascheduler-1.2.0-py3-none-any.whl.metadata
  Downloading yascheduler-1.2.0-py3-none-any.whl.metadata (12 kB)
Collecting matplotlib>=3.1.0 (from ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/e0/8b/b62bc50b01bb2d4af96bc0045c39d60209e2701e172789ceace20a0866b2/matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)
Collecting scipy>=1.1.0 (from ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 22.9 MB/s eta 0:00:00
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.9/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (68.2.2)
Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.7)
Collecting aiohttp~=3.8 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for aiohttp~=3.8 from https://files.pythonhosted.org/packages/5b/8d/821fcb268cfc056964a75da3823896b17eabaa4968a2414121bc93b0c501/aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Collecting asyncssh~=2.11 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for asyncssh~=2.11 from https://files.pythonhosted.org/packages/c8/82/df5365b647cabf9f0f77135b7d7e845c14c6016f8f320b2a172ffe7e9af3/asyncssh-2.13.2-py3-none-any.whl.metadata
  Downloading asyncssh-2.13.2-py3-none-any.whl.metadata (9.8 kB)
Collecting asyncstdlib~=3.10 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for asyncstdlib~=3.10 from https://files.pythonhosted.org/packages/4a/62/0ac4017cc89d02410deda3c4848221bc807bbf77201058b68bc6ceb1c670/asyncstdlib-3.10.8-py3-none-any.whl.metadata
  Downloading asyncstdlib-3.10.8-py3-none-any.whl.metadata (3.5 kB)
Collecting attrs~=21.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 19.0 MB/s eta 0:00:00
Collecting azure-identity~=1.10.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 46.6 MB/s eta 0:00:00
Collecting azure-mgmt-compute~=27.2.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 50.3 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 89.0 MB/s eta 0:00:00
Collecting backoff~=2.1.2 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting hcloud~=1.17 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for hcloud~=1.17 from https://files.pythonhosted.org/packages/d4/2e/d51661c440f3064088487507e8d345637395dc4e90fad6a475a6ce7c8f6b/hcloud-1.29.0-py3-none-any.whl.metadata
  Downloading hcloud-1.29.0-py3-none-any.whl.metadata (4.7 kB)
Collecting pg8000~=1.19 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for pg8000~=1.19 from https://files.pythonhosted.org/packages/6e/2c/9d7ba4b76ad65a56bf0ff128b995b2caaa15eb7ac430268e10cfbcf99228/pg8000-1.30.2-py3-none-any.whl.metadata
  Downloading pg8000-1.30.2-py3-none-any.whl.metadata (78 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.0/79.0 kB 27.6 MB/s eta 0:00:00
Collecting python-daemon~=2.3 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.8.0)
Collecting upcloud_api~=2.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for upcloud_api~=2.0 from https://files.pythonhosted.org/packages/4d/5f/39b65e4412146ff1bdb75146b084a15cefc1a0c09d7db55476cc6c3876c5/upcloud_api-2.5.1-py3-none-any.whl.metadata
  Downloading upcloud_api-2.5.1-py3-none-any.whl.metadata (7.8 kB)
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.4.0.post0)
Collecting pycrystal>=1.0.10 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds_client>=0.24 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting pyparsing>2.3.1 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for pyparsing>2.3.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata
  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)
Collecting spglib>=1.16.0 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for spglib>=1.16.0 from https://files.pythonhosted.org/packages/86/a9/a35a6c9355d819a7c419a6ac13cd108130af2748efc7f7d94c38161aa3d7/spglib-2.1.0-cp39-cp39-manylinux_2_17_x86_64.whl.metadata
  Downloading spglib-2.1.0-cp39-cp39-manylinux_2_17_x86_64.whl.metadata (3.3 kB)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Collecting seekpath (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for seekpath from https://files.pythonhosted.org/packages/30/2c/fcb31e185a3a74d4098d9c44ac108ddcf1a4c88d7d3cea5a569dd812c62b/seekpath-2.1.0-py2.py3-none-any.whl.metadata
  Downloading seekpath-2.1.0-py2.py3-none-any.whl.metadata (4.7 kB)
Collecting pycodcif (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.3 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting imblearn (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)
Collecting progressbar (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading progressbar-2.5.tar.gz (10 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: alembic~=1.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.12.0)
Requirement already satisfied: archive-path~=0.4.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.4.2)
Requirement already satisfied: aio-pika~=6.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (6.8.1)
Requirement already satisfied: circus~=0.18.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.18.0)
Requirement already satisfied: click-spinner~=0.1.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.1.10)
Requirement already satisfied: disk-objectstore~=0.6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.6.0)
Requirement already satisfied: docstring-parser in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.15)
Requirement already satisfied: get-annotations~=0.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.1.2)
Requirement already satisfied: graphviz~=0.19 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.20.1)
Requirement already satisfied: ipython>=7 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (8.15.0)
Requirement already satisfied: kiwipy[rmq]~=0.7.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.7.7)
Requirement already satisfied: importlib-metadata~=4.13 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.13.0)
Requirement already satisfied: paramiko>=2.7.2,~=2.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.12.0)
Requirement already satisfied: plumpy~=0.21.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.21.8)
Requirement already satisfied: pgsu~=0.2.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.4)
Requirement already satisfied: psutil~=5.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (5.9.5)
Requirement already satisfied: psycopg2-binary~=2.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.9.7)
Requirement already satisfied: pytz~=2021.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2021.3)
Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (6.0.1)
Requirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.31.0)
Requirement already satisfied: sqlalchemy~=1.4.22 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.4.49)
Requirement already satisfied: tabulate~=0.8.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.8.10)
Requirement already satisfied: tqdm~=4.45 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.66.1)
Requirement already satisfied: upf_to_json~=0.9.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.9.5)
Requirement already satisfied: wrapt~=1.11 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.15.0)
Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0) (3.2.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0) (6.0.4)
Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata
  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)
Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0) (1.9.2)
Collecting frozenlist>=1.1.1 (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b5/03/7dec2e257bd173b5ca1f74477863b97d322149f6f0284d7decead8c5ceeb/frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)
Collecting aiosignal>=1.1.2 (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Requirement already satisfied: cryptography>=3.1 in /opt/conda/lib/python3.9/site-packages (from asyncssh~=2.11->yascheduler>=1.0.12->mpds-aiida==0.10.0) (41.0.4)
Collecting azure-core<2.0.0,>=1.11.0 (from azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for azure-core<2.0.0,>=1.11.0 from https://files.pythonhosted.org/packages/98/3a/d53e2b8a75c448ef45d7ae4b0659eb6c0d48978f25a709e2a39894a48704/azure_core-1.29.4-py3-none-any.whl.metadata
  Downloading azure_core-1.29.4-py3-none-any.whl.metadata (36 kB)
Collecting msal<2.0.0,>=1.12.0 (from azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for msal<2.0.0,>=1.12.0 from https://files.pythonhosted.org/packages/8f/71/5c385d104814fede34da5e10102bc0f4a0d05ef42eae052dac787381b2bc/msal-1.24.0-py2.py3-none-any.whl.metadata
  Downloading msal-1.24.0-py2.py3-none-any.whl.metadata (11 kB)
Collecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)
Collecting msrest>=0.6.21 (from azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 32.2 MB/s eta 0:00:00
Collecting azure-common~=1.1 (from azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)
Collecting azure-mgmt-core<2.0.0,>=1.3.1 (from azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)
Collecting python-dateutil>=2.7.5 (from hcloud~=1.17->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 62.3 MB/s eta 0:00:00
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2>=2.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.1.3)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0.1->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.19.3)
Collecting contourpy>=1.0.1 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/2b/c0/24c34c41a180f875419b536125799c61e2330b997d77a5a818a3bc3e08cd/contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)
Collecting cycler>=0.10 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/49/50/2e31753c088d364756daa5bed0dab6a5928ebfd6e6d26f975c8b6d6f754a/fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.0/151.0 kB 48.9 MB/s eta 0:00:00
Collecting kiwisolver>=1.0.1 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata
  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)
Collecting pillow>=6.2.0 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/0a/20/a94a0462495de73e248643fb24667270f2e67f44792456ab7207764e80cc/Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata
  Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
Collecting importlib-resources>=3.2.0 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for importlib-resources>=3.2.0 from https://files.pythonhosted.org/packages/65/6e/09d8816b5cb7a4006ef8ad1717a2703ad9f331dae9717d9f22488a2d6469/importlib_resources-6.1.0-py3-none-any.whl.metadata
  Downloading importlib_resources-6.1.0-py3-none-any.whl.metadata (4.1 kB)
Collecting httplib2 (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 36.7 MB/s eta 0:00:00
Collecting ujson (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for ujson from https://files.pythonhosted.org/packages/ed/2f/04fb635a03e11630ae8fd0dff8617442251a4845b7622e359fdf1256e172/ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)
Collecting pandas (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/bc/7e/a9e11bd272e3135108892b6230a115568f477864276181eada3a35d03237/pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Collecting jmespath (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting scramp>=1.4.4 (from pg8000~=1.19->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading scramp-1.4.4-py3-none-any.whl (13 kB)
Collecting bs4 (from pycrystal>=1.0.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading bs4-0.0.1.tar.gz (1.1 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting docutils (from python-daemon~=2.3->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for docutils from https://files.pythonhosted.org/packages/26/87/f238c0670b94533ac0353a4e2a1a771a0cc73277b88bff23d3ae35a256c1/docutils-0.20.1-py3-none-any.whl.metadata
  Downloading docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)
Collecting lockfile>=0.10 (from python-daemon~=2.3->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)
Collecting imbalanced-learn (from imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/a3/9e/fbe60a768502af54563dcb59ca7856f5a8833b3ad5ada658922e1ab09b7f/imbalanced_learn-0.11.0-py3-none-any.whl.metadata
  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)
Requirement already satisfied: aiormq<4,>=3.2.3 in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.3.1)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.2.4)
Requirement already satisfied: pyzmq>=17.0 in /opt/conda/lib/python3.9/site-packages (from circus~=0.18.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (25.1.1)
Requirement already satisfied: tornado>=5.0.2 in /opt/conda/lib/python3.9/site-packages (from circus~=0.18.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (6.3.3)
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=3.1->asyncssh~=2.11->yascheduler>=1.0.12->mpds-aiida==0.10.0) (1.15.1)
Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata~=4.13->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.17.0)
Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.0)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (5.1.1)
Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.19.0)
Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.1.6)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.7.5)
Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.39)
Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.16.1)
Requirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.6.2)
Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (5.10.0)
Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.1.3)
Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.8.0)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.0.11)
Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.10)
Requirement already satisfied: pytray<0.4.0,>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.3.4)
Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.1.0)
Requirement already satisfied: pamqp~=2.0 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.0)
Collecting PyJWT[crypto]<3,>=1.0.0 (from msal<2.0.0,>=1.12.0->azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for PyJWT[crypto]<3,>=1.0.0 from https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl.metadata
  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)
Collecting portalocker<3,>=1.0 (from msal-extensions<2.0.0,>=0.3.0->azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for portalocker<3,>=1.0 from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata
  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)
Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0) (2023.7.22)
Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 16.1 MB/s eta 0:00:00
Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.0.1)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.5.0)
Requirement already satisfied: nest_asyncio~=1.5 in /opt/conda/lib/python3.9/site-packages (from plumpy~=0.21.6->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.5.8)
Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.5)
Collecting asn1crypto>=1.5.1 (from scramp>=1.4.4->pg8000~=1.19->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 kB 39.9 MB/s eta 0:00:00
Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy~=1.4.22->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Collecting beautifulsoup4 (from bs4->pycrystal>=1.0.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.0/143.0 kB 46.9 MB/s eta 0:00:00
Collecting scikit-learn>=1.0.2 (from imbalanced-learn->imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for scikit-learn>=1.0.2 from https://files.pythonhosted.org/packages/af/ad/329a88013936e4372181c0e275c19aa6130b0835876726944b811af5a856/scikit_learn-1.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scikit_learn-1.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)
Collecting joblib>=1.1.1 (from imbalanced-learn->imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata
  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)
Collecting threadpoolctl>=2.0.0 (from imbalanced-learn->imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata
  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)
Collecting tzdata>=2022.1 (from pandas->mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 kB 82.7 MB/s eta 0:00:00
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.1->asyncssh~=2.11->yascheduler>=1.0.12->mpds-aiida==0.10.0) (2.21)
Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.8.3)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.7.0)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.6)
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 56.7 MB/s eta 0:00:00
Collecting soupsieve>1.2 (from beautifulsoup4->bs4->pycrystal>=1.0.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata
  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)
Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.2.0)
Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.4.0)
Requirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.2)
Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 26.0 MB/s eta 0:00:00
Downloading aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 98.1 MB/s eta 0:00:00
Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 84.1 MB/s eta 0:00:00
Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Downloading hcloud-1.29.0-py3-none-any.whl (82 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.1/82.1 kB 30.8 MB/s eta 0:00:00
Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 110.3 MB/s eta 0:00:00
Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 23.3 MB/s eta 0:00:00
Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 41.6 MB/s eta 0:00:00
Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.5/36.5 MB 66.7 MB/s eta 0:00:00
Downloading spglib-2.1.0-cp39-cp39-manylinux_2_17_x86_64.whl (802 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 802.1/802.1 kB 106.0 MB/s eta 0:00:00
Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Downloading seekpath-2.1.0-py2.py3-none-any.whl (77 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.5/77.5 kB 26.5 MB/s eta 0:00:00
Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)
Downloading azure_core-1.29.4-py3-none-any.whl (192 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 192.4/192.4 kB 53.7 MB/s eta 0:00:00
Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.9/301.9 kB 70.5 MB/s eta 0:00:00
Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 131.1 MB/s eta 0:00:00
Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.0/228.0 kB 66.3 MB/s eta 0:00:00
Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)
Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 129.9 MB/s eta 0:00:00
Downloading msal-1.24.0-py2.py3-none-any.whl (91 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.3/91.3 kB 36.9 MB/s eta 0:00:00
Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl (3.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 123.5 MB/s eta 0:00:00
Downloading docutils-0.20.1-py3-none-any.whl (572 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 572.7/572.7 kB 101.5 MB/s eta 0:00:00
Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 235.6/235.6 kB 71.3 MB/s eta 0:00:00
Downloading pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 115.0 MB/s eta 0:00:00
Downloading ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 21.0 MB/s eta 0:00:00
Downloading joblib-1.3.2-py3-none-any.whl (302 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.2/302.2 kB 75.5 MB/s eta 0:00:00
Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)
Downloading scikit_learn-1.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 124.0 MB/s eta 0:00:00
Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)
Downloading soupsieve-2.5-py3-none-any.whl (36 kB)
Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)
Building wheels for collected packages: mpds-aiida, aiida-crystal-dft, mpds-ml-labs, mpds_client, pycrystal, progressbar, pycodcif, sklearn, bs4
  Building wheel for mpds-aiida (setup.py): started
  Building wheel for mpds-aiida (setup.py): finished with status 'done'
  Created wheel for mpds-aiida: filename=mpds_aiida-0.10.0-py3-none-any.whl size=26465 sha256=2dedee032fc389ea8bd8a7bbd9a0ef0b139fe26fa00d315e026cf1cd3d88976b
  Stored in directory: /tmp/pip-ephem-wheel-cache-4bxd6gum/wheels/b0/06/8e/e50124efa87968a6d000ac392f488a8381db0c99360bc56d28
  Building wheel for aiida-crystal-dft (pyproject.toml): started
  Building wheel for aiida-crystal-dft (pyproject.toml): finished with status 'done'
  Created wheel for aiida-crystal-dft: filename=aiida_crystal_dft-0.9.0-py3-none-any.whl size=615034 sha256=0fc2d7680ece94e1708b7c31419d0a23ce4dcdef9413067633d23861661d20f9
  Stored in directory: /tmp/pip-ephem-wheel-cache-4bxd6gum/wheels/35/4e/8b/d0c50c1944f5a32b7e9cf5a628dd09bed51de5b4623743f1d3
  Building wheel for mpds-ml-labs (setup.py): started
  Building wheel for mpds-ml-labs (setup.py): finished with status 'done'
  Created wheel for mpds-ml-labs: filename=mpds_ml_labs-0.0.7-py3-none-any.whl size=36846 sha256=2bd5b44ccd4601ea5967ac78e9bc20f8768d8d8e978d749c61e4f9fbc4afead2
  Stored in directory: /tmp/pip-ephem-wheel-cache-4bxd6gum/wheels/5d/93/92/e3750b9bf7d3ffd0d83691009b13f45e86e5cbabfe59e7747d
  Building wheel for mpds_client (setup.py): started
  Building wheel for mpds_client (setup.py): finished with status 'done'
  Created wheel for mpds_client: filename=mpds_client-0.24-py3-none-any.whl size=9964 sha256=f2258060c5339d2a270671929dfb9061095f3af63a6ff375b76d611061d8f27b
  Stored in directory: /home/aiida/.cache/pip/wheels/93/b3/59/e20f7bf029c83fbeadc49a864bc70312197114776f10aa9442
  Building wheel for pycrystal (setup.py): started
  Building wheel for pycrystal (setup.py): finished with status 'done'
  Created wheel for pycrystal: filename=pycrystal-1.0.16-py3-none-any.whl size=27472 sha256=61b490fe726c29c041976fd7639f37e9a7dcb511eaad5d0a81b7058c73e1bc1e
  Stored in directory: /home/aiida/.cache/pip/wheels/b5/e3/5f/ac959ea648bd0f96552d2f20b71c5a640bf956589a88beb8b1
  Building wheel for progressbar (setup.py): started
  Building wheel for progressbar (setup.py): finished with status 'done'
  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12067 sha256=1d32c4f42aa7a567bbc2cd9eeb548d5857802c095d99738be0b8e51c513c1455
  Stored in directory: /home/aiida/.cache/pip/wheels/d7/d9/89/a3f31c76ff6d51dc3b1575628f59afe59e4ceae3f2748cd7ad
  Building wheel for pycodcif (setup.py): started
  Building wheel for pycodcif (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [8 lines of output]
      running bdist_wheel
      running build
      running build_py
      running build_ext
      building 'pycodcif._pycodcif' extension
      swigging pycodcif.i to pycodcif_wrap.c
      swig -python -o pycodcif_wrap.c pycodcif.i
      error: command 'swig' failed: No such file or directory
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for pycodcif
  Running setup.py clean for pycodcif
  Building wheel for sklearn (setup.py): started
  Building wheel for sklearn (setup.py): finished with status 'done'
  Created wheel for sklearn: filename=sklearn-0.0.post9-py3-none-any.whl size=2952 sha256=5608123a0f79ff1f03b1807eaf505e351b7d2fdea40159028b5a74bdbcc8f1db
  Stored in directory: /home/aiida/.cache/pip/wheels/e2/4f/96/3b01e8981cb6f333764a2443a1f4777896180da6e46efe95c1
  Building wheel for bs4 (setup.py): started
  Building wheel for bs4 (setup.py): finished with status 'done'
  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=79eaad14827e7cb61ee2bd462b868929c44c4c6c007f005ada515234dca55140
  Stored in directory: /home/aiida/.cache/pip/wheels/73/2b/cb/099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3
Successfully built mpds-aiida aiida-crystal-dft mpds-ml-labs mpds_client pycrystal progressbar sklearn bs4
Failed to build pycodcif
ERROR: Could not build wheels for pycodcif, which is required to install pyproject.toml-based projects
</pre>`],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'crystal.mpds' does not start with prefix 'mpds.'","Entry point 'crystal.cif' does not start with prefix 'mpds.'","Entry point 'crystal.aiida' does not start with prefix 'mpds.'"],summaryinfo:[{colorclass:"green",text:"Workflows",count:3}],pip_install_cmd:"pip install git+https://github.com/mpds-io/mpds-aiida",is_installable:"False"},"aiida-muon":{entry_point_prefix:"muon",code_home:"https://github.com/positivemuon/aiida-muon",version_file:"https://raw.githubusercontent.com/positivemuon/aiida-muon/main/aiida_muon/__init__.py",pip_url:"git+https://github.com/positivemuon/aiida-muon",name:"aiida-muon",package_name:"aiida_muon",hosted_on:"github.com",metadata:{description:"aiida-muon is allows to find candiate muon implantation sites and hyperfine field by DFT supercell relaxations and from further symmetry and kinetics analysis.  ",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 2 - Pre-Alpha","Framework :: AiiDA"],author:"Muon  group Parma"},aiida_version:">=2.0,<3",entry_points:{"aiida.workflows":{"muon.find_muon":{description:["FindMuonWorkChain finds the candidate implantation site for a positive muon.","    It first performs DFT relaxation calculations for a set of initial muon sites.","    It then analyzes the results of these calculations and finds candidate muon sites.","    If there are magnetic inequivalent sites not initially, they are recalculated","    It further calculates the muon contact hyperfine field at these candidate sites."],spec:{inputs:[{name:"sc_matrix",required:!0,valid_types:"List",info:" List of length 1 for supercell size "},{name:"structure",required:!0,valid_types:"StructureData",info:"Input initial structure"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"mu_spacing",required:!1,valid_types:"Float, NoneType",info:"Minimum distance in Angstrom between two starting muon positions  generated on a grid."},{name:"qe",required:!1,valid_types:"",info:"Input parameters, settings and options for QE DFT calculations"}],outputs:[{name:"all_index_uuid",required:!0,valid_types:"Dict",info:""},{name:"all_sites",required:!0,valid_types:"Dict",info:""},{name:"unique_sites",required:!0,valid_types:"Dict",info:""},{name:"unique_sites_dipolar",required:!1,valid_types:"List",info:""},{name:"unique_sites_hyperfine",required:!1,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:405,message:"One of the PwRelaxWorkChain subprocesses failed"},{status:406,message:"One of the PwBaseWorkChain subprocesses failed"},{status:407,message:"One of the PPWorkChain subprocesses failed"}]},class:"aiida_muon.workflows.find_muon:FindMuonWorkChain"}}},commits_count:21,development_status:"pre-alpha",errors:[],warnings:[],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/positivemuon/aiida-muon",is_installable:"True"},"aiida-musconv":{entry_point_prefix:"musconv",code_home:"https://github.com/positivemuon/aiida-musconv",version_file:"raw.githubusercontent.com/positivemuon/aiida-musconv/main/aiida_musconv/__init__.py",pip_url:"git+https://github.com/positivemuon/aiida-musconv",name:"aiida-musconv",package_name:"aiida_musconv",hosted_on:"github.com",metadata:{description:"aiida-musconv is a plugin that allows to obtain converged supercell size for an interstitial impurity calculation.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 2 - Pre-Alpha","Framework :: AiiDA"],author:"Muon  group Parma"},aiida_version:">=2.0,<3",entry_points:{"aiida.workflows":{musconv:{description:["WorkChain for finding converged supercell for interstitial impurity calculation"],spec:{inputs:[{name:"pwscf",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Input initial structure"},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space."},{name:"max_iter_num",required:!1,valid_types:"Int, NoneType",info:"Maximum number of iteration in the supercell convergence loop"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_length",required:!1,valid_types:"Float, NoneType",info:"The minimum length of the smallest lattice vector for the first generated supercell "},{name:"pseudofamily",required:!1,valid_types:"Str, NoneType",info:"The label of the pseudo family"}],outputs:[{name:"Converged_SCmatrix",required:!0,valid_types:"ArrayData",info:""},{name:"Converged_supercell",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:402,message:"one of the PwCalculation subprocesses failed"},{status:702,message:"Max number of supercell convergence reached "},{status:704,message:"Error in fitting the forces to an exponential"}]},class:"aiida_musconv.workflows.musconv:MusconvWorkChain"}}},commits_count:43,development_status:"pre-alpha",errors:[],warnings:[],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/positivemuon/aiida-musconv",is_installable:"True"},"aiida-nanotech-empa":{code_home:"https://github.com/nanotech-empa/aiida-nanotech-empa",development_status:"beta",entry_point_prefix:"nanotech_empa",pip_url:"git+https://github.com/nanotech-empa/aiida-nanotech-empa",name:"aiida-nanotech-empa",package_name:"aiida_nanotech_empa",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:31,errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/nanotech-empa/aiida-nanotech-empa/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/nanotech-empa/aiida-nanotech-empa",is_installable:"True"},"aiida-nims-scheduler":{code_home:"https://github.com/atztogo/aiida-nims-scheduler",development_status:"stable",documentation_url:"https://github.com/atztogo/aiida-nims-scheduler",entry_point_prefix:"nims_scheduler",pip_url:"git+https://github.com/atztogo/aiida-nims-scheduler",name:"aiida-nims-scheduler",package_name:"aiida_nims_scheduler",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:25,errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/atztogo/aiida-nims-scheduler/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/atztogo/aiida-nims-scheduler",is_installable:"True"},"aiida-nwchem":{code_home:"https://github.com/aiidateam/aiida-nwchem",documentation_url:"https://aiida-nwchem.readthedocs.io/",entry_point_prefix:"nwchem",pip_url:"aiida-nwchem",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-nwchem/master/setup.json",name:"aiida-nwchem",package_name:"aiida_nwchem",hosted_on:"github.com",metadata:{release_date:"2023-08-22",description:"The official AiiDA plugin for NWChem",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"3.0.1"},aiida_version:">=2.0,<3.0",entry_points:{"aiida.calculations":{"nwchem.base":{description:["Base calculation class for NWChem."],spec:{inputs:[{name:"input_file",required:!0,valid_types:"SinglefileData",info:"NWChem input file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, FolderData, NoneType",info:"Remote directory of a completed NWChem calculation to restart from."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Required output files are missing."},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"The stdout output file could not be read."},{status:312,message:"The stdout output file was incomplete."},{status:313,message:"The stdout contains multiple calculations"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception."}]},class:"aiida_nwchem.calculations.nwchem:NwchemBaseCalculation"},"nwchem.nwchem":{description:["Base calculation class for NWChem.","","    Synthesizes NWChem input file from parameter dictionary and StructureData."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure, with or without a cell"},{name:"add_cell",required:!1,valid_types:"Bool",info:"The input structure, with or without a cell"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, FolderData, NoneType",info:"Remote directory of a completed NWChem calculation to restart from."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Required output files are missing."},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"The stdout output file could not be read."},{status:312,message:"The stdout output file was incomplete."},{status:313,message:"The stdout contains multiple calculations"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception."}]},class:"aiida_nwchem.calculations.nwchem:NwchemCalculation"}},"aiida.parsers":{"nwchem.nwchem":"aiida_nwchem.parsers.nwchem:NwchemBaseParser"},"aiida.workflows":{"nwchem.base":{description:["Workchain to run an NWChem calculation with automated error handling and restarts."],spec:{inputs:[{name:"nwchem",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_nwchem.workflows.base:NwchemBaseWorkChain"}}},commits_count:22,development_status:"beta",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-nwchem",is_installable:"True"},"aiida-open_circuit_voltage":{entry_point_prefix:"quantumespresso.ocv",code_home:"https://github.com/tsthakur/aiida-open_circuit_voltage",name:"aiida-open_circuit_voltage",package_name:"aiida_open_circuit_voltage",hosted_on:"github.com",metadata:{author:"Tushar Thakur",author_email:"tushar.thakur@epfl.ch",version:"0.1.0",description:"The AiiDA plugin to calculate ocv at various charge of states using QE",classifiers:["Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Development Status :: 3 - Alpha","Natural Language :: English","Intended Audience :: Science/Research"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.workflows":{"quantumespresso.ocv.ocvwc":"aiida_open_circuit_voltage.workflows.workchain:OCVWorkChain"}},commits_count:26,development_status:"alpha",errors:[],warnings:["Prefix 'quantumespresso.ocv' does not follow naming convention."],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"See source code repository."},"aiida-optimize":{code_home:"https://github.com/greschd/aiida-optimize",documentation_url:"https://aiida-optimize.readthedocs.io",entry_point_prefix:"optimize",pip_url:"aiida-optimize",plugin_info:"https://raw.githubusercontent.com/greschd/aiida-optimize/master/setup.json",name:"aiida-optimize",package_name:"aiida_optimize",hosted_on:"github.com",metadata:{release_date:"2023-03-30",description:"AiiDA Plugin for running optimization algorithms.",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-optimize.readthedocs.io/",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"1.0.2"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.workflows":{"optimize.optimize":{description:["Runs an optimization procedure, given an optimization engine that defines the optimization","    algorithm, and a process which evaluates the function to be optimized."],spec:{inputs:[{name:"engine",required:!0,valid_types:"Str",info:"Engine that runs the optimization."},{name:"engine_kwargs",required:!0,valid_types:"Dict",info:"Keyword arguments passed to the optimization engine."},{name:"evaluate_process",required:!0,valid_types:"Str",info:"Process which produces the result to be optimized."},{name:"evaluate",required:!1,valid_types:"",info:"Inputs that are passed to all evaluation processes."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"optimal_process_output",required:!0,valid_types:"",info:"Output value of the optimal evaluation process."},{name:"optimal_process_uuid",required:!0,valid_types:"",info:"UUID of the optimal evaluation process."},{name:"engine_outputs",required:!1,valid_types:"",info:""},{name:"optimal_process_input",required:!1,valid_types:"",info:"Input value of the optimal evaluation process."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Optimization failed because one of the evaluate processes did not finish ok."},{status:202,message:"Optimization failed because the engine did not finish ok."}]},class:"aiida_optimize._optimization_workchain:OptimizationWorkChain"},"optimize.wrappers.add_inputs":{description:["Wrapper workchain that takes inputs as keys and values and passes it","    on to a sub-process. This enables taking a process which was not","    designed to be used in optimization, and optimize with respect to","    some arbitrary input. Inputs which always remain the same can be","    specified in the ``inputs`` namespace, whereas the inputs to be","    optimized are given through the ``added_input_keys`` and","    ``added_input_values`` inputs.","","    The outputs of the wrapper workchain are the same as those of","    the wrapped process.","",'    The "added" inputs can only be BaseType sub-classes, or',"    attributes of a Dict. For each input, its port location is given",'    in the "added_input_keys" input. For example, ``x.y`` would set',"    the ``y`` input in the ``x`` namespace.","","    For cases where the input is a Dict attribute, the (possibly nested) attribute name is given after a colon. That means ``x:a.b`` would","    set the ``['a']['b']`` attribute of the ``Dict`` given in the ``x``","    input.","","    In cases where only a single input needs to be added, they can be","    specified directly instead of wrapped in a List."],spec:{inputs:[{name:"added_input_keys",required:!0,valid_types:"List, Str",info:"Specifies the location of each added input."},{name:"added_input_values",required:!0,valid_types:"List, BaseType",info:"Values of the added inputs to be passed into the sub-process."},{name:"sub_process",required:!0,valid_types:"Str",info:"The class of the process that should be wrapped."},{name:"inputs",required:!1,valid_types:"",info:"Inputs to be passed on to the sub-process."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Workchain failed because the sub-process did not finish ok."}]},class:"aiida_optimize.wrappers._add_inputs:AddInputsWorkChain"},"optimize.wrappers.concatenate":{description:["Allows concatenating an arbitrary number of sub-processes.","","    A wrapper workchain that allows concatenating an arbitrary number","    of sub-processes. Outputs of one processes can be configured to","    be passed to the next one."],spec:{inputs:[{name:"output_input_mappings",required:!0,valid_types:"List",info:"Defines how inputs are passed between sub-processes. Each list entry entry has the form `((process_label_a, process_label_b), mapping)`, and defines outputs of process A to be passed to process B. The `mapping` values are dictionaries `{'output_name': 'input_name'}` giving the output name (in process A) and input name (in process B) for each value to pass."},{name:"process_inputs",required:!0,valid_types:"",info:"Inputs which are passed on to the sub-processes. The inputs should be grouped into a namespace identified by the process label."},{name:"process_labels",required:!0,valid_types:"List",info:"A list of pairs (label, process_name). The labels can be any string, the process_name needs to be loadable by `aiida_optimize.process_inputs.load_object`, and defines which process is being run."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"process_outputs",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"Workchain failed because a sub-process failed."}]},class:"aiida_optimize.wrappers._concatenate:ConcatenateWorkChain"},"optimize.wrappers.create_evaluate":{description:["Wrapper workchain to combine two processes: The first process _creates_","    a result, and the second _evaluates_ that result.","","    The purpose of this workchain is to facilitate optimization of processes","    which don't natively produce an output that can be optimized, by only","    having to add the 'evaluation' part."],spec:{inputs:[{name:"create",required:!0,valid_types:"",info:"Inputs which are passed on to the create sub-process."},{name:"create_process",required:!0,valid_types:"Str",info:"The sub-process which performs the create step."},{name:"evaluate_process",required:!0,valid_types:"Str",info:"The sub-process which performs the evaluate step."},{name:"output_input_mapping",required:!0,valid_types:"Dict",info:"A mapping from output names of the create process to input names of the evaluate process. These outputs (if present) are forwarded to the evaluate process."},{name:"evaluate",required:!1,valid_types:"",info:"Inputs which are passed on to the evaluate sub-process."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"create",required:!0,valid_types:"",info:""},{name:"evaluate",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Workchain failed because the 'create' sub-process failed."},{status:202,message:"Workchain failed because the 'evaluate' sub-process failed."}]},class:"aiida_optimize.wrappers._create_evaluate:CreateEvaluateWorkChain"}}},commits_count:2,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"green",text:"Workflows",count:4}],pip_install_cmd:"pip install aiida-optimize",is_installable:"True"},"aiida-orca":{code_home:"https://github.com/pzarabadip/aiida-orca",development_status:"stable",documentation_url:"https://aiida-orca.readthedocs.io/",entry_point_prefix:"orca",pip_url:"git+https://github.com/pzarabadip/aiida-orca",name:"aiida-orca",package_name:"aiida_orca",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"0.5.1",description:"AiiDA plugin for ORCA code",classifiers:["Environment :: Plugins","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Framework :: AiiDA"]},aiida_version:">=1.0.0,<2.0.0",entry_points:{"aiida.calculations":{orca_main:"aiida_orca.calculations:OrcaCalculation",orca_asa:"aiida_orca.calculations:OrcaAsaCalculation"},"aiida.parsers":{orca_base_parser:"aiida_orca.parsers:OrcaBaseParser"},"aiida.workflows":{"orca.base":{description:["Workchain to run a orca calculation with automated error handling and restarts."],spec:{inputs:[{name:"orca",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"the results of the calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"relaxed_structure",required:!1,valid_types:"StructureData",info:"relaxed structure"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:301,message:"The calculation failed with an unrecoverable error coming from aiida-orca."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_orca.workchains:OrcaBaseWorkChain"}}},commits_count:40,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-orca",is_installable:"True"},"aiida-phonopy":{code_home:"https://github.com/aiida-phonopy/aiida-phonopy",documentation_url:"https://aiida-phonopy.readthedocs.io/",entry_point_prefix:"phonopy",pip_url:"aiida-phonopy",plugin_info:"https://raw.githubusercontent.com/aiida-phonopy/aiida-phonopy/master/setup.json",name:"aiida-phonopy",package_name:"aiida_phonopy",hosted_on:"github.com",metadata:{release_date:"2023-05-24",description:"The official AiiDA plugin for Phonopy",author_email:"Lorenzo Bastonero <bastonero.lorenzo@gmail.com>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"1.1.3"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{"phonopy.phonopy":{description:["Base `CalcJob` implementation for Phonopy post-processing."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:`Phonopy parameters (\`setting tags\`) for post processing. The following tags, along their type, are allowed:
PRIMITIVE_AXES
PRIMITIVE_AXIS
EIGENVECTORS
BAND
BAND_PATHS
BAND_POINTS
BAND_LABELS
BAND_CONNECTION
BAND_INDICES
MESH
MP
MESH_NUMBERS
MP_SHIFT
GAMMA_CENTER
WRITE_MESH
DOS
DOS_RANGE
FMIN
FMAX
FPITCH
PDOS
PROJECTION_DIRECTION
XYZ_DIRECTION
SIGMA
DEBYE_MODEL
MOMEMT
MOMENT_ORDER
TPROP
TMIN
TMAX
TSTEP
PRETEND_REAL
CUTOFF_FREQUENCY
TDISP
TDISPMAT
TDISPMAT_CIF
QPOINTS
WRITEDM
NAC_METHOD
Q_DIRECTION
GROUP_VELOCITY
GV_DELTA_Q
SYMMETRY_TOLERANCE
SYMMETRY
MESH_SYMMETRY
FC_SYMMETRY
FULL_FORCE_CONSTANTS
WRITE_FORCE_CONSTANTS
ANIME_TYPE
ANIME
MODULATION
IRREPS
SHOW_IRREPS
LITTLE_COGROUP`},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"force_constants",required:!1,valid_types:"ForceConstantsData, NoneType",info:"Force constants of the input structure."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"phonopy_data",required:!1,valid_types:"PhonopyData, NoneType",info:"The preprocess output info of a previous ForceConstantsWorkChain."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Settings for phonopy calculation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"irreducible_representations",required:!1,valid_types:"Dict",info:"Irreducible representation output."},{name:"modulation",required:!1,valid_types:"Dict",info:"Modulation information."},{name:"output_force_constants",required:!1,valid_types:"ArrayData",info:"Calculated force constants."},{name:"output_parameters",required:!1,valid_types:"Dict",info:"Sum up info of phonopy calculation."},{name:"phonon_bands",required:!1,valid_types:"BandsData",info:"Calculated phonon band structure."},{name:"projected_phonon_dos",required:!1,valid_types:"XyData",info:"Calculated projected DOS."},{name:"qpoints",required:!1,valid_types:"BandsData",info:"Calculated qpoints."},{name:"qpoints_mesh",required:!1,valid_types:"BandsData",info:"Calculated qpoint mesh."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"thermal_displacement_matrices",required:!1,valid_types:"Dict",info:"Calculated thermal displacements matrices."},{name:"thermal_displacements",required:!1,valid_types:"Dict",info:"Calculated thermal displacements."},{name:"thermal_properties",required:!1,valid_types:"XyData",info:"Calculated thermal properties."},{name:"total_phonon_dos",required:!1,valid_types:"XyData",info:"Calculated total DOS."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required phonopy file."},{status:304,message:"The retrieved folder did not contain one or more expected output files."},{status:305,message:"No run mode has been selected."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The loading of yaml file got an unexpected error."},{status:321,message:"The file loading via numpy got an unexpected error."},{status:350,message:"The parser raised an unexpected exception."},{status:400,message:"The parser was not able to parse one or more files."}]},class:"aiida_phonopy.calculations.phonopy:PhonopyCalculation"}},"aiida.data":{"phonopy.force_constants":"aiida_phonopy.data.force_constants:ForceConstantsData","phonopy.phonopy":"aiida_phonopy.data.phonopy:PhonopyData","phonopy.preprocess":"aiida_phonopy.data.preprocess:PreProcessData","phonopy.raw":"aiida_phonopy.data.raw:RawData"},"aiida.parsers":{"phonopy.phonopy":"aiida_phonopy.parsers.phonopy:PhonopyParser"},"aiida.workflows":{"phonopy.phonopy":{description:["Abstract workflow for automated frozen phonons.","","    Phonopy is used to produce structures with displacements,","    while the forces are calculated with a quantum engine of choice.","","    This workchain is meant to be used as a base for other specific force calculato plugin workchains,","    or as an example on how to set a possible workchain/workflow. For this reason, the outline of","    this class is not defined, while it provides the inputs and a `setup` method, which can be used","    in a specific workflow outline. Ideally, the workflow would look like:","","    1. Setup the preprocess data.","","        This is already provided in this class. It setups a `PreProcessData` node, from where","        supercell, primitive cell and supercells with displacements can be easily extracted using","        the methods of the nodes. This node can be taken from `self.ctx.preprocess_data`, and used","        during the outline of the workflow.","","    2. Run supercells using the selected quantum engine/force calculator code.","","        In specific code implementations, a force calculation on supercells needs to be run.","        To get these supercells, one need simply to run:","","        ```self.ctx.preprocess_data.calcfunctions.get_supercells_with_displacements()```","","        This will return a dictionary with all the supercells as StructureData to run for the phonon calculation.","        The keys of this dictionary are of the type `supercell_{number}`, where `number` is an integer.","        These numbers are essentials since the `phonopy` force sets is generated following these numbers,","        in order to make sure to refer to the correct displacement. Thus, it is required to keep track","        of them.","        Moreover,a calculation over the pristine supercell structure should be run before hand as reference.","        This structure can instead be gotten via:","","        ```self.ctx.preprocess_data.calcfunctions.get_supercell()```","","        This will return a StructureData without any label.","","        For an example of implementation, refer to aiidateam/aiida-common-worfklows.","","        * Note: some type of force calculation needs to map some variables from the unitcell to the supercell","        (and in certain case even the primitive cell), e.g. the atomic spin in VASP. Since this is code dependent,","        you will need to map these parameters before launching the force calculation of a certain supercell","        with displacement. This information can be gotten via:","","        ```self.ctx.preprocess_data.get_cells_mappings()```","","        Moreover, consider that cells in phonopy will always (re)fold the atoms in order to have positive coordinates.","","    3. Inspect all runs and expose the forces and energies (not mandatory) outputs.","","        * Suggested: when the calculation on each supercell has finished (correctly)","        expose the output forces (and energies) in the dynamical `supercells_forces(energies)` namespace(s).","        Provide each supercell forces as an `ArrayData` with the forces stored as `forces`","        (e.g. if your code plugin stores  the forces in `TrajectoryData`, extract them with a `calcfunction`).","        Expose each `ArrayData` choosing a **common prefix**, while as **suffix use","        _{number}**, with `{number}` referring to the correspective supercell label suffix (that you are supposed to","        keep track somewhere, e.g. in the label of the code calculation/workchain).","        Now you can gather all the information in one data noe, i.e. in a `PhonopyData` node.","        To do so, you can simple run:","","        ```self.ctx.preprocess_data.calcfunctions.generate_phonopy_data(**self.outputs.supercells_forces)```","","        and then expose it as output in the `output_phonopy_data` namespace.","","        * Alternatively: instead of exposing the supercell forces as outputs, you can directly gather all the forces","        in a dictionary and run directly to the `generate_phonopy_data` method using this dictionary (always using","        the double *).","","        See the implementation in aiidateam/aiida-common-workflows for an example.","","    4. (optional) Run the non-analytical constants on the primitive cell.","","        Non-analytical constants should be run for polar insulators. These require usually a linear response code","        or a finite difference approach (e.g. using the electric enthalpy). Since this is usually the most expensive","        part, you should run them on the primitive cell. To get it, use:","","        ```self.ctx.preprocess_data.calcfunctions.get_primitive_cell()```","","        If you compute also these, collect the dielectric tensor and the effectic born charges in an ArrayData,","        with the arraynames `dielectric` and `born_charges` (in Cartesian coordinates!).","        Then, gather all the information of nac and forces in a unique `PhonopyData` via:","","        ```","        self.ctx.preprocess_data.calcfunctions.generate_phonopy_data(","            nac_parameters=nac_paramters,","            **self.outputs.supercells_forces","            )","        ```","","        and expose the output.","","        * Note: we require in the input for generating the full phonopy data, to give the nac in the primitive cell.","        The primitive cell of phonopy will just rotate the lattice vectors, thus mantaining the Cartasian coordinate","        system. It can happen, though, that the unitcell is not the primitive cell of the system, meaning that the","        primitive cell will contain less atoms. We expect in input the nac computed on this number of atoms. If you","        want, for some reason, compute the nac on the unitcell, you will need to get the reduced nac.","        To do so, you can consider using a built-in function in phonopy, namely:","","        :py:func:`phonopy.structure.symmetry.elaborate_borns_and_epsilon`"],spec:{inputs:[{name:"options",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"displacement_generator",required:!1,valid_types:"Dict, NoneType",info:`Info for displacements generation. The following flags are allowed:
 distance
 is_plusminus
 is_diagonal
 is_trigonal
 number_of_snapshots
 random_seed
 temperature
 cutoff_frequency`},{name:"fc_options",required:!1,valid_types:"Dict, NoneType",info:`Options for force constants calculation (optional). The following flags are allowed:
 calculate_full_force_constants
 fc_calculator
 fc_calculator_options`},{name:"is_symmetry",required:!1,valid_types:"Bool, NoneType",info:"Whether using or not the space group symmetries."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"nac_parameters",required:!1,valid_types:"ArrayData, NoneType",info:"Non-analytical parameters."},{name:"preprocess_data",required:!1,valid_types:"PhonopyData, PreProcessData, NoneType",info:"The preprocess data for frozen phonon calcualtion."},{name:"primitive_matrix",required:!1,valid_types:"List, NoneType",info:"The matrix used to generate the primitive cell from the input structure in the List format. Allowed shapes are 3x1 and 3x3 lists."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"The structure at equilibrium volume."},{name:"supercell_matrix",required:!1,valid_types:"List, NoneType",info:"The matrix used to generate the supercell from the input structure in the List format. Allowed shapes are 3x1 and 3x3 lists."},{name:"symmetry_tolerance",required:!1,valid_types:"Float, NoneType",info:"Symmetry tolerance for space group analysis on the input structure."}],outputs:[{name:"output_phonopy_data",required:!0,valid_types:"PhonopyData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"supercells_forces",required:!0,valid_types:"ArrayData",info:"The forces acting on the atoms of each supercell."},{name:"output_force_constants",required:!1,valid_types:"ForceConstantsData",info:"The matrix of force constants computed with finite displacements."},{name:"supercells",required:!1,valid_types:"StructureData",info:"The supercells with displacements."},{name:"supercells_energies",required:!1,valid_types:"Float",info:"The total energy of each supercell."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_phonopy.workflows.phonopy:PhonopyWorkChain"}}},commits_count:64,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:4},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-phonopy",is_installable:"True"},"aiida-phtools":{code_home:"https://github.com/ltalirz/aiida-phtools",entry_point_prefix:"phtools",pip_url:"aiida-phtools",plugin_info:"https://raw.github.com/ltalirz/aiida-phtools/master/setup.json",name:"aiida-phtools",package_name:"aiida_phtools",hosted_on:"github.com",metadata:{release_date:"2018-06-21",description:"AiiDA plugin for persistence homology tools, used to analyze nanoporous materials.",author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-phtools",classifiers:["Programming Language :: Python"],version:"0.1.0a1"},aiida_version:"*",entry_points:{"aiida.calculations":{"phtools.dmatrix":"aiida_phtools.calculations.distance_matrix:DistanceMatrixCalculation","phtools.surface":"aiida_phtools.calculations.pore_surface:PoreSurfaceCalculation"},"aiida.data":{"phtools.surface":"aiida_phtools.data.pore_surface:PoreSurfaceParameters"},"aiida.parsers":{"phtools.dmatrix":"aiida_phtools.parsers.distance_matrix:DistanceMatrixParser","phtools.surface":"aiida_phtools.parsers.pore_surface:PoreSurfaceParser"}},commits_count:0,development_status:"planning",errors:[],warnings:["Missing classifier 'Framework :: AiiDA'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install --pre aiida-phtools"},"aiida-plumed":{code_home:"https://github.com/ConradJohnston/aiida-plumed",entry_point_prefix:"plumed",pip_url:"aiida-plumed",plugin_info:"https://raw.github.com/ConradJohnston/aiida-plumed/AiiDA-v1.0-compatibility/setup.json",name:"aiida-plumed",package_name:"aiida_plumed",hosted_on:"github.com",metadata:{release_date:"2019-09-16",description:"AiiDA plugin providing support for Plumed2",author:"Conrad Johnston",author_email:"conrad.s.johnston@googlemail.com",license:"MIT",home_page:"https://github.com/ConradJohnston/aiida-plumed",classifiers:["Development Status :: 2 - Pre-Alpha","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0a0"},aiida_version:">=1.0.0b3,<2.0.0",entry_points:{"aiida.calculations":{plumed:"aiida_plumed.calculations:DiffCalculation"},"aiida.cmdline.data":{plumed:"aiida_plumed.cli:data_cli"},"aiida.data":{plumed:"aiida_plumed.data:DiffParameters"},"aiida.parsers":{plumed:"aiida_plumed.parsers:DiffParser"}},commits_count:0,development_status:"pre-alpha",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install --pre aiida-plumed",is_installable:"True"},"aiida-porousmaterials":{code_home:"https://github.com/pzarabadip/aiida-porousmaterials",development_status:"stable",entry_point_prefix:"porousmaterials",pip_url:"aiida-porousmaterials",name:"aiida-porousmaterials",package_name:"aiida_porousmaterials",hosted_on:"github.com",metadata:{release_date:"2020-03-05",description:"AiiDA plugin for PorousMaterials code",author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",license:"MIT",home_page:"https://github.com/pzarabadip/aiida-porousmaterials",classifiers:["Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8"],version:"1.0.0a3"},aiida_version:null,entry_points:{"aiida.calculations":{porousmaterials:{description:["This is PorousMaterialsCalculation as the subclass","    of AiiDA CalcJob to prepare input for the PorousMaterials","    suite of Julia codes.","    Please refer to : https://github.com/SimonEnsemble/PorousMaterials.jl"],spec:{inputs:[{name:"acc_voronoi_nodes",required:!0,valid_types:"SinglefileData",info:"Accessible Voronoi nodes calculated by Zeo++"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"parameters such as cutoff and mixing rules."},{name:"structure",required:!0,valid_types:"CifData",info:"Framework input file as CIF"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"settings",required:!1,valid_types:"Dict",info:"Additional input parameters"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"dictionary of calculated Voronoi energies"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"ev_output_file",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"The retrieved folder does not contain an output file."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_porousmaterials.calculations:PorousMaterialsCalculation"}},"aiida.parsers":{porousmaterials:"aiida_porousmaterials.parser:PorousMaterialsParser"}},commits_count:0,errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install --pre aiida-porousmaterials",is_installable:"True"},"aiida-pseudo":{code_home:"https://github.com/aiidateam/aiida-pseudo",entry_point_prefix:"pseudo",pip_url:"aiida-pseudo",plugin_info:"https://raw.github.com/aiidateam/aiida-pseudo/master/setup.cfg",name:"aiida-pseudo",package_name:"aiida_pseudo",hosted_on:"github.com",metadata:{release_date:"2023-08-23",description:"AiiDA plugin that simplifies working with pseudo potentials.",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>',classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.2.0"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.data":{pseudo:"aiida_pseudo.data.pseudo.pseudo:PseudoPotentialData","pseudo.jthxml":"aiida_pseudo.data.pseudo.jthxml:JthXmlData","pseudo.psf":"aiida_pseudo.data.pseudo.psf:PsfData","pseudo.psml":"aiida_pseudo.data.pseudo.psml:PsmlData","pseudo.psp8":"aiida_pseudo.data.pseudo.psp8:Psp8Data","pseudo.upf":"aiida_pseudo.data.pseudo.upf:UpfData","pseudo.vps":"aiida_pseudo.data.pseudo.vps:VpsData"},"aiida.groups":{"pseudo.family":"aiida_pseudo.groups.family.pseudo:PseudoPotentialFamily","pseudo.family.cutoffs":"aiida_pseudo.groups.family.cutoffs:CutoffsPseudoPotentialFamily","pseudo.family.pseudo_dojo":"aiida_pseudo.groups.family.pseudo_dojo:PseudoDojoFamily","pseudo.family.sssp":"aiida_pseudo.groups.family.sssp:SsspFamily"},console_scripts:{"aiida-pseudo":"aiida_pseudo.cli:cmd_root"}},commits_count:27,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"red",text:"Data",count:7},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Groups)",count:4}],pip_install_cmd:"pip install aiida-pseudo",is_installable:"True"},"aiida-psi4":{code_home:"https://github.com/ltalirz/aiida-psi4/tree/master",development_status:"beta",entry_point_prefix:"psi4",pip_url:"git+https://github.com/ltalirz/aiida-psi4",name:"aiida-psi4",package_name:"aiida_psi4",hosted_on:"github.com",metadata:{author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",version:"0.1.0a0",description:"AiiDA plugin for the Psi4 Quantum Chemistry package.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.4,<2.0.0",entry_points:{"aiida.data":{"psi4.atomic_input":"aiida_psi4.data:AtomicInput"},"aiida.calculations":{psi4:"aiida_psi4.calculations:Psi4Calculation"},"aiida.parsers":{psi4:"aiida_psi4.parsers:QCSchemaParser"}},commits_count:0,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install git+https://github.com/ltalirz/aiida-psi4",is_installable:"True"},"aiida-pyscf":{code_home:"https://github.com/microsoft/aiida-pyscf",entry_point_prefix:"pyscf",pip_url:"aiida-pyscf",plugin_info:"https://raw.githubusercontent.com/microsoft/aiida-pyscf/main/pyproject.toml",name:"aiida-pyscf",package_name:"aiida_pyscf",hosted_on:"github.com",metadata:{release_date:"2023-08-16",description:"AiiDA plugin for the Python-based Simulations of Chemistry Framework (PySCF).",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>, Adam Grofe <v-adamgrofe@microsoft.com>',classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"0.4.1"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"pyscf.base":{description:["``CalcJob`` plugin for PySCF."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"structure",required:!0,valid_types:"StructureData",info:"Input structure with molecular structure definition."},{name:"checkpoint",required:!1,valid_types:"SinglefileData, NoneType",info:"Checkpoint of a previously completed calculation that failed to converge."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Input parameters used to render the PySCF script template."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cubegen",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"checkpoint",required:!1,valid_types:"SinglefileData",info:"The checkpoint file in case the calculation did not converge. Can be used as an input for a restart."},{name:"fcidump",required:!1,valid_types:"SinglefileData",info:"Computed fcidump files."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The computed Hessian."},{name:"model",required:!1,valid_types:"PickledData",info:"The model in serialized form. Can be deserialized and used without having to run the kernel again."},{name:"parameters",required:!1,valid_types:"Dict",info:"Various computed properties parsed from the `FILENAME_RESULTS` output file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"The optimized structure if the input parameters contained the `optimizer` key."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The geometry optimization trajectory if the input parameters contained the `optimizer` key."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The stdout output file was not retrieved."},{status:303,message:"The results JSON file was not retrieved."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."}]},class:"aiida_pyscf.calculations.base:PyscfCalculation"}},"aiida.parsers":{"pyscf.base":"aiida_pyscf.parsers.base:PyscfParser"},"aiida.workflows":{"pyscf.base":{description:["Workchain to run a pyscf calculation with automated error handling and restarts."],spec:{inputs:[{name:"pyscf",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"cubegen",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"checkpoint",required:!1,valid_types:"SinglefileData",info:"The checkpoint file in case the calculation did not converge. Can be used as an input for a restart."},{name:"fcidump",required:!1,valid_types:"SinglefileData",info:"Computed fcidump files."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The computed Hessian."},{name:"model",required:!1,valid_types:"PickledData",info:"The model in serialized form. Can be deserialized and used without having to run the kernel again."},{name:"parameters",required:!1,valid_types:"Dict",info:"Various computed properties parsed from the `FILENAME_RESULTS` output file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"The optimized structure if the input parameters contained the `optimizer` key."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The geometry optimization trajectory if the input parameters contained the `optimizer` key."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed and did not retrieve a checkpoint file from which can be restarted."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_pyscf.workflows.base:PyscfBaseWorkChain"}}},commits_count:67,development_status:"alpha",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-pyscf",is_installable:"True"},"aiida-python":{entry_point_prefix:"aiidapython",code_home:"https://github.com/addman2/aiida-python",name:"aiida-python",package_name:"aiida_python",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:44,development_status:"planning",errors:[],warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found","Prefix 'aiidapython' does not follow naming convention."],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-qeq":{code_home:"https://github.com/ltalirz/aiida-qeq",development_status:"stable",entry_point_prefix:"qeq",pip_url:"aiida-qeq",plugin_info:"https://raw.githubusercontent.com/ltalirz/aiida-qeq/master/setup.json",name:"aiida-qeq",package_name:"aiida_qeq",hosted_on:"github.com",metadata:{release_date:"2018-11-21",description:"AiiDA plugin for computing electronic charges on atoms using equilibration-type models (QEq, EQEq, ...).",author:"Leopold Talirz, Daniele Ongari",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-qeq",classifiers:["Programming Language :: Python"],version:"0.1.0"},aiida_version:">=0.12.2,<1.0.0",entry_points:{"aiida.calculations":{"qeq.eqeq":{description:["AiiDA calculation plugin for the EQeq code."],spec:{inputs:[{name:"charge_data",required:!0,valid_types:"SinglefileData",info:"File containing information on common oxidation state of the elements."},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"ionization_data",required:!0,valid_types:"SinglefileData",info:"File containing ionization data on the elements."},{name:"parameters",required:!0,valid_types:"EQeqParameters",info:"Command line parameters for EQEQ"},{name:"structure",required:!0,valid_types:"CifData",info:"Input structure, for which atomic charges are to be computed."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_qeq.calculations.eqeq:EQeqCalculation"},"qeq.qeq":{description:["AiiDA calculation plugin for the Qeq code."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"SinglefileData",info:"File containing electronegativity and Idempotential data of the elements."},{name:"structure",required:!0,valid_types:"CifData",info:"Input structure, for which atomic charges are to be computed."},{name:"configure",required:!1,valid_types:"QeqParameters",info:"Configuration input for QEQ (configure.input file)"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_qeq.calculations.qeq:QeqCalculation"}},"aiida.data":{"qeq.eqeq":"aiida_qeq.data.eqeq:EQeqParameters","qeq.qeq":"aiida_qeq.data.qeq:QeqParameters"},"aiida.parsers":{"qeq.eqeq":"aiida_qeq.parsers.eqeq:EQeqParser","qeq.qeq":"aiida_qeq.parsers.qeq:QeqParser"}},commits_count:0,errors:[],warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:2}],pip_install_cmd:"pip install aiida-qeq",is_installable:"True"},"aiida-qp2":{code_home:"https://github.com/TREX-CoE/aiida-qp2",entry_point_prefix:"qp2",pip_url:"aiida-qp2",documentation_url:"https://trex-coe.github.io/aiida-qp2/index.html",name:"aiida-qp2",package_name:"aiida_qp2",hosted_on:"github.com",metadata:{release_date:"2022-02-26",description:"AiiDA plugin for the Quantum Package 2.0",author:"Evgeny Posenitskiy",author_email:"posenitskiy@irsamc.ups-tlse.fr",license:"MIT",home_page:"https://github.com/TREX-CoE/aiida-qp2",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.calculations":{qp2:{description:["AiiDA calculation plugin wrapping the Quantum Package code."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters to generate the input file."},{name:"basissets",required:!1,valid_types:"",info:"A dictionary of basissets to be used in the calculations: key is the atomic symbol, value is either a single basisset."},{name:"code",required:!1,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"",info:"A dictionary of pseudopotentials to be used in the calculations: key is the atomic symbol, value is a single pseudopotential."},{name:"settings",required:!1,valid_types:"Dict",info:"Additional input parameters."},{name:"structure",required:!1,valid_types:"StructureData",info:"Input structrure"},{name:"wavefunction",required:!1,valid_types:"SinglefileData",info:"The wavefunction file (EZFIO or TREXIO)."}],outputs:[{name:"output_wavefunction",required:!0,valid_types:"SinglefileData",info:"The wave function file (EZFIO or TREXIO)"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_energy",required:!1,valid_types:"Float",info:"The result of the calculation"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"Calculation did not produce all expected output files."},{status:400,message:"Energy value is not present in the output file."}]},class:"aiida_qp2.calculations:QP2Calculation"}},"aiida.parsers":{qp2:"aiida_qp2.parsers:QP2Parser"}},commits_count:0,development_status:"beta",errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-qp2",is_installable:"True"},"aiida-quantumespresso":{code_home:"https://github.com/aiidateam/aiida-quantumespresso",documentation_url:"https://aiida-quantumespresso.readthedocs.io/",entry_point_prefix:"quantumespresso",pip_url:"aiida-quantumespresso",plugin_info:"https://raw.github.com/aiidateam/aiida-quantumespresso/master/setup.json",name:"aiida-quantumespresso",package_name:"aiida_quantumespresso",hosted_on:"github.com",metadata:{release_date:"2023-07-24",description:"The official AiiDA plugin for Quantum ESPRESSO",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"4.4.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"quantumespresso.cp":{description:["`CalcJob` implementation for the cp.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_trajectory",required:!0,valid_types:"TrajectoryData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The required XML file is not present in the retrieved folder."},{status:304,message:"The retrieved folder contains multiple XML files."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The required XML file could not be read."},{status:330,message:"The required POS file could not be read."},{status:340,message:"The required trajectory data could not be read."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."}]},class:"aiida_quantumespresso.calculations.cp:CpCalculation"},"quantumespresso.create_kpoints_from_distance":{description:["Generate a uniformly spaced kpoint mesh for a given structure.","","    The spacing between kpoints in reciprocal space is guaranteed to be at least the defined distance.","","    :param structure: the StructureData to which the mesh should apply","    :param distance: a Float with the desired distance between kpoints in reciprocal space","    :param force_parity: a Bool to specify whether the generated mesh should maintain parity","    :returns: a KpointsData with the generated mesh"],spec:{inputs:[{name:"distance",required:!0,valid_types:"Data",info:"a Float with the desired distance between kpoints in reciprocal space"},{name:"force_parity",required:!0,valid_types:"Data",info:"a Bool to specify whether the generated mesh should maintain parity"},{name:"structure",required:!0,valid_types:"Data",info:"the StructureData to which the mesh should apply"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.create_kpoints_from_distance:create_kpoints_from_distance"},"quantumespresso.create_magnetic_configuration":{description:["Create a new magnetic configuration from the given structure based on a list of magnetic moments per site.","","    To create the new list of kinds, the algorithm loops over all the elements in the structure and makes a list of the","    sites with that element and their corresponding magnetic moment. Next, it splits this list in three lists:","","    * Zero magnetic moments: Any site that has an absolute magnetic moment lower than ``ztol``","    * Positive magnetic moments","    * Negative magnetic moments","","    The algorithm then sorts the positive and negative lists from large to small absolute value, and loops over each of","    list. New magnetic kinds will be created when the absolute difference between the magnetic moment of the current","    kind and the site exceeds ``atol``.","","    The positive and negative magnetic moments are handled separately to avoid assigning two sites with opposite signs","    in their magnetic moment to the same kind and make sure that each kind has the correct magnetic moment, i.e. the","    largest magnetic moment in absolute value of the sites corresponding to that kind.","","    .. important:: the function currently does not support alloys.","","    :param structure: a `StructureData` instance.","    :param magnetic_moment_per_site: list of magnetic moments for each site in the structure.","    :param atol: the absolute tolerance on determining if two sites have the same magnetic moment.","    :param ztol: threshold for considering a kind to have non-zero magnetic moment."],spec:{inputs:[{name:"magnetic_moment_per_site",required:!0,valid_types:"Data",info:"list of magnetic moments for each site in the structure."},{name:"structure",required:!0,valid_types:"Data",info:"a `StructureData` instance."},{name:"atol",required:!1,valid_types:"Data",info:"the absolute tolerance on determining if two sites have the same magnetic moment."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"ztol",required:!1,valid_types:"Data",info:"threshold for considering a kind to have non-zero magnetic moment."}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.create_magnetic_configuration:create_magnetic_configuration"},"quantumespresso.dos":{description:["`CalcJob` implementation for the dos.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_dos",required:!0,valid_types:"XyData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The dos file could not be read from the retrieved folder."}]},class:"aiida_quantumespresso.calculations.dos:DosCalculation"},"quantumespresso.epw":{description:["`CalcJob` implementation for the epw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"kfpoints",required:!0,valid_types:"KpointsData",info:"fine kpoint mesh"},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"coarse kpoint mesh"},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"parent_folder_nscf",required:!0,valid_types:"RemoteData",info:"the folder of a completed nscf `PwCalculation`"},{name:"parent_folder_ph",required:!0,valid_types:"RemoteData",info:"the folder of a completed `PhCalculation`"},{name:"qfpoints",required:!0,valid_types:"KpointsData",info:"fine qpoint mesh"},{name:"qpoints",required:!0,valid_types:"KpointsData",info:"coarse qpoint mesh"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_quantumespresso.calculations.epw:EpwCalculation"},"quantumespresso.matdyn":{description:["`CalcJob` implementation for the matdyn.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"Kpoints on which to calculate the phonon frequencies."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"parent_folder",required:!1,valid_types:"RemoteData, FolderData, SinglefileData, NoneType",info:"Use a local or remote folder as parent folder (for restarts and similar)"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_phonon_bands",required:!0,valid_types:"BandsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The output frequencies file could not be read from the retrieved folder."},{status:410,message:"Number of kpoints not found in the output data"},{status:411,message:"Number of kpoints in the inputs is not commensurate with those in the output"}]},class:"aiida_quantumespresso.calculations.matdyn:MatdynCalculation"},"quantumespresso.merge_ph_outputs":{description:["Calcfunction to merge outputs from multiple `ph.x` calculations with different q-points."],spec:{inputs:[{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.merge_ph_outputs:merge_ph_outputs"},"quantumespresso.namelists":{description:["`CalcJob` implementation to serve as base class for simple post-processing tools of Quantum ESPRESSO."],spec:{inputs:[{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"parent_folder",required:!1,valid_types:"RemoteData, FolderData, SinglefileData, NoneType",info:"Use a local or remote folder as parent folder (for restarts and similar)"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."}]},class:"aiida_quantumespresso.calculations.namelists:NamelistsCalculation"},"quantumespresso.neb":{description:["Nudged Elastic Band code (neb.x) of Quantum ESPRESSO distribution."],spec:{inputs:[{name:"first_structure",required:!0,valid_types:"StructureData",info:"Initial structure"},{name:"last_structure",required:!0,valid_types:"StructureData",info:"Final structure"},{name:"parameters",required:!0,valid_types:"Dict",info:"NEB-specific input parameters"},{name:"pw",required:!0,valid_types:"Data",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."}],outputs:[{name:"output_mep",required:!0,valid_types:"ArrayData",info:"The original and interpolated energy profiles along the minimum-energy path (mep)"},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output parameters dictionary of the NEB calculation"},{name:"output_trajectory",required:!0,valid_types:"TrajectoryData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"iteration_array",required:!1,valid_types:"ArrayData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:303,message:"The required XML file is not present in the retrieved folder."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.neb:NebCalculation"},"quantumespresso.open_grid":{description:["``CalcJob`` implementation for the ``open_grid.x`` code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a completed `PwCalculation` on an irreducible Brillouin zone"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The explicit list of kpoints of the unfolded kmesh"},{name:"kpoints_mesh",required:!0,valid_types:"KpointsData",info:"The dimensions of the unfolded kmesh"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"The retrieved folder data node could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:312,message:"Found rotation or fractional translation not compatible with FFT grid."},{status:350,message:"Mismatch between kmesh dimensions and number of kpoints."}]},class:"aiida_quantumespresso.calculations.open_grid:OpenGridCalculation"},"quantumespresso.ph":{description:["`CalcJob` implementation for the ph.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"the folder of a completed `PwCalculation`"},{name:"qpoints",required:!0,valid_types:"KpointsData",info:"qpoint mesh"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The minimization cycle did not reach self-consistency."},{status:462,message:"The code failed during the cholesky factorization."}]},class:"aiida_quantumespresso.calculations.ph:PhCalculation"},"quantumespresso.pp":{description:["`CalcJob` implementation for the pp.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Use a node that specifies the input parameters for the namelists"},{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"Output folder of a completed `PwCalculation`"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job is performed."}],outputs:[{name:"output_data",required:!0,valid_types:"ArrayData",info:""},{name:"output_data_multiple",required:!0,valid_types:"ArrayData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The parent folder did not contain the required XML output file."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete."},{status:330,message:"The formatted data output file `{filename}` was not present in the retrieved (temporary) folder."},{status:331,message:"The formatted data output file `{filename}` could not be read."},{status:332,message:"The data file format is not supported by the parser"},{status:333,message:"The formatted data output file `{filename}` could not be parsed: {exception}"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pp:PpCalculation"},"quantumespresso.projwfc":{description:["`CalcJob` implementation for the projwfc.x code of Quantum ESPRESSO.","","    Projwfc.x code of the Quantum ESPRESSO distribution, handles the the computation of projections of bloch","    wavefunctions onto atomic orbitals.","","    <Psi(n,k) | Y(theta,phi)R(r) >. For more information, refer to http://www.quantum-espresso.org/"],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a pw.x calculation"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"Dos",required:!0,valid_types:"XyData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:""},{name:"bands_down",required:!1,valid_types:"BandsData",info:""},{name:"bands_up",required:!1,valid_types:"BandsData",info:""},{name:"projections",required:!1,valid_types:"ProjectionData",info:""},{name:"projections_down",required:!1,valid_types:"ProjectionData",info:""},{name:"projections_up",required:!1,valid_types:"ProjectionData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:330,message:"The pdos_tot file could not be read from the retrieved folder."},{status:340,message:"An exception was raised parsing bands and projections."}]},class:"aiida_quantumespresso.calculations.projwfc:ProjwfcCalculation"},"quantumespresso.pw":{description:["`CalcJob` implementation for the pw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"kpoint mesh or kpoint path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"hubbard_file",required:!1,valid_types:"SinglefileData, NoneType",info:"SinglefileData node containing the output Hubbard parameters from a HpCalculation"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
npool  : The number of 'pools', each taking care of a group of k-points.
nband  : The number of 'band groups', each taking care of a group of Kohn-Sham orbitals.
ntg    : The number of 'task groups' across which the FFT planes are distributed.
ndiag  : The number of 'linear algebra groups' used when parallelizing the subspace diagonalization / iterative orthonormalization. By default, no parameter is passed to Quantum ESPRESSO, meaning it will use its default.`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:304,message:"The retrieved folder contained multiple XML files."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:360,message:"The code failed in finding a valid reciprocal lattice vector."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:461,message:"The code failed with negative dexx in the exchange calculation."},{status:462,message:"The code failed during the cholesky factorization."},{status:463,message:"Too many bands failed to converge during the diagonalization."},{status:464,message:"The S matrix was found to be not positive definite."},{status:465,message:"The `zhegvd` failed in the PPCG diagonalization."},{status:466,message:"The `[Q, R] = qr(X, 0)` failed in the PPCG diagonalization."},{status:467,message:"The eigenvector failed to converge."},{status:468,message:"The factorization in the Broyden routine failed."},{status:481,message:'The k-point parallelization "npools" is too high, some nodes have no k-points.'},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:502,message:"The ionic minimization cycle did not converge after the maximum number of steps."},{status:503,message:"The ionic minimization cycle did not finish because the calculation was interrupted but a partial trajectory and output structure was successfully parsed which can be used for a restart."},{status:510,message:"The electronic minimization cycle failed during an ionic minimization cycle."},{status:511,message:"The ionic minimization cycle converged, but electronic convergence was not reached in the final SCF."},{status:520,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm."},{status:521,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm and electronic convergence failed in the final SCF."},{status:531,message:"The electronic minimization cycle did not reach self-consistency."},{status:541,message:"The variable cell optimization broke the symmetry of the k-points."},{status:542,message:"The cell relaxation caused a significant volume contraction and there is not enough space allocated for radial FFT."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.calculations.pw:PwCalculation"},"quantumespresso.pw2gw":{description:["`CalcJob` implementation for the pw2gw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"Output folder of a completed `PwCalculation`"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"eps",required:!0,valid_types:"ArrayData",info:"The `eps` output node containing 5 arrays `energy`, `epsX`, `epsY`, `epsZ`, `epsTOT`"},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation.`"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:305,message:"The eps*.dat output files could not be read or parsed."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The eps*.dat output files do not have the expected shape (N, 2)."},{status:331,message:"The eps*.dat output files contains different values of energies."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pw2gw:Pw2gwCalculation"},"quantumespresso.pw2wannier90":{description:["`CalcJob` implementation for the pw2wannier.x code of Quantum ESPRESSO.","","    For more information, refer to http://www.quantum-espresso.org/ and http://www.wannier.org/"],spec:{inputs:[{name:"nnkp_file",required:!0,valid_types:"SinglefileData",info:"A SinglefileData containing the .nnkp file generated by wannier90.x -pp"},{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a pw.x calculation"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:340,message:"Encountered a generic error message"},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pw2wannier90:Pw2wannier90Calculation"},"quantumespresso.pwimmigrant":{description:["Create a PwCalculation object that can be used to import old jobs.","","    This is a sublass of aiida_quantumespresso.calculations.PwCalculation","    with slight modifications to some of the class variables and additional","    methods that","","        a. parse the job's input file to create the calculation's input","           nodes that would exist if the calculation were submitted using AiiDa,","        b. bypass the functions of the daemon, and prepare the node's attributes","           such that all the processes (copying of the files to the repository,","           results parsing, ect.) can be performed","","    .. note:: The keyword arguments of PwCalculation are also available.","","    :param remote_workdir: Absolute path to the directory where the job was run.","        The transport of the computer you link ask input to the calculation is","        the transport that will be used to retrieve the calculation's files.","        Therefore, ``remote_workdir`` should be the absolute path to the job's","        directory on that computer.","    :type remote_workdir: str","","    :param input_file_name: The file name of the job's input file.","    :type input_file_name: str","","    :param output_file_name: The file name of the job's output file (i.e. the","        file containing the stdout of QE).","    :type output_file_name: str"],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"kpoint mesh or kpoint path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"hubbard_file",required:!1,valid_types:"SinglefileData, NoneType",info:"SinglefileData node containing the output Hubbard parameters from a HpCalculation"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
npool  : The number of 'pools', each taking care of a group of k-points.
nband  : The number of 'band groups', each taking care of a group of Kohn-Sham orbitals.
ntg    : The number of 'task groups' across which the FFT planes are distributed.
ndiag  : The number of 'linear algebra groups' used when parallelizing the subspace diagonalization / iterative orthonormalization. By default, no parameter is passed to Quantum ESPRESSO, meaning it will use its default.`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:304,message:"The retrieved folder contained multiple XML files."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:360,message:"The code failed in finding a valid reciprocal lattice vector."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:461,message:"The code failed with negative dexx in the exchange calculation."},{status:462,message:"The code failed during the cholesky factorization."},{status:463,message:"Too many bands failed to converge during the diagonalization."},{status:464,message:"The S matrix was found to be not positive definite."},{status:465,message:"The `zhegvd` failed in the PPCG diagonalization."},{status:466,message:"The `[Q, R] = qr(X, 0)` failed in the PPCG diagonalization."},{status:467,message:"The eigenvector failed to converge."},{status:468,message:"The factorization in the Broyden routine failed."},{status:481,message:'The k-point parallelization "npools" is too high, some nodes have no k-points.'},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:502,message:"The ionic minimization cycle did not converge after the maximum number of steps."},{status:503,message:"The ionic minimization cycle did not finish because the calculation was interrupted but a partial trajectory and output structure was successfully parsed which can be used for a restart."},{status:510,message:"The electronic minimization cycle failed during an ionic minimization cycle."},{status:511,message:"The ionic minimization cycle converged, but electronic convergence was not reached in the final SCF."},{status:520,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm."},{status:521,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm and electronic convergence failed in the final SCF."},{status:531,message:"The electronic minimization cycle did not reach self-consistency."},{status:541,message:"The variable cell optimization broke the symmetry of the k-points."},{status:542,message:"The cell relaxation caused a significant volume contraction and there is not enough space allocated for radial FFT."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.calculations.pwimmigrant:PwimmigrantCalculation"},"quantumespresso.q2r":{description:["`CalcJob` implementation for the q2r.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The force constants file could not be read."}]},class:"aiida_quantumespresso.calculations.q2r:Q2rCalculation"},"quantumespresso.seekpath_structure_analysis":{description:["Primitivize the structure with SeeKpath and generate the high symmetry k-point path through its Brillouin zone.","","    This calcfunction will take a structure and pass it through SeeKpath to get the normalized primitive cell and the","    path of high symmetry k-points through its Brillouin zone. Note that the returned primitive cell may differ from the","    original structure in which case the k-points are only congruent with the primitive cell.","","    The keyword arguments can be used to specify various Seekpath parameters, such as:","","        with_time_reversal: True","        reference_distance: 0.025","        recipe: 'hpkot'","        threshold: 1e-07","        symprec: 1e-05","        angle_tolerance: -1.0","","    Note that exact parameters that are available and their defaults will depend on your Seekpath version."],spec:{inputs:[{name:"structure",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.seekpath_structure_analysis:seekpath_structure_analysis"},"quantumespresso.xspectra":{description:["CalcJob implementation for the xspectra.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"core_wfc_data",required:!0,valid_types:"SinglefileData",info:"Core wavefunction data, generated by the upf2plotcore.sh utility"},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The K-point sampling to be used for the XSpectra calculation"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"gamma_file",required:!1,valid_types:"SinglefileData, NoneType",info:"An optional file containing the data for the broadening function used when `gamma_mode=file`"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"spectra",required:!0,valid_types:"XyData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:313,message:"xiabs was set incorrectly, check and ensure that the index value correctly refers to the atomic species containing the core-hole (where the index starts from 1)."},{status:314,message:"xiabs was either set to 0 or less, or was greater than ntyp."},{status:330,message:"The xspectra output file could not be read from the retrieved folder."},{status:331,message:"The spectrum data file could not be read using NumPy genfromtxt"},{status:400,message:"The time limit set for the calculation was exceeded, and the job wrote a save file before exiting."}]},class:"aiida_quantumespresso.calculations.xspectra:XspectraCalculation"}},"aiida.data":{"quantumespresso.force_constants":"aiida_quantumespresso.data.force_constants:ForceConstantsData","quantumespresso.hubbard_structure":"aiida_quantumespresso.data.hubbard_structure:HubbardStructureData"},"aiida.parsers":{"quantumespresso.cp":"aiida_quantumespresso.parsers.cp:CpParser","quantumespresso.dos":"aiida_quantumespresso.parsers.dos:DosParser","quantumespresso.matdyn":"aiida_quantumespresso.parsers.matdyn:MatdynParser","quantumespresso.neb":"aiida_quantumespresso.parsers.neb:NebParser","quantumespresso.open_grid":"aiida_quantumespresso.parsers.open_grid:OpenGridParser","quantumespresso.ph":"aiida_quantumespresso.parsers.ph:PhParser","quantumespresso.pp":"aiida_quantumespresso.parsers.pp:PpParser","quantumespresso.projwfc":"aiida_quantumespresso.parsers.projwfc:ProjwfcParser","quantumespresso.pw":"aiida_quantumespresso.parsers.pw:PwParser","quantumespresso.pw2gw":"aiida_quantumespresso.parsers.pw2gw:Pw2gwParser","quantumespresso.pw2wannier90":"aiida_quantumespresso.parsers.pw2wannier90:Pw2wannier90Parser","quantumespresso.q2r":"aiida_quantumespresso.parsers.q2r:Q2rParser","quantumespresso.xspectra":"aiida_quantumespresso.parsers.xspectra:XspectraParser"},"aiida.tools.calculations":{"quantumespresso.pw":"aiida_quantumespresso.tools.calculations.pw:PwCalculationTools"},"aiida.tools.data.orbitals":{noncollinearhydrogen:"aiida_quantumespresso.tools.data.orbital.noncollinearhydrogen:NoncollinearHydrogenOrbital",spinorbithydrogen:"aiida_quantumespresso.tools.data.orbital.spinorbithydrogen:SpinorbitHydrogenOrbital"},"aiida.workflows":{"quantumespresso.matdyn.base":{description:["Workchain to run a Quantum ESPRESSO matdyn.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"matdyn",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_phonon_bands",required:!0,valid_types:"BandsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.matdyn.base:MatdynBaseWorkChain"},"quantumespresso.pdos":{description:["A WorkChain to compute Total & Partial Density of States of a structure, using Quantum Espresso."],spec:{inputs:[{name:"dos",required:!0,valid_types:"Data",info:"Input parameters for the `dos.x` calculation. Note that the `Emin`, `Emax` and `DeltaE` values have to match with those in the `projwfc` inputs."},{name:"nscf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` of the `nscf` calculation."},{name:"projwfc",required:!0,valid_types:"Data",info:"Input parameters for the `projwfc.x` calculation. Note that the `Emin`, `Emax` and `DeltaE` values have to match with those in the `dos` inputs."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"align_to_fermi",required:!1,valid_types:"Bool",info:"If true, Emin=>Emin-Efermi & Emax=>Emax-Efermi, where Efermi is taken from the `nscf` calculation. Note that it only makes sense to align `Emax` and `Emin` to the fermi level in case they are actually provided by in the `dos` and `projwfc` inputs, since otherwise the "},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If ``True``, work directories of all called calculation will be cleaned at the end of execution."},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` of the `scf` calculation."},{name:"serial_clean",required:!1,valid_types:"Bool, NoneType",info:"If ``True``, calculations will be run in serial, and work directories will be cleaned before the next step."}],outputs:[{name:"dos",required:!0,valid_types:"",info:""},{name:"nscf",required:!0,valid_types:"",info:""},{name:"projwfc",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified for base or nscf namespaces."},{status:401,message:"the SCF sub process failed"},{status:402,message:"the NSCF sub process failed"},{status:403,message:"the DOS sub process failed"},{status:404,message:"the PROJWFC sub process failed"},{status:404,message:"both the DOS and PROJWFC sub process failed"}]},class:"aiida_quantumespresso.workflows.pdos:PdosWorkChain"},"quantumespresso.ph.base":{description:["Workchain to run a Quantum ESPRESSO ph.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"ph",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"only_initialization",required:!1,valid_types:"Bool",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:401,message:"The work chain failed to merge the q-points data from multiple `PhCalculation`s because not all q-points were parsed."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.ph.base:PhBaseWorkChain"},"quantumespresso.pw.bands":{description:["Workchain to compute a band structure for a given structure using Quantum ESPRESSO pw.x.","","    The logic for the computation of various parameters for the BANDS step is as follows:","","    Number of bands:","        One can specify the number of bands to be used in the BANDS step either directly through the input parameters","        `bands.pw.parameters.SYSTEM.nbnd` or through `nbands_factor`. Note that specifying both is not allowed. When","        neither is specified nothing will be set by the work chain and the default of Quantum ESPRESSO will end up being","        used. If the `nbands_factor` is specified the maximum value of the following values will be used:","","        * `nbnd` of the preceding SCF calculation","        * 0.5 * nelectrons * nbands_factor","        * 0.5 * nelectrons + 4","","    Kpoints:","        There are three options; specify either an existing `KpointsData` through `bands_kpoints`, or specify the","        `bands_kpoint_distance`, or specify neither. For the former those exact kpoints will be used for the BANDS step.","        In the two other cases, the structure will first be normalized using SeekPath and the path along high-symmetry","        k-points will be generated on that structure. The distance between kpoints for the path will be equal to that","        of `bands_kpoints_distance` or the SeekPath default if not specified."],spec:{inputs:[{name:"bands",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the BANDS calculation."},{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the SCF calculation."},{name:"structure",required:!0,valid_types:"StructureData",info:"The inputs structure."},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Explicit kpoints to use for the BANDS calculation. Specify either this or `bands_kpoints_distance`."},{name:"bands_kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"Minimum kpoints distance for the BANDS calculation. Specify either this or `bands_kpoints`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"nbands_factor",required:!1,valid_types:"Float, NoneType",info:"The number of bands for the BANDS calculation is that used for the SCF multiplied by this factor."},{name:"relax",required:!1,valid_types:"Data",info:"Inputs for the `PwRelaxWorkChain`, if not specified at all, the relaxation step is skipped."}],outputs:[{name:"band_parameters",required:!0,valid_types:"Dict",info:"The output parameters of the BANDS `PwBaseWorkChain`."},{name:"band_structure",required:!0,valid_types:"BandsData",info:"The computed band structure."},{name:"scf_parameters",required:!0,valid_types:"Dict",info:"The output parameters of the SCF `PwBaseWorkChain`."},{name:"primitive_structure",required:!1,valid_types:"StructureData",info:"The normalized and primitivized structure for which the bands are computed."},{name:"seekpath_parameters",required:!1,valid_types:"Dict",info:"The parameters used in the SeeKpath call to normalize the input or relaxed structure."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Cannot specify both `nbands_factor` and `bands.pw.parameters.SYSTEM.nbnd`."},{status:202,message:"Cannot specify both `bands_kpoints` and `bands_kpoints_distance`."},{status:401,message:"The PwRelaxWorkChain sub process failed"},{status:402,message:"The scf PwBasexWorkChain sub process failed"},{status:403,message:"The bands PwBasexWorkChain sub process failed"}]},class:"aiida_quantumespresso.workflows.pw.bands:PwBandsWorkChain"},"quantumespresso.pw.base":{description:["Workchain to run a Quantum ESPRESSO pw.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"pw",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"An explicit k-points list or mesh. Either this or `kpoints_distance` has to be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by a calculation function based on the input structure."},{name:"kpoints_force_parity",required:!1,valid_types:"Bool, NoneType",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"The explicit `pseudos` or `pseudo_family` could not be used to get the necessary pseudos."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:203,message:"Neither the `options` nor `automatic_parallelization` input was specified. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:210,message:"Required key for `automatic_parallelization` was not specified.This exit status has been deprecated as the automatic parallellization feature was removed."},{status:211,message:"Unrecognized keys were specified for `automatic_parallelization`.This exit status has been deprecated as the automatic parallellization feature was removed."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed with a known unrecoverable error."},{status:320,message:"The initialization calculation failed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.workflows.pw.base:PwBaseWorkChain"},"quantumespresso.pw.relax":{description:["Workchain to relax a structure using Quantum ESPRESSO pw.x."],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the main relax loop."},{name:"structure",required:!0,valid_types:"StructureData",info:"The inputs structure."},{name:"base_final_scf",required:!1,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the final scf."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"max_meta_convergence_iterations",required:!1,valid_types:"Int",info:"The maximum number of variable cell relax iterations in the meta convergence cycle."},{name:"meta_convergence",required:!1,valid_types:"Bool",info:"If `True` the workchain will perform a meta-convergence on the cell volume."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"volume_convergence",required:!1,valid_types:"Float",info:"The volume difference threshold between two consecutive meta convergence iterations."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The successfully relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"the relax PwBaseWorkChain sub process failed"},{status:402,message:"the final scf PwBaseWorkChain sub process failed"}]},class:"aiida_quantumespresso.workflows.pw.relax:PwRelaxWorkChain"},"quantumespresso.q2r.base":{description:["Workchain to run a Quantum ESPRESSO q2r.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"q2r",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.q2r.base:Q2rBaseWorkChain"},"quantumespresso.xps":{description:["Workchain to compute X-ray photoelectron spectra (XPS) for a given structure.","","    The WorkChain itself firstly calls the PwRelaxWorkChain to relax the input structure if","    required. Then determines the input settings for each XPS calculation automatically using","    ``get_xspectra_structures()``. The input structures are generated from the standardized","    structure by converting each to a supercell with cell dimensions of at least 8.0 angstrom","    in each periodic dimension in order to sufficiently reduce the unphysical interaction","    of the core-hole with neighbouring images. The size of the minimum size requirement can be","    overriden by the user if required. Then the standard Delta-Self-Consistent-Field (ΔSCF)","    method is used to get the XPS binding energy. Finally, the XPS spectrum is calculated","    using the Voigt profile."],spec:{inputs:[{name:"ch_scf",required:!0,valid_types:"Data",info:"Input parameters for the basic xps workflow (core-hole SCF)."},{name:"core_hole_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of excited-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"gipaw_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of ground-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation."},{name:"abs_atom_marker",required:!1,valid_types:"Str",info:"The name for the Kind representing the absorbing atom in the structure. Will be used in all structures generated in ``get_xspectra_structures`` step."},{name:"calc_binding_energy",required:!1,valid_types:"Bool",info:"If `True`, run scf calculation for the supercell."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculations will be cleaned at the end of execution."},{name:"core_hole_treatments",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set core-hole treatment to all elements present. The default full-core-hole treatment will be used if not specified."},{name:"correction_energies",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set the correction energy to all elements present. "},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"elements_list",required:!1,valid_types:"List, NoneType",info:"The list of elements to be considered for analysis, each must be valid elements of the periodic table."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"Data",info:"Input parameters for the relax process. If not specified at all, the relaxation step is skipped."},{name:"spglib_settings",required:!1,valid_types:"Dict, NoneType",info:"Optional settings dictionary for the spglib call within ``get_xspectra_structures``."},{name:"structure_preparation_settings",required:!1,valid_types:"Dict, Float, Int, Bool, Str",info:"Optional settings dictionary for the ``get_xspectra_structures()`` method."},{name:"voight_gamma",required:!1,valid_types:"Float",info:"The gamma parameter for the Lorenzian broadening in the Voight method."},{name:"voight_sigma",required:!1,valid_types:"Float",info:"The sigma parameter for the gaussian broadening in the Voight method."}],outputs:[{name:"binding_energies",required:!0,valid_types:"Dict",info:"All the binding energy values for each element calculated by the WorkChain."},{name:"chemical_shifts",required:!0,valid_types:"Dict",info:"All the chemical shift values for each element calculated by the WorkChain."},{name:"final_spectra_be",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element based on binding energy."},{name:"final_spectra_cls",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element based on chemical shift."},{name:"output_parameters_ch_scf",required:!0,valid_types:"Dict",info:"The output parameters of each ``PwBaseWorkChain`` performed``."},{name:"supercell_structure",required:!0,valid_types:"StructureData",info:"The supercell of ``outputs.standardized_structure`` used to generate structures for XPS sub-processes."},{name:"symmetry_analysis_data",required:!0,valid_types:"Dict",info:"The output parameters from ``get_xspectra_structures()``."},{name:"optimized_structure",required:!1,valid_types:"StructureData",info:"The optimized structure from the ``relax`` process."},{name:"output_parameters_relax",required:!1,valid_types:"Dict",info:"The output_parameters of the relax step."},{name:"output_parameters_scf",required:!1,valid_types:"Dict",info:"The output_parameters of the scf step."},{name:"standardized_structure",required:!1,valid_types:"StructureData",info:"The standardized crystal structure used to generate structures for XPS sub-processes."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The Relax sub process failed"},{status:402,message:"The SCF Pw sub processes failed"},{status:402,message:"One or more CH_SCF Pw sub processes failed"}]},class:"aiida_quantumespresso.workflows.xps:XpsWorkChain"},"quantumespresso.xspectra.base":{description:["Workchain to run a Quantum ESPRESSO xspectra.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"xspectra",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"An explicit k-points mesh. Either this or `kpoints_distance` has to be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by a calculation function based on the input structure."},{name:"kpoints_force_parity",required:!1,valid_types:"Bool, NoneType",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"spectra",required:!0,valid_types:"XyData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.xspectra.base:XspectraBaseWorkChain"},"quantumespresso.xspectra.core":{description:["Workchain to compute X-ray absorption spectra for a given structure using Quantum ESPRESSO.","","    The workflow follows the process required to compute the XAS of an input structure: an SCF calculation is performed","    using the provided structure, which is then followed by the calculation of the XAS itself by XSpectra. The","    calculations performed by the WorkChain in a typical run will be:","","    - PwSCF calculation with pw.x of the input structure with a core-hole present.","    - Generation of core-wavefunction data with upf2plotcore.sh (if requested).","    - XAS calculation with xspectra.x to compute the Lanczos coefficients and print the XANES spectra for the","      polarisation vectors requested in the input.","    - Collation of output data from pw.x and xspectra.x calculations, including a combination of XANES dipole spectra","      based on polarisation vectors to represent the powder spectrum of the structure (if requested).","","    If ``run_replot = True`` is set in the inputs (defaults to False), the WorkChain will run a second xspectra.x","    calculation which replots the spectra produced from the ``xs_prod`` step. This option can be very useful for","    obtaining a final spectrum at low levels of broadening (relative to the default of 0.5 eV), particularly as higher","    levels of broadening significantly speed up the convergence of the Lanczos procedure. Inputs for the replot","    calculation are found in the ``xs_plot`` namespace.","","    The core-wavefunction plot derived from the ground-state of the absorbing element can be provided as a top-level","    input or produced by the WorkChain. If left to the WorkChain, the ground-state pseudopotential assigned to the","    absorbing element will be used to generate this data using the upf2plotcore.sh utility script (via the","    ``aiida-shell`` plugin).","","    In its current stage of development, the workflow requires the following:","","    - An input structure where the desired absorbing atom in the system is marked as a separate Kind. The default","      behaviour for the WorkChain is to set the Kind name as 'X', however this can be changed via the `overrides`","      dictionary.","    - A code node for ``upf2plotcore``, configured for the ``aiida-shell`` plugin","      (https://github.com/sphuber/aiida-shell). Alternatively, a ``SinglefileData`` node from a previous ``ShellJob``","      run can be supplied under ``inputs.core_wfc_data``.","    - A suitable pair of pseudopotentials for the element type of the absorbing atom, one for the ground-state occupancy","      which contains GIPAW informtation for the core level of interest for the XAS (e.g. 1s in the case of a K-edge","      calculation) and the other containing a core hole. (For the moment this can be passed either via the","      ``core_hole_pseudos`` field in ``get_builder_from_protocol`` or via the overrides, but will be changed later once","      full families of core-hole pseudopotentials become available)."],spec:{inputs:[{name:"eps_vectors",required:!0,valid_types:"List",info:"The list of 3-vectors to use in XSpectra sub-processes. The number of sub-lists will subsequently define the number of XSpectra calculations to perform"},{name:"scf",required:!0,valid_types:"Data",info:"Input parameters for the `pw.x` calculation."},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation, with at least one site containing the `abs_atom_marker` as the kind label."},{name:"xs_prod",required:!0,valid_types:"Data",info:"Input parameters for the `xspectra.x` calculation to compute the Lanczos."},{name:"abs_atom_marker",required:!1,valid_types:"Str, NoneType",info:"The name for the Kind representing the absorbing atom in the structure. Must corespond to a Kind within the StructureData node supplied to the calculation."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"core_wfc_data",required:!1,valid_types:"SinglefileData, NoneType",info:"The core wavefunction data file extracted from the ground-state pseudo for the absorbing atom."},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"get_powder_spectrum",required:!1,valid_types:"Bool",info:"If `True`, the WorkChain will combine XANES dipole spectra computed using the XAS basis vectors defined according to the `get_powder_spectrum` CalcFunction."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"run_replot",required:!1,valid_types:"Bool",info:""},{name:"upf2plotcore_code",required:!1,valid_types:"Code, NoneType",info:"The code node required for upf2plotcore.sh configured for ``aiida-shell``. Must be provided if `core_wfc_data` is not provided."},{name:"xs_plot",required:!1,valid_types:"Data",info:"Input parameters for the re-plot `xspectra.x` calculation of the Lanczos."}],outputs:[{name:"parameters_scf",required:!0,valid_types:"Dict",info:"The output parameters of the SCF `PwBaseWorkChain`."},{name:"parameters_xspectra",required:!0,valid_types:"Dict",info:"The output dictionaries of each `XspectraBaseWorkChain` performed"},{name:"spectra",required:!0,valid_types:"XyData",info:"An XyData node containing all the final spectra produced by the WorkChain."},{name:"powder_spectrum",required:!1,valid_types:"XyData",info:"The simulated powder spectrum"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The SCF sub process failed"},{status:402,message:"One or more XSpectra sub processes failed"},{status:403,message:"The pseudo for the absorbing element contains no GIPAW information."}]},class:"aiida_quantumespresso.workflows.xspectra.core:XspectraCoreWorkChain"},"quantumespresso.xspectra.crystal":{description:["Workchain to compute all X-ray absorption spectra for a given structure using Quantum ESPRESSO.","","    The WorkChain follows the process required to compute all the K-edge XAS spectra for each","    element in a given structure. The WorkChain itself firstly calls the PwRelaxWorkChain to","    relax the input structure, then determines the input settings for each XAS","    calculation automatically using ``get_xspectra_structures()``:","","        - Firstly the input structure is converted to its conventional standard cell using","          ``spglib`` and detects the space group number for the conventional cell.","        - Symmetry analysis of the standardized structure using ``spglib`` is then used to","          determine the number of non-equivalent atomic sites in the structure for each","          element considered for analysis.","","    Using the symmetry data returned from ``get_xspectra_structures``, input structures for","    the XspectraCoreWorkChain are generated from the standardized structure by converting each","    to a supercell with cell dimensions of at least 8.0 angstroms in each periodic dimension -","    required in order to sufficiently reduce the unphysical interaction of the core-hole with","    neighbouring images. The size of the minimum size requirement can be overriden by the","    user if required. The WorkChain then uses the space group number to set the list of","    polarisation vectors for the ``XspectraCoreWorkChain`` to compute for all subsequent","    calculations."],spec:{inputs:[{name:"core",required:!0,valid_types:"Data",info:"Input parameters for the basic xspectra workflow (core-hole SCF + XAS."},{name:"core_hole_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of excited-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"elements_list",required:!0,valid_types:"List",info:"The list of elements to be considered for analysis, each must be a valid element of the periodic table."},{name:"gipaw_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of ground-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}.'},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation."},{name:"abs_atom_marker",required:!1,valid_types:"Str",info:"The name for the Kind representing the absorbing atom in the structure. Will be used in all structures generated in ``get_xspectra_structures`` step."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculations will be cleaned at the end of execution."},{name:"core_hole_treatments",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set core-hole treatment to given elements present. The default full-core-hole treatment will be used if not specified."},{name:"core_wfc_data",required:!1,valid_types:"SinglefileData",info:"Input namespace to provide core wavefunction inputs for each element. Must follow the format: ``core_wfc_data__{symbol} = {node}``"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"Data",info:"Input parameters for the relax process. If not specified at all, the relaxation step is skipped."},{name:"return_all_powder_spectra",required:!1,valid_types:"Bool",info:"If ``True``, the WorkChain will return all ``powder_spectrum`` nodes from each ``XspectraCoreWorkChain`` sub-process."},{name:"spglib_settings",required:!1,valid_types:"Dict, NoneType",info:"Optional settings dictionary for the spglib call within ``get_xspectra_structures``."},{name:"structure_preparation_settings",required:!1,valid_types:"Dict, Float, Int, Bool, Str",info:"Optional settings dictionary for the ``get_xspectra_structures()`` method."},{name:"upf2plotcore_code",required:!1,valid_types:"Code, NoneType",info:"Code node for the upf2plotcore.sh ShellJob code."}],outputs:[{name:"final_spectra",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element"},{name:"supercell_structure",required:!0,valid_types:"StructureData",info:"The supercell of ``outputs.standardized_structure`` used to generate structures for XSpectra sub-processes."},{name:"symmetry_analysis_data",required:!0,valid_types:"Dict",info:"The output parameters from ``get_xspectra_structures()``."},{name:"optimized_structure",required:!1,valid_types:"StructureData",info:"The optimized structure from the ``relax`` process."},{name:"parameters_relax",required:!1,valid_types:"Dict",info:"The output_parameters of the relax step."},{name:"parameters_scf",required:!1,valid_types:"Dict",info:"The output parameters of each ``PwBaseWorkChain`` performed in each ``XspectraCoreWorkChain``."},{name:"parameters_xspectra",required:!1,valid_types:"Dict",info:"The output dictionaries of each `XspectraCalculation` performed"},{name:"powder_spectra",required:!1,valid_types:"XyData",info:"All the spectra generated by the WorkChain."},{name:"standardized_structure",required:!1,valid_types:"StructureData",info:"The standardized crystal structure used to generate structures for XSpectra sub-processes."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The Relax sub process failed"},{status:402,message:"One or more XSpectra workflows failed"},{status:403,message:"The pseudos for one or more absorbing elements contain no GIPAW information."}]},class:"aiida_quantumespresso.workflows.xspectra.crystal:XspectraCrystalWorkChain"}},console_scripts:{"aiida-quantumespresso":"aiida_quantumespresso.cli:cmd_root"}},commits_count:91,development_status:"stable",errors:[],warnings:["Entry point 'noncollinearhydrogen' does not start with prefix 'quantumespresso.'","Entry point 'spinorbithydrogen' does not start with prefix 'quantumespresso.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:20},{colorclass:"brown",text:"Parsers",count:13},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:11},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Tools calculations, Tools data orbitals)",count:3}],pip_install_cmd:"pip install aiida-quantumespresso",is_installable:"True"},"aiida-quantumespresso-hp":{code_home:"https://github.com/sphuber/aiida-quantumespresso-hp",entry_point_prefix:"quantumespresso.hp",pip_url:"git+https://github.com/sphuber/aiida-quantumespresso-hp",name:"aiida-quantumespresso-hp",package_name:"aiida_quantumespresso_hp",hosted_on:"github.com",metadata:{author:"Sebastiaan P. Huber",author_email:"mail@sphuber.net",version:"0.1.0",description:"The AiiDA plugin for the Hubbard module of Quantum ESPRESSO",classifiers:["License :: OSI Approved :: MIT License","Programming Language :: Python :: 2.7","Development Status :: 4 - Beta"]},aiida_version:">=1.0.0b6,<2.0",entry_points:{"aiida.calculations":{"quantumespresso.hp":"aiida_quantumespresso_hp.calculations.hp:HpCalculation"},"aiida.parsers":{"quantumespresso.hp":"aiida_quantumespresso_hp.parsers.hp:HpParser"},"aiida.workflows":{"quantumespresso.hp.main":"aiida_quantumespresso_hp.workflows.hp.main:HpWorkChain","quantumespresso.hp.parallelize_atoms":"aiida_quantumespresso_hp.workflows.hp.parallelize_atoms:HpParallelizeAtomsWorkChain","quantumespresso.hp.base":"aiida_quantumespresso_hp.workflows.hp.base:HpBaseWorkChain","quantumespresso.hp.hubbard":"aiida_quantumespresso_hp.workflows.hubbard:SelfConsistentHubbardWorkChain"},console_scripts:{launch_calculation_hp:"aiida_quantumespresso_hp.cli.calculations.hp:launch",launch_workflow_hp_base:"aiida_quantumespresso_hp.cli.workflows.hp.base:launch",launch_workflow_hp_main:"aiida_quantumespresso_hp.cli.workflows.hp.main:launch",launch_workflow_hp_hubbard:"aiida_quantumespresso_hp.cli.workflows.hubbard:launch"}},commits_count:0,development_status:"beta",errors:[],warnings:["Missing classifier 'Framework :: AiiDA'","Prefix 'quantumespresso.hp' does not follow naming convention."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:4},{colorclass:"purple",text:"Console scripts",count:4}],pip_install_cmd:"pip install git+https://github.com/sphuber/aiida-quantumespresso-hp",is_installable:"True"},"aiida-raspa":{code_home:"https://github.com/yakutovicha/aiida-raspa",entry_point_prefix:"raspa",pip_url:"aiida-raspa",plugin_info:"https://raw.github.com/yakutovicha/aiida-raspa/master/setup.json",name:"aiida-raspa",package_name:"aiida_raspa",hosted_on:"github.com",metadata:{release_date:"2023-08-26",description:"AiiDA plugin for RASPA code",author_email:"Aliaksandr Yakutovich <aliaksandr.yakutovich@epfl.ch>, Miriam Pougin <miriam.pougin@epfl.ch>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{raspa:{description:["This is a RaspaCalculation, subclass of CalcJob, to prepare input for RASPA code.","    For information on RASPA, refer to: https://github.com/iraspa/raspa2."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"block_pocket",required:!1,valid_types:"SinglefileData",info:"Zeo++ block pocket file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"file",required:!1,valid_types:"SinglefileData",info:"Additional input file(s)"},{name:"framework",required:!1,valid_types:"CifData",info:"Input framework(s)"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote folder used to continue the same simulation stating from the binary restarts."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieved_parent_folder",required:!1,valid_types:"FolderData, NoneType",info:"To use an old calculation as a starting poing for a new one."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional input parameters"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The results of a calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"warnings",required:!1,valid_types:"List",info:"Warnings that appeared during the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"The retrieved folder does not contain an output file."},{status:102,message:'The output does not contain "Starting simulation".'},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:500,message:"The calculation could not be completed due to the lack of time."}]},class:"aiida_raspa.calculations:RaspaCalculation"}},"aiida.parsers":{raspa:"aiida_raspa.parsers:RaspaParser"},"aiida.workflows":{"raspa.base":{description:["Workchain to run a RASPA calculation with automated error handling and restarts."],spec:{inputs:[{name:"raspa",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The results of a calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"warnings",required:!1,valid_types:"List",info:"Warnings that appeared during the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_raspa.workchains:RaspaBaseWorkChain"}}},commits_count:3,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-raspa",is_installable:"True"},"aiida-shell":{code_home:"https://github.com/sphuber/aiida-shell",entry_point_prefix:"core",pip_url:"aiida-shell",plugin_info:"https://raw.github.com/sphuber/aiida-shell/master/pyproject.toml",name:"aiida-shell",package_name:"aiida_shell",hosted_on:"github.com",metadata:{release_date:"2023-06-14",description:"AiiDA plugin that makes running shell commands easy.",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>',classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"0.5.3"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.calculations":{"core.shell":{description:["Implementation of :class:`aiida.engine.CalcJob` to run a simple shell command."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"arguments",required:!1,valid_types:"List, NoneType",info:""},{name:"filenames",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"nodes",required:!1,valid_types:"Data",info:""},{name:"outputs",required:!1,valid_types:"List, NoneType",info:""},{name:"parser",required:!1,valid_types:"PickledData, NoneType",info:""},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Exit status could not be determined: exit status file was not retrieved."},{status:301,message:"Exit status could not be determined: exit status file does not contain a valid integer."},{status:302,message:"The stdout file was not retrieved."},{status:303,message:"One or more output files defined in the `outputs` input were not retrieved: {missing_filepaths}."},{status:310,message:"Callable specified in the `parser` input excepted: {exception}."},{status:400,message:"The command exited with a non-zero status: {status} {stderr}."},{status:410,message:"The command exited with a zero status but the stderr was not empty."}]},class:"aiida_shell.calculations.shell:ShellJob"}},"aiida.data":{"core.code.installed.shell":"aiida_shell.data.code:ShellCode","core.pickled":"aiida_shell.data.pickled:PickledData"},"aiida.parsers":{"core.shell":"aiida_shell.parsers.shell:ShellParser"}},commits_count:46,development_status:"alpha",errors:[],warnings:["Prefix 'core' does not follow naming convention."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2}],pip_install_cmd:"pip install aiida-shell",is_installable:"True"},"aiida-siesta":{code_home:"https://github.com/siesta-project/aiida_siesta_plugin/tree/master",documentation_url:"https://aiida-siesta-plugin.readthedocs.io/",entry_point_prefix:"siesta",pip_url:"aiida-siesta",name:"aiida-siesta",package_name:"aiida_siesta",hosted_on:"github.com",metadata:{release_date:"2022-07-17",description:"A plugin for Siesta's basic functionality within the AiiDA framework.",author_email:'Albero Garcia <albertog@icmab.es>, "Victor M. Garcia-Suarez" <garciavictor@uniovi.es>, Emanuele Bosoni <ebosoni@icmab.es>, Vladimir Dikan <vdikan@icmab.es>, Pol Febrer <pol.febrer@icn2.cat>',classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{},commits_count:6,development_status:"stable",errors:["Unable to retrieve plugin info from: https://raw.github.com/siesta-project/aiida_siesta_plugin/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["No bdist_wheel available for PyPI release"],summaryinfo:[],pip_install_cmd:"pip install aiida-siesta",is_installable:"True"},"aiida-spex":{code_home:"https://github.com/JuDFTteam/aiida-spex",entry_point_prefix:"spex",pip_url:"git+https://github.com/JuDFTteam/aiida-spex",name:"aiida-spex",package_name:"aiida_spex",hosted_on:"github.com",metadata:{author:"The SPEX Team",author_email:"a.chandran@fz-juelich.de",version:"1.1.2",description:"AiiDA plugin for SPEX code",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.0.0b3,<3.0.0",entry_points:{"aiida.calculations":{"spex.spex":"aiida_spex.calculations.spex:SpexCalculation"},"aiida.data":{"spex.spexinp":"aiida_spex.data.spexinp:SpexinpData"},"aiida.parsers":{"spex.spexparser":"aiida_spex.parsers.spex:SpexParser"},"aiida.workflows":{"spex.job":"aiida_spex.workflows.job:SpexJobWorkchain"}},commits_count:0,development_status:"planning",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/JuDFTteam/aiida-spex"},"aiida-spirit":{code_home:"https://github.com/JuDFTteam/aiida-spirit/tree/main",documentation_url:"https://aiida-spirit.readthedocs.io/",entry_point_prefix:"spirit",name:"aiida-spirit",pip_url:"aiida-spirit",package_name:"aiida_spirit",hosted_on:"github.com",metadata:{release_date:"2023-06-23",description:"AiiDA plugin for the spirit code",author:"The JuDFT Team",author_email:"p.ruessmann@fz-juelich.de",license:"MIT",home_page:"https://github.com/JuDFTteam/aiida-spirit",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.2"},aiida_version:null,entry_points:{"aiida.calculations":{spirit:"aiida_spirit.calculations:SpiritCalculation"},"aiida.parsers":{spirit:"aiida_spirit.parsers:SpiritParser"}},commits_count:9,development_status:"planning",errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-spirit"},"aiida-ssh2win":{entry_point_prefix:"ssh2win",code_home:"https://github.com/edan-bainglass/aiida-ssh2win",version_file:"https://raw.githubusercontent.com/edan-bainglass/aiida-ssh2win/develop/aiida_ssh2win/__init__.py",pip_url:"git+https://github.com/edan-bainglass/aiida-ssh2win",name:"aiida-ssh2win",package_name:"aiida_ssh2win",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:13,development_status:"planning",errors:[],warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/edan-bainglass/aiida-ssh2win"},"aiida-sshonly":{code_home:"https://github.com/adegomme/aiida-sshonly",development_status:"beta",entry_point_prefix:"sshonly",pip_url:"aiida-sshonly",plugin_info:"https://raw.github.com/adegomme/aiida-sshonly/master/setup.json",name:"aiida-sshonly",package_name:"aiida_sshonly",hosted_on:"github.com",metadata:{release_date:"2020-10-07",description:"AiiDA plugin adding a sshonly transport option, using only SSH to transfer files, avoiding SFTP, in case it's blocked or non functional on a remote system",author:"adegomme",license:"MIT",home_page:"https://github.com/adegomme/aiida-sshonly",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0a3"},aiida_version:">=1.3.0,<2.0.0",entry_points:{"aiida.transports":{ssh_only:"aiida_sshonly.transports.sshonly:SshOnlyTransport"}},commits_count:0,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'ssh_only' does not start with prefix 'sshonly.'"],summaryinfo:[{colorclass:"orange",text:"Other (Transports)",count:1}],pip_install_cmd:"pip install --pre aiida-sshonly",is_installable:"True"},"aiida-sssp-workflow":{entry_point_prefix:"sssp_workflow",code_home:"https://github.com/aiidateam/aiida-sssp-workflow",version_file:"https://github.com/aiidateam/aiida-sssp-workflow/blob/main/aiida_sssp_workflow/version.py",documentation_url:"https://github.com/aiidateam/aiida-sssp-workflow#readme",pip_url:"aiida-sssp-workflow",plugin_info:"https://github.com/aiidateam/aiida-sssp-workflow/blob/main/setup.cfg",name:"aiida-sssp-workflow",package_name:"aiida_sssp_workflow",hosted_on:"github.com",metadata:{release_date:"2023-09-22",description:"Package for the AiiDA SSSP workflow",author:"Jusong Yu",author_email:"jusong.yu@psi.ch",license:"MIT",home_page:"https://github.com/aiidateam/aiida-sssp-workflow",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3 :: Only","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"4.2.0"},aiida_version:">=2.4.0,<2.5.0",entry_points:{"aiida.calculations":{"sssp_workflow.birch_murnaghan_fit":{description:["doc"],spec:{inputs:[{name:"volume_energy",required:!0,valid_types:"Dict",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_sssp_workflow.calculations.birch_murnaghan_fit:birch_murnaghan_fit"}},"aiida.workflows":{"sssp_workflow.convergence.bands":{description:["WorkChain to converge test on cohisive energy of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.bands:ConvergenceBandsWorkChain"},"sssp_workflow.convergence.cohesive_energy":{description:["WorkChain to converge test on cohisive energy of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.cohesive_energy:ConvergenceCohesiveEnergyWorkChain"},"sssp_workflow.convergence.delta":{description:["WorkChain to converge test on delta factor of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.delta:ConvergenceDeltaWorkChain"},"sssp_workflow.convergence.phonon_frequencies":{description:["WorkChain to converge test on cohisive energy of input structure"],spec:{inputs:[{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"ph_code",required:!0,valid_types:"AbstractCode",info:"The `ph.x` code  use for the `PhCalculation`."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"pw_code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.phonon_frequencies:ConvergencePhononFrequenciesWorkChain"},"sssp_workflow.convergence.pressure":{description:["WorkChain to converge test on pressure of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.pressure:ConvergencePressureWorkChain"},"sssp_workflow.measure.bands":{description:["WorkChain to run bands measure,","    run without sym for distance compare and band structure along the path"],spec:{inputs:[{name:"charge_density_cutoff",required:!0,valid_types:"Float",info:"The charge density cutoff."},{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"options",required:!0,valid_types:"Dict",info:"Optional `options` to use for the `PwCalculations`."},{name:"parallelization",required:!0,valid_types:"Dict",info:"Parallelization options for the `PwCalculations`."},{name:"protocol",required:!0,valid_types:"Str",info:"The protocol which define input calculation parameters."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"wavefunction_cutoff",required:!0,valid_types:"Float",info:"The wavefunction cutoff."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configurations",required:!1,valid_types:"List, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands",required:!0,valid_types:"",info:""},{name:"ecutrho",required:!0,valid_types:"Int",info:""},{name:"ecutwfc",required:!0,valid_types:"Int",info:""},{name:"band_structure",required:!1,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_sssp_workflow.workflows.measure.bands:BandsMeasureWorkChain"},"sssp_workflow.measure.precision":{description:["Workchain to calculate delta factor of specific pseudopotential"],spec:{inputs:[{name:"charge_density_cutoff",required:!0,valid_types:"Float",info:"The charge density cutoff."},{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"options",required:!0,valid_types:"Dict",info:"Optional `options` to use for the `PwCalculations`."},{name:"parallelization",required:!0,valid_types:"Dict",info:"Parallelization options for the `PwCalculations`."},{name:"protocol",required:!0,valid_types:"Str",info:"The protocol which define input calculation parameters."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"wavefunction_cutoff",required:!0,valid_types:"Float",info:"The wavefunction cutoff."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configurations",required:!1,valid_types:"List, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"",info:"The summary output parameters of all delta measures to describe the precision of EOS compare  with the AE equation of state."},{name:"BCC",required:!1,valid_types:"",info:"Delta calculation result of BCC EOS."},{name:"Diamond",required:!1,valid_types:"",info:"Delta calculation result of Diamond EOS."},{name:"FCC",required:!1,valid_types:"",info:"Delta calculation result of FCC EOS."},{name:"GS",required:!1,valid_types:"",info:"Delta calculation result of GS EOS."},{name:"RE",required:!1,valid_types:"",info:"Delta calculation result of RE EOS."},{name:"SC",required:!1,valid_types:"",info:"Delta calculation result of SC EOS."},{name:"X2O",required:!1,valid_types:"",info:"Delta calculation result of X2O EOS."},{name:"X2O3",required:!1,valid_types:"",info:"Delta calculation result of X2O3 EOS."},{name:"X2O5",required:!1,valid_types:"",info:"Delta calculation result of X2O5 EOS."},{name:"XO",required:!1,valid_types:"",info:"Delta calculation result of XO EOS."},{name:"XO2",required:!1,valid_types:"",info:"Delta calculation result of XO2 EOS."},{name:"XO3",required:!1,valid_types:"",info:"Delta calculation result of XO3 EOS."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The metric workchain of configuration {confs} not finished ok."}]},class:"aiida_sssp_workflow.workflows.measure.precision:PrecisionMeasureWorkChain"},"sssp_workflow.verification":{description:["The verification workflow to run all test for the given pseudopotential"],spec:{inputs:[{name:"convergence",required:!0,valid_types:"Data",info:""},{name:"measure",required:!0,valid_types:"Data",info:""},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"pw_code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"charge_density_cutoff",required:!1,valid_types:"Float, NoneType",info:"The charge density cutoff for the Measure properties."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"label",required:!1,valid_types:"Str, NoneType",info:"label store for display as extra attributes."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`"},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"ph_code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `ph.x` code use for the `PhCalculation`."},{name:"properties_list",required:!1,valid_types:"List",info:"The preperties will be calculated, passed as a list."},{name:"wavefunction_cutoff",required:!1,valid_types:"Float, NoneType",info:"The wavefunction cutoff for the Measure properties."}],outputs:[{name:"convergence",required:!0,valid_types:"",info:""},{name:"measure",required:!0,valid_types:"",info:""},{name:"pseudo_info",required:!0,valid_types:"Dict",info:"pseudopotential info"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The caching is triggered but failed."},{status:811,message:"The sub-workflows {processes} is not finished ok."}]},class:"aiida_sssp_workflow.workflows.verifications:VerificationWorkChain"}},console_scripts:{"aiida-sssp-workflow":"aiida_sssp_workflow.cli:cmd_root"}},commits_count:73,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"green",text:"Workflows",count:8},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-sssp-workflow",is_installable:"True"},"aiida-statefile-schedulers":{code_home:"https://github.com/dev-zero/aiida-statefile-schedulers",development_status:"beta",entry_point_prefix:"statefile_schedulers",pip_url:"aiida-statefile-schedulers",name:"aiida-statefile-schedulers",package_name:"aiida_statefile_schedulers",hosted_on:"github.com",metadata:{release_date:"2021-11-23",description:"Simple statefile-driven task schedulers for AiiDA",author:"Tiziano Müller",author_email:"tm@dev-zero.ch",license:"MIT",home_page:"https://github.com/dev-zero/aiida-statefile-schedulers",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.1"},aiida_version:null,entry_points:{"aiida.schedulers":{"statefile_schedulers.direct":"aiida_statefile_schedulers.schedulers.direct:StatefileDirectScheduler"}},commits_count:0,errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"orange",text:"Other (Schedulers)",count:1}],pip_install_cmd:"pip install aiida-statefile-schedulers",is_installable:"True"},"aiida-strain":{code_home:"https://github.com/greschd/aiida-strain",documentation_url:"https://aiida-strain.readthedocs.io",entry_point_prefix:"strain",pip_url:"aiida-strain",name:"aiida-strain",package_name:"aiida_strain",hosted_on:"github.com",metadata:{release_date:"2019-11-22",description:"AiiDA Plugin for applying strain to structures",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-strain.readthedocs.io",classifiers:["Development Status :: 3 - Alpha","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.workflows":{"strain.apply_strains":{description:["Workchain to create strained structures from a given input structure."],spec:{inputs:[{name:"strain_kind",required:!0,valid_types:"Str",info:""},{name:"strain_parameters",required:!0,valid_types:"Str",info:""},{name:"strain_strengths",required:!0,valid_types:"List",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_strain:ApplyStrains"},"strain.apply_strains_with_symmetry":{description:["Workchain to create strained structures from an input structure, and select the symmetries which are compatible with the strained structure from a set of given input symmetries."],spec:{inputs:[{name:"strain_kind",required:!0,valid_types:"Str",info:""},{name:"strain_parameters",required:!0,valid_types:"Str",info:""},{name:"strain_strengths",required:!0,valid_types:"List",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:""},{name:"symmetry_repr_code",required:!0,valid_types:"Code",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_strain:ApplyStrainsWithSymmetry"}}},commits_count:0,development_status:"alpha",errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"green",text:"Workflows",count:2}],pip_install_cmd:"pip install aiida-strain",is_installable:"True"},"aiida-supercell":{code_home:"https://github.com/pzarabadip/aiida-supercell",development_status:"stable",documentation_url:"https://aiida-supercell.readthedocs.io/",entry_point_prefix:"supercell",pip_url:"git+https://github.com/pzarabadip/aiida-supercell",name:"aiida-supercell",package_name:"aiida_supercell",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"1.0.1",description:"AiiDA Plugin for Supercell program",classifiers:["Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"]},aiida_version:">=1.0.0,<2.0",entry_points:{"aiida.calculations":{supercell:{description:["This is a SupercellCalculation, subclass of JobCalculation,","    to prepare input for enumerating structures using Supercell program"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"structure",required:!0,valid_types:"StructureData, SinglefileData",info:"Input structure"},{name:"supercell_size",required:!0,valid_types:"List",info:"Supercell size for enumeration"},{name:"calculate_coulomb_energies",required:!1,valid_types:"Bool",info:"Whether to calculate Coulomb energies"},{name:"charge_balance_method",required:!1,valid_types:"Str",info:"Method to use for charge balancing"},{name:"charges",required:!1,valid_types:"Dict",info:"Dictionary of formal charges to be used"},{name:"merge_symmetric",required:!1,valid_types:"Bool",info:"Whether to merge symmetrically distinct configurations"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"random_seed",required:!1,valid_types:"Int",info:"Random seed number"},{name:"sample_structures",required:!1,valid_types:"Dict",info:"How to sample structures from huge configuration space"},{name:"save_as_archive",required:!1,valid_types:"Bool",info:"Whether to save resulting structures as archive"},{name:"tolerance",required:!1,valid_types:"Float",info:"The maximum distance (in Angstroms) between sites that should be contained within the same group."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"the results of the calculation"},{name:"output_structures",required:!0,valid_types:"StructureData",info:"relaxed structure"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"Input structure could not be processed."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_supercell.calculations:SupercellCalculation"}},"aiida.parsers":{supercell:"aiida_supercell.parsers:SupercellParser"}},commits_count:0,errors:[],warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-supercell",is_installable:"True"},"aiida-symmetry-representation":{code_home:"https://github.com/greschd/aiida_symmetry_representation",documentation_url:"https://aiida-symmetry-representation.readthedocs.io",entry_point_prefix:"symmetry_representation",pip_url:"aiida-symmetry-representation",name:"aiida-symmetry-representation",package_name:"aiida_symmetry_representation",hosted_on:"github.com",metadata:{release_date:"2019-11-18",description:"AiiDA Plugin for symmetry representations.",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-symmetry-representation.readthedocs.io",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.calculations":{"symmetry_representation.filter_symmetries":{description:["Calculation class to run the ``symmetry-repr filter_symmetries`` command."],spec:{inputs:[{name:"structure",required:!0,valid_types:"StructureData",info:"Structure with which the filtered symmetries should be compatible."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"File containing the symmetries (in HDF5 format)."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"The HDF5 file containing the symmetries which are compatible with the structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_symmetry_representation.calculations.filter_symmetries:FilterSymmetriesCalculation"}},"aiida.parsers":{"symmetry_representation.symmetry":"aiida_symmetry_representation.parsers.symmetries:SymmetriesParser"}},commits_count:0,development_status:"stable",errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-symmetry-representation",is_installable:"True"},"aiida-tbextraction":{code_home:"https://github.com/greschd/aiida-tbextraction",documentation_url:"https://aiida-tbextraction.readthedocs.io/",entry_point_prefix:"tbextraction",pip_url:"aiida-tbextraction",name:"aiida-tbextraction",package_name:"aiida_tbextraction",hosted_on:"github.com",metadata:{release_date:"2020-02-25",description:"AiiDA Plugin for extracting tight-binding models",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-tbextraction.readthedocs.io",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0b1"},aiida_version:null,entry_points:{"aiida.workflows":{"tbextraction.fp_run.base":"aiida_tbextraction.fp_run:FirstPrinciplesRunBase","tbextraction.fp_run.reference_bands.base":"aiida_tbextraction.fp_run.reference_bands:ReferenceBandsBase","tbextraction.fp_run.wannier_input.base":"aiida_tbextraction.fp_run.wannier_input:WannierInputBase","tbextraction.calculate_tb":"aiida_tbextraction.calculate_tb:TightBindingCalculation","tbextraction.model_evaluation.base":"aiida_tbextraction.model_evaluation:ModelEvaluationBase","tbextraction.model_evaluation.band_difference":"aiida_tbextraction.model_evaluation:BandDifferenceModelEvaluation","tbextraction.energy_windows.run_window":"aiida_tbextraction.energy_windows.run_window:RunWindow","tbextraction.energy_windows.window_search":"aiida_tbextraction.energy_windows.window_search:WindowSearch","tbextraction.optimize_fp_tb":"aiida_tbextraction.optimize_fp_tb:OptimizeFirstPrinciplesTightBinding","tbextraction.optimize_strained_fp_tb":"aiida_tbextraction.optimize_strained_fp_tb:OptimizeStrainedFirstPrinciplesTightBinding"}},commits_count:0,development_status:"beta",errors:[`Failed to install plugin aiida-tbextraction</br><pre>Collecting aiida-tbextraction
  Downloading aiida-tbextraction-0.2.0b1.tar.gz (19 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [20 lines of output]
      /opt/conda/lib/python3.9/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.
      !!
      
              ********************************************************************************
              Requirements should be satisfied by a PEP 517 installer.
              If you are using pip, you can try \`pip install --use-pep517\`.
              ********************************************************************************
      
      !!
        dist.fetch_build_eggs(dist.setup_requires)
      [ REENTRY ] registering entry points with reentry...
      [ REENTRY ] ... registered to /home/aiida/.config/reentry/data/fb804e5deb254c259a00b9e16a29b7b797b2c8f0a8a97f3aa7401e8a85ce8cdb
      [ REENTRY ] Following entrypoints were registered
      
          aiida-tbextraction -> {'aiida.workflows': {'tbextraction.fp_run.base': 'tbextraction.fp_run.base = aiida_tbextraction.fp_run:FirstPrinciplesRunBase', 'tbextraction.fp_run.reference_bands.base': 'tbextraction.fp_run.reference_bands.base = aiida_tbextraction.fp_run.reference_bands:ReferenceBandsBase', 'tbextraction.fp_run.wannier_input.base': 'tbextraction.fp_run.wannier_input.base = aiida_tbextraction.fp_run.wannier_input:WannierInputBase', 'tbextraction.calculate_tb': 'tbextraction.calculate_tb = aiida_tbextraction.calculate_tb:TightBindingCalculation', 'tbextraction.model_evaluation.base': 'tbextraction.model_evaluation.base = aiida_tbextraction.model_evaluation:ModelEvaluationBase', 'tbextraction.model_evaluation.band_difference': 'tbextraction.model_evaluation.band_difference = aiida_tbextraction.model_evaluation:BandDifferenceModelEvaluation', 'tbextraction.energy_windows.run_window': 'tbextraction.energy_windows.run_window = aiida_tbextraction.energy_windows.run_window:RunWindow', 'tbextraction.energy_windows.window_search': 'tbextraction.energy_windows.window_search = aiida_tbextraction.energy_windows.window_search:WindowSearch', 'tbextraction.optimize_fp_tb': 'tbextraction.optimize_fp_tb = aiida_tbextraction.optimize_fp_tb:OptimizeFirstPrinciplesTightBinding', 'tbextraction.optimize_strained_fp_tb': 'tbextraction.optimize_strained_fp_tb = aiida_tbextraction.optimize_strained_fp_tb:OptimizeStrainedFirstPrinciplesTightBinding'}}
      [ REENTRY ] Current entry point map at /home/aiida/.config/reentry/data/fb804e5deb254c259a00b9e16a29b7b797b2c8f0a8a97f3aa7401e8a85ce8cdb:
          aiida-tbextraction -> {'aiida.workflows': {'tbextraction.fp_run.base': 'tbextraction.fp_run.base = aiida_tbextraction.fp_run:FirstPrinciplesRunBase', 'tbextraction.fp_run.reference_bands.base': 'tbextraction.fp_run.reference_bands.base = aiida_tbextraction.fp_run.reference_bands:ReferenceBandsBase', 'tbextraction.fp_run.wannier_input.base': 'tbextraction.fp_run.wannier_input.base = aiida_tbextraction.fp_run.wannier_input:WannierInputBase', 'tbextraction.calculate_tb': 'tbextraction.calculate_tb = aiida_tbextraction.calculate_tb:TightBindingCalculation', 'tbextraction.model_evaluation.base': 'tbextraction.model_evaluation.base = aiida_tbextraction.model_evaluation:ModelEvaluationBase', 'tbextraction.model_evaluation.band_difference': 'tbextraction.model_evaluation.band_difference = aiida_tbextraction.model_evaluation:BandDifferenceModelEvaluation', 'tbextraction.energy_windows.run_window': 'tbextraction.energy_windows.run_window = aiida_tbextraction.energy_windows.run_window:RunWindow', 'tbextraction.energy_windows.window_search': 'tbextraction.energy_windows.window_search = aiida_tbextraction.energy_windows.window_search:WindowSearch', 'tbextraction.optimize_fp_tb': 'tbextraction.optimize_fp_tb = aiida_tbextraction.optimize_fp_tb:OptimizeFirstPrinciplesTightBinding', 'tbextraction.optimize_strained_fp_tb': 'tbextraction.optimize_strained_fp_tb = aiida_tbextraction.optimize_strained_fp_tb:OptimizeStrainedFirstPrinciplesTightBinding'}}
      error in aiida-tbextraction setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier)
          aiida-core>=1.0.0<2
                    ~~~~~~~^
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"green",text:"Workflows",count:10}],pip_install_cmd:"pip install --pre aiida-tbextraction",is_installable:"False"},"aiida-tbmodels":{code_home:"https://github.com/greschd/aiida-tbmodels",documentation_url:"https://aiida-tbmodels.readthedocs.io",entry_point_prefix:"tbmodels",pip_url:"aiida-tbmodels",name:"aiida-tbmodels",package_name:"aiida_tbmodels",hosted_on:"github.com",metadata:{release_date:"2020-03-03",description:"AiiDA Plugin for running TBmodels",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-tbmodels.readthedocs.io",classifiers:["Development Status :: 3 - Alpha","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.3.0"},aiida_version:null,entry_points:{"aiida.calculations":{"tbmodels.eigenvals":{description:["Calculation class for the 'tbmodels eigenvals' command, which computes the eigenvalues from a given tight-binding model."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"Kpoints for which the eigenvalues are calculated."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands",required:!0,valid_types:"BandsData",info:"The calculated eigenvalues of the model at given k-points."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The result HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."}]},class:"aiida_tbmodels.calculations.eigenvals:EigenvalsCalculation"},"tbmodels.parse":{description:["Calculation plugin for the 'tbmodels parse' command, which creates a","    TBmodels tight-binding model from the Wannier90 output."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"wannier_folder",required:!0,valid_types:"FolderData",info:"Folder containing the Wannier90 output data."},{name:"distance_ratio_threshold",required:!1,valid_types:"Float",info:"Determines the minimum ratio between nearest and next-nearest atom when parsing with 'nearest_atom' mode."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pos_kind",required:!1,valid_types:"Str",info:"Determines how the orbital positions are parsed."},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."},{status:301,message:"The seedname_wsvec.dat file is empty or incomplete."},{status:401,message:"The nearest atom to use for position parsing is ambiguous."}]},class:"aiida_tbmodels.calculations.parse:ParseCalculation"},"tbmodels.slice":{description:["Calculation plugin for the 'tbmodels slice' command, which re-orders or slices orbitals of a tight-binding model."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"slice_idx",required:!0,valid_types:"List",info:"Indices of the orbitals which are sliced from the model."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."}]},class:"aiida_tbmodels.calculations.slice:SliceCalculation"},"tbmodels.symmetrize":{description:["Calculation class for the 'tbmodels symmetrize' command, which creates a symmetrized tight-binding model from a tight-binding model and symmetry representations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"File containing the symmetries in HDF5 format."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."},{status:301,message:"The type of the given symmetries object is incorrect."}]},class:"aiida_tbmodels.calculations.symmetrize:SymmetrizeCalculation"}},"aiida.parsers":{"tbmodels.model":"aiida_tbmodels.parsers.model:ModelParser"}},commits_count:0,development_status:"alpha",errors:[],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:4},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-tbmodels",is_installable:"True"},"aiida-tcod":{code_home:"https://github.com/aiidateam/aiida-tcod",development_status:"beta",entry_point_prefix:"tcod",pip_url:"git+https://github.com/aiidateam/aiida-tcod",name:"aiida-tcod",package_name:"aiida_tcod",hosted_on:"github.com",metadata:{author:"The AiiDA team",author_email:"developers@aiida.net",version:"0.1.0a0",description:"AiiDA plugin to interact with the TCOD",classifiers:["Programming Language :: Python"]},aiida_version:">=1.0.0b1",entry_points:{"aiida.tools.dbexporters":{tcod:"aiida.tools.dbexporters.tcod"}},commits_count:0,errors:[],warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"orange",text:"Other (Database Exporters)",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidateam/aiida-tcod",is_installable:"True"},"aiida-uppasd":{code_home:"https://github.com/uppasd/aiida-uppasd",documentation_url:"https://github.com/uppasd/aiida-uppasd/blob/master/README.md",entry_point_prefix:"uppasd",pip_url:"git+https://github.com/unkcpz/aiida-uppasd",name:"aiida-uppasd",package_name:"aiida_uppasd",hosted_on:"github.com",metadata:{author:"Qichen Xu, Anders Bergman, Anna Delin, Jonathan Chico",author_email:"qichenx@kth.se",version:"0.1.0",description:"Interface for UppASD and AiiDA",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.calculations":{UppASD_core_calculations:"UppASD_AiiDA.calculations.core_calcs:UppASD"},"aiida.parsers":{UppASD_core_parsers:"UppASD_AiiDA.parsers.core_parser:SpinDynamic_core_parser"}},commits_count:0,development_status:"planning",errors:[],warnings:["Entry point 'UppASD_core_calculations' does not start with prefix 'uppasd.'","Entry point 'UppASD_core_parsers' does not start with prefix 'uppasd.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/unkcpz/aiida-uppasd"},"aiida-vasp":{code_home:"https://github.com/aiida-vasp/aiida-vasp",documentation_url:"https://aiida-vasp.readthedocs.io/",entry_point_prefix:"vasp",pip_url:"aiida-vasp",plugin_info:"https://raw.githubusercontent.com/aiida-vasp/aiida-vasp/master/setup.json",name:"aiida-vasp",package_name:"aiida_vasp",hosted_on:"github.com",metadata:{release_date:"2023-07-03",description:"AiiDA plugin for running VASP calculations and workflows.",author_email:"Espen Flage-Larsen <espen.flage-larsen@sigma2.no>",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"3.0.1"},aiida_version:">=2.4,<3.0",entry_points:{"aiida.calculations":{"vasp.immigrant":{description:["Parse VASP output objects stored in a specified directory.","","    Simulate running the VaspCalculation up to the point where it can be","    retrieved and parsed, then hand over control to the runner for the rest.","","    Usage examples","    --------------","    Immigrant calculation can be perfomed as follows.","","    ::","","       code = Code.get_from_string('vasp@local')","       folder = '/home/username/vasp-calc-dir'","       settings = {'parser_settings': {'add_energies': True,","                                       'add_forces': True,","                                       'electronic_step_energies': True}}","       VaspImmigrant = CalculationFactory('vasp.immigrant')","       builder = VaspImmigrant.get_builder_from_folder(code,","                                                       folder,","                                                       settings=settings)","       submit(builder)","","    Instead of ``builder``, inputs dict is obtained similarly as","","    ::","","       code = Code.get_from_string('vasp@local')","       folder = '/home/username/vasp-calc-dir'","       settings = {'parser_settings': {'add_energies': True,","                                       'add_forces': True,","                                       'electronic_step_energies': True}}","       VaspImmigrant = CalculationFactory('vasp.immigrant')","       inputs = VaspImmigrant.get_inputs_from_folder(code,","                                                     folder,","                                                     settings=settings)","       submit(VaspImmigrant, **inputs)","","    Note","    ----","    The defaul metadata is set automatically as follows::","","       {'options': {'max_wallclock_seconds': 1,","        'resources': {'num_machines': 1, 'num_mpiprocs_per_machine': 1}}}","","    Specific scheduler may require setting ``resources`` differently","    (e.g., sge ``'parallel_env'``).","","    ``get_inputs_from_folder`` and ``get_builder_from_folder`` accept several","    kwargs, see the docstring of ``get_inputs_from_folder``."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData, NoneType",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"remote_workdir",required:!1,valid_types:"str, NoneType",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData, NoneType",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.immigrant:VaspImmigrant"},"vasp.neb":{description:["NEB calculations using VASP","","    ------------------------------------","    Calculations for performing NEB calculations.","    NEB calculations requires standard VASP inputs, but POSCAR are placed in","    folder names 00, 01, 02... N for N-1 number of images.","","    Input frames should be placed under the ``neb_images`` input namespace as a dictionary like::","      {","          'image_00': structure_1,","          'image_01': structure_2","          ....","      }","","    Output of individual frames are placed in the corresponding namespace under the same convention."],spec:{inputs:[{name:"final_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for the final image."},{name:"initial_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for initial image."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"neb_images",required:!0,valid_types:"StructureData, CifData",info:"Starting structure for the NEB images"},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"Per-image misc output."},{name:"neb_misc",required:!0,valid_types:"Dict",info:"NEB related data combined for each image"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"structure",required:!0,valid_types:"StructureData",info:"NEB images"},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"Kpoints for each image."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization for each image."},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output file containing the plane wave coefficients."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output files and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:352,message:"a file that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure the `neb_data` and `run_status` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1001,message:"parsing a file has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.neb:VaspNEBCalculation"},"vasp.vasp":{description:["General-purpose VASP calculation.","","    ---------------------------------","    By default retrieves only the 'OUTCAR', 'vasprun.xml', 'EIGENVAL', 'DOSCAR'","    and Wannier90 input / output objects. These objects are deleted after parsing.","    Additional retrieve objects can be specified via the","    ``settings['ADDITIONAL_RETRIEVE_TEMPORARY_LIST']`` input. In addition, if you want to keep","    any objects after parsing, put them in ``settings['ADDITIONAL_RETRIEVE_LIST']`` which is empty","    by default.","","    Floating point precision for writing POSCAR objects can be adjusted using","    ``settings['poscar_precision']``, default: 10","","    The following assumes you are familiar with the AiiDA data structures and","    how to set up and run an AiiDA calculation in general.","","    Example usage::","","        from aiida.orm import CalculationFactory, DataFactory","        from aiida.work import submit","","        proc = CalculationFactory('vasp.vasp').process()","        inputs = proc.get_inputs_template()","        inputs.parameter = <Dict with INCAR params>","        inputs.structure = <StructureData>","        inputs.kpoints = <KpointsData>","        inputs.settings = <Dict with parser settings etc.>","        inputs.potential = DataFactory('vasp.potcar').get_potcars_from_structure(structure, ...)","        inputs.code = <Code representing vasp on your cluster>","","        submit(proc, **inputs)","","    Which is very similar to the workchain example.","","    Since we do not want the content parsers to know about the AiiDA infrastructure,","    i.e. processes etc. we have no access to the exit codes defined on the CalcJob.","    We thus have to deal with failures in parsing directly in the write calls here."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData, NoneType",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData, NoneType",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.vasp:VaspCalculation"},"vasp.vasp2w90":{description:["General purpose Calculation for using vasp with the vasp2wannier90 interface."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData, NoneType",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wannier_parameters",required:!1,valid_types:"Dict, NoneType",info:"Input parameters for the Wannier90 interface."},{name:"wannier_projections",required:!1,valid_types:"OrbitalData, List, NoneType",info:"Projections to be defined in the Wannier90 input."},{name:"wavefunctions",required:!1,valid_types:"WavefunData, NoneType",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.vasp2w90:Vasp2w90Calculation"}},"aiida.cmdline.data":{"vasp-potcar":"aiida_vasp.commands.potcar:potcar"},"aiida.data":{"vasp.archive":"aiida_vasp.data.archive:ArchiveData","vasp.chargedensity":"aiida_vasp.data.chargedensity:ChargedensityData","vasp.potcar":"aiida_vasp.data.potcar:PotcarData","vasp.potcar_file":"aiida_vasp.data.potcar:PotcarFileData","vasp.wavefun":"aiida_vasp.data.wavefun:WavefunData"},"aiida.groups":{"vasp.potcar":"aiida_vasp.data.potcar:PotcarGroup"},"aiida.parsers":{"vasp.neb":"aiida_vasp.parsers.neb:VtstNebParser","vasp.vasp":"aiida_vasp.parsers.vasp:VaspParser","vasp.vasp2w90":"aiida_vasp.parsers.vasp2w90:Vasp2w90Parser"},"aiida.workflows":{"vasp.bands":{description:["Extract the band structure using k-point paths fetched from SeeKpath."],spec:{inputs:[{name:"bands",required:!0,valid_types:"",info:""},{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"restart_folder",required:!0,valid_types:"RemoteData",info:`
            The folder to restart in, which contains the outputs from the prerun to extract the charge density.
            `},{name:"smearing",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"bands",required:!0,valid_types:"BandsData",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the bands workchain"},{status:2001,message:"BandsData not found in exposed_outputs"}]},class:"aiida_vasp.workchains.bands:BandsWorkChain"},"vasp.converge":{description:["A workchain to perform convergence tests."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"converge",required:!0,valid_types:"",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"converge",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"relax",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the converge workchain"}]},class:"aiida_vasp.workchains.converge:ConvergeWorkChain"},"vasp.immigrant":{description:["Import a VASP run executed in the directory specified by folder_path."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"folder_path",required:!1,valid_types:"Str, NoneType",info:"Deprecated."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"potential_family",required:!1,valid_types:"Str, NoneType",info:""},{name:"potential_mapping",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_workdir",required:!1,valid_types:"str, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"use_chgcar",required:!1,valid_types:"Bool, NoneType",info:`
            If True, WavefunData (of WAVECAR) is attached.
            `},{name:"use_wavecar",required:!1,valid_types:"Bool, NoneType",info:`
            If True, WavefunData (of WAVECAR) is attached.
            `},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_vasp.workchains.immigrant:VaspImmigrantWorkChain"},"vasp.master":{description:["The master workchain that selects sub workchains to perform necessary calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"converge",required:!0,valid_types:"",info:""},{name:"dos",required:!0,valid_types:"",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"extract_bands",required:!1,valid_types:"Bool, NoneType",info:"Do you want to extract the band structure?"},{name:"extract_dos",required:!1,valid_types:"Bool, NoneType",info:"Do you want to extract the density of states?"},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The maximum distance between k-points in inverse AA."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"bands",required:!1,valid_types:"",info:""},{name:"dos",required:!1,valid_types:"",info:""}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the master workchain"}]},class:"aiida_vasp.workchains.master:MasterWorkChain"},"vasp.neb":{description:["The NEB workchain.","","    -------------------","    Error handling enriched wrapper around VaspNEBCalculation.","","    Deliberately conserves most of the interface (required inputs) of the VaspNEBCalculation class, but","    makes it possible for a user to interact with a workchain and not a calculation.","","    In addition, implement restarts of calculation when the calculation is net full converged for error handling."],spec:{inputs:[{name:"dynamics",required:!0,valid_types:"",info:""},{name:"final_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for the final image."},{name:"initial_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for initial image."},{name:"neb_images",required:!0,valid_types:"StructureData, CifData",info:"Starting structure for the NEB images"},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"kpoints_spacing",required:!1,valid_types:"Float, NoneType",info:"Spacing for the kpoints in units A^-1 * 2pi (CASTEP style `kpoints_mp_spacing`)"},{name:"kpoints_spacing_vasp",required:!1,valid_types:"Float, NoneType",info:"Spacing for the kpoints in units A^-1 (VASP style)"},{name:"ldau_mapping",required:!1,valid_types:"Dict, NoneType",info:"Mappings, see the doc string of 'get_ldau_keys'"},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"Per-image misc output."},{name:"neb_misc",required:!0,valid_types:"Dict",info:"NEB related data combined for each image"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"structure",required:!0,valid_types:"StructureData",info:"NEB images"},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"Kpoints for each image."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization for each image."},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output file containing the plane wave coefficients."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."},{status:501,message:"Unrecoverable error in launched NEB calculations."},{status:700,message:"the user did not supply a potential family name"},{status:701,message:"ValueError was returned from get_potcars_from_structure"},{status:702,message:"the potential does not exist"},{status:703,message:"the exception: {exception} was thrown while massaging the parameters"}]},class:"aiida_vasp.workchains.neb:VaspNEBWorkChain"},"vasp.relax":{description:["Structure relaxation workchain."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"relax",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"relax",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"the called workchain does not contain the necessary relaxed output structure"},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the relax workchain"},{status:502,message:"there was an error overriding the parameters"}]},class:"aiida_vasp.workchains.relax:RelaxWorkChain"},"vasp.vasp":{description:["The VASP workchain.","","    -------------------","    Error handling enriched wrapper around VaspCalculation.","","    Deliberately conserves most of the interface (required inputs) of the VaspCalculation class, but","    makes it possible for a user to interact with a workchain and not a calculation.","","    This is intended to be used instead of directly submitting a VaspCalculation,","    so that future features like","    automatic restarting, error checking etc. can be propagated to higher level workchains","    automatically by implementing them here.","","    Handlers are implemented to try fix common problems and improves the robustness.","    Individual handlers can be enabled/disabled by setting the ``handler_overrides`` input port.",'    Additional settings may be passed under the "settings" input, which is also forwarded to the',"    calculations. The available options are:","","    - ``USE_WAVECAR_FOR_RESTART`` wether calculation restarts should use the WAVECAR. The default is ``True``.","","    Usage::","","        from aiida.common.extendeddicts import AttributeDict","        from aiida.work import submit","        basevasp = WorkflowFactory('vasp.vasp')","        inputs = basevasp.get_builder()","        inputs = AttributeDict()","        ## ... set inputs","        submit(basevasp, **inputs)","","    To see a working example, including generation of input nodes from scratch, please","    refer to ``examples/run_vasp_lean.py``."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"the calculation is missing at least one required output in the restart workchain"},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:400,message:"the run_calculation step did not successfully add a calculation node to the context"},{status:401,message:"the maximum number of iterations was exceeded"},{status:402,message:"the calculation finished with an unexpected calculation state"},{status:403,message:"the calculation experienced and unexpected failure"},{status:404,message:"the calculation failed to submit, twice in a row"},{status:405,message:"the calculation failed for an unknown reason, twice in a row"},{status:500,message:"Missing critical output for inspecting the status of the calculation."},{status:501,message:"Cannot handle the error - inputs are likely need to be revised manually. Message: {message}"},{status:502,message:"Cannot handle the error - the last calculation did not reach the end of execution."},{status:503,message:"Cannot handle the error - the last calculation did not reach electronic convergence."},{status:504,message:"The ionic relaxation is not converged."},{status:505,message:"At least one of the ionic steps during the relaxation has did not have converged electronic structure."},{status:700,message:"the user did not supply a potential family name"},{status:701,message:"ValueError was returned from get_potcars_from_structure"},{status:702,message:"the potential does not exist"},{status:703,message:"the exception: {exception} was thrown while massaging the parameters"}]},class:"aiida_vasp.workchains.vasp:VaspWorkChain"}},console_scripts:{"mock-vasp":"aiida_vasp.commands.mock_vasp:mock_vasp","mock-vasp-strict":"aiida_vasp.commands.mock_vasp:mock_vasp_strict"}},commits_count:100,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:4},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:5},{colorclass:"green",text:"Workflows",count:7},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:2}],pip_install_cmd:"pip install aiida-vasp",is_installable:"True"},"aiida-vibroscopy":{entry_point_prefix:"vibroscopy",plugin_info:"https://raw.githubusercontent.com/bastonero/aiida-vibroscopy/main/pyproject.toml",code_home:"https://github.com/bastonero/aiida-vibroscopy",version_file:"https://raw.githubusercontent.com/bastonero/aiida-vibroscopy/main/src/aiida_vibroscopy/__init__.py",pip_url:"aiida-vibroscopy",documentation_url:"https://aiida-vibroscopy.readthedocs.io/en/latest/",name:"aiida-vibroscopy",package_name:"aiida_vibroscopy",hosted_on:"github.com",metadata:{release_date:"2023-08-10",description:"AiiDA plugin for vibrational spectoscopy using Quantum ESPRESSO.",author_email:"Lorenzo Bastonero <bastonero.lorenzo@gmail.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: Other/Proprietary License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.0.2"},aiida_version:">=2.2.2,<3.0.0",entry_points:{"aiida.data":{"vibroscopy.fp":"aiida_vibroscopy.data.vibro_fp:VibrationalFrozenPhononData","vibroscopy.vibrational":"aiida_vibroscopy.data.vibro_lr:VibrationalData"},"aiida.workflows":{"vibroscopy.dielectric":{description:["Workchain computing different second and third order tensors.","","    It computes the high frequency dielectric tensor, the Born effective charges,","    the non-linear optical susceptibility and Raman tensors","    using homogeneous small electric fields via the electric enthalpy functional."],spec:{inputs:[{name:"central_difference",required:!0,valid_types:"",info:"The inputs for the central difference scheme."},{name:"property",required:!0,valid_types:"str",info:`irValid inputs are: 
 
 * born-chargesValid inputs are: 
 
 * dielectricValid inputs are: 
 
 * nacValid inputs are: 
 
 * becValid inputs are: 
 
 * ramanValid inputs are: 
 
 * susceptibility-derivativeValid inputs are: 
 
 * non-linear-susceptibility`},{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` that will be used to run the electric enthalpy scfs."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"kpoints_parallel_distance",required:!1,valid_types:"Float, NoneType",info:"Distance of the k-points in reciprocal space along the parallel direction of each applied electric field."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parent_scf",required:!1,valid_types:"RemoteData, NoneType",info:"Scf parent folder from where restarting the scfs with electric fields."}],outputs:[{name:"fields_data",required:!0,valid_types:"",info:"Namespace for passing TrajectoryData containing forces and polarization."},{name:"tensors",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric and Born effectivecharges tensors computed in Cartesian coordinates. Depending on the inputs, it can also contain the derivatives of the susceptibility in respect to the atomic positions (called `Raman tensors`) and the non linear optical susceptibility, always expressed in Cartesian coordinates."},{name:"accuracy_order",required:!1,valid_types:"Int",info:""},{name:"critical_electric_field",required:!1,valid_types:"Float",info:""},{name:"electric_field_step",required:!1,valid_types:"Float",info:""},{name:"units",required:!1,valid_types:"Dict",info:"Units of the susceptibility derivatives tensors."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The initial scf work chain failed."},{status:401,message:"The nscf work chain failed."},{status:402,message:"The electric field scf work chain failed for direction {direction}."},{status:403,message:"The numerical derivatives calculation failed."},{status:404,message:"The scf PwBaseWorkChain sub process in iteration returned a non integer total magnetization (threshold exceeded)."}]},class:"aiida_vibroscopy.workflows.dielectric.base:DielectricWorkChain"},"vibroscopy.dielectric.numerical_derivatives":{description:["Workchain carrying out numerical derivatives.","","    It computes the first and second order derivatives","    of forces and polarization in respect to electric field,","    to obtain dielectric tensor, Born effective charges,","    non linear optical susceptibility and Raman tensors.","","    Forces and polarization must be passed as TrajectoryData","    as a dictionary in `data`. Numerical derivatives can have","    different number of evaluation points, depending on order and accuracy.","    The price to pay is the standardization of the structure of","    the dictionary to pass to this namespace.","","    To understand, let's review the approach.In central differencs approach","    we need the evaluation of the function at the value we want","    the derivative (in our case at :math:`\\mathcal{E}=0`,","    E is the electric field), and at","    displaced positions from this value.","    The evaluation of the function at these points will","    have weights (or coefficients), which depend on order and accuracy.","    For example:","","    - :math:`\\frac{df}{dx} = \\frac{ 0.5 \\cdot f(+1.0 \\cdot h) -0.5 \\cdot f(-1.0 \\cdot h) }{h} +\\mathcal{O}(h^2)`","    - :math:`\\frac{d^2 f}{dx^2} = \\frac{ 1.0 \\cdot f(+1.0 \\cdot h) -2.0 \\cdot f(0. \\cdot h) +1.0 \\cdot f(-1.0 \\cdot h) }{h^2} +\\mathcal{O}(h^2)`","","    Referring to the coefficients for each step as :math:`c_i`,","    where `i` is an integer, our convention is","    to put in sequence the Trajectory data with increasing","    numbers as labels, for example:","","    | '0': TrajectoryData for :math:`c_1`,","    | '1': TrajectoryData for :math:`c_{-1}`,","    | '2': TrajectoryData for :math:`c_2`,","    | '3': TrajectoryData for :math:`c_{-2}`,","    | ...","","    This way to creating an analogous of an array with","    coefficients :math:`[c_1,c_{-1},c_2,c_{-2}, \\dots]`.","","    These dictionaries are going to be put as sub-dictionary","    in a general `data` dictionary. Each sub-dict","    has to be put with a key with suffix a number indicating","    which tensor component is referring to.","    In our case, we use a similar Voigt notation.","    Namely we have two cases:","","    * first order derivatives: keys suffices are 0,1,2;","        0 for :math:`[i,x]`, 1 for :math:`[i,y]`, 2 for","        :math:`[i,z]` (with :math:`i={x,y,z}`)","    * second order derivatives: keys suffices are 0,...5;","        0 for :math:`[i,x,x]`, :math:`\\dots` (as in Voigt),","        5 for :math:`[i,x,y]` (with :math:`i={x,y,z}`)","","    The prefix can be anything. Best practice is using ``field_``","    with and underscorre as prefix. The Trajectory data for the","    :math:`c_0` coefficient (i.e. the one with :math:`\\mathcal{E}=0`)","    must be passed with a different key, namely ``null_field``.","    This is to avoid errors and due to the fact that is common","    to the all derivatives."],spec:{inputs:[{name:"central_difference",required:!0,valid_types:"",info:"The inputs for the central difference scheme."},{name:"data",required:!0,valid_types:"",info:"Namespace for passing TrajectoryData containing forces and polarization."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"tensors",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric and Born effectivecharges tensors computed in Cartesian coordinates. Depending on the inputs, it can also contain the derivatives of the susceptibility in respect to the atomic positions (called `Raman tensors`) and the non linear optical susceptibility, always expressed in Cartesian coordinates."},{name:"units",required:!1,valid_types:"Dict",info:"Units of the susceptibility derivatives tensors."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_vibroscopy.workflows.dielectric.numerical_derivatives:NumericalDerivativesWorkChain"},"vibroscopy.phonons.harmonic":{description:["Workchain for frozen phonons calculations.","","    Non-analytical constants (NAC) and higher order mixed  derivatives are computed","    via finite differences through finite electric fields.","    See :class:`~aiida_vibroscopy.workflows.DielectricWorkChain`","    for more details on how they are carried out."],spec:{inputs:[{name:"phonon",required:!0,valid_types:"Data",info:"Inputs for the `PhononWorkChain` that will beused to calculate the force constants."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"dielectric",required:!1,valid_types:"Data",info:"Inputs for the `DielectricWorkChain` that will beused to calculate the mixed derivatives with electric field."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"phonopy",required:!1,valid_types:"Data",info:"Inputs for the `PhonopyCalculation` that willbe used to calculate the inter-atomic force constants, or for post-processing."}],outputs:[{name:"output_phonon",required:!0,valid_types:"",info:"Outputs of the `PhononWorkChain`."},{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"output_dielectric",required:!1,valid_types:"",info:"Outputs of the `DielectricWorkChain`."},{name:"output_phonopy",required:!1,valid_types:"",info:"Outputs of the post-processing via `phonopy`."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The phonon workchain failed."},{status:401,message:"The dielectric workchain failed."},{status:402,message:"The phonopy calculation failed."}]},class:"aiida_vibroscopy.workflows.phonons.harmonic:HarmonicWorkChain"},"vibroscopy.phonons.phonon":{description:["Class for computing force constants of phonons, without non-analytical corrections."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` that will be used to run the electric enthalpy scfs."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"displacement_generator",required:!1,valid_types:"Dict, NoneType",info:`Info for displacements generation. The following flags are allowed:
 distance
 is_plusminus
 is_diagonal
 is_trigonal
 number_of_snapshots
 random_seed
 cutoff_frequency`},{name:"metadata",required:!1,valid_types:"",info:""},{name:"phonopy",required:!1,valid_types:"Data",info:"Inputs for the `PhonopyCalculation` that willbe used to calculate the inter-atomic force constants, or for post-processing."},{name:"primitive_matrix",required:!1,valid_types:"List, NoneType",info:"Primitive matrix that defines the primitive cell from the unitcell."},{name:"supercell_matrix",required:!1,valid_types:"List, NoneType",info:"Supercell matrix that defines the supercell from the unitcell."}],outputs:[{name:"phonopy_data",required:!0,valid_types:"PhonopyData",info:"The phonopy data with supercells displacements, forces to use in the post-processing calculation."},{name:"supercells_forces",required:!0,valid_types:"ArrayData, TrajectoryData",info:"The forces acting on the atoms of each supercell."},{name:"output_phonopy",required:!1,valid_types:"",info:""},{name:"supercells",required:!1,valid_types:"StructureData",info:"The supercells with displacements."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The initial supercell scf work chain failed."},{status:401,message:"The initial PwBaseWorkChain sub process returned a non integer total magnetization."},{status:402,message:"At least one sub processe did not finish successfully."},{status:403,message:"The phonopy calculation did not finish correctly."}]},class:"aiida_vibroscopy.workflows.phonons.base:PhononWorkChain"},"vibroscopy.spectra.intensities_average":{description:["Workchain that computes IR and Raman spatial and q-direction average spectra."],spec:{inputs:[{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"Vibrational data containing force constants or frozen phonons forces, nac parameters and/or susceptibility derivatives."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:"Options for averaging on the non-analytical directions."}],outputs:[{name:"ir_averaged",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric tensor computed in Cartesian coordinates."},{name:"raman_averaged",required:!1,valid_types:"ArrayData",info:"Contains Born effective charges tensors computed in Cartesian coordinates."},{name:"units",required:!1,valid_types:"Dict",info:"Units of intensities and frequencies."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_vibroscopy.workflows.spectra.intensities_average:IntensitiesAverageWorkChain"},"vibroscopy.spectra.iraman":{description:["Workchain for automatically compute IR and Raman spectra using finite displacements and fields.","","    For other details of the sub-workchains used, see also:","        * :class:`~aiida_vibroscopy.workflows.dielectric.base.DielectricWorkChain` for finite fields","        * :class:`~aiida_vibroscopy.workflows.phonons.base.PhononWorkChain` for finite displacements"],spec:{inputs:[{name:"dielectric",required:!0,valid_types:"Data",info:"Inputs for the `DielectricWorkChain` that will beused to calculate the mixed derivatives with electric field."},{name:"phonon",required:!0,valid_types:"Data",info:"Inputs for the `PhononWorkChain` that will beused to calculate the force constants."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"intensities_average",required:!1,valid_types:"Data",info:"Inputs for the `IntensitiesAverageWorkChain` that willbe used to run the average calculation over intensities."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_phonon",required:!0,valid_types:"",info:"Outputs of the `PhononWorkChain`."},{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"fake",required:!1,valid_types:"",info:""},{name:"output_dielectric",required:!1,valid_types:"",info:"Outputs of the `DielectricWorkChain`."},{name:"output_intensities_average",required:!1,valid_types:"",info:"Intensities average over space and q-points."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The averaging procedure for intensities had an unexpected error."},{status:401,message:"The averaging procedure for intensities had an unexpected error."}]},class:"aiida_vibroscopy.workflows.spectra.iraman:IRamanSpectraWorkChain"}}},commits_count:71,development_status:"beta",errors:[],warnings:[],summaryinfo:[{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:6}],pip_install_cmd:"pip install aiida-vibroscopy",is_installable:"True"},"aiida-wannier90":{code_home:"https://github.com/aiidateam/aiida-wannier90",documentation_url:"https://aiida-wannier90.readthedocs.io/",entry_point_prefix:"wannier90",pip_url:"aiida-wannier90",plugin_info:"https://raw.github.com/aiidateam/aiida-wannier90/master/setup.json",name:"aiida-wannier90",package_name:"aiida_wannier90",hosted_on:"github.com",metadata:{release_date:"2023-07-03",description:"AiiDA Plugin for the Wannier90 code",author:"Junfeng Qiao, Dominik Gresch, Antimo Marrazzo, Daniel Marchand, Giovanni Pizzi, Norma Rivano, The AiiDA team",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.1.0"},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{"wannier90.postw90":{description:["Plugin for Wannier90.","","    Wannier90 is a code for computing maximally-localized Wannier functions.","    See http://www.wannier.org/ for more details."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the Wannier90 code"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``RemoteData`` possibly stored in a remote computer."},{name:"structure",required:!0,valid_types:"StructureData",info:"input crystal structure"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"A list of k-points along a path to be used for bands interpolation; it should contain `labels`. Specify either this or `kpoint_path`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"kpoint_path",required:!1,valid_types:"Dict, NoneType",info:"Description of the k-points path to be used for bands interpolation; it should contain two properties: a list ``path`` of length-2 tuples with the labels of the endpoints of the path; and a dictionary ``point_coords`` giving the scaled coordinates for each high-symmetry endpoint."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"k-point mesh used in the NSCF calculation."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"projections",required:!1,valid_types:"OrbitalData, Dict, List, NoneType",info:"Starting projections for the Wannierisation procedure."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional settings to manage the Wannier90 calculation."}],outputs:[{name:"boltzwann",required:!0,valid_types:"",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The ``output_parameters`` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"interpolated_bands",required:!1,valid_types:"BandsData",info:"The interpolated band structure by Wannier90 (if any)."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required stdout output file."},{status:300,message:"A Wannier90 error file (.werr) has been found."},{status:400,message:'The string "Exiting..." has been found in the Wannier90 output (some partial output might have been parsed).'},{status:401,message:"An error related to bvectors has been found in the Wannier90 output."},{status:402,message:"Energy window contains fewer states than number of target WFs."},{status:403,message:"Error plotting Wanier functions in cube format."},{status:404,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:405,message:"Some output files were missing probably because the calculation got interrupted."},{status:406,message:"The retrieved temporary folder could not be accessed."}]},class:"aiida_wannier90.calculations:Postw90Calculation"},"wannier90.wannier90":{description:["Plugin for Wannier90.","","    Wannier90 is a code for computing maximally-localized Wannier functions.","    See http://www.wannier.org/ for more details."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"k-point mesh used in the NSCF calculation."},{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the Wannier90 code"},{name:"structure",required:!0,valid_types:"StructureData",info:"input crystal structure"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"A list of k-points along a path to be used for bands interpolation; it should contain `labels`. Specify either this or `kpoint_path`."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"kpoint_path",required:!1,valid_types:"Dict, NoneType",info:"Description of the k-points path to be used for bands interpolation; it should contain two properties: a list ``path`` of length-2 tuples with the labels of the endpoints of the path; and a dictionary ``point_coords`` giving the scaled coordinates for each high-symmetry endpoint."},{name:"local_input_folder",required:!1,valid_types:"FolderData, NoneType",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``FolderData`` stored in the AiiDA repository."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"projections",required:!1,valid_types:"OrbitalData, Dict, List, NoneType",info:"Starting projections for the Wannierisation procedure."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"remote_input_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``RemoteData`` possibly stored in a remote computer."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional settings to manage the Wannier90 calculation."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The ``output_parameters`` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"interpolated_bands",required:!1,valid_types:"BandsData",info:"The interpolated band structure by Wannier90 (if any)."},{name:"nnkp_file",required:!1,valid_types:"SinglefileData",info:"The ``.nnkp`` file, produced only in -pp (postproc) mode."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required stdout output file."},{status:300,message:"A Wannier90 error file (.werr) has been found."},{status:400,message:'The string "Exiting..." has been found in the Wannier90 output (some partial output might have been parsed).'},{status:401,message:"An error related to bvectors has been found in the Wannier90 output."},{status:402,message:"Energy window contains fewer states than number of target WFs."},{status:403,message:"Error plotting Wanier functions in cube format."},{status:404,message:"The stdout output file was incomplete probably because the calculation got interrupted."}]},class:"aiida_wannier90.calculations:Wannier90Calculation"}},"aiida.parsers":{"wannier90.postw90":"aiida_wannier90.parsers:Postw90Parser","wannier90.wannier90":"aiida_wannier90.parsers:Wannier90Parser"},"aiida.workflows":{"wannier90.minimal":{description:["Workchain to run a full stack of Quantum ESPRESSO + Wannier90 for GaAs.","","    Note that this is mostly to be used as an example, as there is no","    error checking and runs directly Quantum ESPRESSO calculations rather","    than the base workflows."],spec:{inputs:[{name:"kpoint_path",required:!0,valid_types:"Dict",info:"The kpoints path for the NSCF run and Wannierisation."},{name:"kpoints_nscf",required:!0,valid_types:"KpointsData",info:"The kpoints for the NSCF run and Wannierisation."},{name:"kpoints_scf",required:!0,valid_types:"KpointsData",info:"The kpoints for the SCF run."},{name:"projections",required:!0,valid_types:"OrbitalData",info:"The projections for the Wannierisation."},{name:"pseudo_family",required:!0,valid_types:"Str",info:"The name of a pseudopotential family to use."},{name:"pw2wannier90_code",required:!0,valid_types:"Code",info:"The `pw2wannier90.x` code to use for the `Pw2Wannier90Calculation`s."},{name:"pw_code",required:!0,valid_types:"Code",info:"The `pw.x` code to use for the `PwCalculation`s."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"wannier_code",required:!0,valid_types:"Code",info:"The `wannier90.x` code to use for the `Wannier90Calculation`s."},{name:"max_wallclock_seconds",required:!1,valid_types:"Int, NoneType",info:"Maximum wallclock time in seconds"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"num_machines",required:!1,valid_types:"Int, NoneType",info:"The number of machines (nodes) to use"}],outputs:[{name:"matrices_folder",required:!0,valid_types:"FolderData",info:""},{name:"nnkp_file",required:!0,valid_types:"SinglefileData",info:""},{name:"nscf_output",required:!0,valid_types:"Dict",info:""},{name:"p2wannier_output",required:!0,valid_types:"Dict",info:""},{name:"pw2wan_remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"scf_output",required:!0,valid_types:"Dict",info:""},{name:"wannier_bands",required:!0,valid_types:"BandsData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_wannier90.workflows.minimal:MinimalW90WorkChain"}}},commits_count:20,development_status:"stable",errors:[],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-wannier90",is_installable:"True"},"aiida-wannier90-workflows":{code_home:"https://github.com/aiidateam/aiida-wannier90-workflows",development_status:"stable",entry_point_prefix:"wannier90_workflows",pip_url:"aiida-wannier90-workflows",plugin_info:"https://raw.github.com/aiidateam/aiida-wannier90-workflows/master/setup.json",name:"aiida-wannier90-workflows",package_name:"aiida_wannier90_workflows",hosted_on:"github.com",metadata:{release_date:"2023-07-04",description:"Advanced AiiDA workflows for Wannier90",author:"Junfeng Qiao, Antimo Marrazzo, Giovanni Pizzi",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.1.0"},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{"wannier90_workflows.split":"aiida_wannier90_workflows.calculations.split:Wannier90SplitCalculation"},"aiida.parsers":{"wannier90_workflows.split":"aiida_wannier90_workflows.parsers.split:Wannier90SplitParser"},"aiida.workflows":{"wannier90_workflows.bands":"aiida_wannier90_workflows.workflows.bands:Wannier90BandsWorkChain","wannier90_workflows.base.open_grid":"aiida_wannier90_workflows.workflows.base.open_grid:OpenGridBaseWorkChain","wannier90_workflows.base.projwfc":"aiida_wannier90_workflows.workflows.base.projwfc:ProjwfcBaseWorkChain","wannier90_workflows.base.pw2wannier90":"aiida_wannier90_workflows.workflows.base.pw2wannier90:Pw2wannier90BaseWorkChain","wannier90_workflows.base.wannier90":"aiida_wannier90_workflows.workflows.base.wannier90:Wannier90BaseWorkChain","wannier90_workflows.open_grid":"aiida_wannier90_workflows.workflows.open_grid:Wannier90OpenGridWorkChain","wannier90_workflows.optimize":"aiida_wannier90_workflows.workflows.optimize:Wannier90OptimizeWorkChain","wannier90_workflows.projwfcbands":"aiida_wannier90_workflows.workflows.projwfcbands:ProjwfcBandsWorkChain","wannier90_workflows.split":"aiida_wannier90_workflows.workflows.split:Wannier90SplitWorkChain","wannier90_workflows.wannier90":"aiida_wannier90_workflows.workflows.wannier90:Wannier90WorkChain"},console_scripts:{"aiida-wannier90-workflows":"aiida_wannier90_workflows.cli:cmd_root"}},commits_count:40,errors:[`Failed to fetch entry point metadata for package aiida_wannier90_workflows</br><pre>Traceback (most recent call last):
  File "/opt/conda/lib/python3.9/site-packages/plumpy/processes.py", line 185, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'Protect' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.9/site-packages/aiida/engine/processes/workchains/workchain.py", line 138, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.9/site-packages/aiida/engine/processes/process.py", line 88, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.9/site-packages/plumpy/processes.py", line 190, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.9/site-packages/aiida_wannier90_workflows/workflows/bands.py", line 50, in define
    super().define(spec)
  File "/opt/conda/lib/python3.9/site-packages/aiida_wannier90_workflows/workflows/open_grid.py", line 45, in define
    super().define(spec)
  File "/opt/conda/lib/python3.9/site-packages/aiida_wannier90_workflows/workflows/wannier90.py", line 109, in define
    spec.inputs["nscf"]["pw"].validator = PwCalculation.validate_inputs_base
AttributeError: type object 'PwCalculation' has no attribute 'validate_inputs_base'
</pre>`],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:10},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-wannier90-workflows",is_installable:"True"},"aiida-wien2k":{code_home:"https://github.com/rubel75/aiida-wien2k",entry_point_prefix:"wien2k",name:"aiida-wien2k",package_name:"aiida_wien2k",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:7,development_status:"planning",errors:[],warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-yambo":{code_home:"https://github.com/yambo-code/yambo-aiida/",development_status:"stable",entry_point_prefix:"yambo",pip_url:"aiida-yambo",plugin_info:"https://raw.github.com/yambo-code/yambo-aiida/master/setup.json",name:"aiida-yambo",package_name:"aiida_yambo",hosted_on:"github.com",metadata:{release_date:"2020-11-05",description:"YAMBO plugin and workflows for AiiDA",author:"Miki Bonacci, Michael Atambo, Antimo Marrazzo, Prandini Gianluca",author_email:"miki.bonacci@unimore.it",license:"MIT",home_page:"https://github.com/yambo-code/yambo-aiida",classifiers:["Environment :: Plugins","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Topic :: Scientific/Engineering :: Physics"],version:"1.3.0"},aiida_version:">=1.0.0a2",entry_points:{"aiida.calculations":{"yambo.yambo":{description:["AiiDA plugin for the Yambo code.","    For more information, refer to http://www.yambo-code.org/","    https://github.com/yambo-code/yambo-aiida and http://aiida-yambo.readthedocs.io/en/latest/"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"Use a main code for yambo calculation"},{name:"parameters",required:!0,valid_types:"Dict",info:"Use a node that specifies the input parameters"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:'Use a remote folder as parent folder (for "restarts and similar"'},{name:"settings",required:!0,valid_types:"Dict",info:"Use an additional node for special settings"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"precode_parameters",required:!1,valid_types:"Dict",info:"Use a node that specifies the input parameters for the yambo precode"},{name:"preprocessing_code",required:!1,valid_types:"Code",info:"Use a preprocessing code for starting yambo"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"returns the output parameters"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array_alpha",required:!1,valid_types:"ArrayData",info:"returns the alpha array"},{name:"array_alpha_array",required:!1,valid_types:"ArrayData",info:"returns the alpha array"},{name:"array_alpha_bands",required:!1,valid_types:"ArrayData",info:"returns the alpha array bands"},{name:"array_eels",required:!1,valid_types:"ArrayData",info:"returns the eels array"},{name:"array_eps",required:!1,valid_types:"ArrayData",info:"returns the eps array"},{name:"array_ndb",required:!1,valid_types:"ArrayData",info:"returns the array for ndb"},{name:"array_ndb_HFlocXC",required:!1,valid_types:"ArrayData",info:"returns the array ndb for HFlocXC"},{name:"array_ndb_QP",required:!1,valid_types:"ArrayData",info:"returns the array for ndbQP"},{name:"array_qp",required:!1,valid_types:"ArrayData",info:"returns the quasiparticle array band structure"},{name:"bands_quasiparticle",required:!1,valid_types:"BandsData",info:"returns the quasiparticle band structure"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"system_info",required:!1,valid_types:"Dict",info:"returns some system information after a p2y"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:500,message:"The retrieved folder data node could not be accessed."},{status:501,message:"time exceeded the max walltime"},{status:502,message:"failed calculation for some reason: could be a low number of conduction bands"},{status:503,message:"Unexpected behavior of YamboFolder"},{status:504,message:"parallelization error"},{status:505,message:"general memory error"},{status:506,message:"x_par allocation memory error"}]},class:"aiida_yambo.calculations.yambo:YamboCalculation"}},"aiida.data":{},"aiida.parsers":{"yambo.yambo":"aiida_yambo.parsers.parsers:YamboParser"}},commits_count:75,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-yambo",is_installable:"True"},"aiida-yambo-wannier90":{code_home:"https://github.com/aiidaplugins/aiida-yambo-wannier90",entry_point_prefix:"yambo_wannier90",pip_url:"aiida-yambo-wannier90",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-yambo-wannier90/main/pyproject.toml",documentation_url:"https://aiida-yambo-wannier90.readthedocs.io/en/latest/",version_file:"https://raw.githubusercontent.com/aiidaplugins/aiida-yambo-wannier90/main/aiida_yambo_wannier90/__init__.py",name:"aiida-yambo-wannier90",package_name:"aiida_yambo_wannier90",hosted_on:"github.com",metadata:{release_date:"2022-07-06",description:"Plugin to combine Wannier90 interpolations with GW corrections computed by Yambo",author:"The AiiDA Team",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0b0"},aiida_version:">=1.6.4,<3",entry_points:{"aiida.calculations":{"yambo_wannier90.gw2wannier90":"aiida_yambo_wannier90.calculations.gw2wannier90:Gw2wannier90Calculation"},"aiida.parsers":{"yambo_wannier90.gw2wannier90":"aiida_yambo_wannier90.parsers.gw2wannier90:Gw2wannier90Parser"},"aiida.workflows":{yambo_wannier90:"aiida_yambo_wannier90.workflows:YamboWannier90WorkChain"},console_scripts:{"aiida-yambo-wannier90":"aiida_yambo_wannier90.cli:cmd_root"}},commits_count:0,development_status:"beta",errors:[`Failed to install plugin aiida-yambo-wannier90</br><pre>Collecting aiida-yambo-wannier90
  Downloading aiida_yambo_wannier90-0.1.0b0-py3-none-any.whl (27 kB)
Requirement already satisfied: aiida-core<3,>=1.6.4 in /opt/conda/lib/python3.9/site-packages (from aiida-yambo-wannier90) (2.4.0.post0)
Collecting voluptuous (from aiida-yambo-wannier90)
  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)
Collecting aiida-yambo>=1.3.0 (from aiida-yambo-wannier90)
  Downloading aiida_yambo-1.3.0-py3-none-any.whl (57 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.8/57.8 kB 21.3 MB/s eta 0:00:00
Collecting aiida-wannier90-workflows>=1.0.1 (from aiida-yambo-wannier90)
  Obtaining dependency information for aiida-wannier90-workflows>=1.0.1 from https://files.pythonhosted.org/packages/fd/b8/41d408f6f17f79e95e01c15192d31b941f0393fe9c7d0f0f6787fc9886ce/aiida_wannier90_workflows-2.1.0-py3-none-any.whl.metadata
  Downloading aiida_wannier90_workflows-2.1.0-py3-none-any.whl.metadata (4.7 kB)
Requirement already satisfied: alembic~=1.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.12.0)
Requirement already satisfied: archive-path~=0.4.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.4.2)
Requirement already satisfied: aio-pika~=6.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.8.1)
Requirement already satisfied: circus~=0.18.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.18.0)
Requirement already satisfied: click-spinner~=0.1.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.1.10)
Requirement already satisfied: click~=8.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (8.1.7)
Requirement already satisfied: disk-objectstore~=0.6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.6.0)
Requirement already satisfied: docstring-parser in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.15)
Requirement already satisfied: get-annotations~=0.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.1.2)
Requirement already satisfied: graphviz~=0.19 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.20.1)
Requirement already satisfied: ipython>=7 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (8.15.0)
Requirement already satisfied: jinja2~=3.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.1.2)
Requirement already satisfied: jsonschema~=3.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.2.0)
Requirement already satisfied: kiwipy[rmq]~=0.7.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.7.7)
Requirement already satisfied: importlib-metadata~=4.13 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.13.0)
Requirement already satisfied: numpy~=1.21 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.26.0)
Requirement already satisfied: paramiko>=2.7.2,~=2.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.12.0)
Requirement already satisfied: plumpy~=0.21.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.21.8)
Requirement already satisfied: pgsu~=0.2.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.4)
Requirement already satisfied: psutil~=5.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (5.9.5)
Requirement already satisfied: psycopg2-binary~=2.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.9.7)
Requirement already satisfied: pytz~=2021.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2021.3)
Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.0.1)
Requirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.31.0)
Requirement already satisfied: sqlalchemy~=1.4.22 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.4.49)
Requirement already satisfied: tabulate~=0.8.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.8.10)
Requirement already satisfied: tqdm~=4.45 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.66.1)
Requirement already satisfied: upf_to_json~=0.9.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.9.5)
Requirement already satisfied: wrapt~=1.11 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.15.0)
Collecting aiida-pseudo>=0.6 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-pseudo>=0.6 from https://files.pythonhosted.org/packages/6a/96/203eb64f3775f093e6ff0c17aeea52c3d127759d18542a58663dd7822e5c/aiida_pseudo-1.2.0-py3-none-any.whl.metadata
  Downloading aiida_pseudo-1.2.0-py3-none-any.whl.metadata (10 kB)
Collecting aiida-quantumespresso>=4.3 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-quantumespresso>=4.3 from https://files.pythonhosted.org/packages/44/b7/dd5cc31567b448f5fa84cdbb2d80ce51e07267868cac3d21525df9d0a6ed/aiida_quantumespresso-4.4.0-py3-none-any.whl.metadata
  Downloading aiida_quantumespresso-4.4.0-py3-none-any.whl.metadata (32 kB)
Collecting aiida-wannier90>=2.1 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-wannier90>=2.1 from https://files.pythonhosted.org/packages/52/da/4215feadd7ec82c13834fed9ed4f4bbc18b36b3b2fbc0bdb0d9765e9e0b8/aiida_wannier90-2.1.0-py3-none-any.whl.metadata
  Downloading aiida_wannier90-2.1.0-py3-none-any.whl.metadata (4.1 kB)
Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90) (0.4.6)
INFO: pip is looking at multiple versions of aiida-yambo to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-wannier90-workflows>=1.0.1 (from aiida-yambo-wannier90)
  Downloading aiida_wannier90_workflows-1.0.2-py3-none-any.whl (22 kB)
Collecting aiida-core<3,>=1.6.4 (from aiida-yambo-wannier90)
  Downloading aiida_core-1.6.9-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 52.5 MB/s eta 0:00:00
Collecting aiida-quantumespresso>=3.0.0a6 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading aiida_quantumespresso-3.5.2-py3-none-any.whl (729 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 729.3/729.3 kB 75.2 MB/s eta 0:00:00
Collecting netcdf4 (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for netcdf4 from https://files.pythonhosted.org/packages/f9/06/d677c7c5e9c46ddbbc07a7952bfe931f4a598eef0dea7683cb7c1a08cdcf/netCDF4-1.6.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading netCDF4-1.6.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting h5py (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for h5py from https://files.pythonhosted.org/packages/4f/79/8e6e05bc4954ebdb8b9c587f780a11f28790585798bd15a8e4870cfc02bc/h5py-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading h5py-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)
Collecting pytest (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for pytest from https://files.pythonhosted.org/packages/df/d0/e192c4275aecabf74faa1aacd75ef700091913236ec78b1a98f62a2412ee/pytest-7.4.2-py3-none-any.whl.metadata
  Downloading pytest-7.4.2-py3-none-any.whl.metadata (7.9 kB)
Collecting psycopg2-binary<2.9 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading psycopg2_binary-2.8.6-cp39-cp39-manylinux1_x86_64.whl (3.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 78.9 MB/s eta 0:00:00
Collecting aiida-pseudo~=0.6.1 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-pseudo~=0.6.1 from https://files.pythonhosted.org/packages/b7/6d/8432b84a538ac479235b043cb7ce1eba59e8f8c195a369a52395f41bf5e6/aiida_pseudo-0.6.5-py3-none-any.whl.metadata
  Downloading aiida_pseudo-0.6.5-py3-none-any.whl.metadata (3.3 kB)
Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90) (23.1)
Collecting qe-tools~=2.0rc1 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading qe_tools-2.0.0-py3-none-any.whl (23 kB)
Collecting xmlschema>=1.2.5,~=1.2 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading xmlschema-1.11.3-py3-none-any.whl (356 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 356.5/356.5 kB 79.3 MB/s eta 0:00:00
Collecting importlib_resources (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for importlib_resources from https://files.pythonhosted.org/packages/65/6e/09d8816b5cb7a4006ef8ad1717a2703ad9f331dae9717d9f22488a2d6469/importlib_resources-6.1.0-py3-none-any.whl.metadata
  Downloading importlib_resources-6.1.0-py3-none-any.whl.metadata (4.1 kB)
Collecting aldjemy~=0.9.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading aldjemy-0.9.1-py3-none-any.whl (26 kB)
Collecting archive-path~=0.2.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading archive_path-0.2.1-py3-none-any.whl (17 kB)
Collecting circus~=0.17.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading circus-0.17.2-py3-none-any.whl (204 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 204.2/204.2 kB 37.3 MB/s eta 0:00:00
Collecting click-completion~=0.5.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading click-completion-0.5.2.tar.gz (10 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting click-config-file~=0.6.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading click_config_file-0.6.0-py2.py3-none-any.whl (6.0 kB)
Collecting click~=7.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 31.7 MB/s eta 0:00:00
Collecting django~=2.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Django-2.2.28-py3-none-any.whl (7.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.5/7.5 MB 68.8 MB/s eta 0:00:00
Collecting ete3~=3.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading ete3-3.1.3.tar.gz (4.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 79.0 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting ipython~=7.20 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 793.8/793.8 kB 60.5 MB/s eta 0:00:00
Collecting jinja2~=2.10 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 40.9 MB/s eta 0:00:00
Collecting markupsafe<2.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading MarkupSafe-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)
Requirement already satisfied: pamqp~=2.3 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.3.0)
Collecting plumpy~=0.20.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading plumpy-0.20.0-py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 26.8 MB/s eta 0:00:00
Collecting python-dateutil~=2.8 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 66.0 MB/s eta 0:00:00
Collecting pytz~=2019.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 kB 82.0 MB/s eta 0:00:00
Collecting pyyaml~=5.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 630.1/630.1 kB 102.8 MB/s eta 0:00:00
Collecting reentry~=1.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading reentry-1.3.3-py3-none-any.whl (17 kB)
Collecting simplejson~=3.16 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading simplejson-3.19.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.4/137.4 kB 40.3 MB/s eta 0:00:00
Collecting sqlalchemy-utils~=0.36.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading SQLAlchemy-Utils-0.36.5.tar.gz (131 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.2/131.2 kB 40.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sqlalchemy~=1.3.10 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading SQLAlchemy-1.3.24-cp39-cp39-manylinux2010_x86_64.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 118.5 MB/s eta 0:00:00
Collecting tzlocal~=2.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)
Collecting wrapt~=1.11.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading wrapt-1.11.2.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
INFO: pip is looking at multiple versions of aiida-core[atomic-tools,docs] to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-core[atomic_tools,docs]>=1.0.0a2 (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-core[atomic_tools,docs]>=1.0.0a2 from https://files.pythonhosted.org/packages/2b/ec/a99338a82592fb94c5741288143d34281162fe4e19228e059cfec67d5589/aiida_core-2.4.0-py3-none-any.whl.metadata
  Downloading aiida_core-2.4.0-py3-none-any.whl.metadata (10 kB)
  Obtaining dependency information for aiida-core[atomic_tools,docs]>=1.0.0a2 from https://files.pythonhosted.org/packages/d9/96/c88f1af662144765c15acdbada6d33f92e57a0c2311f6aa09fa8fcc7c91a/aiida_core-2.3.1-py3-none-any.whl.metadata
  Downloading aiida_core-2.3.1-py3-none-any.whl.metadata (11 kB)
  Downloading aiida_core-2.3.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 119.6 MB/s eta 0:00:00
  Downloading aiida_core-2.2.2-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 123.0 MB/s eta 0:00:00
  Downloading aiida_core-2.2.1-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 124.4 MB/s eta 0:00:00
  Downloading aiida_core-2.2.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 121.6 MB/s eta 0:00:00
  Downloading aiida_core-2.1.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 119.1 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of aiida-core[atomic-tools,docs] to determine which version is compatible with other requirements. This could take a while.
  Downloading aiida_core-2.1.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 123.5 MB/s eta 0:00:00
  Downloading aiida_core-2.1.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 116.2 MB/s eta 0:00:00
  Downloading aiida_core-2.0.4-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 123.5 MB/s eta 0:00:00
  Downloading aiida_core-2.0.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 125.3 MB/s eta 0:00:00
  Downloading aiida_core-2.0.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 123.0 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading aiida_core-2.0.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 116.9 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 118.1 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0b1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 121.5 MB/s eta 0:00:00
Collecting seekpath>=1.9.3,~=1.9 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading seekpath-1.9.7-py2.py3-none-any.whl (86 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.9/86.9 kB 35.6 MB/s eta 0:00:00
Collecting PyCifRW~=4.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading PyCifRW-4.4.5-cp39-cp39-manylinux_2_5_x86_64.whl (162 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.4/162.4 kB 60.7 MB/s eta 0:00:00
Collecting sphinx-copybutton~=0.3.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinx_copybutton-0.3.3-py3-none-any.whl (12 kB)
Collecting sphinxcontrib-details-directive~=0.1.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinxcontrib_details_directive-0.1.0-py2.py3-none-any.whl (10 kB)
Collecting pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pymatgen-2022.2.1.tar.gz (2.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 125.7 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Installing backend dependencies: started
  Installing backend dependencies: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting spglib~=1.14 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading spglib-1.16.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 325.5/325.5 kB 76.0 MB/s eta 0:00:00
Collecting pydata-sphinx-theme~=0.4.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pydata_sphinx_theme-0.4.3-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 122.7 MB/s eta 0:00:00
Collecting sphinx~=3.2.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Sphinx-3.2.1-py3-none-any.whl (2.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 137.9 MB/s eta 0:00:00
Requirement already satisfied: pygments~=2.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.16.1)
Collecting sphinx-notfound-page~=0.5 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinx_notfound_page-0.8.3-py2.py3-none-any.whl (8.5 kB)
Collecting flask-restful~=0.3.7 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for flask-restful~=0.3.7 from https://files.pythonhosted.org/packages/d7/7b/f0b45f0df7d2978e5ae51804bb5939b7897b2ace24306009da0cc34d8d1f/Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata
  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata (1.0 kB)
Collecting pyparsing~=2.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 25.1 MB/s eta 0:00:00
Collecting pymysql~=0.9.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading PyMySQL-0.9.3-py2.py3-none-any.whl (47 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.7/47.7 kB 20.0 MB/s eta 0:00:00
Collecting ase~=3.18 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 127.5 MB/s eta 0:00:00
Collecting sphinx-panels~=0.5.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinx_panels-0.5.2-py3-none-any.whl (87 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.8/87.8 kB 32.9 MB/s eta 0:00:00
Collecting docutils==0.15.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 547.6/547.6 kB 99.8 MB/s eta 0:00:00
Collecting flask~=1.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Flask-1.1.4-py2.py3-none-any.whl (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.6/94.6 kB 29.7 MB/s eta 0:00:00
Collecting flask-cors~=3.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)
Collecting python-memcached~=1.59 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading python_memcached-1.59-py2.py3-none-any.whl (16 kB)
Collecting sphinxext-rediraffe~=0.2.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinxext_rediraffe-0.2.7-py3-none-any.whl (8.3 kB)
Collecting matplotlib>=3.3.4,~=3.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for matplotlib>=3.3.4,~=3.3 from https://files.pythonhosted.org/packages/e0/8b/b62bc50b01bb2d4af96bc0045c39d60209e2701e172789ceace20a0866b2/matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)
INFO: pip is looking at multiple versions of aiida-wannier90 to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-wannier90>=2.0.0 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading aiida_wannier90-2.0.1-py2.py3-none-any.whl (28 kB)
Requirement already satisfied: aiormq<4,>=3.2.3 in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.3.1)
Requirement already satisfied: yarl in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.9.2)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.2.4)
Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.8.0)
Requirement already satisfied: pyzmq>=17.0 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (25.1.1)
Requirement already satisfied: tornado>=5.0.2 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.3.3)
Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from click-completion~=0.5.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.16.0)
Collecting shellingham (from click-completion~=0.5.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for shellingham from https://files.pythonhosted.org/packages/57/70/0265437683625b2e6491736706d3d679d90e2a26f6bff59f4e46e09872b9/shellingham-1.5.3-py2.py3-none-any.whl.metadata
  Downloading shellingham-1.5.3-py2.py3-none-any.whl.metadata (3.4 kB)
Collecting configobj>=5.0.6 (from click-config-file~=0.6.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)
Collecting sqlparse>=0.2.2 (from django~=2.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 17.2 MB/s eta 0:00:00
Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (68.2.2)
Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.19.0)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (5.1.1)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.7.5)
Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (5.10.0)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.0.39)
Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.0)
Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.1.6)
Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.8.0)
Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (23.1.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.19.3)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.0.11)
Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.10)
Requirement already satisfied: pytray<0.4.0,>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.3.4)
Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.1.0)
INFO: pip is looking at multiple versions of kiwipy[rmq] to determine which version is compatible with other requirements. This could take a while.
Collecting kiwipy[rmq]~=0.7.5 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading kiwipy-0.7.6-py3-none-any.whl (29 kB)
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.0.1)
Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (41.0.4)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.5.0)
Collecting nest-asyncio~=1.4.0 (from plumpy~=0.20.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)
Collecting cftime (from netcdf4->aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Downloading cftime-1.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 120.4 MB/s eta 0:00:00
Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from netcdf4->aiida-yambo>=1.3.0->aiida-yambo-wannier90) (2023.7.22)
Collecting iniconfig (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.9/site-packages (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90) (1.3.0)
Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.9/site-packages (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90) (1.1.3)
Collecting tomli>=1.0.0 (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)
Collecting pint~=0.16.1 (from aiida-pseudo~=0.6.1->aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading Pint-0.16.1-py2.py3-none-any.whl (205 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 205.9/205.9 kB 60.6 MB/s eta 0:00:00
Collecting scipy>=1.1.0 (from ase~=3.18->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 22.7 MB/s eta 0:00:00
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.15.1)
Collecting Werkzeug<2.0,>=0.15 (from flask~=1.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.6/298.6 kB 70.7 MB/s eta 0:00:00
Collecting itsdangerous<2.0,>=0.24 (from flask~=1.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting aniso8601>=0.82 (from flask-restful~=0.3.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 18.3 MB/s eta 0:00:00
Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.8.3)
Collecting contourpy>=1.0.1 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/2b/c0/24c34c41a180f875419b536125799c61e2330b997d77a5a818a3bc3e08cd/contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)
Collecting cycler>=0.10 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/49/50/2e31753c088d364756daa5bed0dab6a5928ebfd6e6d26f975c8b6d6f754a/fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.0/151.0 kB 49.1 MB/s eta 0:00:00
Collecting kiwisolver>=1.0.1 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata
  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)
Collecting pillow>=6.2.0 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/0a/20/a94a0462495de73e248643fb24667270f2e67f44792456ab7207764e80cc/Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata
  Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from importlib_resources->aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90) (3.17.0)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.7.0)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.6)
Requirement already satisfied: ruamel.yaml>=0.15.6 in /opt/conda/lib/python3.9/site-packages (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.17.32)
Collecting monty>=3.0.2 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for monty>=3.0.2 from https://files.pythonhosted.org/packages/e4/f6/48d2daf13a8bc8f636091a1465a037ac5804268cef22d03e2d7ccef6ee90/monty-2023.9.5-py3-none-any.whl.metadata
  Downloading monty-2023.9.5-py3-none-any.whl.metadata (2.9 kB)
Collecting networkx>=2.2 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 111.4 MB/s eta 0:00:00
Collecting palettable>=3.1.1 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading palettable-3.3.3-py2.py3-none-any.whl (332 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 332.3/332.3 kB 77.1 MB/s eta 0:00:00
Collecting sympy (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 95.4 MB/s eta 0:00:00
Collecting pandas (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/bc/7e/a9e11bd272e3135108892b6230a115568f477864276181eada3a35d03237/pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Collecting plotly>=4.5.0 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for plotly>=4.5.0 from https://files.pythonhosted.org/packages/df/79/c80174d711ee26ee5da55a9cc3e248f1ec7a0188b5e4d6bbbbcd09b974b0/plotly-5.17.0-py2.py3-none-any.whl.metadata
  Downloading plotly-5.17.0-py2.py3-none-any.whl.metadata (7.0 kB)
Collecting uncertainties>=3.1.4 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading uncertainties-3.1.7-py2.py3-none-any.whl (98 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.4/98.4 kB 32.4 MB/s eta 0:00:00
Collecting Cython>=0.29.23 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for Cython>=0.29.23 from https://files.pythonhosted.org/packages/18/f1/c3918a7a367a17d5c07d8e576c51ba78fc807f214f748026876352f8b0c2/Cython-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Using cached Cython-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)
Collecting pybtex (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 561.4/561.4 kB 95.5 MB/s eta 0:00:00
Collecting future>=0.15 (from seekpath>=1.9.3,~=1.9->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading future-0.18.3.tar.gz (840 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 840.9/840.9 kB 112.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sphinxcontrib-applehelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/c0/0c/261c0949083c0ac635853528bb0070c89e927841d4e533ba0b5563365c06/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata
  Downloading sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)
Collecting sphinxcontrib-devhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/c0/03/010ac733ec7b7f71c1dc88e7115743ee466560d6d85373b56fb9916e4586/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata
  Downloading sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)
Collecting sphinxcontrib-jsmath (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)
Collecting sphinxcontrib-htmlhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-htmlhelp from https://files.pythonhosted.org/packages/28/7a/958f8e3e6abe8219d0d1f1224886de847ab227b218f4a07b61bc337f64be/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata
  Downloading sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata (2.2 kB)
Collecting sphinxcontrib-serializinghtml (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/95/d6/2e0bda62b2a808070ac922d21a950aa2cb5e4fcfb87e5ff5f86bc43a2201/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata (2.3 kB)
Collecting sphinxcontrib-qthelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/1f/e5/1850f3f118e95581c1e30b57028ac979badee1eb29e70ee72b0241f5a185/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata
  Downloading sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata (2.2 kB)
Collecting snowballstemmer>=1.1 (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.0/93.0 kB 32.6 MB/s eta 0:00:00
Collecting babel>=1.3 (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 124.9 MB/s eta 0:00:00
Collecting alabaster<0.8,>=0.7 (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)
Collecting imagesize (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)
Collecting elementpath<3.0.0,>=2.5.0 (from xmlschema>=1.2.5,~=1.2->aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading elementpath-2.5.3-py3-none-any.whl (181 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.4/181.4 kB 49.1 MB/s eta 0:00:00
Requirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.0.4)
Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.4)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.21)
Collecting tenacity>=6.2.0 (from plotly>=4.5.0->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for tenacity>=6.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata
  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.2.0)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.0.5)
Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.9/site-packages (from ruamel.yaml>=0.15.6->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.7)
INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.
Collecting pandas (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/83/f0/2765daac3c58165460b127df5c0ef7b3a039f3bfe7ea7a51f3d20b01371b/pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/9f/80/5faa1875236ded526a5572bf1f2bdd3c46ec4dcc0e5b49b3b8a889a7b567/pandas-2.1.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.1.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/9e/0d/91a9fd2c202f2b1d97a38ab591890f86480ecbb596cbc56d035f6f23fdcc/pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/9f/cc/cc8135de2a574fd87940b1d41c9c52d226d3ebc9fc8f6e9f18a7b0a81b57/pandas-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
  Downloading pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 126.2 MB/s eta 0:00:00
  Downloading pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 130.7 MB/s eta 0:00:00
  Downloading pandas-2.0.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 121.2 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.
  Downloading pandas-2.0.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 122.9 MB/s eta 0:00:00
  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 128.0 MB/s eta 0:00:00
  Downloading pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 118.5 MB/s eta 0:00:00
  Downloading pandas-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 125.6 MB/s eta 0:00:00
  Downloading pandas-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 127.8 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading pandas-1.5.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 127.5 MB/s eta 0:00:00
  Downloading pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 124.1 MB/s eta 0:00:00
  Downloading pandas-1.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 112.3 MB/s eta 0:00:00
  Downloading pandas-1.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 126.1 MB/s eta 0:00:00
  Downloading pandas-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 119.1 MB/s eta 0:00:00
  Downloading pandas-1.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 120.5 MB/s eta 0:00:00
  Downloading pandas-1.4.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 122.1 MB/s eta 0:00:00
  Downloading pandas-1.3.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.5/11.5 MB 126.2 MB/s eta 0:00:00
Collecting latexcodec>=1.0.4 (from pybtex->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)
INFO: pip is looking at multiple versions of sphinxcontrib-applehelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-applehelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/b1/db/2c9a62f9d7c8abf45fa79d28a9d0c80e16cb42deac58a699cbd952efda1a/sphinxcontrib_applehelp-1.0.6-py3-none-any.whl.metadata
  Downloading sphinxcontrib_applehelp-1.0.6-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/57/57/1cdaff9321329139ffb0616b9907f2ddf46fa9a6a9488a93f049b2325472/sphinxcontrib_applehelp-1.0.5-py3-none-any.whl.metadata
  Downloading sphinxcontrib_applehelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 120.6/120.6 kB 30.8 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-devhelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-devhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/5d/b6/7f58acb86c93e54236ca8b5b79dd3873138397060a74a143b1c1e30ba6bf/sphinxcontrib_devhelp-1.0.4-py3-none-any.whl.metadata
  Downloading sphinxcontrib_devhelp-1.0.4-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/30/68/7e7c2e823a50cc4d0835b962425924fe7006afa2bc7151a79c30b91fcf52/sphinxcontrib_devhelp-1.0.3-py3-none-any.whl.metadata
  Downloading sphinxcontrib_devhelp-1.0.3-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.7/84.7 kB 25.8 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-htmlhelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-htmlhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-htmlhelp from https://files.pythonhosted.org/packages/d0/a1/5b678486ce3f7f3135ac5396db4591e967fc6709f27aa57fe13c97180953/sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl.metadata
  Downloading sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-htmlhelp from https://files.pythonhosted.org/packages/57/41/ad44d14fd5273a7b20905fa4dd8444abf1795f6581666f6272e7d8cabf5a/sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl.metadata
  Downloading sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.8/99.8 kB 35.7 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-qthelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-qthelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/c1/54/d3f8d78634c43be776bbec969cce56cf6a6ba49fc950774179b6cc20176b/sphinxcontrib_qthelp-1.0.5-py3-none-any.whl.metadata
  Downloading sphinxcontrib_qthelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/8d/57/6edeb937dbc2858d980242ffc5913303c19774048b68654e5bee9556e146/sphinxcontrib_qthelp-1.0.4-py3-none-any.whl.metadata
  Downloading sphinxcontrib_qthelp-1.0.4-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.6/90.6 kB 31.2 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-serializinghtml to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-serializinghtml (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/dc/85/ea34b6be0494eff8ae281107bb4a83f6c83066b358f2525a251dc852817c/sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl.metadata (2.3 kB)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/36/c6/0d5b3f258fdb107558163e88607eb6c245d8785fbd707e027f2da7fbc795/sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl.metadata (2.3 kB)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/82/a2/962548d13ceddff95eac7843c9ff37b451c02b69429007b93d6a10a353d3/sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl.metadata (2.3 kB)
  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.0/94.0 kB 37.8 MB/s eta 0:00:00
Collecting mpmath>=0.19 (from sympy->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 97.4 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of disk-objectstore to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-pseudo~=0.6.1 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading aiida_pseudo-0.6.4-py3-none-any.whl (74 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.0/74.0 kB 29.1 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of sphinxcontrib-serializinghtml to determine which version is compatible with other requirements. This could take a while.
  Downloading aiida_pseudo-0.6.3-py3-none-any.whl (73 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.7/73.7 kB 26.3 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of sphinxcontrib-applehelp to determine which version is compatible with other requirements. This could take a while.
INFO: pip is still looking at multiple versions of sphinxcontrib-devhelp to determine which version is compatible with other requirements. This could take a while.
INFO: pip is still looking at multiple versions of sphinxcontrib-htmlhelp to determine which version is compatible with other requirements. This could take a while.
INFO: pip is still looking at multiple versions of sphinxcontrib-qthelp to determine which version is compatible with other requirements. This could take a while.
  Downloading aiida_pseudo-0.6.2-py3-none-any.whl (73 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.2/73.2 kB 17.7 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading aiida_pseudo-0.6.1-py3-none-any.whl (68 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.7/68.7 kB 22.5 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
INFO: pip is still looking at multiple versions of disk-objectstore to determine which version is compatible with other requirements. This could take a while.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
Collecting sqlalchemy-utils~=0.36.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading SQLAlchemy-Utils-0.36.4.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.6/128.6 kB 36.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.3.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.3/128.3 kB 39.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.2.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 43.4 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.1.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.0/128.0 kB 43.9 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.0.tar.gz (127 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.5/127.5 kB 38.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
Collecting alembic~=1.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/a2/8b/46919127496036c8e990b2b236454a0d8655fd46e1df2fd35610a9cbc842/alembic-1.12.0-py3-none-any.whl.metadata
  Downloading alembic-1.12.0-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
INFO: pip is still looking at multiple versions of kiwipy[rmq] to determine which version is compatible with other requirements. This could take a while.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/ab/7d/b572fc6a51bc430b1fa0ef59591db32b14105093324d472eed8ea296d2df/alembic-1.11.3-py3-none-any.whl.metadata
  Downloading alembic-1.11.3-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/34/fe/eebb260c86c71d9ed861aa1434fc50601df657425b18329994af8c0bd789/alembic-1.11.2-py3-none-any.whl.metadata
  Downloading alembic-1.11.2-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/11/00/46a4f66ad54c661350a1cd5daae4b4ab2232486c55635ee12ff12958b03f/alembic-1.11.1-py3-none-any.whl.metadata
  Downloading alembic-1.11.1-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/59/4d/28b13ff3a9c26988f8c32f460cc34ee806ac46038232ee493b9baaaf6164/alembic-1.11.0-py3-none-any.whl.metadata
  Downloading alembic-1.11.0-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.9/212.9 kB 58.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.3/212.3 kB 63.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.2/212.2 kB 59.3 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.1-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.2/212.2 kB 60.3 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.0-py3-none-any.whl (211 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.9/211.9 kB 59.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.5/210.5 kB 59.2 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.3-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.6/210.6 kB 63.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.6/210.6 kB 67.8 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.1-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.4/210.4 kB 62.7 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.0-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.2/210.2 kB 55.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.8/209.8 kB 63.1 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.3/209.3 kB 65.8 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.7/210.7 kB 55.7 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.4/210.4 kB 65.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.7/209.7 kB 65.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.4-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.1/209.1 kB 62.2 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.3-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.7/208.7 kB 61.2 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.2-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.7/208.7 kB 65.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.1-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.4/208.4 kB 62.9 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.0-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.2/208.2 kB 57.8 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 164.7/164.7 kB 51.0 MB/s eta 0:00:00
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError("HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)")': /simple/python-editor/
Collecting python-editor>=0.3 (from alembic~=1.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
Collecting alembic~=1.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading alembic-1.6.4-py2.py3-none-any.whl (164 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 164.7/164.7 kB 48.1 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
ERROR: Exception:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/cli/base_command.py", line 180, in exc_logging_wrapper
    status = run_func(*args)
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/cli/req_command.py", line 248, in wrapper
    return func(self, options, args)
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/commands/install.py", line 377, in run
    requirement_set = resolver.resolve(
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py", line 92, in resolve
    result = self._result = resolver.resolve(
  File "/opt/conda/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py", line 546, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
  File "/opt/conda/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py", line 457, in resolve
    raise ResolutionTooDeep(max_rounds)
pip._vendor.resolvelib.resolvers.ResolutionTooDeep: 200000
</pre>`],warnings:[],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install --pre aiida-yambo-wannier90",is_installable:"False"},"aiida-yascheduler":{code_home:"https://github.com/tilde-lab/yascheduler",documentation_url:"https://github.com/tilde-lab/yascheduler",entry_point_prefix:"yascheduler",pip_url:"yascheduler",plugin_info:"https://raw.githubusercontent.com/tilde-lab/yascheduler/master/setup.json",name:"aiida-yascheduler",package_name:"aiida_yascheduler",hosted_on:"github.com",metadata:{release_date:"2023-07-29",description:"Yet another computing scheduler and cloud orchestration engine",author:"Andrey Sobolev",author_email:"Evgeny Blokhin <eb@tilde.pro>, Sergei Korolev <knopki@duck.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Information Analysis","Topic :: Scientific/Engineering :: Physics","Topic :: Software Development :: Libraries :: Python Modules"],version:"1.2.0"},aiida_version:null,entry_points:{"aiida.schedulers":{yascheduler:"yascheduler.aiida_plugin:YaScheduler"},console_scripts:{yainit:"yascheduler.utils:init",yanodes:"yascheduler.utils:show_nodes",yascheduler:"yascheduler.utils:daemonize",yasetnode:"yascheduler.utils:manage_node",yastatus:"yascheduler.utils:check_status",yasubmit:"yascheduler.utils:submit"}},commits_count:56,development_status:"beta",errors:[`Failed to import package aiida_yascheduler</br><pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
ModuleNotFoundError: No module named 'aiida_yascheduler'
</pre>`],warnings:["AiiDA version not found"],summaryinfo:[{colorclass:"purple",text:"Console scripts",count:6},{colorclass:"orange",text:"Other (Schedulers)",count:1}],pip_install_cmd:"pip install yascheduler",is_installable:"True"},"aiida-z2pack":{code_home:"https://github.com/AntimoMarrazzo/aiida-z2pack",entry_point_prefix:"z2pack",pip_url:"git+https://github.com/AntimoMarrazzo/aiida-z2pack",name:"aiida-z2pack",package_name:"aiida_z2pack",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:18,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/antimomarrazzo/aiida-z2pack/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/AntimoMarrazzo/aiida-z2pack"},"aiida-zeopp":{code_home:"https://github.com/lsmo-epfl/aiida-zeopp",development_status:"stable",entry_point_prefix:"zeopp",pip_url:"aiida-zeopp",plugin_info:"https://raw.github.com/lsmo-epfl/aiida-zeopp/master/setup.json",name:"aiida-zeopp",package_name:"aiida_zeopp",hosted_on:"github.com",metadata:{release_date:"2023-08-26",description:"AiiDA plugin for zeo++",author_email:"Leopold Talirz <leopold.talirz@epfl.ch>, Miriam Pougin <miriam.pougin@epfl.ch>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"zeopp.network":{description:["AiiDA calculation plugin for the zeo++ network binary"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"NetworkParameters",info:"command line parameters for zeo++"},{name:"structure",required:!0,valid_types:"CifData",info:"input structure to be analyzed"},{name:"atomic_radii",required:!1,valid_types:"SinglefileData, NoneType",info:"atomic radii file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"key-value pairs parsed from zeo++ output file(s)."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"block",required:!1,valid_types:"SinglefileData",info:"Blocked pockets fileoutput file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation completed successfully."},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"Not all expected output files were found."},{status:102,message:"Empty block file. This indicates the calculation of blocked pockets did not finish."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_zeopp.calculations.network:NetworkCalculation"}},"aiida.data":{"zeopp.parameters":"aiida_zeopp.data.parameters:NetworkParameters"},"aiida.parsers":{"zeopp.network":"aiida_zeopp.parsers.network:NetworkParser"}},commits_count:4,errors:[],warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install aiida-zeopp",is_installable:"True"}},Fw=[{name:"Calculations",colorclass:"blue",num_entries:54,total_num:132},{name:"Parsers",colorclass:"brown",num_entries:54,total_num:109},{name:"Data",colorclass:"red",num_entries:30,total_num:103},{name:"Workflows",colorclass:"green",num_entries:40,total_num:143},{name:"Console scripts",colorclass:"purple",num_entries:16,total_num:27},{name:"Other",tooltip:"Aenet potentials, Calculations importers, Calculations monitors, ...",colorclass:"orange",num_entries:26,total_num:99}],Uw={planning:["Not yet ready to use. Developers welcome!","status-planning-d9644d.svg"],"pre-alpha":["Not yet ready to use. Developers welcome!","status-planning-d9644d.svg"],alpha:["Adds new functionality, not yet ready for production. Testing welcome!","status-alpha-d6af23.svg"],beta:["Adds new functionality, not yet ready for production. Testing welcome!","status-beta-d6af23.svg"],stable:["Ready for production calculations. Bug reports welcome!","status-stable-4cc61e.svg"],mature:["Ready for production calculations. Bug reports welcome!","status-stable-4cc61e.svg"],inactive:["No longer maintained.","status-inactive-bbbbbb.svg"]},Gw={"aiida.calculations":"CalcJobs and calculation functions","aiida.parsers":"CalcJob parsers","aiida.data":"Data node types","aiida.cmdline.data":"verdi data commands","aiida.groups":"Group types","aiida.workflows":"WorkChains and work functions","aiida.schedulers":"Job scheduler support","aiida.transports":"Data transport protocols","aiida.tests":"Development test modules","aiida.tools.dbexporters":"Support for exporting to external databases","aiida.tools.dbimporters":"Support for importing from external databases",console_scripts:"Console scripts"},fn={plugins:Lw,globalsummary:Fw,status_dict:Uw,entrypointtypes:Gw};var Yu={},r_={exports:{}};(function(e){function t(n){return n&&n.__esModule?n:{default:n}}e.exports=t,e.exports.__esModule=!0,e.exports.default=e.exports})(r_);var Ju=r_.exports,pc={};function k(){return k=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},k.apply(this,arguments)}function _i(e){return e!==null&&typeof e=="object"&&e.constructor===Object}function s_(e){if(!_i(e))return e;const t={};return Object.keys(e).forEach(n=>{t[n]=s_(e[n])}),t}function Wt(e,t,n={clone:!0}){const i=n.clone?k({},e):e;return _i(e)&&_i(t)&&Object.keys(t).forEach(a=>{a!=="__proto__"&&(_i(t[a])&&a in e&&_i(e[a])?i[a]=Wt(e[a],t[a],n):n.clone?i[a]=_i(t[a])?s_(t[a]):t[a]:i[a]=t[a])}),i}function ai(e){let t="https://mui.com/production-error/?code="+e;for(let n=1;n<arguments.length;n+=1)t+="&args[]="+encodeURIComponent(arguments[n]);return"Minified MUI error #"+e+"; visit "+t+" for the full message."}var pe={};/**
 * @license React
 * react-is.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var ep=Symbol.for("react.element"),tp=Symbol.for("react.portal"),Gs=Symbol.for("react.fragment"),$s=Symbol.for("react.strict_mode"),Vs=Symbol.for("react.profiler"),Hs=Symbol.for("react.provider"),Zs=Symbol.for("react.context"),$w=Symbol.for("react.server_context"),Qs=Symbol.for("react.forward_ref"),Ks=Symbol.for("react.suspense"),Xs=Symbol.for("react.suspense_list"),Ys=Symbol.for("react.memo"),Js=Symbol.for("react.lazy"),Vw=Symbol.for("react.offscreen"),l_;l_=Symbol.for("react.module.reference");function Lt(e){if(typeof e=="object"&&e!==null){var t=e.$$typeof;switch(t){case ep:switch(e=e.type,e){case Gs:case Vs:case $s:case Ks:case Xs:return e;default:switch(e=e&&e.$$typeof,e){case $w:case Zs:case Qs:case Js:case Ys:case Hs:return e;default:return t}}case tp:return t}}}pe.ContextConsumer=Zs;pe.ContextProvider=Hs;pe.Element=ep;pe.ForwardRef=Qs;pe.Fragment=Gs;pe.Lazy=Js;pe.Memo=Ys;pe.Portal=tp;pe.Profiler=Vs;pe.StrictMode=$s;pe.Suspense=Ks;pe.SuspenseList=Xs;pe.isAsyncMode=function(){return!1};pe.isConcurrentMode=function(){return!1};pe.isContextConsumer=function(e){return Lt(e)===Zs};pe.isContextProvider=function(e){return Lt(e)===Hs};pe.isElement=function(e){return typeof e=="object"&&e!==null&&e.$$typeof===ep};pe.isForwardRef=function(e){return Lt(e)===Qs};pe.isFragment=function(e){return Lt(e)===Gs};pe.isLazy=function(e){return Lt(e)===Js};pe.isMemo=function(e){return Lt(e)===Ys};pe.isPortal=function(e){return Lt(e)===tp};pe.isProfiler=function(e){return Lt(e)===Vs};pe.isStrictMode=function(e){return Lt(e)===$s};pe.isSuspense=function(e){return Lt(e)===Ks};pe.isSuspenseList=function(e){return Lt(e)===Xs};pe.isValidElementType=function(e){return typeof e=="string"||typeof e=="function"||e===Gs||e===Vs||e===$s||e===Ks||e===Xs||e===Vw||typeof e=="object"&&e!==null&&(e.$$typeof===Js||e.$$typeof===Ys||e.$$typeof===Hs||e.$$typeof===Zs||e.$$typeof===Qs||e.$$typeof===l_||e.getModuleId!==void 0)};pe.typeOf=Lt;function Z(e){if(typeof e!="string")throw new Error(ai(7));return e.charAt(0).toUpperCase()+e.slice(1)}function Sd(...e){return e.reduce((t,n)=>n==null?t:function(...a){t.apply(this,a),n.apply(this,a)},()=>{})}function el(e,t=166){let n;function i(...a){const o=()=>{e.apply(this,a)};clearTimeout(n),n=setTimeout(o,t)}return i.clear=()=>{clearTimeout(n)},i}function Hw(e,t){return()=>null}function Wr(e,t){return v.isValidElement(e)&&t.indexOf(e.type.muiName)!==-1}function yt(e){return e&&e.ownerDocument||document}function pn(e){return yt(e).defaultView||window}function Zw(e,t){return()=>null}function gs(e,t){typeof e=="function"?e(t):e&&(e.current=t)}const Qw=typeof window<"u"?v.useLayoutEffect:v.useEffect,oi=Qw;let lf=0;function Kw(e){const[t,n]=v.useState(e),i=e||t;return v.useEffect(()=>{t==null&&(lf+=1,n(`mui-${lf}`))},[t]),i}const cf=Ur["useId".toString()];function c_(e){if(cf!==void 0){const t=cf();return e??t}return Kw(e)}function Xw(e,t,n,i,a){return null}function Ed({controlled:e,default:t,name:n,state:i="value"}){const{current:a}=v.useRef(e!==void 0),[o,r]=v.useState(t),s=a?e:o,l=v.useCallback(c=>{a||r(c)},[]);return[s,l]}function Ci(e){const t=v.useRef(e);return oi(()=>{t.current=e}),v.useCallback((...n)=>(0,t.current)(...n),[])}function Xe(...e){return v.useMemo(()=>e.every(t=>t==null)?null:t=>{e.forEach(n=>{gs(n,t)})},e)}let tl=!0,Ad=!1,df;const Yw={text:!0,search:!0,url:!0,tel:!0,email:!0,password:!0,number:!0,date:!0,month:!0,week:!0,time:!0,datetime:!0,"datetime-local":!0};function Jw(e){const{type:t,tagName:n}=e;return!!(n==="INPUT"&&Yw[t]&&!e.readOnly||n==="TEXTAREA"&&!e.readOnly||e.isContentEditable)}function ex(e){e.metaKey||e.altKey||e.ctrlKey||(tl=!0)}function mc(){tl=!1}function tx(){this.visibilityState==="hidden"&&Ad&&(tl=!0)}function nx(e){e.addEventListener("keydown",ex,!0),e.addEventListener("mousedown",mc,!0),e.addEventListener("pointerdown",mc,!0),e.addEventListener("touchstart",mc,!0),e.addEventListener("visibilitychange",tx,!0)}function ix(e){const{target:t}=e;try{return t.matches(":focus-visible")}catch{}return tl||Jw(t)}function d_(){const e=v.useCallback(a=>{a!=null&&nx(a.ownerDocument)},[]),t=v.useRef(!1);function n(){return t.current?(Ad=!0,window.clearTimeout(df),df=window.setTimeout(()=>{Ad=!1},100),t.current=!1,!0):!1}function i(a){return ix(a)?(t.current=!0,!0):!1}return{isFocusVisibleRef:t,onFocus:i,onBlur:n,ref:e}}function u_(e){const t=e.documentElement.clientWidth;return Math.abs(window.innerWidth-t)}function p_(e,t){const n=k({},t);return Object.keys(e).forEach(i=>{if(i.toString().match(/^(components|slots)$/))n[i]=k({},e[i],n[i]);else if(i.toString().match(/^(componentsProps|slotProps)$/)){const a=e[i]||{},o=t[i];n[i]={},!o||!Object.keys(o)?n[i]=a:!a||!Object.keys(a)?n[i]=o:(n[i]=k({},o),Object.keys(a).forEach(r=>{n[i][r]=p_(a[r],o[r])}))}else n[i]===void 0&&(n[i]=e[i])}),n}function fe(e,t,n=void 0){const i={};return Object.keys(e).forEach(a=>{i[a]=e[a].reduce((o,r)=>{if(r){const s=t(r);s!==""&&o.push(s),n&&n[r]&&o.push(n[r])}return o},[]).join(" ")}),i}const uf=e=>e,ax=()=>{let e=uf;return{configure(t){e=t},generate(t){return e(t)},reset(){e=uf}}},ox=ax(),np=ox,rx={active:"active",checked:"checked",completed:"completed",disabled:"disabled",error:"error",expanded:"expanded",focused:"focused",focusVisible:"focusVisible",open:"open",readOnly:"readOnly",required:"required",selected:"selected"};function me(e,t,n="Mui"){const i=rx[t];return i?`${n}-${i}`:`${np.generate(e)}-${t}`}function re(e,t,n="Mui"){const i={};return t.forEach(a=>{i[a]=me(e,a,n)}),i}function U(e,t){if(e==null)return{};var n={},i=Object.keys(e),a,o;for(o=0;o<i.length;o++)a=i[o],!(t.indexOf(a)>=0)&&(n[a]=e[a]);return n}function m_(e){var t,n,i="";if(typeof e=="string"||typeof e=="number")i+=e;else if(typeof e=="object")if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=m_(e[t]))&&(i&&(i+=" "),i+=n);else for(t in e)e[t]&&(i&&(i+=" "),i+=t);return i}function V(){for(var e,t,n=0,i="";n<arguments.length;)(e=arguments[n++])&&(t=m_(e))&&(i&&(i+=" "),i+=t);return i}function f_(e){var t=Object.create(null);return function(n){return t[n]===void 0&&(t[n]=e(n)),t[n]}}var sx=/^((children|dangerouslySetInnerHTML|key|ref|autoFocus|defaultValue|defaultChecked|innerHTML|suppressContentEditableWarning|suppressHydrationWarning|valueLink|abbr|accept|acceptCharset|accessKey|action|allow|allowUserMedia|allowPaymentRequest|allowFullScreen|allowTransparency|alt|async|autoComplete|autoPlay|capture|cellPadding|cellSpacing|challenge|charSet|checked|cite|classID|className|cols|colSpan|content|contentEditable|contextMenu|controls|controlsList|coords|crossOrigin|data|dateTime|decoding|default|defer|dir|disabled|disablePictureInPicture|download|draggable|encType|enterKeyHint|form|formAction|formEncType|formMethod|formNoValidate|formTarget|frameBorder|headers|height|hidden|high|href|hrefLang|htmlFor|httpEquiv|id|inputMode|integrity|is|keyParams|keyType|kind|label|lang|list|loading|loop|low|marginHeight|marginWidth|max|maxLength|media|mediaGroup|method|min|minLength|multiple|muted|name|nonce|noValidate|open|optimum|pattern|placeholder|playsInline|poster|preload|profile|radioGroup|readOnly|referrerPolicy|rel|required|reversed|role|rows|rowSpan|sandbox|scope|scoped|scrolling|seamless|selected|shape|size|sizes|slot|span|spellCheck|src|srcDoc|srcLang|srcSet|start|step|style|summary|tabIndex|target|title|translate|type|useMap|value|width|wmode|wrap|about|datatype|inlist|prefix|property|resource|typeof|vocab|autoCapitalize|autoCorrect|autoSave|color|incremental|fallback|inert|itemProp|itemScope|itemType|itemID|itemRef|on|option|results|security|unselectable|accentHeight|accumulate|additive|alignmentBaseline|allowReorder|alphabetic|amplitude|arabicForm|ascent|attributeName|attributeType|autoReverse|azimuth|baseFrequency|baselineShift|baseProfile|bbox|begin|bias|by|calcMode|capHeight|clip|clipPathUnits|clipPath|clipRule|colorInterpolation|colorInterpolationFilters|colorProfile|colorRendering|contentScriptType|contentStyleType|cursor|cx|cy|d|decelerate|descent|diffuseConstant|direction|display|divisor|dominantBaseline|dur|dx|dy|edgeMode|elevation|enableBackground|end|exponent|externalResourcesRequired|fill|fillOpacity|fillRule|filter|filterRes|filterUnits|floodColor|floodOpacity|focusable|fontFamily|fontSize|fontSizeAdjust|fontStretch|fontStyle|fontVariant|fontWeight|format|from|fr|fx|fy|g1|g2|glyphName|glyphOrientationHorizontal|glyphOrientationVertical|glyphRef|gradientTransform|gradientUnits|hanging|horizAdvX|horizOriginX|ideographic|imageRendering|in|in2|intercept|k|k1|k2|k3|k4|kernelMatrix|kernelUnitLength|kerning|keyPoints|keySplines|keyTimes|lengthAdjust|letterSpacing|lightingColor|limitingConeAngle|local|markerEnd|markerMid|markerStart|markerHeight|markerUnits|markerWidth|mask|maskContentUnits|maskUnits|mathematical|mode|numOctaves|offset|opacity|operator|order|orient|orientation|origin|overflow|overlinePosition|overlineThickness|panose1|paintOrder|pathLength|patternContentUnits|patternTransform|patternUnits|pointerEvents|points|pointsAtX|pointsAtY|pointsAtZ|preserveAlpha|preserveAspectRatio|primitiveUnits|r|radius|refX|refY|renderingIntent|repeatCount|repeatDur|requiredExtensions|requiredFeatures|restart|result|rotate|rx|ry|scale|seed|shapeRendering|slope|spacing|specularConstant|specularExponent|speed|spreadMethod|startOffset|stdDeviation|stemh|stemv|stitchTiles|stopColor|stopOpacity|strikethroughPosition|strikethroughThickness|string|stroke|strokeDasharray|strokeDashoffset|strokeLinecap|strokeLinejoin|strokeMiterlimit|strokeOpacity|strokeWidth|surfaceScale|systemLanguage|tableValues|targetX|targetY|textAnchor|textDecoration|textRendering|textLength|to|transform|u1|u2|underlinePosition|underlineThickness|unicode|unicodeBidi|unicodeRange|unitsPerEm|vAlphabetic|vHanging|vIdeographic|vMathematical|values|vectorEffect|version|vertAdvY|vertOriginX|vertOriginY|viewBox|viewTarget|visibility|widths|wordSpacing|writingMode|x|xHeight|x1|x2|xChannelSelector|xlinkActuate|xlinkArcrole|xlinkHref|xlinkRole|xlinkShow|xlinkTitle|xlinkType|xmlBase|xmlns|xmlnsXlink|xmlLang|xmlSpace|y|y1|y2|yChannelSelector|z|zoomAndPan|for|class|autofocus)|(([Dd][Aa][Tt][Aa]|[Aa][Rr][Ii][Aa]|x)-.*))$/,lx=f_(function(e){return sx.test(e)||e.charCodeAt(0)===111&&e.charCodeAt(1)===110&&e.charCodeAt(2)<91});function cx(e){if(e.sheet)return e.sheet;for(var t=0;t<document.styleSheets.length;t++)if(document.styleSheets[t].ownerNode===e)return document.styleSheets[t]}function dx(e){var t=document.createElement("style");return t.setAttribute("data-emotion",e.key),e.nonce!==void 0&&t.setAttribute("nonce",e.nonce),t.appendChild(document.createTextNode("")),t.setAttribute("data-s",""),t}var ux=function(){function e(n){var i=this;this._insertTag=function(a){var o;i.tags.length===0?i.insertionPoint?o=i.insertionPoint.nextSibling:i.prepend?o=i.container.firstChild:o=i.before:o=i.tags[i.tags.length-1].nextSibling,i.container.insertBefore(a,o),i.tags.push(a)},this.isSpeedy=n.speedy===void 0?!0:n.speedy,this.tags=[],this.ctr=0,this.nonce=n.nonce,this.key=n.key,this.container=n.container,this.prepend=n.prepend,this.insertionPoint=n.insertionPoint,this.before=null}var t=e.prototype;return t.hydrate=function(i){i.forEach(this._insertTag)},t.insert=function(i){this.ctr%(this.isSpeedy?65e3:1)===0&&this._insertTag(dx(this));var a=this.tags[this.tags.length-1];if(this.isSpeedy){var o=cx(a);try{o.insertRule(i,o.cssRules.length)}catch{}}else a.appendChild(document.createTextNode(i));this.ctr++},t.flush=function(){this.tags.forEach(function(i){return i.parentNode&&i.parentNode.removeChild(i)}),this.tags=[],this.ctr=0},e}(),tt="-ms-",_s="-moz-",ie="-webkit-",h_="comm",ip="rule",ap="decl",px="@import",y_="@keyframes",mx="@layer",fx=Math.abs,nl=String.fromCharCode,hx=Object.assign;function yx(e,t){return Ze(e,0)^45?(((t<<2^Ze(e,0))<<2^Ze(e,1))<<2^Ze(e,2))<<2^Ze(e,3):0}function g_(e){return e.trim()}function gx(e,t){return(e=t.exec(e))?e[0]:e}function ae(e,t,n){return e.replace(t,n)}function Nd(e,t){return e.indexOf(t)}function Ze(e,t){return e.charCodeAt(t)|0}function zo(e,t,n){return e.slice(t,n)}function nn(e){return e.length}function op(e){return e.length}function vr(e,t){return t.push(e),e}function _x(e,t){return e.map(t).join("")}var il=1,Ta=1,__=0,_t=0,ze=0,Aa="";function al(e,t,n,i,a,o,r){return{value:e,root:t,parent:n,type:i,props:a,children:o,line:il,column:Ta,length:r,return:""}}function Ga(e,t){return hx(al("",null,null,"",null,null,0),e,{length:-e.length},t)}function bx(){return ze}function vx(){return ze=_t>0?Ze(Aa,--_t):0,Ta--,ze===10&&(Ta=1,il--),ze}function kt(){return ze=_t<__?Ze(Aa,_t++):0,Ta++,ze===10&&(Ta=1,il++),ze}function un(){return Ze(Aa,_t)}function jr(){return _t}function Zo(e,t){return zo(Aa,e,t)}function Wo(e){switch(e){case 0:case 9:case 10:case 13:case 32:return 5;case 33:case 43:case 44:case 47:case 62:case 64:case 126:case 59:case 123:case 125:return 4;case 58:return 3;case 34:case 39:case 40:case 91:return 2;case 41:case 93:return 1}return 0}function b_(e){return il=Ta=1,__=nn(Aa=e),_t=0,[]}function v_(e){return Aa="",e}function Mr(e){return g_(Zo(_t-1,Rd(e===91?e+2:e===40?e+1:e)))}function wx(e){for(;(ze=un())&&ze<33;)kt();return Wo(e)>2||Wo(ze)>3?"":" "}function xx(e,t){for(;--t&&kt()&&!(ze<48||ze>102||ze>57&&ze<65||ze>70&&ze<97););return Zo(e,jr()+(t<6&&un()==32&&kt()==32))}function Rd(e){for(;kt();)switch(ze){case e:return _t;case 34:case 39:e!==34&&e!==39&&Rd(ze);break;case 40:e===41&&Rd(e);break;case 92:kt();break}return _t}function Tx(e,t){for(;kt()&&e+ze!==47+10;)if(e+ze===42+42&&un()===47)break;return"/*"+Zo(t,_t-1)+"*"+nl(e===47?e:kt())}function kx(e){for(;!Wo(un());)kt();return Zo(e,_t)}function Cx(e){return v_(Lr("",null,null,null,[""],e=b_(e),0,[0],e))}function Lr(e,t,n,i,a,o,r,s,l){for(var c=0,d=0,h=r,y=0,p=0,f=0,u=1,T=1,g=1,_=0,b="",w=a,C=o,I=i,x=b;T;)switch(f=_,_=kt()){case 40:if(f!=108&&Ze(x,h-1)==58){Nd(x+=ae(Mr(_),"&","&\f"),"&\f")!=-1&&(g=-1);break}case 34:case 39:case 91:x+=Mr(_);break;case 9:case 10:case 13:case 32:x+=wx(f);break;case 92:x+=xx(jr()-1,7);continue;case 47:switch(un()){case 42:case 47:vr(Ix(Tx(kt(),jr()),t,n),l);break;default:x+="/"}break;case 123*u:s[c++]=nn(x)*g;case 125*u:case 59:case 0:switch(_){case 0:case 125:T=0;case 59+d:g==-1&&(x=ae(x,/\f/g,"")),p>0&&nn(x)-h&&vr(p>32?mf(x+";",i,n,h-1):mf(ae(x," ","")+";",i,n,h-2),l);break;case 59:x+=";";default:if(vr(I=pf(x,t,n,c,d,a,s,b,w=[],C=[],h),o),_===123)if(d===0)Lr(x,t,I,I,w,o,h,s,C);else switch(y===99&&Ze(x,3)===110?100:y){case 100:case 108:case 109:case 115:Lr(e,I,I,i&&vr(pf(e,I,I,0,0,a,s,b,a,w=[],h),C),a,C,h,s,i?w:C);break;default:Lr(x,I,I,I,[""],C,0,s,C)}}c=d=p=0,u=g=1,b=x="",h=r;break;case 58:h=1+nn(x),p=f;default:if(u<1){if(_==123)--u;else if(_==125&&u++==0&&vx()==125)continue}switch(x+=nl(_),_*u){case 38:g=d>0?1:(x+="\f",-1);break;case 44:s[c++]=(nn(x)-1)*g,g=1;break;case 64:un()===45&&(x+=Mr(kt())),y=un(),d=h=nn(b=x+=kx(jr())),_++;break;case 45:f===45&&nn(x)==2&&(u=0)}}return o}function pf(e,t,n,i,a,o,r,s,l,c,d){for(var h=a-1,y=a===0?o:[""],p=op(y),f=0,u=0,T=0;f<i;++f)for(var g=0,_=zo(e,h+1,h=fx(u=r[f])),b=e;g<p;++g)(b=g_(u>0?y[g]+" "+_:ae(_,/&\f/g,y[g])))&&(l[T++]=b);return al(e,t,n,a===0?ip:s,l,c,d)}function Ix(e,t,n){return al(e,t,n,h_,nl(bx()),zo(e,2,-2),0)}function mf(e,t,n,i){return al(e,t,n,ap,zo(e,0,i),zo(e,i+1,-1),i)}function fa(e,t){for(var n="",i=op(e),a=0;a<i;a++)n+=t(e[a],a,e,t)||"";return n}function qx(e,t,n,i){switch(e.type){case mx:if(e.children.length)break;case px:case ap:return e.return=e.return||e.value;case h_:return"";case y_:return e.return=e.value+"{"+fa(e.children,i)+"}";case ip:e.value=e.props.join(",")}return nn(n=fa(e.children,i))?e.return=e.value+"{"+n+"}":""}function Dx(e){var t=op(e);return function(n,i,a,o){for(var r="",s=0;s<t;s++)r+=e[s](n,i,a,o)||"";return r}}function Px(e){return function(t){t.root||(t=t.return)&&e(t)}}var Sx=function(t,n,i){for(var a=0,o=0;a=o,o=un(),a===38&&o===12&&(n[i]=1),!Wo(o);)kt();return Zo(t,_t)},Ex=function(t,n){var i=-1,a=44;do switch(Wo(a)){case 0:a===38&&un()===12&&(n[i]=1),t[i]+=Sx(_t-1,n,i);break;case 2:t[i]+=Mr(a);break;case 4:if(a===44){t[++i]=un()===58?"&\f":"",n[i]=t[i].length;break}default:t[i]+=nl(a)}while(a=kt());return t},Ax=function(t,n){return v_(Ex(b_(t),n))},ff=new WeakMap,Nx=function(t){if(!(t.type!=="rule"||!t.parent||t.length<1)){for(var n=t.value,i=t.parent,a=t.column===i.column&&t.line===i.line;i.type!=="rule";)if(i=i.parent,!i)return;if(!(t.props.length===1&&n.charCodeAt(0)!==58&&!ff.get(i))&&!a){ff.set(t,!0);for(var o=[],r=Ax(n,o),s=i.props,l=0,c=0;l<r.length;l++)for(var d=0;d<s.length;d++,c++)t.props[c]=o[l]?r[l].replace(/&\f/g,s[d]):s[d]+" "+r[l]}}},Rx=function(t){if(t.type==="decl"){var n=t.value;n.charCodeAt(0)===108&&n.charCodeAt(2)===98&&(t.return="",t.value="")}};function w_(e,t){switch(yx(e,t)){case 5103:return ie+"print-"+e+e;case 5737:case 4201:case 3177:case 3433:case 1641:case 4457:case 2921:case 5572:case 6356:case 5844:case 3191:case 6645:case 3005:case 6391:case 5879:case 5623:case 6135:case 4599:case 4855:case 4215:case 6389:case 5109:case 5365:case 5621:case 3829:return ie+e+e;case 5349:case 4246:case 4810:case 6968:case 2756:return ie+e+_s+e+tt+e+e;case 6828:case 4268:return ie+e+tt+e+e;case 6165:return ie+e+tt+"flex-"+e+e;case 5187:return ie+e+ae(e,/(\w+).+(:[^]+)/,ie+"box-$1$2"+tt+"flex-$1$2")+e;case 5443:return ie+e+tt+"flex-item-"+ae(e,/flex-|-self/,"")+e;case 4675:return ie+e+tt+"flex-line-pack"+ae(e,/align-content|flex-|-self/,"")+e;case 5548:return ie+e+tt+ae(e,"shrink","negative")+e;case 5292:return ie+e+tt+ae(e,"basis","preferred-size")+e;case 6060:return ie+"box-"+ae(e,"-grow","")+ie+e+tt+ae(e,"grow","positive")+e;case 4554:return ie+ae(e,/([^-])(transform)/g,"$1"+ie+"$2")+e;case 6187:return ae(ae(ae(e,/(zoom-|grab)/,ie+"$1"),/(image-set)/,ie+"$1"),e,"")+e;case 5495:case 3959:return ae(e,/(image-set\([^]*)/,ie+"$1$`$1");case 4968:return ae(ae(e,/(.+:)(flex-)?(.*)/,ie+"box-pack:$3"+tt+"flex-pack:$3"),/s.+-b[^;]+/,"justify")+ie+e+e;case 4095:case 3583:case 4068:case 2532:return ae(e,/(.+)-inline(.+)/,ie+"$1$2")+e;case 8116:case 7059:case 5753:case 5535:case 5445:case 5701:case 4933:case 4677:case 5533:case 5789:case 5021:case 4765:if(nn(e)-1-t>6)switch(Ze(e,t+1)){case 109:if(Ze(e,t+4)!==45)break;case 102:return ae(e,/(.+:)(.+)-([^]+)/,"$1"+ie+"$2-$3$1"+_s+(Ze(e,t+3)==108?"$3":"$2-$3"))+e;case 115:return~Nd(e,"stretch")?w_(ae(e,"stretch","fill-available"),t)+e:e}break;case 4949:if(Ze(e,t+1)!==115)break;case 6444:switch(Ze(e,nn(e)-3-(~Nd(e,"!important")&&10))){case 107:return ae(e,":",":"+ie)+e;case 101:return ae(e,/(.+:)([^;!]+)(;|!.+)?/,"$1"+ie+(Ze(e,14)===45?"inline-":"")+"box$3$1"+ie+"$2$3$1"+tt+"$2box$3")+e}break;case 5936:switch(Ze(e,t+11)){case 114:return ie+e+tt+ae(e,/[svh]\w+-[tblr]{2}/,"tb")+e;case 108:return ie+e+tt+ae(e,/[svh]\w+-[tblr]{2}/,"tb-rl")+e;case 45:return ie+e+tt+ae(e,/[svh]\w+-[tblr]{2}/,"lr")+e}return ie+e+tt+e+e}return e}var Bx=function(t,n,i,a){if(t.length>-1&&!t.return)switch(t.type){case ap:t.return=w_(t.value,t.length);break;case y_:return fa([Ga(t,{value:ae(t.value,"@","@"+ie)})],a);case ip:if(t.length)return _x(t.props,function(o){switch(gx(o,/(::plac\w+|:read-\w+)/)){case":read-only":case":read-write":return fa([Ga(t,{props:[ae(o,/:(read-\w+)/,":"+_s+"$1")]})],a);case"::placeholder":return fa([Ga(t,{props:[ae(o,/:(plac\w+)/,":"+ie+"input-$1")]}),Ga(t,{props:[ae(o,/:(plac\w+)/,":"+_s+"$1")]}),Ga(t,{props:[ae(o,/:(plac\w+)/,tt+"input-$1")]})],a)}return""})}},Ox=[Bx],zx=function(t){var n=t.key;if(n==="css"){var i=document.querySelectorAll("style[data-emotion]:not([data-s])");Array.prototype.forEach.call(i,function(u){var T=u.getAttribute("data-emotion");T.indexOf(" ")!==-1&&(document.head.appendChild(u),u.setAttribute("data-s",""))})}var a=t.stylisPlugins||Ox,o={},r,s=[];r=t.container||document.head,Array.prototype.forEach.call(document.querySelectorAll('style[data-emotion^="'+n+' "]'),function(u){for(var T=u.getAttribute("data-emotion").split(" "),g=1;g<T.length;g++)o[T[g]]=!0;s.push(u)});var l,c=[Nx,Rx];{var d,h=[qx,Px(function(u){d.insert(u)})],y=Dx(c.concat(a,h)),p=function(T){return fa(Cx(T),y)};l=function(T,g,_,b){d=_,p(T?T+"{"+g.styles+"}":g.styles),b&&(f.inserted[g.name]=!0)}}var f={key:n,sheet:new ux({key:n,container:r,nonce:t.nonce,speedy:t.speedy,prepend:t.prepend,insertionPoint:t.insertionPoint}),nonce:t.nonce,inserted:o,registered:{},insert:l};return f.sheet.hydrate(s),f},x_={exports:{}},de={};/** @license React v16.13.1
 * react-is.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Ge=typeof Symbol=="function"&&Symbol.for,rp=Ge?Symbol.for("react.element"):60103,sp=Ge?Symbol.for("react.portal"):60106,ol=Ge?Symbol.for("react.fragment"):60107,rl=Ge?Symbol.for("react.strict_mode"):60108,sl=Ge?Symbol.for("react.profiler"):60114,ll=Ge?Symbol.for("react.provider"):60109,cl=Ge?Symbol.for("react.context"):60110,lp=Ge?Symbol.for("react.async_mode"):60111,dl=Ge?Symbol.for("react.concurrent_mode"):60111,ul=Ge?Symbol.for("react.forward_ref"):60112,pl=Ge?Symbol.for("react.suspense"):60113,Wx=Ge?Symbol.for("react.suspense_list"):60120,ml=Ge?Symbol.for("react.memo"):60115,fl=Ge?Symbol.for("react.lazy"):60116,jx=Ge?Symbol.for("react.block"):60121,Mx=Ge?Symbol.for("react.fundamental"):60117,Lx=Ge?Symbol.for("react.responder"):60118,Fx=Ge?Symbol.for("react.scope"):60119;function Dt(e){if(typeof e=="object"&&e!==null){var t=e.$$typeof;switch(t){case rp:switch(e=e.type,e){case lp:case dl:case ol:case sl:case rl:case pl:return e;default:switch(e=e&&e.$$typeof,e){case cl:case ul:case fl:case ml:case ll:return e;default:return t}}case sp:return t}}}function T_(e){return Dt(e)===dl}de.AsyncMode=lp;de.ConcurrentMode=dl;de.ContextConsumer=cl;de.ContextProvider=ll;de.Element=rp;de.ForwardRef=ul;de.Fragment=ol;de.Lazy=fl;de.Memo=ml;de.Portal=sp;de.Profiler=sl;de.StrictMode=rl;de.Suspense=pl;de.isAsyncMode=function(e){return T_(e)||Dt(e)===lp};de.isConcurrentMode=T_;de.isContextConsumer=function(e){return Dt(e)===cl};de.isContextProvider=function(e){return Dt(e)===ll};de.isElement=function(e){return typeof e=="object"&&e!==null&&e.$$typeof===rp};de.isForwardRef=function(e){return Dt(e)===ul};de.isFragment=function(e){return Dt(e)===ol};de.isLazy=function(e){return Dt(e)===fl};de.isMemo=function(e){return Dt(e)===ml};de.isPortal=function(e){return Dt(e)===sp};de.isProfiler=function(e){return Dt(e)===sl};de.isStrictMode=function(e){return Dt(e)===rl};de.isSuspense=function(e){return Dt(e)===pl};de.isValidElementType=function(e){return typeof e=="string"||typeof e=="function"||e===ol||e===dl||e===sl||e===rl||e===pl||e===Wx||typeof e=="object"&&e!==null&&(e.$$typeof===fl||e.$$typeof===ml||e.$$typeof===ll||e.$$typeof===cl||e.$$typeof===ul||e.$$typeof===Mx||e.$$typeof===Lx||e.$$typeof===Fx||e.$$typeof===jx)};de.typeOf=Dt;x_.exports=de;var Ux=x_.exports,k_=Ux,Gx={$$typeof:!0,render:!0,defaultProps:!0,displayName:!0,propTypes:!0},$x={$$typeof:!0,compare:!0,defaultProps:!0,displayName:!0,propTypes:!0,type:!0},C_={};C_[k_.ForwardRef]=Gx;C_[k_.Memo]=$x;var Vx=!0;function Hx(e,t,n){var i="";return n.split(" ").forEach(function(a){e[a]!==void 0?t.push(e[a]+";"):i+=a+" "}),i}var I_=function(t,n,i){var a=t.key+"-"+n.name;(i===!1||Vx===!1)&&t.registered[a]===void 0&&(t.registered[a]=n.styles)},q_=function(t,n,i){I_(t,n,i);var a=t.key+"-"+n.name;if(t.inserted[n.name]===void 0){var o=n;do t.insert(n===o?"."+a:"",o,t.sheet,!0),o=o.next;while(o!==void 0)}};function Zx(e){for(var t=0,n,i=0,a=e.length;a>=4;++i,a-=4)n=e.charCodeAt(i)&255|(e.charCodeAt(++i)&255)<<8|(e.charCodeAt(++i)&255)<<16|(e.charCodeAt(++i)&255)<<24,n=(n&65535)*1540483477+((n>>>16)*59797<<16),n^=n>>>24,t=(n&65535)*1540483477+((n>>>16)*59797<<16)^(t&65535)*1540483477+((t>>>16)*59797<<16);switch(a){case 3:t^=(e.charCodeAt(i+2)&255)<<16;case 2:t^=(e.charCodeAt(i+1)&255)<<8;case 1:t^=e.charCodeAt(i)&255,t=(t&65535)*1540483477+((t>>>16)*59797<<16)}return t^=t>>>13,t=(t&65535)*1540483477+((t>>>16)*59797<<16),((t^t>>>15)>>>0).toString(36)}var Qx={animationIterationCount:1,aspectRatio:1,borderImageOutset:1,borderImageSlice:1,borderImageWidth:1,boxFlex:1,boxFlexGroup:1,boxOrdinalGroup:1,columnCount:1,columns:1,flex:1,flexGrow:1,flexPositive:1,flexShrink:1,flexNegative:1,flexOrder:1,gridRow:1,gridRowEnd:1,gridRowSpan:1,gridRowStart:1,gridColumn:1,gridColumnEnd:1,gridColumnSpan:1,gridColumnStart:1,msGridRow:1,msGridRowSpan:1,msGridColumn:1,msGridColumnSpan:1,fontWeight:1,lineHeight:1,opacity:1,order:1,orphans:1,tabSize:1,widows:1,zIndex:1,zoom:1,WebkitLineClamp:1,fillOpacity:1,floodOpacity:1,stopOpacity:1,strokeDasharray:1,strokeDashoffset:1,strokeMiterlimit:1,strokeOpacity:1,strokeWidth:1},Kx=/[A-Z]|^ms/g,Xx=/_EMO_([^_]+?)_([^]*?)_EMO_/g,D_=function(t){return t.charCodeAt(1)===45},hf=function(t){return t!=null&&typeof t!="boolean"},fc=f_(function(e){return D_(e)?e:e.replace(Kx,"-$&").toLowerCase()}),yf=function(t,n){switch(t){case"animation":case"animationName":if(typeof n=="string")return n.replace(Xx,function(i,a,o){return an={name:a,styles:o,next:an},a})}return Qx[t]!==1&&!D_(t)&&typeof n=="number"&&n!==0?n+"px":n};function jo(e,t,n){if(n==null)return"";if(n.__emotion_styles!==void 0)return n;switch(typeof n){case"boolean":return"";case"object":{if(n.anim===1)return an={name:n.name,styles:n.styles,next:an},n.name;if(n.styles!==void 0){var i=n.next;if(i!==void 0)for(;i!==void 0;)an={name:i.name,styles:i.styles,next:an},i=i.next;var a=n.styles+";";return a}return Yx(e,t,n)}case"function":{if(e!==void 0){var o=an,r=n(e);return an=o,jo(e,t,r)}break}}if(t==null)return n;var s=t[n];return s!==void 0?s:n}function Yx(e,t,n){var i="";if(Array.isArray(n))for(var a=0;a<n.length;a++)i+=jo(e,t,n[a])+";";else for(var o in n){var r=n[o];if(typeof r!="object")t!=null&&t[r]!==void 0?i+=o+"{"+t[r]+"}":hf(r)&&(i+=fc(o)+":"+yf(o,r)+";");else if(Array.isArray(r)&&typeof r[0]=="string"&&(t==null||t[r[0]]===void 0))for(var s=0;s<r.length;s++)hf(r[s])&&(i+=fc(o)+":"+yf(o,r[s])+";");else{var l=jo(e,t,r);switch(o){case"animation":case"animationName":{i+=fc(o)+":"+l+";";break}default:i+=o+"{"+l+"}"}}}return i}var gf=/label:\s*([^\s;\n{]+)\s*(;|$)/g,an,cp=function(t,n,i){if(t.length===1&&typeof t[0]=="object"&&t[0]!==null&&t[0].styles!==void 0)return t[0];var a=!0,o="";an=void 0;var r=t[0];r==null||r.raw===void 0?(a=!1,o+=jo(i,n,r)):o+=r[0];for(var s=1;s<t.length;s++)o+=jo(i,n,t[s]),a&&(o+=r[s]);gf.lastIndex=0;for(var l="",c;(c=gf.exec(o))!==null;)l+="-"+c[1];var d=Zx(o)+l;return{name:d,styles:o,next:an}},Jx=function(t){return t()},P_=Ur["useInsertionEffect"]?Ur["useInsertionEffect"]:!1,e2=P_||Jx,_f=P_||v.useLayoutEffect,S_=v.createContext(typeof HTMLElement<"u"?zx({key:"css"}):null);S_.Provider;var E_=function(t){return v.forwardRef(function(n,i){var a=v.useContext(S_);return t(n,a,i)})},dp=v.createContext({}),t2=E_(function(e,t){var n=e.styles,i=cp([n],void 0,v.useContext(dp)),a=v.useRef();return _f(function(){var o=t.key+"-global",r=new t.sheet.constructor({key:o,nonce:t.sheet.nonce,container:t.sheet.container,speedy:t.sheet.isSpeedy}),s=!1,l=document.querySelector('style[data-emotion="'+o+" "+i.name+'"]');return t.sheet.tags.length&&(r.before=t.sheet.tags[0]),l!==null&&(s=!0,l.setAttribute("data-emotion",o),r.hydrate([l])),a.current=[r,s],function(){r.flush()}},[t]),_f(function(){var o=a.current,r=o[0],s=o[1];if(s){o[1]=!1;return}if(i.next!==void 0&&q_(t,i.next,!0),r.tags.length){var l=r.tags[r.tags.length-1].nextElementSibling;r.before=l,r.flush()}t.insert("",i,r,!1)},[t,i.name]),null});function n2(){for(var e=arguments.length,t=new Array(e),n=0;n<e;n++)t[n]=arguments[n];return cp(t)}var up=function(){var t=n2.apply(void 0,arguments),n="animation-"+t.name;return{name:n,styles:"@keyframes "+n+"{"+t.styles+"}",anim:1,toString:function(){return"_EMO_"+this.name+"_"+this.styles+"_EMO_"}}},i2=lx,a2=function(t){return t!=="theme"},bf=function(t){return typeof t=="string"&&t.charCodeAt(0)>96?i2:a2},vf=function(t,n,i){var a;if(n){var o=n.shouldForwardProp;a=t.__emotion_forwardProp&&o?function(r){return t.__emotion_forwardProp(r)&&o(r)}:o}return typeof a!="function"&&i&&(a=t.__emotion_forwardProp),a},o2=function(t){var n=t.cache,i=t.serialized,a=t.isStringTag;return I_(n,i,a),e2(function(){return q_(n,i,a)}),null},r2=function e(t,n){var i=t.__emotion_real===t,a=i&&t.__emotion_base||t,o,r;n!==void 0&&(o=n.label,r=n.target);var s=vf(t,n,i),l=s||bf(a),c=!l("as");return function(){var d=arguments,h=i&&t.__emotion_styles!==void 0?t.__emotion_styles.slice(0):[];if(o!==void 0&&h.push("label:"+o+";"),d[0]==null||d[0].raw===void 0)h.push.apply(h,d);else{h.push(d[0][0]);for(var y=d.length,p=1;p<y;p++)h.push(d[p],d[0][p])}var f=E_(function(u,T,g){var _=c&&u.as||a,b="",w=[],C=u;if(u.theme==null){C={};for(var I in u)C[I]=u[I];C.theme=v.useContext(dp)}typeof u.className=="string"?b=Hx(T.registered,w,u.className):u.className!=null&&(b=u.className+" ");var x=cp(h.concat(w),T.registered,C);b+=T.key+"-"+x.name,r!==void 0&&(b+=" "+r);var q=c&&s===void 0?bf(_):l,S={};for(var P in u)c&&P==="as"||q(P)&&(S[P]=u[P]);return S.className=b,S.ref=g,v.createElement(v.Fragment,null,v.createElement(o2,{cache:T,serialized:x,isStringTag:typeof _=="string"}),v.createElement(_,S))});return f.displayName=o!==void 0?o:"Styled("+(typeof a=="string"?a:a.displayName||a.name||"Component")+")",f.defaultProps=t.defaultProps,f.__emotion_real=f,f.__emotion_base=a,f.__emotion_styles=h,f.__emotion_forwardProp=s,Object.defineProperty(f,"toString",{value:function(){return"."+r}}),f.withComponent=function(u,T){return e(u,k({},n,T,{shouldForwardProp:vf(f,T,!0)})).apply(void 0,h)},f}},s2=["a","abbr","address","area","article","aside","audio","b","base","bdi","bdo","big","blockquote","body","br","button","canvas","caption","cite","code","col","colgroup","data","datalist","dd","del","details","dfn","dialog","div","dl","dt","em","embed","fieldset","figcaption","figure","footer","form","h1","h2","h3","h4","h5","h6","head","header","hgroup","hr","html","i","iframe","img","input","ins","kbd","keygen","label","legend","li","link","main","map","mark","marquee","menu","menuitem","meta","meter","nav","noscript","object","ol","optgroup","option","output","p","param","picture","pre","progress","q","rp","rt","ruby","s","samp","script","section","select","small","source","span","strong","style","sub","summary","sup","table","tbody","td","textarea","tfoot","th","thead","time","title","tr","track","u","ul","var","video","wbr","circle","clipPath","defs","ellipse","foreignObject","g","image","line","linearGradient","mask","path","pattern","polygon","polyline","radialGradient","rect","stop","svg","text","tspan"],Bd=r2.bind();s2.forEach(function(e){Bd[e]=Bd(e)});function l2(e){return e==null||Object.keys(e).length===0}function c2(e){const{styles:t,defaultTheme:n={}}=e,i=typeof t=="function"?a=>t(l2(a)?n:a):t;return m.jsx(t2,{styles:i})}/**
 * @mui/styled-engine v5.14.10
 *
 * @license MIT
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */function A_(e,t){return Bd(e,t)}const d2=(e,t)=>{Array.isArray(e.__emotion_styles)&&(e.__emotion_styles=t(e.__emotion_styles))},u2=["values","unit","step"],p2=e=>{const t=Object.keys(e).map(n=>({key:n,val:e[n]}))||[];return t.sort((n,i)=>n.val-i.val),t.reduce((n,i)=>k({},n,{[i.key]:i.val}),{})};function m2(e){const{values:t={xs:0,sm:600,md:900,lg:1200,xl:1536},unit:n="px",step:i=5}=e,a=U(e,u2),o=p2(t),r=Object.keys(o);function s(y){return`@media (min-width:${typeof t[y]=="number"?t[y]:y}${n})`}function l(y){return`@media (max-width:${(typeof t[y]=="number"?t[y]:y)-i/100}${n})`}function c(y,p){const f=r.indexOf(p);return`@media (min-width:${typeof t[y]=="number"?t[y]:y}${n}) and (max-width:${(f!==-1&&typeof t[r[f]]=="number"?t[r[f]]:p)-i/100}${n})`}function d(y){return r.indexOf(y)+1<r.length?c(y,r[r.indexOf(y)+1]):s(y)}function h(y){const p=r.indexOf(y);return p===0?s(r[1]):p===r.length-1?l(r[p]):c(y,r[r.indexOf(y)+1]).replace("@media","@media not all and")}return k({keys:r,values:o,up:s,down:l,between:c,only:d,not:h,unit:n},a)}const f2={borderRadius:4},h2=f2;function fo(e,t){return t?Wt(e,t,{clone:!1}):e}const pp={xs:0,sm:600,md:900,lg:1200,xl:1536},wf={keys:["xs","sm","md","lg","xl"],up:e=>`@media (min-width:${pp[e]}px)`};function Pn(e,t,n){const i=e.theme||{};if(Array.isArray(t)){const o=i.breakpoints||wf;return t.reduce((r,s,l)=>(r[o.up(o.keys[l])]=n(t[l]),r),{})}if(typeof t=="object"){const o=i.breakpoints||wf;return Object.keys(t).reduce((r,s)=>{if(Object.keys(o.values||pp).indexOf(s)!==-1){const l=o.up(s);r[l]=n(t[s],s)}else{const l=s;r[l]=t[l]}return r},{})}return n(t)}function y2(e={}){var t;return((t=e.keys)==null?void 0:t.reduce((i,a)=>{const o=e.up(a);return i[o]={},i},{}))||{}}function g2(e,t){return e.reduce((n,i)=>{const a=n[i];return(!a||Object.keys(a).length===0)&&delete n[i],n},t)}function hl(e,t,n=!0){if(!t||typeof t!="string")return null;if(e&&e.vars&&n){const i=`vars.${t}`.split(".").reduce((a,o)=>a&&a[o]?a[o]:null,e);if(i!=null)return i}return t.split(".").reduce((i,a)=>i&&i[a]!=null?i[a]:null,e)}function bs(e,t,n,i=n){let a;return typeof e=="function"?a=e(n):Array.isArray(e)?a=e[n]||i:a=hl(e,n)||i,t&&(a=t(a,i,e)),a}function se(e){const{prop:t,cssProperty:n=e.prop,themeKey:i,transform:a}=e,o=r=>{if(r[t]==null)return null;const s=r[t],l=r.theme,c=hl(l,i)||{};return Pn(r,s,h=>{let y=bs(c,a,h);return h===y&&typeof h=="string"&&(y=bs(c,a,`${t}${h==="default"?"":Z(h)}`,h)),n===!1?y:{[n]:y}})};return o.propTypes={},o.filterProps=[t],o}function _2(e){const t={};return n=>(t[n]===void 0&&(t[n]=e(n)),t[n])}const b2={m:"margin",p:"padding"},v2={t:"Top",r:"Right",b:"Bottom",l:"Left",x:["Left","Right"],y:["Top","Bottom"]},xf={marginX:"mx",marginY:"my",paddingX:"px",paddingY:"py"},w2=_2(e=>{if(e.length>2)if(xf[e])e=xf[e];else return[e];const[t,n]=e.split(""),i=b2[t],a=v2[n]||"";return Array.isArray(a)?a.map(o=>i+o):[i+a]}),mp=["m","mt","mr","mb","ml","mx","my","margin","marginTop","marginRight","marginBottom","marginLeft","marginX","marginY","marginInline","marginInlineStart","marginInlineEnd","marginBlock","marginBlockStart","marginBlockEnd"],fp=["p","pt","pr","pb","pl","px","py","padding","paddingTop","paddingRight","paddingBottom","paddingLeft","paddingX","paddingY","paddingInline","paddingInlineStart","paddingInlineEnd","paddingBlock","paddingBlockStart","paddingBlockEnd"];[...mp,...fp];function Qo(e,t,n,i){var a;const o=(a=hl(e,t,!1))!=null?a:n;return typeof o=="number"?r=>typeof r=="string"?r:o*r:Array.isArray(o)?r=>typeof r=="string"?r:o[r]:typeof o=="function"?o:()=>{}}function N_(e){return Qo(e,"spacing",8)}function Ko(e,t){if(typeof t=="string"||t==null)return t;const n=Math.abs(t),i=e(n);return t>=0?i:typeof i=="number"?-i:`-${i}`}function x2(e,t){return n=>e.reduce((i,a)=>(i[a]=Ko(t,n),i),{})}function T2(e,t,n,i){if(t.indexOf(n)===-1)return null;const a=w2(n),o=x2(a,i),r=e[n];return Pn(e,r,o)}function R_(e,t){const n=N_(e.theme);return Object.keys(e).map(i=>T2(e,t,i,n)).reduce(fo,{})}function Ee(e){return R_(e,mp)}Ee.propTypes={};Ee.filterProps=mp;function Ae(e){return R_(e,fp)}Ae.propTypes={};Ae.filterProps=fp;function k2(e=8){if(e.mui)return e;const t=N_({spacing:e}),n=(...i)=>(i.length===0?[1]:i).map(o=>{const r=t(o);return typeof r=="number"?`${r}px`:r}).join(" ");return n.mui=!0,n}function yl(...e){const t=e.reduce((i,a)=>(a.filterProps.forEach(o=>{i[o]=a}),i),{}),n=i=>Object.keys(i).reduce((a,o)=>t[o]?fo(a,t[o](i)):a,{});return n.propTypes={},n.filterProps=e.reduce((i,a)=>i.concat(a.filterProps),[]),n}function rn(e){return typeof e!="number"?e:`${e}px solid`}const C2=se({prop:"border",themeKey:"borders",transform:rn}),I2=se({prop:"borderTop",themeKey:"borders",transform:rn}),q2=se({prop:"borderRight",themeKey:"borders",transform:rn}),D2=se({prop:"borderBottom",themeKey:"borders",transform:rn}),P2=se({prop:"borderLeft",themeKey:"borders",transform:rn}),S2=se({prop:"borderColor",themeKey:"palette"}),E2=se({prop:"borderTopColor",themeKey:"palette"}),A2=se({prop:"borderRightColor",themeKey:"palette"}),N2=se({prop:"borderBottomColor",themeKey:"palette"}),R2=se({prop:"borderLeftColor",themeKey:"palette"}),gl=e=>{if(e.borderRadius!==void 0&&e.borderRadius!==null){const t=Qo(e.theme,"shape.borderRadius",4),n=i=>({borderRadius:Ko(t,i)});return Pn(e,e.borderRadius,n)}return null};gl.propTypes={};gl.filterProps=["borderRadius"];yl(C2,I2,q2,D2,P2,S2,E2,A2,N2,R2,gl);const _l=e=>{if(e.gap!==void 0&&e.gap!==null){const t=Qo(e.theme,"spacing",8),n=i=>({gap:Ko(t,i)});return Pn(e,e.gap,n)}return null};_l.propTypes={};_l.filterProps=["gap"];const bl=e=>{if(e.columnGap!==void 0&&e.columnGap!==null){const t=Qo(e.theme,"spacing",8),n=i=>({columnGap:Ko(t,i)});return Pn(e,e.columnGap,n)}return null};bl.propTypes={};bl.filterProps=["columnGap"];const vl=e=>{if(e.rowGap!==void 0&&e.rowGap!==null){const t=Qo(e.theme,"spacing",8),n=i=>({rowGap:Ko(t,i)});return Pn(e,e.rowGap,n)}return null};vl.propTypes={};vl.filterProps=["rowGap"];const B2=se({prop:"gridColumn"}),O2=se({prop:"gridRow"}),z2=se({prop:"gridAutoFlow"}),W2=se({prop:"gridAutoColumns"}),j2=se({prop:"gridAutoRows"}),M2=se({prop:"gridTemplateColumns"}),L2=se({prop:"gridTemplateRows"}),F2=se({prop:"gridTemplateAreas"}),U2=se({prop:"gridArea"});yl(_l,bl,vl,B2,O2,z2,W2,j2,M2,L2,F2,U2);function ha(e,t){return t==="grey"?t:e}const G2=se({prop:"color",themeKey:"palette",transform:ha}),$2=se({prop:"bgcolor",cssProperty:"backgroundColor",themeKey:"palette",transform:ha}),V2=se({prop:"backgroundColor",themeKey:"palette",transform:ha});yl(G2,$2,V2);function wt(e){return e<=1&&e!==0?`${e*100}%`:e}const H2=se({prop:"width",transform:wt}),hp=e=>{if(e.maxWidth!==void 0&&e.maxWidth!==null){const t=n=>{var i,a;const o=((i=e.theme)==null||(i=i.breakpoints)==null||(i=i.values)==null?void 0:i[n])||pp[n];return o?((a=e.theme)==null||(a=a.breakpoints)==null?void 0:a.unit)!=="px"?{maxWidth:`${o}${e.theme.breakpoints.unit}`}:{maxWidth:o}:{maxWidth:wt(n)}};return Pn(e,e.maxWidth,t)}return null};hp.filterProps=["maxWidth"];const Z2=se({prop:"minWidth",transform:wt}),Q2=se({prop:"height",transform:wt}),K2=se({prop:"maxHeight",transform:wt}),X2=se({prop:"minHeight",transform:wt});se({prop:"size",cssProperty:"width",transform:wt});se({prop:"size",cssProperty:"height",transform:wt});const Y2=se({prop:"boxSizing"});yl(H2,hp,Z2,Q2,K2,X2,Y2);const J2={border:{themeKey:"borders",transform:rn},borderTop:{themeKey:"borders",transform:rn},borderRight:{themeKey:"borders",transform:rn},borderBottom:{themeKey:"borders",transform:rn},borderLeft:{themeKey:"borders",transform:rn},borderColor:{themeKey:"palette"},borderTopColor:{themeKey:"palette"},borderRightColor:{themeKey:"palette"},borderBottomColor:{themeKey:"palette"},borderLeftColor:{themeKey:"palette"},borderRadius:{themeKey:"shape.borderRadius",style:gl},color:{themeKey:"palette",transform:ha},bgcolor:{themeKey:"palette",cssProperty:"backgroundColor",transform:ha},backgroundColor:{themeKey:"palette",transform:ha},p:{style:Ae},pt:{style:Ae},pr:{style:Ae},pb:{style:Ae},pl:{style:Ae},px:{style:Ae},py:{style:Ae},padding:{style:Ae},paddingTop:{style:Ae},paddingRight:{style:Ae},paddingBottom:{style:Ae},paddingLeft:{style:Ae},paddingX:{style:Ae},paddingY:{style:Ae},paddingInline:{style:Ae},paddingInlineStart:{style:Ae},paddingInlineEnd:{style:Ae},paddingBlock:{style:Ae},paddingBlockStart:{style:Ae},paddingBlockEnd:{style:Ae},m:{style:Ee},mt:{style:Ee},mr:{style:Ee},mb:{style:Ee},ml:{style:Ee},mx:{style:Ee},my:{style:Ee},margin:{style:Ee},marginTop:{style:Ee},marginRight:{style:Ee},marginBottom:{style:Ee},marginLeft:{style:Ee},marginX:{style:Ee},marginY:{style:Ee},marginInline:{style:Ee},marginInlineStart:{style:Ee},marginInlineEnd:{style:Ee},marginBlock:{style:Ee},marginBlockStart:{style:Ee},marginBlockEnd:{style:Ee},displayPrint:{cssProperty:!1,transform:e=>({"@media print":{display:e}})},display:{},overflow:{},textOverflow:{},visibility:{},whiteSpace:{},flexBasis:{},flexDirection:{},flexWrap:{},justifyContent:{},alignItems:{},alignContent:{},order:{},flex:{},flexGrow:{},flexShrink:{},alignSelf:{},justifyItems:{},justifySelf:{},gap:{style:_l},rowGap:{style:vl},columnGap:{style:bl},gridColumn:{},gridRow:{},gridAutoFlow:{},gridAutoColumns:{},gridAutoRows:{},gridTemplateColumns:{},gridTemplateRows:{},gridTemplateAreas:{},gridArea:{},position:{},zIndex:{themeKey:"zIndex"},top:{},right:{},bottom:{},left:{},boxShadow:{themeKey:"shadows"},width:{transform:wt},maxWidth:{style:hp},minWidth:{transform:wt},height:{transform:wt},maxHeight:{transform:wt},minHeight:{transform:wt},boxSizing:{},fontFamily:{themeKey:"typography"},fontSize:{themeKey:"typography"},fontStyle:{themeKey:"typography"},fontWeight:{themeKey:"typography"},letterSpacing:{},textTransform:{},lineHeight:{},textAlign:{},typography:{cssProperty:!1,themeKey:"typography"}},wl=J2;function e3(...e){const t=e.reduce((i,a)=>i.concat(Object.keys(a)),[]),n=new Set(t);return e.every(i=>n.size===Object.keys(i).length)}function t3(e,t){return typeof e=="function"?e(t):e}function n3(){function e(n,i,a,o){const r={[n]:i,theme:a},s=o[n];if(!s)return{[n]:i};const{cssProperty:l=n,themeKey:c,transform:d,style:h}=s;if(i==null)return null;if(c==="typography"&&i==="inherit")return{[n]:i};const y=hl(a,c)||{};return h?h(r):Pn(r,i,f=>{let u=bs(y,d,f);return f===u&&typeof f=="string"&&(u=bs(y,d,`${n}${f==="default"?"":Z(f)}`,f)),l===!1?u:{[l]:u}})}function t(n){var i;const{sx:a,theme:o={}}=n||{};if(!a)return null;const r=(i=o.unstable_sxConfig)!=null?i:wl;function s(l){let c=l;if(typeof l=="function")c=l(o);else if(typeof l!="object")return l;if(!c)return null;const d=y2(o.breakpoints),h=Object.keys(d);let y=d;return Object.keys(c).forEach(p=>{const f=t3(c[p],o);if(f!=null)if(typeof f=="object")if(r[p])y=fo(y,e(p,f,o,r));else{const u=Pn({theme:o},f,T=>({[p]:T}));e3(u,f)?y[p]=t({sx:f,theme:o}):y=fo(y,u)}else y=fo(y,e(p,f,o,r))}),g2(h,y)}return Array.isArray(a)?a.map(s):s(a)}return t}const B_=n3();B_.filterProps=["sx"];const xl=B_,i3=["breakpoints","palette","spacing","shape"];function yp(e={},...t){const{breakpoints:n={},palette:i={},spacing:a,shape:o={}}=e,r=U(e,i3),s=m2(n),l=k2(a);let c=Wt({breakpoints:s,direction:"ltr",components:{},palette:k({mode:"light"},i),spacing:l,shape:k({},h2,o)},r);return c=t.reduce((d,h)=>Wt(d,h),c),c.unstable_sxConfig=k({},wl,r==null?void 0:r.unstable_sxConfig),c.unstable_sx=function(h){return xl({sx:h,theme:this})},c}function a3(e){return Object.keys(e).length===0}function o3(e=null){const t=v.useContext(dp);return!t||a3(t)?e:t}const r3=yp();function Tl(e=r3){return o3(e)}function s3({styles:e,themeId:t,defaultTheme:n={}}){const i=Tl(n),a=typeof e=="function"?e(t&&i[t]||i):e;return m.jsx(c2,{styles:a})}const l3=["sx"],c3=e=>{var t,n;const i={systemProps:{},otherProps:{}},a=(t=e==null||(n=e.theme)==null?void 0:n.unstable_sxConfig)!=null?t:wl;return Object.keys(e).forEach(o=>{a[o]?i.systemProps[o]=e[o]:i.otherProps[o]=e[o]}),i};function O_(e){const{sx:t}=e,n=U(e,l3),{systemProps:i,otherProps:a}=c3(n);let o;return Array.isArray(t)?o=[i,...t]:typeof t=="function"?o=(...r)=>{const s=t(...r);return _i(s)?k({},i,s):i}:o=k({},i,t),k({},a,{sx:o})}const d3=["className","component"];function u3(e={}){const{themeId:t,defaultTheme:n,defaultClassName:i="MuiBox-root",generateClassName:a}=e,o=A_("div",{shouldForwardProp:s=>s!=="theme"&&s!=="sx"&&s!=="as"})(xl);return v.forwardRef(function(l,c){const d=Tl(n),h=O_(l),{className:y,component:p="div"}=h,f=U(h,d3);return m.jsx(o,k({as:p,ref:c,className:V(y,a?a(i):i),theme:t&&d[t]||d},f))})}const p3=["variant"];function Tf(e){return e.length===0}function z_(e){const{variant:t}=e,n=U(e,p3);let i=t||"";return Object.keys(n).sort().forEach(a=>{a==="color"?i+=Tf(i)?e[a]:Z(e[a]):i+=`${Tf(i)?a:Z(a)}${Z(e[a].toString())}`}),i}const m3=["name","slot","skipVariantsResolver","skipSx","overridesResolver"];function f3(e){return Object.keys(e).length===0}function h3(e){return typeof e=="string"&&e.charCodeAt(0)>96}const y3=(e,t)=>t.components&&t.components[e]&&t.components[e].styleOverrides?t.components[e].styleOverrides:null,g3=(e,t)=>{let n=[];t&&t.components&&t.components[e]&&t.components[e].variants&&(n=t.components[e].variants);const i={};return n.forEach(a=>{const o=z_(a.props);i[o]=a.style}),i},_3=(e,t,n,i)=>{var a;const{ownerState:o={}}=e,r=[],s=n==null||(a=n.components)==null||(a=a[i])==null?void 0:a.variants;return s&&s.forEach(l=>{let c=!0;Object.keys(l.props).forEach(d=>{o[d]!==l.props[d]&&e[d]!==l.props[d]&&(c=!1)}),c&&r.push(t[z_(l.props)])}),r};function ho(e){return e!=="ownerState"&&e!=="theme"&&e!=="sx"&&e!=="as"}const b3=yp(),v3=e=>e&&e.charAt(0).toLowerCase()+e.slice(1);function $a({defaultTheme:e,theme:t,themeId:n}){return f3(t)?e:t[n]||t}function w3(e){return e?(t,n)=>n[e]:null}function x3(e={}){const{themeId:t,defaultTheme:n=b3,rootShouldForwardProp:i=ho,slotShouldForwardProp:a=ho}=e,o=r=>xl(k({},r,{theme:$a(k({},r,{defaultTheme:n,themeId:t}))}));return o.__mui_systemSx=!0,(r,s={})=>{d2(r,w=>w.filter(C=>!(C!=null&&C.__mui_systemSx)));const{name:l,slot:c,skipVariantsResolver:d,skipSx:h,overridesResolver:y=w3(v3(c))}=s,p=U(s,m3),f=d!==void 0?d:c&&c!=="Root"&&c!=="root"||!1,u=h||!1;let T,g=ho;c==="Root"||c==="root"?g=i:c?g=a:h3(r)&&(g=void 0);const _=A_(r,k({shouldForwardProp:g,label:T},p)),b=(w,...C)=>{const I=C?C.map(P=>typeof P=="function"&&P.__emotion_real!==P?R=>P(k({},R,{theme:$a(k({},R,{defaultTheme:n,themeId:t}))})):P):[];let x=w;l&&y&&I.push(P=>{const R=$a(k({},P,{defaultTheme:n,themeId:t})),O=y3(l,R);if(O){const M={};return Object.entries(O).forEach(([A,B])=>{M[A]=typeof B=="function"?B(k({},P,{theme:R})):B}),y(P,M)}return null}),l&&!f&&I.push(P=>{const R=$a(k({},P,{defaultTheme:n,themeId:t}));return _3(P,g3(l,R),R,l)}),u||I.push(o);const q=I.length-C.length;if(Array.isArray(w)&&q>0){const P=new Array(q).fill("");x=[...w,...P],x.raw=[...w.raw,...P]}else typeof w=="function"&&w.__emotion_real!==w&&(x=P=>w(k({},P,{theme:$a(k({},P,{defaultTheme:n,themeId:t}))})));const S=_(x,...I);return r.muiName&&(S.muiName=r.muiName),S};return _.withConfig&&(b.withConfig=_.withConfig),b}}function T3(e){const{theme:t,name:n,props:i}=e;return!t||!t.components||!t.components[n]||!t.components[n].defaultProps?i:p_(t.components[n].defaultProps,i)}function k3({props:e,name:t,defaultTheme:n,themeId:i}){let a=Tl(n);return i&&(a=a[i]||a),T3({theme:a,name:t,props:e})}function gp(e,t=0,n=1){return Math.min(Math.max(t,e),n)}function C3(e){e=e.slice(1);const t=new RegExp(`.{1,${e.length>=6?2:1}}`,"g");let n=e.match(t);return n&&n[0].length===1&&(n=n.map(i=>i+i)),n?`rgb${n.length===4?"a":""}(${n.map((i,a)=>a<3?parseInt(i,16):Math.round(parseInt(i,16)/255*1e3)/1e3).join(", ")})`:""}function Bi(e){if(e.type)return e;if(e.charAt(0)==="#")return Bi(C3(e));const t=e.indexOf("("),n=e.substring(0,t);if(["rgb","rgba","hsl","hsla","color"].indexOf(n)===-1)throw new Error(ai(9,e));let i=e.substring(t+1,e.length-1),a;if(n==="color"){if(i=i.split(" "),a=i.shift(),i.length===4&&i[3].charAt(0)==="/"&&(i[3]=i[3].slice(1)),["srgb","display-p3","a98-rgb","prophoto-rgb","rec-2020"].indexOf(a)===-1)throw new Error(ai(10,a))}else i=i.split(",");return i=i.map(o=>parseFloat(o)),{type:n,values:i,colorSpace:a}}function kl(e){const{type:t,colorSpace:n}=e;let{values:i}=e;return t.indexOf("rgb")!==-1?i=i.map((a,o)=>o<3?parseInt(a,10):a):t.indexOf("hsl")!==-1&&(i[1]=`${i[1]}%`,i[2]=`${i[2]}%`),t.indexOf("color")!==-1?i=`${n} ${i.join(" ")}`:i=`${i.join(", ")}`,`${t}(${i})`}function I3(e){e=Bi(e);const{values:t}=e,n=t[0],i=t[1]/100,a=t[2]/100,o=i*Math.min(a,1-a),r=(c,d=(c+n/30)%12)=>a-o*Math.max(Math.min(d-3,9-d,1),-1);let s="rgb";const l=[Math.round(r(0)*255),Math.round(r(8)*255),Math.round(r(4)*255)];return e.type==="hsla"&&(s+="a",l.push(t[3])),kl({type:s,values:l})}function kf(e){e=Bi(e);let t=e.type==="hsl"||e.type==="hsla"?Bi(I3(e)).values:e.values;return t=t.map(n=>(e.type!=="color"&&(n/=255),n<=.03928?n/12.92:((n+.055)/1.055)**2.4)),Number((.2126*t[0]+.7152*t[1]+.0722*t[2]).toFixed(3))}function q3(e,t){const n=kf(e),i=kf(t);return(Math.max(n,i)+.05)/(Math.min(n,i)+.05)}function Tn(e,t){return e=Bi(e),t=gp(t),(e.type==="rgb"||e.type==="hsl")&&(e.type+="a"),e.type==="color"?e.values[3]=`/${t}`:e.values[3]=t,kl(e)}function Od(e,t){if(e=Bi(e),t=gp(t),e.type.indexOf("hsl")!==-1)e.values[2]*=1-t;else if(e.type.indexOf("rgb")!==-1||e.type.indexOf("color")!==-1)for(let n=0;n<3;n+=1)e.values[n]*=1-t;return kl(e)}function zd(e,t){if(e=Bi(e),t=gp(t),e.type.indexOf("hsl")!==-1)e.values[2]+=(100-e.values[2])*t;else if(e.type.indexOf("rgb")!==-1)for(let n=0;n<3;n+=1)e.values[n]+=(255-e.values[n])*t;else if(e.type.indexOf("color")!==-1)for(let n=0;n<3;n+=1)e.values[n]+=(1-e.values[n])*t;return kl(e)}function D3(e,t){return k({toolbar:{minHeight:56,[e.up("xs")]:{"@media (orientation: landscape)":{minHeight:48}},[e.up("sm")]:{minHeight:64}}},t)}const P3={black:"#000",white:"#fff"},Mo=P3,S3={50:"#fafafa",100:"#f5f5f5",200:"#eeeeee",300:"#e0e0e0",400:"#bdbdbd",500:"#9e9e9e",600:"#757575",700:"#616161",800:"#424242",900:"#212121",A100:"#f5f5f5",A200:"#eeeeee",A400:"#bdbdbd",A700:"#616161"},E3=S3,A3={50:"#f3e5f5",100:"#e1bee7",200:"#ce93d8",300:"#ba68c8",400:"#ab47bc",500:"#9c27b0",600:"#8e24aa",700:"#7b1fa2",800:"#6a1b9a",900:"#4a148c",A100:"#ea80fc",A200:"#e040fb",A400:"#d500f9",A700:"#aa00ff"},Li=A3,N3={50:"#ffebee",100:"#ffcdd2",200:"#ef9a9a",300:"#e57373",400:"#ef5350",500:"#f44336",600:"#e53935",700:"#d32f2f",800:"#c62828",900:"#b71c1c",A100:"#ff8a80",A200:"#ff5252",A400:"#ff1744",A700:"#d50000"},Fi=N3,R3={50:"#fff3e0",100:"#ffe0b2",200:"#ffcc80",300:"#ffb74d",400:"#ffa726",500:"#ff9800",600:"#fb8c00",700:"#f57c00",800:"#ef6c00",900:"#e65100",A100:"#ffd180",A200:"#ffab40",A400:"#ff9100",A700:"#ff6d00"},Va=R3,B3={50:"#e3f2fd",100:"#bbdefb",200:"#90caf9",300:"#64b5f6",400:"#42a5f5",500:"#2196f3",600:"#1e88e5",700:"#1976d2",800:"#1565c0",900:"#0d47a1",A100:"#82b1ff",A200:"#448aff",A400:"#2979ff",A700:"#2962ff"},Ui=B3,O3={50:"#e1f5fe",100:"#b3e5fc",200:"#81d4fa",300:"#4fc3f7",400:"#29b6f6",500:"#03a9f4",600:"#039be5",700:"#0288d1",800:"#0277bd",900:"#01579b",A100:"#80d8ff",A200:"#40c4ff",A400:"#00b0ff",A700:"#0091ea"},Gi=O3,z3={50:"#e8f5e9",100:"#c8e6c9",200:"#a5d6a7",300:"#81c784",400:"#66bb6a",500:"#4caf50",600:"#43a047",700:"#388e3c",800:"#2e7d32",900:"#1b5e20",A100:"#b9f6ca",A200:"#69f0ae",A400:"#00e676",A700:"#00c853"},$i=z3,W3=["mode","contrastThreshold","tonalOffset"],Cf={text:{primary:"rgba(0, 0, 0, 0.87)",secondary:"rgba(0, 0, 0, 0.6)",disabled:"rgba(0, 0, 0, 0.38)"},divider:"rgba(0, 0, 0, 0.12)",background:{paper:Mo.white,default:Mo.white},action:{active:"rgba(0, 0, 0, 0.54)",hover:"rgba(0, 0, 0, 0.04)",hoverOpacity:.04,selected:"rgba(0, 0, 0, 0.08)",selectedOpacity:.08,disabled:"rgba(0, 0, 0, 0.26)",disabledBackground:"rgba(0, 0, 0, 0.12)",disabledOpacity:.38,focus:"rgba(0, 0, 0, 0.12)",focusOpacity:.12,activatedOpacity:.12}},hc={text:{primary:Mo.white,secondary:"rgba(255, 255, 255, 0.7)",disabled:"rgba(255, 255, 255, 0.5)",icon:"rgba(255, 255, 255, 0.5)"},divider:"rgba(255, 255, 255, 0.12)",background:{paper:"#121212",default:"#121212"},action:{active:Mo.white,hover:"rgba(255, 255, 255, 0.08)",hoverOpacity:.08,selected:"rgba(255, 255, 255, 0.16)",selectedOpacity:.16,disabled:"rgba(255, 255, 255, 0.3)",disabledBackground:"rgba(255, 255, 255, 0.12)",disabledOpacity:.38,focus:"rgba(255, 255, 255, 0.12)",focusOpacity:.12,activatedOpacity:.24}};function If(e,t,n,i){const a=i.light||i,o=i.dark||i*1.5;e[t]||(e.hasOwnProperty(n)?e[t]=e[n]:t==="light"?e.light=zd(e.main,a):t==="dark"&&(e.dark=Od(e.main,o)))}function j3(e="light"){return e==="dark"?{main:Ui[200],light:Ui[50],dark:Ui[400]}:{main:Ui[700],light:Ui[400],dark:Ui[800]}}function M3(e="light"){return e==="dark"?{main:Li[200],light:Li[50],dark:Li[400]}:{main:Li[500],light:Li[300],dark:Li[700]}}function L3(e="light"){return e==="dark"?{main:Fi[500],light:Fi[300],dark:Fi[700]}:{main:Fi[700],light:Fi[400],dark:Fi[800]}}function F3(e="light"){return e==="dark"?{main:Gi[400],light:Gi[300],dark:Gi[700]}:{main:Gi[700],light:Gi[500],dark:Gi[900]}}function U3(e="light"){return e==="dark"?{main:$i[400],light:$i[300],dark:$i[700]}:{main:$i[800],light:$i[500],dark:$i[900]}}function G3(e="light"){return e==="dark"?{main:Va[400],light:Va[300],dark:Va[700]}:{main:"#ed6c02",light:Va[500],dark:Va[900]}}function $3(e){const{mode:t="light",contrastThreshold:n=3,tonalOffset:i=.2}=e,a=U(e,W3),o=e.primary||j3(t),r=e.secondary||M3(t),s=e.error||L3(t),l=e.info||F3(t),c=e.success||U3(t),d=e.warning||G3(t);function h(u){return q3(u,hc.text.primary)>=n?hc.text.primary:Cf.text.primary}const y=({color:u,name:T,mainShade:g=500,lightShade:_=300,darkShade:b=700})=>{if(u=k({},u),!u.main&&u[g]&&(u.main=u[g]),!u.hasOwnProperty("main"))throw new Error(ai(11,T?` (${T})`:"",g));if(typeof u.main!="string")throw new Error(ai(12,T?` (${T})`:"",JSON.stringify(u.main)));return If(u,"light",_,i),If(u,"dark",b,i),u.contrastText||(u.contrastText=h(u.main)),u},p={dark:hc,light:Cf};return Wt(k({common:k({},Mo),mode:t,primary:y({color:o,name:"primary"}),secondary:y({color:r,name:"secondary",mainShade:"A400",lightShade:"A200",darkShade:"A700"}),error:y({color:s,name:"error"}),warning:y({color:d,name:"warning"}),info:y({color:l,name:"info"}),success:y({color:c,name:"success"}),grey:E3,contrastThreshold:n,getContrastText:h,augmentColor:y,tonalOffset:i},p[t]),a)}const V3=["fontFamily","fontSize","fontWeightLight","fontWeightRegular","fontWeightMedium","fontWeightBold","htmlFontSize","allVariants","pxToRem"];function H3(e){return Math.round(e*1e5)/1e5}const qf={textTransform:"uppercase"},Df='"Roboto", "Helvetica", "Arial", sans-serif';function Z3(e,t){const n=typeof t=="function"?t(e):t,{fontFamily:i=Df,fontSize:a=14,fontWeightLight:o=300,fontWeightRegular:r=400,fontWeightMedium:s=500,fontWeightBold:l=700,htmlFontSize:c=16,allVariants:d,pxToRem:h}=n,y=U(n,V3),p=a/14,f=h||(g=>`${g/c*p}rem`),u=(g,_,b,w,C)=>k({fontFamily:i,fontWeight:g,fontSize:f(_),lineHeight:b},i===Df?{letterSpacing:`${H3(w/_)}em`}:{},C,d),T={h1:u(o,96,1.167,-1.5),h2:u(o,60,1.2,-.5),h3:u(r,48,1.167,0),h4:u(r,34,1.235,.25),h5:u(r,24,1.334,0),h6:u(s,20,1.6,.15),subtitle1:u(r,16,1.75,.15),subtitle2:u(s,14,1.57,.1),body1:u(r,16,1.5,.15),body2:u(r,14,1.43,.15),button:u(s,14,1.75,.4,qf),caption:u(r,12,1.66,.4),overline:u(r,12,2.66,1,qf),inherit:{fontFamily:"inherit",fontWeight:"inherit",fontSize:"inherit",lineHeight:"inherit",letterSpacing:"inherit"}};return Wt(k({htmlFontSize:c,pxToRem:f,fontFamily:i,fontSize:a,fontWeightLight:o,fontWeightRegular:r,fontWeightMedium:s,fontWeightBold:l},T),y,{clone:!1})}const Q3=.2,K3=.14,X3=.12;function ke(...e){return[`${e[0]}px ${e[1]}px ${e[2]}px ${e[3]}px rgba(0,0,0,${Q3})`,`${e[4]}px ${e[5]}px ${e[6]}px ${e[7]}px rgba(0,0,0,${K3})`,`${e[8]}px ${e[9]}px ${e[10]}px ${e[11]}px rgba(0,0,0,${X3})`].join(",")}const Y3=["none",ke(0,2,1,-1,0,1,1,0,0,1,3,0),ke(0,3,1,-2,0,2,2,0,0,1,5,0),ke(0,3,3,-2,0,3,4,0,0,1,8,0),ke(0,2,4,-1,0,4,5,0,0,1,10,0),ke(0,3,5,-1,0,5,8,0,0,1,14,0),ke(0,3,5,-1,0,6,10,0,0,1,18,0),ke(0,4,5,-2,0,7,10,1,0,2,16,1),ke(0,5,5,-3,0,8,10,1,0,3,14,2),ke(0,5,6,-3,0,9,12,1,0,3,16,2),ke(0,6,6,-3,0,10,14,1,0,4,18,3),ke(0,6,7,-4,0,11,15,1,0,4,20,3),ke(0,7,8,-4,0,12,17,2,0,5,22,4),ke(0,7,8,-4,0,13,19,2,0,5,24,4),ke(0,7,9,-4,0,14,21,2,0,5,26,4),ke(0,8,9,-5,0,15,22,2,0,6,28,5),ke(0,8,10,-5,0,16,24,2,0,6,30,5),ke(0,8,11,-5,0,17,26,2,0,6,32,5),ke(0,9,11,-5,0,18,28,2,0,7,34,6),ke(0,9,12,-6,0,19,29,2,0,7,36,6),ke(0,10,13,-6,0,20,31,3,0,8,38,7),ke(0,10,13,-6,0,21,33,3,0,8,40,7),ke(0,10,14,-6,0,22,35,3,0,8,42,7),ke(0,11,14,-7,0,23,36,3,0,9,44,8),ke(0,11,15,-7,0,24,38,3,0,9,46,8)],J3=Y3,e6=["duration","easing","delay"],t6={easeInOut:"cubic-bezier(0.4, 0, 0.2, 1)",easeOut:"cubic-bezier(0.0, 0, 0.2, 1)",easeIn:"cubic-bezier(0.4, 0, 1, 1)",sharp:"cubic-bezier(0.4, 0, 0.6, 1)"},n6={shortest:150,shorter:200,short:250,standard:300,complex:375,enteringScreen:225,leavingScreen:195};function Pf(e){return`${Math.round(e)}ms`}function i6(e){if(!e)return 0;const t=e/36;return Math.round((4+15*t**.25+t/5)*10)}function a6(e){const t=k({},t6,e.easing),n=k({},n6,e.duration);return k({getAutoHeightDuration:i6,create:(a=["all"],o={})=>{const{duration:r=n.standard,easing:s=t.easeInOut,delay:l=0}=o;return U(o,e6),(Array.isArray(a)?a:[a]).map(c=>`${c} ${typeof r=="string"?r:Pf(r)} ${s} ${typeof l=="string"?l:Pf(l)}`).join(",")}},e,{easing:t,duration:n})}const o6={mobileStepper:1e3,fab:1050,speedDial:1050,appBar:1100,drawer:1200,modal:1300,snackbar:1400,tooltip:1500},r6=o6,s6=["breakpoints","mixins","spacing","palette","transitions","typography","shape"];function W_(e={},...t){const{mixins:n={},palette:i={},transitions:a={},typography:o={}}=e,r=U(e,s6);if(e.vars)throw new Error(ai(18));const s=$3(i),l=yp(e);let c=Wt(l,{mixins:D3(l.breakpoints,n),palette:s,shadows:J3.slice(),typography:Z3(s,o),transitions:a6(a),zIndex:k({},r6)});return c=Wt(c,r),c=t.reduce((d,h)=>Wt(d,h),c),c.unstable_sxConfig=k({},wl,r==null?void 0:r.unstable_sxConfig),c.unstable_sx=function(h){return xl({sx:h,theme:this})},c}const l6=W_(),Cl=l6,Xo="$$material";function he({props:e,name:t}){return k3({props:e,name:t,defaultTheme:Cl,themeId:Xo})}const Yt=e=>ho(e)&&e!=="classes",c6=ho,d6=x3({themeId:Xo,defaultTheme:Cl,rootShouldForwardProp:Yt}),F=d6;function u6(e){return me("MuiSvgIcon",e)}re("MuiSvgIcon",["root","colorPrimary","colorSecondary","colorAction","colorError","colorDisabled","fontSizeInherit","fontSizeSmall","fontSizeMedium","fontSizeLarge"]);const p6=["children","className","color","component","fontSize","htmlColor","inheritViewBox","titleAccess","viewBox"],m6=e=>{const{color:t,fontSize:n,classes:i}=e,a={root:["root",t!=="inherit"&&`color${Z(t)}`,`fontSize${Z(n)}`]};return fe(a,u6,i)},f6=F("svg",{name:"MuiSvgIcon",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.color!=="inherit"&&t[`color${Z(n.color)}`],t[`fontSize${Z(n.fontSize)}`]]}})(({theme:e,ownerState:t})=>{var n,i,a,o,r,s,l,c,d,h,y,p,f;return{userSelect:"none",width:"1em",height:"1em",display:"inline-block",fill:t.hasSvgAsChild?void 0:"currentColor",flexShrink:0,transition:(n=e.transitions)==null||(i=n.create)==null?void 0:i.call(n,"fill",{duration:(a=e.transitions)==null||(a=a.duration)==null?void 0:a.shorter}),fontSize:{inherit:"inherit",small:((o=e.typography)==null||(r=o.pxToRem)==null?void 0:r.call(o,20))||"1.25rem",medium:((s=e.typography)==null||(l=s.pxToRem)==null?void 0:l.call(s,24))||"1.5rem",large:((c=e.typography)==null||(d=c.pxToRem)==null?void 0:d.call(c,35))||"2.1875rem"}[t.fontSize],color:(h=(y=(e.vars||e).palette)==null||(y=y[t.color])==null?void 0:y.main)!=null?h:{action:(p=(e.vars||e).palette)==null||(p=p.action)==null?void 0:p.active,disabled:(f=(e.vars||e).palette)==null||(f=f.action)==null?void 0:f.disabled,inherit:void 0}[t.color]}}),j_=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiSvgIcon"}),{children:a,className:o,color:r="inherit",component:s="svg",fontSize:l="medium",htmlColor:c,inheritViewBox:d=!1,titleAccess:h,viewBox:y="0 0 24 24"}=i,p=U(i,p6),f=v.isValidElement(a)&&a.type==="svg",u=k({},i,{color:r,component:s,fontSize:l,instanceFontSize:t.fontSize,inheritViewBox:d,viewBox:y,hasSvgAsChild:f}),T={};d||(T.viewBox=y);const g=m6(u);return m.jsxs(f6,k({as:s,className:V(g.root,o),focusable:"false",color:c,"aria-hidden":h?void 0:!0,role:h?"img":void 0,ref:n},T,p,f&&a.props,{ownerState:u,children:[f?a.props.children:a,h?m.jsx("title",{children:h}):null]}))});j_.muiName="SvgIcon";const Sf=j_;function Wi(e,t){function n(i,a){return m.jsx(Sf,k({"data-testid":`${t}Icon`,ref:a},i,{children:e}))}return n.muiName=Sf.muiName,v.memo(v.forwardRef(n))}const h6={configure:e=>{np.configure(e)}},y6=Object.freeze(Object.defineProperty({__proto__:null,capitalize:Z,createChainedFunction:Sd,createSvgIcon:Wi,debounce:el,deprecatedPropType:Hw,isMuiElement:Wr,ownerDocument:yt,ownerWindow:pn,requirePropFactory:Zw,setRef:gs,unstable_ClassNameGenerator:h6,unstable_useEnhancedEffect:oi,unstable_useId:c_,unsupportedProp:Xw,useControlled:Ed,useEventCallback:Ci,useForkRef:Xe,useIsFocusVisible:d_},Symbol.toStringTag,{value:"Module"})),g6=f0(y6);var Ef;function _p(){return Ef||(Ef=1,function(e){"use client";Object.defineProperty(e,"__esModule",{value:!0}),Object.defineProperty(e,"default",{enumerable:!0,get:function(){return t.createSvgIcon}});var t=g6}(pc)),pc}var _6=Ju;Object.defineProperty(Yu,"__esModule",{value:!0});var M_=Yu.default=void 0,b6=_6(_p()),v6=m,w6=(0,b6.default)((0,v6.jsx)("path",{d:"M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"}),"Search");M_=Yu.default=w6;var bp={},x6=Ju;Object.defineProperty(bp,"__esModule",{value:!0});var L_=bp.default=void 0,T6=x6(_p()),k6=m,C6=(0,T6.default)((0,k6.jsx)("path",{d:"M19 7v4H5.83l3.58-3.59L8 6l-6 6 6 6 1.41-1.41L5.83 13H21V7z"}),"KeyboardReturn");L_=bp.default=C6;function Sn(e){return Array.isArray?Array.isArray(e):G_(e)==="[object Array]"}const I6=1/0;function q6(e){if(typeof e=="string")return e;let t=e+"";return t=="0"&&1/e==-I6?"-0":t}function D6(e){return e==null?"":q6(e)}function ln(e){return typeof e=="string"}function F_(e){return typeof e=="number"}function P6(e){return e===!0||e===!1||S6(e)&&G_(e)=="[object Boolean]"}function U_(e){return typeof e=="object"}function S6(e){return U_(e)&&e!==null}function vt(e){return e!=null}function yc(e){return!e.trim().length}function G_(e){return e==null?e===void 0?"[object Undefined]":"[object Null]":Object.prototype.toString.call(e)}const E6="Incorrect 'index' type",A6=e=>`Invalid value for key ${e}`,N6=e=>`Pattern length exceeds max of ${e}.`,R6=e=>`Missing ${e} property in key`,B6=e=>`Property 'weight' in key '${e}' must be a positive integer`,Af=Object.prototype.hasOwnProperty;class O6{constructor(t){this._keys=[],this._keyMap={};let n=0;t.forEach(i=>{let a=$_(i);n+=a.weight,this._keys.push(a),this._keyMap[a.id]=a,n+=a.weight}),this._keys.forEach(i=>{i.weight/=n})}get(t){return this._keyMap[t]}keys(){return this._keys}toJSON(){return JSON.stringify(this._keys)}}function $_(e){let t=null,n=null,i=null,a=1,o=null;if(ln(e)||Sn(e))i=e,t=Nf(e),n=Wd(e);else{if(!Af.call(e,"name"))throw new Error(R6("name"));const r=e.name;if(i=r,Af.call(e,"weight")&&(a=e.weight,a<=0))throw new Error(B6(r));t=Nf(r),n=Wd(r),o=e.getFn}return{path:t,id:n,weight:a,src:i,getFn:o}}function Nf(e){return Sn(e)?e:e.split(".")}function Wd(e){return Sn(e)?e.join("."):e}function z6(e,t){let n=[],i=!1;const a=(o,r,s)=>{if(vt(o))if(!r[s])n.push(o);else{let l=r[s];const c=o[l];if(!vt(c))return;if(s===r.length-1&&(ln(c)||F_(c)||P6(c)))n.push(D6(c));else if(Sn(c)){i=!0;for(let d=0,h=c.length;d<h;d+=1)a(c[d],r,s+1)}else r.length&&a(c,r,s+1)}};return a(e,ln(t)?t.split("."):t,0),i?n:n[0]}const W6={includeMatches:!1,findAllMatches:!1,minMatchCharLength:1},j6={isCaseSensitive:!1,includeScore:!1,keys:[],shouldSort:!0,sortFn:(e,t)=>e.score===t.score?e.idx<t.idx?-1:1:e.score<t.score?-1:1},M6={location:0,threshold:.6,distance:100},L6={useExtendedSearch:!1,getFn:z6,ignoreLocation:!1,ignoreFieldNorm:!1,fieldNormWeight:1};var H={...j6,...W6,...M6,...L6};const F6=/[^ ]+/g;function U6(e=1,t=3){const n=new Map,i=Math.pow(10,t);return{get(a){const o=a.match(F6).length;if(n.has(o))return n.get(o);const r=1/Math.pow(o,.5*e),s=parseFloat(Math.round(r*i)/i);return n.set(o,s),s},clear(){n.clear()}}}class vp{constructor({getFn:t=H.getFn,fieldNormWeight:n=H.fieldNormWeight}={}){this.norm=U6(n,3),this.getFn=t,this.isCreated=!1,this.setIndexRecords()}setSources(t=[]){this.docs=t}setIndexRecords(t=[]){this.records=t}setKeys(t=[]){this.keys=t,this._keysMap={},t.forEach((n,i)=>{this._keysMap[n.id]=i})}create(){this.isCreated||!this.docs.length||(this.isCreated=!0,ln(this.docs[0])?this.docs.forEach((t,n)=>{this._addString(t,n)}):this.docs.forEach((t,n)=>{this._addObject(t,n)}),this.norm.clear())}add(t){const n=this.size();ln(t)?this._addString(t,n):this._addObject(t,n)}removeAt(t){this.records.splice(t,1);for(let n=t,i=this.size();n<i;n+=1)this.records[n].i-=1}getValueForItemAtKeyId(t,n){return t[this._keysMap[n]]}size(){return this.records.length}_addString(t,n){if(!vt(t)||yc(t))return;let i={v:t,i:n,n:this.norm.get(t)};this.records.push(i)}_addObject(t,n){let i={i:n,$:{}};this.keys.forEach((a,o)=>{let r=a.getFn?a.getFn(t):this.getFn(t,a.path);if(vt(r)){if(Sn(r)){let s=[];const l=[{nestedArrIndex:-1,value:r}];for(;l.length;){const{nestedArrIndex:c,value:d}=l.pop();if(vt(d))if(ln(d)&&!yc(d)){let h={v:d,i:c,n:this.norm.get(d)};s.push(h)}else Sn(d)&&d.forEach((h,y)=>{l.push({nestedArrIndex:y,value:h})})}i.$[o]=s}else if(ln(r)&&!yc(r)){let s={v:r,n:this.norm.get(r)};i.$[o]=s}}}),this.records.push(i)}toJSON(){return{keys:this.keys,records:this.records}}}function V_(e,t,{getFn:n=H.getFn,fieldNormWeight:i=H.fieldNormWeight}={}){const a=new vp({getFn:n,fieldNormWeight:i});return a.setKeys(e.map($_)),a.setSources(t),a.create(),a}function G6(e,{getFn:t=H.getFn,fieldNormWeight:n=H.fieldNormWeight}={}){const{keys:i,records:a}=e,o=new vp({getFn:t,fieldNormWeight:n});return o.setKeys(i),o.setIndexRecords(a),o}function wr(e,{errors:t=0,currentLocation:n=0,expectedLocation:i=0,distance:a=H.distance,ignoreLocation:o=H.ignoreLocation}={}){const r=t/e.length;if(o)return r;const s=Math.abs(i-n);return a?r+s/a:s?1:r}function $6(e=[],t=H.minMatchCharLength){let n=[],i=-1,a=-1,o=0;for(let r=e.length;o<r;o+=1){let s=e[o];s&&i===-1?i=o:!s&&i!==-1&&(a=o-1,a-i+1>=t&&n.push([i,a]),i=-1)}return e[o-1]&&o-i>=t&&n.push([i,o-1]),n}const bi=32;function V6(e,t,n,{location:i=H.location,distance:a=H.distance,threshold:o=H.threshold,findAllMatches:r=H.findAllMatches,minMatchCharLength:s=H.minMatchCharLength,includeMatches:l=H.includeMatches,ignoreLocation:c=H.ignoreLocation}={}){if(t.length>bi)throw new Error(N6(bi));const d=t.length,h=e.length,y=Math.max(0,Math.min(i,h));let p=o,f=y;const u=s>1||l,T=u?Array(h):[];let g;for(;(g=e.indexOf(t,f))>-1;){let x=wr(t,{currentLocation:g,expectedLocation:y,distance:a,ignoreLocation:c});if(p=Math.min(x,p),f=g+d,u){let q=0;for(;q<d;)T[g+q]=1,q+=1}}f=-1;let _=[],b=1,w=d+h;const C=1<<d-1;for(let x=0;x<d;x+=1){let q=0,S=w;for(;q<S;)wr(t,{errors:x,currentLocation:y+S,expectedLocation:y,distance:a,ignoreLocation:c})<=p?q=S:w=S,S=Math.floor((w-q)/2+q);w=S;let P=Math.max(1,y-S+1),R=r?h:Math.min(y+S,h)+d,O=Array(R+2);O[R+1]=(1<<x)-1;for(let A=R;A>=P;A-=1){let B=A-1,z=n[e.charAt(B)];if(u&&(T[B]=+!!z),O[A]=(O[A+1]<<1|1)&z,x&&(O[A]|=(_[A+1]|_[A])<<1|1|_[A+1]),O[A]&C&&(b=wr(t,{errors:x,currentLocation:B,expectedLocation:y,distance:a,ignoreLocation:c}),b<=p)){if(p=b,f=B,f<=y)break;P=Math.max(1,2*y-f)}}if(wr(t,{errors:x+1,currentLocation:y,expectedLocation:y,distance:a,ignoreLocation:c})>p)break;_=O}const I={isMatch:f>=0,score:Math.max(.001,b)};if(u){const x=$6(T,s);x.length?l&&(I.indices=x):I.isMatch=!1}return I}function H6(e){let t={};for(let n=0,i=e.length;n<i;n+=1){const a=e.charAt(n);t[a]=(t[a]||0)|1<<i-n-1}return t}class H_{constructor(t,{location:n=H.location,threshold:i=H.threshold,distance:a=H.distance,includeMatches:o=H.includeMatches,findAllMatches:r=H.findAllMatches,minMatchCharLength:s=H.minMatchCharLength,isCaseSensitive:l=H.isCaseSensitive,ignoreLocation:c=H.ignoreLocation}={}){if(this.options={location:n,threshold:i,distance:a,includeMatches:o,findAllMatches:r,minMatchCharLength:s,isCaseSensitive:l,ignoreLocation:c},this.pattern=l?t:t.toLowerCase(),this.chunks=[],!this.pattern.length)return;const d=(y,p)=>{this.chunks.push({pattern:y,alphabet:H6(y),startIndex:p})},h=this.pattern.length;if(h>bi){let y=0;const p=h%bi,f=h-p;for(;y<f;)d(this.pattern.substr(y,bi),y),y+=bi;if(p){const u=h-bi;d(this.pattern.substr(u),u)}}else d(this.pattern,0)}searchIn(t){const{isCaseSensitive:n,includeMatches:i}=this.options;if(n||(t=t.toLowerCase()),this.pattern===t){let f={isMatch:!0,score:0};return i&&(f.indices=[[0,t.length-1]]),f}const{location:a,distance:o,threshold:r,findAllMatches:s,minMatchCharLength:l,ignoreLocation:c}=this.options;let d=[],h=0,y=!1;this.chunks.forEach(({pattern:f,alphabet:u,startIndex:T})=>{const{isMatch:g,score:_,indices:b}=V6(t,f,u,{location:a+T,distance:o,threshold:r,findAllMatches:s,minMatchCharLength:l,includeMatches:i,ignoreLocation:c});g&&(y=!0),h+=_,g&&b&&(d=[...d,...b])});let p={isMatch:y,score:y?h/this.chunks.length:1};return y&&i&&(p.indices=d),p}}class di{constructor(t){this.pattern=t}static isMultiMatch(t){return Rf(t,this.multiRegex)}static isSingleMatch(t){return Rf(t,this.singleRegex)}search(){}}function Rf(e,t){const n=e.match(t);return n?n[1]:null}class Z6 extends di{constructor(t){super(t)}static get type(){return"exact"}static get multiRegex(){return/^="(.*)"$/}static get singleRegex(){return/^=(.*)$/}search(t){const n=t===this.pattern;return{isMatch:n,score:n?0:1,indices:[0,this.pattern.length-1]}}}class Q6 extends di{constructor(t){super(t)}static get type(){return"inverse-exact"}static get multiRegex(){return/^!"(.*)"$/}static get singleRegex(){return/^!(.*)$/}search(t){const i=t.indexOf(this.pattern)===-1;return{isMatch:i,score:i?0:1,indices:[0,t.length-1]}}}class K6 extends di{constructor(t){super(t)}static get type(){return"prefix-exact"}static get multiRegex(){return/^\^"(.*)"$/}static get singleRegex(){return/^\^(.*)$/}search(t){const n=t.startsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[0,this.pattern.length-1]}}}class X6 extends di{constructor(t){super(t)}static get type(){return"inverse-prefix-exact"}static get multiRegex(){return/^!\^"(.*)"$/}static get singleRegex(){return/^!\^(.*)$/}search(t){const n=!t.startsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[0,t.length-1]}}}class Y6 extends di{constructor(t){super(t)}static get type(){return"suffix-exact"}static get multiRegex(){return/^"(.*)"\$$/}static get singleRegex(){return/^(.*)\$$/}search(t){const n=t.endsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[t.length-this.pattern.length,t.length-1]}}}class J6 extends di{constructor(t){super(t)}static get type(){return"inverse-suffix-exact"}static get multiRegex(){return/^!"(.*)"\$$/}static get singleRegex(){return/^!(.*)\$$/}search(t){const n=!t.endsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[0,t.length-1]}}}class Z_ extends di{constructor(t,{location:n=H.location,threshold:i=H.threshold,distance:a=H.distance,includeMatches:o=H.includeMatches,findAllMatches:r=H.findAllMatches,minMatchCharLength:s=H.minMatchCharLength,isCaseSensitive:l=H.isCaseSensitive,ignoreLocation:c=H.ignoreLocation}={}){super(t),this._bitapSearch=new H_(t,{location:n,threshold:i,distance:a,includeMatches:o,findAllMatches:r,minMatchCharLength:s,isCaseSensitive:l,ignoreLocation:c})}static get type(){return"fuzzy"}static get multiRegex(){return/^"(.*)"$/}static get singleRegex(){return/^(.*)$/}search(t){return this._bitapSearch.searchIn(t)}}class Q_ extends di{constructor(t){super(t)}static get type(){return"include"}static get multiRegex(){return/^'"(.*)"$/}static get singleRegex(){return/^'(.*)$/}search(t){let n=0,i;const a=[],o=this.pattern.length;for(;(i=t.indexOf(this.pattern,n))>-1;)n=i+o,a.push([i,n-1]);const r=!!a.length;return{isMatch:r,score:r?0:1,indices:a}}}const jd=[Z6,Q_,K6,X6,J6,Y6,Q6,Z_],Bf=jd.length,eT=/ +(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)/,tT="|";function nT(e,t={}){return e.split(tT).map(n=>{let i=n.trim().split(eT).filter(o=>o&&!!o.trim()),a=[];for(let o=0,r=i.length;o<r;o+=1){const s=i[o];let l=!1,c=-1;for(;!l&&++c<Bf;){const d=jd[c];let h=d.isMultiMatch(s);h&&(a.push(new d(h,t)),l=!0)}if(!l)for(c=-1;++c<Bf;){const d=jd[c];let h=d.isSingleMatch(s);if(h){a.push(new d(h,t));break}}}return a})}const iT=new Set([Z_.type,Q_.type]);class aT{constructor(t,{isCaseSensitive:n=H.isCaseSensitive,includeMatches:i=H.includeMatches,minMatchCharLength:a=H.minMatchCharLength,ignoreLocation:o=H.ignoreLocation,findAllMatches:r=H.findAllMatches,location:s=H.location,threshold:l=H.threshold,distance:c=H.distance}={}){this.query=null,this.options={isCaseSensitive:n,includeMatches:i,minMatchCharLength:a,findAllMatches:r,ignoreLocation:o,location:s,threshold:l,distance:c},this.pattern=n?t:t.toLowerCase(),this.query=nT(this.pattern,this.options)}static condition(t,n){return n.useExtendedSearch}searchIn(t){const n=this.query;if(!n)return{isMatch:!1,score:1};const{includeMatches:i,isCaseSensitive:a}=this.options;t=a?t:t.toLowerCase();let o=0,r=[],s=0;for(let l=0,c=n.length;l<c;l+=1){const d=n[l];r.length=0,o=0;for(let h=0,y=d.length;h<y;h+=1){const p=d[h],{isMatch:f,indices:u,score:T}=p.search(t);if(f){if(o+=1,s+=T,i){const g=p.constructor.type;iT.has(g)?r=[...r,...u]:r.push(u)}}else{s=0,o=0,r.length=0;break}}if(o){let h={isMatch:!0,score:s/o};return i&&(h.indices=r),h}}return{isMatch:!1,score:1}}}const Md=[];function oT(...e){Md.push(...e)}function Ld(e,t){for(let n=0,i=Md.length;n<i;n+=1){let a=Md[n];if(a.condition(e,t))return new a(e,t)}return new H_(e,t)}const vs={AND:"$and",OR:"$or"},Fd={PATH:"$path",PATTERN:"$val"},Ud=e=>!!(e[vs.AND]||e[vs.OR]),rT=e=>!!e[Fd.PATH],sT=e=>!Sn(e)&&U_(e)&&!Ud(e),Of=e=>({[vs.AND]:Object.keys(e).map(t=>({[t]:e[t]}))});function K_(e,t,{auto:n=!0}={}){const i=a=>{let o=Object.keys(a);const r=rT(a);if(!r&&o.length>1&&!Ud(a))return i(Of(a));if(sT(a)){const l=r?a[Fd.PATH]:o[0],c=r?a[Fd.PATTERN]:a[l];if(!ln(c))throw new Error(A6(l));const d={keyId:Wd(l),pattern:c};return n&&(d.searcher=Ld(c,t)),d}let s={children:[],operator:o[0]};return o.forEach(l=>{const c=a[l];Sn(c)&&c.forEach(d=>{s.children.push(i(d))})}),s};return Ud(e)||(e=Of(e)),i(e)}function lT(e,{ignoreFieldNorm:t=H.ignoreFieldNorm}){e.forEach(n=>{let i=1;n.matches.forEach(({key:a,norm:o,score:r})=>{const s=a?a.weight:null;i*=Math.pow(r===0&&s?Number.EPSILON:r,(s||1)*(t?1:o))}),n.score=i})}function cT(e,t){const n=e.matches;t.matches=[],vt(n)&&n.forEach(i=>{if(!vt(i.indices)||!i.indices.length)return;const{indices:a,value:o}=i;let r={indices:a,value:o};i.key&&(r.key=i.key.src),i.idx>-1&&(r.refIndex=i.idx),t.matches.push(r)})}function dT(e,t){t.score=e.score}function uT(e,t,{includeMatches:n=H.includeMatches,includeScore:i=H.includeScore}={}){const a=[];return n&&a.push(cT),i&&a.push(dT),e.map(o=>{const{idx:r}=o,s={item:t[r],refIndex:r};return a.length&&a.forEach(l=>{l(o,s)}),s})}class Na{constructor(t,n={},i){this.options={...H,...n},this.options.useExtendedSearch,this._keyStore=new O6(this.options.keys),this.setCollection(t,i)}setCollection(t,n){if(this._docs=t,n&&!(n instanceof vp))throw new Error(E6);this._myIndex=n||V_(this.options.keys,this._docs,{getFn:this.options.getFn,fieldNormWeight:this.options.fieldNormWeight})}add(t){vt(t)&&(this._docs.push(t),this._myIndex.add(t))}remove(t=()=>!1){const n=[];for(let i=0,a=this._docs.length;i<a;i+=1){const o=this._docs[i];t(o,i)&&(this.removeAt(i),i-=1,a-=1,n.push(o))}return n}removeAt(t){this._docs.splice(t,1),this._myIndex.removeAt(t)}getIndex(){return this._myIndex}search(t,{limit:n=-1}={}){const{includeMatches:i,includeScore:a,shouldSort:o,sortFn:r,ignoreFieldNorm:s}=this.options;let l=ln(t)?ln(this._docs[0])?this._searchStringList(t):this._searchObjectList(t):this._searchLogical(t);return lT(l,{ignoreFieldNorm:s}),o&&l.sort(r),F_(n)&&n>-1&&(l=l.slice(0,n)),uT(l,this._docs,{includeMatches:i,includeScore:a})}_searchStringList(t){const n=Ld(t,this.options),{records:i}=this._myIndex,a=[];return i.forEach(({v:o,i:r,n:s})=>{if(!vt(o))return;const{isMatch:l,score:c,indices:d}=n.searchIn(o);l&&a.push({item:o,idx:r,matches:[{score:c,value:o,norm:s,indices:d}]})}),a}_searchLogical(t){const n=K_(t,this.options),i=(s,l,c)=>{if(!s.children){const{keyId:h,searcher:y}=s,p=this._findMatches({key:this._keyStore.get(h),value:this._myIndex.getValueForItemAtKeyId(l,h),searcher:y});return p&&p.length?[{idx:c,item:l,matches:p}]:[]}const d=[];for(let h=0,y=s.children.length;h<y;h+=1){const p=s.children[h],f=i(p,l,c);if(f.length)d.push(...f);else if(s.operator===vs.AND)return[]}return d},a=this._myIndex.records,o={},r=[];return a.forEach(({$:s,i:l})=>{if(vt(s)){let c=i(n,s,l);c.length&&(o[l]||(o[l]={idx:l,item:s,matches:[]},r.push(o[l])),c.forEach(({matches:d})=>{o[l].matches.push(...d)}))}}),r}_searchObjectList(t){const n=Ld(t,this.options),{keys:i,records:a}=this._myIndex,o=[];return a.forEach(({$:r,i:s})=>{if(!vt(r))return;let l=[];i.forEach((c,d)=>{l.push(...this._findMatches({key:c,value:r[d],searcher:n}))}),l.length&&o.push({idx:s,item:r,matches:l})}),o}_findMatches({key:t,value:n,searcher:i}){if(!vt(n))return[];let a=[];if(Sn(n))n.forEach(({v:o,i:r,n:s})=>{if(!vt(o))return;const{isMatch:l,score:c,indices:d}=i.searchIn(o);l&&a.push({score:c,key:t,value:o,idx:r,norm:s,indices:d})});else{const{v:o,n:r}=n,{isMatch:s,score:l,indices:c}=i.searchIn(o);s&&a.push({score:l,key:t,value:o,norm:r,indices:c})}return a}}Na.version="6.6.2";Na.createIndex=V_;Na.parseIndex=G6;Na.config=H;Na.parseQuery=K_;oT(aT);const X_=v.createContext(),Yo=()=>v.useContext(X_),pT=({children:e})=>{const[t,n]=v.useState(""),[i,a]=v.useState(),[o,r]=v.useState(!1);return m.jsx(X_.Provider,{value:{searchQuery:t,setSearchQuery:n,searchResults:i,setSearchResults:a,isSearchSubmitted:o,setIsSearchSubmitted:r},children:e})};function Y_(e,t){const n=JSON.parse(e);let i=[];function a(s,l){if(typeof l=="string"&&l.toLowerCase().includes(t.toLowerCase()))return l.trim();if(typeof l=="object")for(const c in l){const d=a(c,l[c]);c>0&&typeof d=="string"?i.push(s+": "+l[(c-"1").toString()]+" "+d):c==0&&l.length>1&&typeof d=="string"?i.push(s+": "+d+" "+l[1]):typeof d=="string"&&i.push(c+": "+d)}}for(const s in n)a(s,n[s]);const o=i[0];let r=[];try{const s=o.toLowerCase(),l=t.toLowerCase(),c=s.indexOf(l);if(c!==-1){const d=o.substring(0,c),h=o.substring(c,c+l.length),y=o.substring(c+l.length);r=[d,h,y]}}catch{r=[null,null,null]}return r}const mT=fn.plugins;let zf=["name","metadata.description","entry_point_prefix","metadata.author"];function fT(e){const t=[],n=JSON.parse(JSON.stringify(e));return Object.entries(n).forEach(([a,o])=>{Object.entries(o.entry_points).forEach(([r,s])=>{for(const l in s){let c=["entry_points",r,l];o.entry_points[r][l]=JSON.stringify(o.entry_points[r][l]),zf.push(c)}}),t.push(o)}),new Na(t,{keys:zf,includeScore:!0,ignoreLocation:!0,threshold:.1,includeMatches:!0})}const hT=fT(mT);function yT(){const{searchQuery:e,setSearchQuery:t,setSearchResults:n,isSearchSubmitted:i,setIsSearchSubmitted:a}=Yo(),o=l=>{t(l),document.querySelector(".suggestions-list").style.display="block",document.querySelector(".dropdown-search").style.display="block",(l==""||i==!0)&&(a(!1),document.querySelector(".dropdown-search").style.display="none");const c=document.querySelector(".enter-symbol");c&&(c.style.opacity=l?"1":"0")};let r=hT.search(e);const s=l=>{l.preventDefault(),e&&(n(r),a(!0),document.querySelector(".suggestions-list").style.display="none",document.querySelector(".dropdown-search").style.display="none")};return m.jsx(m.Fragment,{children:m.jsxs("div",{className:"search",children:[m.jsxs("form",{className:"search-form",children:[m.jsx("button",{style:{fontSize:"20px",minWidth:"90px",backgroundColor:"white",border:"1px solid #ccc",borderRadius:"4px"},onClick:l=>{s(l)},children:m.jsx(M_,{})}),m.jsxs("div",{className:"input-container",children:[m.jsx("input",{type:"text",placeholder:"Search for plugins",value:e,label:"search",onChange:l=>o(l.target.value)}),m.jsx(L_,{className:"enter-symbol"})]})]}),m.jsxs("ul",{className:"suggestions-list",children:[r.slice(0,3).map(l=>m.jsxs(m.Fragment,{children:[m.jsx(Ri,{to:`/${l.item.name}`,children:m.jsxs("h3",{className:"suggestion-item",children:[l.item.name," "]},l.item.name)}),m.jsx("ul",{children:l.matches.filter(c=>typeof c.key=="object").slice(0,1).map(c=>m.jsxs(m.Fragment,{children:[m.jsx(Ri,{to:`/${l.item.name}#${c.key[1]}.${c.key[2]}`,children:m.jsxs("li",{className:"suggestion-item",children:[c.key[2]," "]},c.key)}),m.jsx(J_,{match_value:c.value})]}))})]})),m.jsx("button",{className:"dropdown-search",onClick:l=>{s(l)},children:" Search"})]})]})})}function gT(){const{searchResults:e,searchQuery:t}=Yo();return m.jsxs(m.Fragment,{children:[m.jsxs("h2",{children:["Showing ",e.length," pages matching the search query."]}),e.length===0&&m.jsx("div",{children:m.jsxs("h3",{className:"submenu-entry",style:{textAlign:"center",color:"black"},children:["Can't find what you're looking for?",m.jsx("br",{}),"Join the AiiDA community on Discourse and request a plugin ",m.jsx("a",{href:"https://aiida.discourse.group/new-topic?title=Request%20for%20Plugin...&category=community/plugin-requests",target:"_blank",children:"here."})]})}),e.map(n=>m.jsx(m.Fragment,{children:m.jsxs("div",{className:"submenu-entry",children:[m.jsx(Ri,{to:`/${n.item.name}`,children:m.jsx("h3",{className:"suggestion-item",children:n.item.name},n.item.name)}),m.jsx("ul",{children:n.matches.filter(i=>typeof i.key=="object").map(i=>m.jsx(m.Fragment,{children:Y_(i.value,t)[0]!=null&&m.jsxs(m.Fragment,{children:[m.jsx(Ri,{to:`/${n.item.name}#${i.key[1]}.${i.key[2]}`,children:m.jsx("li",{className:"suggestion-item",children:i.key[2]},i.key)}),m.jsx(J_,{match_value:i.value})]})}))})]})}))]})}function J_({match_value:e}){const{searchQuery:t}=Yo(),[n,i,a]=Y_(e,t);return m.jsx(m.Fragment,{children:n!=null&&m.jsxs("p",{children:[n,m.jsx("span",{style:{backgroundColor:"yellow"},children:i}),a,"..."]})})}function Ra(){const e=Tl(Cl);return e[Xo]||e}const _T=e=>{let t;return e<1?t=5.11916*e**2:t=4.5*Math.log(e+1)+2,(t/100).toFixed(2)},Wf=_T,bT=W_(),vT=u3({themeId:Xo,defaultTheme:bT,defaultClassName:"MuiBox-root",generateClassName:np.generate}),wT=vT;function Jo({props:e,states:t,muiFormControl:n}){return t.reduce((i,a)=>(i[a]=e[a],n&&typeof e[a]>"u"&&(i[a]=n[a]),i),{})}const xT=v.createContext(void 0),wp=xT;function er(){return v.useContext(wp)}function TT(e){return me("MuiFormLabel",e)}const kT=re("MuiFormLabel",["root","colorSecondary","focused","disabled","error","filled","required","asterisk"]),yo=kT,CT=["children","className","color","component","disabled","error","filled","focused","required"],IT=e=>{const{classes:t,color:n,focused:i,disabled:a,error:o,filled:r,required:s}=e,l={root:["root",`color${Z(n)}`,a&&"disabled",o&&"error",r&&"filled",i&&"focused",s&&"required"],asterisk:["asterisk",o&&"error"]};return fe(l,TT,t)},qT=F("label",{name:"MuiFormLabel",slot:"Root",overridesResolver:({ownerState:e},t)=>k({},t.root,e.color==="secondary"&&t.colorSecondary,e.filled&&t.filled)})(({theme:e,ownerState:t})=>k({color:(e.vars||e).palette.text.secondary},e.typography.body1,{lineHeight:"1.4375em",padding:0,position:"relative",[`&.${yo.focused}`]:{color:(e.vars||e).palette[t.color].main},[`&.${yo.disabled}`]:{color:(e.vars||e).palette.text.disabled},[`&.${yo.error}`]:{color:(e.vars||e).palette.error.main}})),DT=F("span",{name:"MuiFormLabel",slot:"Asterisk",overridesResolver:(e,t)=>t.asterisk})(({theme:e})=>({[`&.${yo.error}`]:{color:(e.vars||e).palette.error.main}})),PT=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiFormLabel"}),{children:a,className:o,component:r="label"}=i,s=U(i,CT),l=er(),c=Jo({props:i,muiFormControl:l,states:["color","required","focused","disabled","error","filled"]}),d=k({},i,{color:c.color||"primary",component:r,disabled:c.disabled,error:c.error,filled:c.filled,focused:c.focused,required:c.required}),h=IT(d);return m.jsxs(qT,k({as:r,ownerState:d,className:V(h.root,o),ref:n},s,{children:[a,c.required&&m.jsxs(DT,{ownerState:d,"aria-hidden":!0,className:h.asterisk,children:[" ","*"]})]}))}),ST=PT;function ET(e){return me("MuiInputLabel",e)}re("MuiInputLabel",["root","focused","disabled","error","required","asterisk","formControl","sizeSmall","shrink","animated","standard","filled","outlined"]);const AT=["disableAnimation","margin","shrink","variant","className"],NT=e=>{const{classes:t,formControl:n,size:i,shrink:a,disableAnimation:o,variant:r,required:s}=e,l={root:["root",n&&"formControl",!o&&"animated",a&&"shrink",i&&i!=="normal"&&`size${Z(i)}`,r],asterisk:[s&&"asterisk"]},c=fe(l,ET,t);return k({},t,c)},RT=F(ST,{shouldForwardProp:e=>Yt(e)||e==="classes",name:"MuiInputLabel",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[{[`& .${yo.asterisk}`]:t.asterisk},t.root,n.formControl&&t.formControl,n.size==="small"&&t.sizeSmall,n.shrink&&t.shrink,!n.disableAnimation&&t.animated,t[n.variant]]}})(({theme:e,ownerState:t})=>k({display:"block",transformOrigin:"top left",whiteSpace:"nowrap",overflow:"hidden",textOverflow:"ellipsis",maxWidth:"100%"},t.formControl&&{position:"absolute",left:0,top:0,transform:"translate(0, 20px) scale(1)"},t.size==="small"&&{transform:"translate(0, 17px) scale(1)"},t.shrink&&{transform:"translate(0, -1.5px) scale(0.75)",transformOrigin:"top left",maxWidth:"133%"},!t.disableAnimation&&{transition:e.transitions.create(["color","transform","max-width"],{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut})},t.variant==="filled"&&k({zIndex:1,pointerEvents:"none",transform:"translate(12px, 16px) scale(1)",maxWidth:"calc(100% - 24px)"},t.size==="small"&&{transform:"translate(12px, 13px) scale(1)"},t.shrink&&k({userSelect:"none",pointerEvents:"auto",transform:"translate(12px, 7px) scale(0.75)",maxWidth:"calc(133% - 24px)"},t.size==="small"&&{transform:"translate(12px, 4px) scale(0.75)"})),t.variant==="outlined"&&k({zIndex:1,pointerEvents:"none",transform:"translate(14px, 16px) scale(1)",maxWidth:"calc(100% - 24px)"},t.size==="small"&&{transform:"translate(14px, 9px) scale(1)"},t.shrink&&{userSelect:"none",pointerEvents:"auto",maxWidth:"calc(133% - 32px)",transform:"translate(14px, -9px) scale(0.75)"}))),BT=v.forwardRef(function(t,n){const i=he({name:"MuiInputLabel",props:t}),{disableAnimation:a=!1,shrink:o,className:r}=i,s=U(i,AT),l=er();let c=o;typeof c>"u"&&l&&(c=l.filled||l.focused||l.adornedStart);const d=Jo({props:i,muiFormControl:l,states:["size","variant","required"]}),h=k({},i,{disableAnimation:a,formControl:l,shrink:c,size:d.size,variant:d.variant,required:d.required}),y=NT(h);return m.jsx(RT,k({"data-shrink":c,ownerState:h,ref:n,className:V(y.root,r)},s,{classes:y}))}),OT=BT,zT=v.createContext({}),Gd=zT;function $d(e,t){return $d=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(i,a){return i.__proto__=a,i},$d(e,t)}function eb(e,t){e.prototype=Object.create(t.prototype),e.prototype.constructor=e,$d(e,t)}const jf={disabled:!1},ws=Zt.createContext(null);var WT=function(t){return t.scrollTop},no="unmounted",yi="exited",gi="entering",Zi="entered",Vd="exiting",Nn=function(e){eb(t,e);function t(i,a){var o;o=e.call(this,i,a)||this;var r=a,s=r&&!r.isMounting?i.enter:i.appear,l;return o.appearStatus=null,i.in?s?(l=yi,o.appearStatus=gi):l=Zi:i.unmountOnExit||i.mountOnEnter?l=no:l=yi,o.state={status:l},o.nextCallback=null,o}t.getDerivedStateFromProps=function(a,o){var r=a.in;return r&&o.status===no?{status:yi}:null};var n=t.prototype;return n.componentDidMount=function(){this.updateStatus(!0,this.appearStatus)},n.componentDidUpdate=function(a){var o=null;if(a!==this.props){var r=this.state.status;this.props.in?r!==gi&&r!==Zi&&(o=gi):(r===gi||r===Zi)&&(o=Vd)}this.updateStatus(!1,o)},n.componentWillUnmount=function(){this.cancelNextCallback()},n.getTimeouts=function(){var a=this.props.timeout,o,r,s;return o=r=s=a,a!=null&&typeof a!="number"&&(o=a.exit,r=a.enter,s=a.appear!==void 0?a.appear:r),{exit:o,enter:r,appear:s}},n.updateStatus=function(a,o){if(a===void 0&&(a=!1),o!==null)if(this.cancelNextCallback(),o===gi){if(this.props.unmountOnExit||this.props.mountOnEnter){var r=this.props.nodeRef?this.props.nodeRef.current:br.findDOMNode(this);r&&WT(r)}this.performEnter(a)}else this.performExit();else this.props.unmountOnExit&&this.state.status===yi&&this.setState({status:no})},n.performEnter=function(a){var o=this,r=this.props.enter,s=this.context?this.context.isMounting:a,l=this.props.nodeRef?[s]:[br.findDOMNode(this),s],c=l[0],d=l[1],h=this.getTimeouts(),y=s?h.appear:h.enter;if(!a&&!r||jf.disabled){this.safeSetState({status:Zi},function(){o.props.onEntered(c)});return}this.props.onEnter(c,d),this.safeSetState({status:gi},function(){o.props.onEntering(c,d),o.onTransitionEnd(y,function(){o.safeSetState({status:Zi},function(){o.props.onEntered(c,d)})})})},n.performExit=function(){var a=this,o=this.props.exit,r=this.getTimeouts(),s=this.props.nodeRef?void 0:br.findDOMNode(this);if(!o||jf.disabled){this.safeSetState({status:yi},function(){a.props.onExited(s)});return}this.props.onExit(s),this.safeSetState({status:Vd},function(){a.props.onExiting(s),a.onTransitionEnd(r.exit,function(){a.safeSetState({status:yi},function(){a.props.onExited(s)})})})},n.cancelNextCallback=function(){this.nextCallback!==null&&(this.nextCallback.cancel(),this.nextCallback=null)},n.safeSetState=function(a,o){o=this.setNextCallback(o),this.setState(a,o)},n.setNextCallback=function(a){var o=this,r=!0;return this.nextCallback=function(s){r&&(r=!1,o.nextCallback=null,a(s))},this.nextCallback.cancel=function(){r=!1},this.nextCallback},n.onTransitionEnd=function(a,o){this.setNextCallback(o);var r=this.props.nodeRef?this.props.nodeRef.current:br.findDOMNode(this),s=a==null&&!this.props.addEndListener;if(!r||s){setTimeout(this.nextCallback,0);return}if(this.props.addEndListener){var l=this.props.nodeRef?[this.nextCallback]:[r,this.nextCallback],c=l[0],d=l[1];this.props.addEndListener(c,d)}a!=null&&setTimeout(this.nextCallback,a)},n.render=function(){var a=this.state.status;if(a===no)return null;var o=this.props,r=o.children;o.in,o.mountOnEnter,o.unmountOnExit,o.appear,o.enter,o.exit,o.timeout,o.addEndListener,o.onEnter,o.onEntering,o.onEntered,o.onExit,o.onExiting,o.onExited,o.nodeRef;var s=U(o,["children","in","mountOnEnter","unmountOnExit","appear","enter","exit","timeout","addEndListener","onEnter","onEntering","onEntered","onExit","onExiting","onExited","nodeRef"]);return Zt.createElement(ws.Provider,{value:null},typeof r=="function"?r(a,s):Zt.cloneElement(Zt.Children.only(r),s))},t}(Zt.Component);Nn.contextType=ws;Nn.propTypes={};function Vi(){}Nn.defaultProps={in:!1,mountOnEnter:!1,unmountOnExit:!1,appear:!1,enter:!0,exit:!0,onEnter:Vi,onEntering:Vi,onEntered:Vi,onExit:Vi,onExiting:Vi,onExited:Vi};Nn.UNMOUNTED=no;Nn.EXITED=yi;Nn.ENTERING=gi;Nn.ENTERED=Zi;Nn.EXITING=Vd;const xp=Nn;function jT(e){if(e===void 0)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}function Tp(e,t){var n=function(o){return t&&v.isValidElement(o)?t(o):o},i=Object.create(null);return e&&v.Children.map(e,function(a){return a}).forEach(function(a){i[a.key]=n(a)}),i}function MT(e,t){e=e||{},t=t||{};function n(d){return d in t?t[d]:e[d]}var i=Object.create(null),a=[];for(var o in e)o in t?a.length&&(i[o]=a,a=[]):a.push(o);var r,s={};for(var l in t){if(i[l])for(r=0;r<i[l].length;r++){var c=i[l][r];s[i[l][r]]=n(c)}s[l]=n(l)}for(r=0;r<a.length;r++)s[a[r]]=n(a[r]);return s}function Ii(e,t,n){return n[t]!=null?n[t]:e.props[t]}function LT(e,t){return Tp(e.children,function(n){return v.cloneElement(n,{onExited:t.bind(null,n),in:!0,appear:Ii(n,"appear",e),enter:Ii(n,"enter",e),exit:Ii(n,"exit",e)})})}function FT(e,t,n){var i=Tp(e.children),a=MT(t,i);return Object.keys(a).forEach(function(o){var r=a[o];if(v.isValidElement(r)){var s=o in t,l=o in i,c=t[o],d=v.isValidElement(c)&&!c.props.in;l&&(!s||d)?a[o]=v.cloneElement(r,{onExited:n.bind(null,r),in:!0,exit:Ii(r,"exit",e),enter:Ii(r,"enter",e)}):!l&&s&&!d?a[o]=v.cloneElement(r,{in:!1}):l&&s&&v.isValidElement(c)&&(a[o]=v.cloneElement(r,{onExited:n.bind(null,r),in:c.props.in,exit:Ii(r,"exit",e),enter:Ii(r,"enter",e)}))}}),a}var UT=Object.values||function(e){return Object.keys(e).map(function(t){return e[t]})},GT={component:"div",childFactory:function(t){return t}},kp=function(e){eb(t,e);function t(i,a){var o;o=e.call(this,i,a)||this;var r=o.handleExited.bind(jT(o));return o.state={contextValue:{isMounting:!0},handleExited:r,firstRender:!0},o}var n=t.prototype;return n.componentDidMount=function(){this.mounted=!0,this.setState({contextValue:{isMounting:!1}})},n.componentWillUnmount=function(){this.mounted=!1},t.getDerivedStateFromProps=function(a,o){var r=o.children,s=o.handleExited,l=o.firstRender;return{children:l?LT(a,s):FT(a,r,s),firstRender:!1}},n.handleExited=function(a,o){var r=Tp(this.props.children);a.key in r||(a.props.onExited&&a.props.onExited(o),this.mounted&&this.setState(function(s){var l=k({},s.children);return delete l[a.key],{children:l}}))},n.render=function(){var a=this.props,o=a.component,r=a.childFactory,s=U(a,["component","childFactory"]),l=this.state.contextValue,c=UT(this.state.children).map(r);return delete s.appear,delete s.enter,delete s.exit,o===null?Zt.createElement(ws.Provider,{value:l},c):Zt.createElement(ws.Provider,{value:l},Zt.createElement(o,s,c))},t}(Zt.Component);kp.propTypes={};kp.defaultProps=GT;const $T=kp;function VT(e){const{className:t,classes:n,pulsate:i=!1,rippleX:a,rippleY:o,rippleSize:r,in:s,onExited:l,timeout:c}=e,[d,h]=v.useState(!1),y=V(t,n.ripple,n.rippleVisible,i&&n.ripplePulsate),p={width:r,height:r,top:-(r/2)+o,left:-(r/2)+a},f=V(n.child,d&&n.childLeaving,i&&n.childPulsate);return!s&&!d&&h(!0),v.useEffect(()=>{if(!s&&l!=null){const u=setTimeout(l,c);return()=>{clearTimeout(u)}}},[l,s,c]),m.jsx("span",{className:y,style:p,children:m.jsx("span",{className:f})})}const HT=re("MuiTouchRipple",["root","ripple","rippleVisible","ripplePulsate","child","childLeaving","childPulsate"]),Nt=HT,ZT=["center","classes","className"];let Il=e=>e,Mf,Lf,Ff,Uf;const Hd=550,QT=80,KT=up(Mf||(Mf=Il`
  0% {
    transform: scale(0);
    opacity: 0.1;
  }

  100% {
    transform: scale(1);
    opacity: 0.3;
  }
`)),XT=up(Lf||(Lf=Il`
  0% {
    opacity: 1;
  }

  100% {
    opacity: 0;
  }
`)),YT=up(Ff||(Ff=Il`
  0% {
    transform: scale(1);
  }

  50% {
    transform: scale(0.92);
  }

  100% {
    transform: scale(1);
  }
`)),JT=F("span",{name:"MuiTouchRipple",slot:"Root"})({overflow:"hidden",pointerEvents:"none",position:"absolute",zIndex:0,top:0,right:0,bottom:0,left:0,borderRadius:"inherit"}),ek=F(VT,{name:"MuiTouchRipple",slot:"Ripple"})(Uf||(Uf=Il`
  opacity: 0;
  position: absolute;

  &.${0} {
    opacity: 0.3;
    transform: scale(1);
    animation-name: ${0};
    animation-duration: ${0}ms;
    animation-timing-function: ${0};
  }

  &.${0} {
    animation-duration: ${0}ms;
  }

  & .${0} {
    opacity: 1;
    display: block;
    width: 100%;
    height: 100%;
    border-radius: 50%;
    background-color: currentColor;
  }

  & .${0} {
    opacity: 0;
    animation-name: ${0};
    animation-duration: ${0}ms;
    animation-timing-function: ${0};
  }

  & .${0} {
    position: absolute;
    /* @noflip */
    left: 0px;
    top: 0;
    animation-name: ${0};
    animation-duration: 2500ms;
    animation-timing-function: ${0};
    animation-iteration-count: infinite;
    animation-delay: 200ms;
  }
`),Nt.rippleVisible,KT,Hd,({theme:e})=>e.transitions.easing.easeInOut,Nt.ripplePulsate,({theme:e})=>e.transitions.duration.shorter,Nt.child,Nt.childLeaving,XT,Hd,({theme:e})=>e.transitions.easing.easeInOut,Nt.childPulsate,YT,({theme:e})=>e.transitions.easing.easeInOut),tk=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiTouchRipple"}),{center:a=!1,classes:o={},className:r}=i,s=U(i,ZT),[l,c]=v.useState([]),d=v.useRef(0),h=v.useRef(null);v.useEffect(()=>{h.current&&(h.current(),h.current=null)},[l]);const y=v.useRef(!1),p=v.useRef(0),f=v.useRef(null),u=v.useRef(null);v.useEffect(()=>()=>{p.current&&clearTimeout(p.current)},[]);const T=v.useCallback(w=>{const{pulsate:C,rippleX:I,rippleY:x,rippleSize:q,cb:S}=w;c(P=>[...P,m.jsx(ek,{classes:{ripple:V(o.ripple,Nt.ripple),rippleVisible:V(o.rippleVisible,Nt.rippleVisible),ripplePulsate:V(o.ripplePulsate,Nt.ripplePulsate),child:V(o.child,Nt.child),childLeaving:V(o.childLeaving,Nt.childLeaving),childPulsate:V(o.childPulsate,Nt.childPulsate)},timeout:Hd,pulsate:C,rippleX:I,rippleY:x,rippleSize:q},d.current)]),d.current+=1,h.current=S},[o]),g=v.useCallback((w={},C={},I=()=>{})=>{const{pulsate:x=!1,center:q=a||C.pulsate,fakeElement:S=!1}=C;if((w==null?void 0:w.type)==="mousedown"&&y.current){y.current=!1;return}(w==null?void 0:w.type)==="touchstart"&&(y.current=!0);const P=S?null:u.current,R=P?P.getBoundingClientRect():{width:0,height:0,left:0,top:0};let O,M,A;if(q||w===void 0||w.clientX===0&&w.clientY===0||!w.clientX&&!w.touches)O=Math.round(R.width/2),M=Math.round(R.height/2);else{const{clientX:B,clientY:z}=w.touches&&w.touches.length>0?w.touches[0]:w;O=Math.round(B-R.left),M=Math.round(z-R.top)}if(q)A=Math.sqrt((2*R.width**2+R.height**2)/3),A%2===0&&(A+=1);else{const B=Math.max(Math.abs((P?P.clientWidth:0)-O),O)*2+2,z=Math.max(Math.abs((P?P.clientHeight:0)-M),M)*2+2;A=Math.sqrt(B**2+z**2)}w!=null&&w.touches?f.current===null&&(f.current=()=>{T({pulsate:x,rippleX:O,rippleY:M,rippleSize:A,cb:I})},p.current=setTimeout(()=>{f.current&&(f.current(),f.current=null)},QT)):T({pulsate:x,rippleX:O,rippleY:M,rippleSize:A,cb:I})},[a,T]),_=v.useCallback(()=>{g({},{pulsate:!0})},[g]),b=v.useCallback((w,C)=>{if(clearTimeout(p.current),(w==null?void 0:w.type)==="touchend"&&f.current){f.current(),f.current=null,p.current=setTimeout(()=>{b(w,C)});return}f.current=null,c(I=>I.length>0?I.slice(1):I),h.current=C},[]);return v.useImperativeHandle(n,()=>({pulsate:_,start:g,stop:b}),[_,g,b]),m.jsx(JT,k({className:V(Nt.root,o.root,r),ref:u},s,{children:m.jsx($T,{component:null,exit:!0,children:l})}))}),nk=tk;function ik(e){return me("MuiButtonBase",e)}const ak=re("MuiButtonBase",["root","disabled","focusVisible"]),ok=ak,rk=["action","centerRipple","children","className","component","disabled","disableRipple","disableTouchRipple","focusRipple","focusVisibleClassName","LinkComponent","onBlur","onClick","onContextMenu","onDragLeave","onFocus","onFocusVisible","onKeyDown","onKeyUp","onMouseDown","onMouseLeave","onMouseUp","onTouchEnd","onTouchMove","onTouchStart","tabIndex","TouchRippleProps","touchRippleRef","type"],sk=e=>{const{disabled:t,focusVisible:n,focusVisibleClassName:i,classes:a}=e,r=fe({root:["root",t&&"disabled",n&&"focusVisible"]},ik,a);return n&&i&&(r.root+=` ${i}`),r},lk=F("button",{name:"MuiButtonBase",slot:"Root",overridesResolver:(e,t)=>t.root})({display:"inline-flex",alignItems:"center",justifyContent:"center",position:"relative",boxSizing:"border-box",WebkitTapHighlightColor:"transparent",backgroundColor:"transparent",outline:0,border:0,margin:0,borderRadius:0,padding:0,cursor:"pointer",userSelect:"none",verticalAlign:"middle",MozAppearance:"none",WebkitAppearance:"none",textDecoration:"none",color:"inherit","&::-moz-focus-inner":{borderStyle:"none"},[`&.${ok.disabled}`]:{pointerEvents:"none",cursor:"default"},"@media print":{colorAdjust:"exact"}}),ck=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiButtonBase"}),{action:a,centerRipple:o=!1,children:r,className:s,component:l="button",disabled:c=!1,disableRipple:d=!1,disableTouchRipple:h=!1,focusRipple:y=!1,LinkComponent:p="a",onBlur:f,onClick:u,onContextMenu:T,onDragLeave:g,onFocus:_,onFocusVisible:b,onKeyDown:w,onKeyUp:C,onMouseDown:I,onMouseLeave:x,onMouseUp:q,onTouchEnd:S,onTouchMove:P,onTouchStart:R,tabIndex:O=0,TouchRippleProps:M,touchRippleRef:A,type:B}=i,z=U(i,rk),L=v.useRef(null),D=v.useRef(null),N=Xe(D,A),{isFocusVisibleRef:W,onFocus:te,onBlur:Q,ref:Re}=d_(),[J,we]=v.useState(!1);c&&J&&we(!1),v.useImperativeHandle(a,()=>({focusVisible:()=>{we(!0),L.current.focus()}}),[]);const[le,$e]=v.useState(!1);v.useEffect(()=>{$e(!0)},[]);const Pt=le&&!d&&!c;v.useEffect(()=>{J&&y&&!d&&le&&D.current.pulsate()},[d,y,J,le]);function Be($,gn,Ba=h){return Ci(G=>(gn&&gn(G),!Ba&&D.current&&D.current[$](G),!0))}const ct=Be("start",I),oe=Be("stop",T),Ie=Be("stop",g),X=Be("stop",q),ue=Be("stop",$=>{J&&$.preventDefault(),x&&x($)}),xe=Be("start",R),Rn=Be("stop",S),St=Be("stop",P),Et=Be("stop",$=>{Q($),W.current===!1&&we(!1),f&&f($)},!1),Ut=Ci($=>{L.current||(L.current=$.currentTarget),te($),W.current===!0&&(we(!0),b&&b($)),_&&_($)}),At=()=>{const $=L.current;return l&&l!=="button"&&!($.tagName==="A"&&$.href)},qe=v.useRef(!1),hn=Ci($=>{y&&!qe.current&&J&&D.current&&$.key===" "&&(qe.current=!0,D.current.stop($,()=>{D.current.start($)})),$.target===$.currentTarget&&At()&&$.key===" "&&$.preventDefault(),w&&w($),$.target===$.currentTarget&&At()&&$.key==="Enter"&&!c&&($.preventDefault(),u&&u($))}),dt=Ci($=>{y&&$.key===" "&&D.current&&J&&!$.defaultPrevented&&(qe.current=!1,D.current.stop($,()=>{D.current.pulsate($)})),C&&C($),u&&$.target===$.currentTarget&&At()&&$.key===" "&&!$.defaultPrevented&&u($)});let Te=l;Te==="button"&&(z.href||z.to)&&(Te=p);const Jt={};Te==="button"?(Jt.type=B===void 0?"button":B,Jt.disabled=c):(!z.href&&!z.to&&(Jt.role="button"),c&&(Jt["aria-disabled"]=c));const Bn=Xe(n,Re,L),yn=k({},i,{centerRipple:o,component:l,disabled:c,disableRipple:d,disableTouchRipple:h,focusRipple:y,tabIndex:O,focusVisible:J}),ye=sk(yn);return m.jsxs(lk,k({as:Te,className:V(ye.root,s),ownerState:yn,onBlur:Et,onClick:u,onContextMenu:oe,onFocus:Ut,onKeyDown:hn,onKeyUp:dt,onMouseDown:ct,onMouseLeave:ue,onMouseUp:X,onDragLeave:Ie,onTouchEnd:Rn,onTouchMove:St,onTouchStart:xe,ref:Bn,tabIndex:c?-1:O,type:B},Jt,z,{children:[r,Pt?m.jsx(nk,k({ref:N,center:o},M)):null]}))}),tb=ck;function dk(e){return me("MuiDivider",e)}const uk=re("MuiDivider",["root","absolute","fullWidth","inset","middle","flexItem","light","vertical","withChildren","withChildrenVertical","textAlignRight","textAlignLeft","wrapper","wrapperVertical"]),Gf=uk,pk=["absolute","children","className","component","flexItem","light","orientation","role","textAlign","variant"],mk=e=>{const{absolute:t,children:n,classes:i,flexItem:a,light:o,orientation:r,textAlign:s,variant:l}=e;return fe({root:["root",t&&"absolute",l,o&&"light",r==="vertical"&&"vertical",a&&"flexItem",n&&"withChildren",n&&r==="vertical"&&"withChildrenVertical",s==="right"&&r!=="vertical"&&"textAlignRight",s==="left"&&r!=="vertical"&&"textAlignLeft"],wrapper:["wrapper",r==="vertical"&&"wrapperVertical"]},dk,i)},fk=F("div",{name:"MuiDivider",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.absolute&&t.absolute,t[n.variant],n.light&&t.light,n.orientation==="vertical"&&t.vertical,n.flexItem&&t.flexItem,n.children&&t.withChildren,n.children&&n.orientation==="vertical"&&t.withChildrenVertical,n.textAlign==="right"&&n.orientation!=="vertical"&&t.textAlignRight,n.textAlign==="left"&&n.orientation!=="vertical"&&t.textAlignLeft]}})(({theme:e,ownerState:t})=>k({margin:0,flexShrink:0,borderWidth:0,borderStyle:"solid",borderColor:(e.vars||e).palette.divider,borderBottomWidth:"thin"},t.absolute&&{position:"absolute",bottom:0,left:0,width:"100%"},t.light&&{borderColor:e.vars?`rgba(${e.vars.palette.dividerChannel} / 0.08)`:Tn(e.palette.divider,.08)},t.variant==="inset"&&{marginLeft:72},t.variant==="middle"&&t.orientation==="horizontal"&&{marginLeft:e.spacing(2),marginRight:e.spacing(2)},t.variant==="middle"&&t.orientation==="vertical"&&{marginTop:e.spacing(1),marginBottom:e.spacing(1)},t.orientation==="vertical"&&{height:"100%",borderBottomWidth:0,borderRightWidth:"thin"},t.flexItem&&{alignSelf:"stretch",height:"auto"}),({ownerState:e})=>k({},e.children&&{display:"flex",whiteSpace:"nowrap",textAlign:"center",border:0,"&::before, &::after":{content:'""',alignSelf:"center"}}),({theme:e,ownerState:t})=>k({},t.children&&t.orientation!=="vertical"&&{"&::before, &::after":{width:"100%",borderTop:`thin solid ${(e.vars||e).palette.divider}`}}),({theme:e,ownerState:t})=>k({},t.children&&t.orientation==="vertical"&&{flexDirection:"column","&::before, &::after":{height:"100%",borderLeft:`thin solid ${(e.vars||e).palette.divider}`}}),({ownerState:e})=>k({},e.textAlign==="right"&&e.orientation!=="vertical"&&{"&::before":{width:"90%"},"&::after":{width:"10%"}},e.textAlign==="left"&&e.orientation!=="vertical"&&{"&::before":{width:"10%"},"&::after":{width:"90%"}})),hk=F("span",{name:"MuiDivider",slot:"Wrapper",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.wrapper,n.orientation==="vertical"&&t.wrapperVertical]}})(({theme:e,ownerState:t})=>k({display:"inline-block",paddingLeft:`calc(${e.spacing(1)} * 1.2)`,paddingRight:`calc(${e.spacing(1)} * 1.2)`},t.orientation==="vertical"&&{paddingTop:`calc(${e.spacing(1)} * 1.2)`,paddingBottom:`calc(${e.spacing(1)} * 1.2)`})),nb=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiDivider"}),{absolute:a=!1,children:o,className:r,component:s=o?"div":"hr",flexItem:l=!1,light:c=!1,orientation:d="horizontal",role:h=s!=="hr"?"separator":void 0,textAlign:y="center",variant:p="fullWidth"}=i,f=U(i,pk),u=k({},i,{absolute:a,component:s,flexItem:l,light:c,orientation:d,role:h,textAlign:y,variant:p}),T=mk(u);return m.jsx(fk,k({as:s,className:V(T.root,r),role:h,ref:n,ownerState:u},f,{children:o?m.jsx(hk,{className:T.wrapper,ownerState:u,children:o}):null}))});nb.muiSkipListHighlight=!0;const $f=nb,yk=re("MuiListItemIcon",["root","alignItemsFlexStart"]),Vf=yk;function gk(e){return me("MuiTypography",e)}re("MuiTypography",["root","h1","h2","h3","h4","h5","h6","subtitle1","subtitle2","body1","body2","inherit","button","caption","overline","alignLeft","alignRight","alignCenter","alignJustify","noWrap","gutterBottom","paragraph"]);const _k=["align","className","component","gutterBottom","noWrap","paragraph","variant","variantMapping"],bk=e=>{const{align:t,gutterBottom:n,noWrap:i,paragraph:a,variant:o,classes:r}=e,s={root:["root",o,e.align!=="inherit"&&`align${Z(t)}`,n&&"gutterBottom",i&&"noWrap",a&&"paragraph"]};return fe(s,gk,r)},vk=F("span",{name:"MuiTypography",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.variant&&t[n.variant],n.align!=="inherit"&&t[`align${Z(n.align)}`],n.noWrap&&t.noWrap,n.gutterBottom&&t.gutterBottom,n.paragraph&&t.paragraph]}})(({theme:e,ownerState:t})=>k({margin:0},t.variant==="inherit"&&{font:"inherit"},t.variant!=="inherit"&&e.typography[t.variant],t.align!=="inherit"&&{textAlign:t.align},t.noWrap&&{overflow:"hidden",textOverflow:"ellipsis",whiteSpace:"nowrap"},t.gutterBottom&&{marginBottom:"0.35em"},t.paragraph&&{marginBottom:16})),Hf={h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",h6:"h6",subtitle1:"h6",subtitle2:"h6",body1:"p",body2:"p",inherit:"p"},wk={primary:"primary.main",textPrimary:"text.primary",secondary:"secondary.main",textSecondary:"text.secondary",error:"error.main"},xk=e=>wk[e]||e,Tk=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiTypography"}),a=xk(i.color),o=O_(k({},i,{color:a})),{align:r="inherit",className:s,component:l,gutterBottom:c=!1,noWrap:d=!1,paragraph:h=!1,variant:y="body1",variantMapping:p=Hf}=o,f=U(o,_k),u=k({},o,{align:r,color:a,className:s,component:l,gutterBottom:c,noWrap:d,paragraph:h,variant:y,variantMapping:p}),T=l||(h?"p":p[y]||Hf[y])||"span",g=bk(u);return m.jsx(vk,k({as:T,ref:n,ownerState:u,className:V(g.root,s)},f))}),ib=Tk,kk=re("MuiListItemText",["root","multiline","dense","inset","primary","secondary"]),Zf=kk;function Ck(e){return me("MuiMenuItem",e)}const Ik=re("MuiMenuItem",["root","focusVisible","dense","disabled","divider","gutters","selected"]),Ha=Ik,qk=["autoFocus","component","dense","divider","disableGutters","focusVisibleClassName","role","tabIndex","className"],Dk=(e,t)=>{const{ownerState:n}=e;return[t.root,n.dense&&t.dense,n.divider&&t.divider,!n.disableGutters&&t.gutters]},Pk=e=>{const{disabled:t,dense:n,divider:i,disableGutters:a,selected:o,classes:r}=e,l=fe({root:["root",n&&"dense",t&&"disabled",!a&&"gutters",i&&"divider",o&&"selected"]},Ck,r);return k({},r,l)},Sk=F(tb,{shouldForwardProp:e=>Yt(e)||e==="classes",name:"MuiMenuItem",slot:"Root",overridesResolver:Dk})(({theme:e,ownerState:t})=>k({},e.typography.body1,{display:"flex",justifyContent:"flex-start",alignItems:"center",position:"relative",textDecoration:"none",minHeight:48,paddingTop:6,paddingBottom:6,boxSizing:"border-box",whiteSpace:"nowrap"},!t.disableGutters&&{paddingLeft:16,paddingRight:16},t.divider&&{borderBottom:`1px solid ${(e.vars||e).palette.divider}`,backgroundClip:"padding-box"},{"&:hover":{textDecoration:"none",backgroundColor:(e.vars||e).palette.action.hover,"@media (hover: none)":{backgroundColor:"transparent"}},[`&.${Ha.selected}`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / ${e.vars.palette.action.selectedOpacity})`:Tn(e.palette.primary.main,e.palette.action.selectedOpacity),[`&.${Ha.focusVisible}`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / calc(${e.vars.palette.action.selectedOpacity} + ${e.vars.palette.action.focusOpacity}))`:Tn(e.palette.primary.main,e.palette.action.selectedOpacity+e.palette.action.focusOpacity)}},[`&.${Ha.selected}:hover`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / calc(${e.vars.palette.action.selectedOpacity} + ${e.vars.palette.action.hoverOpacity}))`:Tn(e.palette.primary.main,e.palette.action.selectedOpacity+e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / ${e.vars.palette.action.selectedOpacity})`:Tn(e.palette.primary.main,e.palette.action.selectedOpacity)}},[`&.${Ha.focusVisible}`]:{backgroundColor:(e.vars||e).palette.action.focus},[`&.${Ha.disabled}`]:{opacity:(e.vars||e).palette.action.disabledOpacity},[`& + .${Gf.root}`]:{marginTop:e.spacing(1),marginBottom:e.spacing(1)},[`& + .${Gf.inset}`]:{marginLeft:52},[`& .${Zf.root}`]:{marginTop:0,marginBottom:0},[`& .${Zf.inset}`]:{paddingLeft:36},[`& .${Vf.root}`]:{minWidth:36}},!t.dense&&{[e.breakpoints.up("sm")]:{minHeight:"auto"}},t.dense&&k({minHeight:32,paddingTop:4,paddingBottom:4},e.typography.body2,{[`& .${Vf.root} svg`]:{fontSize:"1.25rem"}}))),Ek=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiMenuItem"}),{autoFocus:a=!1,component:o="li",dense:r=!1,divider:s=!1,disableGutters:l=!1,focusVisibleClassName:c,role:d="menuitem",tabIndex:h,className:y}=i,p=U(i,qk),f=v.useContext(Gd),u=v.useMemo(()=>({dense:r||f.dense||!1,disableGutters:l}),[f.dense,r,l]),T=v.useRef(null);oi(()=>{a&&T.current&&T.current.focus()},[a]);const g=k({},i,{dense:u.dense,divider:s,disableGutters:l}),_=Pk(i),b=Xe(T,n);let w;return i.disabled||(w=h!==void 0?h:-1),m.jsx(Gd.Provider,{value:u,children:m.jsx(Sk,k({ref:b,role:d,tabIndex:w,component:o,focusVisibleClassName:V(_.focusVisible,c),className:V(_.root,y)},p,{ownerState:g,classes:_}))})}),gc=Ek;function Qf(e){return e!=null&&!(Array.isArray(e)&&e.length===0)}function xs(e,t=!1){return e&&(Qf(e.value)&&e.value!==""||t&&Qf(e.defaultValue)&&e.defaultValue!=="")}function Ak(e){return e.startAdornment}function Nk(e){return me("MuiFormControl",e)}re("MuiFormControl",["root","marginNone","marginNormal","marginDense","fullWidth","disabled"]);const Rk=["children","className","color","component","disabled","error","focused","fullWidth","hiddenLabel","margin","required","size","variant"],Bk=e=>{const{classes:t,margin:n,fullWidth:i}=e,a={root:["root",n!=="none"&&`margin${Z(n)}`,i&&"fullWidth"]};return fe(a,Nk,t)},Ok=F("div",{name:"MuiFormControl",slot:"Root",overridesResolver:({ownerState:e},t)=>k({},t.root,t[`margin${Z(e.margin)}`],e.fullWidth&&t.fullWidth)})(({ownerState:e})=>k({display:"inline-flex",flexDirection:"column",position:"relative",minWidth:0,padding:0,margin:0,border:0,verticalAlign:"top"},e.margin==="normal"&&{marginTop:16,marginBottom:8},e.margin==="dense"&&{marginTop:8,marginBottom:4},e.fullWidth&&{width:"100%"})),zk=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiFormControl"}),{children:a,className:o,color:r="primary",component:s="div",disabled:l=!1,error:c=!1,focused:d,fullWidth:h=!1,hiddenLabel:y=!1,margin:p="none",required:f=!1,size:u="medium",variant:T="outlined"}=i,g=U(i,Rk),_=k({},i,{color:r,component:s,disabled:l,error:c,fullWidth:h,hiddenLabel:y,margin:p,required:f,size:u,variant:T}),b=Bk(_),[w,C]=v.useState(()=>{let M=!1;return a&&v.Children.forEach(a,A=>{if(!Wr(A,["Input","Select"]))return;const B=Wr(A,["Select"])?A.props.input:A;B&&Ak(B.props)&&(M=!0)}),M}),[I,x]=v.useState(()=>{let M=!1;return a&&v.Children.forEach(a,A=>{Wr(A,["Input","Select"])&&(xs(A.props,!0)||xs(A.props.inputProps,!0))&&(M=!0)}),M}),[q,S]=v.useState(!1);l&&q&&S(!1);const P=d!==void 0&&!l?d:q;let R;const O=v.useMemo(()=>({adornedStart:w,setAdornedStart:C,color:r,disabled:l,error:c,filled:I,focused:P,fullWidth:h,hiddenLabel:y,size:u,onBlur:()=>{S(!1)},onEmpty:()=>{x(!1)},onFilled:()=>{x(!0)},onFocus:()=>{S(!0)},registerEffect:R,required:f,variant:T}),[w,r,l,c,I,P,h,y,R,f,u,T]);return m.jsx(wp.Provider,{value:O,children:m.jsx(Ok,k({as:s,ownerState:_,className:V(b.root,o),ref:n},g,{children:a}))})}),Wk=zk;function Ts(e){return typeof e=="string"}function jk(e,t,n){return e===void 0||Ts(e)?t:k({},t,{ownerState:k({},t.ownerState,n)})}function ab(e,t=[]){if(e===void 0)return{};const n={};return Object.keys(e).filter(i=>i.match(/^on[A-Z]/)&&typeof e[i]=="function"&&!t.includes(i)).forEach(i=>{n[i]=e[i]}),n}function Mk(e,t,n){return typeof e=="function"?e(t,n):e}function Kf(e){if(e===void 0)return{};const t={};return Object.keys(e).filter(n=>!(n.match(/^on[A-Z]/)&&typeof e[n]=="function")).forEach(n=>{t[n]=e[n]}),t}function Lk(e){const{getSlotProps:t,additionalProps:n,externalSlotProps:i,externalForwardedProps:a,className:o}=e;if(!t){const p=V(a==null?void 0:a.className,i==null?void 0:i.className,o,n==null?void 0:n.className),f=k({},n==null?void 0:n.style,a==null?void 0:a.style,i==null?void 0:i.style),u=k({},n,a,i);return p.length>0&&(u.className=p),Object.keys(f).length>0&&(u.style=f),{props:u,internalRef:void 0}}const r=ab(k({},a,i)),s=Kf(i),l=Kf(a),c=t(r),d=V(c==null?void 0:c.className,n==null?void 0:n.className,o,a==null?void 0:a.className,i==null?void 0:i.className),h=k({},c==null?void 0:c.style,n==null?void 0:n.style,a==null?void 0:a.style,i==null?void 0:i.style),y=k({},c,n,l,s);return d.length>0&&(y.className=d),Object.keys(h).length>0&&(y.style=h),{props:y,internalRef:c.ref}}const Fk=["elementType","externalSlotProps","ownerState","skipResolvingSlotProps"];function ka(e){var t;const{elementType:n,externalSlotProps:i,ownerState:a,skipResolvingSlotProps:o=!1}=e,r=U(e,Fk),s=o?{}:Mk(i,a),{props:l,internalRef:c}=Lk(k({},r,{externalSlotProps:s})),d=Xe(c,s==null?void 0:s.ref,(t=e.additionalProps)==null?void 0:t.ref);return jk(n,k({},l,{ref:d}),a)}function Uk(e){return me("MuiList",e)}re("MuiList",["root","padding","dense","subheader"]);const Gk=["children","className","component","dense","disablePadding","subheader"],$k=e=>{const{classes:t,disablePadding:n,dense:i,subheader:a}=e;return fe({root:["root",!n&&"padding",i&&"dense",a&&"subheader"]},Uk,t)},Vk=F("ul",{name:"MuiList",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,!n.disablePadding&&t.padding,n.dense&&t.dense,n.subheader&&t.subheader]}})(({ownerState:e})=>k({listStyle:"none",margin:0,padding:0,position:"relative"},!e.disablePadding&&{paddingTop:8,paddingBottom:8},e.subheader&&{paddingTop:0})),Hk=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiList"}),{children:a,className:o,component:r="ul",dense:s=!1,disablePadding:l=!1,subheader:c}=i,d=U(i,Gk),h=v.useMemo(()=>({dense:s}),[s]),y=k({},i,{component:r,dense:s,disablePadding:l}),p=$k(y);return m.jsx(Gd.Provider,{value:h,children:m.jsxs(Vk,k({as:r,className:V(p.root,o),ref:n,ownerState:y},d,{children:[c,a]}))})}),Zk=Hk,Qk=["actions","autoFocus","autoFocusItem","children","className","disabledItemsFocusable","disableListWrap","onKeyDown","variant"];function _c(e,t,n){return e===t?e.firstChild:t&&t.nextElementSibling?t.nextElementSibling:n?null:e.firstChild}function Xf(e,t,n){return e===t?n?e.firstChild:e.lastChild:t&&t.previousElementSibling?t.previousElementSibling:n?null:e.lastChild}function ob(e,t){if(t===void 0)return!0;let n=e.innerText;return n===void 0&&(n=e.textContent),n=n.trim().toLowerCase(),n.length===0?!1:t.repeating?n[0]===t.keys[0]:n.indexOf(t.keys.join(""))===0}function Za(e,t,n,i,a,o){let r=!1,s=a(e,t,t?n:!1);for(;s;){if(s===e.firstChild){if(r)return!1;r=!0}const l=i?!1:s.disabled||s.getAttribute("aria-disabled")==="true";if(!s.hasAttribute("tabindex")||!ob(s,o)||l)s=a(e,s,n);else return s.focus(),!0}return!1}const Kk=v.forwardRef(function(t,n){const{actions:i,autoFocus:a=!1,autoFocusItem:o=!1,children:r,className:s,disabledItemsFocusable:l=!1,disableListWrap:c=!1,onKeyDown:d,variant:h="selectedMenu"}=t,y=U(t,Qk),p=v.useRef(null),f=v.useRef({keys:[],repeating:!0,previousKeyMatched:!0,lastTime:null});oi(()=>{a&&p.current.focus()},[a]),v.useImperativeHandle(i,()=>({adjustStyleForScrollbar:(b,w)=>{const C=!p.current.style.width;if(b.clientHeight<p.current.clientHeight&&C){const I=`${u_(yt(b))}px`;p.current.style[w.direction==="rtl"?"paddingLeft":"paddingRight"]=I,p.current.style.width=`calc(100% + ${I})`}return p.current}}),[]);const u=b=>{const w=p.current,C=b.key,I=yt(w).activeElement;if(C==="ArrowDown")b.preventDefault(),Za(w,I,c,l,_c);else if(C==="ArrowUp")b.preventDefault(),Za(w,I,c,l,Xf);else if(C==="Home")b.preventDefault(),Za(w,null,c,l,_c);else if(C==="End")b.preventDefault(),Za(w,null,c,l,Xf);else if(C.length===1){const x=f.current,q=C.toLowerCase(),S=performance.now();x.keys.length>0&&(S-x.lastTime>500?(x.keys=[],x.repeating=!0,x.previousKeyMatched=!0):x.repeating&&q!==x.keys[0]&&(x.repeating=!1)),x.lastTime=S,x.keys.push(q);const P=I&&!x.repeating&&ob(I,x);x.previousKeyMatched&&(P||Za(w,I,!1,l,_c,x))?b.preventDefault():x.previousKeyMatched=!1}d&&d(b)},T=Xe(p,n);let g=-1;v.Children.forEach(r,(b,w)=>{if(!v.isValidElement(b)){g===w&&(g+=1,g>=r.length&&(g=-1));return}b.props.disabled||(h==="selectedMenu"&&b.props.selected||g===-1)&&(g=w),g===w&&(b.props.disabled||b.props.muiSkipListHighlight||b.type.muiSkipListHighlight)&&(g+=1,g>=r.length&&(g=-1))});const _=v.Children.map(r,(b,w)=>{if(w===g){const C={};return o&&(C.autoFocus=!0),b.props.tabIndex===void 0&&h==="selectedMenu"&&(C.tabIndex=0),v.cloneElement(b,C)}return b});return m.jsx(Zk,k({role:"menu",ref:T,className:s,onKeyDown:u,tabIndex:a?0:-1},y,{children:_}))}),Xk=Kk,Yk=["input","select","textarea","a[href]","button","[tabindex]","audio[controls]","video[controls]",'[contenteditable]:not([contenteditable="false"])'].join(",");function Jk(e){const t=parseInt(e.getAttribute("tabindex")||"",10);return Number.isNaN(t)?e.contentEditable==="true"||(e.nodeName==="AUDIO"||e.nodeName==="VIDEO"||e.nodeName==="DETAILS")&&e.getAttribute("tabindex")===null?0:e.tabIndex:t}function eC(e){if(e.tagName!=="INPUT"||e.type!=="radio"||!e.name)return!1;const t=i=>e.ownerDocument.querySelector(`input[type="radio"]${i}`);let n=t(`[name="${e.name}"]:checked`);return n||(n=t(`[name="${e.name}"]`)),n!==e}function tC(e){return!(e.disabled||e.tagName==="INPUT"&&e.type==="hidden"||eC(e))}function nC(e){const t=[],n=[];return Array.from(e.querySelectorAll(Yk)).forEach((i,a)=>{const o=Jk(i);o===-1||!tC(i)||(o===0?t.push(i):n.push({documentOrder:a,tabIndex:o,node:i}))}),n.sort((i,a)=>i.tabIndex===a.tabIndex?i.documentOrder-a.documentOrder:i.tabIndex-a.tabIndex).map(i=>i.node).concat(t)}function iC(){return!0}function aC(e){const{children:t,disableAutoFocus:n=!1,disableEnforceFocus:i=!1,disableRestoreFocus:a=!1,getTabbable:o=nC,isEnabled:r=iC,open:s}=e,l=v.useRef(!1),c=v.useRef(null),d=v.useRef(null),h=v.useRef(null),y=v.useRef(null),p=v.useRef(!1),f=v.useRef(null),u=Xe(t.ref,f),T=v.useRef(null);v.useEffect(()=>{!s||!f.current||(p.current=!n)},[n,s]),v.useEffect(()=>{if(!s||!f.current)return;const b=yt(f.current);return f.current.contains(b.activeElement)||(f.current.hasAttribute("tabIndex")||f.current.setAttribute("tabIndex","-1"),p.current&&f.current.focus()),()=>{a||(h.current&&h.current.focus&&(l.current=!0,h.current.focus()),h.current=null)}},[s]),v.useEffect(()=>{if(!s||!f.current)return;const b=yt(f.current),w=x=>{T.current=x,!(i||!r()||x.key!=="Tab")&&b.activeElement===f.current&&x.shiftKey&&(l.current=!0,d.current&&d.current.focus())},C=()=>{const x=f.current;if(x===null)return;if(!b.hasFocus()||!r()||l.current){l.current=!1;return}if(x.contains(b.activeElement)||i&&b.activeElement!==c.current&&b.activeElement!==d.current)return;if(b.activeElement!==y.current)y.current=null;else if(y.current!==null)return;if(!p.current)return;let q=[];if((b.activeElement===c.current||b.activeElement===d.current)&&(q=o(f.current)),q.length>0){var S,P;const R=!!((S=T.current)!=null&&S.shiftKey&&((P=T.current)==null?void 0:P.key)==="Tab"),O=q[0],M=q[q.length-1];typeof O!="string"&&typeof M!="string"&&(R?M.focus():O.focus())}else x.focus()};b.addEventListener("focusin",C),b.addEventListener("keydown",w,!0);const I=setInterval(()=>{b.activeElement&&b.activeElement.tagName==="BODY"&&C()},50);return()=>{clearInterval(I),b.removeEventListener("focusin",C),b.removeEventListener("keydown",w,!0)}},[n,i,a,r,s,o]);const g=b=>{h.current===null&&(h.current=b.relatedTarget),p.current=!0,y.current=b.target;const w=t.props.onFocus;w&&w(b)},_=b=>{h.current===null&&(h.current=b.relatedTarget),p.current=!0};return m.jsxs(v.Fragment,{children:[m.jsx("div",{tabIndex:s?0:-1,onFocus:_,ref:c,"data-testid":"sentinelStart"}),v.cloneElement(t,{ref:u,onFocus:g}),m.jsx("div",{tabIndex:s?0:-1,onFocus:_,ref:d,"data-testid":"sentinelEnd"})]})}function oC(e){return typeof e=="function"?e():e}const rC=v.forwardRef(function(t,n){const{children:i,container:a,disablePortal:o=!1}=t,[r,s]=v.useState(null),l=Xe(v.isValidElement(i)?i.ref:null,n);if(oi(()=>{o||s(oC(a)||document.body)},[a,o]),oi(()=>{if(r&&!o)return gs(n,r),()=>{gs(n,null)}},[n,r,o]),o){if(v.isValidElement(i)){const c={ref:l};return v.cloneElement(i,c)}return m.jsx(v.Fragment,{children:i})}return m.jsx(v.Fragment,{children:r&&Ls.createPortal(i,r)})});function sC(e){const t=yt(e);return t.body===e?pn(e).innerWidth>t.documentElement.clientWidth:e.scrollHeight>e.clientHeight}function go(e,t){t?e.setAttribute("aria-hidden","true"):e.removeAttribute("aria-hidden")}function Yf(e){return parseInt(pn(e).getComputedStyle(e).paddingRight,10)||0}function lC(e){const n=["TEMPLATE","SCRIPT","STYLE","LINK","MAP","META","NOSCRIPT","PICTURE","COL","COLGROUP","PARAM","SLOT","SOURCE","TRACK"].indexOf(e.tagName)!==-1,i=e.tagName==="INPUT"&&e.getAttribute("type")==="hidden";return n||i}function Jf(e,t,n,i,a){const o=[t,n,...i];[].forEach.call(e.children,r=>{const s=o.indexOf(r)===-1,l=!lC(r);s&&l&&go(r,a)})}function bc(e,t){let n=-1;return e.some((i,a)=>t(i)?(n=a,!0):!1),n}function cC(e,t){const n=[],i=e.container;if(!t.disableScrollLock){if(sC(i)){const r=u_(yt(i));n.push({value:i.style.paddingRight,property:"padding-right",el:i}),i.style.paddingRight=`${Yf(i)+r}px`;const s=yt(i).querySelectorAll(".mui-fixed");[].forEach.call(s,l=>{n.push({value:l.style.paddingRight,property:"padding-right",el:l}),l.style.paddingRight=`${Yf(l)+r}px`})}let o;if(i.parentNode instanceof DocumentFragment)o=yt(i).body;else{const r=i.parentElement,s=pn(i);o=(r==null?void 0:r.nodeName)==="HTML"&&s.getComputedStyle(r).overflowY==="scroll"?r:i}n.push({value:o.style.overflow,property:"overflow",el:o},{value:o.style.overflowX,property:"overflow-x",el:o},{value:o.style.overflowY,property:"overflow-y",el:o}),o.style.overflow="hidden"}return()=>{n.forEach(({value:o,el:r,property:s})=>{o?r.style.setProperty(s,o):r.style.removeProperty(s)})}}function dC(e){const t=[];return[].forEach.call(e.children,n=>{n.getAttribute("aria-hidden")==="true"&&t.push(n)}),t}class uC{constructor(){this.containers=void 0,this.modals=void 0,this.modals=[],this.containers=[]}add(t,n){let i=this.modals.indexOf(t);if(i!==-1)return i;i=this.modals.length,this.modals.push(t),t.modalRef&&go(t.modalRef,!1);const a=dC(n);Jf(n,t.mount,t.modalRef,a,!0);const o=bc(this.containers,r=>r.container===n);return o!==-1?(this.containers[o].modals.push(t),i):(this.containers.push({modals:[t],container:n,restore:null,hiddenSiblings:a}),i)}mount(t,n){const i=bc(this.containers,o=>o.modals.indexOf(t)!==-1),a=this.containers[i];a.restore||(a.restore=cC(a,n))}remove(t,n=!0){const i=this.modals.indexOf(t);if(i===-1)return i;const a=bc(this.containers,r=>r.modals.indexOf(t)!==-1),o=this.containers[a];if(o.modals.splice(o.modals.indexOf(t),1),this.modals.splice(i,1),o.modals.length===0)o.restore&&o.restore(),t.modalRef&&go(t.modalRef,n),Jf(o.container,t.mount,t.modalRef,o.hiddenSiblings,!1),this.containers.splice(a,1);else{const r=o.modals[o.modals.length-1];r.modalRef&&go(r.modalRef,!1)}return i}isTopModal(t){return this.modals.length>0&&this.modals[this.modals.length-1]===t}}function pC(e){return typeof e=="function"?e():e}function mC(e){return e?e.props.hasOwnProperty("in"):!1}const fC=new uC;function hC(e){const{container:t,disableEscapeKeyDown:n=!1,disableScrollLock:i=!1,manager:a=fC,closeAfterTransition:o=!1,onTransitionEnter:r,onTransitionExited:s,children:l,onClose:c,open:d,rootRef:h}=e,y=v.useRef({}),p=v.useRef(null),f=v.useRef(null),u=Xe(f,h),[T,g]=v.useState(!d),_=mC(l);let b=!0;(e["aria-hidden"]==="false"||e["aria-hidden"]===!1)&&(b=!1);const w=()=>yt(p.current),C=()=>(y.current.modalRef=f.current,y.current.mount=p.current,y.current),I=()=>{a.mount(C(),{disableScrollLock:i}),f.current&&(f.current.scrollTop=0)},x=Ci(()=>{const z=pC(t)||w().body;a.add(C(),z),f.current&&I()}),q=v.useCallback(()=>a.isTopModal(C()),[a]),S=Ci(z=>{p.current=z,z&&(d&&q()?I():f.current&&go(f.current,b))}),P=v.useCallback(()=>{a.remove(C(),b)},[b,a]);v.useEffect(()=>()=>{P()},[P]),v.useEffect(()=>{d?x():(!_||!o)&&P()},[d,P,_,o,x]);const R=z=>L=>{var D;(D=z.onKeyDown)==null||D.call(z,L),!(L.key!=="Escape"||!q())&&(n||(L.stopPropagation(),c&&c(L,"escapeKeyDown")))},O=z=>L=>{var D;(D=z.onClick)==null||D.call(z,L),L.target===L.currentTarget&&c&&c(L,"backdropClick")};return{getRootProps:(z={})=>{const L=ab(e);delete L.onTransitionEnter,delete L.onTransitionExited;const D=k({},L,z);return k({role:"presentation"},D,{onKeyDown:R(D),ref:u})},getBackdropProps:(z={})=>{const L=z;return k({"aria-hidden":!0},L,{onClick:O(L),open:d})},getTransitionProps:()=>{const z=()=>{g(!1),r&&r()},L=()=>{g(!0),s&&s(),o&&P()};return{onEnter:Sd(z,l==null?void 0:l.props.onEnter),onExited:Sd(L,l==null?void 0:l.props.onExited)}},rootRef:u,portalRef:S,isTopModal:q,exited:T,hasTransition:_}}const yC=["onChange","maxRows","minRows","style","value"];function xr(e){return parseInt(e,10)||0}const gC={shadow:{visibility:"hidden",position:"absolute",overflow:"hidden",height:0,top:0,left:0,transform:"translateZ(0)"}};function eh(e){return e==null||Object.keys(e).length===0||e.outerHeightStyle===0&&!e.overflow}const _C=v.forwardRef(function(t,n){const{onChange:i,maxRows:a,minRows:o=1,style:r,value:s}=t,l=U(t,yC),{current:c}=v.useRef(s!=null),d=v.useRef(null),h=Xe(n,d),y=v.useRef(null),p=v.useRef(0),[f,u]=v.useState({outerHeightStyle:0}),T=v.useCallback(()=>{const C=d.current,x=pn(C).getComputedStyle(C);if(x.width==="0px")return{outerHeightStyle:0};const q=y.current;q.style.width=x.width,q.value=C.value||t.placeholder||"x",q.value.slice(-1)===`
`&&(q.value+=" ");const S=x.boxSizing,P=xr(x.paddingBottom)+xr(x.paddingTop),R=xr(x.borderBottomWidth)+xr(x.borderTopWidth),O=q.scrollHeight;q.value="x";const M=q.scrollHeight;let A=O;o&&(A=Math.max(Number(o)*M,A)),a&&(A=Math.min(Number(a)*M,A)),A=Math.max(A,M);const B=A+(S==="border-box"?P+R:0),z=Math.abs(A-O)<=1;return{outerHeightStyle:B,overflow:z}},[a,o,t.placeholder]),g=(C,I)=>{const{outerHeightStyle:x,overflow:q}=I;return p.current<20&&(x>0&&Math.abs((C.outerHeightStyle||0)-x)>1||C.overflow!==q)?(p.current+=1,{overflow:q,outerHeightStyle:x}):C},_=v.useCallback(()=>{const C=T();eh(C)||u(I=>g(I,C))},[T]),b=()=>{const C=T();eh(C)||Ls.flushSync(()=>{u(I=>g(I,C))})};v.useEffect(()=>{const C=()=>{p.current=0,d.current&&b()},I=el(()=>{p.current=0,d.current&&b()});let x;const q=d.current,S=pn(q);return S.addEventListener("resize",I),typeof ResizeObserver<"u"&&(x=new ResizeObserver(C),x.observe(q)),()=>{I.clear(),S.removeEventListener("resize",I),x&&x.disconnect()}}),oi(()=>{_()}),v.useEffect(()=>{p.current=0},[s]);const w=C=>{p.current=0,c||_(),i&&i(C)};return m.jsxs(v.Fragment,{children:[m.jsx("textarea",k({value:s,onChange:w,ref:h,rows:o,style:k({height:f.outerHeightStyle,overflow:f.overflow?"hidden":void 0},r)},l)),m.jsx("textarea",{"aria-hidden":!0,className:t.className,readOnly:!0,ref:y,tabIndex:-1,style:k({},gC.shadow,r,{paddingTop:0,paddingBottom:0})})]})}),Cp=e=>e.scrollTop;function Ca(e,t){var n,i;const{timeout:a,easing:o,style:r={}}=e;return{duration:(n=r.transitionDuration)!=null?n:typeof a=="number"?a:a[t.mode]||0,easing:(i=r.transitionTimingFunction)!=null?i:typeof o=="object"?o[t.mode]:o,delay:r.transitionDelay}}const bC=["addEndListener","appear","children","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"];function Zd(e){return`scale(${e}, ${e**2})`}const vC={entering:{opacity:1,transform:Zd(1)},entered:{opacity:1,transform:"none"}},vc=typeof navigator<"u"&&/^((?!chrome|android).)*(safari|mobile)/i.test(navigator.userAgent)&&/(os |version\/)15(.|_)4/i.test(navigator.userAgent),rb=v.forwardRef(function(t,n){const{addEndListener:i,appear:a=!0,children:o,easing:r,in:s,onEnter:l,onEntered:c,onEntering:d,onExit:h,onExited:y,onExiting:p,style:f,timeout:u="auto",TransitionComponent:T=xp}=t,g=U(t,bC),_=v.useRef(),b=v.useRef(),w=Ra(),C=v.useRef(null),I=Xe(C,o.ref,n),x=B=>z=>{if(B){const L=C.current;z===void 0?B(L):B(L,z)}},q=x(d),S=x((B,z)=>{Cp(B);const{duration:L,delay:D,easing:N}=Ca({style:f,timeout:u,easing:r},{mode:"enter"});let W;u==="auto"?(W=w.transitions.getAutoHeightDuration(B.clientHeight),b.current=W):W=L,B.style.transition=[w.transitions.create("opacity",{duration:W,delay:D}),w.transitions.create("transform",{duration:vc?W:W*.666,delay:D,easing:N})].join(","),l&&l(B,z)}),P=x(c),R=x(p),O=x(B=>{const{duration:z,delay:L,easing:D}=Ca({style:f,timeout:u,easing:r},{mode:"exit"});let N;u==="auto"?(N=w.transitions.getAutoHeightDuration(B.clientHeight),b.current=N):N=z,B.style.transition=[w.transitions.create("opacity",{duration:N,delay:L}),w.transitions.create("transform",{duration:vc?N:N*.666,delay:vc?L:L||N*.333,easing:D})].join(","),B.style.opacity=0,B.style.transform=Zd(.75),h&&h(B)}),M=x(y),A=B=>{u==="auto"&&(_.current=setTimeout(B,b.current||0)),i&&i(C.current,B)};return v.useEffect(()=>()=>{clearTimeout(_.current)},[]),m.jsx(T,k({appear:a,in:s,nodeRef:C,onEnter:S,onEntered:P,onEntering:q,onExit:O,onExited:M,onExiting:R,addEndListener:A,timeout:u==="auto"?null:u},g,{children:(B,z)=>v.cloneElement(o,k({style:k({opacity:0,transform:Zd(.75),visibility:B==="exited"&&!s?"hidden":void 0},vC[B],f,o.props.style),ref:I},z))}))});rb.muiSupportAuto=!0;const wC=rb,xC=["addEndListener","appear","children","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"],TC={entering:{opacity:1},entered:{opacity:1}},kC=v.forwardRef(function(t,n){const i=Ra(),a={enter:i.transitions.duration.enteringScreen,exit:i.transitions.duration.leavingScreen},{addEndListener:o,appear:r=!0,children:s,easing:l,in:c,onEnter:d,onEntered:h,onEntering:y,onExit:p,onExited:f,onExiting:u,style:T,timeout:g=a,TransitionComponent:_=xp}=t,b=U(t,xC),w=v.useRef(null),C=Xe(w,s.ref,n),I=A=>B=>{if(A){const z=w.current;B===void 0?A(z):A(z,B)}},x=I(y),q=I((A,B)=>{Cp(A);const z=Ca({style:T,timeout:g,easing:l},{mode:"enter"});A.style.webkitTransition=i.transitions.create("opacity",z),A.style.transition=i.transitions.create("opacity",z),d&&d(A,B)}),S=I(h),P=I(u),R=I(A=>{const B=Ca({style:T,timeout:g,easing:l},{mode:"exit"});A.style.webkitTransition=i.transitions.create("opacity",B),A.style.transition=i.transitions.create("opacity",B),p&&p(A)}),O=I(f),M=A=>{o&&o(w.current,A)};return m.jsx(_,k({appear:r,in:c,nodeRef:w,onEnter:q,onEntered:S,onEntering:x,onExit:R,onExited:O,onExiting:P,addEndListener:M,timeout:g},b,{children:(A,B)=>v.cloneElement(s,k({style:k({opacity:0,visibility:A==="exited"&&!c?"hidden":void 0},TC[A],T,s.props.style),ref:C},B))}))}),sb=kC;function CC(e){return me("MuiBackdrop",e)}re("MuiBackdrop",["root","invisible"]);const IC=["children","className","component","components","componentsProps","invisible","open","slotProps","slots","TransitionComponent","transitionDuration"],qC=e=>{const{classes:t,invisible:n}=e;return fe({root:["root",n&&"invisible"]},CC,t)},DC=F("div",{name:"MuiBackdrop",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.invisible&&t.invisible]}})(({ownerState:e})=>k({position:"fixed",display:"flex",alignItems:"center",justifyContent:"center",right:0,bottom:0,top:0,left:0,backgroundColor:"rgba(0, 0, 0, 0.5)",WebkitTapHighlightColor:"transparent"},e.invisible&&{backgroundColor:"transparent"})),PC=v.forwardRef(function(t,n){var i,a,o;const r=he({props:t,name:"MuiBackdrop"}),{children:s,className:l,component:c="div",components:d={},componentsProps:h={},invisible:y=!1,open:p,slotProps:f={},slots:u={},TransitionComponent:T=sb,transitionDuration:g}=r,_=U(r,IC),b=k({},r,{component:c,invisible:y}),w=qC(b),C=(i=f.root)!=null?i:h.root;return m.jsx(T,k({in:p,timeout:g},_,{children:m.jsx(DC,k({"aria-hidden":!0},C,{as:(a=(o=u.root)!=null?o:d.Root)!=null?a:c,className:V(w.root,l,C==null?void 0:C.className),ownerState:k({},b,C==null?void 0:C.ownerState),classes:w,ref:n,children:s}))}))}),lb=PC;function SC(e){return me("MuiModal",e)}re("MuiModal",["root","hidden","backdrop"]);const EC=["BackdropComponent","BackdropProps","classes","className","closeAfterTransition","children","container","component","components","componentsProps","disableAutoFocus","disableEnforceFocus","disableEscapeKeyDown","disablePortal","disableRestoreFocus","disableScrollLock","hideBackdrop","keepMounted","onBackdropClick","onClose","onTransitionEnter","onTransitionExited","open","slotProps","slots","theme"],AC=e=>{const{open:t,exited:n,classes:i}=e;return fe({root:["root",!t&&n&&"hidden"],backdrop:["backdrop"]},SC,i)},NC=F("div",{name:"MuiModal",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,!n.open&&n.exited&&t.hidden]}})(({theme:e,ownerState:t})=>k({position:"fixed",zIndex:(e.vars||e).zIndex.modal,right:0,bottom:0,top:0,left:0},!t.open&&t.exited&&{visibility:"hidden"})),RC=F(lb,{name:"MuiModal",slot:"Backdrop",overridesResolver:(e,t)=>t.backdrop})({zIndex:-1}),BC=v.forwardRef(function(t,n){var i,a,o,r,s,l;const c=he({name:"MuiModal",props:t}),{BackdropComponent:d=RC,BackdropProps:h,className:y,closeAfterTransition:p=!1,children:f,container:u,component:T,components:g={},componentsProps:_={},disableAutoFocus:b=!1,disableEnforceFocus:w=!1,disableEscapeKeyDown:C=!1,disablePortal:I=!1,disableRestoreFocus:x=!1,disableScrollLock:q=!1,hideBackdrop:S=!1,keepMounted:P=!1,onBackdropClick:R,open:O,slotProps:M,slots:A}=c,B=U(c,EC),z=k({},c,{closeAfterTransition:p,disableAutoFocus:b,disableEnforceFocus:w,disableEscapeKeyDown:C,disablePortal:I,disableRestoreFocus:x,disableScrollLock:q,hideBackdrop:S,keepMounted:P}),{getRootProps:L,getBackdropProps:D,getTransitionProps:N,portalRef:W,isTopModal:te,exited:Q,hasTransition:Re}=hC(k({},z,{rootRef:n})),J=k({},z,{exited:Q}),we=AC(J),le={};if(f.props.tabIndex===void 0&&(le.tabIndex="-1"),Re){const{onEnter:X,onExited:ue}=N();le.onEnter=X,le.onExited=ue}const $e=(i=(a=A==null?void 0:A.root)!=null?a:g.Root)!=null?i:NC,Pt=(o=(r=A==null?void 0:A.backdrop)!=null?r:g.Backdrop)!=null?o:d,Be=(s=M==null?void 0:M.root)!=null?s:_.root,ct=(l=M==null?void 0:M.backdrop)!=null?l:_.backdrop,oe=ka({elementType:$e,externalSlotProps:Be,externalForwardedProps:B,getSlotProps:L,additionalProps:{ref:n,as:T},ownerState:J,className:V(y,Be==null?void 0:Be.className,we==null?void 0:we.root,!J.open&&J.exited&&(we==null?void 0:we.hidden))}),Ie=ka({elementType:Pt,externalSlotProps:ct,additionalProps:h,getSlotProps:X=>D(k({},X,{onClick:ue=>{R&&R(ue),X!=null&&X.onClick&&X.onClick(ue)}})),className:V(ct==null?void 0:ct.className,h==null?void 0:h.className,we==null?void 0:we.backdrop),ownerState:J});return!P&&!O&&(!Re||Q)?null:m.jsx(rC,{ref:W,container:u,disablePortal:I,children:m.jsxs($e,k({},oe,{children:[!S&&d?m.jsx(Pt,k({},Ie)):null,m.jsx(aC,{disableEnforceFocus:w,disableAutoFocus:b,disableRestoreFocus:x,isEnabled:te,open:O,children:v.cloneElement(f,le)})]}))})}),Ip=BC;function OC(e){return me("MuiPaper",e)}re("MuiPaper",["root","rounded","outlined","elevation","elevation0","elevation1","elevation2","elevation3","elevation4","elevation5","elevation6","elevation7","elevation8","elevation9","elevation10","elevation11","elevation12","elevation13","elevation14","elevation15","elevation16","elevation17","elevation18","elevation19","elevation20","elevation21","elevation22","elevation23","elevation24"]);const zC=["className","component","elevation","square","variant"],WC=e=>{const{square:t,elevation:n,variant:i,classes:a}=e,o={root:["root",i,!t&&"rounded",i==="elevation"&&`elevation${n}`]};return fe(o,OC,a)},jC=F("div",{name:"MuiPaper",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,t[n.variant],!n.square&&t.rounded,n.variant==="elevation"&&t[`elevation${n.elevation}`]]}})(({theme:e,ownerState:t})=>{var n;return k({backgroundColor:(e.vars||e).palette.background.paper,color:(e.vars||e).palette.text.primary,transition:e.transitions.create("box-shadow")},!t.square&&{borderRadius:e.shape.borderRadius},t.variant==="outlined"&&{border:`1px solid ${(e.vars||e).palette.divider}`},t.variant==="elevation"&&k({boxShadow:(e.vars||e).shadows[t.elevation]},!e.vars&&e.palette.mode==="dark"&&{backgroundImage:`linear-gradient(${Tn("#fff",Wf(t.elevation))}, ${Tn("#fff",Wf(t.elevation))})`},e.vars&&{backgroundImage:(n=e.vars.overlays)==null?void 0:n[t.elevation]}))}),MC=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiPaper"}),{className:a,component:o="div",elevation:r=1,square:s=!1,variant:l="elevation"}=i,c=U(i,zC),d=k({},i,{component:o,elevation:r,square:s,variant:l}),h=WC(d);return m.jsx(jC,k({as:o,ownerState:d,className:V(h.root,a),ref:n},c))}),tr=MC;function LC(e){return me("MuiPopover",e)}re("MuiPopover",["root","paper"]);const FC=["onEntering"],UC=["action","anchorEl","anchorOrigin","anchorPosition","anchorReference","children","className","container","elevation","marginThreshold","open","PaperProps","slots","slotProps","transformOrigin","TransitionComponent","transitionDuration","TransitionProps","disableScrollLock"],GC=["slotProps"];function th(e,t){let n=0;return typeof t=="number"?n=t:t==="center"?n=e.height/2:t==="bottom"&&(n=e.height),n}function nh(e,t){let n=0;return typeof t=="number"?n=t:t==="center"?n=e.width/2:t==="right"&&(n=e.width),n}function ih(e){return[e.horizontal,e.vertical].map(t=>typeof t=="number"?`${t}px`:t).join(" ")}function wc(e){return typeof e=="function"?e():e}const $C=e=>{const{classes:t}=e;return fe({root:["root"],paper:["paper"]},LC,t)},VC=F(Ip,{name:"MuiPopover",slot:"Root",overridesResolver:(e,t)=>t.root})({}),cb=F(tr,{name:"MuiPopover",slot:"Paper",overridesResolver:(e,t)=>t.paper})({position:"absolute",overflowY:"auto",overflowX:"hidden",minWidth:16,minHeight:16,maxWidth:"calc(100% - 32px)",maxHeight:"calc(100% - 32px)",outline:0}),HC=v.forwardRef(function(t,n){var i,a,o;const r=he({props:t,name:"MuiPopover"}),{action:s,anchorEl:l,anchorOrigin:c={vertical:"top",horizontal:"left"},anchorPosition:d,anchorReference:h="anchorEl",children:y,className:p,container:f,elevation:u=8,marginThreshold:T=16,open:g,PaperProps:_={},slots:b,slotProps:w,transformOrigin:C={vertical:"top",horizontal:"left"},TransitionComponent:I=wC,transitionDuration:x="auto",TransitionProps:{onEntering:q}={},disableScrollLock:S=!1}=r,P=U(r.TransitionProps,FC),R=U(r,UC),O=(i=w==null?void 0:w.paper)!=null?i:_,M=v.useRef(),A=Xe(M,O.ref),B=k({},r,{anchorOrigin:c,anchorReference:h,elevation:u,marginThreshold:T,externalPaperSlotProps:O,transformOrigin:C,TransitionComponent:I,transitionDuration:x,TransitionProps:P}),z=$C(B),L=v.useCallback(()=>{if(h==="anchorPosition")return d;const X=wc(l),xe=(X&&X.nodeType===1?X:yt(M.current).body).getBoundingClientRect();return{top:xe.top+th(xe,c.vertical),left:xe.left+nh(xe,c.horizontal)}},[l,c.horizontal,c.vertical,d,h]),D=v.useCallback(X=>({vertical:th(X,C.vertical),horizontal:nh(X,C.horizontal)}),[C.horizontal,C.vertical]),N=v.useCallback(X=>{const ue={width:X.offsetWidth,height:X.offsetHeight},xe=D(ue);if(h==="none")return{top:null,left:null,transformOrigin:ih(xe)};const Rn=L();let St=Rn.top-xe.vertical,Et=Rn.left-xe.horizontal;const Ut=St+ue.height,At=Et+ue.width,qe=pn(wc(l)),hn=qe.innerHeight-T,dt=qe.innerWidth-T;if(T!==null&&St<T){const Te=St-T;St-=Te,xe.vertical+=Te}else if(T!==null&&Ut>hn){const Te=Ut-hn;St-=Te,xe.vertical+=Te}if(T!==null&&Et<T){const Te=Et-T;Et-=Te,xe.horizontal+=Te}else if(At>dt){const Te=At-dt;Et-=Te,xe.horizontal+=Te}return{top:`${Math.round(St)}px`,left:`${Math.round(Et)}px`,transformOrigin:ih(xe)}},[l,h,L,D,T]),[W,te]=v.useState(g),Q=v.useCallback(()=>{const X=M.current;if(!X)return;const ue=N(X);ue.top!==null&&(X.style.top=ue.top),ue.left!==null&&(X.style.left=ue.left),X.style.transformOrigin=ue.transformOrigin,te(!0)},[N]);v.useEffect(()=>(S&&window.addEventListener("scroll",Q),()=>window.removeEventListener("scroll",Q)),[l,S,Q]);const Re=(X,ue)=>{q&&q(X,ue),Q()},J=()=>{te(!1)};v.useEffect(()=>{g&&Q()}),v.useImperativeHandle(s,()=>g?{updatePosition:()=>{Q()}}:null,[g,Q]),v.useEffect(()=>{if(!g)return;const X=el(()=>{Q()}),ue=pn(l);return ue.addEventListener("resize",X),()=>{X.clear(),ue.removeEventListener("resize",X)}},[l,g,Q]);let we=x;x==="auto"&&!I.muiSupportAuto&&(we=void 0);const le=f||(l?yt(wc(l)).body:void 0),$e=(a=b==null?void 0:b.root)!=null?a:VC,Pt=(o=b==null?void 0:b.paper)!=null?o:cb,Be=ka({elementType:Pt,externalSlotProps:k({},O,{style:W?O.style:k({},O.style,{opacity:0})}),additionalProps:{elevation:u,ref:A},ownerState:B,className:V(z.paper,O==null?void 0:O.className)}),ct=ka({elementType:$e,externalSlotProps:(w==null?void 0:w.root)||{},externalForwardedProps:R,additionalProps:{ref:n,slotProps:{backdrop:{invisible:!0}},container:le,open:g},ownerState:B,className:V(z.root,p)}),{slotProps:oe}=ct,Ie=U(ct,GC);return m.jsx($e,k({},Ie,!Ts($e)&&{slotProps:oe,disableScrollLock:S},{children:m.jsx(I,k({appear:!0,in:g,onEntering:Re,onExited:J,timeout:we},P,{children:m.jsx(Pt,k({},Be,{children:y}))}))}))}),ZC=HC;function QC(e){return me("MuiMenu",e)}re("MuiMenu",["root","paper","list"]);const KC=["onEntering"],XC=["autoFocus","children","className","disableAutoFocusItem","MenuListProps","onClose","open","PaperProps","PopoverClasses","transitionDuration","TransitionProps","variant","slots","slotProps"],YC={vertical:"top",horizontal:"right"},JC={vertical:"top",horizontal:"left"},eI=e=>{const{classes:t}=e;return fe({root:["root"],paper:["paper"],list:["list"]},QC,t)},tI=F(ZC,{shouldForwardProp:e=>Yt(e)||e==="classes",name:"MuiMenu",slot:"Root",overridesResolver:(e,t)=>t.root})({}),nI=F(cb,{name:"MuiMenu",slot:"Paper",overridesResolver:(e,t)=>t.paper})({maxHeight:"calc(100% - 96px)",WebkitOverflowScrolling:"touch"}),iI=F(Xk,{name:"MuiMenu",slot:"List",overridesResolver:(e,t)=>t.list})({outline:0}),aI=v.forwardRef(function(t,n){var i,a;const o=he({props:t,name:"MuiMenu"}),{autoFocus:r=!0,children:s,className:l,disableAutoFocusItem:c=!1,MenuListProps:d={},onClose:h,open:y,PaperProps:p={},PopoverClasses:f,transitionDuration:u="auto",TransitionProps:{onEntering:T}={},variant:g="selectedMenu",slots:_={},slotProps:b={}}=o,w=U(o.TransitionProps,KC),C=U(o,XC),I=Ra(),x=I.direction==="rtl",q=k({},o,{autoFocus:r,disableAutoFocusItem:c,MenuListProps:d,onEntering:T,PaperProps:p,transitionDuration:u,TransitionProps:w,variant:g}),S=eI(q),P=r&&!c&&y,R=v.useRef(null),O=(N,W)=>{R.current&&R.current.adjustStyleForScrollbar(N,I),T&&T(N,W)},M=N=>{N.key==="Tab"&&(N.preventDefault(),h&&h(N,"tabKeyDown"))};let A=-1;v.Children.map(s,(N,W)=>{v.isValidElement(N)&&(N.props.disabled||(g==="selectedMenu"&&N.props.selected||A===-1)&&(A=W))});const B=(i=_.paper)!=null?i:nI,z=(a=b.paper)!=null?a:p,L=ka({elementType:_.root,externalSlotProps:b.root,ownerState:q,className:[S.root,l]}),D=ka({elementType:B,externalSlotProps:z,ownerState:q,className:S.paper});return m.jsx(tI,k({onClose:h,anchorOrigin:{vertical:"bottom",horizontal:x?"right":"left"},transformOrigin:x?YC:JC,slots:{paper:B,root:_.root},slotProps:{root:L,paper:D},open:y,ref:n,transitionDuration:u,TransitionProps:k({onEntering:O},w),ownerState:q},C,{classes:f,children:m.jsx(iI,k({onKeyDown:M,actions:R,autoFocus:r&&(A===-1||c),autoFocusItem:P,variant:g},d,{className:V(S.list,d.className),children:s}))}))}),oI=aI;function rI(e){return me("MuiNativeSelect",e)}const sI=re("MuiNativeSelect",["root","select","multiple","filled","outlined","standard","disabled","icon","iconOpen","iconFilled","iconOutlined","iconStandard","nativeInput","error"]),qp=sI,lI=["className","disabled","error","IconComponent","inputRef","variant"],cI=e=>{const{classes:t,variant:n,disabled:i,multiple:a,open:o,error:r}=e,s={select:["select",n,i&&"disabled",a&&"multiple",r&&"error"],icon:["icon",`icon${Z(n)}`,o&&"iconOpen",i&&"disabled"]};return fe(s,rI,t)},db=({ownerState:e,theme:t})=>k({MozAppearance:"none",WebkitAppearance:"none",userSelect:"none",borderRadius:0,cursor:"pointer","&:focus":k({},t.vars?{backgroundColor:`rgba(${t.vars.palette.common.onBackgroundChannel} / 0.05)`}:{backgroundColor:t.palette.mode==="light"?"rgba(0, 0, 0, 0.05)":"rgba(255, 255, 255, 0.05)"},{borderRadius:0}),"&::-ms-expand":{display:"none"},[`&.${qp.disabled}`]:{cursor:"default"},"&[multiple]":{height:"auto"},"&:not([multiple]) option, &:not([multiple]) optgroup":{backgroundColor:(t.vars||t).palette.background.paper},"&&&":{paddingRight:24,minWidth:16}},e.variant==="filled"&&{"&&&":{paddingRight:32}},e.variant==="outlined"&&{borderRadius:(t.vars||t).shape.borderRadius,"&:focus":{borderRadius:(t.vars||t).shape.borderRadius},"&&&":{paddingRight:32}}),dI=F("select",{name:"MuiNativeSelect",slot:"Select",shouldForwardProp:Yt,overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.select,t[n.variant],n.error&&t.error,{[`&.${qp.multiple}`]:t.multiple}]}})(db),ub=({ownerState:e,theme:t})=>k({position:"absolute",right:0,top:"calc(50% - .5em)",pointerEvents:"none",color:(t.vars||t).palette.action.active,[`&.${qp.disabled}`]:{color:(t.vars||t).palette.action.disabled}},e.open&&{transform:"rotate(180deg)"},e.variant==="filled"&&{right:7},e.variant==="outlined"&&{right:7}),uI=F("svg",{name:"MuiNativeSelect",slot:"Icon",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.icon,n.variant&&t[`icon${Z(n.variant)}`],n.open&&t.iconOpen]}})(ub),pI=v.forwardRef(function(t,n){const{className:i,disabled:a,error:o,IconComponent:r,inputRef:s,variant:l="standard"}=t,c=U(t,lI),d=k({},t,{disabled:a,variant:l,error:o}),h=cI(d);return m.jsxs(v.Fragment,{children:[m.jsx(dI,k({ownerState:d,className:V(h.select,i),disabled:a,ref:s||n},c)),t.multiple?null:m.jsx(uI,{as:r,ownerState:d,className:h.icon})]})}),mI=pI;function fI(e){return me("MuiSelect",e)}const hI=re("MuiSelect",["root","select","multiple","filled","outlined","standard","disabled","focused","icon","iconOpen","iconFilled","iconOutlined","iconStandard","nativeInput","error"]),Qa=hI;var ah;const yI=["aria-describedby","aria-label","autoFocus","autoWidth","children","className","defaultOpen","defaultValue","disabled","displayEmpty","error","IconComponent","inputRef","labelId","MenuProps","multiple","name","onBlur","onChange","onClose","onFocus","onOpen","open","readOnly","renderValue","SelectDisplayProps","tabIndex","type","value","variant"],gI=F("div",{name:"MuiSelect",slot:"Select",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[{[`&.${Qa.select}`]:t.select},{[`&.${Qa.select}`]:t[n.variant]},{[`&.${Qa.error}`]:t.error},{[`&.${Qa.multiple}`]:t.multiple}]}})(db,{[`&.${Qa.select}`]:{height:"auto",minHeight:"1.4375em",textOverflow:"ellipsis",whiteSpace:"nowrap",overflow:"hidden"}}),_I=F("svg",{name:"MuiSelect",slot:"Icon",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.icon,n.variant&&t[`icon${Z(n.variant)}`],n.open&&t.iconOpen]}})(ub),bI=F("input",{shouldForwardProp:e=>c6(e)&&e!=="classes",name:"MuiSelect",slot:"NativeInput",overridesResolver:(e,t)=>t.nativeInput})({bottom:0,left:0,position:"absolute",opacity:0,pointerEvents:"none",width:"100%",boxSizing:"border-box"});function oh(e,t){return typeof t=="object"&&t!==null?e===t:String(e)===String(t)}function vI(e){return e==null||typeof e=="string"&&!e.trim()}const wI=e=>{const{classes:t,variant:n,disabled:i,multiple:a,open:o,error:r}=e,s={select:["select",n,i&&"disabled",a&&"multiple",r&&"error"],icon:["icon",`icon${Z(n)}`,o&&"iconOpen",i&&"disabled"],nativeInput:["nativeInput"]};return fe(s,fI,t)},xI=v.forwardRef(function(t,n){var i;const{"aria-describedby":a,"aria-label":o,autoFocus:r,autoWidth:s,children:l,className:c,defaultOpen:d,defaultValue:h,disabled:y,displayEmpty:p,error:f=!1,IconComponent:u,inputRef:T,labelId:g,MenuProps:_={},multiple:b,name:w,onBlur:C,onChange:I,onClose:x,onFocus:q,onOpen:S,open:P,readOnly:R,renderValue:O,SelectDisplayProps:M={},tabIndex:A,value:B,variant:z="standard"}=t,L=U(t,yI),[D,N]=Ed({controlled:B,default:h,name:"Select"}),[W,te]=Ed({controlled:P,default:d,name:"Select"}),Q=v.useRef(null),Re=v.useRef(null),[J,we]=v.useState(null),{current:le}=v.useRef(P!=null),[$e,Pt]=v.useState(),Be=Xe(n,T),ct=v.useCallback(G=>{Re.current=G,G&&we(G)},[]),oe=J==null?void 0:J.parentNode;v.useImperativeHandle(Be,()=>({focus:()=>{Re.current.focus()},node:Q.current,value:D}),[D]),v.useEffect(()=>{d&&W&&J&&!le&&(Pt(s?null:oe.clientWidth),Re.current.focus())},[J,s]),v.useEffect(()=>{r&&Re.current.focus()},[r]),v.useEffect(()=>{if(!g)return;const G=yt(Re.current).getElementById(g);if(G){const ge=()=>{getSelection().isCollapsed&&Re.current.focus()};return G.addEventListener("click",ge),()=>{G.removeEventListener("click",ge)}}},[g]);const Ie=(G,ge)=>{G?S&&S(ge):x&&x(ge),le||(Pt(s?null:oe.clientWidth),te(G))},X=G=>{G.button===0&&(G.preventDefault(),Re.current.focus(),Ie(!0,G))},ue=G=>{Ie(!1,G)},xe=v.Children.toArray(l),Rn=G=>{const ge=xe.find(Ve=>Ve.props.value===G.target.value);ge!==void 0&&(N(ge.props.value),I&&I(G,ge))},St=G=>ge=>{let Ve;if(ge.currentTarget.hasAttribute("tabindex")){if(b){Ve=Array.isArray(D)?D.slice():[];const ji=D.indexOf(G.props.value);ji===-1?Ve.push(G.props.value):Ve.splice(ji,1)}else Ve=G.props.value;if(G.props.onClick&&G.props.onClick(ge),D!==Ve&&(N(Ve),I)){const ji=ge.nativeEvent||ge,Gp=new ji.constructor(ji.type,ji);Object.defineProperty(Gp,"target",{writable:!0,value:{value:Ve,name:w}}),I(Gp,G)}b||Ie(!1,ge)}},Et=G=>{R||[" ","ArrowUp","ArrowDown","Enter"].indexOf(G.key)!==-1&&(G.preventDefault(),Ie(!0,G))},Ut=J!==null&&W,At=G=>{!Ut&&C&&(Object.defineProperty(G,"target",{writable:!0,value:{value:D,name:w}}),C(G))};delete L["aria-invalid"];let qe,hn;const dt=[];let Te=!1;(xs({value:D})||p)&&(O?qe=O(D):Te=!0);const Jt=xe.map(G=>{if(!v.isValidElement(G))return null;let ge;if(b){if(!Array.isArray(D))throw new Error(ai(2));ge=D.some(Ve=>oh(Ve,G.props.value)),ge&&Te&&dt.push(G.props.children)}else ge=oh(D,G.props.value),ge&&Te&&(hn=G.props.children);return v.cloneElement(G,{"aria-selected":ge?"true":"false",onClick:St(G),onKeyUp:Ve=>{Ve.key===" "&&Ve.preventDefault(),G.props.onKeyUp&&G.props.onKeyUp(Ve)},role:"option",selected:ge,value:void 0,"data-value":G.props.value})});Te&&(b?dt.length===0?qe=null:qe=dt.reduce((G,ge,Ve)=>(G.push(ge),Ve<dt.length-1&&G.push(", "),G),[]):qe=hn);let Bn=$e;!s&&le&&J&&(Bn=oe.clientWidth);let yn;typeof A<"u"?yn=A:yn=y?null:0;const ye=M.id||(w?`mui-component-select-${w}`:void 0),$=k({},t,{variant:z,value:D,open:Ut,error:f}),gn=wI($),Ba=k({},_.PaperProps,(i=_.slotProps)==null?void 0:i.paper);return m.jsxs(v.Fragment,{children:[m.jsx(gI,k({ref:ct,tabIndex:yn,role:"button","aria-disabled":y?"true":void 0,"aria-expanded":Ut?"true":"false","aria-haspopup":"listbox","aria-label":o,"aria-labelledby":[g,ye].filter(Boolean).join(" ")||void 0,"aria-describedby":a,onKeyDown:Et,onMouseDown:y||R?null:X,onBlur:At,onFocus:q},M,{ownerState:$,className:V(M.className,gn.select,c),id:ye,children:vI(qe)?ah||(ah=m.jsx("span",{className:"notranslate",children:"​"})):qe})),m.jsx(bI,k({"aria-invalid":f,value:Array.isArray(D)?D.join(","):D,name:w,ref:Q,"aria-hidden":!0,onChange:Rn,tabIndex:-1,disabled:y,className:gn.nativeInput,autoFocus:r,ownerState:$},L)),m.jsx(_I,{as:u,className:gn.icon,ownerState:$}),m.jsx(oI,k({id:`menu-${w||""}`,anchorEl:oe,open:Ut,onClose:ue,anchorOrigin:{vertical:"bottom",horizontal:"center"},transformOrigin:{vertical:"top",horizontal:"center"}},_,{MenuListProps:k({"aria-labelledby":g,role:"listbox",disableListWrap:!0},_.MenuListProps),slotProps:{paper:k({},Ba,{style:k({minWidth:Bn},Ba!=null?Ba.style:null)})},children:Jt}))]})}),TI=xI,kI=Wi(m.jsx("path",{d:"M7 10l5 5 5-5z"}),"ArrowDropDown");function CI(e){return m.jsx(s3,k({},e,{defaultTheme:Cl,themeId:Xo}))}function II(e){return me("MuiInputBase",e)}const qI=re("MuiInputBase",["root","formControl","focused","disabled","adornedStart","adornedEnd","error","sizeSmall","multiline","colorSecondary","fullWidth","hiddenLabel","readOnly","input","inputSizeSmall","inputMultiline","inputTypeSearch","inputAdornedStart","inputAdornedEnd","inputHiddenLabel"]),Ia=qI,DI=["aria-describedby","autoComplete","autoFocus","className","color","components","componentsProps","defaultValue","disabled","disableInjectingGlobalStyles","endAdornment","error","fullWidth","id","inputComponent","inputProps","inputRef","margin","maxRows","minRows","multiline","name","onBlur","onChange","onClick","onFocus","onKeyDown","onKeyUp","placeholder","readOnly","renderSuffix","rows","size","slotProps","slots","startAdornment","type","value"],ql=(e,t)=>{const{ownerState:n}=e;return[t.root,n.formControl&&t.formControl,n.startAdornment&&t.adornedStart,n.endAdornment&&t.adornedEnd,n.error&&t.error,n.size==="small"&&t.sizeSmall,n.multiline&&t.multiline,n.color&&t[`color${Z(n.color)}`],n.fullWidth&&t.fullWidth,n.hiddenLabel&&t.hiddenLabel]},Dl=(e,t)=>{const{ownerState:n}=e;return[t.input,n.size==="small"&&t.inputSizeSmall,n.multiline&&t.inputMultiline,n.type==="search"&&t.inputTypeSearch,n.startAdornment&&t.inputAdornedStart,n.endAdornment&&t.inputAdornedEnd,n.hiddenLabel&&t.inputHiddenLabel]},PI=e=>{const{classes:t,color:n,disabled:i,error:a,endAdornment:o,focused:r,formControl:s,fullWidth:l,hiddenLabel:c,multiline:d,readOnly:h,size:y,startAdornment:p,type:f}=e,u={root:["root",`color${Z(n)}`,i&&"disabled",a&&"error",l&&"fullWidth",r&&"focused",s&&"formControl",y&&y!=="medium"&&`size${Z(y)}`,d&&"multiline",p&&"adornedStart",o&&"adornedEnd",c&&"hiddenLabel",h&&"readOnly"],input:["input",i&&"disabled",f==="search"&&"inputTypeSearch",d&&"inputMultiline",y==="small"&&"inputSizeSmall",c&&"inputHiddenLabel",p&&"inputAdornedStart",o&&"inputAdornedEnd",h&&"readOnly"]};return fe(u,II,t)},Pl=F("div",{name:"MuiInputBase",slot:"Root",overridesResolver:ql})(({theme:e,ownerState:t})=>k({},e.typography.body1,{color:(e.vars||e).palette.text.primary,lineHeight:"1.4375em",boxSizing:"border-box",position:"relative",cursor:"text",display:"inline-flex",alignItems:"center",[`&.${Ia.disabled}`]:{color:(e.vars||e).palette.text.disabled,cursor:"default"}},t.multiline&&k({padding:"4px 0 5px"},t.size==="small"&&{paddingTop:1}),t.fullWidth&&{width:"100%"})),Sl=F("input",{name:"MuiInputBase",slot:"Input",overridesResolver:Dl})(({theme:e,ownerState:t})=>{const n=e.palette.mode==="light",i=k({color:"currentColor"},e.vars?{opacity:e.vars.opacity.inputPlaceholder}:{opacity:n?.42:.5},{transition:e.transitions.create("opacity",{duration:e.transitions.duration.shorter})}),a={opacity:"0 !important"},o=e.vars?{opacity:e.vars.opacity.inputPlaceholder}:{opacity:n?.42:.5};return k({font:"inherit",letterSpacing:"inherit",color:"currentColor",padding:"4px 0 5px",border:0,boxSizing:"content-box",background:"none",height:"1.4375em",margin:0,WebkitTapHighlightColor:"transparent",display:"block",minWidth:0,width:"100%",animationName:"mui-auto-fill-cancel",animationDuration:"10ms","&::-webkit-input-placeholder":i,"&::-moz-placeholder":i,"&:-ms-input-placeholder":i,"&::-ms-input-placeholder":i,"&:focus":{outline:0},"&:invalid":{boxShadow:"none"},"&::-webkit-search-decoration":{WebkitAppearance:"none"},[`label[data-shrink=false] + .${Ia.formControl} &`]:{"&::-webkit-input-placeholder":a,"&::-moz-placeholder":a,"&:-ms-input-placeholder":a,"&::-ms-input-placeholder":a,"&:focus::-webkit-input-placeholder":o,"&:focus::-moz-placeholder":o,"&:focus:-ms-input-placeholder":o,"&:focus::-ms-input-placeholder":o},[`&.${Ia.disabled}`]:{opacity:1,WebkitTextFillColor:(e.vars||e).palette.text.disabled},"&:-webkit-autofill":{animationDuration:"5000s",animationName:"mui-auto-fill"}},t.size==="small"&&{paddingTop:1},t.multiline&&{height:"auto",resize:"none",padding:0,paddingTop:0},t.type==="search"&&{MozAppearance:"textfield"})}),SI=m.jsx(CI,{styles:{"@keyframes mui-auto-fill":{from:{display:"block"}},"@keyframes mui-auto-fill-cancel":{from:{display:"block"}}}}),EI=v.forwardRef(function(t,n){var i;const a=he({props:t,name:"MuiInputBase"}),{"aria-describedby":o,autoComplete:r,autoFocus:s,className:l,components:c={},componentsProps:d={},defaultValue:h,disabled:y,disableInjectingGlobalStyles:p,endAdornment:f,fullWidth:u=!1,id:T,inputComponent:g="input",inputProps:_={},inputRef:b,maxRows:w,minRows:C,multiline:I=!1,name:x,onBlur:q,onChange:S,onClick:P,onFocus:R,onKeyDown:O,onKeyUp:M,placeholder:A,readOnly:B,renderSuffix:z,rows:L,slotProps:D={},slots:N={},startAdornment:W,type:te="text",value:Q}=a,Re=U(a,DI),J=_.value!=null?_.value:Q,{current:we}=v.useRef(J!=null),le=v.useRef(),$e=v.useCallback(ye=>{},[]),Pt=Xe(le,b,_.ref,$e),[Be,ct]=v.useState(!1),oe=er(),Ie=Jo({props:a,muiFormControl:oe,states:["color","disabled","error","hiddenLabel","size","required","filled"]});Ie.focused=oe?oe.focused:Be,v.useEffect(()=>{!oe&&y&&Be&&(ct(!1),q&&q())},[oe,y,Be,q]);const X=oe&&oe.onFilled,ue=oe&&oe.onEmpty,xe=v.useCallback(ye=>{xs(ye)?X&&X():ue&&ue()},[X,ue]);oi(()=>{we&&xe({value:J})},[J,xe,we]);const Rn=ye=>{if(Ie.disabled){ye.stopPropagation();return}R&&R(ye),_.onFocus&&_.onFocus(ye),oe&&oe.onFocus?oe.onFocus(ye):ct(!0)},St=ye=>{q&&q(ye),_.onBlur&&_.onBlur(ye),oe&&oe.onBlur?oe.onBlur(ye):ct(!1)},Et=(ye,...$)=>{if(!we){const gn=ye.target||le.current;if(gn==null)throw new Error(ai(1));xe({value:gn.value})}_.onChange&&_.onChange(ye,...$),S&&S(ye,...$)};v.useEffect(()=>{xe(le.current)},[]);const Ut=ye=>{le.current&&ye.currentTarget===ye.target&&le.current.focus(),P&&P(ye)};let At=g,qe=_;I&&At==="input"&&(L?qe=k({type:void 0,minRows:L,maxRows:L},qe):qe=k({type:void 0,maxRows:w,minRows:C},qe),At=_C);const hn=ye=>{xe(ye.animationName==="mui-auto-fill-cancel"?le.current:{value:"x"})};v.useEffect(()=>{oe&&oe.setAdornedStart(!!W)},[oe,W]);const dt=k({},a,{color:Ie.color||"primary",disabled:Ie.disabled,endAdornment:f,error:Ie.error,focused:Ie.focused,formControl:oe,fullWidth:u,hiddenLabel:Ie.hiddenLabel,multiline:I,size:Ie.size,startAdornment:W,type:te}),Te=PI(dt),Jt=N.root||c.Root||Pl,Bn=D.root||d.root||{},yn=N.input||c.Input||Sl;return qe=k({},qe,(i=D.input)!=null?i:d.input),m.jsxs(v.Fragment,{children:[!p&&SI,m.jsxs(Jt,k({},Bn,!Ts(Jt)&&{ownerState:k({},dt,Bn.ownerState)},{ref:n,onClick:Ut},Re,{className:V(Te.root,Bn.className,l,B&&"MuiInputBase-readOnly"),children:[W,m.jsx(wp.Provider,{value:null,children:m.jsx(yn,k({ownerState:dt,"aria-invalid":Ie.error,"aria-describedby":o,autoComplete:r,autoFocus:s,defaultValue:h,disabled:Ie.disabled,id:T,onAnimationStart:hn,name:x,placeholder:A,readOnly:B,required:Ie.required,rows:L,value:J,onKeyDown:O,onKeyUp:M,type:te},qe,!Ts(yn)&&{as:At,ownerState:k({},dt,qe.ownerState)},{ref:Pt,className:V(Te.input,qe.className,B&&"MuiInputBase-readOnly"),onBlur:St,onChange:Et,onFocus:Rn}))}),f,z?z(k({},Ie,{startAdornment:W})):null]}))]})}),Dp=EI;function AI(e){return me("MuiInput",e)}const NI=k({},Ia,re("MuiInput",["root","underline","input"])),Ka=NI,RI=["disableUnderline","components","componentsProps","fullWidth","inputComponent","multiline","slotProps","slots","type"],BI=e=>{const{classes:t,disableUnderline:n}=e,a=fe({root:["root",!n&&"underline"],input:["input"]},AI,t);return k({},t,a)},OI=F(Pl,{shouldForwardProp:e=>Yt(e)||e==="classes",name:"MuiInput",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[...ql(e,t),!n.disableUnderline&&t.underline]}})(({theme:e,ownerState:t})=>{let i=e.palette.mode==="light"?"rgba(0, 0, 0, 0.42)":"rgba(255, 255, 255, 0.7)";return e.vars&&(i=`rgba(${e.vars.palette.common.onBackgroundChannel} / ${e.vars.opacity.inputUnderline})`),k({position:"relative"},t.formControl&&{"label + &":{marginTop:16}},!t.disableUnderline&&{"&:after":{borderBottom:`2px solid ${(e.vars||e).palette[t.color].main}`,left:0,bottom:0,content:'""',position:"absolute",right:0,transform:"scaleX(0)",transition:e.transitions.create("transform",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),pointerEvents:"none"},[`&.${Ka.focused}:after`]:{transform:"scaleX(1) translateX(0)"},[`&.${Ka.error}`]:{"&:before, &:after":{borderBottomColor:(e.vars||e).palette.error.main}},"&:before":{borderBottom:`1px solid ${i}`,left:0,bottom:0,content:'"\\00a0"',position:"absolute",right:0,transition:e.transitions.create("border-bottom-color",{duration:e.transitions.duration.shorter}),pointerEvents:"none"},[`&:hover:not(.${Ka.disabled}, .${Ka.error}):before`]:{borderBottom:`2px solid ${(e.vars||e).palette.text.primary}`,"@media (hover: none)":{borderBottom:`1px solid ${i}`}},[`&.${Ka.disabled}:before`]:{borderBottomStyle:"dotted"}})}),zI=F(Sl,{name:"MuiInput",slot:"Input",overridesResolver:Dl})({}),pb=v.forwardRef(function(t,n){var i,a,o,r;const s=he({props:t,name:"MuiInput"}),{disableUnderline:l,components:c={},componentsProps:d,fullWidth:h=!1,inputComponent:y="input",multiline:p=!1,slotProps:f,slots:u={},type:T="text"}=s,g=U(s,RI),_=BI(s),w={root:{ownerState:{disableUnderline:l}}},C=f??d?Wt(f??d,w):w,I=(i=(a=u.root)!=null?a:c.Root)!=null?i:OI,x=(o=(r=u.input)!=null?r:c.Input)!=null?o:zI;return m.jsx(Dp,k({slots:{root:I,input:x},slotProps:C,fullWidth:h,inputComponent:y,multiline:p,ref:n,type:T},g,{classes:_}))});pb.muiName="Input";const WI=pb;function jI(e){return me("MuiFilledInput",e)}const MI=k({},Ia,re("MuiFilledInput",["root","underline","input"])),mi=MI,LI=["disableUnderline","components","componentsProps","fullWidth","hiddenLabel","inputComponent","multiline","slotProps","slots","type"],FI=e=>{const{classes:t,disableUnderline:n}=e,a=fe({root:["root",!n&&"underline"],input:["input"]},jI,t);return k({},t,a)},UI=F(Pl,{shouldForwardProp:e=>Yt(e)||e==="classes",name:"MuiFilledInput",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[...ql(e,t),!n.disableUnderline&&t.underline]}})(({theme:e,ownerState:t})=>{var n;const i=e.palette.mode==="light",a=i?"rgba(0, 0, 0, 0.42)":"rgba(255, 255, 255, 0.7)",o=i?"rgba(0, 0, 0, 0.06)":"rgba(255, 255, 255, 0.09)",r=i?"rgba(0, 0, 0, 0.09)":"rgba(255, 255, 255, 0.13)",s=i?"rgba(0, 0, 0, 0.12)":"rgba(255, 255, 255, 0.12)";return k({position:"relative",backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o,borderTopLeftRadius:(e.vars||e).shape.borderRadius,borderTopRightRadius:(e.vars||e).shape.borderRadius,transition:e.transitions.create("background-color",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),"&:hover":{backgroundColor:e.vars?e.vars.palette.FilledInput.hoverBg:r,"@media (hover: none)":{backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o}},[`&.${mi.focused}`]:{backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o},[`&.${mi.disabled}`]:{backgroundColor:e.vars?e.vars.palette.FilledInput.disabledBg:s}},!t.disableUnderline&&{"&:after":{borderBottom:`2px solid ${(n=(e.vars||e).palette[t.color||"primary"])==null?void 0:n.main}`,left:0,bottom:0,content:'""',position:"absolute",right:0,transform:"scaleX(0)",transition:e.transitions.create("transform",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),pointerEvents:"none"},[`&.${mi.focused}:after`]:{transform:"scaleX(1) translateX(0)"},[`&.${mi.error}`]:{"&:before, &:after":{borderBottomColor:(e.vars||e).palette.error.main}},"&:before":{borderBottom:`1px solid ${e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / ${e.vars.opacity.inputUnderline})`:a}`,left:0,bottom:0,content:'"\\00a0"',position:"absolute",right:0,transition:e.transitions.create("border-bottom-color",{duration:e.transitions.duration.shorter}),pointerEvents:"none"},[`&:hover:not(.${mi.disabled}, .${mi.error}):before`]:{borderBottom:`1px solid ${(e.vars||e).palette.text.primary}`},[`&.${mi.disabled}:before`]:{borderBottomStyle:"dotted"}},t.startAdornment&&{paddingLeft:12},t.endAdornment&&{paddingRight:12},t.multiline&&k({padding:"25px 12px 8px"},t.size==="small"&&{paddingTop:21,paddingBottom:4},t.hiddenLabel&&{paddingTop:16,paddingBottom:17}))}),GI=F(Sl,{name:"MuiFilledInput",slot:"Input",overridesResolver:Dl})(({theme:e,ownerState:t})=>k({paddingTop:25,paddingRight:12,paddingBottom:8,paddingLeft:12},!e.vars&&{"&:-webkit-autofill":{WebkitBoxShadow:e.palette.mode==="light"?null:"0 0 0 100px #266798 inset",WebkitTextFillColor:e.palette.mode==="light"?null:"#fff",caretColor:e.palette.mode==="light"?null:"#fff",borderTopLeftRadius:"inherit",borderTopRightRadius:"inherit"}},e.vars&&{"&:-webkit-autofill":{borderTopLeftRadius:"inherit",borderTopRightRadius:"inherit"},[e.getColorSchemeSelector("dark")]:{"&:-webkit-autofill":{WebkitBoxShadow:"0 0 0 100px #266798 inset",WebkitTextFillColor:"#fff",caretColor:"#fff"}}},t.size==="small"&&{paddingTop:21,paddingBottom:4},t.hiddenLabel&&{paddingTop:16,paddingBottom:17},t.multiline&&{paddingTop:0,paddingBottom:0,paddingLeft:0,paddingRight:0},t.startAdornment&&{paddingLeft:0},t.endAdornment&&{paddingRight:0},t.hiddenLabel&&t.size==="small"&&{paddingTop:8,paddingBottom:9})),mb=v.forwardRef(function(t,n){var i,a,o,r;const s=he({props:t,name:"MuiFilledInput"}),{components:l={},componentsProps:c,fullWidth:d=!1,inputComponent:h="input",multiline:y=!1,slotProps:p,slots:f={},type:u="text"}=s,T=U(s,LI),g=k({},s,{fullWidth:d,inputComponent:h,multiline:y,type:u}),_=FI(s),b={root:{ownerState:g},input:{ownerState:g}},w=p??c?Wt(p??c,b):b,C=(i=(a=f.root)!=null?a:l.Root)!=null?i:UI,I=(o=(r=f.input)!=null?r:l.Input)!=null?o:GI;return m.jsx(Dp,k({slots:{root:C,input:I},componentsProps:w,fullWidth:d,inputComponent:h,multiline:y,ref:n,type:u},T,{classes:_}))});mb.muiName="Input";const $I=mb;var rh;const VI=["children","classes","className","label","notched"],HI=F("fieldset")({textAlign:"left",position:"absolute",bottom:0,right:0,top:-5,left:0,margin:0,padding:"0 8px",pointerEvents:"none",borderRadius:"inherit",borderStyle:"solid",borderWidth:1,overflow:"hidden",minWidth:"0%"}),ZI=F("legend")(({ownerState:e,theme:t})=>k({float:"unset",width:"auto",overflow:"hidden"},!e.withLabel&&{padding:0,lineHeight:"11px",transition:t.transitions.create("width",{duration:150,easing:t.transitions.easing.easeOut})},e.withLabel&&k({display:"block",padding:0,height:11,fontSize:"0.75em",visibility:"hidden",maxWidth:.01,transition:t.transitions.create("max-width",{duration:50,easing:t.transitions.easing.easeOut}),whiteSpace:"nowrap","& > span":{paddingLeft:5,paddingRight:5,display:"inline-block",opacity:0,visibility:"visible"}},e.notched&&{maxWidth:"100%",transition:t.transitions.create("max-width",{duration:100,easing:t.transitions.easing.easeOut,delay:50})})));function QI(e){const{className:t,label:n,notched:i}=e,a=U(e,VI),o=n!=null&&n!=="",r=k({},e,{notched:i,withLabel:o});return m.jsx(HI,k({"aria-hidden":!0,className:t,ownerState:r},a,{children:m.jsx(ZI,{ownerState:r,children:o?m.jsx("span",{children:n}):rh||(rh=m.jsx("span",{className:"notranslate",children:"​"}))})}))}function KI(e){return me("MuiOutlinedInput",e)}const XI=k({},Ia,re("MuiOutlinedInput",["root","notchedOutline","input"])),zn=XI,YI=["components","fullWidth","inputComponent","label","multiline","notched","slots","type"],JI=e=>{const{classes:t}=e,i=fe({root:["root"],notchedOutline:["notchedOutline"],input:["input"]},KI,t);return k({},t,i)},eq=F(Pl,{shouldForwardProp:e=>Yt(e)||e==="classes",name:"MuiOutlinedInput",slot:"Root",overridesResolver:ql})(({theme:e,ownerState:t})=>{const n=e.palette.mode==="light"?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)";return k({position:"relative",borderRadius:(e.vars||e).shape.borderRadius,[`&:hover .${zn.notchedOutline}`]:{borderColor:(e.vars||e).palette.text.primary},"@media (hover: none)":{[`&:hover .${zn.notchedOutline}`]:{borderColor:e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / 0.23)`:n}},[`&.${zn.focused} .${zn.notchedOutline}`]:{borderColor:(e.vars||e).palette[t.color].main,borderWidth:2},[`&.${zn.error} .${zn.notchedOutline}`]:{borderColor:(e.vars||e).palette.error.main},[`&.${zn.disabled} .${zn.notchedOutline}`]:{borderColor:(e.vars||e).palette.action.disabled}},t.startAdornment&&{paddingLeft:14},t.endAdornment&&{paddingRight:14},t.multiline&&k({padding:"16.5px 14px"},t.size==="small"&&{padding:"8.5px 14px"}))}),tq=F(QI,{name:"MuiOutlinedInput",slot:"NotchedOutline",overridesResolver:(e,t)=>t.notchedOutline})(({theme:e})=>{const t=e.palette.mode==="light"?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)";return{borderColor:e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / 0.23)`:t}}),nq=F(Sl,{name:"MuiOutlinedInput",slot:"Input",overridesResolver:Dl})(({theme:e,ownerState:t})=>k({padding:"16.5px 14px"},!e.vars&&{"&:-webkit-autofill":{WebkitBoxShadow:e.palette.mode==="light"?null:"0 0 0 100px #266798 inset",WebkitTextFillColor:e.palette.mode==="light"?null:"#fff",caretColor:e.palette.mode==="light"?null:"#fff",borderRadius:"inherit"}},e.vars&&{"&:-webkit-autofill":{borderRadius:"inherit"},[e.getColorSchemeSelector("dark")]:{"&:-webkit-autofill":{WebkitBoxShadow:"0 0 0 100px #266798 inset",WebkitTextFillColor:"#fff",caretColor:"#fff"}}},t.size==="small"&&{padding:"8.5px 14px"},t.multiline&&{padding:0},t.startAdornment&&{paddingLeft:0},t.endAdornment&&{paddingRight:0})),fb=v.forwardRef(function(t,n){var i,a,o,r,s;const l=he({props:t,name:"MuiOutlinedInput"}),{components:c={},fullWidth:d=!1,inputComponent:h="input",label:y,multiline:p=!1,notched:f,slots:u={},type:T="text"}=l,g=U(l,YI),_=JI(l),b=er(),w=Jo({props:l,muiFormControl:b,states:["color","disabled","error","focused","hiddenLabel","size","required"]}),C=k({},l,{color:w.color||"primary",disabled:w.disabled,error:w.error,focused:w.focused,formControl:b,fullWidth:d,hiddenLabel:w.hiddenLabel,multiline:p,size:w.size,type:T}),I=(i=(a=u.root)!=null?a:c.Root)!=null?i:eq,x=(o=(r=u.input)!=null?r:c.Input)!=null?o:nq;return m.jsx(Dp,k({slots:{root:I,input:x},renderSuffix:q=>m.jsx(tq,{ownerState:C,className:_.notchedOutline,label:y!=null&&y!==""&&w.required?s||(s=m.jsxs(v.Fragment,{children:[y," ","*"]})):y,notched:typeof f<"u"?f:!!(q.startAdornment||q.filled||q.focused)}),fullWidth:d,inputComponent:h,multiline:p,ref:n,type:T},g,{classes:k({},_,{notchedOutline:null})}))});fb.muiName="Input";const iq=fb,aq=["autoWidth","children","classes","className","defaultOpen","displayEmpty","IconComponent","id","input","inputProps","label","labelId","MenuProps","multiple","native","onClose","onOpen","open","renderValue","SelectDisplayProps","variant"],oq=["root"],rq=e=>{const{classes:t}=e;return t},Pp={name:"MuiSelect",overridesResolver:(e,t)=>t.root,shouldForwardProp:e=>Yt(e)&&e!=="variant",slot:"Root"},sq=F(WI,Pp)(""),lq=F(iq,Pp)(""),cq=F($I,Pp)(""),hb=v.forwardRef(function(t,n){const i=he({name:"MuiSelect",props:t}),{autoWidth:a=!1,children:o,classes:r={},className:s,defaultOpen:l=!1,displayEmpty:c=!1,IconComponent:d=kI,id:h,input:y,inputProps:p,label:f,labelId:u,MenuProps:T,multiple:g=!1,native:_=!1,onClose:b,onOpen:w,open:C,renderValue:I,SelectDisplayProps:x,variant:q="outlined"}=i,S=U(i,aq),P=_?mI:TI,R=er(),O=Jo({props:i,muiFormControl:R,states:["variant","error"]}),M=O.variant||q,A=k({},i,{variant:M,classes:r}),B=rq(A),z=U(B,oq),L=y||{standard:m.jsx(sq,{ownerState:A}),outlined:m.jsx(lq,{label:f,ownerState:A}),filled:m.jsx(cq,{ownerState:A})}[M],D=Xe(n,L.ref);return m.jsx(v.Fragment,{children:v.cloneElement(L,k({inputComponent:P,inputProps:k({children:o,error:O.error,IconComponent:d,variant:M,type:void 0,multiple:g},_?{id:h}:{autoWidth:a,defaultOpen:l,displayEmpty:c,labelId:u,MenuProps:T,onClose:b,onOpen:w,open:C,renderValue:I,SelectDisplayProps:k({id:h},x)},p,{classes:p?Wt(z,p.classes):z},y?y.props.inputProps:{})},g&&_&&M==="outlined"?{notched:!0}:{},{ref:D,className:V(L.props.className,s,B.root)},!y&&{variant:M},S))})});hb.muiName="Select";const dq=hb,uq=fn.plugins,yb=v.createContext(),gb=()=>v.useContext(yb),pq=({children:e})=>{const[t,n]=v.useState("release"),[i,a]=v.useState(uq);return m.jsx(yb.Provider,{value:{sortOption:t,setSortOption:n,sortedData:i,setSortedData:a},children:e})},xc=fn.plugins;function mq(){const{setSearchQuery:e,setIsSearchSubmitted:t}=Yo(),{sortOption:n,setSortOption:i,setSortedData:a}=gb();v.useEffect(()=>{document.documentElement.style.scrollBehavior="auto",l(n),o()},[n]);function o(){var c=window.scrollY;window.onscroll=function(){var d=window.scrollY;c>d?document.querySelector("header").style.top="0":c>150&&(document.querySelector("header").style.top="-155px"),c=d}}function r(c){const d=Object.entries(c);return d.sort(([,h],[,y])=>y.commits_count-h.commits_count),Object.fromEntries(d)}function s(c){const d=Object.entries(c);return d.sort(([,h],[,y])=>!h.metadata.release_date&&!y.metadata.release_date?0:h.metadata.release_date?y.metadata.release_date?new Date(y.metadata.release_date)-new Date(h.metadata.release_date):-1:1),Object.fromEntries(d)}const l=c=>{i(c),e(""),t(!1);let d={};c==="commits"?d=r(xc):c=="alpha"?d=xc:c=="release"&&(d=s(xc)),a(d)};return m.jsx(wT,{children:m.jsxs(Wk,{children:[m.jsx(OT,{children:"Sort"}),m.jsxs(dq,{value:n,label:"Sort",onChange:c=>l(c.target.value),children:[m.jsx(gc,{value:"commits",children:"Commits Count"}),m.jsx(gc,{value:"alpha",children:"Alphabetical"}),m.jsx(gc,{value:"release",children:"Recent Release"})]})]})})}var Sp={},fq=Ju;Object.defineProperty(Sp,"__esModule",{value:!0});var _b=Sp.default=void 0,hq=fq(_p()),yq=m,gq=(0,hq.default)((0,yq.jsx)("path",{d:"M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z"}),"CheckCircle");_b=Sp.default=gq;function _q(e){return me("MuiDialog",e)}const bq=re("MuiDialog",["root","scrollPaper","scrollBody","container","paper","paperScrollPaper","paperScrollBody","paperWidthFalse","paperWidthXs","paperWidthSm","paperWidthMd","paperWidthLg","paperWidthXl","paperFullWidth","paperFullScreen"]),Tc=bq,vq=v.createContext({}),bb=vq,wq=["aria-describedby","aria-labelledby","BackdropComponent","BackdropProps","children","className","disableEscapeKeyDown","fullScreen","fullWidth","maxWidth","onBackdropClick","onClose","open","PaperComponent","PaperProps","scroll","TransitionComponent","transitionDuration","TransitionProps"],xq=F(lb,{name:"MuiDialog",slot:"Backdrop",overrides:(e,t)=>t.backdrop})({zIndex:-1}),Tq=e=>{const{classes:t,scroll:n,maxWidth:i,fullWidth:a,fullScreen:o}=e,r={root:["root"],container:["container",`scroll${Z(n)}`],paper:["paper",`paperScroll${Z(n)}`,`paperWidth${Z(String(i))}`,a&&"paperFullWidth",o&&"paperFullScreen"]};return fe(r,_q,t)},kq=F(Ip,{name:"MuiDialog",slot:"Root",overridesResolver:(e,t)=>t.root})({"@media print":{position:"absolute !important"}}),Cq=F("div",{name:"MuiDialog",slot:"Container",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.container,t[`scroll${Z(n.scroll)}`]]}})(({ownerState:e})=>k({height:"100%","@media print":{height:"auto"},outline:0},e.scroll==="paper"&&{display:"flex",justifyContent:"center",alignItems:"center"},e.scroll==="body"&&{overflowY:"auto",overflowX:"hidden",textAlign:"center","&:after":{content:'""',display:"inline-block",verticalAlign:"middle",height:"100%",width:"0"}})),Iq=F(tr,{name:"MuiDialog",slot:"Paper",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.paper,t[`scrollPaper${Z(n.scroll)}`],t[`paperWidth${Z(String(n.maxWidth))}`],n.fullWidth&&t.paperFullWidth,n.fullScreen&&t.paperFullScreen]}})(({theme:e,ownerState:t})=>k({margin:32,position:"relative",overflowY:"auto","@media print":{overflowY:"visible",boxShadow:"none"}},t.scroll==="paper"&&{display:"flex",flexDirection:"column",maxHeight:"calc(100% - 64px)"},t.scroll==="body"&&{display:"inline-block",verticalAlign:"middle",textAlign:"left"},!t.maxWidth&&{maxWidth:"calc(100% - 64px)"},t.maxWidth==="xs"&&{maxWidth:e.breakpoints.unit==="px"?Math.max(e.breakpoints.values.xs,444):`max(${e.breakpoints.values.xs}${e.breakpoints.unit}, 444px)`,[`&.${Tc.paperScrollBody}`]:{[e.breakpoints.down(Math.max(e.breakpoints.values.xs,444)+32*2)]:{maxWidth:"calc(100% - 64px)"}}},t.maxWidth&&t.maxWidth!=="xs"&&{maxWidth:`${e.breakpoints.values[t.maxWidth]}${e.breakpoints.unit}`,[`&.${Tc.paperScrollBody}`]:{[e.breakpoints.down(e.breakpoints.values[t.maxWidth]+32*2)]:{maxWidth:"calc(100% - 64px)"}}},t.fullWidth&&{width:"calc(100% - 64px)"},t.fullScreen&&{margin:0,width:"100%",maxWidth:"100%",height:"100%",maxHeight:"none",borderRadius:0,[`&.${Tc.paperScrollBody}`]:{margin:0,maxWidth:"100%"}})),qq=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiDialog"}),a=Ra(),o={enter:a.transitions.duration.enteringScreen,exit:a.transitions.duration.leavingScreen},{"aria-describedby":r,"aria-labelledby":s,BackdropComponent:l,BackdropProps:c,children:d,className:h,disableEscapeKeyDown:y=!1,fullScreen:p=!1,fullWidth:f=!1,maxWidth:u="sm",onBackdropClick:T,onClose:g,open:_,PaperComponent:b=tr,PaperProps:w={},scroll:C="paper",TransitionComponent:I=sb,transitionDuration:x=o,TransitionProps:q}=i,S=U(i,wq),P=k({},i,{disableEscapeKeyDown:y,fullScreen:p,fullWidth:f,maxWidth:u,scroll:C}),R=Tq(P),O=v.useRef(),M=L=>{O.current=L.target===L.currentTarget},A=L=>{O.current&&(O.current=null,T&&T(L),g&&g(L,"backdropClick"))},B=c_(s),z=v.useMemo(()=>({titleId:B}),[B]);return m.jsx(kq,k({className:V(R.root,h),closeAfterTransition:!0,components:{Backdrop:xq},componentsProps:{backdrop:k({transitionDuration:x,as:l},c)},disableEscapeKeyDown:y,onClose:g,open:_,ref:n,onClick:A,ownerState:P},S,{children:m.jsx(I,k({appear:!0,in:_,timeout:x,role:"presentation"},q,{children:m.jsx(Cq,{className:V(R.container),onMouseDown:M,ownerState:P,children:m.jsx(Iq,k({as:b,elevation:24,role:"dialog","aria-describedby":r,"aria-labelledby":B},w,{className:V(R.paper,w.className),ownerState:P,children:m.jsx(bb.Provider,{value:z,children:d})}))})}))}))}),Dq=qq;function Pq(e){return me("MuiDialogContent",e)}re("MuiDialogContent",["root","dividers"]);function Sq(e){return me("MuiDialogTitle",e)}const Eq=re("MuiDialogTitle",["root"]),Aq=Eq,Nq=["className","dividers"],Rq=e=>{const{classes:t,dividers:n}=e;return fe({root:["root",n&&"dividers"]},Pq,t)},Bq=F("div",{name:"MuiDialogContent",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.dividers&&t.dividers]}})(({theme:e,ownerState:t})=>k({flex:"1 1 auto",WebkitOverflowScrolling:"touch",overflowY:"auto",padding:"20px 24px"},t.dividers?{padding:"16px 24px",borderTop:`1px solid ${(e.vars||e).palette.divider}`,borderBottom:`1px solid ${(e.vars||e).palette.divider}`}:{[`.${Aq.root} + &`]:{paddingTop:0}})),Oq=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiDialogContent"}),{className:a,dividers:o=!1}=i,r=U(i,Nq),s=k({},i,{dividers:o}),l=Rq(s);return m.jsx(Bq,k({className:V(l.root,a),ownerState:s,ref:n},r))}),zq=Oq;function Wq(e){return me("MuiDialogContentText",e)}re("MuiDialogContentText",["root"]);const jq=["children","className"],Mq=e=>{const{classes:t}=e,i=fe({root:["root"]},Wq,t);return k({},t,i)},Lq=F(ib,{shouldForwardProp:e=>Yt(e)||e==="classes",name:"MuiDialogContentText",slot:"Root",overridesResolver:(e,t)=>t.root})({}),Fq=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiDialogContentText"}),{className:a}=i,o=U(i,jq),r=Mq(o);return m.jsx(Lq,k({component:"p",variant:"body1",color:"text.secondary",ref:n,ownerState:o,className:V(r.root,a)},i,{classes:r}))}),Uq=Fq,Gq=["className","id"],$q=e=>{const{classes:t}=e;return fe({root:["root"]},Sq,t)},Vq=F(ib,{name:"MuiDialogTitle",slot:"Root",overridesResolver:(e,t)=>t.root})({padding:"16px 24px",flex:"0 0 auto"}),Hq=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiDialogTitle"}),{className:a,id:o}=i,r=U(i,Gq),s=i,l=$q(s),{titleId:c=o}=v.useContext(bb);return m.jsx(Vq,k({component:"h2",className:V(l.root,a),ownerState:s,ref:n,variant:"h6",id:o??c},r))}),Zq=Hq,vb="data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACMAAAAhCAYAAABTERJSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAFhgAABYYBG6Yz4AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAUbSURBVFiFzZhrbFRVEMd%2Fc%2B5uu6UUbIFC%2FUAUVEQCLbQJBIiBDyiImJiIhmohYNCkqJAQxASLF8tDgYRHBLXRhIcKNtFEhVDgAxBJqgmVh4JEKg3EIn2QYqBlt917xg%2BFss%2ByaDHOtzsz5z%2B%2FuZl7ztmF%2F5HJvxVQN6cPYX8%2FPLnOmsvNAvqfwuib%2FbNIk9cQeQnLcKRL5xLIV%2Fic9eJeunjPYbRs4FjQSpTB3aS1IpRKeeOOewajy%2FKKEO8Q0DuVdKy8IqsbPulxGHUfCBBu%2BwUYGuFuBTK7wQnht6PEbf4tlRomVRjCbXNjQEB0AyrFQOL5ENIJm7dTLZE6DPJCnEtFZVXDLny%2B4Sjv0PmmYu1ZdUek9RiMgoDmJ8V0L7XJqsZ3UW8YsBOwEeHeeFce7jEYXBy0m9m4BbXqSj2%2Bxnkg26MCVrN6DEZcwggtd8pTFx%2Fh3B9B50YLaFOPwXQKUt0tBLegtSomfBlfY13PwijbEnhztGzgJsK5h9W9qeWwBqjvyhB2iBs1Qz0AU974DciRGO8CVN8AJhAeMAdA3KbrKEtvxhsI%2B9emWiJlGBEU680Cfk%2BSsVqXZvcFYGXjF8ABVJ%2BTNfVXehyms1zzn1gmIOxLEB6E31%2FWBe5rnCarmo7elf7dJEeaLh80GasliI5F6Q9cAz1GY1OJVNDxTzQTw7iY%2FHEZRQY7xqJ9RU2LFe%2FYqakdP911ha0XhjjiTVAkDwgatWfCGeYocx8M3glG8g8EXhSrLrHnEFJ5Ymow%2FkhIYv6ttYUW1iFmEqqxdVoUs9FmsDYSqmtmJh3Cl1%2BVtl2s7owDUdocR5bceiyoSivGTT5vzpbzL1uoBpmcAAQgW7ArnKD9ng9rc%2BNgrobSNwpSkkhcRN%2BvmXLjIsDovYHHEfmsYFygPAnIDEQrQPzJYCOaLHLUfIt7Oq0LJn9fxkSgNCb1qEIQ5UKgT%2Fs6gJmVOOroJhQBXVqw118QtWLdyUxEP45sUpSzqP7RDdFYMyB9UReMiF1MzPwoUqHt8hjGFFeP5wZAbZ%2F0%2BcAtAAcji6LeSq%2FMYiAvSsdw3GtrfVSVFUBbIhwRWYR7yOcr%2FBi%2FB1MSJZ16JlgH1AGM3EO2QnmMyrSbTSiACgFBv4yCUapZkt9qwWVL7aeOyHvArJjm8%2Fz9BhdI4XcZgz2%2FvRALosjsk1ODOyMcJn9%2FYI6IrkS5vxMGdUwou2YKfyVqJpn5t9aNs3gbQMbdbkxnGdsr4bTHm2AxWo9yNZK4PXR3uzhAh%2BM0AZejnCrGdy0UvJxl0oMKgWSLR%2B1LH2aE9ViejiFs%2BXn6bTjng3MlIhJ1I1TkuLdg6OcAbD7Xx%2Bc3y9TrWAiSHqVkbZ2v9ilCo6s4AjwZCzFyD9mOL305nV9aonvsQeT2L0gVk4OwOJqXXVRW7naaxswDKVdlYLyMXAnntteYmws2xcVVZzq%2BtHPAooQggmJkc6TLSusOiL4RKgwzzYU1iFQgiUBA1H7E8yPau%2BZl9P7AblVNebtHqTgxLfRqrNvZWjsHZFuqMqKcDWdlFjF7UGvX8Jn24DyEAykJwNcdg0OvJ4p5pQ9tV6SMlP4A0PNh8aYze1ArROyUNTNouy8tNF3Rt0CSXb6bRFl4%2FIfQzNMjaE9WwpYOWQnOdEF%2BTdJNO0iFh7%2BI0kfORzQZb6P2kymS9oTxzBiM9rUqLWr1WE5G6ODhycQd%2FUnNVeMbcH68hYkGycNoUNWc8fxaxfwhDbHpfwM5oeTY7rUX8QAAAABJRU5ErkJggg%3D%3D";const sh=fn.status_dict,Qq="/aiida-registry/pr-preview/pr-280/";function Kq(){const{sortOption:e,sortedData:t}=gb();return m.jsx(m.Fragment,{children:Object.entries(t).map(([n,i])=>m.jsxs("div",{className:"submenu-entry",children:[m.jsx(Ri,{to:`/${n}`,children:m.jsxs("h2",{style:{display:"inline"},children:[n," "]})}),i.is_installable==="True"&&m.jsx(Xq,{}),m.jsxs("p",{className:"currentstate",children:[m.jsx("img",{className:"svg-badge",src:`${Qq}${sh[i.development_status][1]}`,title:sh[i.development_status][0]})," ",i.aiida_version&&m.jsx("img",{className:"svg-badge",title:`Compatible with aiida-core ${i.aiida_version}`,src:`https://img.shields.io/badge/AiiDA-${i.aiida_version}-007ec6.svg?logo=${vb}`}),e==="commits"&&m.jsx("img",{className:"svg-badge",style:{padding:"3px"},src:`https://img.shields.io/badge/Yearly%20Commits-${i.commits_count}-007ec6.svg`}),e==="release"&&i.metadata.release_date&&m.jsx("img",{className:"svg-badge",style:{padding:"3px"},src:`https://img.shields.io/badge/Recent%20Release-${i.metadata.release_date.replace(/-/g,"/")}-007ec6.svg`})]}),m.jsx("p",{children:i.metadata.description}),m.jsxs("ul",{className:"plugin-info",children:[m.jsx("li",{children:m.jsx("a",{href:i.code_home,children:"Source Code"})}),i.documentation_url&&m.jsx("li",{children:m.jsx("a",{href:i.documentation_url,children:"Documentation"})}),m.jsx("li",{children:m.jsx(Ri,{to:`/${n}`,children:"Plugin details"})})]}),i.summaryinfo&&m.jsx(m.Fragment,{children:m.jsx("p",{className:"summaryinfo",children:i.summaryinfo.map(a=>m.jsxs("span",{className:"badge",children:[m.jsx("span",{className:`badge-left ${a.colorclass}`,children:a.text}),m.jsx("span",{className:"badge-right",children:a.count})]},a.text))})})]},n))})}function Xq(){const[e,t]=v.useState(!1),n=()=>{t(!0)},i=()=>{t(!1)};return m.jsxs(m.Fragment,{children:[m.jsxs("div",{className:"classbox",style:{backgroundColor:"transparent"},children:[m.jsx(_b,{onClick:n,style:{color:"green",cursor:"pointer",marginBottom:"-5"}}),m.jsx("span",{className:"tooltiptext",children:"Plugin successfully installed"})]}),m.jsxs(Dq,{open:e,onClose:i,children:[m.jsx(Zq,{children:"This plugin can be installed with the latest aiida-core version."}),m.jsx(zq,{children:m.jsxs(Uq,{children:["This check mark indicates that this plugin was installed successfully inside the latest",m.jsxs("a",{rel:"noopener noreferrer",target:"_blank",href:"https://hub.docker.com/r/aiidateam/aiida-core",children:[m.jsx("code",{children:" aiida-core"})," docker image"]}),". For in-depth compatibility tests see the source code repository of the plugin."]})})]})]})}const Yq=fn.globalsummary,Jq=fn.plugins,eD=Object.keys(Jq).length;function tD(){return m.jsxs(m.Fragment,{children:[m.jsxs("h2",{children:["Registered plugin packages: ",eD]}),m.jsx("div",{className:"globalsummary-box",children:m.jsx("div",{style:{display:"table"},children:Yq.map(e=>m.jsxs("span",{className:"badge",style:{display:"table-row",lineHeight:2},children:[m.jsx("span",{style:{display:"table-cell",float:"none",textAlign:"right"},children:m.jsxs("span",{className:`badge-left ${e.colorclass} tooltip`,style:{float:"none",display:"inline",textAlign:"right",border:"none"},children:[e.name,e.tooltip&&m.jsx("span",{className:"tooltiptext",children:e.tooltip})]})}),m.jsx("span",{style:{display:"table-cell",float:"none",textAlign:"left"},children:m.jsxs("span",{className:"badge-right",style:{float:"none",display:"inline",textAlign:"left",border:"none"},children:[e.total_num," plugin",e.total_num!==1?"s":""," in ",e.num_entries," package",e.num_entries!==1?"s":""]})})]},e.name))})})]})}function nD(){const{isSearchSubmitted:e}=Yo();return m.jsxs("main",{className:"fade-enter",children:[m.jsx(tD,{}),m.jsxs("div",{id:"entrylist",children:[m.jsx("h1",{children:"Package list"}),m.jsxs("div",{className:"bar-container",children:[m.jsx("div",{style:{flex:"1",marginRight:"10px"},children:m.jsx(yT,{})}),m.jsx(mq,{})]}),e===!0?m.jsx(gT,{}):m.jsx(Kq,{})]})]})}function vi(){return vi=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},vi.apply(this,arguments)}const iD=["children","options"],lh=["allowFullScreen","allowTransparency","autoComplete","autoFocus","autoPlay","cellPadding","cellSpacing","charSet","className","classId","colSpan","contentEditable","contextMenu","crossOrigin","encType","formAction","formEncType","formMethod","formNoValidate","formTarget","frameBorder","hrefLang","inputMode","keyParams","keyType","marginHeight","marginWidth","maxLength","mediaGroup","minLength","noValidate","radioGroup","readOnly","rowSpan","spellCheck","srcDoc","srcLang","srcSet","tabIndex","useMap"].reduce((e,t)=>(e[t.toLowerCase()]=t,e),{for:"htmlFor"}),ch={amp:"&",apos:"'",gt:">",lt:"<",nbsp:" ",quot:"“"},aD=["style","script"],oD=/([-A-Z0-9_:]+)(?:\s*=\s*(?:(?:"((?:\\.|[^"])*)")|(?:'((?:\\.|[^'])*)')|(?:\{((?:\\.|{[^}]*?}|[^}])*)\})))?/gi,rD=/mailto:/i,sD=/\n{2,}$/,wb=/^( *>[^\n]+(\n[^\n]+)*\n*)+\n{2,}/,lD=/^ *> ?/gm,cD=/^ {2,}\n/,dD=/^(?:( *[-*_])){3,} *(?:\n *)+\n/,xb=/^\s*(`{3,}|~{3,}) *(\S+)?([^\n]*?)?\n([\s\S]+?)\s*\1 *(?:\n *)*\n?/,Tb=/^(?: {4}[^\n]+\n*)+(?:\n *)+\n?/,uD=/^(`+)\s*([\s\S]*?[^`])\s*\1(?!`)/,pD=/^(?:\n *)*\n/,mD=/\r\n?/g,fD=/^\[\^([^\]]+)](:.*)\n/,hD=/^\[\^([^\]]+)]/,yD=/\f/g,gD=/^\s*?\[(x|\s)\]/,kb=/^ *(#{1,6}) *([^\n]+?)(?: +#*)?(?:\n *)*(?:\n|$)/,Cb=/^ *(#{1,6}) +([^\n]+?)(?: +#*)?(?:\n *)*(?:\n|$)/,Ib=/^([^\n]+)\n *(=|-){3,} *(?:\n *)+\n/,Qd=/^ *(?!<[a-z][^ >/]* ?\/>)<([a-z][^ >/]*) ?([^>]*)\/{0}>\n?(\s*(?:<\1[^>]*?>[\s\S]*?<\/\1>|(?!<\1)[\s\S])*?)<\/\1>\n*/i,_D=/&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-fA-F]{1,6});/gi,qb=/^<!--[\s\S]*?(?:-->)/,bD=/^(data|aria|x)-[a-z_][a-z\d_.-]*$/,Kd=/^ *<([a-z][a-z0-9:]*)(?:\s+((?:<.*?>|[^>])*))?\/?>(?!<\/\1>)(\s*\n)?/i,vD=/^\{.*\}$/,wD=/^(https?:\/\/[^\s<]+[^<.,:;"')\]\s])/,xD=/^<([^ >]+@[^ >]+)>/,TD=/^<([^ >]+:\/[^ >]+)>/,kD=/-([a-z])?/gi,Db=/^(.*\|?.*)\n *(\|? *[-:]+ *\|[-| :]*)\n((?:.*\|.*\n)*)\n?/,CD=/^\[([^\]]*)\]:\s+<?([^\s>]+)>?\s*("([^"]*)")?/,ID=/^!\[([^\]]*)\] ?\[([^\]]*)\]/,qD=/^\[([^\]]*)\] ?\[([^\]]*)\]/,DD=/(\[|\])/g,PD=/(\n|^[-*]\s|^#|^ {2,}|^-{2,}|^>\s)/,SD=/\t/g,ED=/^ *\| */,AD=/(^ *\||\| *$)/g,ND=/ *$/,RD=/^ *:-+: *$/,BD=/^ *:-+ *$/,OD=/^ *-+: *$/,zD=/^([*_])\1((?:\[.*?\][([].*?[)\]]|<.*?>(?:.*?<.*?>)?|`.*?`|~+.*?~+|.)*?)\1\1(?!\1)/,WD=/^([*_])((?:\[.*?\][([].*?[)\]]|<.*?>(?:.*?<.*?>)?|`.*?`|~+.*?~+|.)*?)\1(?!\1|\w)/,jD=/^==((?:\[.*?\]|<.*?>(?:.*?<.*?>)?|`.*?`|.)*?)==/,MD=/^~~((?:\[.*?\]|<.*?>(?:.*?<.*?>)?|`.*?`|.)*?)~~/,LD=/^\\([^0-9A-Za-z\s])/,FD=/^[\s\S]+?(?=[^0-9A-Z\s\u00c0-\uffff&#;.()'"]|\d+\.|\n\n| {2,}\n|\w+:\S|$)/i,UD=/^\n+/,GD=/^([ \t]*)/,$D=/\\([^\\])/g,dh=/ *\n+$/,VD=/(?:^|\n)( *)$/,Ep="(?:\\d+\\.)",Ap="(?:[*+-])";function Pb(e){return"( *)("+(e===1?Ep:Ap)+") +"}const Sb=Pb(1),Eb=Pb(2);function Ab(e){return new RegExp("^"+(e===1?Sb:Eb))}const HD=Ab(1),ZD=Ab(2);function Nb(e){return new RegExp("^"+(e===1?Sb:Eb)+"[^\\n]*(?:\\n(?!\\1"+(e===1?Ep:Ap)+" )[^\\n]*)*(\\n|$)","gm")}const Rb=Nb(1),Bb=Nb(2);function Ob(e){const t=e===1?Ep:Ap;return new RegExp("^( *)("+t+") [\\s\\S]+?(?:\\n{2,}(?! )(?!\\1"+t+" (?!"+t+" ))\\n*|\\s*\\n*$)")}const zb=Ob(1),Wb=Ob(2);function uh(e,t){const n=t===1,i=n?zb:Wb,a=n?Rb:Bb,o=n?HD:ZD;return{t(r,s,l){const c=VD.exec(l);return c&&(s.o||!s._&&!s.u)?i.exec(r=c[1]+r):null},i:ee.HIGH,l(r,s,l){const c=n?+r[2]:void 0,d=r[0].replace(sD,`
`).match(a);let h=!1;return{p:d.map(function(y,p){const f=o.exec(y)[0].length,u=new RegExp("^ {1,"+f+"}","gm"),T=y.replace(u,"").replace(o,""),g=p===d.length-1,_=T.indexOf(`

`)!==-1||g&&h;h=_;const b=l._,w=l.o;let C;l.o=!0,_?(l._=!1,C=T.replace(dh,`

`)):(l._=!0,C=T.replace(dh,""));const I=s(C,l);return l._=b,l.o=w,I}),m:n,g:c}},h:(r,s,l)=>e(r.m?"ol":"ul",{key:l.k,start:r.g},r.p.map(function(c,d){return e("li",{key:d},s(c,l))}))}}const QD=/^\[([^\]]*)]\( *((?:\([^)]*\)|[^() ])*) *"?([^)"]*)?"?\)/,KD=/^!\[([^\]]*)]\( *((?:\([^)]*\)|[^() ])*) *"?([^)"]*)?"?\)/,jb=[wb,xb,Tb,kb,Ib,Cb,qb,Db,Rb,zb,Bb,Wb],XD=[...jb,/^[^\n]+(?:  \n|\n{2,})/,Qd,Kd];function YD(e){return e.replace(/[ÀÁÂÃÄÅàáâãäåæÆ]/g,"a").replace(/[çÇ]/g,"c").replace(/[ðÐ]/g,"d").replace(/[ÈÉÊËéèêë]/g,"e").replace(/[ÏïÎîÍíÌì]/g,"i").replace(/[Ññ]/g,"n").replace(/[øØœŒÕõÔôÓóÒò]/g,"o").replace(/[ÜüÛûÚúÙù]/g,"u").replace(/[ŸÿÝý]/g,"y").replace(/[^a-z0-9- ]/gi,"").replace(/ /gi,"-").toLowerCase()}function JD(e){return OD.test(e)?"right":RD.test(e)?"center":BD.test(e)?"left":null}function ph(e,t,n){const i=n.$;n.$=!0;const a=t(e.trim(),n);n.$=i;let o=[[]];return a.forEach(function(r,s){r.type==="tableSeparator"?s!==0&&s!==a.length-1&&o.push([]):(r.type!=="text"||a[s+1]!=null&&a[s+1].type!=="tableSeparator"||(r.v=r.v.replace(ND,"")),o[o.length-1].push(r))}),o}function e9(e,t,n){n._=!0;const i=ph(e[1],t,n),a=e[2].replace(AD,"").split("|").map(JD),o=function(r,s,l){return r.trim().split(`
`).map(function(c){return ph(c,s,l)})}(e[3],t,n);return n._=!1,{S:a,A:o,L:i,type:"table"}}function mh(e,t){return e.S[t]==null?{}:{textAlign:e.S[t]}}function Wn(e){return function(t,n){return n._?e.exec(t):null}}function jn(e){return function(t,n){return n._||n.u?e.exec(t):null}}function _n(e){return function(t,n){return n._||n.u?null:e.exec(t)}}function Xa(e){return function(t){return e.exec(t)}}function t9(e,t,n){if(t._||t.u||n&&!n.endsWith(`
`))return null;let i="";e.split(`
`).every(o=>!jb.some(r=>r.test(o))&&(i+=o+`
`,o.trim()));const a=i.trimEnd();return a==""?null:[i,a]}function Hi(e){try{if(decodeURIComponent(e).replace(/[^A-Za-z0-9/:]/g,"").match(/^\s*(javascript|vbscript|data(?!:image)):/i))return}catch{return null}return e}function fh(e){return e.replace($D,"$1")}function Fr(e,t,n){const i=n._||!1,a=n.u||!1;n._=!0,n.u=!0;const o=e(t,n);return n._=i,n.u=a,o}function n9(e,t,n){const i=n._||!1,a=n.u||!1;n._=!1,n.u=!0;const o=e(t,n);return n._=i,n.u=a,o}function i9(e,t,n){return n._=!1,e(t,n)}const kc=(e,t,n)=>({v:Fr(t,e[1],n)});function Cc(){return{}}function Ic(){return null}function a9(...e){return e.filter(Boolean).join(" ")}function qc(e,t,n){let i=e;const a=t.split(".");for(;a.length&&(i=i[a[0]],i!==void 0);)a.shift();return i||n}var ee;function o9(e,t={}){t.overrides=t.overrides||{},t.slugify=t.slugify||YD,t.namedCodesToUnicode=t.namedCodesToUnicode?vi({},ch,t.namedCodesToUnicode):ch;const n=t.createElement||v.createElement;function i(p,f,...u){const T=qc(t.overrides,`${p}.props`,{});return n(function(g,_){const b=qc(_,g);return b?typeof b=="function"||typeof b=="object"&&"render"in b?b:qc(_,`${g}.component`,g):g}(p,t.overrides),vi({},f,T,{className:a9(f==null?void 0:f.className,T.className)||void 0}),...u)}function a(p){let f=!1;t.forceInline?f=!0:t.forceBlock||(f=PD.test(p)===!1);const u=d(c(f?p:`${p.trimEnd().replace(UD,"")}

`,{_:f}));for(;typeof u[u.length-1]=="string"&&!u[u.length-1].trim();)u.pop();if(t.wrapper===null)return u;const T=t.wrapper||(f?"span":"div");let g;if(u.length>1||t.forceWrapper)g=u;else{if(u.length===1)return g=u[0],typeof g=="string"?i("span",{key:"outer"},g):g;g=null}return v.createElement(T,{key:"outer"},g)}function o(p){const f=p.match(oD);return f?f.reduce(function(u,T,g){const _=T.indexOf("=");if(_!==-1){const b=function(x){return x.indexOf("-")!==-1&&x.match(bD)===null&&(x=x.replace(kD,function(q,S){return S.toUpperCase()})),x}(T.slice(0,_)).trim(),w=function(x){const q=x[0];return(q==='"'||q==="'")&&x.length>=2&&x[x.length-1]===q?x.slice(1,-1):x}(T.slice(_+1).trim()),C=lh[b]||b,I=u[C]=function(x,q){return x==="style"?q.split(/;\s?/).reduce(function(S,P){const R=P.slice(0,P.indexOf(":"));return S[R.replace(/(-[a-z])/g,O=>O[1].toUpperCase())]=P.slice(R.length+1).trim(),S},{}):x==="href"?Hi(q):(q.match(vD)&&(q=q.slice(1,q.length-1)),q==="true"||q!=="false"&&q)}(b,w);typeof I=="string"&&(Qd.test(I)||Kd.test(I))&&(u[C]=v.cloneElement(a(I.trim()),{key:g}))}else T!=="style"&&(u[lh[T]||T]=!0);return u},{}):null}const r=[],s={},l={blockQuote:{t:_n(wb),i:ee.HIGH,l:(p,f,u)=>({v:f(p[0].replace(lD,""),u)}),h:(p,f,u)=>i("blockquote",{key:u.k},f(p.v,u))},breakLine:{t:Xa(cD),i:ee.HIGH,l:Cc,h:(p,f,u)=>i("br",{key:u.k})},breakThematic:{t:_n(dD),i:ee.HIGH,l:Cc,h:(p,f,u)=>i("hr",{key:u.k})},codeBlock:{t:_n(Tb),i:ee.MAX,l:p=>({v:p[0].replace(/^ {4}/gm,"").replace(/\n+$/,""),M:void 0}),h:(p,f,u)=>i("pre",{key:u.k},i("code",vi({},p.O,{className:p.M?`lang-${p.M}`:""}),p.v))},codeFenced:{t:_n(xb),i:ee.MAX,l:p=>({O:o(p[3]||""),v:p[4],M:p[2]||void 0,type:"codeBlock"})},codeInline:{t:jn(uD),i:ee.LOW,l:p=>({v:p[2]}),h:(p,f,u)=>i("code",{key:u.k},p.v)},footnote:{t:_n(fD),i:ee.MAX,l:p=>(r.push({I:p[2],j:p[1]}),{}),h:Ic},footnoteReference:{t:Wn(hD),i:ee.HIGH,l:p=>({v:p[1],B:`#${t.slugify(p[1])}`}),h:(p,f,u)=>i("a",{key:u.k,href:Hi(p.B)},i("sup",{key:u.k},p.v))},gfmTask:{t:Wn(gD),i:ee.HIGH,l:p=>({R:p[1].toLowerCase()==="x"}),h:(p,f,u)=>i("input",{checked:p.R,key:u.k,readOnly:!0,type:"checkbox"})},heading:{t:_n(t.enforceAtxHeadings?Cb:kb),i:ee.HIGH,l:(p,f,u)=>({v:Fr(f,p[2],u),T:t.slugify(p[2]),C:p[1].length}),h:(p,f,u)=>i(`h${p.C}`,{id:p.T,key:u.k},f(p.v,u))},headingSetext:{t:_n(Ib),i:ee.MAX,l:(p,f,u)=>({v:Fr(f,p[1],u),C:p[2]==="="?1:2,type:"heading"})},htmlComment:{t:Xa(qb),i:ee.HIGH,l:()=>({}),h:Ic},image:{t:jn(KD),i:ee.HIGH,l:p=>({D:p[1],B:fh(p[2]),F:p[3]}),h:(p,f,u)=>i("img",{key:u.k,alt:p.D||void 0,title:p.F||void 0,src:Hi(p.B)})},link:{t:Wn(QD),i:ee.LOW,l:(p,f,u)=>({v:n9(f,p[1],u),B:fh(p[2]),F:p[3]}),h:(p,f,u)=>i("a",{key:u.k,href:Hi(p.B),title:p.F},f(p.v,u))},linkAngleBraceStyleDetector:{t:Wn(TD),i:ee.MAX,l:p=>({v:[{v:p[1],type:"text"}],B:p[1],type:"link"})},linkBareUrlDetector:{t:(p,f)=>f.N?null:Wn(wD)(p,f),i:ee.MAX,l:p=>({v:[{v:p[1],type:"text"}],B:p[1],F:void 0,type:"link"})},linkMailtoDetector:{t:Wn(xD),i:ee.MAX,l(p){let f=p[1],u=p[1];return rD.test(u)||(u="mailto:"+u),{v:[{v:f.replace("mailto:",""),type:"text"}],B:u,type:"link"}}},orderedList:uh(i,1),unorderedList:uh(i,2),newlineCoalescer:{t:_n(pD),i:ee.LOW,l:Cc,h:()=>`
`},paragraph:{t:t9,i:ee.LOW,l:kc,h:(p,f,u)=>i("p",{key:u.k},f(p.v,u))},ref:{t:Wn(CD),i:ee.MAX,l:p=>(s[p[1]]={B:p[2],F:p[4]},{}),h:Ic},refImage:{t:jn(ID),i:ee.MAX,l:p=>({D:p[1]||void 0,P:p[2]}),h:(p,f,u)=>i("img",{key:u.k,alt:p.D,src:Hi(s[p.P].B),title:s[p.P].F})},refLink:{t:Wn(qD),i:ee.MAX,l:(p,f,u)=>({v:f(p[1],u),Z:f(p[0].replace(DD,"\\$1"),u),P:p[2]}),h:(p,f,u)=>s[p.P]?i("a",{key:u.k,href:Hi(s[p.P].B),title:s[p.P].F},f(p.v,u)):i("span",{key:u.k},f(p.Z,u))},table:{t:_n(Db),i:ee.HIGH,l:e9,h:(p,f,u)=>i("table",{key:u.k},i("thead",null,i("tr",null,p.L.map(function(T,g){return i("th",{key:g,style:mh(p,g)},f(T,u))}))),i("tbody",null,p.A.map(function(T,g){return i("tr",{key:g},T.map(function(_,b){return i("td",{key:b,style:mh(p,b)},f(_,u))}))})))},tableSeparator:{t:function(p,f){return f.$?(f._=!0,ED.exec(p)):null},i:ee.HIGH,l:function(){return{type:"tableSeparator"}},h:()=>" | "},text:{t:Xa(FD),i:ee.MIN,l:p=>({v:p[0].replace(_D,(f,u)=>t.namedCodesToUnicode[u]?t.namedCodesToUnicode[u]:f)}),h:p=>p.v},textBolded:{t:jn(zD),i:ee.MED,l:(p,f,u)=>({v:f(p[2],u)}),h:(p,f,u)=>i("strong",{key:u.k},f(p.v,u))},textEmphasized:{t:jn(WD),i:ee.LOW,l:(p,f,u)=>({v:f(p[2],u)}),h:(p,f,u)=>i("em",{key:u.k},f(p.v,u))},textEscaped:{t:jn(LD),i:ee.HIGH,l:p=>({v:p[1],type:"text"})},textMarked:{t:jn(jD),i:ee.LOW,l:kc,h:(p,f,u)=>i("mark",{key:u.k},f(p.v,u))},textStrikethroughed:{t:jn(MD),i:ee.LOW,l:kc,h:(p,f,u)=>i("del",{key:u.k},f(p.v,u))}};t.disableParsingRawHTML!==!0&&(l.htmlBlock={t:Xa(Qd),i:ee.HIGH,l(p,f,u){const[,T]=p[3].match(GD),g=new RegExp(`^${T}`,"gm"),_=p[3].replace(g,""),b=(w=_,XD.some(q=>q.test(w))?i9:Fr);var w;const C=p[1].toLowerCase(),I=aD.indexOf(C)!==-1;u.N=u.N||C==="a";const x=I?p[3]:b(f,_,u);return u.N=!1,{O:o(p[2]),v:x,G:I,H:I?C:p[1]}},h:(p,f,u)=>i(p.H,vi({key:u.k},p.O),p.G?p.v:f(p.v,u))},l.htmlSelfClosing={t:Xa(Kd),i:ee.HIGH,l:p=>({O:o(p[2]||""),H:p[1]}),h:(p,f,u)=>i(p.H,vi({},p.O,{key:u.k}))});const c=function(p){let f=Object.keys(p);function u(T,g){let _=[],b="";for(;T;){let w=0;for(;w<f.length;){const C=f[w],I=p[C],x=I.t(T,g,b);if(x){const q=x[0];T=T.substring(q.length);const S=I.l(x,u,g);S.type==null&&(S.type=C),_.push(S),b=q;break}w++}}return _}return f.sort(function(T,g){let _=p[T].i,b=p[g].i;return _!==b?_-b:T<g?-1:1}),function(T,g){return u(function(_){return _.replace(mD,`
`).replace(yD,"").replace(SD,"    ")}(T),g)}}(l),d=(h=function(p){return function(f,u,T){return p[f.type].h(f,u,T)}}(l),function p(f,u={}){if(Array.isArray(f)){const T=u.k,g=[];let _=!1;for(let b=0;b<f.length;b++){u.k=b;const w=p(f[b],u),C=typeof w=="string";C&&_?g[g.length-1]+=w:w!==null&&g.push(w),_=C}return u.k=T,g}return h(f,p,u)});var h;const y=a(e);return r.length?i("div",null,y,i("footer",{key:"footer"},r.map(function(p){return i("div",{id:t.slugify(p.j),key:p.j},p.j,d(c(p.I,{_:!0})))}))):y}(function(e){e[e.MAX=0]="MAX",e[e.HIGH=1]="HIGH",e[e.MED=2]="MED",e[e.LOW=3]="LOW",e[e.MIN=4]="MIN"})(ee||(ee={}));const Xd=e=>{let{children:t,options:n}=e,i=function(a,o){if(a==null)return{};var r,s,l={},c=Object.keys(a);for(s=0;s<c.length;s++)o.indexOf(r=c[s])>=0||(l[r]=a[r]);return l}(e,iD);return v.cloneElement(o9(t,n),i)};function r9(e){return me("MuiAlert",e)}const s9=re("MuiAlert",["root","action","icon","message","filled","filledSuccess","filledInfo","filledWarning","filledError","outlined","outlinedSuccess","outlinedInfo","outlinedWarning","outlinedError","standard","standardSuccess","standardInfo","standardWarning","standardError"]),hh=s9;function l9(e){return me("MuiIconButton",e)}const c9=re("MuiIconButton",["root","disabled","colorInherit","colorPrimary","colorSecondary","colorError","colorInfo","colorSuccess","colorWarning","edgeStart","edgeEnd","sizeSmall","sizeMedium","sizeLarge"]),d9=c9,u9=["edge","children","className","color","disabled","disableFocusRipple","size"],p9=e=>{const{classes:t,disabled:n,color:i,edge:a,size:o}=e,r={root:["root",n&&"disabled",i!=="default"&&`color${Z(i)}`,a&&`edge${Z(a)}`,`size${Z(o)}`]};return fe(r,l9,t)},m9=F(tb,{name:"MuiIconButton",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.color!=="default"&&t[`color${Z(n.color)}`],n.edge&&t[`edge${Z(n.edge)}`],t[`size${Z(n.size)}`]]}})(({theme:e,ownerState:t})=>k({textAlign:"center",flex:"0 0 auto",fontSize:e.typography.pxToRem(24),padding:8,borderRadius:"50%",overflow:"visible",color:(e.vars||e).palette.action.active,transition:e.transitions.create("background-color",{duration:e.transitions.duration.shortest})},!t.disableRipple&&{"&:hover":{backgroundColor:e.vars?`rgba(${e.vars.palette.action.activeChannel} / ${e.vars.palette.action.hoverOpacity})`:Tn(e.palette.action.active,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"}}},t.edge==="start"&&{marginLeft:t.size==="small"?-3:-12},t.edge==="end"&&{marginRight:t.size==="small"?-3:-12}),({theme:e,ownerState:t})=>{var n;const i=(n=(e.vars||e).palette)==null?void 0:n[t.color];return k({},t.color==="inherit"&&{color:"inherit"},t.color!=="inherit"&&t.color!=="default"&&k({color:i==null?void 0:i.main},!t.disableRipple&&{"&:hover":k({},i&&{backgroundColor:e.vars?`rgba(${i.mainChannel} / ${e.vars.palette.action.hoverOpacity})`:Tn(i.main,e.palette.action.hoverOpacity)},{"@media (hover: none)":{backgroundColor:"transparent"}})}),t.size==="small"&&{padding:5,fontSize:e.typography.pxToRem(18)},t.size==="large"&&{padding:12,fontSize:e.typography.pxToRem(28)},{[`&.${d9.disabled}`]:{backgroundColor:"transparent",color:(e.vars||e).palette.action.disabled}})}),f9=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiIconButton"}),{edge:a=!1,children:o,className:r,color:s="default",disabled:l=!1,disableFocusRipple:c=!1,size:d="medium"}=i,h=U(i,u9),y=k({},i,{edge:a,color:s,disabled:l,disableFocusRipple:c,size:d}),p=p9(y);return m.jsx(m9,k({className:V(p.root,r),centerRipple:!0,focusRipple:!c,disabled:l,ref:n,ownerState:y},h,{children:o}))}),h9=f9,y9=Wi(m.jsx("path",{d:"M20,12A8,8 0 0,1 12,20A8,8 0 0,1 4,12A8,8 0 0,1 12,4C12.76,4 13.5,4.11 14.2, 4.31L15.77,2.74C14.61,2.26 13.34,2 12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0, 0 22,12M7.91,10.08L6.5,11.5L11,16L21,6L19.59,4.58L11,13.17L7.91,10.08Z"}),"SuccessOutlined"),g9=Wi(m.jsx("path",{d:"M12 5.99L19.53 19H4.47L12 5.99M12 2L1 21h22L12 2zm1 14h-2v2h2v-2zm0-6h-2v4h2v-4z"}),"ReportProblemOutlined"),_9=Wi(m.jsx("path",{d:"M11 15h2v2h-2zm0-8h2v6h-2zm.99-5C6.47 2 2 6.48 2 12s4.47 10 9.99 10C17.52 22 22 17.52 22 12S17.52 2 11.99 2zM12 20c-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8-3.58 8-8 8z"}),"ErrorOutline"),b9=Wi(m.jsx("path",{d:"M11,9H13V7H11M12,20C7.59,20 4,16.41 4,12C4,7.59 7.59,4 12,4C16.41,4 20,7.59 20, 12C20,16.41 16.41,20 12,20M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12A10, 10 0 0,0 12,2M11,17H13V11H11V17Z"}),"InfoOutlined"),v9=Wi(m.jsx("path",{d:"M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"}),"Close"),w9=["action","children","className","closeText","color","components","componentsProps","icon","iconMapping","onClose","role","severity","slotProps","slots","variant"],x9=e=>{const{variant:t,color:n,severity:i,classes:a}=e,o={root:["root",`${t}${Z(n||i)}`,`${t}`],icon:["icon"],message:["message"],action:["action"]};return fe(o,r9,a)},T9=F(tr,{name:"MuiAlert",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,t[n.variant],t[`${n.variant}${Z(n.color||n.severity)}`]]}})(({theme:e,ownerState:t})=>{const n=e.palette.mode==="light"?Od:zd,i=e.palette.mode==="light"?zd:Od,a=t.color||t.severity;return k({},e.typography.body2,{backgroundColor:"transparent",display:"flex",padding:"6px 16px"},a&&t.variant==="standard"&&{color:e.vars?e.vars.palette.Alert[`${a}Color`]:n(e.palette[a].light,.6),backgroundColor:e.vars?e.vars.palette.Alert[`${a}StandardBg`]:i(e.palette[a].light,.9),[`& .${hh.icon}`]:e.vars?{color:e.vars.palette.Alert[`${a}IconColor`]}:{color:e.palette[a].main}},a&&t.variant==="outlined"&&{color:e.vars?e.vars.palette.Alert[`${a}Color`]:n(e.palette[a].light,.6),border:`1px solid ${(e.vars||e).palette[a].light}`,[`& .${hh.icon}`]:e.vars?{color:e.vars.palette.Alert[`${a}IconColor`]}:{color:e.palette[a].main}},a&&t.variant==="filled"&&k({fontWeight:e.typography.fontWeightMedium},e.vars?{color:e.vars.palette.Alert[`${a}FilledColor`],backgroundColor:e.vars.palette.Alert[`${a}FilledBg`]}:{backgroundColor:e.palette.mode==="dark"?e.palette[a].dark:e.palette[a].main,color:e.palette.getContrastText(e.palette[a].main)}))}),k9=F("div",{name:"MuiAlert",slot:"Icon",overridesResolver:(e,t)=>t.icon})({marginRight:12,padding:"7px 0",display:"flex",fontSize:22,opacity:.9}),C9=F("div",{name:"MuiAlert",slot:"Message",overridesResolver:(e,t)=>t.message})({padding:"8px 0",minWidth:0,overflow:"auto"}),yh=F("div",{name:"MuiAlert",slot:"Action",overridesResolver:(e,t)=>t.action})({display:"flex",alignItems:"flex-start",padding:"4px 0 0 16px",marginLeft:"auto",marginRight:-8}),gh={success:m.jsx(y9,{fontSize:"inherit"}),warning:m.jsx(g9,{fontSize:"inherit"}),error:m.jsx(_9,{fontSize:"inherit"}),info:m.jsx(b9,{fontSize:"inherit"})},I9=v.forwardRef(function(t,n){var i,a,o,r,s,l;const c=he({props:t,name:"MuiAlert"}),{action:d,children:h,className:y,closeText:p="Close",color:f,components:u={},componentsProps:T={},icon:g,iconMapping:_=gh,onClose:b,role:w="alert",severity:C="success",slotProps:I={},slots:x={},variant:q="standard"}=c,S=U(c,w9),P=k({},c,{color:f,severity:C,variant:q}),R=x9(P),O=(i=(a=x.closeButton)!=null?a:u.CloseButton)!=null?i:h9,M=(o=(r=x.closeIcon)!=null?r:u.CloseIcon)!=null?o:v9,A=(s=I.closeButton)!=null?s:T.closeButton,B=(l=I.closeIcon)!=null?l:T.closeIcon;return m.jsxs(T9,k({role:w,elevation:0,ownerState:P,className:V(R.root,y),ref:n},S,{children:[g!==!1?m.jsx(k9,{ownerState:P,className:R.icon,children:g||_[C]||gh[C]}):null,m.jsx(C9,{ownerState:P,className:R.message,children:h}),d!=null?m.jsx(yh,{ownerState:P,className:R.action,children:d}):null,d==null&&b?m.jsx(yh,{ownerState:P,className:R.action,children:m.jsx(O,k({size:"small","aria-label":p,title:p,color:"inherit",onClick:b},A,{children:m.jsx(M,k({fontSize:"small"},B))}))}):null]}))}),Dc=I9;var Np={},Rp={};(function(e){Object.defineProperty(e,"__esModule",{value:!0}),e.Doctype=e.CDATA=e.Tag=e.Style=e.Script=e.Comment=e.Directive=e.Text=e.Root=e.isTag=e.ElementType=void 0;var t;(function(i){i.Root="root",i.Text="text",i.Directive="directive",i.Comment="comment",i.Script="script",i.Style="style",i.Tag="tag",i.CDATA="cdata",i.Doctype="doctype"})(t=e.ElementType||(e.ElementType={}));function n(i){return i.type===t.Tag||i.type===t.Script||i.type===t.Style}e.isTag=n,e.Root=t.Root,e.Text=t.Text,e.Directive=t.Directive,e.Comment=t.Comment,e.Script=t.Script,e.Style=t.Style,e.Tag=t.Tag,e.CDATA=t.CDATA,e.Doctype=t.Doctype})(Rp);var K={},ui=sn&&sn.__extends||function(){var e=function(t,n){return e=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(i,a){i.__proto__=a}||function(i,a){for(var o in a)Object.prototype.hasOwnProperty.call(a,o)&&(i[o]=a[o])},e(t,n)};return function(t,n){if(typeof n!="function"&&n!==null)throw new TypeError("Class extends value "+String(n)+" is not a constructor or null");e(t,n);function i(){this.constructor=t}t.prototype=n===null?Object.create(n):(i.prototype=n.prototype,new i)}}(),_o=sn&&sn.__assign||function(){return _o=Object.assign||function(e){for(var t,n=1,i=arguments.length;n<i;n++){t=arguments[n];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(e[a]=t[a])}return e},_o.apply(this,arguments)};Object.defineProperty(K,"__esModule",{value:!0});K.cloneNode=K.hasChildren=K.isDocument=K.isDirective=K.isComment=K.isText=K.isCDATA=K.isTag=K.Element=K.Document=K.CDATA=K.NodeWithChildren=K.ProcessingInstruction=K.Comment=K.Text=K.DataNode=K.Node=void 0;var gt=Rp,Bp=function(){function e(){this.parent=null,this.prev=null,this.next=null,this.startIndex=null,this.endIndex=null}return Object.defineProperty(e.prototype,"parentNode",{get:function(){return this.parent},set:function(t){this.parent=t},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"previousSibling",{get:function(){return this.prev},set:function(t){this.prev=t},enumerable:!1,configurable:!0}),Object.defineProperty(e.prototype,"nextSibling",{get:function(){return this.next},set:function(t){this.next=t},enumerable:!1,configurable:!0}),e.prototype.cloneNode=function(t){return t===void 0&&(t=!1),Op(this,t)},e}();K.Node=Bp;var El=function(e){ui(t,e);function t(n){var i=e.call(this)||this;return i.data=n,i}return Object.defineProperty(t.prototype,"nodeValue",{get:function(){return this.data},set:function(n){this.data=n},enumerable:!1,configurable:!0}),t}(Bp);K.DataNode=El;var Mb=function(e){ui(t,e);function t(){var n=e!==null&&e.apply(this,arguments)||this;return n.type=gt.ElementType.Text,n}return Object.defineProperty(t.prototype,"nodeType",{get:function(){return 3},enumerable:!1,configurable:!0}),t}(El);K.Text=Mb;var Lb=function(e){ui(t,e);function t(){var n=e!==null&&e.apply(this,arguments)||this;return n.type=gt.ElementType.Comment,n}return Object.defineProperty(t.prototype,"nodeType",{get:function(){return 8},enumerable:!1,configurable:!0}),t}(El);K.Comment=Lb;var Fb=function(e){ui(t,e);function t(n,i){var a=e.call(this,i)||this;return a.name=n,a.type=gt.ElementType.Directive,a}return Object.defineProperty(t.prototype,"nodeType",{get:function(){return 1},enumerable:!1,configurable:!0}),t}(El);K.ProcessingInstruction=Fb;var Al=function(e){ui(t,e);function t(n){var i=e.call(this)||this;return i.children=n,i}return Object.defineProperty(t.prototype,"firstChild",{get:function(){var n;return(n=this.children[0])!==null&&n!==void 0?n:null},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"lastChild",{get:function(){return this.children.length>0?this.children[this.children.length-1]:null},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"childNodes",{get:function(){return this.children},set:function(n){this.children=n},enumerable:!1,configurable:!0}),t}(Bp);K.NodeWithChildren=Al;var Ub=function(e){ui(t,e);function t(){var n=e!==null&&e.apply(this,arguments)||this;return n.type=gt.ElementType.CDATA,n}return Object.defineProperty(t.prototype,"nodeType",{get:function(){return 4},enumerable:!1,configurable:!0}),t}(Al);K.CDATA=Ub;var Gb=function(e){ui(t,e);function t(){var n=e!==null&&e.apply(this,arguments)||this;return n.type=gt.ElementType.Root,n}return Object.defineProperty(t.prototype,"nodeType",{get:function(){return 9},enumerable:!1,configurable:!0}),t}(Al);K.Document=Gb;var $b=function(e){ui(t,e);function t(n,i,a,o){a===void 0&&(a=[]),o===void 0&&(o=n==="script"?gt.ElementType.Script:n==="style"?gt.ElementType.Style:gt.ElementType.Tag);var r=e.call(this,a)||this;return r.name=n,r.attribs=i,r.type=o,r}return Object.defineProperty(t.prototype,"nodeType",{get:function(){return 1},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"tagName",{get:function(){return this.name},set:function(n){this.name=n},enumerable:!1,configurable:!0}),Object.defineProperty(t.prototype,"attributes",{get:function(){var n=this;return Object.keys(this.attribs).map(function(i){var a,o;return{name:i,value:n.attribs[i],namespace:(a=n["x-attribsNamespace"])===null||a===void 0?void 0:a[i],prefix:(o=n["x-attribsPrefix"])===null||o===void 0?void 0:o[i]}})},enumerable:!1,configurable:!0}),t}(Al);K.Element=$b;function Vb(e){return(0,gt.isTag)(e)}K.isTag=Vb;function Hb(e){return e.type===gt.ElementType.CDATA}K.isCDATA=Hb;function Zb(e){return e.type===gt.ElementType.Text}K.isText=Zb;function Qb(e){return e.type===gt.ElementType.Comment}K.isComment=Qb;function Kb(e){return e.type===gt.ElementType.Directive}K.isDirective=Kb;function Xb(e){return e.type===gt.ElementType.Root}K.isDocument=Xb;function q9(e){return Object.prototype.hasOwnProperty.call(e,"children")}K.hasChildren=q9;function Op(e,t){t===void 0&&(t=!1);var n;if(Zb(e))n=new Mb(e.data);else if(Qb(e))n=new Lb(e.data);else if(Vb(e)){var i=t?Pc(e.children):[],a=new $b(e.name,_o({},e.attribs),i);i.forEach(function(l){return l.parent=a}),e.namespace!=null&&(a.namespace=e.namespace),e["x-attribsNamespace"]&&(a["x-attribsNamespace"]=_o({},e["x-attribsNamespace"])),e["x-attribsPrefix"]&&(a["x-attribsPrefix"]=_o({},e["x-attribsPrefix"])),n=a}else if(Hb(e)){var i=t?Pc(e.children):[],o=new Ub(i);i.forEach(function(c){return c.parent=o}),n=o}else if(Xb(e)){var i=t?Pc(e.children):[],r=new Gb(i);i.forEach(function(c){return c.parent=r}),e["x-mode"]&&(r["x-mode"]=e["x-mode"]),n=r}else if(Kb(e)){var s=new Fb(e.name,e.data);e["x-name"]!=null&&(s["x-name"]=e["x-name"],s["x-publicId"]=e["x-publicId"],s["x-systemId"]=e["x-systemId"]),n=s}else throw new Error("Not implemented yet: ".concat(e.type));return n.startIndex=e.startIndex,n.endIndex=e.endIndex,e.sourceCodeLocation!=null&&(n.sourceCodeLocation=e.sourceCodeLocation),n}K.cloneNode=Op;function Pc(e){for(var t=e.map(function(i){return Op(i,!0)}),n=1;n<t.length;n++)t[n].prev=t[n-1],t[n-1].next=t[n];return t}(function(e){var t=sn&&sn.__createBinding||(Object.create?function(s,l,c,d){d===void 0&&(d=c);var h=Object.getOwnPropertyDescriptor(l,c);(!h||("get"in h?!l.__esModule:h.writable||h.configurable))&&(h={enumerable:!0,get:function(){return l[c]}}),Object.defineProperty(s,d,h)}:function(s,l,c,d){d===void 0&&(d=c),s[d]=l[c]}),n=sn&&sn.__exportStar||function(s,l){for(var c in s)c!=="default"&&!Object.prototype.hasOwnProperty.call(l,c)&&t(l,s,c)};Object.defineProperty(e,"__esModule",{value:!0}),e.DomHandler=void 0;var i=Rp,a=K;n(K,e);var o={withStartIndices:!1,withEndIndices:!1,xmlMode:!1},r=function(){function s(l,c,d){this.dom=[],this.root=new a.Document(this.dom),this.done=!1,this.tagStack=[this.root],this.lastNode=null,this.parser=null,typeof c=="function"&&(d=c,c=o),typeof l=="object"&&(c=l,l=void 0),this.callback=l??null,this.options=c??o,this.elementCB=d??null}return s.prototype.onparserinit=function(l){this.parser=l},s.prototype.onreset=function(){this.dom=[],this.root=new a.Document(this.dom),this.done=!1,this.tagStack=[this.root],this.lastNode=null,this.parser=null},s.prototype.onend=function(){this.done||(this.done=!0,this.parser=null,this.handleCallback(null))},s.prototype.onerror=function(l){this.handleCallback(l)},s.prototype.onclosetag=function(){this.lastNode=null;var l=this.tagStack.pop();this.options.withEndIndices&&(l.endIndex=this.parser.endIndex),this.elementCB&&this.elementCB(l)},s.prototype.onopentag=function(l,c){var d=this.options.xmlMode?i.ElementType.Tag:void 0,h=new a.Element(l,c,void 0,d);this.addNode(h),this.tagStack.push(h)},s.prototype.ontext=function(l){var c=this.lastNode;if(c&&c.type===i.ElementType.Text)c.data+=l,this.options.withEndIndices&&(c.endIndex=this.parser.endIndex);else{var d=new a.Text(l);this.addNode(d),this.lastNode=d}},s.prototype.oncomment=function(l){if(this.lastNode&&this.lastNode.type===i.ElementType.Comment){this.lastNode.data+=l;return}var c=new a.Comment(l);this.addNode(c),this.lastNode=c},s.prototype.oncommentend=function(){this.lastNode=null},s.prototype.oncdatastart=function(){var l=new a.Text(""),c=new a.CDATA([l]);this.addNode(c),l.parent=c,this.lastNode=l},s.prototype.oncdataend=function(){this.lastNode=null},s.prototype.onprocessinginstruction=function(l,c){var d=new a.ProcessingInstruction(l,c);this.addNode(d)},s.prototype.handleCallback=function(l){if(typeof this.callback=="function")this.callback(l,this.dom);else if(l)throw l},s.prototype.addNode=function(l){var c=this.tagStack[this.tagStack.length-1],d=c.children[c.children.length-1];this.options.withStartIndices&&(l.startIndex=this.parser.startIndex),this.options.withEndIndices&&(l.endIndex=this.parser.endIndex),c.children.push(l),d&&(l.prev=d,d.next=l),l.parent=c,this.lastNode=null},s}();e.DomHandler=r,e.default=r})(Np);var _h="html",bh="head",Tr="body",D9=/<([a-zA-Z]+[0-9]?)/,vh=/<head[^]*>/i,wh=/<body[^]*>/i,ks=function(){throw new Error("This browser does not support `document.implementation.createHTMLDocument`")},Yd=function(){throw new Error("This browser does not support `DOMParser.prototype.parseFromString`")},xh=typeof window=="object"&&window.DOMParser;if(typeof xh=="function"){var P9=new xh,S9="text/html";Yd=function(e,t){return t&&(e="<"+t+">"+e+"</"+t+">"),P9.parseFromString(e,S9)},ks=Yd}if(typeof document=="object"&&document.implementation){var kr=document.implementation.createHTMLDocument();ks=function(e,t){if(t){var n=kr.documentElement.querySelector(t);return n.innerHTML=e,kr}return kr.documentElement.innerHTML=e,kr}}var Sc=typeof document=="object"?document.createElement("template"):{},Jd;Sc.content&&(Jd=function(e){return Sc.innerHTML=e,Sc.content.childNodes});function E9(e){var t,n=e.match(D9);n&&n[1]&&(t=n[1].toLowerCase());var i,a,o;switch(t){case _h:return i=Yd(e),vh.test(e)||(a=i.querySelector(bh),a&&a.parentNode.removeChild(a)),wh.test(e)||(a=i.querySelector(Tr),a&&a.parentNode.removeChild(a)),i.querySelectorAll(_h);case bh:case Tr:return i=ks(e),o=i.querySelectorAll(t),wh.test(e)&&vh.test(e)?o[0].parentNode.childNodes:o;default:return Jd?Jd(e):(a=ks(e,Tr).querySelector(Tr),a.childNodes)}}var A9=E9,zp={},Yb={};Yb.CASE_SENSITIVE_TAG_NAMES=["animateMotion","animateTransform","clipPath","feBlend","feColorMatrix","feComponentTransfer","feComposite","feConvolveMatrix","feDiffuseLighting","feDisplacementMap","feDropShadow","feFlood","feFuncA","feFuncB","feFuncG","feFuncR","feGaussianBlur","feImage","feMerge","feMergeNode","feMorphology","feOffset","fePointLight","feSpecularLighting","feSpotLight","feTile","feTurbulence","foreignObject","linearGradient","radialGradient","textPath"];var Nl=Np,N9=Yb,Th=N9.CASE_SENSITIVE_TAG_NAMES,R9=Nl.Comment,B9=Nl.Element,O9=Nl.ProcessingInstruction,z9=Nl.Text,Jb={},Ec;for(var Ac=0,W9=Th.length;Ac<W9;Ac++)Ec=Th[Ac],Jb[Ec.toLowerCase()]=Ec;function j9(e){return Jb[e]}function e0(e){for(var t={},n,i=0,a=e.length;i<a;i++)n=e[i],t[n.name]=n.value;return t}function M9(e){e=e.toLowerCase();var t=j9(e);return t||e}function t0(e,t,n){t=t||null;for(var i=[],a,o=0,r=e.length;o<r;o++){var s=e[o],l;switch(s.nodeType){case 1:a=M9(s.nodeName),l=new B9(a,e0(s.attributes)),l.children=t0(a==="template"?s.content.childNodes:s.childNodes,l);break;case 3:l=new z9(s.nodeValue);break;case 8:l=new R9(s.nodeValue);break;default:continue}var c=i[o-1]||null;c&&(c.next=l),l.parent=t,l.prev=c,l.next=null,i.push(l)}return n&&(l=new O9(n.substring(0,n.indexOf(" ")).toLowerCase(),n),l.next=i[0]||null,l.parent=t,i.unshift(l),i[1]&&(i[1].prev=i[0])),i}zp.formatAttributes=e0;zp.formatDOM=t0;var L9=A9,F9=zp,U9=F9.formatDOM,G9=/<(![a-zA-Z\s]+)>/;function $9(e){if(typeof e!="string")throw new TypeError("First argument must be a string");if(e==="")return[];var t=e.match(G9),n;return t&&t[1]&&(n=t[1]),U9(L9(e),null,n)}var V9=$9,Ft={},Rl={},H9=0;Rl.SAME=H9;var Z9=1;Rl.CAMELCASE=Z9;Rl.possibleStandardNames={accept:0,acceptCharset:1,"accept-charset":"acceptCharset",accessKey:1,action:0,allowFullScreen:1,alt:0,as:0,async:0,autoCapitalize:1,autoComplete:1,autoCorrect:1,autoFocus:1,autoPlay:1,autoSave:1,capture:0,cellPadding:1,cellSpacing:1,challenge:0,charSet:1,checked:0,children:0,cite:0,class:"className",classID:1,className:1,cols:0,colSpan:1,content:0,contentEditable:1,contextMenu:1,controls:0,controlsList:1,coords:0,crossOrigin:1,dangerouslySetInnerHTML:1,data:0,dateTime:1,default:0,defaultChecked:1,defaultValue:1,defer:0,dir:0,disabled:0,disablePictureInPicture:1,disableRemotePlayback:1,download:0,draggable:0,encType:1,enterKeyHint:1,for:"htmlFor",form:0,formMethod:1,formAction:1,formEncType:1,formNoValidate:1,formTarget:1,frameBorder:1,headers:0,height:0,hidden:0,high:0,href:0,hrefLang:1,htmlFor:1,httpEquiv:1,"http-equiv":"httpEquiv",icon:0,id:0,innerHTML:1,inputMode:1,integrity:0,is:0,itemID:1,itemProp:1,itemRef:1,itemScope:1,itemType:1,keyParams:1,keyType:1,kind:0,label:0,lang:0,list:0,loop:0,low:0,manifest:0,marginWidth:1,marginHeight:1,max:0,maxLength:1,media:0,mediaGroup:1,method:0,min:0,minLength:1,multiple:0,muted:0,name:0,noModule:1,nonce:0,noValidate:1,open:0,optimum:0,pattern:0,placeholder:0,playsInline:1,poster:0,preload:0,profile:0,radioGroup:1,readOnly:1,referrerPolicy:1,rel:0,required:0,reversed:0,role:0,rows:0,rowSpan:1,sandbox:0,scope:0,scoped:0,scrolling:0,seamless:0,selected:0,shape:0,size:0,sizes:0,span:0,spellCheck:1,src:0,srcDoc:1,srcLang:1,srcSet:1,start:0,step:0,style:0,summary:0,tabIndex:1,target:0,title:0,type:0,useMap:1,value:0,width:0,wmode:0,wrap:0,about:0,accentHeight:1,"accent-height":"accentHeight",accumulate:0,additive:0,alignmentBaseline:1,"alignment-baseline":"alignmentBaseline",allowReorder:1,alphabetic:0,amplitude:0,arabicForm:1,"arabic-form":"arabicForm",ascent:0,attributeName:1,attributeType:1,autoReverse:1,azimuth:0,baseFrequency:1,baselineShift:1,"baseline-shift":"baselineShift",baseProfile:1,bbox:0,begin:0,bias:0,by:0,calcMode:1,capHeight:1,"cap-height":"capHeight",clip:0,clipPath:1,"clip-path":"clipPath",clipPathUnits:1,clipRule:1,"clip-rule":"clipRule",color:0,colorInterpolation:1,"color-interpolation":"colorInterpolation",colorInterpolationFilters:1,"color-interpolation-filters":"colorInterpolationFilters",colorProfile:1,"color-profile":"colorProfile",colorRendering:1,"color-rendering":"colorRendering",contentScriptType:1,contentStyleType:1,cursor:0,cx:0,cy:0,d:0,datatype:0,decelerate:0,descent:0,diffuseConstant:1,direction:0,display:0,divisor:0,dominantBaseline:1,"dominant-baseline":"dominantBaseline",dur:0,dx:0,dy:0,edgeMode:1,elevation:0,enableBackground:1,"enable-background":"enableBackground",end:0,exponent:0,externalResourcesRequired:1,fill:0,fillOpacity:1,"fill-opacity":"fillOpacity",fillRule:1,"fill-rule":"fillRule",filter:0,filterRes:1,filterUnits:1,floodOpacity:1,"flood-opacity":"floodOpacity",floodColor:1,"flood-color":"floodColor",focusable:0,fontFamily:1,"font-family":"fontFamily",fontSize:1,"font-size":"fontSize",fontSizeAdjust:1,"font-size-adjust":"fontSizeAdjust",fontStretch:1,"font-stretch":"fontStretch",fontStyle:1,"font-style":"fontStyle",fontVariant:1,"font-variant":"fontVariant",fontWeight:1,"font-weight":"fontWeight",format:0,from:0,fx:0,fy:0,g1:0,g2:0,glyphName:1,"glyph-name":"glyphName",glyphOrientationHorizontal:1,"glyph-orientation-horizontal":"glyphOrientationHorizontal",glyphOrientationVertical:1,"glyph-orientation-vertical":"glyphOrientationVertical",glyphRef:1,gradientTransform:1,gradientUnits:1,hanging:0,horizAdvX:1,"horiz-adv-x":"horizAdvX",horizOriginX:1,"horiz-origin-x":"horizOriginX",ideographic:0,imageRendering:1,"image-rendering":"imageRendering",in2:0,in:0,inlist:0,intercept:0,k1:0,k2:0,k3:0,k4:0,k:0,kernelMatrix:1,kernelUnitLength:1,kerning:0,keyPoints:1,keySplines:1,keyTimes:1,lengthAdjust:1,letterSpacing:1,"letter-spacing":"letterSpacing",lightingColor:1,"lighting-color":"lightingColor",limitingConeAngle:1,local:0,markerEnd:1,"marker-end":"markerEnd",markerHeight:1,markerMid:1,"marker-mid":"markerMid",markerStart:1,"marker-start":"markerStart",markerUnits:1,markerWidth:1,mask:0,maskContentUnits:1,maskUnits:1,mathematical:0,mode:0,numOctaves:1,offset:0,opacity:0,operator:0,order:0,orient:0,orientation:0,origin:0,overflow:0,overlinePosition:1,"overline-position":"overlinePosition",overlineThickness:1,"overline-thickness":"overlineThickness",paintOrder:1,"paint-order":"paintOrder",panose1:0,"panose-1":"panose1",pathLength:1,patternContentUnits:1,patternTransform:1,patternUnits:1,pointerEvents:1,"pointer-events":"pointerEvents",points:0,pointsAtX:1,pointsAtY:1,pointsAtZ:1,prefix:0,preserveAlpha:1,preserveAspectRatio:1,primitiveUnits:1,property:0,r:0,radius:0,refX:1,refY:1,renderingIntent:1,"rendering-intent":"renderingIntent",repeatCount:1,repeatDur:1,requiredExtensions:1,requiredFeatures:1,resource:0,restart:0,result:0,results:0,rotate:0,rx:0,ry:0,scale:0,security:0,seed:0,shapeRendering:1,"shape-rendering":"shapeRendering",slope:0,spacing:0,specularConstant:1,specularExponent:1,speed:0,spreadMethod:1,startOffset:1,stdDeviation:1,stemh:0,stemv:0,stitchTiles:1,stopColor:1,"stop-color":"stopColor",stopOpacity:1,"stop-opacity":"stopOpacity",strikethroughPosition:1,"strikethrough-position":"strikethroughPosition",strikethroughThickness:1,"strikethrough-thickness":"strikethroughThickness",string:0,stroke:0,strokeDasharray:1,"stroke-dasharray":"strokeDasharray",strokeDashoffset:1,"stroke-dashoffset":"strokeDashoffset",strokeLinecap:1,"stroke-linecap":"strokeLinecap",strokeLinejoin:1,"stroke-linejoin":"strokeLinejoin",strokeMiterlimit:1,"stroke-miterlimit":"strokeMiterlimit",strokeWidth:1,"stroke-width":"strokeWidth",strokeOpacity:1,"stroke-opacity":"strokeOpacity",suppressContentEditableWarning:1,suppressHydrationWarning:1,surfaceScale:1,systemLanguage:1,tableValues:1,targetX:1,targetY:1,textAnchor:1,"text-anchor":"textAnchor",textDecoration:1,"text-decoration":"textDecoration",textLength:1,textRendering:1,"text-rendering":"textRendering",to:0,transform:0,typeof:0,u1:0,u2:0,underlinePosition:1,"underline-position":"underlinePosition",underlineThickness:1,"underline-thickness":"underlineThickness",unicode:0,unicodeBidi:1,"unicode-bidi":"unicodeBidi",unicodeRange:1,"unicode-range":"unicodeRange",unitsPerEm:1,"units-per-em":"unitsPerEm",unselectable:0,vAlphabetic:1,"v-alphabetic":"vAlphabetic",values:0,vectorEffect:1,"vector-effect":"vectorEffect",version:0,vertAdvY:1,"vert-adv-y":"vertAdvY",vertOriginX:1,"vert-origin-x":"vertOriginX",vertOriginY:1,"vert-origin-y":"vertOriginY",vHanging:1,"v-hanging":"vHanging",vIdeographic:1,"v-ideographic":"vIdeographic",viewBox:1,viewTarget:1,visibility:0,vMathematical:1,"v-mathematical":"vMathematical",vocab:0,widths:0,wordSpacing:1,"word-spacing":"wordSpacing",writingMode:1,"writing-mode":"writingMode",x1:0,x2:0,x:0,xChannelSelector:1,xHeight:1,"x-height":"xHeight",xlinkActuate:1,"xlink:actuate":"xlinkActuate",xlinkArcrole:1,"xlink:arcrole":"xlinkArcrole",xlinkHref:1,"xlink:href":"xlinkHref",xlinkRole:1,"xlink:role":"xlinkRole",xlinkShow:1,"xlink:show":"xlinkShow",xlinkTitle:1,"xlink:title":"xlinkTitle",xlinkType:1,"xlink:type":"xlinkType",xmlBase:1,"xml:base":"xmlBase",xmlLang:1,"xml:lang":"xmlLang",xmlns:0,"xml:space":"xmlSpace",xmlnsXlink:1,"xmlns:xlink":"xmlnsXlink",xmlSpace:1,y1:0,y2:0,y:0,yChannelSelector:1,z:0,zoomAndPan:1};Object.defineProperty(Ft,"__esModule",{value:!0});function Q9(e,t){return K9(e)||X9(e,t)||Y9(e,t)||J9()}function K9(e){if(Array.isArray(e))return e}function X9(e,t){var n=e==null?null:typeof Symbol<"u"&&e[Symbol.iterator]||e["@@iterator"];if(n!=null){var i=[],a=!0,o=!1,r,s;try{for(n=n.call(e);!(a=(r=n.next()).done)&&(i.push(r.value),!(t&&i.length===t));a=!0);}catch(l){o=!0,s=l}finally{try{!a&&n.return!=null&&n.return()}finally{if(o)throw s}}return i}}function Y9(e,t){if(e){if(typeof e=="string")return kh(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);if(n==="Object"&&e.constructor&&(n=e.constructor.name),n==="Map"||n==="Set")return Array.from(e);if(n==="Arguments"||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return kh(e,t)}}function kh(e,t){(t==null||t>e.length)&&(t=e.length);for(var n=0,i=new Array(t);n<t;n++)i[n]=e[n];return i}function J9(){throw new TypeError(`Invalid attempt to destructure non-iterable instance.
In order to be iterable, non-array objects must have a [Symbol.iterator]() method.`)}var n0=0,pi=1,Bl=2,Ol=3,Wp=4,i0=5,a0=6;function e4(e){return Ye.hasOwnProperty(e)?Ye[e]:null}function lt(e,t,n,i,a,o,r){this.acceptsBooleans=t===Bl||t===Ol||t===Wp,this.attributeName=i,this.attributeNamespace=a,this.mustUseProperty=n,this.propertyName=e,this.type=t,this.sanitizeURL=o,this.removeEmptyString=r}var Ye={},t4=["children","dangerouslySetInnerHTML","defaultValue","defaultChecked","innerHTML","suppressContentEditableWarning","suppressHydrationWarning","style"];t4.forEach(function(e){Ye[e]=new lt(e,n0,!1,e,null,!1,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(e){var t=Q9(e,2),n=t[0],i=t[1];Ye[n]=new lt(n,pi,!1,i,null,!1,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(e){Ye[e]=new lt(e,Bl,!1,e.toLowerCase(),null,!1,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(e){Ye[e]=new lt(e,Bl,!1,e,null,!1,!1)});["allowFullScreen","async","autoFocus","autoPlay","controls","default","defer","disabled","disablePictureInPicture","disableRemotePlayback","formNoValidate","hidden","loop","noModule","noValidate","open","playsInline","readOnly","required","reversed","scoped","seamless","itemScope"].forEach(function(e){Ye[e]=new lt(e,Ol,!1,e.toLowerCase(),null,!1,!1)});["checked","multiple","muted","selected"].forEach(function(e){Ye[e]=new lt(e,Ol,!0,e,null,!1,!1)});["capture","download"].forEach(function(e){Ye[e]=new lt(e,Wp,!1,e,null,!1,!1)});["cols","rows","size","span"].forEach(function(e){Ye[e]=new lt(e,a0,!1,e,null,!1,!1)});["rowSpan","start"].forEach(function(e){Ye[e]=new lt(e,i0,!1,e.toLowerCase(),null,!1,!1)});var jp=/[\-\:]([a-z])/g,Mp=function(t){return t[1].toUpperCase()};["accent-height","alignment-baseline","arabic-form","baseline-shift","cap-height","clip-path","clip-rule","color-interpolation","color-interpolation-filters","color-profile","color-rendering","dominant-baseline","enable-background","fill-opacity","fill-rule","flood-color","flood-opacity","font-family","font-size","font-size-adjust","font-stretch","font-style","font-variant","font-weight","glyph-name","glyph-orientation-horizontal","glyph-orientation-vertical","horiz-adv-x","horiz-origin-x","image-rendering","letter-spacing","lighting-color","marker-end","marker-mid","marker-start","overline-position","overline-thickness","paint-order","panose-1","pointer-events","rendering-intent","shape-rendering","stop-color","stop-opacity","strikethrough-position","strikethrough-thickness","stroke-dasharray","stroke-dashoffset","stroke-linecap","stroke-linejoin","stroke-miterlimit","stroke-opacity","stroke-width","text-anchor","text-decoration","text-rendering","underline-position","underline-thickness","unicode-bidi","unicode-range","units-per-em","v-alphabetic","v-hanging","v-ideographic","v-mathematical","vector-effect","vert-adv-y","vert-origin-x","vert-origin-y","word-spacing","writing-mode","xmlns:xlink","x-height"].forEach(function(e){var t=e.replace(jp,Mp);Ye[t]=new lt(t,pi,!1,e,null,!1,!1)});["xlink:actuate","xlink:arcrole","xlink:role","xlink:show","xlink:title","xlink:type"].forEach(function(e){var t=e.replace(jp,Mp);Ye[t]=new lt(t,pi,!1,e,"http://www.w3.org/1999/xlink",!1,!1)});["xml:base","xml:lang","xml:space"].forEach(function(e){var t=e.replace(jp,Mp);Ye[t]=new lt(t,pi,!1,e,"http://www.w3.org/XML/1998/namespace",!1,!1)});["tabIndex","crossOrigin"].forEach(function(e){Ye[e]=new lt(e,pi,!1,e.toLowerCase(),null,!1,!1)});var n4="xlinkHref";Ye[n4]=new lt("xlinkHref",pi,!1,"xlink:href","http://www.w3.org/1999/xlink",!0,!1);["src","href","action","formAction"].forEach(function(e){Ye[e]=new lt(e,pi,!1,e.toLowerCase(),null,!0,!0)});var Lp=Rl,i4=Lp.CAMELCASE,a4=Lp.SAME,Ch=Lp.possibleStandardNames,o4=":A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD",r4=o4+"\\-.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040",s4=RegExp.prototype.test.bind(new RegExp("^(data|aria)-["+r4+"]*$")),l4=Object.keys(Ch).reduce(function(e,t){var n=Ch[t];return n===a4?e[t]=t:n===i4?e[t.toLowerCase()]=t:e[t]=n,e},{});Ft.BOOLEAN=Ol;Ft.BOOLEANISH_STRING=Bl;Ft.NUMERIC=i0;Ft.OVERLOADED_BOOLEAN=Wp;Ft.POSITIVE_NUMERIC=a0;Ft.RESERVED=n0;Ft.STRING=pi;Ft.getPropertyInfo=e4;Ft.isCustomAttribute=s4;Ft.possibleStandardNames=l4;var Fp={},Up={exports:{}},Ih=/\/\*[^*]*\*+([^/*][^*]*\*+)*\//g,c4=/\n/g,d4=/^\s*/,u4=/^(\*?[-#/*\\\w]+(\[[0-9a-z_-]+\])?)\s*/,p4=/^:\s*/,m4=/^((?:'(?:\\'|.)*?'|"(?:\\"|.)*?"|\([^)]*?\)|[^};])+)/,f4=/^[;\s]*/,h4=/^\s+|\s+$/g,y4=`
`,qh="/",Dh="*",wi="",g4="comment",_4="declaration",b4=function(e,t){if(typeof e!="string")throw new TypeError("First argument must be a string");if(!e)return[];t=t||{};var n=1,i=1;function a(f){var u=f.match(c4);u&&(n+=u.length);var T=f.lastIndexOf(y4);i=~T?f.length-T:i+f.length}function o(){var f={line:n,column:i};return function(u){return u.position=new r(f),c(),u}}function r(f){this.start=f,this.end={line:n,column:i},this.source=t.source}r.prototype.content=e;function s(f){var u=new Error(t.source+":"+n+":"+i+": "+f);if(u.reason=f,u.filename=t.source,u.line=n,u.column=i,u.source=e,!t.silent)throw u}function l(f){var u=f.exec(e);if(u){var T=u[0];return a(T),e=e.slice(T.length),u}}function c(){l(d4)}function d(f){var u;for(f=f||[];u=h();)u!==!1&&f.push(u);return f}function h(){var f=o();if(!(qh!=e.charAt(0)||Dh!=e.charAt(1))){for(var u=2;wi!=e.charAt(u)&&(Dh!=e.charAt(u)||qh!=e.charAt(u+1));)++u;if(u+=2,wi===e.charAt(u-1))return s("End of comment missing");var T=e.slice(2,u-2);return i+=2,a(T),e=e.slice(u),i+=2,f({type:g4,comment:T})}}function y(){var f=o(),u=l(u4);if(u){if(h(),!l(p4))return s("property missing ':'");var T=l(m4),g=f({type:_4,property:Ph(u[0].replace(Ih,wi)),value:T?Ph(T[0].replace(Ih,wi)):wi});return l(f4),g}}function p(){var f=[];d(f);for(var u;u=y();)u!==!1&&(f.push(u),d(f));return f}return c(),p()};function Ph(e){return e?e.replace(h4,wi):wi}var v4=b4;function o0(e,t){var n=null;if(!e||typeof e!="string")return n;for(var i,a=v4(e),o=typeof t=="function",r,s,l=0,c=a.length;l<c;l++)i=a[l],r=i.property,s=i.value,o?t(r,s,i):s&&(n||(n={}),n[r]=s);return n}Up.exports=o0;Up.exports.default=o0;var w4=Up.exports,zl={};Object.defineProperty(zl,"__esModule",{value:!0});zl.camelCase=void 0;var x4=/^--[a-zA-Z0-9-]+$/,T4=/-([a-z])/g,k4=/^[^-]+$/,C4=/^-(webkit|moz|ms|o|khtml)-/,I4=/^-(ms)-/,q4=function(e){return!e||k4.test(e)||x4.test(e)},D4=function(e,t){return t.toUpperCase()},Sh=function(e,t){return"".concat(t,"-")},P4=function(e,t){return t===void 0&&(t={}),q4(e)?e:(e=e.toLowerCase(),t.reactCompat?e=e.replace(I4,Sh):e=e.replace(C4,Sh),e.replace(T4,D4))};zl.camelCase=P4;var S4=sn&&sn.__importDefault||function(e){return e&&e.__esModule?e:{default:e}};Object.defineProperty(Fp,"__esModule",{value:!0});var E4=S4(w4),A4=zl;function N4(e,t){var n={};return!e||typeof e!="string"||(0,E4.default)(e,function(i,a){i&&a&&(n[(0,A4.camelCase)(i,t)]=a)}),n}Fp.default=N4;var R4=v,B4=Fp.default;function O4(e,t){if(!e||typeof e!="object")throw new TypeError("First argument must be an object");var n=typeof t=="function",i={},a={};for(var o in e){var r=e[o];if(n&&(i=t(o,r),i&&i.length===2)){a[i[0]]=i[1];continue}typeof r=="string"&&(a[r]=o)}return a}var z4=new Set(["annotation-xml","color-profile","font-face","font-face-src","font-face-uri","font-face-format","font-face-name","missing-glyph"]);function W4(e,t){return e.indexOf("-")===-1?t&&typeof t.is=="string":!z4.has(e)}var j4={reactCompat:!0};function M4(e,t){if(e!=null)try{t.style=B4(e,j4)}catch{t.style={}}}var L4=R4.version.split(".")[0]>=16,r0=new Set(["tr","tbody","thead","tfoot","colgroup","table","head","html","frameset"]);function F4(e){return!r0.has(e.name)}function U4(e){return e}var s0={PRESERVE_CUSTOM_ATTRIBUTES:L4,ELEMENTS_WITH_NO_TEXT_CHILDREN:r0,invertObject:O4,isCustomComponent:W4,setStyleProp:M4,canTextBeChildOfNode:F4,returnFirstArg:U4},io=Ft,Eh=s0,G4=["checked","value"],$4=["input","select","textarea"],V4={reset:!0,submit:!0},l0=function(t,n){t=t||{};var i,a,o,r,s,l={},c=t.type&&V4[t.type];for(i in t){if(o=t[i],io.isCustomAttribute(i)){l[i]=o;continue}if(a=i.toLowerCase(),r=Ah(a),r){switch(s=io.getPropertyInfo(r),G4.indexOf(r)!==-1&&$4.indexOf(n)!==-1&&!c&&(r=Ah("default"+a)),l[r]=o,s&&s.type){case io.BOOLEAN:l[r]=!0;break;case io.OVERLOADED_BOOLEAN:o===""&&(l[r]=!0);break}continue}Eh.PRESERVE_CUSTOM_ATTRIBUTES&&(l[i]=o)}return Eh.setStyleProp(t.style,l),l};function Ah(e){return io.possibleStandardNames[e]}var H4=v,Z4=l0,Lo=s0,Q4=Lo.setStyleProp,K4=Lo.canTextBeChildOfNode;function c0(e,t){t=t||{};for(var n=t.library||H4,i=n.cloneElement,a=n.createElement,o=n.isValidElement,r=[],s,l,c=typeof t.replace=="function",d=t.transform||Lo.returnFirstArg,h,y,p,f=t.trim,u=0,T=e.length;u<T;u++){if(s=e[u],c&&(h=t.replace(s),o(h))){T>1&&(h=i(h,{key:h.key||u})),r.push(d(h,s,u));continue}if(s.type==="text"){if(l=!s.data.trim().length,l&&s.parent&&!K4(s.parent)||f&&l)continue;r.push(d(s.data,s,u));continue}switch(y=s.attribs,X4(s)?Q4(y.style,y):y&&(y=Z4(y,s.name)),p=null,s.type){case"script":case"style":s.children[0]&&(y.dangerouslySetInnerHTML={__html:s.children[0].data});break;case"tag":s.name==="textarea"&&s.children[0]?y.defaultValue=s.children[0].data:s.children&&s.children.length&&(p=c0(s.children,t));break;default:continue}T>1&&(y.key=u),r.push(d(a(s.name,y,p),s,u))}return r.length===1?r[0]:r}function X4(e){return Lo.PRESERVE_CUSTOM_ATTRIBUTES&&e.type==="tag"&&Lo.isCustomComponent(e.name,e.attribs)}var Y4=c0,Wl=Np,sa=V9,J4=l0,d0=Y4;sa=typeof sa.default=="function"?sa.default:sa;var eP={lowerCaseAttributeNames:!1};function mn(e,t){if(typeof e!="string")throw new TypeError("First argument must be a string");return e===""?[]:(t=t||{},d0(sa(e,t.htmlparser2||eP),t))}mn.domToReact=d0;mn.htmlToDOM=sa;mn.attributesToProps=J4;mn.Comment=Wl.Comment;mn.Element=Wl.Element;mn.ProcessingInstruction=Wl.ProcessingInstruction;mn.Text=Wl.Text;var tP=mn;mn.default=mn;const En=eu(tP);En.domToReact;En.htmlToDOM;En.attributesToProps;En.Comment;En.Element;En.ProcessingInstruction;En.Text;const Nh=fn.entrypointtypes,nP=fn.plugins,Rh=fn.status_dict,iP="/aiida-registry/pr-preview/pr-280/";function aP({pluginKey:e}){const t=nP[e];return v.useEffect(()=>{window.scrollTo(0,0),document.documentElement.style.scrollBehavior="smooth",(()=>{const i=window.location.hash;if(i){let a=window.location.href;window.location.href=a+" ",window.location.href=a;const o=document.getElementById(i);o&&o.scrollIntoView()}})()},[]),m.jsx(m.Fragment,{children:m.jsxs("div",{id:"details",className:"fade-enter",children:[m.jsxs("h1",{className:"plugin-header",children:['AiiDA plugin package "',m.jsx("a",{href:t.code_home,children:t.name}),'"']}),m.jsx(Ri,{to:"/",children:m.jsx("p",{style:{display:"inline"},children:"< back to the registry index"})}),m.jsx("h2",{id:"general.information",children:"General information"}),m.jsxs("div",{children:[m.jsxs("p",{children:[m.jsx("strong",{children:"Current state: "}),m.jsx("img",{className:"svg-badge",src:`${iP}${Rh[t.development_status][1]}`,title:Rh[t.development_status][0]})]}),t.metadata.description&&m.jsxs("p",{children:[m.jsx("strong",{children:"Short description"}),": ",t.metadata.description]}),t.pip_url&&m.jsxs("p",{children:[m.jsx("strong",{children:"How to install"}),": ",m.jsx("code",{children:t.pip_install_cmd})]}),m.jsxs("p",{children:[m.jsx("strong",{children:"Source code"}),": ",m.jsx("a",{href:t.code_home,target:"_blank",children:"Go to the source code repository"})]}),t.documentation_url?m.jsxs("p",{children:[m.jsx("strong",{children:"Documentation"}),": ",m.jsx("a",{href:t.documentation_url,target:"_blank",children:"Go to plugin documentation"})]}):m.jsxs("p",{children:[m.jsx("strong",{children:"Documentation"}),": No documentation provided by the package author"]})]}),m.jsx("h3",{children:"Registry checks"}),t.warnings.length!==0||t.errors.length!==0?m.jsxs(m.Fragment,{children:[t.warnings&&m.jsx(m.Fragment,{children:t.warnings.map(n=>m.jsx(Dc,{severity:"warning",children:En(`${n}`)}))}),t.errors&&m.jsx(m.Fragment,{children:t.errors.map(n=>m.jsx(Dc,{severity:"error",children:En(`${n}`)}))})]}):m.jsx(Dc,{severity:"success",children:"All checks passed!"}),m.jsx("h2",{id:"detailed.information",children:"Detailed information"}),Object.keys(t.metadata).length!==0?m.jsxs(m.Fragment,{children:[t.metadata.author&&m.jsxs("p",{children:[m.jsx("strong",{children:"Author(s)"}),": ",t.metadata.author]}),t.metadata.author_email&&m.jsxs("p",{children:[m.jsx("strong",{children:"Contact"}),":",t.metadata.author_email.split(",").map(n=>m.jsxs("span",{children:[m.jsx("a",{href:`mailto:${n.trim()}`,children:n.trim()}),", "]},n))]}),m.jsxs("p",{children:[m.jsx("strong",{children:"How to use from python"}),":"," ",m.jsxs("code",{children:["import ",t.package_name]})]}),m.jsxs("p",{children:[m.jsx("strong",{children:"Most recent version"}),": ",t.metadata.version]}),t.aiida_version&&m.jsxs("p",{children:[m.jsx("strong",{children:"Compatibility: "}),m.jsx("img",{className:"svg-badge",src:`https://img.shields.io/badge/AiiDA-${t.aiida_version}-007ec6.svg?logo=${vb}`})]}),t.summaryinfo.length!==0&&m.jsxs(m.Fragment,{children:[m.jsx("h3",{id:"plugins",children:"Plugins provided by the package"}),t.summaryinfo.map(n=>m.jsxs("span",{className:"badge",children:[m.jsx("span",{className:`badge-left ${n.colorclass}`,children:n.text}),m.jsx("span",{className:"badge-right",children:n.count})]},n.text))]}),t.entry_points?Object.entries(t.entry_points).map(([n,i])=>m.jsx(m.Fragment,{children:m.jsxs("div",{children:[m.jsx("h2",{style:{color:"black"},id:n,children:n in Nh?m.jsxs(m.Fragment,{children:[Nh[n]," ",m.jsxs("span",{className:"entrypointraw",children:["(",n,")"]})]}):n}),m.jsx("ul",{children:Object.entries(i).map(([a,o])=>m.jsxs("li",{children:[m.jsx("h2",{style:{color:"black"},id:`${n}.${a}`,children:a}),typeof o=="string"?m.jsxs("div",{className:"classbox",children:["class",m.jsxs("span",{className:"tooltiptext",children:[" ",o]})]}):m.jsx(oP,{entryPoints:o})]},a))})]},n)})):m.jsx("p",{children:"No entry points defined for this plugin."})]}):m.jsx("div",{id:"description",children:m.jsxs("p",{children:["Detailed information for this package could not be obtained. Ask the plugin author to add a ",m.jsx("code",{children:"setup.json"})," file to the plugin source code."]})})]})})}const oP=({entryPoints:e})=>m.jsxs("div",{style:{overflow:"auto"},children:[m.jsx("table",{children:m.jsx("tbody",{children:m.jsxs("tr",{children:[m.jsx("th",{children:"Class"}),m.jsx("td",{children:m.jsx("code",{children:e.class})})]})})}),m.jsxs("table",{children:[m.jsx("tr",{children:m.jsx("th",{children:"Description"})}),e.description.map(t=>m.jsx("tr",{className:"ep_description",children:m.jsx(Xd,{children:t.trim()})}))]}),m.jsxs("table",{children:[m.jsxs("tr",{children:[m.jsx("th",{children:"Inputs"}),m.jsx("th",{children:"Required"}),m.jsx("th",{children:"Valid Types"}),m.jsx("th",{children:"Description"})]}),m.jsx(Bh,{spec:e.spec.inputs}),m.jsxs("tr",{children:[m.jsx("th",{children:"Outputs"}),m.jsx("th",{children:"Required"}),m.jsx("th",{children:"Valid Types"}),m.jsx("th",{children:"Description"})]}),m.jsx(Bh,{spec:e.spec.outputs})]}),m.jsxs("table",{children:[m.jsx("tr",{children:m.jsx("th",{children:"Exit Codes"})}),m.jsxs("tr",{children:[m.jsx("th",{children:"Status"}),m.jsx("th",{children:"Message"})]}),e.spec.exit_codes.map(t=>m.jsxs("tr",{className:"ep_description",children:[m.jsx("td",{children:t.status}),m.jsx(Xd,{children:t.message})]}))]})]}),Bh=({spec:e})=>m.jsx(m.Fragment,{children:e.map(t=>m.jsxs("tr",{className:"ep_description",children:[m.jsx("td",{children:t.name}),m.jsx("td",{children:t.required.toString()}),m.jsx("td",{children:t.valid_types}),m.jsx(Xd,{children:t.info})]}))});const rP=["addEndListener","appear","children","container","direction","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"];function sP(e,t,n){const i=t.getBoundingClientRect(),a=n&&n.getBoundingClientRect(),o=pn(t);let r;if(t.fakeTransform)r=t.fakeTransform;else{const c=o.getComputedStyle(t);r=c.getPropertyValue("-webkit-transform")||c.getPropertyValue("transform")}let s=0,l=0;if(r&&r!=="none"&&typeof r=="string"){const c=r.split("(")[1].split(")")[0].split(",");s=parseInt(c[4],10),l=parseInt(c[5],10)}return e==="left"?a?`translateX(${a.right+s-i.left}px)`:`translateX(${o.innerWidth+s-i.left}px)`:e==="right"?a?`translateX(-${i.right-a.left-s}px)`:`translateX(-${i.left+i.width-s}px)`:e==="up"?a?`translateY(${a.bottom+l-i.top}px)`:`translateY(${o.innerHeight+l-i.top}px)`:a?`translateY(-${i.top-a.top+i.height-l}px)`:`translateY(-${i.top+i.height-l}px)`}function lP(e){return typeof e=="function"?e():e}function Cr(e,t,n){const i=lP(n),a=sP(e,t,i);a&&(t.style.webkitTransform=a,t.style.transform=a)}const cP=v.forwardRef(function(t,n){const i=Ra(),a={enter:i.transitions.easing.easeOut,exit:i.transitions.easing.sharp},o={enter:i.transitions.duration.enteringScreen,exit:i.transitions.duration.leavingScreen},{addEndListener:r,appear:s=!0,children:l,container:c,direction:d="down",easing:h=a,in:y,onEnter:p,onEntered:f,onEntering:u,onExit:T,onExited:g,onExiting:_,style:b,timeout:w=o,TransitionComponent:C=xp}=t,I=U(t,rP),x=v.useRef(null),q=Xe(l.ref,x,n),S=D=>N=>{D&&(N===void 0?D(x.current):D(x.current,N))},P=S((D,N)=>{Cr(d,D,c),Cp(D),p&&p(D,N)}),R=S((D,N)=>{const W=Ca({timeout:w,style:b,easing:h},{mode:"enter"});D.style.webkitTransition=i.transitions.create("-webkit-transform",k({},W)),D.style.transition=i.transitions.create("transform",k({},W)),D.style.webkitTransform="none",D.style.transform="none",u&&u(D,N)}),O=S(f),M=S(_),A=S(D=>{const N=Ca({timeout:w,style:b,easing:h},{mode:"exit"});D.style.webkitTransition=i.transitions.create("-webkit-transform",N),D.style.transition=i.transitions.create("transform",N),Cr(d,D,c),T&&T(D)}),B=S(D=>{D.style.webkitTransition="",D.style.transition="",g&&g(D)}),z=D=>{r&&r(x.current,D)},L=v.useCallback(()=>{x.current&&Cr(d,x.current,c)},[d,c]);return v.useEffect(()=>{if(y||d==="down"||d==="right")return;const D=el(()=>{x.current&&Cr(d,x.current,c)}),N=pn(x.current);return N.addEventListener("resize",D),()=>{D.clear(),N.removeEventListener("resize",D)}},[d,y,c]),v.useEffect(()=>{y||L()},[y,L]),m.jsx(C,k({nodeRef:x,onEnter:P,onEntered:O,onEntering:R,onExit:A,onExited:B,onExiting:M,addEndListener:z,appear:s,in:y,timeout:w},I,{children:(D,N)=>v.cloneElement(l,k({ref:q,style:k({visibility:D==="exited"&&!y?"hidden":void 0},b,l.props.style)},N))}))}),dP=cP;function uP(e){return me("MuiDrawer",e)}re("MuiDrawer",["root","docked","paper","paperAnchorLeft","paperAnchorRight","paperAnchorTop","paperAnchorBottom","paperAnchorDockedLeft","paperAnchorDockedRight","paperAnchorDockedTop","paperAnchorDockedBottom","modal"]);const pP=["BackdropProps"],mP=["anchor","BackdropProps","children","className","elevation","hideBackdrop","ModalProps","onClose","open","PaperProps","SlideProps","TransitionComponent","transitionDuration","variant"],u0=(e,t)=>{const{ownerState:n}=e;return[t.root,(n.variant==="permanent"||n.variant==="persistent")&&t.docked,t.modal]},fP=e=>{const{classes:t,anchor:n,variant:i}=e,a={root:["root"],docked:[(i==="permanent"||i==="persistent")&&"docked"],modal:["modal"],paper:["paper",`paperAnchor${Z(n)}`,i!=="temporary"&&`paperAnchorDocked${Z(n)}`]};return fe(a,uP,t)},hP=F(Ip,{name:"MuiDrawer",slot:"Root",overridesResolver:u0})(({theme:e})=>({zIndex:(e.vars||e).zIndex.drawer})),Oh=F("div",{shouldForwardProp:Yt,name:"MuiDrawer",slot:"Docked",skipVariantsResolver:!1,overridesResolver:u0})({flex:"0 0 auto"}),yP=F(tr,{name:"MuiDrawer",slot:"Paper",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.paper,t[`paperAnchor${Z(n.anchor)}`],n.variant!=="temporary"&&t[`paperAnchorDocked${Z(n.anchor)}`]]}})(({theme:e,ownerState:t})=>k({overflowY:"auto",display:"flex",flexDirection:"column",height:"100%",flex:"1 0 auto",zIndex:(e.vars||e).zIndex.drawer,WebkitOverflowScrolling:"touch",position:"fixed",top:0,outline:0},t.anchor==="left"&&{left:0},t.anchor==="top"&&{top:0,left:0,right:0,height:"auto",maxHeight:"100%"},t.anchor==="right"&&{right:0},t.anchor==="bottom"&&{top:"auto",left:0,bottom:0,right:0,height:"auto",maxHeight:"100%"},t.anchor==="left"&&t.variant!=="temporary"&&{borderRight:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="top"&&t.variant!=="temporary"&&{borderBottom:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="right"&&t.variant!=="temporary"&&{borderLeft:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="bottom"&&t.variant!=="temporary"&&{borderTop:`1px solid ${(e.vars||e).palette.divider}`})),p0={left:"right",right:"left",top:"down",bottom:"up"};function gP(e){return["left","right"].indexOf(e)!==-1}function _P(e,t){return e.direction==="rtl"&&gP(t)?p0[t]:t}const bP=v.forwardRef(function(t,n){const i=he({props:t,name:"MuiDrawer"}),a=Ra(),o={enter:a.transitions.duration.enteringScreen,exit:a.transitions.duration.leavingScreen},{anchor:r="left",BackdropProps:s,children:l,className:c,elevation:d=16,hideBackdrop:h=!1,ModalProps:{BackdropProps:y}={},onClose:p,open:f=!1,PaperProps:u={},SlideProps:T,TransitionComponent:g=dP,transitionDuration:_=o,variant:b="temporary"}=i,w=U(i.ModalProps,pP),C=U(i,mP),I=v.useRef(!1);v.useEffect(()=>{I.current=!0},[]);const x=_P(a,r),S=k({},i,{anchor:r,elevation:d,open:f,variant:b},C),P=fP(S),R=m.jsx(yP,k({elevation:b==="temporary"?d:0,square:!0},u,{className:V(P.paper,u.className),ownerState:S,children:l}));if(b==="permanent")return m.jsx(Oh,k({className:V(P.root,P.docked,c),ownerState:S,ref:n},C,{children:R}));const O=m.jsx(g,k({in:f,direction:p0[x],timeout:_,appear:I.current},T,{children:R}));return b==="persistent"?m.jsx(Oh,k({className:V(P.root,P.docked,c),ownerState:S,ref:n},C,{children:O})):m.jsx(hP,k({BackdropProps:k({},s,y,{transitionDuration:_}),className:V(P.root,P.modal,c),open:f,ownerState:S,onClose:p,hideBackdrop:h,ref:n},C,w,{children:O}))}),vP=bP,wP=fn.plugins;function xP({pluginKey:e}){const t=wP[e];function n(){function a(){document.querySelector("header").style.top="-155px",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="0"}setTimeout(a,800)}const i=m.jsxs("div",{style:{paddingLeft:"10px"},children:[m.jsx("h1",{children:"Plugin content"}),m.jsx($f,{}),m.jsx("p",{children:m.jsx("a",{style:{color:"black"},href:"#general.information",onClick:n,children:"General Information"})}),m.jsx("p",{children:m.jsx("a",{style:{color:"black"},href:"#detailed.information",onClick:n,children:"Detailed Information"})}),m.jsx("p",{children:m.jsx("a",{style:{color:"black"},href:"#plugins",onClick:n,children:"Plugins provided by the package"})}),t.entry_points&&Object.entries(t.entry_points).map(([a,o])=>m.jsx(m.Fragment,{children:m.jsx("ul",{children:m.jsxs("li",{children:[m.jsx("a",{style:{color:"black"},href:`#${a}`,onClick:n,children:a}),Object.entries(o).map(([r,s])=>m.jsx("ul",{children:m.jsx("li",{children:m.jsx("a",{style:{color:"black"},href:`#${a}.${r}`,onClick:n,children:r})})},r))]})})})),m.jsx($f,{})]});return m.jsx(vP,{variant:"permanent",id:"sidebar",anchor:"right",sx:{display:{xs:"none",sm:"block"}},open:!0,children:i})}function TP(){return m.jsxs(m.Fragment,{children:[m.jsx(kP,{}),m.jsx("div",{style:{marginTop:"155px"},children:m.jsx(pq,{children:m.jsx(pT,{children:m.jsxs(Dw,{children:[m.jsx(qd,{path:"/",element:m.jsx(nD,{})}),m.jsx(qd,{path:"/:key",element:m.jsx(IP,{})})]})})})}),m.jsx(CP,{})]})}function kP(){return m.jsx("header",{children:m.jsxs("div",{style:{paddingLeft:"20px"},children:[m.jsx("h1",{children:m.jsx("a",{href:"http://aiidateam.github.io/aiida-registry",children:m.jsx("img",{src:Ww,height:"70px"})})}),m.jsx("p",{style:{fontSize:"90%"},children:m.jsx("a",{href:"http://github.com/aiidateam/aiida-registry",style:{color:"#999"},children:"[View on GitHub/register your package]"})})]})})}function CP(){return m.jsxs("footer",{className:"footer",children:[m.jsx("hr",{}),"The official ",m.jsx("a",{href:"http://aiidateam.github.io/aiida-registry",children:"registry"})," of ",m.jsx("a",{href:"http://www.aiida.net",children:"AiiDA"})," plugins.",m.jsx("br",{}),"This work is supported by the ",m.jsx("a",{href:"http://nccr-marvel.ch",target:"_blank",children:"MARVEL National Centre for Competence in Research"})," funded by the ",m.jsx("a",{href:"http://www.snf.ch/en",target:"_blank",children:"Swiss National Science Foundation"}),", as well as by the ",m.jsx("a",{href:"http://www.max-centre.eu",target:"_blank",children:"MaX European Centre of Excellence"})," funded by the Horizon 2020 EINFRA-5 program, Grant No. 676598.",m.jsx("br",{}),m.jsx("br",{}),m.jsxs("div",{style:{textAlign:"center"},children:[m.jsx("img",{src:jw,height:"70px"}),"    ",m.jsx("img",{src:Mw,height:"70px"})]})]})}function IP(){const{key:e}=fw();v.useEffect(()=>(document.querySelector("footer").style.width="calc(100% - 380px)",()=>{document.querySelector("footer").style.width="calc(100% - 64px)"}),[]);function t(){var n=window.scrollY;window.onscroll=function(){var i=window.scrollY;n>i?(document.querySelector("header").style.top="0",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="155px"):n>150&&(document.querySelector("header").style.top="-155px",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="0"),n=i}}return t(),m.jsx(m.Fragment,{children:m.jsxs("div",{id:"detailsContainer",children:[m.jsx(aP,{pluginKey:e}),m.jsx(xP,{pluginKey:e})]})})}const qP="/aiida-registry/pr-preview/pr-280/";Nc.createRoot(document.getElementById("root")).render(m.jsx(Zt.StrictMode,{children:m.jsx(Rw,{basename:qP,children:m.jsx(TP,{})})}));
