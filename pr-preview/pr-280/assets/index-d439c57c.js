function W_(e,t){for(var n=0;n<t.length;n++){const i=t[n];if(typeof i!="string"&&!Array.isArray(i)){for(const a in i)if(a!=="default"&&!(a in e)){const o=Object.getOwnPropertyDescriptor(i,a);o&&Object.defineProperty(e,a,o.get?o:{enumerable:!0,get:()=>i[a]})}}}return Object.freeze(Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}))}(function(){const t=document.createElement("link").relList;if(t&&t.supports&&t.supports("modulepreload"))return;for(const a of document.querySelectorAll('link[rel="modulepreload"]'))i(a);new MutationObserver(a=>{for(const o of a)if(o.type==="childList")for(const r of o.addedNodes)r.tagName==="LINK"&&r.rel==="modulepreload"&&i(r)}).observe(document,{childList:!0,subtree:!0});function n(a){const o={};return a.integrity&&(o.integrity=a.integrity),a.referrerPolicy&&(o.referrerPolicy=a.referrerPolicy),a.crossOrigin==="use-credentials"?o.credentials="include":a.crossOrigin==="anonymous"?o.credentials="omit":o.credentials="same-origin",o}function i(a){if(a.ep)return;a.ep=!0;const o=n(a);fetch(a.href,o)}})();function Ef(e){return e&&e.__esModule&&Object.prototype.hasOwnProperty.call(e,"default")?e.default:e}function j_(e){if(e.__esModule)return e;var t=e.default;if(typeof t=="function"){var n=function i(){return this instanceof i?Reflect.construct(t,arguments,this.constructor):t.apply(this,arguments)};n.prototype=t.prototype}else n={};return Object.defineProperty(n,"__esModule",{value:!0}),Object.keys(e).forEach(function(i){var a=Object.getOwnPropertyDescriptor(e,i);Object.defineProperty(n,i,a.get?a:{enumerable:!0,get:function(){return e[i]}})}),n}var Nf={exports:{}},ss={},Bf={exports:{}},X={};/**
 * @license React
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Co=Symbol.for("react.element"),M_=Symbol.for("react.portal"),L_=Symbol.for("react.fragment"),F_=Symbol.for("react.strict_mode"),U_=Symbol.for("react.profiler"),G_=Symbol.for("react.provider"),$_=Symbol.for("react.context"),V_=Symbol.for("react.forward_ref"),H_=Symbol.for("react.suspense"),Z_=Symbol.for("react.memo"),Q_=Symbol.for("react.lazy"),tp=Symbol.iterator;function K_(e){return e===null||typeof e!="object"?null:(e=tp&&e[tp]||e["@@iterator"],typeof e=="function"?e:null)}var Rf={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},Of=Object.assign,zf={};function ha(e,t,n){this.props=e,this.context=t,this.refs=zf,this.updater=n||Rf}ha.prototype.isReactComponent={};ha.prototype.setState=function(e,t){if(typeof e!="object"&&typeof e!="function"&&e!=null)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")};ha.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")};function Wf(){}Wf.prototype=ha.prototype;function xd(e,t,n){this.props=e,this.context=t,this.refs=zf,this.updater=n||Rf}var Td=xd.prototype=new Wf;Td.constructor=xd;Of(Td,ha.prototype);Td.isPureReactComponent=!0;var np=Array.isArray,jf=Object.prototype.hasOwnProperty,kd={current:null},Mf={key:!0,ref:!0,__self:!0,__source:!0};function Lf(e,t,n){var i,a={},o=null,r=null;if(t!=null)for(i in t.ref!==void 0&&(r=t.ref),t.key!==void 0&&(o=""+t.key),t)jf.call(t,i)&&!Mf.hasOwnProperty(i)&&(a[i]=t[i]);var s=arguments.length-2;if(s===1)a.children=n;else if(1<s){for(var l=Array(s),c=0;c<s;c++)l[c]=arguments[c+2];a.children=l}if(e&&e.defaultProps)for(i in s=e.defaultProps,s)a[i]===void 0&&(a[i]=s[i]);return{$$typeof:Co,type:e,key:o,ref:r,props:a,_owner:kd.current}}function X_(e,t){return{$$typeof:Co,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}function Id(e){return typeof e=="object"&&e!==null&&e.$$typeof===Co}function Y_(e){var t={"=":"=0",":":"=2"};return"$"+e.replace(/[=:]/g,function(n){return t[n]})}var ip=/\/+/g;function ml(e,t){return typeof e=="object"&&e!==null&&e.key!=null?Y_(""+e.key):t.toString(36)}function cr(e,t,n,i,a){var o=typeof e;(o==="undefined"||o==="boolean")&&(e=null);var r=!1;if(e===null)r=!0;else switch(o){case"string":case"number":r=!0;break;case"object":switch(e.$$typeof){case Co:case M_:r=!0}}if(r)return r=e,a=a(r),e=i===""?"."+ml(r,0):i,np(a)?(n="",e!=null&&(n=e.replace(ip,"$&/")+"/"),cr(a,t,n,"",function(c){return c})):a!=null&&(Id(a)&&(a=X_(a,n+(!a.key||r&&r.key===a.key?"":(""+a.key).replace(ip,"$&/")+"/")+e)),t.push(a)),1;if(r=0,i=i===""?".":i+":",np(e))for(var s=0;s<e.length;s++){o=e[s];var l=i+ml(o,s);r+=cr(o,t,n,l,a)}else if(l=K_(e),typeof l=="function")for(e=l.call(e),s=0;!(o=e.next()).done;)o=o.value,l=i+ml(o,s++),r+=cr(o,t,n,l,a);else if(o==="object")throw t=String(e),Error("Objects are not valid as a React child (found: "+(t==="[object Object]"?"object with keys {"+Object.keys(e).join(", ")+"}":t)+"). If you meant to render a collection of children, use an array instead.");return r}function Lo(e,t,n){if(e==null)return e;var i=[],a=0;return cr(e,i,"","",function(o){return t.call(n,o,a++)}),i}function J_(e){if(e._status===-1){var t=e._result;t=t(),t.then(function(n){(e._status===0||e._status===-1)&&(e._status=1,e._result=n)},function(n){(e._status===0||e._status===-1)&&(e._status=2,e._result=n)}),e._status===-1&&(e._status=0,e._result=t)}if(e._status===1)return e._result.default;throw e._result}var at={current:null},dr={transition:null},eb={ReactCurrentDispatcher:at,ReactCurrentBatchConfig:dr,ReactCurrentOwner:kd};X.Children={map:Lo,forEach:function(e,t,n){Lo(e,function(){t.apply(this,arguments)},n)},count:function(e){var t=0;return Lo(e,function(){t++}),t},toArray:function(e){return Lo(e,function(t){return t})||[]},only:function(e){if(!Id(e))throw Error("React.Children.only expected to receive a single React element child.");return e}};X.Component=ha;X.Fragment=L_;X.Profiler=U_;X.PureComponent=xd;X.StrictMode=F_;X.Suspense=H_;X.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=eb;X.cloneElement=function(e,t,n){if(e==null)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+e+".");var i=Of({},e.props),a=e.key,o=e.ref,r=e._owner;if(t!=null){if(t.ref!==void 0&&(o=t.ref,r=kd.current),t.key!==void 0&&(a=""+t.key),e.type&&e.type.defaultProps)var s=e.type.defaultProps;for(l in t)jf.call(t,l)&&!Mf.hasOwnProperty(l)&&(i[l]=t[l]===void 0&&s!==void 0?s[l]:t[l])}var l=arguments.length-2;if(l===1)i.children=n;else if(1<l){s=Array(l);for(var c=0;c<l;c++)s[c]=arguments[c+2];i.children=s}return{$$typeof:Co,type:e.type,key:a,ref:o,props:i,_owner:r}};X.createContext=function(e){return e={$$typeof:$_,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null},e.Provider={$$typeof:G_,_context:e},e.Consumer=e};X.createElement=Lf;X.createFactory=function(e){var t=Lf.bind(null,e);return t.type=e,t};X.createRef=function(){return{current:null}};X.forwardRef=function(e){return{$$typeof:V_,render:e}};X.isValidElement=Id;X.lazy=function(e){return{$$typeof:Q_,_payload:{_status:-1,_result:e},_init:J_}};X.memo=function(e,t){return{$$typeof:Z_,type:e,compare:t===void 0?null:t}};X.startTransition=function(e){var t=dr.transition;dr.transition={};try{e()}finally{dr.transition=t}};X.unstable_act=function(){throw Error("act(...) is not supported in production builds of React.")};X.useCallback=function(e,t){return at.current.useCallback(e,t)};X.useContext=function(e){return at.current.useContext(e)};X.useDebugValue=function(){};X.useDeferredValue=function(e){return at.current.useDeferredValue(e)};X.useEffect=function(e,t){return at.current.useEffect(e,t)};X.useId=function(){return at.current.useId()};X.useImperativeHandle=function(e,t,n){return at.current.useImperativeHandle(e,t,n)};X.useInsertionEffect=function(e,t){return at.current.useInsertionEffect(e,t)};X.useLayoutEffect=function(e,t){return at.current.useLayoutEffect(e,t)};X.useMemo=function(e,t){return at.current.useMemo(e,t)};X.useReducer=function(e,t,n){return at.current.useReducer(e,t,n)};X.useRef=function(e){return at.current.useRef(e)};X.useState=function(e){return at.current.useState(e)};X.useSyncExternalStore=function(e,t,n){return at.current.useSyncExternalStore(e,t,n)};X.useTransition=function(){return at.current.useTransition()};X.version="18.2.0";Bf.exports=X;var v=Bf.exports;const Ut=Ef(v),qr=W_({__proto__:null,default:Ut},[v]);/**
 * @license React
 * react-jsx-runtime.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var tb=v,nb=Symbol.for("react.element"),ib=Symbol.for("react.fragment"),ab=Object.prototype.hasOwnProperty,ob=tb.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,rb={key:!0,ref:!0,__self:!0,__source:!0};function Ff(e,t,n){var i,a={},o=null,r=null;n!==void 0&&(o=""+n),t.key!==void 0&&(o=""+t.key),t.ref!==void 0&&(r=t.ref);for(i in t)ab.call(t,i)&&!rb.hasOwnProperty(i)&&(a[i]=t[i]);if(e&&e.defaultProps)for(i in t=e.defaultProps,t)a[i]===void 0&&(a[i]=t[i]);return{$$typeof:nb,type:e,key:o,ref:r,props:a,_owner:ob.current}}ss.Fragment=ib;ss.jsx=Ff;ss.jsxs=Ff;Nf.exports=ss;var p=Nf.exports,ic={},Uf={exports:{}},xt={},Gf={exports:{}},$f={};/**
 * @license React
 * scheduler.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */(function(e){function t(D,N){var W=D.length;D.push(N);e:for(;0<W;){var ee=W-1>>>1,Q=D[ee];if(0<a(Q,N))D[ee]=N,D[W]=Q,W=ee;else break e}}function n(D){return D.length===0?null:D[0]}function i(D){if(D.length===0)return null;var N=D[0],W=D.pop();if(W!==N){D[0]=W;e:for(var ee=0,Q=D.length,Ne=Q>>>1;ee<Ne;){var Y=2*(ee+1)-1,ve=D[Y],se=Y+1,Ge=D[se];if(0>a(ve,W))se<Q&&0>a(Ge,ve)?(D[ee]=Ge,D[se]=W,ee=se):(D[ee]=ve,D[Y]=W,ee=Y);else if(se<Q&&0>a(Ge,W))D[ee]=Ge,D[se]=W,ee=se;else break e}}return N}function a(D,N){var W=D.sortIndex-N.sortIndex;return W!==0?W:D.id-N.id}if(typeof performance=="object"&&typeof performance.now=="function"){var o=performance;e.unstable_now=function(){return o.now()}}else{var r=Date,s=r.now();e.unstable_now=function(){return r.now()-s}}var l=[],c=[],d=1,f=null,h=3,u=!1,y=!1,m=!1,k=typeof setTimeout=="function"?setTimeout:null,_=typeof clearTimeout=="function"?clearTimeout:null,g=typeof setImmediate<"u"?setImmediate:null;typeof navigator<"u"&&navigator.scheduling!==void 0&&navigator.scheduling.isInputPending!==void 0&&navigator.scheduling.isInputPending.bind(navigator.scheduling);function b(D){for(var N=n(c);N!==null;){if(N.callback===null)i(c);else if(N.startTime<=D)i(c),N.sortIndex=N.expirationTime,t(l,N);else break;N=n(c)}}function w(D){if(m=!1,b(D),!y)if(n(l)!==null)y=!0,z(I);else{var N=n(c);N!==null&&L(w,N.startTime-D)}}function I(D,N){y=!1,m&&(m=!1,_(C),C=-1),u=!0;var W=h;try{for(b(N),f=n(l);f!==null&&(!(f.expirationTime>N)||D&&!B());){var ee=f.callback;if(typeof ee=="function"){f.callback=null,h=f.priorityLevel;var Q=ee(f.expirationTime<=N);N=e.unstable_now(),typeof Q=="function"?f.callback=Q:f===n(l)&&i(l),b(N)}else i(l);f=n(l)}if(f!==null)var Ne=!0;else{var Y=n(c);Y!==null&&L(w,Y.startTime-N),Ne=!1}return Ne}finally{f=null,h=W,u=!1}}var q=!1,x=null,C=-1,S=5,P=-1;function B(){return!(e.unstable_now()-P<S)}function O(){if(x!==null){var D=e.unstable_now();P=D;var N=!0;try{N=x(!0,D)}finally{N?M():(q=!1,x=null)}}else q=!1}var M;if(typeof g=="function")M=function(){g(O)};else if(typeof MessageChannel<"u"){var E=new MessageChannel,R=E.port2;E.port1.onmessage=O,M=function(){R.postMessage(null)}}else M=function(){k(O,0)};function z(D){x=D,q||(q=!0,M())}function L(D,N){C=k(function(){D(e.unstable_now())},N)}e.unstable_IdlePriority=5,e.unstable_ImmediatePriority=1,e.unstable_LowPriority=4,e.unstable_NormalPriority=3,e.unstable_Profiling=null,e.unstable_UserBlockingPriority=2,e.unstable_cancelCallback=function(D){D.callback=null},e.unstable_continueExecution=function(){y||u||(y=!0,z(I))},e.unstable_forceFrameRate=function(D){0>D||125<D?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):S=0<D?Math.floor(1e3/D):5},e.unstable_getCurrentPriorityLevel=function(){return h},e.unstable_getFirstCallbackNode=function(){return n(l)},e.unstable_next=function(D){switch(h){case 1:case 2:case 3:var N=3;break;default:N=h}var W=h;h=N;try{return D()}finally{h=W}},e.unstable_pauseExecution=function(){},e.unstable_requestPaint=function(){},e.unstable_runWithPriority=function(D,N){switch(D){case 1:case 2:case 3:case 4:case 5:break;default:D=3}var W=h;h=D;try{return N()}finally{h=W}},e.unstable_scheduleCallback=function(D,N,W){var ee=e.unstable_now();switch(typeof W=="object"&&W!==null?(W=W.delay,W=typeof W=="number"&&0<W?ee+W:ee):W=ee,D){case 1:var Q=-1;break;case 2:Q=250;break;case 5:Q=1073741823;break;case 4:Q=1e4;break;default:Q=5e3}return Q=W+Q,D={id:d++,callback:N,priorityLevel:D,startTime:W,expirationTime:Q,sortIndex:-1},W>ee?(D.sortIndex=W,t(c,D),n(l)===null&&D===n(c)&&(m?(_(C),C=-1):m=!0,L(w,W-ee))):(D.sortIndex=Q,t(l,D),y||u||(y=!0,z(I))),D},e.unstable_shouldYield=B,e.unstable_wrapCallback=function(D){var N=h;return function(){var W=h;h=N;try{return D.apply(this,arguments)}finally{h=W}}}})($f);Gf.exports=$f;var sb=Gf.exports;/**
 * @license React
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Vf=v,wt=sb;function A(e){for(var t="https://reactjs.org/docs/error-decoder.html?invariant="+e,n=1;n<arguments.length;n++)t+="&args[]="+encodeURIComponent(arguments[n]);return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}var Hf=new Set,ao={};function Ii(e,t){aa(e,t),aa(e+"Capture",t)}function aa(e,t){for(ao[e]=t,e=0;e<t.length;e++)Hf.add(t[e])}var _n=!(typeof window>"u"||typeof window.document>"u"||typeof window.document.createElement>"u"),ac=Object.prototype.hasOwnProperty,lb=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,ap={},op={};function cb(e){return ac.call(op,e)?!0:ac.call(ap,e)?!1:lb.test(e)?op[e]=!0:(ap[e]=!0,!1)}function db(e,t,n,i){if(n!==null&&n.type===0)return!1;switch(typeof t){case"function":case"symbol":return!0;case"boolean":return i?!1:n!==null?!n.acceptsBooleans:(e=e.toLowerCase().slice(0,5),e!=="data-"&&e!=="aria-");default:return!1}}function ub(e,t,n,i){if(t===null||typeof t>"u"||db(e,t,n,i))return!0;if(i)return!1;if(n!==null)switch(n.type){case 3:return!t;case 4:return t===!1;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}function ot(e,t,n,i,a,o,r){this.acceptsBooleans=t===2||t===3||t===4,this.attributeName=i,this.attributeNamespace=a,this.mustUseProperty=n,this.propertyName=e,this.type=t,this.sanitizeURL=o,this.removeEmptyString=r}var Qe={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(e){Qe[e]=new ot(e,0,!1,e,null,!1,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(e){var t=e[0];Qe[t]=new ot(t,1,!1,e[1],null,!1,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(e){Qe[e]=new ot(e,2,!1,e.toLowerCase(),null,!1,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(e){Qe[e]=new ot(e,2,!1,e,null,!1,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(e){Qe[e]=new ot(e,3,!1,e.toLowerCase(),null,!1,!1)});["checked","multiple","muted","selected"].forEach(function(e){Qe[e]=new ot(e,3,!0,e,null,!1,!1)});["capture","download"].forEach(function(e){Qe[e]=new ot(e,4,!1,e,null,!1,!1)});["cols","rows","size","span"].forEach(function(e){Qe[e]=new ot(e,6,!1,e,null,!1,!1)});["rowSpan","start"].forEach(function(e){Qe[e]=new ot(e,5,!1,e.toLowerCase(),null,!1,!1)});var qd=/[\-:]([a-z])/g;function Cd(e){return e[1].toUpperCase()}"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(e){var t=e.replace(qd,Cd);Qe[t]=new ot(t,1,!1,e,null,!1,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(e){var t=e.replace(qd,Cd);Qe[t]=new ot(t,1,!1,e,"http://www.w3.org/1999/xlink",!1,!1)});["xml:base","xml:lang","xml:space"].forEach(function(e){var t=e.replace(qd,Cd);Qe[t]=new ot(t,1,!1,e,"http://www.w3.org/XML/1998/namespace",!1,!1)});["tabIndex","crossOrigin"].forEach(function(e){Qe[e]=new ot(e,1,!1,e.toLowerCase(),null,!1,!1)});Qe.xlinkHref=new ot("xlinkHref",1,!1,"xlink:href","http://www.w3.org/1999/xlink",!0,!1);["src","href","action","formAction"].forEach(function(e){Qe[e]=new ot(e,1,!1,e.toLowerCase(),null,!0,!0)});function Dd(e,t,n,i){var a=Qe.hasOwnProperty(t)?Qe[t]:null;(a!==null?a.type!==0:i||!(2<t.length)||t[0]!=="o"&&t[0]!=="O"||t[1]!=="n"&&t[1]!=="N")&&(ub(t,n,a,i)&&(n=null),i||a===null?cb(t)&&(n===null?e.removeAttribute(t):e.setAttribute(t,""+n)):a.mustUseProperty?e[a.propertyName]=n===null?a.type===3?!1:"":n:(t=a.attributeName,i=a.attributeNamespace,n===null?e.removeAttribute(t):(a=a.type,n=a===3||a===4&&n===!0?"":""+n,i?e.setAttributeNS(i,t,n):e.setAttribute(t,n))))}var kn=Vf.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,Fo=Symbol.for("react.element"),Wi=Symbol.for("react.portal"),ji=Symbol.for("react.fragment"),Pd=Symbol.for("react.strict_mode"),oc=Symbol.for("react.profiler"),Zf=Symbol.for("react.provider"),Qf=Symbol.for("react.context"),Sd=Symbol.for("react.forward_ref"),rc=Symbol.for("react.suspense"),sc=Symbol.for("react.suspense_list"),Ad=Symbol.for("react.memo"),En=Symbol.for("react.lazy"),Kf=Symbol.for("react.offscreen"),rp=Symbol.iterator;function ka(e){return e===null||typeof e!="object"?null:(e=rp&&e[rp]||e["@@iterator"],typeof e=="function"?e:null)}var Pe=Object.assign,fl;function Ma(e){if(fl===void 0)try{throw Error()}catch(n){var t=n.stack.trim().match(/\n( *(at )?)/);fl=t&&t[1]||""}return`
`+fl+e}var hl=!1;function yl(e,t){if(!e||hl)return"";hl=!0;var n=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,"props",{set:function(){throw Error()}}),typeof Reflect=="object"&&Reflect.construct){try{Reflect.construct(t,[])}catch(c){var i=c}Reflect.construct(e,[],t)}else{try{t.call()}catch(c){i=c}e.call(t.prototype)}else{try{throw Error()}catch(c){i=c}e()}}catch(c){if(c&&i&&typeof c.stack=="string"){for(var a=c.stack.split(`
`),o=i.stack.split(`
`),r=a.length-1,s=o.length-1;1<=r&&0<=s&&a[r]!==o[s];)s--;for(;1<=r&&0<=s;r--,s--)if(a[r]!==o[s]){if(r!==1||s!==1)do if(r--,s--,0>s||a[r]!==o[s]){var l=`
`+a[r].replace(" at new "," at ");return e.displayName&&l.includes("<anonymous>")&&(l=l.replace("<anonymous>",e.displayName)),l}while(1<=r&&0<=s);break}}}finally{hl=!1,Error.prepareStackTrace=n}return(e=e?e.displayName||e.name:"")?Ma(e):""}function pb(e){switch(e.tag){case 5:return Ma(e.type);case 16:return Ma("Lazy");case 13:return Ma("Suspense");case 19:return Ma("SuspenseList");case 0:case 2:case 15:return e=yl(e.type,!1),e;case 11:return e=yl(e.type.render,!1),e;case 1:return e=yl(e.type,!0),e;default:return""}}function lc(e){if(e==null)return null;if(typeof e=="function")return e.displayName||e.name||null;if(typeof e=="string")return e;switch(e){case ji:return"Fragment";case Wi:return"Portal";case oc:return"Profiler";case Pd:return"StrictMode";case rc:return"Suspense";case sc:return"SuspenseList"}if(typeof e=="object")switch(e.$$typeof){case Qf:return(e.displayName||"Context")+".Consumer";case Zf:return(e._context.displayName||"Context")+".Provider";case Sd:var t=e.render;return e=e.displayName,e||(e=t.displayName||t.name||"",e=e!==""?"ForwardRef("+e+")":"ForwardRef"),e;case Ad:return t=e.displayName||null,t!==null?t:lc(e.type)||"Memo";case En:t=e._payload,e=e._init;try{return lc(e(t))}catch{}}return null}function mb(e){var t=e.type;switch(e.tag){case 24:return"Cache";case 9:return(t.displayName||"Context")+".Consumer";case 10:return(t._context.displayName||"Context")+".Provider";case 18:return"DehydratedFragment";case 11:return e=t.render,e=e.displayName||e.name||"",t.displayName||(e!==""?"ForwardRef("+e+")":"ForwardRef");case 7:return"Fragment";case 5:return t;case 4:return"Portal";case 3:return"Root";case 6:return"Text";case 16:return lc(t);case 8:return t===Pd?"StrictMode":"Mode";case 22:return"Offscreen";case 12:return"Profiler";case 21:return"Scope";case 13:return"Suspense";case 19:return"SuspenseList";case 25:return"TracingMarker";case 1:case 0:case 17:case 2:case 14:case 15:if(typeof t=="function")return t.displayName||t.name||null;if(typeof t=="string")return t}return null}function Zn(e){switch(typeof e){case"boolean":case"number":case"string":case"undefined":return e;case"object":return e;default:return""}}function Xf(e){var t=e.type;return(e=e.nodeName)&&e.toLowerCase()==="input"&&(t==="checkbox"||t==="radio")}function fb(e){var t=Xf(e)?"checked":"value",n=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),i=""+e[t];if(!e.hasOwnProperty(t)&&typeof n<"u"&&typeof n.get=="function"&&typeof n.set=="function"){var a=n.get,o=n.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return a.call(this)},set:function(r){i=""+r,o.call(this,r)}}),Object.defineProperty(e,t,{enumerable:n.enumerable}),{getValue:function(){return i},setValue:function(r){i=""+r},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}function Uo(e){e._valueTracker||(e._valueTracker=fb(e))}function Yf(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var n=t.getValue(),i="";return e&&(i=Xf(e)?e.checked?"true":"false":e.value),e=i,e!==n?(t.setValue(e),!0):!1}function Cr(e){if(e=e||(typeof document<"u"?document:void 0),typeof e>"u")return null;try{return e.activeElement||e.body}catch{return e.body}}function cc(e,t){var n=t.checked;return Pe({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:n??e._wrapperState.initialChecked})}function sp(e,t){var n=t.defaultValue==null?"":t.defaultValue,i=t.checked!=null?t.checked:t.defaultChecked;n=Zn(t.value!=null?t.value:n),e._wrapperState={initialChecked:i,initialValue:n,controlled:t.type==="checkbox"||t.type==="radio"?t.checked!=null:t.value!=null}}function Jf(e,t){t=t.checked,t!=null&&Dd(e,"checked",t,!1)}function dc(e,t){Jf(e,t);var n=Zn(t.value),i=t.type;if(n!=null)i==="number"?(n===0&&e.value===""||e.value!=n)&&(e.value=""+n):e.value!==""+n&&(e.value=""+n);else if(i==="submit"||i==="reset"){e.removeAttribute("value");return}t.hasOwnProperty("value")?uc(e,t.type,n):t.hasOwnProperty("defaultValue")&&uc(e,t.type,Zn(t.defaultValue)),t.checked==null&&t.defaultChecked!=null&&(e.defaultChecked=!!t.defaultChecked)}function lp(e,t,n){if(t.hasOwnProperty("value")||t.hasOwnProperty("defaultValue")){var i=t.type;if(!(i!=="submit"&&i!=="reset"||t.value!==void 0&&t.value!==null))return;t=""+e._wrapperState.initialValue,n||t===e.value||(e.value=t),e.defaultValue=t}n=e.name,n!==""&&(e.name=""),e.defaultChecked=!!e._wrapperState.initialChecked,n!==""&&(e.name=n)}function uc(e,t,n){(t!=="number"||Cr(e.ownerDocument)!==e)&&(n==null?e.defaultValue=""+e._wrapperState.initialValue:e.defaultValue!==""+n&&(e.defaultValue=""+n))}var La=Array.isArray;function Ki(e,t,n,i){if(e=e.options,t){t={};for(var a=0;a<n.length;a++)t["$"+n[a]]=!0;for(n=0;n<e.length;n++)a=t.hasOwnProperty("$"+e[n].value),e[n].selected!==a&&(e[n].selected=a),a&&i&&(e[n].defaultSelected=!0)}else{for(n=""+Zn(n),t=null,a=0;a<e.length;a++){if(e[a].value===n){e[a].selected=!0,i&&(e[a].defaultSelected=!0);return}t!==null||e[a].disabled||(t=e[a])}t!==null&&(t.selected=!0)}}function pc(e,t){if(t.dangerouslySetInnerHTML!=null)throw Error(A(91));return Pe({},t,{value:void 0,defaultValue:void 0,children:""+e._wrapperState.initialValue})}function cp(e,t){var n=t.value;if(n==null){if(n=t.children,t=t.defaultValue,n!=null){if(t!=null)throw Error(A(92));if(La(n)){if(1<n.length)throw Error(A(93));n=n[0]}t=n}t==null&&(t=""),n=t}e._wrapperState={initialValue:Zn(n)}}function eh(e,t){var n=Zn(t.value),i=Zn(t.defaultValue);n!=null&&(n=""+n,n!==e.value&&(e.value=n),t.defaultValue==null&&e.defaultValue!==n&&(e.defaultValue=n)),i!=null&&(e.defaultValue=""+i)}function dp(e){var t=e.textContent;t===e._wrapperState.initialValue&&t!==""&&t!==null&&(e.value=t)}function th(e){switch(e){case"svg":return"http://www.w3.org/2000/svg";case"math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function mc(e,t){return e==null||e==="http://www.w3.org/1999/xhtml"?th(t):e==="http://www.w3.org/2000/svg"&&t==="foreignObject"?"http://www.w3.org/1999/xhtml":e}var Go,nh=function(e){return typeof MSApp<"u"&&MSApp.execUnsafeLocalFunction?function(t,n,i,a){MSApp.execUnsafeLocalFunction(function(){return e(t,n,i,a)})}:e}(function(e,t){if(e.namespaceURI!=="http://www.w3.org/2000/svg"||"innerHTML"in e)e.innerHTML=t;else{for(Go=Go||document.createElement("div"),Go.innerHTML="<svg>"+t.valueOf().toString()+"</svg>",t=Go.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}});function oo(e,t){if(t){var n=e.firstChild;if(n&&n===e.lastChild&&n.nodeType===3){n.nodeValue=t;return}}e.textContent=t}var $a={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},hb=["Webkit","ms","Moz","O"];Object.keys($a).forEach(function(e){hb.forEach(function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),$a[t]=$a[e]})});function ih(e,t,n){return t==null||typeof t=="boolean"||t===""?"":n||typeof t!="number"||t===0||$a.hasOwnProperty(e)&&$a[e]?(""+t).trim():t+"px"}function ah(e,t){e=e.style;for(var n in t)if(t.hasOwnProperty(n)){var i=n.indexOf("--")===0,a=ih(n,t[n],i);n==="float"&&(n="cssFloat"),i?e.setProperty(n,a):e[n]=a}}var yb=Pe({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function fc(e,t){if(t){if(yb[e]&&(t.children!=null||t.dangerouslySetInnerHTML!=null))throw Error(A(137,e));if(t.dangerouslySetInnerHTML!=null){if(t.children!=null)throw Error(A(60));if(typeof t.dangerouslySetInnerHTML!="object"||!("__html"in t.dangerouslySetInnerHTML))throw Error(A(61))}if(t.style!=null&&typeof t.style!="object")throw Error(A(62))}}function hc(e,t){if(e.indexOf("-")===-1)return typeof t.is=="string";switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var yc=null;function Ed(e){return e=e.target||e.srcElement||window,e.correspondingUseElement&&(e=e.correspondingUseElement),e.nodeType===3?e.parentNode:e}var gc=null,Xi=null,Yi=null;function up(e){if(e=So(e)){if(typeof gc!="function")throw Error(A(280));var t=e.stateNode;t&&(t=ps(t),gc(e.stateNode,e.type,t))}}function oh(e){Xi?Yi?Yi.push(e):Yi=[e]:Xi=e}function rh(){if(Xi){var e=Xi,t=Yi;if(Yi=Xi=null,up(e),t)for(e=0;e<t.length;e++)up(t[e])}}function sh(e,t){return e(t)}function lh(){}var gl=!1;function ch(e,t,n){if(gl)return e(t,n);gl=!0;try{return sh(e,t,n)}finally{gl=!1,(Xi!==null||Yi!==null)&&(lh(),rh())}}function ro(e,t){var n=e.stateNode;if(n===null)return null;var i=ps(n);if(i===null)return null;n=i[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(i=!i.disabled)||(e=e.type,i=!(e==="button"||e==="input"||e==="select"||e==="textarea")),e=!i;break e;default:e=!1}if(e)return null;if(n&&typeof n!="function")throw Error(A(231,t,typeof n));return n}var _c=!1;if(_n)try{var Ia={};Object.defineProperty(Ia,"passive",{get:function(){_c=!0}}),window.addEventListener("test",Ia,Ia),window.removeEventListener("test",Ia,Ia)}catch{_c=!1}function gb(e,t,n,i,a,o,r,s,l){var c=Array.prototype.slice.call(arguments,3);try{t.apply(n,c)}catch(d){this.onError(d)}}var Va=!1,Dr=null,Pr=!1,bc=null,_b={onError:function(e){Va=!0,Dr=e}};function bb(e,t,n,i,a,o,r,s,l){Va=!1,Dr=null,gb.apply(_b,arguments)}function vb(e,t,n,i,a,o,r,s,l){if(bb.apply(this,arguments),Va){if(Va){var c=Dr;Va=!1,Dr=null}else throw Error(A(198));Pr||(Pr=!0,bc=c)}}function qi(e){var t=e,n=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do t=e,t.flags&4098&&(n=t.return),e=t.return;while(e)}return t.tag===3?n:null}function dh(e){if(e.tag===13){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function pp(e){if(qi(e)!==e)throw Error(A(188))}function wb(e){var t=e.alternate;if(!t){if(t=qi(e),t===null)throw Error(A(188));return t!==e?null:e}for(var n=e,i=t;;){var a=n.return;if(a===null)break;var o=a.alternate;if(o===null){if(i=a.return,i!==null){n=i;continue}break}if(a.child===o.child){for(o=a.child;o;){if(o===n)return pp(a),e;if(o===i)return pp(a),t;o=o.sibling}throw Error(A(188))}if(n.return!==i.return)n=a,i=o;else{for(var r=!1,s=a.child;s;){if(s===n){r=!0,n=a,i=o;break}if(s===i){r=!0,i=a,n=o;break}s=s.sibling}if(!r){for(s=o.child;s;){if(s===n){r=!0,n=o,i=a;break}if(s===i){r=!0,i=o,n=a;break}s=s.sibling}if(!r)throw Error(A(189))}}if(n.alternate!==i)throw Error(A(190))}if(n.tag!==3)throw Error(A(188));return n.stateNode.current===n?e:t}function uh(e){return e=wb(e),e!==null?ph(e):null}function ph(e){if(e.tag===5||e.tag===6)return e;for(e=e.child;e!==null;){var t=ph(e);if(t!==null)return t;e=e.sibling}return null}var mh=wt.unstable_scheduleCallback,mp=wt.unstable_cancelCallback,xb=wt.unstable_shouldYield,Tb=wt.unstable_requestPaint,Re=wt.unstable_now,kb=wt.unstable_getCurrentPriorityLevel,Nd=wt.unstable_ImmediatePriority,fh=wt.unstable_UserBlockingPriority,Sr=wt.unstable_NormalPriority,Ib=wt.unstable_LowPriority,hh=wt.unstable_IdlePriority,ls=null,nn=null;function qb(e){if(nn&&typeof nn.onCommitFiberRoot=="function")try{nn.onCommitFiberRoot(ls,e,void 0,(e.current.flags&128)===128)}catch{}}var Gt=Math.clz32?Math.clz32:Pb,Cb=Math.log,Db=Math.LN2;function Pb(e){return e>>>=0,e===0?32:31-(Cb(e)/Db|0)|0}var $o=64,Vo=4194304;function Fa(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return e&4194240;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return e&130023424;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function Ar(e,t){var n=e.pendingLanes;if(n===0)return 0;var i=0,a=e.suspendedLanes,o=e.pingedLanes,r=n&268435455;if(r!==0){var s=r&~a;s!==0?i=Fa(s):(o&=r,o!==0&&(i=Fa(o)))}else r=n&~a,r!==0?i=Fa(r):o!==0&&(i=Fa(o));if(i===0)return 0;if(t!==0&&t!==i&&!(t&a)&&(a=i&-i,o=t&-t,a>=o||a===16&&(o&4194240)!==0))return t;if(i&4&&(i|=n&16),t=e.entangledLanes,t!==0)for(e=e.entanglements,t&=i;0<t;)n=31-Gt(t),a=1<<n,i|=e[n],t&=~a;return i}function Sb(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return-1;case 134217728:case 268435456:case 536870912:case 1073741824:return-1;default:return-1}}function Ab(e,t){for(var n=e.suspendedLanes,i=e.pingedLanes,a=e.expirationTimes,o=e.pendingLanes;0<o;){var r=31-Gt(o),s=1<<r,l=a[r];l===-1?(!(s&n)||s&i)&&(a[r]=Sb(s,t)):l<=t&&(e.expiredLanes|=s),o&=~s}}function vc(e){return e=e.pendingLanes&-1073741825,e!==0?e:e&1073741824?1073741824:0}function yh(){var e=$o;return $o<<=1,!($o&4194240)&&($o=64),e}function _l(e){for(var t=[],n=0;31>n;n++)t.push(e);return t}function Do(e,t,n){e.pendingLanes|=t,t!==536870912&&(e.suspendedLanes=0,e.pingedLanes=0),e=e.eventTimes,t=31-Gt(t),e[t]=n}function Eb(e,t){var n=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var i=e.eventTimes;for(e=e.expirationTimes;0<n;){var a=31-Gt(n),o=1<<a;t[a]=0,i[a]=-1,e[a]=-1,n&=~o}}function Bd(e,t){var n=e.entangledLanes|=t;for(e=e.entanglements;n;){var i=31-Gt(n),a=1<<i;a&t|e[i]&t&&(e[i]|=t),n&=~a}}var le=0;function gh(e){return e&=-e,1<e?4<e?e&268435455?16:536870912:4:1}var _h,Rd,bh,vh,wh,wc=!1,Ho=[],jn=null,Mn=null,Ln=null,so=new Map,lo=new Map,Bn=[],Nb="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit".split(" ");function fp(e,t){switch(e){case"focusin":case"focusout":jn=null;break;case"dragenter":case"dragleave":Mn=null;break;case"mouseover":case"mouseout":Ln=null;break;case"pointerover":case"pointerout":so.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":lo.delete(t.pointerId)}}function qa(e,t,n,i,a,o){return e===null||e.nativeEvent!==o?(e={blockedOn:t,domEventName:n,eventSystemFlags:i,nativeEvent:o,targetContainers:[a]},t!==null&&(t=So(t),t!==null&&Rd(t)),e):(e.eventSystemFlags|=i,t=e.targetContainers,a!==null&&t.indexOf(a)===-1&&t.push(a),e)}function Bb(e,t,n,i,a){switch(t){case"focusin":return jn=qa(jn,e,t,n,i,a),!0;case"dragenter":return Mn=qa(Mn,e,t,n,i,a),!0;case"mouseover":return Ln=qa(Ln,e,t,n,i,a),!0;case"pointerover":var o=a.pointerId;return so.set(o,qa(so.get(o)||null,e,t,n,i,a)),!0;case"gotpointercapture":return o=a.pointerId,lo.set(o,qa(lo.get(o)||null,e,t,n,i,a)),!0}return!1}function xh(e){var t=ui(e.target);if(t!==null){var n=qi(t);if(n!==null){if(t=n.tag,t===13){if(t=dh(n),t!==null){e.blockedOn=t,wh(e.priority,function(){bh(n)});return}}else if(t===3&&n.stateNode.current.memoizedState.isDehydrated){e.blockedOn=n.tag===3?n.stateNode.containerInfo:null;return}}}e.blockedOn=null}function ur(e){if(e.blockedOn!==null)return!1;for(var t=e.targetContainers;0<t.length;){var n=xc(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(n===null){n=e.nativeEvent;var i=new n.constructor(n.type,n);yc=i,n.target.dispatchEvent(i),yc=null}else return t=So(n),t!==null&&Rd(t),e.blockedOn=n,!1;t.shift()}return!0}function hp(e,t,n){ur(e)&&n.delete(t)}function Rb(){wc=!1,jn!==null&&ur(jn)&&(jn=null),Mn!==null&&ur(Mn)&&(Mn=null),Ln!==null&&ur(Ln)&&(Ln=null),so.forEach(hp),lo.forEach(hp)}function Ca(e,t){e.blockedOn===t&&(e.blockedOn=null,wc||(wc=!0,wt.unstable_scheduleCallback(wt.unstable_NormalPriority,Rb)))}function co(e){function t(a){return Ca(a,e)}if(0<Ho.length){Ca(Ho[0],e);for(var n=1;n<Ho.length;n++){var i=Ho[n];i.blockedOn===e&&(i.blockedOn=null)}}for(jn!==null&&Ca(jn,e),Mn!==null&&Ca(Mn,e),Ln!==null&&Ca(Ln,e),so.forEach(t),lo.forEach(t),n=0;n<Bn.length;n++)i=Bn[n],i.blockedOn===e&&(i.blockedOn=null);for(;0<Bn.length&&(n=Bn[0],n.blockedOn===null);)xh(n),n.blockedOn===null&&Bn.shift()}var Ji=kn.ReactCurrentBatchConfig,Er=!0;function Ob(e,t,n,i){var a=le,o=Ji.transition;Ji.transition=null;try{le=1,Od(e,t,n,i)}finally{le=a,Ji.transition=o}}function zb(e,t,n,i){var a=le,o=Ji.transition;Ji.transition=null;try{le=4,Od(e,t,n,i)}finally{le=a,Ji.transition=o}}function Od(e,t,n,i){if(Er){var a=xc(e,t,n,i);if(a===null)Dl(e,t,i,Nr,n),fp(e,i);else if(Bb(a,e,t,n,i))i.stopPropagation();else if(fp(e,i),t&4&&-1<Nb.indexOf(e)){for(;a!==null;){var o=So(a);if(o!==null&&_h(o),o=xc(e,t,n,i),o===null&&Dl(e,t,i,Nr,n),o===a)break;a=o}a!==null&&i.stopPropagation()}else Dl(e,t,i,null,n)}}var Nr=null;function xc(e,t,n,i){if(Nr=null,e=Ed(i),e=ui(e),e!==null)if(t=qi(e),t===null)e=null;else if(n=t.tag,n===13){if(e=dh(t),e!==null)return e;e=null}else if(n===3){if(t.stateNode.current.memoizedState.isDehydrated)return t.tag===3?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Nr=e,null}function Th(e){switch(e){case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 1;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"toggle":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 4;case"message":switch(kb()){case Nd:return 1;case fh:return 4;case Sr:case Ib:return 16;case hh:return 536870912;default:return 16}default:return 16}}var On=null,zd=null,pr=null;function kh(){if(pr)return pr;var e,t=zd,n=t.length,i,a="value"in On?On.value:On.textContent,o=a.length;for(e=0;e<n&&t[e]===a[e];e++);var r=n-e;for(i=1;i<=r&&t[n-i]===a[o-i];i++);return pr=a.slice(e,1<i?1-i:void 0)}function mr(e){var t=e.keyCode;return"charCode"in e?(e=e.charCode,e===0&&t===13&&(e=13)):e=t,e===10&&(e=13),32<=e||e===13?e:0}function Zo(){return!0}function yp(){return!1}function Tt(e){function t(n,i,a,o,r){this._reactName=n,this._targetInst=a,this.type=i,this.nativeEvent=o,this.target=r,this.currentTarget=null;for(var s in e)e.hasOwnProperty(s)&&(n=e[s],this[s]=n?n(o):o[s]);return this.isDefaultPrevented=(o.defaultPrevented!=null?o.defaultPrevented:o.returnValue===!1)?Zo:yp,this.isPropagationStopped=yp,this}return Pe(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var n=this.nativeEvent;n&&(n.preventDefault?n.preventDefault():typeof n.returnValue!="unknown"&&(n.returnValue=!1),this.isDefaultPrevented=Zo)},stopPropagation:function(){var n=this.nativeEvent;n&&(n.stopPropagation?n.stopPropagation():typeof n.cancelBubble!="unknown"&&(n.cancelBubble=!0),this.isPropagationStopped=Zo)},persist:function(){},isPersistent:Zo}),t}var ya={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},Wd=Tt(ya),Po=Pe({},ya,{view:0,detail:0}),Wb=Tt(Po),bl,vl,Da,cs=Pe({},Po,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:jd,button:0,buttons:0,relatedTarget:function(e){return e.relatedTarget===void 0?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==Da&&(Da&&e.type==="mousemove"?(bl=e.screenX-Da.screenX,vl=e.screenY-Da.screenY):vl=bl=0,Da=e),bl)},movementY:function(e){return"movementY"in e?e.movementY:vl}}),gp=Tt(cs),jb=Pe({},cs,{dataTransfer:0}),Mb=Tt(jb),Lb=Pe({},Po,{relatedTarget:0}),wl=Tt(Lb),Fb=Pe({},ya,{animationName:0,elapsedTime:0,pseudoElement:0}),Ub=Tt(Fb),Gb=Pe({},ya,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),$b=Tt(Gb),Vb=Pe({},ya,{data:0}),_p=Tt(Vb),Hb={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},Zb={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},Qb={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function Kb(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):(e=Qb[e])?!!t[e]:!1}function jd(){return Kb}var Xb=Pe({},Po,{key:function(e){if(e.key){var t=Hb[e.key]||e.key;if(t!=="Unidentified")return t}return e.type==="keypress"?(e=mr(e),e===13?"Enter":String.fromCharCode(e)):e.type==="keydown"||e.type==="keyup"?Zb[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:jd,charCode:function(e){return e.type==="keypress"?mr(e):0},keyCode:function(e){return e.type==="keydown"||e.type==="keyup"?e.keyCode:0},which:function(e){return e.type==="keypress"?mr(e):e.type==="keydown"||e.type==="keyup"?e.keyCode:0}}),Yb=Tt(Xb),Jb=Pe({},cs,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0}),bp=Tt(Jb),e0=Pe({},Po,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:jd}),t0=Tt(e0),n0=Pe({},ya,{propertyName:0,elapsedTime:0,pseudoElement:0}),i0=Tt(n0),a0=Pe({},cs,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),o0=Tt(a0),r0=[9,13,27,32],Md=_n&&"CompositionEvent"in window,Ha=null;_n&&"documentMode"in document&&(Ha=document.documentMode);var s0=_n&&"TextEvent"in window&&!Ha,Ih=_n&&(!Md||Ha&&8<Ha&&11>=Ha),vp=String.fromCharCode(32),wp=!1;function qh(e,t){switch(e){case"keyup":return r0.indexOf(t.keyCode)!==-1;case"keydown":return t.keyCode!==229;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function Ch(e){return e=e.detail,typeof e=="object"&&"data"in e?e.data:null}var Mi=!1;function l0(e,t){switch(e){case"compositionend":return Ch(t);case"keypress":return t.which!==32?null:(wp=!0,vp);case"textInput":return e=t.data,e===vp&&wp?null:e;default:return null}}function c0(e,t){if(Mi)return e==="compositionend"||!Md&&qh(e,t)?(e=kh(),pr=zd=On=null,Mi=!1,e):null;switch(e){case"paste":return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return Ih&&t.locale!=="ko"?null:t.data;default:return null}}var d0={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function xp(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t==="input"?!!d0[e.type]:t==="textarea"}function Dh(e,t,n,i){oh(i),t=Br(t,"onChange"),0<t.length&&(n=new Wd("onChange","change",null,n,i),e.push({event:n,listeners:t}))}var Za=null,uo=null;function u0(e){jh(e,0)}function ds(e){var t=Ui(e);if(Yf(t))return e}function p0(e,t){if(e==="change")return t}var Ph=!1;if(_n){var xl;if(_n){var Tl="oninput"in document;if(!Tl){var Tp=document.createElement("div");Tp.setAttribute("oninput","return;"),Tl=typeof Tp.oninput=="function"}xl=Tl}else xl=!1;Ph=xl&&(!document.documentMode||9<document.documentMode)}function kp(){Za&&(Za.detachEvent("onpropertychange",Sh),uo=Za=null)}function Sh(e){if(e.propertyName==="value"&&ds(uo)){var t=[];Dh(t,uo,e,Ed(e)),ch(u0,t)}}function m0(e,t,n){e==="focusin"?(kp(),Za=t,uo=n,Za.attachEvent("onpropertychange",Sh)):e==="focusout"&&kp()}function f0(e){if(e==="selectionchange"||e==="keyup"||e==="keydown")return ds(uo)}function h0(e,t){if(e==="click")return ds(t)}function y0(e,t){if(e==="input"||e==="change")return ds(t)}function g0(e,t){return e===t&&(e!==0||1/e===1/t)||e!==e&&t!==t}var Vt=typeof Object.is=="function"?Object.is:g0;function po(e,t){if(Vt(e,t))return!0;if(typeof e!="object"||e===null||typeof t!="object"||t===null)return!1;var n=Object.keys(e),i=Object.keys(t);if(n.length!==i.length)return!1;for(i=0;i<n.length;i++){var a=n[i];if(!ac.call(t,a)||!Vt(e[a],t[a]))return!1}return!0}function Ip(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function qp(e,t){var n=Ip(e);e=0;for(var i;n;){if(n.nodeType===3){if(i=e+n.textContent.length,e<=t&&i>=t)return{node:n,offset:t-e};e=i}e:{for(;n;){if(n.nextSibling){n=n.nextSibling;break e}n=n.parentNode}n=void 0}n=Ip(n)}}function Ah(e,t){return e&&t?e===t?!0:e&&e.nodeType===3?!1:t&&t.nodeType===3?Ah(e,t.parentNode):"contains"in e?e.contains(t):e.compareDocumentPosition?!!(e.compareDocumentPosition(t)&16):!1:!1}function Eh(){for(var e=window,t=Cr();t instanceof e.HTMLIFrameElement;){try{var n=typeof t.contentWindow.location.href=="string"}catch{n=!1}if(n)e=t.contentWindow;else break;t=Cr(e.document)}return t}function Ld(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(t==="input"&&(e.type==="text"||e.type==="search"||e.type==="tel"||e.type==="url"||e.type==="password")||t==="textarea"||e.contentEditable==="true")}function _0(e){var t=Eh(),n=e.focusedElem,i=e.selectionRange;if(t!==n&&n&&n.ownerDocument&&Ah(n.ownerDocument.documentElement,n)){if(i!==null&&Ld(n)){if(t=i.start,e=i.end,e===void 0&&(e=t),"selectionStart"in n)n.selectionStart=t,n.selectionEnd=Math.min(e,n.value.length);else if(e=(t=n.ownerDocument||document)&&t.defaultView||window,e.getSelection){e=e.getSelection();var a=n.textContent.length,o=Math.min(i.start,a);i=i.end===void 0?o:Math.min(i.end,a),!e.extend&&o>i&&(a=i,i=o,o=a),a=qp(n,o);var r=qp(n,i);a&&r&&(e.rangeCount!==1||e.anchorNode!==a.node||e.anchorOffset!==a.offset||e.focusNode!==r.node||e.focusOffset!==r.offset)&&(t=t.createRange(),t.setStart(a.node,a.offset),e.removeAllRanges(),o>i?(e.addRange(t),e.extend(r.node,r.offset)):(t.setEnd(r.node,r.offset),e.addRange(t)))}}for(t=[],e=n;e=e.parentNode;)e.nodeType===1&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for(typeof n.focus=="function"&&n.focus(),n=0;n<t.length;n++)e=t[n],e.element.scrollLeft=e.left,e.element.scrollTop=e.top}}var b0=_n&&"documentMode"in document&&11>=document.documentMode,Li=null,Tc=null,Qa=null,kc=!1;function Cp(e,t,n){var i=n.window===n?n.document:n.nodeType===9?n:n.ownerDocument;kc||Li==null||Li!==Cr(i)||(i=Li,"selectionStart"in i&&Ld(i)?i={start:i.selectionStart,end:i.selectionEnd}:(i=(i.ownerDocument&&i.ownerDocument.defaultView||window).getSelection(),i={anchorNode:i.anchorNode,anchorOffset:i.anchorOffset,focusNode:i.focusNode,focusOffset:i.focusOffset}),Qa&&po(Qa,i)||(Qa=i,i=Br(Tc,"onSelect"),0<i.length&&(t=new Wd("onSelect","select",null,t,n),e.push({event:t,listeners:i}),t.target=Li)))}function Qo(e,t){var n={};return n[e.toLowerCase()]=t.toLowerCase(),n["Webkit"+e]="webkit"+t,n["Moz"+e]="moz"+t,n}var Fi={animationend:Qo("Animation","AnimationEnd"),animationiteration:Qo("Animation","AnimationIteration"),animationstart:Qo("Animation","AnimationStart"),transitionend:Qo("Transition","TransitionEnd")},kl={},Nh={};_n&&(Nh=document.createElement("div").style,"AnimationEvent"in window||(delete Fi.animationend.animation,delete Fi.animationiteration.animation,delete Fi.animationstart.animation),"TransitionEvent"in window||delete Fi.transitionend.transition);function us(e){if(kl[e])return kl[e];if(!Fi[e])return e;var t=Fi[e],n;for(n in t)if(t.hasOwnProperty(n)&&n in Nh)return kl[e]=t[n];return e}var Bh=us("animationend"),Rh=us("animationiteration"),Oh=us("animationstart"),zh=us("transitionend"),Wh=new Map,Dp="abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");function Yn(e,t){Wh.set(e,t),Ii(t,[e])}for(var Il=0;Il<Dp.length;Il++){var ql=Dp[Il],v0=ql.toLowerCase(),w0=ql[0].toUpperCase()+ql.slice(1);Yn(v0,"on"+w0)}Yn(Bh,"onAnimationEnd");Yn(Rh,"onAnimationIteration");Yn(Oh,"onAnimationStart");Yn("dblclick","onDoubleClick");Yn("focusin","onFocus");Yn("focusout","onBlur");Yn(zh,"onTransitionEnd");aa("onMouseEnter",["mouseout","mouseover"]);aa("onMouseLeave",["mouseout","mouseover"]);aa("onPointerEnter",["pointerout","pointerover"]);aa("onPointerLeave",["pointerout","pointerover"]);Ii("onChange","change click focusin focusout input keydown keyup selectionchange".split(" "));Ii("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" "));Ii("onBeforeInput",["compositionend","keypress","textInput","paste"]);Ii("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" "));Ii("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" "));Ii("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var Ua="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),x0=new Set("cancel close invalid load scroll toggle".split(" ").concat(Ua));function Pp(e,t,n){var i=e.type||"unknown-event";e.currentTarget=n,vb(i,t,void 0,e),e.currentTarget=null}function jh(e,t){t=(t&4)!==0;for(var n=0;n<e.length;n++){var i=e[n],a=i.event;i=i.listeners;e:{var o=void 0;if(t)for(var r=i.length-1;0<=r;r--){var s=i[r],l=s.instance,c=s.currentTarget;if(s=s.listener,l!==o&&a.isPropagationStopped())break e;Pp(a,s,c),o=l}else for(r=0;r<i.length;r++){if(s=i[r],l=s.instance,c=s.currentTarget,s=s.listener,l!==o&&a.isPropagationStopped())break e;Pp(a,s,c),o=l}}}if(Pr)throw e=bc,Pr=!1,bc=null,e}function _e(e,t){var n=t[Pc];n===void 0&&(n=t[Pc]=new Set);var i=e+"__bubble";n.has(i)||(Mh(t,e,2,!1),n.add(i))}function Cl(e,t,n){var i=0;t&&(i|=4),Mh(n,e,i,t)}var Ko="_reactListening"+Math.random().toString(36).slice(2);function mo(e){if(!e[Ko]){e[Ko]=!0,Hf.forEach(function(n){n!=="selectionchange"&&(x0.has(n)||Cl(n,!1,e),Cl(n,!0,e))});var t=e.nodeType===9?e:e.ownerDocument;t===null||t[Ko]||(t[Ko]=!0,Cl("selectionchange",!1,t))}}function Mh(e,t,n,i){switch(Th(t)){case 1:var a=Ob;break;case 4:a=zb;break;default:a=Od}n=a.bind(null,t,n,e),a=void 0,!_c||t!=="touchstart"&&t!=="touchmove"&&t!=="wheel"||(a=!0),i?a!==void 0?e.addEventListener(t,n,{capture:!0,passive:a}):e.addEventListener(t,n,!0):a!==void 0?e.addEventListener(t,n,{passive:a}):e.addEventListener(t,n,!1)}function Dl(e,t,n,i,a){var o=i;if(!(t&1)&&!(t&2)&&i!==null)e:for(;;){if(i===null)return;var r=i.tag;if(r===3||r===4){var s=i.stateNode.containerInfo;if(s===a||s.nodeType===8&&s.parentNode===a)break;if(r===4)for(r=i.return;r!==null;){var l=r.tag;if((l===3||l===4)&&(l=r.stateNode.containerInfo,l===a||l.nodeType===8&&l.parentNode===a))return;r=r.return}for(;s!==null;){if(r=ui(s),r===null)return;if(l=r.tag,l===5||l===6){i=o=r;continue e}s=s.parentNode}}i=i.return}ch(function(){var c=o,d=Ed(n),f=[];e:{var h=Wh.get(e);if(h!==void 0){var u=Wd,y=e;switch(e){case"keypress":if(mr(n)===0)break e;case"keydown":case"keyup":u=Yb;break;case"focusin":y="focus",u=wl;break;case"focusout":y="blur",u=wl;break;case"beforeblur":case"afterblur":u=wl;break;case"click":if(n.button===2)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":u=gp;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":u=Mb;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":u=t0;break;case Bh:case Rh:case Oh:u=Ub;break;case zh:u=i0;break;case"scroll":u=Wb;break;case"wheel":u=o0;break;case"copy":case"cut":case"paste":u=$b;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":u=bp}var m=(t&4)!==0,k=!m&&e==="scroll",_=m?h!==null?h+"Capture":null:h;m=[];for(var g=c,b;g!==null;){b=g;var w=b.stateNode;if(b.tag===5&&w!==null&&(b=w,_!==null&&(w=ro(g,_),w!=null&&m.push(fo(g,w,b)))),k)break;g=g.return}0<m.length&&(h=new u(h,y,null,n,d),f.push({event:h,listeners:m}))}}if(!(t&7)){e:{if(h=e==="mouseover"||e==="pointerover",u=e==="mouseout"||e==="pointerout",h&&n!==yc&&(y=n.relatedTarget||n.fromElement)&&(ui(y)||y[bn]))break e;if((u||h)&&(h=d.window===d?d:(h=d.ownerDocument)?h.defaultView||h.parentWindow:window,u?(y=n.relatedTarget||n.toElement,u=c,y=y?ui(y):null,y!==null&&(k=qi(y),y!==k||y.tag!==5&&y.tag!==6)&&(y=null)):(u=null,y=c),u!==y)){if(m=gp,w="onMouseLeave",_="onMouseEnter",g="mouse",(e==="pointerout"||e==="pointerover")&&(m=bp,w="onPointerLeave",_="onPointerEnter",g="pointer"),k=u==null?h:Ui(u),b=y==null?h:Ui(y),h=new m(w,g+"leave",u,n,d),h.target=k,h.relatedTarget=b,w=null,ui(d)===c&&(m=new m(_,g+"enter",y,n,d),m.target=b,m.relatedTarget=k,w=m),k=w,u&&y)t:{for(m=u,_=y,g=0,b=m;b;b=Pi(b))g++;for(b=0,w=_;w;w=Pi(w))b++;for(;0<g-b;)m=Pi(m),g--;for(;0<b-g;)_=Pi(_),b--;for(;g--;){if(m===_||_!==null&&m===_.alternate)break t;m=Pi(m),_=Pi(_)}m=null}else m=null;u!==null&&Sp(f,h,u,m,!1),y!==null&&k!==null&&Sp(f,k,y,m,!0)}}e:{if(h=c?Ui(c):window,u=h.nodeName&&h.nodeName.toLowerCase(),u==="select"||u==="input"&&h.type==="file")var I=p0;else if(xp(h))if(Ph)I=y0;else{I=f0;var q=m0}else(u=h.nodeName)&&u.toLowerCase()==="input"&&(h.type==="checkbox"||h.type==="radio")&&(I=h0);if(I&&(I=I(e,c))){Dh(f,I,n,d);break e}q&&q(e,h,c),e==="focusout"&&(q=h._wrapperState)&&q.controlled&&h.type==="number"&&uc(h,"number",h.value)}switch(q=c?Ui(c):window,e){case"focusin":(xp(q)||q.contentEditable==="true")&&(Li=q,Tc=c,Qa=null);break;case"focusout":Qa=Tc=Li=null;break;case"mousedown":kc=!0;break;case"contextmenu":case"mouseup":case"dragend":kc=!1,Cp(f,n,d);break;case"selectionchange":if(b0)break;case"keydown":case"keyup":Cp(f,n,d)}var x;if(Md)e:{switch(e){case"compositionstart":var C="onCompositionStart";break e;case"compositionend":C="onCompositionEnd";break e;case"compositionupdate":C="onCompositionUpdate";break e}C=void 0}else Mi?qh(e,n)&&(C="onCompositionEnd"):e==="keydown"&&n.keyCode===229&&(C="onCompositionStart");C&&(Ih&&n.locale!=="ko"&&(Mi||C!=="onCompositionStart"?C==="onCompositionEnd"&&Mi&&(x=kh()):(On=d,zd="value"in On?On.value:On.textContent,Mi=!0)),q=Br(c,C),0<q.length&&(C=new _p(C,e,null,n,d),f.push({event:C,listeners:q}),x?C.data=x:(x=Ch(n),x!==null&&(C.data=x)))),(x=s0?l0(e,n):c0(e,n))&&(c=Br(c,"onBeforeInput"),0<c.length&&(d=new _p("onBeforeInput","beforeinput",null,n,d),f.push({event:d,listeners:c}),d.data=x))}jh(f,t)})}function fo(e,t,n){return{instance:e,listener:t,currentTarget:n}}function Br(e,t){for(var n=t+"Capture",i=[];e!==null;){var a=e,o=a.stateNode;a.tag===5&&o!==null&&(a=o,o=ro(e,n),o!=null&&i.unshift(fo(e,o,a)),o=ro(e,t),o!=null&&i.push(fo(e,o,a))),e=e.return}return i}function Pi(e){if(e===null)return null;do e=e.return;while(e&&e.tag!==5);return e||null}function Sp(e,t,n,i,a){for(var o=t._reactName,r=[];n!==null&&n!==i;){var s=n,l=s.alternate,c=s.stateNode;if(l!==null&&l===i)break;s.tag===5&&c!==null&&(s=c,a?(l=ro(n,o),l!=null&&r.unshift(fo(n,l,s))):a||(l=ro(n,o),l!=null&&r.push(fo(n,l,s)))),n=n.return}r.length!==0&&e.push({event:t,listeners:r})}var T0=/\r\n?/g,k0=/\u0000|\uFFFD/g;function Ap(e){return(typeof e=="string"?e:""+e).replace(T0,`
`).replace(k0,"")}function Xo(e,t,n){if(t=Ap(t),Ap(e)!==t&&n)throw Error(A(425))}function Rr(){}var Ic=null,qc=null;function Cc(e,t){return e==="textarea"||e==="noscript"||typeof t.children=="string"||typeof t.children=="number"||typeof t.dangerouslySetInnerHTML=="object"&&t.dangerouslySetInnerHTML!==null&&t.dangerouslySetInnerHTML.__html!=null}var Dc=typeof setTimeout=="function"?setTimeout:void 0,I0=typeof clearTimeout=="function"?clearTimeout:void 0,Ep=typeof Promise=="function"?Promise:void 0,q0=typeof queueMicrotask=="function"?queueMicrotask:typeof Ep<"u"?function(e){return Ep.resolve(null).then(e).catch(C0)}:Dc;function C0(e){setTimeout(function(){throw e})}function Pl(e,t){var n=t,i=0;do{var a=n.nextSibling;if(e.removeChild(n),a&&a.nodeType===8)if(n=a.data,n==="/$"){if(i===0){e.removeChild(a),co(t);return}i--}else n!=="$"&&n!=="$?"&&n!=="$!"||i++;n=a}while(n);co(t)}function Fn(e){for(;e!=null;e=e.nextSibling){var t=e.nodeType;if(t===1||t===3)break;if(t===8){if(t=e.data,t==="$"||t==="$!"||t==="$?")break;if(t==="/$")return null}}return e}function Np(e){e=e.previousSibling;for(var t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="$"||n==="$!"||n==="$?"){if(t===0)return e;t--}else n==="/$"&&t++}e=e.previousSibling}return null}var ga=Math.random().toString(36).slice(2),Jt="__reactFiber$"+ga,ho="__reactProps$"+ga,bn="__reactContainer$"+ga,Pc="__reactEvents$"+ga,D0="__reactListeners$"+ga,P0="__reactHandles$"+ga;function ui(e){var t=e[Jt];if(t)return t;for(var n=e.parentNode;n;){if(t=n[bn]||n[Jt]){if(n=t.alternate,t.child!==null||n!==null&&n.child!==null)for(e=Np(e);e!==null;){if(n=e[Jt])return n;e=Np(e)}return t}e=n,n=e.parentNode}return null}function So(e){return e=e[Jt]||e[bn],!e||e.tag!==5&&e.tag!==6&&e.tag!==13&&e.tag!==3?null:e}function Ui(e){if(e.tag===5||e.tag===6)return e.stateNode;throw Error(A(33))}function ps(e){return e[ho]||null}var Sc=[],Gi=-1;function Jn(e){return{current:e}}function be(e){0>Gi||(e.current=Sc[Gi],Sc[Gi]=null,Gi--)}function ge(e,t){Gi++,Sc[Gi]=e.current,e.current=t}var Qn={},tt=Jn(Qn),dt=Jn(!1),_i=Qn;function oa(e,t){var n=e.type.contextTypes;if(!n)return Qn;var i=e.stateNode;if(i&&i.__reactInternalMemoizedUnmaskedChildContext===t)return i.__reactInternalMemoizedMaskedChildContext;var a={},o;for(o in n)a[o]=t[o];return i&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=a),a}function ut(e){return e=e.childContextTypes,e!=null}function Or(){be(dt),be(tt)}function Bp(e,t,n){if(tt.current!==Qn)throw Error(A(168));ge(tt,t),ge(dt,n)}function Lh(e,t,n){var i=e.stateNode;if(t=t.childContextTypes,typeof i.getChildContext!="function")return n;i=i.getChildContext();for(var a in i)if(!(a in t))throw Error(A(108,mb(e)||"Unknown",a));return Pe({},n,i)}function zr(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||Qn,_i=tt.current,ge(tt,e),ge(dt,dt.current),!0}function Rp(e,t,n){var i=e.stateNode;if(!i)throw Error(A(169));n?(e=Lh(e,t,_i),i.__reactInternalMemoizedMergedChildContext=e,be(dt),be(tt),ge(tt,e)):be(dt),ge(dt,n)}var mn=null,ms=!1,Sl=!1;function Fh(e){mn===null?mn=[e]:mn.push(e)}function S0(e){ms=!0,Fh(e)}function ei(){if(!Sl&&mn!==null){Sl=!0;var e=0,t=le;try{var n=mn;for(le=1;e<n.length;e++){var i=n[e];do i=i(!0);while(i!==null)}mn=null,ms=!1}catch(a){throw mn!==null&&(mn=mn.slice(e+1)),mh(Nd,ei),a}finally{le=t,Sl=!1}}return null}var $i=[],Vi=0,Wr=null,jr=0,St=[],At=0,bi=null,fn=1,hn="";function ai(e,t){$i[Vi++]=jr,$i[Vi++]=Wr,Wr=e,jr=t}function Uh(e,t,n){St[At++]=fn,St[At++]=hn,St[At++]=bi,bi=e;var i=fn;e=hn;var a=32-Gt(i)-1;i&=~(1<<a),n+=1;var o=32-Gt(t)+a;if(30<o){var r=a-a%5;o=(i&(1<<r)-1).toString(32),i>>=r,a-=r,fn=1<<32-Gt(t)+a|n<<a|i,hn=o+e}else fn=1<<o|n<<a|i,hn=e}function Fd(e){e.return!==null&&(ai(e,1),Uh(e,1,0))}function Ud(e){for(;e===Wr;)Wr=$i[--Vi],$i[Vi]=null,jr=$i[--Vi],$i[Vi]=null;for(;e===bi;)bi=St[--At],St[At]=null,hn=St[--At],St[At]=null,fn=St[--At],St[At]=null}var bt=null,_t=null,ke=!1,Ft=null;function Gh(e,t){var n=Et(5,null,null,0);n.elementType="DELETED",n.stateNode=t,n.return=e,t=e.deletions,t===null?(e.deletions=[n],e.flags|=16):t.push(n)}function Op(e,t){switch(e.tag){case 5:var n=e.type;return t=t.nodeType!==1||n.toLowerCase()!==t.nodeName.toLowerCase()?null:t,t!==null?(e.stateNode=t,bt=e,_t=Fn(t.firstChild),!0):!1;case 6:return t=e.pendingProps===""||t.nodeType!==3?null:t,t!==null?(e.stateNode=t,bt=e,_t=null,!0):!1;case 13:return t=t.nodeType!==8?null:t,t!==null?(n=bi!==null?{id:fn,overflow:hn}:null,e.memoizedState={dehydrated:t,treeContext:n,retryLane:1073741824},n=Et(18,null,null,0),n.stateNode=t,n.return=e,e.child=n,bt=e,_t=null,!0):!1;default:return!1}}function Ac(e){return(e.mode&1)!==0&&(e.flags&128)===0}function Ec(e){if(ke){var t=_t;if(t){var n=t;if(!Op(e,t)){if(Ac(e))throw Error(A(418));t=Fn(n.nextSibling);var i=bt;t&&Op(e,t)?Gh(i,n):(e.flags=e.flags&-4097|2,ke=!1,bt=e)}}else{if(Ac(e))throw Error(A(418));e.flags=e.flags&-4097|2,ke=!1,bt=e}}}function zp(e){for(e=e.return;e!==null&&e.tag!==5&&e.tag!==3&&e.tag!==13;)e=e.return;bt=e}function Yo(e){if(e!==bt)return!1;if(!ke)return zp(e),ke=!0,!1;var t;if((t=e.tag!==3)&&!(t=e.tag!==5)&&(t=e.type,t=t!=="head"&&t!=="body"&&!Cc(e.type,e.memoizedProps)),t&&(t=_t)){if(Ac(e))throw $h(),Error(A(418));for(;t;)Gh(e,t),t=Fn(t.nextSibling)}if(zp(e),e.tag===13){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(A(317));e:{for(e=e.nextSibling,t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="/$"){if(t===0){_t=Fn(e.nextSibling);break e}t--}else n!=="$"&&n!=="$!"&&n!=="$?"||t++}e=e.nextSibling}_t=null}}else _t=bt?Fn(e.stateNode.nextSibling):null;return!0}function $h(){for(var e=_t;e;)e=Fn(e.nextSibling)}function ra(){_t=bt=null,ke=!1}function Gd(e){Ft===null?Ft=[e]:Ft.push(e)}var A0=kn.ReactCurrentBatchConfig;function Mt(e,t){if(e&&e.defaultProps){t=Pe({},t),e=e.defaultProps;for(var n in e)t[n]===void 0&&(t[n]=e[n]);return t}return t}var Mr=Jn(null),Lr=null,Hi=null,$d=null;function Vd(){$d=Hi=Lr=null}function Hd(e){var t=Mr.current;be(Mr),e._currentValue=t}function Nc(e,t,n){for(;e!==null;){var i=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,i!==null&&(i.childLanes|=t)):i!==null&&(i.childLanes&t)!==t&&(i.childLanes|=t),e===n)break;e=e.return}}function ea(e,t){Lr=e,$d=Hi=null,e=e.dependencies,e!==null&&e.firstContext!==null&&(e.lanes&t&&(ct=!0),e.firstContext=null)}function Rt(e){var t=e._currentValue;if($d!==e)if(e={context:e,memoizedValue:t,next:null},Hi===null){if(Lr===null)throw Error(A(308));Hi=e,Lr.dependencies={lanes:0,firstContext:e}}else Hi=Hi.next=e;return t}var pi=null;function Zd(e){pi===null?pi=[e]:pi.push(e)}function Vh(e,t,n,i){var a=t.interleaved;return a===null?(n.next=n,Zd(t)):(n.next=a.next,a.next=n),t.interleaved=n,vn(e,i)}function vn(e,t){e.lanes|=t;var n=e.alternate;for(n!==null&&(n.lanes|=t),n=e,e=e.return;e!==null;)e.childLanes|=t,n=e.alternate,n!==null&&(n.childLanes|=t),n=e,e=e.return;return n.tag===3?n.stateNode:null}var Nn=!1;function Qd(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function Hh(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function gn(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function Un(e,t,n){var i=e.updateQueue;if(i===null)return null;if(i=i.shared,te&2){var a=i.pending;return a===null?t.next=t:(t.next=a.next,a.next=t),i.pending=t,vn(e,n)}return a=i.interleaved,a===null?(t.next=t,Zd(i)):(t.next=a.next,a.next=t),i.interleaved=t,vn(e,n)}function fr(e,t,n){if(t=t.updateQueue,t!==null&&(t=t.shared,(n&4194240)!==0)){var i=t.lanes;i&=e.pendingLanes,n|=i,t.lanes=n,Bd(e,n)}}function Wp(e,t){var n=e.updateQueue,i=e.alternate;if(i!==null&&(i=i.updateQueue,n===i)){var a=null,o=null;if(n=n.firstBaseUpdate,n!==null){do{var r={eventTime:n.eventTime,lane:n.lane,tag:n.tag,payload:n.payload,callback:n.callback,next:null};o===null?a=o=r:o=o.next=r,n=n.next}while(n!==null);o===null?a=o=t:o=o.next=t}else a=o=t;n={baseState:i.baseState,firstBaseUpdate:a,lastBaseUpdate:o,shared:i.shared,effects:i.effects},e.updateQueue=n;return}e=n.lastBaseUpdate,e===null?n.firstBaseUpdate=t:e.next=t,n.lastBaseUpdate=t}function Fr(e,t,n,i){var a=e.updateQueue;Nn=!1;var o=a.firstBaseUpdate,r=a.lastBaseUpdate,s=a.shared.pending;if(s!==null){a.shared.pending=null;var l=s,c=l.next;l.next=null,r===null?o=c:r.next=c,r=l;var d=e.alternate;d!==null&&(d=d.updateQueue,s=d.lastBaseUpdate,s!==r&&(s===null?d.firstBaseUpdate=c:s.next=c,d.lastBaseUpdate=l))}if(o!==null){var f=a.baseState;r=0,d=c=l=null,s=o;do{var h=s.lane,u=s.eventTime;if((i&h)===h){d!==null&&(d=d.next={eventTime:u,lane:0,tag:s.tag,payload:s.payload,callback:s.callback,next:null});e:{var y=e,m=s;switch(h=t,u=n,m.tag){case 1:if(y=m.payload,typeof y=="function"){f=y.call(u,f,h);break e}f=y;break e;case 3:y.flags=y.flags&-65537|128;case 0:if(y=m.payload,h=typeof y=="function"?y.call(u,f,h):y,h==null)break e;f=Pe({},f,h);break e;case 2:Nn=!0}}s.callback!==null&&s.lane!==0&&(e.flags|=64,h=a.effects,h===null?a.effects=[s]:h.push(s))}else u={eventTime:u,lane:h,tag:s.tag,payload:s.payload,callback:s.callback,next:null},d===null?(c=d=u,l=f):d=d.next=u,r|=h;if(s=s.next,s===null){if(s=a.shared.pending,s===null)break;h=s,s=h.next,h.next=null,a.lastBaseUpdate=h,a.shared.pending=null}}while(1);if(d===null&&(l=f),a.baseState=l,a.firstBaseUpdate=c,a.lastBaseUpdate=d,t=a.shared.interleaved,t!==null){a=t;do r|=a.lane,a=a.next;while(a!==t)}else o===null&&(a.shared.lanes=0);wi|=r,e.lanes=r,e.memoizedState=f}}function jp(e,t,n){if(e=t.effects,t.effects=null,e!==null)for(t=0;t<e.length;t++){var i=e[t],a=i.callback;if(a!==null){if(i.callback=null,i=n,typeof a!="function")throw Error(A(191,a));a.call(i)}}}var Zh=new Vf.Component().refs;function Bc(e,t,n,i){t=e.memoizedState,n=n(i,t),n=n==null?t:Pe({},t,n),e.memoizedState=n,e.lanes===0&&(e.updateQueue.baseState=n)}var fs={isMounted:function(e){return(e=e._reactInternals)?qi(e)===e:!1},enqueueSetState:function(e,t,n){e=e._reactInternals;var i=it(),a=$n(e),o=gn(i,a);o.payload=t,n!=null&&(o.callback=n),t=Un(e,o,a),t!==null&&($t(t,e,a,i),fr(t,e,a))},enqueueReplaceState:function(e,t,n){e=e._reactInternals;var i=it(),a=$n(e),o=gn(i,a);o.tag=1,o.payload=t,n!=null&&(o.callback=n),t=Un(e,o,a),t!==null&&($t(t,e,a,i),fr(t,e,a))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var n=it(),i=$n(e),a=gn(n,i);a.tag=2,t!=null&&(a.callback=t),t=Un(e,a,i),t!==null&&($t(t,e,i,n),fr(t,e,i))}};function Mp(e,t,n,i,a,o,r){return e=e.stateNode,typeof e.shouldComponentUpdate=="function"?e.shouldComponentUpdate(i,o,r):t.prototype&&t.prototype.isPureReactComponent?!po(n,i)||!po(a,o):!0}function Qh(e,t,n){var i=!1,a=Qn,o=t.contextType;return typeof o=="object"&&o!==null?o=Rt(o):(a=ut(t)?_i:tt.current,i=t.contextTypes,o=(i=i!=null)?oa(e,a):Qn),t=new t(n,o),e.memoizedState=t.state!==null&&t.state!==void 0?t.state:null,t.updater=fs,e.stateNode=t,t._reactInternals=e,i&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=a,e.__reactInternalMemoizedMaskedChildContext=o),t}function Lp(e,t,n,i){e=t.state,typeof t.componentWillReceiveProps=="function"&&t.componentWillReceiveProps(n,i),typeof t.UNSAFE_componentWillReceiveProps=="function"&&t.UNSAFE_componentWillReceiveProps(n,i),t.state!==e&&fs.enqueueReplaceState(t,t.state,null)}function Rc(e,t,n,i){var a=e.stateNode;a.props=n,a.state=e.memoizedState,a.refs=Zh,Qd(e);var o=t.contextType;typeof o=="object"&&o!==null?a.context=Rt(o):(o=ut(t)?_i:tt.current,a.context=oa(e,o)),a.state=e.memoizedState,o=t.getDerivedStateFromProps,typeof o=="function"&&(Bc(e,t,o,n),a.state=e.memoizedState),typeof t.getDerivedStateFromProps=="function"||typeof a.getSnapshotBeforeUpdate=="function"||typeof a.UNSAFE_componentWillMount!="function"&&typeof a.componentWillMount!="function"||(t=a.state,typeof a.componentWillMount=="function"&&a.componentWillMount(),typeof a.UNSAFE_componentWillMount=="function"&&a.UNSAFE_componentWillMount(),t!==a.state&&fs.enqueueReplaceState(a,a.state,null),Fr(e,n,a,i),a.state=e.memoizedState),typeof a.componentDidMount=="function"&&(e.flags|=4194308)}function Pa(e,t,n){if(e=n.ref,e!==null&&typeof e!="function"&&typeof e!="object"){if(n._owner){if(n=n._owner,n){if(n.tag!==1)throw Error(A(309));var i=n.stateNode}if(!i)throw Error(A(147,e));var a=i,o=""+e;return t!==null&&t.ref!==null&&typeof t.ref=="function"&&t.ref._stringRef===o?t.ref:(t=function(r){var s=a.refs;s===Zh&&(s=a.refs={}),r===null?delete s[o]:s[o]=r},t._stringRef=o,t)}if(typeof e!="string")throw Error(A(284));if(!n._owner)throw Error(A(290,e))}return e}function Jo(e,t){throw e=Object.prototype.toString.call(t),Error(A(31,e==="[object Object]"?"object with keys {"+Object.keys(t).join(", ")+"}":e))}function Fp(e){var t=e._init;return t(e._payload)}function Kh(e){function t(_,g){if(e){var b=_.deletions;b===null?(_.deletions=[g],_.flags|=16):b.push(g)}}function n(_,g){if(!e)return null;for(;g!==null;)t(_,g),g=g.sibling;return null}function i(_,g){for(_=new Map;g!==null;)g.key!==null?_.set(g.key,g):_.set(g.index,g),g=g.sibling;return _}function a(_,g){return _=Vn(_,g),_.index=0,_.sibling=null,_}function o(_,g,b){return _.index=b,e?(b=_.alternate,b!==null?(b=b.index,b<g?(_.flags|=2,g):b):(_.flags|=2,g)):(_.flags|=1048576,g)}function r(_){return e&&_.alternate===null&&(_.flags|=2),_}function s(_,g,b,w){return g===null||g.tag!==6?(g=zl(b,_.mode,w),g.return=_,g):(g=a(g,b),g.return=_,g)}function l(_,g,b,w){var I=b.type;return I===ji?d(_,g,b.props.children,w,b.key):g!==null&&(g.elementType===I||typeof I=="object"&&I!==null&&I.$$typeof===En&&Fp(I)===g.type)?(w=a(g,b.props),w.ref=Pa(_,g,b),w.return=_,w):(w=vr(b.type,b.key,b.props,null,_.mode,w),w.ref=Pa(_,g,b),w.return=_,w)}function c(_,g,b,w){return g===null||g.tag!==4||g.stateNode.containerInfo!==b.containerInfo||g.stateNode.implementation!==b.implementation?(g=Wl(b,_.mode,w),g.return=_,g):(g=a(g,b.children||[]),g.return=_,g)}function d(_,g,b,w,I){return g===null||g.tag!==7?(g=gi(b,_.mode,w,I),g.return=_,g):(g=a(g,b),g.return=_,g)}function f(_,g,b){if(typeof g=="string"&&g!==""||typeof g=="number")return g=zl(""+g,_.mode,b),g.return=_,g;if(typeof g=="object"&&g!==null){switch(g.$$typeof){case Fo:return b=vr(g.type,g.key,g.props,null,_.mode,b),b.ref=Pa(_,null,g),b.return=_,b;case Wi:return g=Wl(g,_.mode,b),g.return=_,g;case En:var w=g._init;return f(_,w(g._payload),b)}if(La(g)||ka(g))return g=gi(g,_.mode,b,null),g.return=_,g;Jo(_,g)}return null}function h(_,g,b,w){var I=g!==null?g.key:null;if(typeof b=="string"&&b!==""||typeof b=="number")return I!==null?null:s(_,g,""+b,w);if(typeof b=="object"&&b!==null){switch(b.$$typeof){case Fo:return b.key===I?l(_,g,b,w):null;case Wi:return b.key===I?c(_,g,b,w):null;case En:return I=b._init,h(_,g,I(b._payload),w)}if(La(b)||ka(b))return I!==null?null:d(_,g,b,w,null);Jo(_,b)}return null}function u(_,g,b,w,I){if(typeof w=="string"&&w!==""||typeof w=="number")return _=_.get(b)||null,s(g,_,""+w,I);if(typeof w=="object"&&w!==null){switch(w.$$typeof){case Fo:return _=_.get(w.key===null?b:w.key)||null,l(g,_,w,I);case Wi:return _=_.get(w.key===null?b:w.key)||null,c(g,_,w,I);case En:var q=w._init;return u(_,g,b,q(w._payload),I)}if(La(w)||ka(w))return _=_.get(b)||null,d(g,_,w,I,null);Jo(g,w)}return null}function y(_,g,b,w){for(var I=null,q=null,x=g,C=g=0,S=null;x!==null&&C<b.length;C++){x.index>C?(S=x,x=null):S=x.sibling;var P=h(_,x,b[C],w);if(P===null){x===null&&(x=S);break}e&&x&&P.alternate===null&&t(_,x),g=o(P,g,C),q===null?I=P:q.sibling=P,q=P,x=S}if(C===b.length)return n(_,x),ke&&ai(_,C),I;if(x===null){for(;C<b.length;C++)x=f(_,b[C],w),x!==null&&(g=o(x,g,C),q===null?I=x:q.sibling=x,q=x);return ke&&ai(_,C),I}for(x=i(_,x);C<b.length;C++)S=u(x,_,C,b[C],w),S!==null&&(e&&S.alternate!==null&&x.delete(S.key===null?C:S.key),g=o(S,g,C),q===null?I=S:q.sibling=S,q=S);return e&&x.forEach(function(B){return t(_,B)}),ke&&ai(_,C),I}function m(_,g,b,w){var I=ka(b);if(typeof I!="function")throw Error(A(150));if(b=I.call(b),b==null)throw Error(A(151));for(var q=I=null,x=g,C=g=0,S=null,P=b.next();x!==null&&!P.done;C++,P=b.next()){x.index>C?(S=x,x=null):S=x.sibling;var B=h(_,x,P.value,w);if(B===null){x===null&&(x=S);break}e&&x&&B.alternate===null&&t(_,x),g=o(B,g,C),q===null?I=B:q.sibling=B,q=B,x=S}if(P.done)return n(_,x),ke&&ai(_,C),I;if(x===null){for(;!P.done;C++,P=b.next())P=f(_,P.value,w),P!==null&&(g=o(P,g,C),q===null?I=P:q.sibling=P,q=P);return ke&&ai(_,C),I}for(x=i(_,x);!P.done;C++,P=b.next())P=u(x,_,C,P.value,w),P!==null&&(e&&P.alternate!==null&&x.delete(P.key===null?C:P.key),g=o(P,g,C),q===null?I=P:q.sibling=P,q=P);return e&&x.forEach(function(O){return t(_,O)}),ke&&ai(_,C),I}function k(_,g,b,w){if(typeof b=="object"&&b!==null&&b.type===ji&&b.key===null&&(b=b.props.children),typeof b=="object"&&b!==null){switch(b.$$typeof){case Fo:e:{for(var I=b.key,q=g;q!==null;){if(q.key===I){if(I=b.type,I===ji){if(q.tag===7){n(_,q.sibling),g=a(q,b.props.children),g.return=_,_=g;break e}}else if(q.elementType===I||typeof I=="object"&&I!==null&&I.$$typeof===En&&Fp(I)===q.type){n(_,q.sibling),g=a(q,b.props),g.ref=Pa(_,q,b),g.return=_,_=g;break e}n(_,q);break}else t(_,q);q=q.sibling}b.type===ji?(g=gi(b.props.children,_.mode,w,b.key),g.return=_,_=g):(w=vr(b.type,b.key,b.props,null,_.mode,w),w.ref=Pa(_,g,b),w.return=_,_=w)}return r(_);case Wi:e:{for(q=b.key;g!==null;){if(g.key===q)if(g.tag===4&&g.stateNode.containerInfo===b.containerInfo&&g.stateNode.implementation===b.implementation){n(_,g.sibling),g=a(g,b.children||[]),g.return=_,_=g;break e}else{n(_,g);break}else t(_,g);g=g.sibling}g=Wl(b,_.mode,w),g.return=_,_=g}return r(_);case En:return q=b._init,k(_,g,q(b._payload),w)}if(La(b))return y(_,g,b,w);if(ka(b))return m(_,g,b,w);Jo(_,b)}return typeof b=="string"&&b!==""||typeof b=="number"?(b=""+b,g!==null&&g.tag===6?(n(_,g.sibling),g=a(g,b),g.return=_,_=g):(n(_,g),g=zl(b,_.mode,w),g.return=_,_=g),r(_)):n(_,g)}return k}var sa=Kh(!0),Xh=Kh(!1),Ao={},an=Jn(Ao),yo=Jn(Ao),go=Jn(Ao);function mi(e){if(e===Ao)throw Error(A(174));return e}function Kd(e,t){switch(ge(go,t),ge(yo,e),ge(an,Ao),e=t.nodeType,e){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:mc(null,"");break;default:e=e===8?t.parentNode:t,t=e.namespaceURI||null,e=e.tagName,t=mc(t,e)}be(an),ge(an,t)}function la(){be(an),be(yo),be(go)}function Yh(e){mi(go.current);var t=mi(an.current),n=mc(t,e.type);t!==n&&(ge(yo,e),ge(an,n))}function Xd(e){yo.current===e&&(be(an),be(yo))}var Ce=Jn(0);function Ur(e){for(var t=e;t!==null;){if(t.tag===13){var n=t.memoizedState;if(n!==null&&(n=n.dehydrated,n===null||n.data==="$?"||n.data==="$!"))return t}else if(t.tag===19&&t.memoizedProps.revealOrder!==void 0){if(t.flags&128)return t}else if(t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var Al=[];function Yd(){for(var e=0;e<Al.length;e++)Al[e]._workInProgressVersionPrimary=null;Al.length=0}var hr=kn.ReactCurrentDispatcher,El=kn.ReactCurrentBatchConfig,vi=0,De=null,je=null,Le=null,Gr=!1,Ka=!1,_o=0,E0=0;function Xe(){throw Error(A(321))}function Jd(e,t){if(t===null)return!1;for(var n=0;n<t.length&&n<e.length;n++)if(!Vt(e[n],t[n]))return!1;return!0}function eu(e,t,n,i,a,o){if(vi=o,De=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,hr.current=e===null||e.memoizedState===null?O0:z0,e=n(i,a),Ka){o=0;do{if(Ka=!1,_o=0,25<=o)throw Error(A(301));o+=1,Le=je=null,t.updateQueue=null,hr.current=W0,e=n(i,a)}while(Ka)}if(hr.current=$r,t=je!==null&&je.next!==null,vi=0,Le=je=De=null,Gr=!1,t)throw Error(A(300));return e}function tu(){var e=_o!==0;return _o=0,e}function Kt(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return Le===null?De.memoizedState=Le=e:Le=Le.next=e,Le}function Ot(){if(je===null){var e=De.alternate;e=e!==null?e.memoizedState:null}else e=je.next;var t=Le===null?De.memoizedState:Le.next;if(t!==null)Le=t,je=e;else{if(e===null)throw Error(A(310));je=e,e={memoizedState:je.memoizedState,baseState:je.baseState,baseQueue:je.baseQueue,queue:je.queue,next:null},Le===null?De.memoizedState=Le=e:Le=Le.next=e}return Le}function bo(e,t){return typeof t=="function"?t(e):t}function Nl(e){var t=Ot(),n=t.queue;if(n===null)throw Error(A(311));n.lastRenderedReducer=e;var i=je,a=i.baseQueue,o=n.pending;if(o!==null){if(a!==null){var r=a.next;a.next=o.next,o.next=r}i.baseQueue=a=o,n.pending=null}if(a!==null){o=a.next,i=i.baseState;var s=r=null,l=null,c=o;do{var d=c.lane;if((vi&d)===d)l!==null&&(l=l.next={lane:0,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null}),i=c.hasEagerState?c.eagerState:e(i,c.action);else{var f={lane:d,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null};l===null?(s=l=f,r=i):l=l.next=f,De.lanes|=d,wi|=d}c=c.next}while(c!==null&&c!==o);l===null?r=i:l.next=s,Vt(i,t.memoizedState)||(ct=!0),t.memoizedState=i,t.baseState=r,t.baseQueue=l,n.lastRenderedState=i}if(e=n.interleaved,e!==null){a=e;do o=a.lane,De.lanes|=o,wi|=o,a=a.next;while(a!==e)}else a===null&&(n.lanes=0);return[t.memoizedState,n.dispatch]}function Bl(e){var t=Ot(),n=t.queue;if(n===null)throw Error(A(311));n.lastRenderedReducer=e;var i=n.dispatch,a=n.pending,o=t.memoizedState;if(a!==null){n.pending=null;var r=a=a.next;do o=e(o,r.action),r=r.next;while(r!==a);Vt(o,t.memoizedState)||(ct=!0),t.memoizedState=o,t.baseQueue===null&&(t.baseState=o),n.lastRenderedState=o}return[o,i]}function Jh(){}function ey(e,t){var n=De,i=Ot(),a=t(),o=!Vt(i.memoizedState,a);if(o&&(i.memoizedState=a,ct=!0),i=i.queue,nu(iy.bind(null,n,i,e),[e]),i.getSnapshot!==t||o||Le!==null&&Le.memoizedState.tag&1){if(n.flags|=2048,vo(9,ny.bind(null,n,i,a,t),void 0,null),Fe===null)throw Error(A(349));vi&30||ty(n,t,a)}return a}function ty(e,t,n){e.flags|=16384,e={getSnapshot:t,value:n},t=De.updateQueue,t===null?(t={lastEffect:null,stores:null},De.updateQueue=t,t.stores=[e]):(n=t.stores,n===null?t.stores=[e]:n.push(e))}function ny(e,t,n,i){t.value=n,t.getSnapshot=i,ay(t)&&oy(e)}function iy(e,t,n){return n(function(){ay(t)&&oy(e)})}function ay(e){var t=e.getSnapshot;e=e.value;try{var n=t();return!Vt(e,n)}catch{return!0}}function oy(e){var t=vn(e,1);t!==null&&$t(t,e,1,-1)}function Up(e){var t=Kt();return typeof e=="function"&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:bo,lastRenderedState:e},t.queue=e,e=e.dispatch=R0.bind(null,De,e),[t.memoizedState,e]}function vo(e,t,n,i){return e={tag:e,create:t,destroy:n,deps:i,next:null},t=De.updateQueue,t===null?(t={lastEffect:null,stores:null},De.updateQueue=t,t.lastEffect=e.next=e):(n=t.lastEffect,n===null?t.lastEffect=e.next=e:(i=n.next,n.next=e,e.next=i,t.lastEffect=e)),e}function ry(){return Ot().memoizedState}function yr(e,t,n,i){var a=Kt();De.flags|=e,a.memoizedState=vo(1|t,n,void 0,i===void 0?null:i)}function hs(e,t,n,i){var a=Ot();i=i===void 0?null:i;var o=void 0;if(je!==null){var r=je.memoizedState;if(o=r.destroy,i!==null&&Jd(i,r.deps)){a.memoizedState=vo(t,n,o,i);return}}De.flags|=e,a.memoizedState=vo(1|t,n,o,i)}function Gp(e,t){return yr(8390656,8,e,t)}function nu(e,t){return hs(2048,8,e,t)}function sy(e,t){return hs(4,2,e,t)}function ly(e,t){return hs(4,4,e,t)}function cy(e,t){if(typeof t=="function")return e=e(),t(e),function(){t(null)};if(t!=null)return e=e(),t.current=e,function(){t.current=null}}function dy(e,t,n){return n=n!=null?n.concat([e]):null,hs(4,4,cy.bind(null,t,e),n)}function iu(){}function uy(e,t){var n=Ot();t=t===void 0?null:t;var i=n.memoizedState;return i!==null&&t!==null&&Jd(t,i[1])?i[0]:(n.memoizedState=[e,t],e)}function py(e,t){var n=Ot();t=t===void 0?null:t;var i=n.memoizedState;return i!==null&&t!==null&&Jd(t,i[1])?i[0]:(e=e(),n.memoizedState=[e,t],e)}function my(e,t,n){return vi&21?(Vt(n,t)||(n=yh(),De.lanes|=n,wi|=n,e.baseState=!0),t):(e.baseState&&(e.baseState=!1,ct=!0),e.memoizedState=n)}function N0(e,t){var n=le;le=n!==0&&4>n?n:4,e(!0);var i=El.transition;El.transition={};try{e(!1),t()}finally{le=n,El.transition=i}}function fy(){return Ot().memoizedState}function B0(e,t,n){var i=$n(e);if(n={lane:i,action:n,hasEagerState:!1,eagerState:null,next:null},hy(e))yy(t,n);else if(n=Vh(e,t,n,i),n!==null){var a=it();$t(n,e,i,a),gy(n,t,i)}}function R0(e,t,n){var i=$n(e),a={lane:i,action:n,hasEagerState:!1,eagerState:null,next:null};if(hy(e))yy(t,a);else{var o=e.alternate;if(e.lanes===0&&(o===null||o.lanes===0)&&(o=t.lastRenderedReducer,o!==null))try{var r=t.lastRenderedState,s=o(r,n);if(a.hasEagerState=!0,a.eagerState=s,Vt(s,r)){var l=t.interleaved;l===null?(a.next=a,Zd(t)):(a.next=l.next,l.next=a),t.interleaved=a;return}}catch{}finally{}n=Vh(e,t,a,i),n!==null&&(a=it(),$t(n,e,i,a),gy(n,t,i))}}function hy(e){var t=e.alternate;return e===De||t!==null&&t===De}function yy(e,t){Ka=Gr=!0;var n=e.pending;n===null?t.next=t:(t.next=n.next,n.next=t),e.pending=t}function gy(e,t,n){if(n&4194240){var i=t.lanes;i&=e.pendingLanes,n|=i,t.lanes=n,Bd(e,n)}}var $r={readContext:Rt,useCallback:Xe,useContext:Xe,useEffect:Xe,useImperativeHandle:Xe,useInsertionEffect:Xe,useLayoutEffect:Xe,useMemo:Xe,useReducer:Xe,useRef:Xe,useState:Xe,useDebugValue:Xe,useDeferredValue:Xe,useTransition:Xe,useMutableSource:Xe,useSyncExternalStore:Xe,useId:Xe,unstable_isNewReconciler:!1},O0={readContext:Rt,useCallback:function(e,t){return Kt().memoizedState=[e,t===void 0?null:t],e},useContext:Rt,useEffect:Gp,useImperativeHandle:function(e,t,n){return n=n!=null?n.concat([e]):null,yr(4194308,4,cy.bind(null,t,e),n)},useLayoutEffect:function(e,t){return yr(4194308,4,e,t)},useInsertionEffect:function(e,t){return yr(4,2,e,t)},useMemo:function(e,t){var n=Kt();return t=t===void 0?null:t,e=e(),n.memoizedState=[e,t],e},useReducer:function(e,t,n){var i=Kt();return t=n!==void 0?n(t):t,i.memoizedState=i.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},i.queue=e,e=e.dispatch=B0.bind(null,De,e),[i.memoizedState,e]},useRef:function(e){var t=Kt();return e={current:e},t.memoizedState=e},useState:Up,useDebugValue:iu,useDeferredValue:function(e){return Kt().memoizedState=e},useTransition:function(){var e=Up(!1),t=e[0];return e=N0.bind(null,e[1]),Kt().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,n){var i=De,a=Kt();if(ke){if(n===void 0)throw Error(A(407));n=n()}else{if(n=t(),Fe===null)throw Error(A(349));vi&30||ty(i,t,n)}a.memoizedState=n;var o={value:n,getSnapshot:t};return a.queue=o,Gp(iy.bind(null,i,o,e),[e]),i.flags|=2048,vo(9,ny.bind(null,i,o,n,t),void 0,null),n},useId:function(){var e=Kt(),t=Fe.identifierPrefix;if(ke){var n=hn,i=fn;n=(i&~(1<<32-Gt(i)-1)).toString(32)+n,t=":"+t+"R"+n,n=_o++,0<n&&(t+="H"+n.toString(32)),t+=":"}else n=E0++,t=":"+t+"r"+n.toString(32)+":";return e.memoizedState=t},unstable_isNewReconciler:!1},z0={readContext:Rt,useCallback:uy,useContext:Rt,useEffect:nu,useImperativeHandle:dy,useInsertionEffect:sy,useLayoutEffect:ly,useMemo:py,useReducer:Nl,useRef:ry,useState:function(){return Nl(bo)},useDebugValue:iu,useDeferredValue:function(e){var t=Ot();return my(t,je.memoizedState,e)},useTransition:function(){var e=Nl(bo)[0],t=Ot().memoizedState;return[e,t]},useMutableSource:Jh,useSyncExternalStore:ey,useId:fy,unstable_isNewReconciler:!1},W0={readContext:Rt,useCallback:uy,useContext:Rt,useEffect:nu,useImperativeHandle:dy,useInsertionEffect:sy,useLayoutEffect:ly,useMemo:py,useReducer:Bl,useRef:ry,useState:function(){return Bl(bo)},useDebugValue:iu,useDeferredValue:function(e){var t=Ot();return je===null?t.memoizedState=e:my(t,je.memoizedState,e)},useTransition:function(){var e=Bl(bo)[0],t=Ot().memoizedState;return[e,t]},useMutableSource:Jh,useSyncExternalStore:ey,useId:fy,unstable_isNewReconciler:!1};function ca(e,t){try{var n="",i=t;do n+=pb(i),i=i.return;while(i);var a=n}catch(o){a=`
Error generating stack: `+o.message+`
`+o.stack}return{value:e,source:t,stack:a,digest:null}}function Rl(e,t,n){return{value:e,source:null,stack:n??null,digest:t??null}}function Oc(e,t){try{console.error(t.value)}catch(n){setTimeout(function(){throw n})}}var j0=typeof WeakMap=="function"?WeakMap:Map;function _y(e,t,n){n=gn(-1,n),n.tag=3,n.payload={element:null};var i=t.value;return n.callback=function(){Hr||(Hr=!0,Vc=i),Oc(e,t)},n}function by(e,t,n){n=gn(-1,n),n.tag=3;var i=e.type.getDerivedStateFromError;if(typeof i=="function"){var a=t.value;n.payload=function(){return i(a)},n.callback=function(){Oc(e,t)}}var o=e.stateNode;return o!==null&&typeof o.componentDidCatch=="function"&&(n.callback=function(){Oc(e,t),typeof i!="function"&&(Gn===null?Gn=new Set([this]):Gn.add(this));var r=t.stack;this.componentDidCatch(t.value,{componentStack:r!==null?r:""})}),n}function $p(e,t,n){var i=e.pingCache;if(i===null){i=e.pingCache=new j0;var a=new Set;i.set(t,a)}else a=i.get(t),a===void 0&&(a=new Set,i.set(t,a));a.has(n)||(a.add(n),e=J0.bind(null,e,t,n),t.then(e,e))}function Vp(e){do{var t;if((t=e.tag===13)&&(t=e.memoizedState,t=t!==null?t.dehydrated!==null:!0),t)return e;e=e.return}while(e!==null);return null}function Hp(e,t,n,i,a){return e.mode&1?(e.flags|=65536,e.lanes=a,e):(e===t?e.flags|=65536:(e.flags|=128,n.flags|=131072,n.flags&=-52805,n.tag===1&&(n.alternate===null?n.tag=17:(t=gn(-1,1),t.tag=2,Un(n,t,1))),n.lanes|=1),e)}var M0=kn.ReactCurrentOwner,ct=!1;function nt(e,t,n,i){t.child=e===null?Xh(t,null,n,i):sa(t,e.child,n,i)}function Zp(e,t,n,i,a){n=n.render;var o=t.ref;return ea(t,a),i=eu(e,t,n,i,o,a),n=tu(),e!==null&&!ct?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,wn(e,t,a)):(ke&&n&&Fd(t),t.flags|=1,nt(e,t,i,a),t.child)}function Qp(e,t,n,i,a){if(e===null){var o=n.type;return typeof o=="function"&&!uu(o)&&o.defaultProps===void 0&&n.compare===null&&n.defaultProps===void 0?(t.tag=15,t.type=o,vy(e,t,o,i,a)):(e=vr(n.type,null,i,t,t.mode,a),e.ref=t.ref,e.return=t,t.child=e)}if(o=e.child,!(e.lanes&a)){var r=o.memoizedProps;if(n=n.compare,n=n!==null?n:po,n(r,i)&&e.ref===t.ref)return wn(e,t,a)}return t.flags|=1,e=Vn(o,i),e.ref=t.ref,e.return=t,t.child=e}function vy(e,t,n,i,a){if(e!==null){var o=e.memoizedProps;if(po(o,i)&&e.ref===t.ref)if(ct=!1,t.pendingProps=i=o,(e.lanes&a)!==0)e.flags&131072&&(ct=!0);else return t.lanes=e.lanes,wn(e,t,a)}return zc(e,t,n,i,a)}function wy(e,t,n){var i=t.pendingProps,a=i.children,o=e!==null?e.memoizedState:null;if(i.mode==="hidden")if(!(t.mode&1))t.memoizedState={baseLanes:0,cachePool:null,transitions:null},ge(Qi,ht),ht|=n;else{if(!(n&1073741824))return e=o!==null?o.baseLanes|n:n,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,ge(Qi,ht),ht|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},i=o!==null?o.baseLanes:n,ge(Qi,ht),ht|=i}else o!==null?(i=o.baseLanes|n,t.memoizedState=null):i=n,ge(Qi,ht),ht|=i;return nt(e,t,a,n),t.child}function xy(e,t){var n=t.ref;(e===null&&n!==null||e!==null&&e.ref!==n)&&(t.flags|=512,t.flags|=2097152)}function zc(e,t,n,i,a){var o=ut(n)?_i:tt.current;return o=oa(t,o),ea(t,a),n=eu(e,t,n,i,o,a),i=tu(),e!==null&&!ct?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~a,wn(e,t,a)):(ke&&i&&Fd(t),t.flags|=1,nt(e,t,n,a),t.child)}function Kp(e,t,n,i,a){if(ut(n)){var o=!0;zr(t)}else o=!1;if(ea(t,a),t.stateNode===null)gr(e,t),Qh(t,n,i),Rc(t,n,i,a),i=!0;else if(e===null){var r=t.stateNode,s=t.memoizedProps;r.props=s;var l=r.context,c=n.contextType;typeof c=="object"&&c!==null?c=Rt(c):(c=ut(n)?_i:tt.current,c=oa(t,c));var d=n.getDerivedStateFromProps,f=typeof d=="function"||typeof r.getSnapshotBeforeUpdate=="function";f||typeof r.UNSAFE_componentWillReceiveProps!="function"&&typeof r.componentWillReceiveProps!="function"||(s!==i||l!==c)&&Lp(t,r,i,c),Nn=!1;var h=t.memoizedState;r.state=h,Fr(t,i,r,a),l=t.memoizedState,s!==i||h!==l||dt.current||Nn?(typeof d=="function"&&(Bc(t,n,d,i),l=t.memoizedState),(s=Nn||Mp(t,n,s,i,h,l,c))?(f||typeof r.UNSAFE_componentWillMount!="function"&&typeof r.componentWillMount!="function"||(typeof r.componentWillMount=="function"&&r.componentWillMount(),typeof r.UNSAFE_componentWillMount=="function"&&r.UNSAFE_componentWillMount()),typeof r.componentDidMount=="function"&&(t.flags|=4194308)):(typeof r.componentDidMount=="function"&&(t.flags|=4194308),t.memoizedProps=i,t.memoizedState=l),r.props=i,r.state=l,r.context=c,i=s):(typeof r.componentDidMount=="function"&&(t.flags|=4194308),i=!1)}else{r=t.stateNode,Hh(e,t),s=t.memoizedProps,c=t.type===t.elementType?s:Mt(t.type,s),r.props=c,f=t.pendingProps,h=r.context,l=n.contextType,typeof l=="object"&&l!==null?l=Rt(l):(l=ut(n)?_i:tt.current,l=oa(t,l));var u=n.getDerivedStateFromProps;(d=typeof u=="function"||typeof r.getSnapshotBeforeUpdate=="function")||typeof r.UNSAFE_componentWillReceiveProps!="function"&&typeof r.componentWillReceiveProps!="function"||(s!==f||h!==l)&&Lp(t,r,i,l),Nn=!1,h=t.memoizedState,r.state=h,Fr(t,i,r,a);var y=t.memoizedState;s!==f||h!==y||dt.current||Nn?(typeof u=="function"&&(Bc(t,n,u,i),y=t.memoizedState),(c=Nn||Mp(t,n,c,i,h,y,l)||!1)?(d||typeof r.UNSAFE_componentWillUpdate!="function"&&typeof r.componentWillUpdate!="function"||(typeof r.componentWillUpdate=="function"&&r.componentWillUpdate(i,y,l),typeof r.UNSAFE_componentWillUpdate=="function"&&r.UNSAFE_componentWillUpdate(i,y,l)),typeof r.componentDidUpdate=="function"&&(t.flags|=4),typeof r.getSnapshotBeforeUpdate=="function"&&(t.flags|=1024)):(typeof r.componentDidUpdate!="function"||s===e.memoizedProps&&h===e.memoizedState||(t.flags|=4),typeof r.getSnapshotBeforeUpdate!="function"||s===e.memoizedProps&&h===e.memoizedState||(t.flags|=1024),t.memoizedProps=i,t.memoizedState=y),r.props=i,r.state=y,r.context=l,i=c):(typeof r.componentDidUpdate!="function"||s===e.memoizedProps&&h===e.memoizedState||(t.flags|=4),typeof r.getSnapshotBeforeUpdate!="function"||s===e.memoizedProps&&h===e.memoizedState||(t.flags|=1024),i=!1)}return Wc(e,t,n,i,o,a)}function Wc(e,t,n,i,a,o){xy(e,t);var r=(t.flags&128)!==0;if(!i&&!r)return a&&Rp(t,n,!1),wn(e,t,o);i=t.stateNode,M0.current=t;var s=r&&typeof n.getDerivedStateFromError!="function"?null:i.render();return t.flags|=1,e!==null&&r?(t.child=sa(t,e.child,null,o),t.child=sa(t,null,s,o)):nt(e,t,s,o),t.memoizedState=i.state,a&&Rp(t,n,!0),t.child}function Ty(e){var t=e.stateNode;t.pendingContext?Bp(e,t.pendingContext,t.pendingContext!==t.context):t.context&&Bp(e,t.context,!1),Kd(e,t.containerInfo)}function Xp(e,t,n,i,a){return ra(),Gd(a),t.flags|=256,nt(e,t,n,i),t.child}var jc={dehydrated:null,treeContext:null,retryLane:0};function Mc(e){return{baseLanes:e,cachePool:null,transitions:null}}function ky(e,t,n){var i=t.pendingProps,a=Ce.current,o=!1,r=(t.flags&128)!==0,s;if((s=r)||(s=e!==null&&e.memoizedState===null?!1:(a&2)!==0),s?(o=!0,t.flags&=-129):(e===null||e.memoizedState!==null)&&(a|=1),ge(Ce,a&1),e===null)return Ec(t),e=t.memoizedState,e!==null&&(e=e.dehydrated,e!==null)?(t.mode&1?e.data==="$!"?t.lanes=8:t.lanes=1073741824:t.lanes=1,null):(r=i.children,e=i.fallback,o?(i=t.mode,o=t.child,r={mode:"hidden",children:r},!(i&1)&&o!==null?(o.childLanes=0,o.pendingProps=r):o=_s(r,i,0,null),e=gi(e,i,n,null),o.return=t,e.return=t,o.sibling=e,t.child=o,t.child.memoizedState=Mc(n),t.memoizedState=jc,e):au(t,r));if(a=e.memoizedState,a!==null&&(s=a.dehydrated,s!==null))return L0(e,t,r,i,s,a,n);if(o){o=i.fallback,r=t.mode,a=e.child,s=a.sibling;var l={mode:"hidden",children:i.children};return!(r&1)&&t.child!==a?(i=t.child,i.childLanes=0,i.pendingProps=l,t.deletions=null):(i=Vn(a,l),i.subtreeFlags=a.subtreeFlags&14680064),s!==null?o=Vn(s,o):(o=gi(o,r,n,null),o.flags|=2),o.return=t,i.return=t,i.sibling=o,t.child=i,i=o,o=t.child,r=e.child.memoizedState,r=r===null?Mc(n):{baseLanes:r.baseLanes|n,cachePool:null,transitions:r.transitions},o.memoizedState=r,o.childLanes=e.childLanes&~n,t.memoizedState=jc,i}return o=e.child,e=o.sibling,i=Vn(o,{mode:"visible",children:i.children}),!(t.mode&1)&&(i.lanes=n),i.return=t,i.sibling=null,e!==null&&(n=t.deletions,n===null?(t.deletions=[e],t.flags|=16):n.push(e)),t.child=i,t.memoizedState=null,i}function au(e,t){return t=_s({mode:"visible",children:t},e.mode,0,null),t.return=e,e.child=t}function er(e,t,n,i){return i!==null&&Gd(i),sa(t,e.child,null,n),e=au(t,t.pendingProps.children),e.flags|=2,t.memoizedState=null,e}function L0(e,t,n,i,a,o,r){if(n)return t.flags&256?(t.flags&=-257,i=Rl(Error(A(422))),er(e,t,r,i)):t.memoizedState!==null?(t.child=e.child,t.flags|=128,null):(o=i.fallback,a=t.mode,i=_s({mode:"visible",children:i.children},a,0,null),o=gi(o,a,r,null),o.flags|=2,i.return=t,o.return=t,i.sibling=o,t.child=i,t.mode&1&&sa(t,e.child,null,r),t.child.memoizedState=Mc(r),t.memoizedState=jc,o);if(!(t.mode&1))return er(e,t,r,null);if(a.data==="$!"){if(i=a.nextSibling&&a.nextSibling.dataset,i)var s=i.dgst;return i=s,o=Error(A(419)),i=Rl(o,i,void 0),er(e,t,r,i)}if(s=(r&e.childLanes)!==0,ct||s){if(i=Fe,i!==null){switch(r&-r){case 4:a=2;break;case 16:a=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:a=32;break;case 536870912:a=268435456;break;default:a=0}a=a&(i.suspendedLanes|r)?0:a,a!==0&&a!==o.retryLane&&(o.retryLane=a,vn(e,a),$t(i,e,a,-1))}return du(),i=Rl(Error(A(421))),er(e,t,r,i)}return a.data==="$?"?(t.flags|=128,t.child=e.child,t=e1.bind(null,e),a._reactRetry=t,null):(e=o.treeContext,_t=Fn(a.nextSibling),bt=t,ke=!0,Ft=null,e!==null&&(St[At++]=fn,St[At++]=hn,St[At++]=bi,fn=e.id,hn=e.overflow,bi=t),t=au(t,i.children),t.flags|=4096,t)}function Yp(e,t,n){e.lanes|=t;var i=e.alternate;i!==null&&(i.lanes|=t),Nc(e.return,t,n)}function Ol(e,t,n,i,a){var o=e.memoizedState;o===null?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:i,tail:n,tailMode:a}:(o.isBackwards=t,o.rendering=null,o.renderingStartTime=0,o.last=i,o.tail=n,o.tailMode=a)}function Iy(e,t,n){var i=t.pendingProps,a=i.revealOrder,o=i.tail;if(nt(e,t,i.children,n),i=Ce.current,i&2)i=i&1|2,t.flags|=128;else{if(e!==null&&e.flags&128)e:for(e=t.child;e!==null;){if(e.tag===13)e.memoizedState!==null&&Yp(e,n,t);else if(e.tag===19)Yp(e,n,t);else if(e.child!==null){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;e.sibling===null;){if(e.return===null||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}i&=1}if(ge(Ce,i),!(t.mode&1))t.memoizedState=null;else switch(a){case"forwards":for(n=t.child,a=null;n!==null;)e=n.alternate,e!==null&&Ur(e)===null&&(a=n),n=n.sibling;n=a,n===null?(a=t.child,t.child=null):(a=n.sibling,n.sibling=null),Ol(t,!1,a,n,o);break;case"backwards":for(n=null,a=t.child,t.child=null;a!==null;){if(e=a.alternate,e!==null&&Ur(e)===null){t.child=a;break}e=a.sibling,a.sibling=n,n=a,a=e}Ol(t,!0,n,null,o);break;case"together":Ol(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function gr(e,t){!(t.mode&1)&&e!==null&&(e.alternate=null,t.alternate=null,t.flags|=2)}function wn(e,t,n){if(e!==null&&(t.dependencies=e.dependencies),wi|=t.lanes,!(n&t.childLanes))return null;if(e!==null&&t.child!==e.child)throw Error(A(153));if(t.child!==null){for(e=t.child,n=Vn(e,e.pendingProps),t.child=n,n.return=t;e.sibling!==null;)e=e.sibling,n=n.sibling=Vn(e,e.pendingProps),n.return=t;n.sibling=null}return t.child}function F0(e,t,n){switch(t.tag){case 3:Ty(t),ra();break;case 5:Yh(t);break;case 1:ut(t.type)&&zr(t);break;case 4:Kd(t,t.stateNode.containerInfo);break;case 10:var i=t.type._context,a=t.memoizedProps.value;ge(Mr,i._currentValue),i._currentValue=a;break;case 13:if(i=t.memoizedState,i!==null)return i.dehydrated!==null?(ge(Ce,Ce.current&1),t.flags|=128,null):n&t.child.childLanes?ky(e,t,n):(ge(Ce,Ce.current&1),e=wn(e,t,n),e!==null?e.sibling:null);ge(Ce,Ce.current&1);break;case 19:if(i=(n&t.childLanes)!==0,e.flags&128){if(i)return Iy(e,t,n);t.flags|=128}if(a=t.memoizedState,a!==null&&(a.rendering=null,a.tail=null,a.lastEffect=null),ge(Ce,Ce.current),i)break;return null;case 22:case 23:return t.lanes=0,wy(e,t,n)}return wn(e,t,n)}var qy,Lc,Cy,Dy;qy=function(e,t){for(var n=t.child;n!==null;){if(n.tag===5||n.tag===6)e.appendChild(n.stateNode);else if(n.tag!==4&&n.child!==null){n.child.return=n,n=n.child;continue}if(n===t)break;for(;n.sibling===null;){if(n.return===null||n.return===t)return;n=n.return}n.sibling.return=n.return,n=n.sibling}};Lc=function(){};Cy=function(e,t,n,i){var a=e.memoizedProps;if(a!==i){e=t.stateNode,mi(an.current);var o=null;switch(n){case"input":a=cc(e,a),i=cc(e,i),o=[];break;case"select":a=Pe({},a,{value:void 0}),i=Pe({},i,{value:void 0}),o=[];break;case"textarea":a=pc(e,a),i=pc(e,i),o=[];break;default:typeof a.onClick!="function"&&typeof i.onClick=="function"&&(e.onclick=Rr)}fc(n,i);var r;n=null;for(c in a)if(!i.hasOwnProperty(c)&&a.hasOwnProperty(c)&&a[c]!=null)if(c==="style"){var s=a[c];for(r in s)s.hasOwnProperty(r)&&(n||(n={}),n[r]="")}else c!=="dangerouslySetInnerHTML"&&c!=="children"&&c!=="suppressContentEditableWarning"&&c!=="suppressHydrationWarning"&&c!=="autoFocus"&&(ao.hasOwnProperty(c)?o||(o=[]):(o=o||[]).push(c,null));for(c in i){var l=i[c];if(s=a!=null?a[c]:void 0,i.hasOwnProperty(c)&&l!==s&&(l!=null||s!=null))if(c==="style")if(s){for(r in s)!s.hasOwnProperty(r)||l&&l.hasOwnProperty(r)||(n||(n={}),n[r]="");for(r in l)l.hasOwnProperty(r)&&s[r]!==l[r]&&(n||(n={}),n[r]=l[r])}else n||(o||(o=[]),o.push(c,n)),n=l;else c==="dangerouslySetInnerHTML"?(l=l?l.__html:void 0,s=s?s.__html:void 0,l!=null&&s!==l&&(o=o||[]).push(c,l)):c==="children"?typeof l!="string"&&typeof l!="number"||(o=o||[]).push(c,""+l):c!=="suppressContentEditableWarning"&&c!=="suppressHydrationWarning"&&(ao.hasOwnProperty(c)?(l!=null&&c==="onScroll"&&_e("scroll",e),o||s===l||(o=[])):(o=o||[]).push(c,l))}n&&(o=o||[]).push("style",n);var c=o;(t.updateQueue=c)&&(t.flags|=4)}};Dy=function(e,t,n,i){n!==i&&(t.flags|=4)};function Sa(e,t){if(!ke)switch(e.tailMode){case"hidden":t=e.tail;for(var n=null;t!==null;)t.alternate!==null&&(n=t),t=t.sibling;n===null?e.tail=null:n.sibling=null;break;case"collapsed":n=e.tail;for(var i=null;n!==null;)n.alternate!==null&&(i=n),n=n.sibling;i===null?t||e.tail===null?e.tail=null:e.tail.sibling=null:i.sibling=null}}function Ye(e){var t=e.alternate!==null&&e.alternate.child===e.child,n=0,i=0;if(t)for(var a=e.child;a!==null;)n|=a.lanes|a.childLanes,i|=a.subtreeFlags&14680064,i|=a.flags&14680064,a.return=e,a=a.sibling;else for(a=e.child;a!==null;)n|=a.lanes|a.childLanes,i|=a.subtreeFlags,i|=a.flags,a.return=e,a=a.sibling;return e.subtreeFlags|=i,e.childLanes=n,t}function U0(e,t,n){var i=t.pendingProps;switch(Ud(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return Ye(t),null;case 1:return ut(t.type)&&Or(),Ye(t),null;case 3:return i=t.stateNode,la(),be(dt),be(tt),Yd(),i.pendingContext&&(i.context=i.pendingContext,i.pendingContext=null),(e===null||e.child===null)&&(Yo(t)?t.flags|=4:e===null||e.memoizedState.isDehydrated&&!(t.flags&256)||(t.flags|=1024,Ft!==null&&(Qc(Ft),Ft=null))),Lc(e,t),Ye(t),null;case 5:Xd(t);var a=mi(go.current);if(n=t.type,e!==null&&t.stateNode!=null)Cy(e,t,n,i,a),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!i){if(t.stateNode===null)throw Error(A(166));return Ye(t),null}if(e=mi(an.current),Yo(t)){i=t.stateNode,n=t.type;var o=t.memoizedProps;switch(i[Jt]=t,i[ho]=o,e=(t.mode&1)!==0,n){case"dialog":_e("cancel",i),_e("close",i);break;case"iframe":case"object":case"embed":_e("load",i);break;case"video":case"audio":for(a=0;a<Ua.length;a++)_e(Ua[a],i);break;case"source":_e("error",i);break;case"img":case"image":case"link":_e("error",i),_e("load",i);break;case"details":_e("toggle",i);break;case"input":sp(i,o),_e("invalid",i);break;case"select":i._wrapperState={wasMultiple:!!o.multiple},_e("invalid",i);break;case"textarea":cp(i,o),_e("invalid",i)}fc(n,o),a=null;for(var r in o)if(o.hasOwnProperty(r)){var s=o[r];r==="children"?typeof s=="string"?i.textContent!==s&&(o.suppressHydrationWarning!==!0&&Xo(i.textContent,s,e),a=["children",s]):typeof s=="number"&&i.textContent!==""+s&&(o.suppressHydrationWarning!==!0&&Xo(i.textContent,s,e),a=["children",""+s]):ao.hasOwnProperty(r)&&s!=null&&r==="onScroll"&&_e("scroll",i)}switch(n){case"input":Uo(i),lp(i,o,!0);break;case"textarea":Uo(i),dp(i);break;case"select":case"option":break;default:typeof o.onClick=="function"&&(i.onclick=Rr)}i=a,t.updateQueue=i,i!==null&&(t.flags|=4)}else{r=a.nodeType===9?a:a.ownerDocument,e==="http://www.w3.org/1999/xhtml"&&(e=th(n)),e==="http://www.w3.org/1999/xhtml"?n==="script"?(e=r.createElement("div"),e.innerHTML="<script><\/script>",e=e.removeChild(e.firstChild)):typeof i.is=="string"?e=r.createElement(n,{is:i.is}):(e=r.createElement(n),n==="select"&&(r=e,i.multiple?r.multiple=!0:i.size&&(r.size=i.size))):e=r.createElementNS(e,n),e[Jt]=t,e[ho]=i,qy(e,t,!1,!1),t.stateNode=e;e:{switch(r=hc(n,i),n){case"dialog":_e("cancel",e),_e("close",e),a=i;break;case"iframe":case"object":case"embed":_e("load",e),a=i;break;case"video":case"audio":for(a=0;a<Ua.length;a++)_e(Ua[a],e);a=i;break;case"source":_e("error",e),a=i;break;case"img":case"image":case"link":_e("error",e),_e("load",e),a=i;break;case"details":_e("toggle",e),a=i;break;case"input":sp(e,i),a=cc(e,i),_e("invalid",e);break;case"option":a=i;break;case"select":e._wrapperState={wasMultiple:!!i.multiple},a=Pe({},i,{value:void 0}),_e("invalid",e);break;case"textarea":cp(e,i),a=pc(e,i),_e("invalid",e);break;default:a=i}fc(n,a),s=a;for(o in s)if(s.hasOwnProperty(o)){var l=s[o];o==="style"?ah(e,l):o==="dangerouslySetInnerHTML"?(l=l?l.__html:void 0,l!=null&&nh(e,l)):o==="children"?typeof l=="string"?(n!=="textarea"||l!=="")&&oo(e,l):typeof l=="number"&&oo(e,""+l):o!=="suppressContentEditableWarning"&&o!=="suppressHydrationWarning"&&o!=="autoFocus"&&(ao.hasOwnProperty(o)?l!=null&&o==="onScroll"&&_e("scroll",e):l!=null&&Dd(e,o,l,r))}switch(n){case"input":Uo(e),lp(e,i,!1);break;case"textarea":Uo(e),dp(e);break;case"option":i.value!=null&&e.setAttribute("value",""+Zn(i.value));break;case"select":e.multiple=!!i.multiple,o=i.value,o!=null?Ki(e,!!i.multiple,o,!1):i.defaultValue!=null&&Ki(e,!!i.multiple,i.defaultValue,!0);break;default:typeof a.onClick=="function"&&(e.onclick=Rr)}switch(n){case"button":case"input":case"select":case"textarea":i=!!i.autoFocus;break e;case"img":i=!0;break e;default:i=!1}}i&&(t.flags|=4)}t.ref!==null&&(t.flags|=512,t.flags|=2097152)}return Ye(t),null;case 6:if(e&&t.stateNode!=null)Dy(e,t,e.memoizedProps,i);else{if(typeof i!="string"&&t.stateNode===null)throw Error(A(166));if(n=mi(go.current),mi(an.current),Yo(t)){if(i=t.stateNode,n=t.memoizedProps,i[Jt]=t,(o=i.nodeValue!==n)&&(e=bt,e!==null))switch(e.tag){case 3:Xo(i.nodeValue,n,(e.mode&1)!==0);break;case 5:e.memoizedProps.suppressHydrationWarning!==!0&&Xo(i.nodeValue,n,(e.mode&1)!==0)}o&&(t.flags|=4)}else i=(n.nodeType===9?n:n.ownerDocument).createTextNode(i),i[Jt]=t,t.stateNode=i}return Ye(t),null;case 13:if(be(Ce),i=t.memoizedState,e===null||e.memoizedState!==null&&e.memoizedState.dehydrated!==null){if(ke&&_t!==null&&t.mode&1&&!(t.flags&128))$h(),ra(),t.flags|=98560,o=!1;else if(o=Yo(t),i!==null&&i.dehydrated!==null){if(e===null){if(!o)throw Error(A(318));if(o=t.memoizedState,o=o!==null?o.dehydrated:null,!o)throw Error(A(317));o[Jt]=t}else ra(),!(t.flags&128)&&(t.memoizedState=null),t.flags|=4;Ye(t),o=!1}else Ft!==null&&(Qc(Ft),Ft=null),o=!0;if(!o)return t.flags&65536?t:null}return t.flags&128?(t.lanes=n,t):(i=i!==null,i!==(e!==null&&e.memoizedState!==null)&&i&&(t.child.flags|=8192,t.mode&1&&(e===null||Ce.current&1?Me===0&&(Me=3):du())),t.updateQueue!==null&&(t.flags|=4),Ye(t),null);case 4:return la(),Lc(e,t),e===null&&mo(t.stateNode.containerInfo),Ye(t),null;case 10:return Hd(t.type._context),Ye(t),null;case 17:return ut(t.type)&&Or(),Ye(t),null;case 19:if(be(Ce),o=t.memoizedState,o===null)return Ye(t),null;if(i=(t.flags&128)!==0,r=o.rendering,r===null)if(i)Sa(o,!1);else{if(Me!==0||e!==null&&e.flags&128)for(e=t.child;e!==null;){if(r=Ur(e),r!==null){for(t.flags|=128,Sa(o,!1),i=r.updateQueue,i!==null&&(t.updateQueue=i,t.flags|=4),t.subtreeFlags=0,i=n,n=t.child;n!==null;)o=n,e=i,o.flags&=14680066,r=o.alternate,r===null?(o.childLanes=0,o.lanes=e,o.child=null,o.subtreeFlags=0,o.memoizedProps=null,o.memoizedState=null,o.updateQueue=null,o.dependencies=null,o.stateNode=null):(o.childLanes=r.childLanes,o.lanes=r.lanes,o.child=r.child,o.subtreeFlags=0,o.deletions=null,o.memoizedProps=r.memoizedProps,o.memoizedState=r.memoizedState,o.updateQueue=r.updateQueue,o.type=r.type,e=r.dependencies,o.dependencies=e===null?null:{lanes:e.lanes,firstContext:e.firstContext}),n=n.sibling;return ge(Ce,Ce.current&1|2),t.child}e=e.sibling}o.tail!==null&&Re()>da&&(t.flags|=128,i=!0,Sa(o,!1),t.lanes=4194304)}else{if(!i)if(e=Ur(r),e!==null){if(t.flags|=128,i=!0,n=e.updateQueue,n!==null&&(t.updateQueue=n,t.flags|=4),Sa(o,!0),o.tail===null&&o.tailMode==="hidden"&&!r.alternate&&!ke)return Ye(t),null}else 2*Re()-o.renderingStartTime>da&&n!==1073741824&&(t.flags|=128,i=!0,Sa(o,!1),t.lanes=4194304);o.isBackwards?(r.sibling=t.child,t.child=r):(n=o.last,n!==null?n.sibling=r:t.child=r,o.last=r)}return o.tail!==null?(t=o.tail,o.rendering=t,o.tail=t.sibling,o.renderingStartTime=Re(),t.sibling=null,n=Ce.current,ge(Ce,i?n&1|2:n&1),t):(Ye(t),null);case 22:case 23:return cu(),i=t.memoizedState!==null,e!==null&&e.memoizedState!==null!==i&&(t.flags|=8192),i&&t.mode&1?ht&1073741824&&(Ye(t),t.subtreeFlags&6&&(t.flags|=8192)):Ye(t),null;case 24:return null;case 25:return null}throw Error(A(156,t.tag))}function G0(e,t){switch(Ud(t),t.tag){case 1:return ut(t.type)&&Or(),e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 3:return la(),be(dt),be(tt),Yd(),e=t.flags,e&65536&&!(e&128)?(t.flags=e&-65537|128,t):null;case 5:return Xd(t),null;case 13:if(be(Ce),e=t.memoizedState,e!==null&&e.dehydrated!==null){if(t.alternate===null)throw Error(A(340));ra()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 19:return be(Ce),null;case 4:return la(),null;case 10:return Hd(t.type._context),null;case 22:case 23:return cu(),null;case 24:return null;default:return null}}var tr=!1,et=!1,$0=typeof WeakSet=="function"?WeakSet:Set,j=null;function Zi(e,t){var n=e.ref;if(n!==null)if(typeof n=="function")try{n(null)}catch(i){Ee(e,t,i)}else n.current=null}function Fc(e,t,n){try{n()}catch(i){Ee(e,t,i)}}var Jp=!1;function V0(e,t){if(Ic=Er,e=Eh(),Ld(e)){if("selectionStart"in e)var n={start:e.selectionStart,end:e.selectionEnd};else e:{n=(n=e.ownerDocument)&&n.defaultView||window;var i=n.getSelection&&n.getSelection();if(i&&i.rangeCount!==0){n=i.anchorNode;var a=i.anchorOffset,o=i.focusNode;i=i.focusOffset;try{n.nodeType,o.nodeType}catch{n=null;break e}var r=0,s=-1,l=-1,c=0,d=0,f=e,h=null;t:for(;;){for(var u;f!==n||a!==0&&f.nodeType!==3||(s=r+a),f!==o||i!==0&&f.nodeType!==3||(l=r+i),f.nodeType===3&&(r+=f.nodeValue.length),(u=f.firstChild)!==null;)h=f,f=u;for(;;){if(f===e)break t;if(h===n&&++c===a&&(s=r),h===o&&++d===i&&(l=r),(u=f.nextSibling)!==null)break;f=h,h=f.parentNode}f=u}n=s===-1||l===-1?null:{start:s,end:l}}else n=null}n=n||{start:0,end:0}}else n=null;for(qc={focusedElem:e,selectionRange:n},Er=!1,j=t;j!==null;)if(t=j,e=t.child,(t.subtreeFlags&1028)!==0&&e!==null)e.return=t,j=e;else for(;j!==null;){t=j;try{var y=t.alternate;if(t.flags&1024)switch(t.tag){case 0:case 11:case 15:break;case 1:if(y!==null){var m=y.memoizedProps,k=y.memoizedState,_=t.stateNode,g=_.getSnapshotBeforeUpdate(t.elementType===t.type?m:Mt(t.type,m),k);_.__reactInternalSnapshotBeforeUpdate=g}break;case 3:var b=t.stateNode.containerInfo;b.nodeType===1?b.textContent="":b.nodeType===9&&b.documentElement&&b.removeChild(b.documentElement);break;case 5:case 6:case 4:case 17:break;default:throw Error(A(163))}}catch(w){Ee(t,t.return,w)}if(e=t.sibling,e!==null){e.return=t.return,j=e;break}j=t.return}return y=Jp,Jp=!1,y}function Xa(e,t,n){var i=t.updateQueue;if(i=i!==null?i.lastEffect:null,i!==null){var a=i=i.next;do{if((a.tag&e)===e){var o=a.destroy;a.destroy=void 0,o!==void 0&&Fc(t,n,o)}a=a.next}while(a!==i)}}function ys(e,t){if(t=t.updateQueue,t=t!==null?t.lastEffect:null,t!==null){var n=t=t.next;do{if((n.tag&e)===e){var i=n.create;n.destroy=i()}n=n.next}while(n!==t)}}function Uc(e){var t=e.ref;if(t!==null){var n=e.stateNode;switch(e.tag){case 5:e=n;break;default:e=n}typeof t=="function"?t(e):t.current=e}}function Py(e){var t=e.alternate;t!==null&&(e.alternate=null,Py(t)),e.child=null,e.deletions=null,e.sibling=null,e.tag===5&&(t=e.stateNode,t!==null&&(delete t[Jt],delete t[ho],delete t[Pc],delete t[D0],delete t[P0])),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function Sy(e){return e.tag===5||e.tag===3||e.tag===4}function em(e){e:for(;;){for(;e.sibling===null;){if(e.return===null||Sy(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;e.tag!==5&&e.tag!==6&&e.tag!==18;){if(e.flags&2||e.child===null||e.tag===4)continue e;e.child.return=e,e=e.child}if(!(e.flags&2))return e.stateNode}}function Gc(e,t,n){var i=e.tag;if(i===5||i===6)e=e.stateNode,t?n.nodeType===8?n.parentNode.insertBefore(e,t):n.insertBefore(e,t):(n.nodeType===8?(t=n.parentNode,t.insertBefore(e,n)):(t=n,t.appendChild(e)),n=n._reactRootContainer,n!=null||t.onclick!==null||(t.onclick=Rr));else if(i!==4&&(e=e.child,e!==null))for(Gc(e,t,n),e=e.sibling;e!==null;)Gc(e,t,n),e=e.sibling}function $c(e,t,n){var i=e.tag;if(i===5||i===6)e=e.stateNode,t?n.insertBefore(e,t):n.appendChild(e);else if(i!==4&&(e=e.child,e!==null))for($c(e,t,n),e=e.sibling;e!==null;)$c(e,t,n),e=e.sibling}var Ve=null,Lt=!1;function Dn(e,t,n){for(n=n.child;n!==null;)Ay(e,t,n),n=n.sibling}function Ay(e,t,n){if(nn&&typeof nn.onCommitFiberUnmount=="function")try{nn.onCommitFiberUnmount(ls,n)}catch{}switch(n.tag){case 5:et||Zi(n,t);case 6:var i=Ve,a=Lt;Ve=null,Dn(e,t,n),Ve=i,Lt=a,Ve!==null&&(Lt?(e=Ve,n=n.stateNode,e.nodeType===8?e.parentNode.removeChild(n):e.removeChild(n)):Ve.removeChild(n.stateNode));break;case 18:Ve!==null&&(Lt?(e=Ve,n=n.stateNode,e.nodeType===8?Pl(e.parentNode,n):e.nodeType===1&&Pl(e,n),co(e)):Pl(Ve,n.stateNode));break;case 4:i=Ve,a=Lt,Ve=n.stateNode.containerInfo,Lt=!0,Dn(e,t,n),Ve=i,Lt=a;break;case 0:case 11:case 14:case 15:if(!et&&(i=n.updateQueue,i!==null&&(i=i.lastEffect,i!==null))){a=i=i.next;do{var o=a,r=o.destroy;o=o.tag,r!==void 0&&(o&2||o&4)&&Fc(n,t,r),a=a.next}while(a!==i)}Dn(e,t,n);break;case 1:if(!et&&(Zi(n,t),i=n.stateNode,typeof i.componentWillUnmount=="function"))try{i.props=n.memoizedProps,i.state=n.memoizedState,i.componentWillUnmount()}catch(s){Ee(n,t,s)}Dn(e,t,n);break;case 21:Dn(e,t,n);break;case 22:n.mode&1?(et=(i=et)||n.memoizedState!==null,Dn(e,t,n),et=i):Dn(e,t,n);break;default:Dn(e,t,n)}}function tm(e){var t=e.updateQueue;if(t!==null){e.updateQueue=null;var n=e.stateNode;n===null&&(n=e.stateNode=new $0),t.forEach(function(i){var a=t1.bind(null,e,i);n.has(i)||(n.add(i),i.then(a,a))})}}function jt(e,t){var n=t.deletions;if(n!==null)for(var i=0;i<n.length;i++){var a=n[i];try{var o=e,r=t,s=r;e:for(;s!==null;){switch(s.tag){case 5:Ve=s.stateNode,Lt=!1;break e;case 3:Ve=s.stateNode.containerInfo,Lt=!0;break e;case 4:Ve=s.stateNode.containerInfo,Lt=!0;break e}s=s.return}if(Ve===null)throw Error(A(160));Ay(o,r,a),Ve=null,Lt=!1;var l=a.alternate;l!==null&&(l.return=null),a.return=null}catch(c){Ee(a,t,c)}}if(t.subtreeFlags&12854)for(t=t.child;t!==null;)Ey(t,e),t=t.sibling}function Ey(e,t){var n=e.alternate,i=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(jt(t,e),Qt(e),i&4){try{Xa(3,e,e.return),ys(3,e)}catch(m){Ee(e,e.return,m)}try{Xa(5,e,e.return)}catch(m){Ee(e,e.return,m)}}break;case 1:jt(t,e),Qt(e),i&512&&n!==null&&Zi(n,n.return);break;case 5:if(jt(t,e),Qt(e),i&512&&n!==null&&Zi(n,n.return),e.flags&32){var a=e.stateNode;try{oo(a,"")}catch(m){Ee(e,e.return,m)}}if(i&4&&(a=e.stateNode,a!=null)){var o=e.memoizedProps,r=n!==null?n.memoizedProps:o,s=e.type,l=e.updateQueue;if(e.updateQueue=null,l!==null)try{s==="input"&&o.type==="radio"&&o.name!=null&&Jf(a,o),hc(s,r);var c=hc(s,o);for(r=0;r<l.length;r+=2){var d=l[r],f=l[r+1];d==="style"?ah(a,f):d==="dangerouslySetInnerHTML"?nh(a,f):d==="children"?oo(a,f):Dd(a,d,f,c)}switch(s){case"input":dc(a,o);break;case"textarea":eh(a,o);break;case"select":var h=a._wrapperState.wasMultiple;a._wrapperState.wasMultiple=!!o.multiple;var u=o.value;u!=null?Ki(a,!!o.multiple,u,!1):h!==!!o.multiple&&(o.defaultValue!=null?Ki(a,!!o.multiple,o.defaultValue,!0):Ki(a,!!o.multiple,o.multiple?[]:"",!1))}a[ho]=o}catch(m){Ee(e,e.return,m)}}break;case 6:if(jt(t,e),Qt(e),i&4){if(e.stateNode===null)throw Error(A(162));a=e.stateNode,o=e.memoizedProps;try{a.nodeValue=o}catch(m){Ee(e,e.return,m)}}break;case 3:if(jt(t,e),Qt(e),i&4&&n!==null&&n.memoizedState.isDehydrated)try{co(t.containerInfo)}catch(m){Ee(e,e.return,m)}break;case 4:jt(t,e),Qt(e);break;case 13:jt(t,e),Qt(e),a=e.child,a.flags&8192&&(o=a.memoizedState!==null,a.stateNode.isHidden=o,!o||a.alternate!==null&&a.alternate.memoizedState!==null||(su=Re())),i&4&&tm(e);break;case 22:if(d=n!==null&&n.memoizedState!==null,e.mode&1?(et=(c=et)||d,jt(t,e),et=c):jt(t,e),Qt(e),i&8192){if(c=e.memoizedState!==null,(e.stateNode.isHidden=c)&&!d&&e.mode&1)for(j=e,d=e.child;d!==null;){for(f=j=d;j!==null;){switch(h=j,u=h.child,h.tag){case 0:case 11:case 14:case 15:Xa(4,h,h.return);break;case 1:Zi(h,h.return);var y=h.stateNode;if(typeof y.componentWillUnmount=="function"){i=h,n=h.return;try{t=i,y.props=t.memoizedProps,y.state=t.memoizedState,y.componentWillUnmount()}catch(m){Ee(i,n,m)}}break;case 5:Zi(h,h.return);break;case 22:if(h.memoizedState!==null){im(f);continue}}u!==null?(u.return=h,j=u):im(f)}d=d.sibling}e:for(d=null,f=e;;){if(f.tag===5){if(d===null){d=f;try{a=f.stateNode,c?(o=a.style,typeof o.setProperty=="function"?o.setProperty("display","none","important"):o.display="none"):(s=f.stateNode,l=f.memoizedProps.style,r=l!=null&&l.hasOwnProperty("display")?l.display:null,s.style.display=ih("display",r))}catch(m){Ee(e,e.return,m)}}}else if(f.tag===6){if(d===null)try{f.stateNode.nodeValue=c?"":f.memoizedProps}catch(m){Ee(e,e.return,m)}}else if((f.tag!==22&&f.tag!==23||f.memoizedState===null||f===e)&&f.child!==null){f.child.return=f,f=f.child;continue}if(f===e)break e;for(;f.sibling===null;){if(f.return===null||f.return===e)break e;d===f&&(d=null),f=f.return}d===f&&(d=null),f.sibling.return=f.return,f=f.sibling}}break;case 19:jt(t,e),Qt(e),i&4&&tm(e);break;case 21:break;default:jt(t,e),Qt(e)}}function Qt(e){var t=e.flags;if(t&2){try{e:{for(var n=e.return;n!==null;){if(Sy(n)){var i=n;break e}n=n.return}throw Error(A(160))}switch(i.tag){case 5:var a=i.stateNode;i.flags&32&&(oo(a,""),i.flags&=-33);var o=em(e);$c(e,o,a);break;case 3:case 4:var r=i.stateNode.containerInfo,s=em(e);Gc(e,s,r);break;default:throw Error(A(161))}}catch(l){Ee(e,e.return,l)}e.flags&=-3}t&4096&&(e.flags&=-4097)}function H0(e,t,n){j=e,Ny(e)}function Ny(e,t,n){for(var i=(e.mode&1)!==0;j!==null;){var a=j,o=a.child;if(a.tag===22&&i){var r=a.memoizedState!==null||tr;if(!r){var s=a.alternate,l=s!==null&&s.memoizedState!==null||et;s=tr;var c=et;if(tr=r,(et=l)&&!c)for(j=a;j!==null;)r=j,l=r.child,r.tag===22&&r.memoizedState!==null?am(a):l!==null?(l.return=r,j=l):am(a);for(;o!==null;)j=o,Ny(o),o=o.sibling;j=a,tr=s,et=c}nm(e)}else a.subtreeFlags&8772&&o!==null?(o.return=a,j=o):nm(e)}}function nm(e){for(;j!==null;){var t=j;if(t.flags&8772){var n=t.alternate;try{if(t.flags&8772)switch(t.tag){case 0:case 11:case 15:et||ys(5,t);break;case 1:var i=t.stateNode;if(t.flags&4&&!et)if(n===null)i.componentDidMount();else{var a=t.elementType===t.type?n.memoizedProps:Mt(t.type,n.memoizedProps);i.componentDidUpdate(a,n.memoizedState,i.__reactInternalSnapshotBeforeUpdate)}var o=t.updateQueue;o!==null&&jp(t,o,i);break;case 3:var r=t.updateQueue;if(r!==null){if(n=null,t.child!==null)switch(t.child.tag){case 5:n=t.child.stateNode;break;case 1:n=t.child.stateNode}jp(t,r,n)}break;case 5:var s=t.stateNode;if(n===null&&t.flags&4){n=s;var l=t.memoizedProps;switch(t.type){case"button":case"input":case"select":case"textarea":l.autoFocus&&n.focus();break;case"img":l.src&&(n.src=l.src)}}break;case 6:break;case 4:break;case 12:break;case 13:if(t.memoizedState===null){var c=t.alternate;if(c!==null){var d=c.memoizedState;if(d!==null){var f=d.dehydrated;f!==null&&co(f)}}}break;case 19:case 17:case 21:case 22:case 23:case 25:break;default:throw Error(A(163))}et||t.flags&512&&Uc(t)}catch(h){Ee(t,t.return,h)}}if(t===e){j=null;break}if(n=t.sibling,n!==null){n.return=t.return,j=n;break}j=t.return}}function im(e){for(;j!==null;){var t=j;if(t===e){j=null;break}var n=t.sibling;if(n!==null){n.return=t.return,j=n;break}j=t.return}}function am(e){for(;j!==null;){var t=j;try{switch(t.tag){case 0:case 11:case 15:var n=t.return;try{ys(4,t)}catch(l){Ee(t,n,l)}break;case 1:var i=t.stateNode;if(typeof i.componentDidMount=="function"){var a=t.return;try{i.componentDidMount()}catch(l){Ee(t,a,l)}}var o=t.return;try{Uc(t)}catch(l){Ee(t,o,l)}break;case 5:var r=t.return;try{Uc(t)}catch(l){Ee(t,r,l)}}}catch(l){Ee(t,t.return,l)}if(t===e){j=null;break}var s=t.sibling;if(s!==null){s.return=t.return,j=s;break}j=t.return}}var Z0=Math.ceil,Vr=kn.ReactCurrentDispatcher,ou=kn.ReactCurrentOwner,Nt=kn.ReactCurrentBatchConfig,te=0,Fe=null,ze=null,Ze=0,ht=0,Qi=Jn(0),Me=0,wo=null,wi=0,gs=0,ru=0,Ya=null,lt=null,su=0,da=1/0,pn=null,Hr=!1,Vc=null,Gn=null,nr=!1,zn=null,Zr=0,Ja=0,Hc=null,_r=-1,br=0;function it(){return te&6?Re():_r!==-1?_r:_r=Re()}function $n(e){return e.mode&1?te&2&&Ze!==0?Ze&-Ze:A0.transition!==null?(br===0&&(br=yh()),br):(e=le,e!==0||(e=window.event,e=e===void 0?16:Th(e.type)),e):1}function $t(e,t,n,i){if(50<Ja)throw Ja=0,Hc=null,Error(A(185));Do(e,n,i),(!(te&2)||e!==Fe)&&(e===Fe&&(!(te&2)&&(gs|=n),Me===4&&Rn(e,Ze)),pt(e,i),n===1&&te===0&&!(t.mode&1)&&(da=Re()+500,ms&&ei()))}function pt(e,t){var n=e.callbackNode;Ab(e,t);var i=Ar(e,e===Fe?Ze:0);if(i===0)n!==null&&mp(n),e.callbackNode=null,e.callbackPriority=0;else if(t=i&-i,e.callbackPriority!==t){if(n!=null&&mp(n),t===1)e.tag===0?S0(om.bind(null,e)):Fh(om.bind(null,e)),q0(function(){!(te&6)&&ei()}),n=null;else{switch(gh(i)){case 1:n=Nd;break;case 4:n=fh;break;case 16:n=Sr;break;case 536870912:n=hh;break;default:n=Sr}n=Ly(n,By.bind(null,e))}e.callbackPriority=t,e.callbackNode=n}}function By(e,t){if(_r=-1,br=0,te&6)throw Error(A(327));var n=e.callbackNode;if(ta()&&e.callbackNode!==n)return null;var i=Ar(e,e===Fe?Ze:0);if(i===0)return null;if(i&30||i&e.expiredLanes||t)t=Qr(e,i);else{t=i;var a=te;te|=2;var o=Oy();(Fe!==e||Ze!==t)&&(pn=null,da=Re()+500,yi(e,t));do try{X0();break}catch(s){Ry(e,s)}while(1);Vd(),Vr.current=o,te=a,ze!==null?t=0:(Fe=null,Ze=0,t=Me)}if(t!==0){if(t===2&&(a=vc(e),a!==0&&(i=a,t=Zc(e,a))),t===1)throw n=wo,yi(e,0),Rn(e,i),pt(e,Re()),n;if(t===6)Rn(e,i);else{if(a=e.current.alternate,!(i&30)&&!Q0(a)&&(t=Qr(e,i),t===2&&(o=vc(e),o!==0&&(i=o,t=Zc(e,o))),t===1))throw n=wo,yi(e,0),Rn(e,i),pt(e,Re()),n;switch(e.finishedWork=a,e.finishedLanes=i,t){case 0:case 1:throw Error(A(345));case 2:oi(e,lt,pn);break;case 3:if(Rn(e,i),(i&130023424)===i&&(t=su+500-Re(),10<t)){if(Ar(e,0)!==0)break;if(a=e.suspendedLanes,(a&i)!==i){it(),e.pingedLanes|=e.suspendedLanes&a;break}e.timeoutHandle=Dc(oi.bind(null,e,lt,pn),t);break}oi(e,lt,pn);break;case 4:if(Rn(e,i),(i&4194240)===i)break;for(t=e.eventTimes,a=-1;0<i;){var r=31-Gt(i);o=1<<r,r=t[r],r>a&&(a=r),i&=~o}if(i=a,i=Re()-i,i=(120>i?120:480>i?480:1080>i?1080:1920>i?1920:3e3>i?3e3:4320>i?4320:1960*Z0(i/1960))-i,10<i){e.timeoutHandle=Dc(oi.bind(null,e,lt,pn),i);break}oi(e,lt,pn);break;case 5:oi(e,lt,pn);break;default:throw Error(A(329))}}}return pt(e,Re()),e.callbackNode===n?By.bind(null,e):null}function Zc(e,t){var n=Ya;return e.current.memoizedState.isDehydrated&&(yi(e,t).flags|=256),e=Qr(e,t),e!==2&&(t=lt,lt=n,t!==null&&Qc(t)),e}function Qc(e){lt===null?lt=e:lt.push.apply(lt,e)}function Q0(e){for(var t=e;;){if(t.flags&16384){var n=t.updateQueue;if(n!==null&&(n=n.stores,n!==null))for(var i=0;i<n.length;i++){var a=n[i],o=a.getSnapshot;a=a.value;try{if(!Vt(o(),a))return!1}catch{return!1}}}if(n=t.child,t.subtreeFlags&16384&&n!==null)n.return=t,t=n;else{if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}function Rn(e,t){for(t&=~ru,t&=~gs,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var n=31-Gt(t),i=1<<n;e[n]=-1,t&=~i}}function om(e){if(te&6)throw Error(A(327));ta();var t=Ar(e,0);if(!(t&1))return pt(e,Re()),null;var n=Qr(e,t);if(e.tag!==0&&n===2){var i=vc(e);i!==0&&(t=i,n=Zc(e,i))}if(n===1)throw n=wo,yi(e,0),Rn(e,t),pt(e,Re()),n;if(n===6)throw Error(A(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,oi(e,lt,pn),pt(e,Re()),null}function lu(e,t){var n=te;te|=1;try{return e(t)}finally{te=n,te===0&&(da=Re()+500,ms&&ei())}}function xi(e){zn!==null&&zn.tag===0&&!(te&6)&&ta();var t=te;te|=1;var n=Nt.transition,i=le;try{if(Nt.transition=null,le=1,e)return e()}finally{le=i,Nt.transition=n,te=t,!(te&6)&&ei()}}function cu(){ht=Qi.current,be(Qi)}function yi(e,t){e.finishedWork=null,e.finishedLanes=0;var n=e.timeoutHandle;if(n!==-1&&(e.timeoutHandle=-1,I0(n)),ze!==null)for(n=ze.return;n!==null;){var i=n;switch(Ud(i),i.tag){case 1:i=i.type.childContextTypes,i!=null&&Or();break;case 3:la(),be(dt),be(tt),Yd();break;case 5:Xd(i);break;case 4:la();break;case 13:be(Ce);break;case 19:be(Ce);break;case 10:Hd(i.type._context);break;case 22:case 23:cu()}n=n.return}if(Fe=e,ze=e=Vn(e.current,null),Ze=ht=t,Me=0,wo=null,ru=gs=wi=0,lt=Ya=null,pi!==null){for(t=0;t<pi.length;t++)if(n=pi[t],i=n.interleaved,i!==null){n.interleaved=null;var a=i.next,o=n.pending;if(o!==null){var r=o.next;o.next=a,i.next=r}n.pending=i}pi=null}return e}function Ry(e,t){do{var n=ze;try{if(Vd(),hr.current=$r,Gr){for(var i=De.memoizedState;i!==null;){var a=i.queue;a!==null&&(a.pending=null),i=i.next}Gr=!1}if(vi=0,Le=je=De=null,Ka=!1,_o=0,ou.current=null,n===null||n.return===null){Me=1,wo=t,ze=null;break}e:{var o=e,r=n.return,s=n,l=t;if(t=Ze,s.flags|=32768,l!==null&&typeof l=="object"&&typeof l.then=="function"){var c=l,d=s,f=d.tag;if(!(d.mode&1)&&(f===0||f===11||f===15)){var h=d.alternate;h?(d.updateQueue=h.updateQueue,d.memoizedState=h.memoizedState,d.lanes=h.lanes):(d.updateQueue=null,d.memoizedState=null)}var u=Vp(r);if(u!==null){u.flags&=-257,Hp(u,r,s,o,t),u.mode&1&&$p(o,c,t),t=u,l=c;var y=t.updateQueue;if(y===null){var m=new Set;m.add(l),t.updateQueue=m}else y.add(l);break e}else{if(!(t&1)){$p(o,c,t),du();break e}l=Error(A(426))}}else if(ke&&s.mode&1){var k=Vp(r);if(k!==null){!(k.flags&65536)&&(k.flags|=256),Hp(k,r,s,o,t),Gd(ca(l,s));break e}}o=l=ca(l,s),Me!==4&&(Me=2),Ya===null?Ya=[o]:Ya.push(o),o=r;do{switch(o.tag){case 3:o.flags|=65536,t&=-t,o.lanes|=t;var _=_y(o,l,t);Wp(o,_);break e;case 1:s=l;var g=o.type,b=o.stateNode;if(!(o.flags&128)&&(typeof g.getDerivedStateFromError=="function"||b!==null&&typeof b.componentDidCatch=="function"&&(Gn===null||!Gn.has(b)))){o.flags|=65536,t&=-t,o.lanes|=t;var w=by(o,s,t);Wp(o,w);break e}}o=o.return}while(o!==null)}Wy(n)}catch(I){t=I,ze===n&&n!==null&&(ze=n=n.return);continue}break}while(1)}function Oy(){var e=Vr.current;return Vr.current=$r,e===null?$r:e}function du(){(Me===0||Me===3||Me===2)&&(Me=4),Fe===null||!(wi&268435455)&&!(gs&268435455)||Rn(Fe,Ze)}function Qr(e,t){var n=te;te|=2;var i=Oy();(Fe!==e||Ze!==t)&&(pn=null,yi(e,t));do try{K0();break}catch(a){Ry(e,a)}while(1);if(Vd(),te=n,Vr.current=i,ze!==null)throw Error(A(261));return Fe=null,Ze=0,Me}function K0(){for(;ze!==null;)zy(ze)}function X0(){for(;ze!==null&&!xb();)zy(ze)}function zy(e){var t=My(e.alternate,e,ht);e.memoizedProps=e.pendingProps,t===null?Wy(e):ze=t,ou.current=null}function Wy(e){var t=e;do{var n=t.alternate;if(e=t.return,t.flags&32768){if(n=G0(n,t),n!==null){n.flags&=32767,ze=n;return}if(e!==null)e.flags|=32768,e.subtreeFlags=0,e.deletions=null;else{Me=6,ze=null;return}}else if(n=U0(n,t,ht),n!==null){ze=n;return}if(t=t.sibling,t!==null){ze=t;return}ze=t=e}while(t!==null);Me===0&&(Me=5)}function oi(e,t,n){var i=le,a=Nt.transition;try{Nt.transition=null,le=1,Y0(e,t,n,i)}finally{Nt.transition=a,le=i}return null}function Y0(e,t,n,i){do ta();while(zn!==null);if(te&6)throw Error(A(327));n=e.finishedWork;var a=e.finishedLanes;if(n===null)return null;if(e.finishedWork=null,e.finishedLanes=0,n===e.current)throw Error(A(177));e.callbackNode=null,e.callbackPriority=0;var o=n.lanes|n.childLanes;if(Eb(e,o),e===Fe&&(ze=Fe=null,Ze=0),!(n.subtreeFlags&2064)&&!(n.flags&2064)||nr||(nr=!0,Ly(Sr,function(){return ta(),null})),o=(n.flags&15990)!==0,n.subtreeFlags&15990||o){o=Nt.transition,Nt.transition=null;var r=le;le=1;var s=te;te|=4,ou.current=null,V0(e,n),Ey(n,e),_0(qc),Er=!!Ic,qc=Ic=null,e.current=n,H0(n),Tb(),te=s,le=r,Nt.transition=o}else e.current=n;if(nr&&(nr=!1,zn=e,Zr=a),o=e.pendingLanes,o===0&&(Gn=null),qb(n.stateNode),pt(e,Re()),t!==null)for(i=e.onRecoverableError,n=0;n<t.length;n++)a=t[n],i(a.value,{componentStack:a.stack,digest:a.digest});if(Hr)throw Hr=!1,e=Vc,Vc=null,e;return Zr&1&&e.tag!==0&&ta(),o=e.pendingLanes,o&1?e===Hc?Ja++:(Ja=0,Hc=e):Ja=0,ei(),null}function ta(){if(zn!==null){var e=gh(Zr),t=Nt.transition,n=le;try{if(Nt.transition=null,le=16>e?16:e,zn===null)var i=!1;else{if(e=zn,zn=null,Zr=0,te&6)throw Error(A(331));var a=te;for(te|=4,j=e.current;j!==null;){var o=j,r=o.child;if(j.flags&16){var s=o.deletions;if(s!==null){for(var l=0;l<s.length;l++){var c=s[l];for(j=c;j!==null;){var d=j;switch(d.tag){case 0:case 11:case 15:Xa(8,d,o)}var f=d.child;if(f!==null)f.return=d,j=f;else for(;j!==null;){d=j;var h=d.sibling,u=d.return;if(Py(d),d===c){j=null;break}if(h!==null){h.return=u,j=h;break}j=u}}}var y=o.alternate;if(y!==null){var m=y.child;if(m!==null){y.child=null;do{var k=m.sibling;m.sibling=null,m=k}while(m!==null)}}j=o}}if(o.subtreeFlags&2064&&r!==null)r.return=o,j=r;else e:for(;j!==null;){if(o=j,o.flags&2048)switch(o.tag){case 0:case 11:case 15:Xa(9,o,o.return)}var _=o.sibling;if(_!==null){_.return=o.return,j=_;break e}j=o.return}}var g=e.current;for(j=g;j!==null;){r=j;var b=r.child;if(r.subtreeFlags&2064&&b!==null)b.return=r,j=b;else e:for(r=g;j!==null;){if(s=j,s.flags&2048)try{switch(s.tag){case 0:case 11:case 15:ys(9,s)}}catch(I){Ee(s,s.return,I)}if(s===r){j=null;break e}var w=s.sibling;if(w!==null){w.return=s.return,j=w;break e}j=s.return}}if(te=a,ei(),nn&&typeof nn.onPostCommitFiberRoot=="function")try{nn.onPostCommitFiberRoot(ls,e)}catch{}i=!0}return i}finally{le=n,Nt.transition=t}}return!1}function rm(e,t,n){t=ca(n,t),t=_y(e,t,1),e=Un(e,t,1),t=it(),e!==null&&(Do(e,1,t),pt(e,t))}function Ee(e,t,n){if(e.tag===3)rm(e,e,n);else for(;t!==null;){if(t.tag===3){rm(t,e,n);break}else if(t.tag===1){var i=t.stateNode;if(typeof t.type.getDerivedStateFromError=="function"||typeof i.componentDidCatch=="function"&&(Gn===null||!Gn.has(i))){e=ca(n,e),e=by(t,e,1),t=Un(t,e,1),e=it(),t!==null&&(Do(t,1,e),pt(t,e));break}}t=t.return}}function J0(e,t,n){var i=e.pingCache;i!==null&&i.delete(t),t=it(),e.pingedLanes|=e.suspendedLanes&n,Fe===e&&(Ze&n)===n&&(Me===4||Me===3&&(Ze&130023424)===Ze&&500>Re()-su?yi(e,0):ru|=n),pt(e,t)}function jy(e,t){t===0&&(e.mode&1?(t=Vo,Vo<<=1,!(Vo&130023424)&&(Vo=4194304)):t=1);var n=it();e=vn(e,t),e!==null&&(Do(e,t,n),pt(e,n))}function e1(e){var t=e.memoizedState,n=0;t!==null&&(n=t.retryLane),jy(e,n)}function t1(e,t){var n=0;switch(e.tag){case 13:var i=e.stateNode,a=e.memoizedState;a!==null&&(n=a.retryLane);break;case 19:i=e.stateNode;break;default:throw Error(A(314))}i!==null&&i.delete(t),jy(e,n)}var My;My=function(e,t,n){if(e!==null)if(e.memoizedProps!==t.pendingProps||dt.current)ct=!0;else{if(!(e.lanes&n)&&!(t.flags&128))return ct=!1,F0(e,t,n);ct=!!(e.flags&131072)}else ct=!1,ke&&t.flags&1048576&&Uh(t,jr,t.index);switch(t.lanes=0,t.tag){case 2:var i=t.type;gr(e,t),e=t.pendingProps;var a=oa(t,tt.current);ea(t,n),a=eu(null,t,i,e,a,n);var o=tu();return t.flags|=1,typeof a=="object"&&a!==null&&typeof a.render=="function"&&a.$$typeof===void 0?(t.tag=1,t.memoizedState=null,t.updateQueue=null,ut(i)?(o=!0,zr(t)):o=!1,t.memoizedState=a.state!==null&&a.state!==void 0?a.state:null,Qd(t),a.updater=fs,t.stateNode=a,a._reactInternals=t,Rc(t,i,e,n),t=Wc(null,t,i,!0,o,n)):(t.tag=0,ke&&o&&Fd(t),nt(null,t,a,n),t=t.child),t;case 16:i=t.elementType;e:{switch(gr(e,t),e=t.pendingProps,a=i._init,i=a(i._payload),t.type=i,a=t.tag=i1(i),e=Mt(i,e),a){case 0:t=zc(null,t,i,e,n);break e;case 1:t=Kp(null,t,i,e,n);break e;case 11:t=Zp(null,t,i,e,n);break e;case 14:t=Qp(null,t,i,Mt(i.type,e),n);break e}throw Error(A(306,i,""))}return t;case 0:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:Mt(i,a),zc(e,t,i,a,n);case 1:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:Mt(i,a),Kp(e,t,i,a,n);case 3:e:{if(Ty(t),e===null)throw Error(A(387));i=t.pendingProps,o=t.memoizedState,a=o.element,Hh(e,t),Fr(t,i,null,n);var r=t.memoizedState;if(i=r.element,o.isDehydrated)if(o={element:i,isDehydrated:!1,cache:r.cache,pendingSuspenseBoundaries:r.pendingSuspenseBoundaries,transitions:r.transitions},t.updateQueue.baseState=o,t.memoizedState=o,t.flags&256){a=ca(Error(A(423)),t),t=Xp(e,t,i,n,a);break e}else if(i!==a){a=ca(Error(A(424)),t),t=Xp(e,t,i,n,a);break e}else for(_t=Fn(t.stateNode.containerInfo.firstChild),bt=t,ke=!0,Ft=null,n=Xh(t,null,i,n),t.child=n;n;)n.flags=n.flags&-3|4096,n=n.sibling;else{if(ra(),i===a){t=wn(e,t,n);break e}nt(e,t,i,n)}t=t.child}return t;case 5:return Yh(t),e===null&&Ec(t),i=t.type,a=t.pendingProps,o=e!==null?e.memoizedProps:null,r=a.children,Cc(i,a)?r=null:o!==null&&Cc(i,o)&&(t.flags|=32),xy(e,t),nt(e,t,r,n),t.child;case 6:return e===null&&Ec(t),null;case 13:return ky(e,t,n);case 4:return Kd(t,t.stateNode.containerInfo),i=t.pendingProps,e===null?t.child=sa(t,null,i,n):nt(e,t,i,n),t.child;case 11:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:Mt(i,a),Zp(e,t,i,a,n);case 7:return nt(e,t,t.pendingProps,n),t.child;case 8:return nt(e,t,t.pendingProps.children,n),t.child;case 12:return nt(e,t,t.pendingProps.children,n),t.child;case 10:e:{if(i=t.type._context,a=t.pendingProps,o=t.memoizedProps,r=a.value,ge(Mr,i._currentValue),i._currentValue=r,o!==null)if(Vt(o.value,r)){if(o.children===a.children&&!dt.current){t=wn(e,t,n);break e}}else for(o=t.child,o!==null&&(o.return=t);o!==null;){var s=o.dependencies;if(s!==null){r=o.child;for(var l=s.firstContext;l!==null;){if(l.context===i){if(o.tag===1){l=gn(-1,n&-n),l.tag=2;var c=o.updateQueue;if(c!==null){c=c.shared;var d=c.pending;d===null?l.next=l:(l.next=d.next,d.next=l),c.pending=l}}o.lanes|=n,l=o.alternate,l!==null&&(l.lanes|=n),Nc(o.return,n,t),s.lanes|=n;break}l=l.next}}else if(o.tag===10)r=o.type===t.type?null:o.child;else if(o.tag===18){if(r=o.return,r===null)throw Error(A(341));r.lanes|=n,s=r.alternate,s!==null&&(s.lanes|=n),Nc(r,n,t),r=o.sibling}else r=o.child;if(r!==null)r.return=o;else for(r=o;r!==null;){if(r===t){r=null;break}if(o=r.sibling,o!==null){o.return=r.return,r=o;break}r=r.return}o=r}nt(e,t,a.children,n),t=t.child}return t;case 9:return a=t.type,i=t.pendingProps.children,ea(t,n),a=Rt(a),i=i(a),t.flags|=1,nt(e,t,i,n),t.child;case 14:return i=t.type,a=Mt(i,t.pendingProps),a=Mt(i.type,a),Qp(e,t,i,a,n);case 15:return vy(e,t,t.type,t.pendingProps,n);case 17:return i=t.type,a=t.pendingProps,a=t.elementType===i?a:Mt(i,a),gr(e,t),t.tag=1,ut(i)?(e=!0,zr(t)):e=!1,ea(t,n),Qh(t,i,a),Rc(t,i,a,n),Wc(null,t,i,!0,e,n);case 19:return Iy(e,t,n);case 22:return wy(e,t,n)}throw Error(A(156,t.tag))};function Ly(e,t){return mh(e,t)}function n1(e,t,n,i){this.tag=e,this.key=n,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=i,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Et(e,t,n,i){return new n1(e,t,n,i)}function uu(e){return e=e.prototype,!(!e||!e.isReactComponent)}function i1(e){if(typeof e=="function")return uu(e)?1:0;if(e!=null){if(e=e.$$typeof,e===Sd)return 11;if(e===Ad)return 14}return 2}function Vn(e,t){var n=e.alternate;return n===null?(n=Et(e.tag,t,e.key,e.mode),n.elementType=e.elementType,n.type=e.type,n.stateNode=e.stateNode,n.alternate=e,e.alternate=n):(n.pendingProps=t,n.type=e.type,n.flags=0,n.subtreeFlags=0,n.deletions=null),n.flags=e.flags&14680064,n.childLanes=e.childLanes,n.lanes=e.lanes,n.child=e.child,n.memoizedProps=e.memoizedProps,n.memoizedState=e.memoizedState,n.updateQueue=e.updateQueue,t=e.dependencies,n.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext},n.sibling=e.sibling,n.index=e.index,n.ref=e.ref,n}function vr(e,t,n,i,a,o){var r=2;if(i=e,typeof e=="function")uu(e)&&(r=1);else if(typeof e=="string")r=5;else e:switch(e){case ji:return gi(n.children,a,o,t);case Pd:r=8,a|=8;break;case oc:return e=Et(12,n,t,a|2),e.elementType=oc,e.lanes=o,e;case rc:return e=Et(13,n,t,a),e.elementType=rc,e.lanes=o,e;case sc:return e=Et(19,n,t,a),e.elementType=sc,e.lanes=o,e;case Kf:return _s(n,a,o,t);default:if(typeof e=="object"&&e!==null)switch(e.$$typeof){case Zf:r=10;break e;case Qf:r=9;break e;case Sd:r=11;break e;case Ad:r=14;break e;case En:r=16,i=null;break e}throw Error(A(130,e==null?e:typeof e,""))}return t=Et(r,n,t,a),t.elementType=e,t.type=i,t.lanes=o,t}function gi(e,t,n,i){return e=Et(7,e,i,t),e.lanes=n,e}function _s(e,t,n,i){return e=Et(22,e,i,t),e.elementType=Kf,e.lanes=n,e.stateNode={isHidden:!1},e}function zl(e,t,n){return e=Et(6,e,null,t),e.lanes=n,e}function Wl(e,t,n){return t=Et(4,e.children!==null?e.children:[],e.key,t),t.lanes=n,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function a1(e,t,n,i,a){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=_l(0),this.expirationTimes=_l(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=_l(0),this.identifierPrefix=i,this.onRecoverableError=a,this.mutableSourceEagerHydrationData=null}function pu(e,t,n,i,a,o,r,s,l){return e=new a1(e,t,n,s,l),t===1?(t=1,o===!0&&(t|=8)):t=0,o=Et(3,null,null,t),e.current=o,o.stateNode=e,o.memoizedState={element:i,isDehydrated:n,cache:null,transitions:null,pendingSuspenseBoundaries:null},Qd(o),e}function o1(e,t,n){var i=3<arguments.length&&arguments[3]!==void 0?arguments[3]:null;return{$$typeof:Wi,key:i==null?null:""+i,children:e,containerInfo:t,implementation:n}}function Fy(e){if(!e)return Qn;e=e._reactInternals;e:{if(qi(e)!==e||e.tag!==1)throw Error(A(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(ut(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(t!==null);throw Error(A(171))}if(e.tag===1){var n=e.type;if(ut(n))return Lh(e,n,t)}return t}function Uy(e,t,n,i,a,o,r,s,l){return e=pu(n,i,!0,e,a,o,r,s,l),e.context=Fy(null),n=e.current,i=it(),a=$n(n),o=gn(i,a),o.callback=t??null,Un(n,o,a),e.current.lanes=a,Do(e,a,i),pt(e,i),e}function bs(e,t,n,i){var a=t.current,o=it(),r=$n(a);return n=Fy(n),t.context===null?t.context=n:t.pendingContext=n,t=gn(o,r),t.payload={element:e},i=i===void 0?null:i,i!==null&&(t.callback=i),e=Un(a,t,r),e!==null&&($t(e,a,r,o),fr(e,a,r)),r}function Kr(e){if(e=e.current,!e.child)return null;switch(e.child.tag){case 5:return e.child.stateNode;default:return e.child.stateNode}}function sm(e,t){if(e=e.memoizedState,e!==null&&e.dehydrated!==null){var n=e.retryLane;e.retryLane=n!==0&&n<t?n:t}}function mu(e,t){sm(e,t),(e=e.alternate)&&sm(e,t)}function r1(){return null}var Gy=typeof reportError=="function"?reportError:function(e){console.error(e)};function fu(e){this._internalRoot=e}vs.prototype.render=fu.prototype.render=function(e){var t=this._internalRoot;if(t===null)throw Error(A(409));bs(e,t,null,null)};vs.prototype.unmount=fu.prototype.unmount=function(){var e=this._internalRoot;if(e!==null){this._internalRoot=null;var t=e.containerInfo;xi(function(){bs(null,e,null,null)}),t[bn]=null}};function vs(e){this._internalRoot=e}vs.prototype.unstable_scheduleHydration=function(e){if(e){var t=vh();e={blockedOn:null,target:e,priority:t};for(var n=0;n<Bn.length&&t!==0&&t<Bn[n].priority;n++);Bn.splice(n,0,e),n===0&&xh(e)}};function hu(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11)}function ws(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11&&(e.nodeType!==8||e.nodeValue!==" react-mount-point-unstable "))}function lm(){}function s1(e,t,n,i,a){if(a){if(typeof i=="function"){var o=i;i=function(){var c=Kr(r);o.call(c)}}var r=Uy(t,i,e,0,null,!1,!1,"",lm);return e._reactRootContainer=r,e[bn]=r.current,mo(e.nodeType===8?e.parentNode:e),xi(),r}for(;a=e.lastChild;)e.removeChild(a);if(typeof i=="function"){var s=i;i=function(){var c=Kr(l);s.call(c)}}var l=pu(e,0,!1,null,null,!1,!1,"",lm);return e._reactRootContainer=l,e[bn]=l.current,mo(e.nodeType===8?e.parentNode:e),xi(function(){bs(t,l,n,i)}),l}function xs(e,t,n,i,a){var o=n._reactRootContainer;if(o){var r=o;if(typeof a=="function"){var s=a;a=function(){var l=Kr(r);s.call(l)}}bs(t,r,e,a)}else r=s1(n,t,e,a,i);return Kr(r)}_h=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var n=Fa(t.pendingLanes);n!==0&&(Bd(t,n|1),pt(t,Re()),!(te&6)&&(da=Re()+500,ei()))}break;case 13:xi(function(){var i=vn(e,1);if(i!==null){var a=it();$t(i,e,1,a)}}),mu(e,1)}};Rd=function(e){if(e.tag===13){var t=vn(e,134217728);if(t!==null){var n=it();$t(t,e,134217728,n)}mu(e,134217728)}};bh=function(e){if(e.tag===13){var t=$n(e),n=vn(e,t);if(n!==null){var i=it();$t(n,e,t,i)}mu(e,t)}};vh=function(){return le};wh=function(e,t){var n=le;try{return le=e,t()}finally{le=n}};gc=function(e,t,n){switch(t){case"input":if(dc(e,n),t=n.name,n.type==="radio"&&t!=null){for(n=e;n.parentNode;)n=n.parentNode;for(n=n.querySelectorAll("input[name="+JSON.stringify(""+t)+'][type="radio"]'),t=0;t<n.length;t++){var i=n[t];if(i!==e&&i.form===e.form){var a=ps(i);if(!a)throw Error(A(90));Yf(i),dc(i,a)}}}break;case"textarea":eh(e,n);break;case"select":t=n.value,t!=null&&Ki(e,!!n.multiple,t,!1)}};sh=lu;lh=xi;var l1={usingClientEntryPoint:!1,Events:[So,Ui,ps,oh,rh,lu]},Aa={findFiberByHostInstance:ui,bundleType:0,version:"18.2.0",rendererPackageName:"react-dom"},c1={bundleType:Aa.bundleType,version:Aa.version,rendererPackageName:Aa.rendererPackageName,rendererConfig:Aa.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:kn.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return e=uh(e),e===null?null:e.stateNode},findFiberByHostInstance:Aa.findFiberByHostInstance||r1,findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:"18.2.0-next-9e3b772b8-20220608"};if(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__<"u"){var ir=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!ir.isDisabled&&ir.supportsFiber)try{ls=ir.inject(c1),nn=ir}catch{}}xt.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=l1;xt.createPortal=function(e,t){var n=2<arguments.length&&arguments[2]!==void 0?arguments[2]:null;if(!hu(t))throw Error(A(200));return o1(e,t,null,n)};xt.createRoot=function(e,t){if(!hu(e))throw Error(A(299));var n=!1,i="",a=Gy;return t!=null&&(t.unstable_strictMode===!0&&(n=!0),t.identifierPrefix!==void 0&&(i=t.identifierPrefix),t.onRecoverableError!==void 0&&(a=t.onRecoverableError)),t=pu(e,1,!1,null,null,n,!1,i,a),e[bn]=t.current,mo(e.nodeType===8?e.parentNode:e),new fu(t)};xt.findDOMNode=function(e){if(e==null)return null;if(e.nodeType===1)return e;var t=e._reactInternals;if(t===void 0)throw typeof e.render=="function"?Error(A(188)):(e=Object.keys(e).join(","),Error(A(268,e)));return e=uh(t),e=e===null?null:e.stateNode,e};xt.flushSync=function(e){return xi(e)};xt.hydrate=function(e,t,n){if(!ws(t))throw Error(A(200));return xs(null,e,t,!0,n)};xt.hydrateRoot=function(e,t,n){if(!hu(e))throw Error(A(405));var i=n!=null&&n.hydratedSources||null,a=!1,o="",r=Gy;if(n!=null&&(n.unstable_strictMode===!0&&(a=!0),n.identifierPrefix!==void 0&&(o=n.identifierPrefix),n.onRecoverableError!==void 0&&(r=n.onRecoverableError)),t=Uy(t,null,e,1,n??null,a,!1,o,r),e[bn]=t.current,mo(e),i)for(e=0;e<i.length;e++)n=i[e],a=n._getVersion,a=a(n._source),t.mutableSourceEagerHydrationData==null?t.mutableSourceEagerHydrationData=[n,a]:t.mutableSourceEagerHydrationData.push(n,a);return new vs(t)};xt.render=function(e,t,n){if(!ws(t))throw Error(A(200));return xs(null,e,t,!1,n)};xt.unmountComponentAtNode=function(e){if(!ws(e))throw Error(A(40));return e._reactRootContainer?(xi(function(){xs(null,null,e,!1,function(){e._reactRootContainer=null,e[bn]=null})}),!0):!1};xt.unstable_batchedUpdates=lu;xt.unstable_renderSubtreeIntoContainer=function(e,t,n,i){if(!ws(n))throw Error(A(200));if(e==null||e._reactInternals===void 0)throw Error(A(38));return xs(e,t,n,!1,i)};xt.version="18.2.0-next-9e3b772b8-20220608";function $y(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE($y)}catch(e){console.error(e)}}$y(),Uf.exports=xt;var Ts=Uf.exports;const ar=Ef(Ts);var cm=Ts;ic.createRoot=cm.createRoot,ic.hydrateRoot=cm.hydrateRoot;/**
 * @remix-run/router v1.9.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function xo(){return xo=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},xo.apply(this,arguments)}var Wn;(function(e){e.Pop="POP",e.Push="PUSH",e.Replace="REPLACE"})(Wn||(Wn={}));const dm="popstate";function d1(e){e===void 0&&(e={});function t(i,a){let{pathname:o,search:r,hash:s}=i.location;return Kc("",{pathname:o,search:r,hash:s},a.state&&a.state.usr||null,a.state&&a.state.key||"default")}function n(i,a){return typeof a=="string"?a:Xr(a)}return p1(t,n,null,e)}function We(e,t){if(e===!1||e===null||typeof e>"u")throw new Error(t)}function yu(e,t){if(!e){typeof console<"u"&&console.warn(t);try{throw new Error(t)}catch{}}}function u1(){return Math.random().toString(36).substr(2,8)}function um(e,t){return{usr:e.state,key:e.key,idx:t}}function Kc(e,t,n,i){return n===void 0&&(n=null),xo({pathname:typeof e=="string"?e:e.pathname,search:"",hash:""},typeof t=="string"?_a(t):t,{state:n,key:t&&t.key||i||u1()})}function Xr(e){let{pathname:t="/",search:n="",hash:i=""}=e;return n&&n!=="?"&&(t+=n.charAt(0)==="?"?n:"?"+n),i&&i!=="#"&&(t+=i.charAt(0)==="#"?i:"#"+i),t}function _a(e){let t={};if(e){let n=e.indexOf("#");n>=0&&(t.hash=e.substr(n),e=e.substr(0,n));let i=e.indexOf("?");i>=0&&(t.search=e.substr(i),e=e.substr(0,i)),e&&(t.pathname=e)}return t}function p1(e,t,n,i){i===void 0&&(i={});let{window:a=document.defaultView,v5Compat:o=!1}=i,r=a.history,s=Wn.Pop,l=null,c=d();c==null&&(c=0,r.replaceState(xo({},r.state,{idx:c}),""));function d(){return(r.state||{idx:null}).idx}function f(){s=Wn.Pop;let k=d(),_=k==null?null:k-c;c=k,l&&l({action:s,location:m.location,delta:_})}function h(k,_){s=Wn.Push;let g=Kc(m.location,k,_);n&&n(g,k),c=d()+1;let b=um(g,c),w=m.createHref(g);try{r.pushState(b,"",w)}catch(I){if(I instanceof DOMException&&I.name==="DataCloneError")throw I;a.location.assign(w)}o&&l&&l({action:s,location:m.location,delta:1})}function u(k,_){s=Wn.Replace;let g=Kc(m.location,k,_);n&&n(g,k),c=d();let b=um(g,c),w=m.createHref(g);r.replaceState(b,"",w),o&&l&&l({action:s,location:m.location,delta:0})}function y(k){let _=a.location.origin!=="null"?a.location.origin:a.location.href,g=typeof k=="string"?k:Xr(k);return We(_,"No window.location.(origin|href) available to create URL for href: "+g),new URL(g,_)}let m={get action(){return s},get location(){return e(a,r)},listen(k){if(l)throw new Error("A history only accepts one active listener");return a.addEventListener(dm,f),l=k,()=>{a.removeEventListener(dm,f),l=null}},createHref(k){return t(a,k)},createURL:y,encodeLocation(k){let _=y(k);return{pathname:_.pathname,search:_.search,hash:_.hash}},push:h,replace:u,go(k){return r.go(k)}};return m}var pm;(function(e){e.data="data",e.deferred="deferred",e.redirect="redirect",e.error="error"})(pm||(pm={}));function m1(e,t,n){n===void 0&&(n="/");let i=typeof t=="string"?_a(t):t,a=gu(i.pathname||"/",n);if(a==null)return null;let o=Vy(e);f1(o);let r=null;for(let s=0;r==null&&s<o.length;++s)r=T1(o[s],q1(a));return r}function Vy(e,t,n,i){t===void 0&&(t=[]),n===void 0&&(n=[]),i===void 0&&(i="");let a=(o,r,s)=>{let l={relativePath:s===void 0?o.path||"":s,caseSensitive:o.caseSensitive===!0,childrenIndex:r,route:o};l.relativePath.startsWith("/")&&(We(l.relativePath.startsWith(i),'Absolute route path "'+l.relativePath+'" nested under path '+('"'+i+'" is not valid. An absolute child route path ')+"must start with the combined path of all its parent routes."),l.relativePath=l.relativePath.slice(i.length));let c=Hn([i,l.relativePath]),d=n.concat(l);o.children&&o.children.length>0&&(We(o.index!==!0,"Index routes must not have child routes. Please remove "+('all child routes from route path "'+c+'".')),Vy(o.children,t,d,c)),!(o.path==null&&!o.index)&&t.push({path:c,score:w1(c,o.index),routesMeta:d})};return e.forEach((o,r)=>{var s;if(o.path===""||!((s=o.path)!=null&&s.includes("?")))a(o,r);else for(let l of Hy(o.path))a(o,r,l)}),t}function Hy(e){let t=e.split("/");if(t.length===0)return[];let[n,...i]=t,a=n.endsWith("?"),o=n.replace(/\?$/,"");if(i.length===0)return a?[o,""]:[o];let r=Hy(i.join("/")),s=[];return s.push(...r.map(l=>l===""?o:[o,l].join("/"))),a&&s.push(...r),s.map(l=>e.startsWith("/")&&l===""?"/":l)}function f1(e){e.sort((t,n)=>t.score!==n.score?n.score-t.score:x1(t.routesMeta.map(i=>i.childrenIndex),n.routesMeta.map(i=>i.childrenIndex)))}const h1=/^:\w+$/,y1=3,g1=2,_1=1,b1=10,v1=-2,mm=e=>e==="*";function w1(e,t){let n=e.split("/"),i=n.length;return n.some(mm)&&(i+=v1),t&&(i+=g1),n.filter(a=>!mm(a)).reduce((a,o)=>a+(h1.test(o)?y1:o===""?_1:b1),i)}function x1(e,t){return e.length===t.length&&e.slice(0,-1).every((i,a)=>i===t[a])?e[e.length-1]-t[t.length-1]:0}function T1(e,t){let{routesMeta:n}=e,i={},a="/",o=[];for(let r=0;r<n.length;++r){let s=n[r],l=r===n.length-1,c=a==="/"?t:t.slice(a.length)||"/",d=k1({path:s.relativePath,caseSensitive:s.caseSensitive,end:l},c);if(!d)return null;Object.assign(i,d.params);let f=s.route;o.push({params:i,pathname:Hn([a,d.pathname]),pathnameBase:S1(Hn([a,d.pathnameBase])),route:f}),d.pathnameBase!=="/"&&(a=Hn([a,d.pathnameBase]))}return o}function k1(e,t){typeof e=="string"&&(e={path:e,caseSensitive:!1,end:!0});let[n,i]=I1(e.path,e.caseSensitive,e.end),a=t.match(n);if(!a)return null;let o=a[0],r=o.replace(/(.)\/+$/,"$1"),s=a.slice(1);return{params:i.reduce((c,d,f)=>{if(d==="*"){let h=s[f]||"";r=o.slice(0,o.length-h.length).replace(/(.)\/+$/,"$1")}return c[d]=C1(s[f]||"",d),c},{}),pathname:o,pathnameBase:r,pattern:e}}function I1(e,t,n){t===void 0&&(t=!1),n===void 0&&(n=!0),yu(e==="*"||!e.endsWith("*")||e.endsWith("/*"),'Route path "'+e+'" will be treated as if it were '+('"'+e.replace(/\*$/,"/*")+'" because the `*` character must ')+"always follow a `/` in the pattern. To get rid of this warning, "+('please change the route path to "'+e.replace(/\*$/,"/*")+'".'));let i=[],a="^"+e.replace(/\/*\*?$/,"").replace(/^\/*/,"/").replace(/[\\.*+^$?{}|()[\]]/g,"\\$&").replace(/\/:(\w+)/g,(r,s)=>(i.push(s),"/([^\\/]+)"));return e.endsWith("*")?(i.push("*"),a+=e==="*"||e==="/*"?"(.*)$":"(?:\\/(.+)|\\/*)$"):n?a+="\\/*$":e!==""&&e!=="/"&&(a+="(?:(?=\\/|$))"),[new RegExp(a,t?void 0:"i"),i]}function q1(e){try{return decodeURI(e)}catch(t){return yu(!1,'The URL path "'+e+'" could not be decoded because it is is a malformed URL segment. This is probably due to a bad percent '+("encoding ("+t+").")),e}}function C1(e,t){try{return decodeURIComponent(e)}catch(n){return yu(!1,'The value for the URL param "'+t+'" will not be decoded because'+(' the string "'+e+'" is a malformed URL segment. This is probably')+(" due to a bad percent encoding ("+n+").")),e}}function gu(e,t){if(t==="/")return e;if(!e.toLowerCase().startsWith(t.toLowerCase()))return null;let n=t.endsWith("/")?t.length-1:t.length,i=e.charAt(n);return i&&i!=="/"?null:e.slice(n)||"/"}function D1(e,t){t===void 0&&(t="/");let{pathname:n,search:i="",hash:a=""}=typeof e=="string"?_a(e):e;return{pathname:n?n.startsWith("/")?n:P1(n,t):t,search:A1(i),hash:E1(a)}}function P1(e,t){let n=t.replace(/\/+$/,"").split("/");return e.split("/").forEach(a=>{a===".."?n.length>1&&n.pop():a!=="."&&n.push(a)}),n.length>1?n.join("/"):"/"}function jl(e,t,n,i){return"Cannot include a '"+e+"' character in a manually specified "+("`to."+t+"` field ["+JSON.stringify(i)+"].  Please separate it out to the ")+("`to."+n+"` field. Alternatively you may provide the full path as ")+'a string in <Link to="..."> and the router will parse it for you.'}function Zy(e){return e.filter((t,n)=>n===0||t.route.path&&t.route.path.length>0)}function Qy(e,t,n,i){i===void 0&&(i=!1);let a;typeof e=="string"?a=_a(e):(a=xo({},e),We(!a.pathname||!a.pathname.includes("?"),jl("?","pathname","search",a)),We(!a.pathname||!a.pathname.includes("#"),jl("#","pathname","hash",a)),We(!a.search||!a.search.includes("#"),jl("#","search","hash",a)));let o=e===""||a.pathname==="",r=o?"/":a.pathname,s;if(i||r==null)s=n;else{let f=t.length-1;if(r.startsWith("..")){let h=r.split("/");for(;h[0]==="..";)h.shift(),f-=1;a.pathname=h.join("/")}s=f>=0?t[f]:"/"}let l=D1(a,s),c=r&&r!=="/"&&r.endsWith("/"),d=(o||r===".")&&n.endsWith("/");return!l.pathname.endsWith("/")&&(c||d)&&(l.pathname+="/"),l}const Hn=e=>e.join("/").replace(/\/\/+/g,"/"),S1=e=>e.replace(/\/+$/,"").replace(/^\/*/,"/"),A1=e=>!e||e==="?"?"":e.startsWith("?")?e:"?"+e,E1=e=>!e||e==="#"?"":e.startsWith("#")?e:"#"+e;function N1(e){return e!=null&&typeof e.status=="number"&&typeof e.statusText=="string"&&typeof e.internal=="boolean"&&"data"in e}const Ky=["post","put","patch","delete"];new Set(Ky);const B1=["get",...Ky];new Set(B1);/**
 * React Router v6.16.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function Yr(){return Yr=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},Yr.apply(this,arguments)}const _u=v.createContext(null),R1=v.createContext(null),ba=v.createContext(null),ks=v.createContext(null),ti=v.createContext({outlet:null,matches:[],isDataRoute:!1}),Xy=v.createContext(null);function O1(e,t){let{relative:n}=t===void 0?{}:t;Eo()||We(!1);let{basename:i,navigator:a}=v.useContext(ba),{hash:o,pathname:r,search:s}=Jy(e,{relative:n}),l=r;return i!=="/"&&(l=r==="/"?i:Hn([i,r])),a.createHref({pathname:l,search:s,hash:o})}function Eo(){return v.useContext(ks)!=null}function Is(){return Eo()||We(!1),v.useContext(ks).location}function Yy(e){v.useContext(ba).static||v.useLayoutEffect(e)}function z1(){let{isDataRoute:e}=v.useContext(ti);return e?X1():W1()}function W1(){Eo()||We(!1);let e=v.useContext(_u),{basename:t,navigator:n}=v.useContext(ba),{matches:i}=v.useContext(ti),{pathname:a}=Is(),o=JSON.stringify(Zy(i).map(l=>l.pathnameBase)),r=v.useRef(!1);return Yy(()=>{r.current=!0}),v.useCallback(function(l,c){if(c===void 0&&(c={}),!r.current)return;if(typeof l=="number"){n.go(l);return}let d=Qy(l,JSON.parse(o),a,c.relative==="path");e==null&&t!=="/"&&(d.pathname=d.pathname==="/"?t:Hn([t,d.pathname])),(c.replace?n.replace:n.push)(d,c.state,c)},[t,n,o,a,e])}function j1(){let{matches:e}=v.useContext(ti),t=e[e.length-1];return t?t.params:{}}function Jy(e,t){let{relative:n}=t===void 0?{}:t,{matches:i}=v.useContext(ti),{pathname:a}=Is(),o=JSON.stringify(Zy(i).map(r=>r.pathnameBase));return v.useMemo(()=>Qy(e,JSON.parse(o),a,n==="path"),[e,o,a,n])}function M1(e,t){return L1(e,t)}function L1(e,t,n){Eo()||We(!1);let{navigator:i}=v.useContext(ba),{matches:a}=v.useContext(ti),o=a[a.length-1],r=o?o.params:{};o&&o.pathname;let s=o?o.pathnameBase:"/";o&&o.route;let l=Is(),c;if(t){var d;let m=typeof t=="string"?_a(t):t;s==="/"||(d=m.pathname)!=null&&d.startsWith(s)||We(!1),c=m}else c=l;let f=c.pathname||"/",h=s==="/"?f:f.slice(s.length)||"/",u=m1(e,{pathname:h}),y=V1(u&&u.map(m=>Object.assign({},m,{params:Object.assign({},r,m.params),pathname:Hn([s,i.encodeLocation?i.encodeLocation(m.pathname).pathname:m.pathname]),pathnameBase:m.pathnameBase==="/"?s:Hn([s,i.encodeLocation?i.encodeLocation(m.pathnameBase).pathname:m.pathnameBase])})),a,n);return t&&y?v.createElement(ks.Provider,{value:{location:Yr({pathname:"/",search:"",hash:"",state:null,key:"default"},c),navigationType:Wn.Pop}},y):y}function F1(){let e=K1(),t=N1(e)?e.status+" "+e.statusText:e instanceof Error?e.message:JSON.stringify(e),n=e instanceof Error?e.stack:null,a={padding:"0.5rem",backgroundColor:"rgba(200,200,200, 0.5)"},o=null;return v.createElement(v.Fragment,null,v.createElement("h2",null,"Unexpected Application Error!"),v.createElement("h3",{style:{fontStyle:"italic"}},t),n?v.createElement("pre",{style:a},n):null,o)}const U1=v.createElement(F1,null);class G1 extends v.Component{constructor(t){super(t),this.state={location:t.location,revalidation:t.revalidation,error:t.error}}static getDerivedStateFromError(t){return{error:t}}static getDerivedStateFromProps(t,n){return n.location!==t.location||n.revalidation!=="idle"&&t.revalidation==="idle"?{error:t.error,location:t.location,revalidation:t.revalidation}:{error:t.error||n.error,location:n.location,revalidation:t.revalidation||n.revalidation}}componentDidCatch(t,n){console.error("React Router caught the following error during render",t,n)}render(){return this.state.error?v.createElement(ti.Provider,{value:this.props.routeContext},v.createElement(Xy.Provider,{value:this.state.error,children:this.props.component})):this.props.children}}function $1(e){let{routeContext:t,match:n,children:i}=e,a=v.useContext(_u);return a&&a.static&&a.staticContext&&(n.route.errorElement||n.route.ErrorBoundary)&&(a.staticContext._deepestRenderedBoundaryId=n.route.id),v.createElement(ti.Provider,{value:t},i)}function V1(e,t,n){var i;if(t===void 0&&(t=[]),n===void 0&&(n=null),e==null){var a;if((a=n)!=null&&a.errors)e=n.matches;else return null}let o=e,r=(i=n)==null?void 0:i.errors;if(r!=null){let s=o.findIndex(l=>l.route.id&&(r==null?void 0:r[l.route.id]));s>=0||We(!1),o=o.slice(0,Math.min(o.length,s+1))}return o.reduceRight((s,l,c)=>{let d=l.route.id?r==null?void 0:r[l.route.id]:null,f=null;n&&(f=l.route.errorElement||U1);let h=t.concat(o.slice(0,c+1)),u=()=>{let y;return d?y=f:l.route.Component?y=v.createElement(l.route.Component,null):l.route.element?y=l.route.element:y=s,v.createElement($1,{match:l,routeContext:{outlet:s,matches:h,isDataRoute:n!=null},children:y})};return n&&(l.route.ErrorBoundary||l.route.errorElement||c===0)?v.createElement(G1,{location:n.location,revalidation:n.revalidation,component:f,error:d,children:u(),routeContext:{outlet:null,matches:h,isDataRoute:!0}}):u()},null)}var eg=function(e){return e.UseBlocker="useBlocker",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e}(eg||{}),Jr=function(e){return e.UseBlocker="useBlocker",e.UseLoaderData="useLoaderData",e.UseActionData="useActionData",e.UseRouteError="useRouteError",e.UseNavigation="useNavigation",e.UseRouteLoaderData="useRouteLoaderData",e.UseMatches="useMatches",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e.UseRouteId="useRouteId",e}(Jr||{});function H1(e){let t=v.useContext(_u);return t||We(!1),t}function Z1(e){let t=v.useContext(R1);return t||We(!1),t}function Q1(e){let t=v.useContext(ti);return t||We(!1),t}function tg(e){let t=Q1(),n=t.matches[t.matches.length-1];return n.route.id||We(!1),n.route.id}function K1(){var e;let t=v.useContext(Xy),n=Z1(Jr.UseRouteError),i=tg(Jr.UseRouteError);return t||((e=n.errors)==null?void 0:e[i])}function X1(){let{router:e}=H1(eg.UseNavigateStable),t=tg(Jr.UseNavigateStable),n=v.useRef(!1);return Yy(()=>{n.current=!0}),v.useCallback(function(a,o){o===void 0&&(o={}),n.current&&(typeof a=="number"?e.navigate(a):e.navigate(a,Yr({fromRouteId:t},o)))},[e,t])}function Xc(e){We(!1)}function Y1(e){let{basename:t="/",children:n=null,location:i,navigationType:a=Wn.Pop,navigator:o,static:r=!1}=e;Eo()&&We(!1);let s=t.replace(/^\/*/,"/"),l=v.useMemo(()=>({basename:s,navigator:o,static:r}),[s,o,r]);typeof i=="string"&&(i=_a(i));let{pathname:c="/",search:d="",hash:f="",state:h=null,key:u="default"}=i,y=v.useMemo(()=>{let m=gu(c,s);return m==null?null:{location:{pathname:m,search:d,hash:f,state:h,key:u},navigationType:a}},[s,c,d,f,h,u,a]);return y==null?null:v.createElement(ba.Provider,{value:l},v.createElement(ks.Provider,{children:n,value:y}))}function J1(e){let{children:t,location:n}=e;return M1(Yc(t),n)}new Promise(()=>{});function Yc(e,t){t===void 0&&(t=[]);let n=[];return v.Children.forEach(e,(i,a)=>{if(!v.isValidElement(i))return;let o=[...t,a];if(i.type===v.Fragment){n.push.apply(n,Yc(i.props.children,o));return}i.type!==Xc&&We(!1),!i.props.index||!i.props.children||We(!1);let r={id:i.props.id||o.join("-"),caseSensitive:i.props.caseSensitive,element:i.props.element,Component:i.props.Component,index:i.props.index,path:i.props.path,loader:i.props.loader,action:i.props.action,errorElement:i.props.errorElement,ErrorBoundary:i.props.ErrorBoundary,hasErrorBoundary:i.props.ErrorBoundary!=null||i.props.errorElement!=null,shouldRevalidate:i.props.shouldRevalidate,handle:i.props.handle,lazy:i.props.lazy};i.props.children&&(r.children=Yc(i.props.children,o)),n.push(r)}),n}/**
 * React Router DOM v6.16.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function Jc(){return Jc=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},Jc.apply(this,arguments)}function ev(e,t){if(e==null)return{};var n={},i=Object.keys(e),a,o;for(o=0;o<i.length;o++)a=i[o],!(t.indexOf(a)>=0)&&(n[a]=e[a]);return n}function tv(e){return!!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey)}function nv(e,t){return e.button===0&&(!t||t==="_self")&&!tv(e)}const iv=["onClick","relative","reloadDocument","replace","state","target","to","preventScrollReset"],av="startTransition",fm=qr[av];function ov(e){let{basename:t,children:n,future:i,window:a}=e,o=v.useRef();o.current==null&&(o.current=d1({window:a,v5Compat:!0}));let r=o.current,[s,l]=v.useState({action:r.action,location:r.location}),{v7_startTransition:c}=i||{},d=v.useCallback(f=>{c&&fm?fm(()=>l(f)):l(f)},[l,c]);return v.useLayoutEffect(()=>r.listen(d),[r,d]),v.createElement(Y1,{basename:t,children:n,location:s.location,navigationType:s.action,navigator:r})}const rv=typeof window<"u"&&typeof window.document<"u"&&typeof window.document.createElement<"u",sv=/^(?:[a-z][a-z0-9+.-]*:|\/\/)/i,Ti=v.forwardRef(function(t,n){let{onClick:i,relative:a,reloadDocument:o,replace:r,state:s,target:l,to:c,preventScrollReset:d}=t,f=ev(t,iv),{basename:h}=v.useContext(ba),u,y=!1;if(typeof c=="string"&&sv.test(c)&&(u=c,rv))try{let g=new URL(window.location.href),b=c.startsWith("//")?new URL(g.protocol+c):new URL(c),w=gu(b.pathname,h);b.origin===g.origin&&w!=null?c=w+b.search+b.hash:y=!0}catch{}let m=O1(c,{relative:a}),k=lv(c,{replace:r,state:s,target:l,preventScrollReset:d,relative:a});function _(g){i&&i(g),g.defaultPrevented||k(g)}return v.createElement("a",Jc({},f,{href:u||m,onClick:y||o?i:_,ref:n,target:l}))});var hm;(function(e){e.UseScrollRestoration="useScrollRestoration",e.UseSubmit="useSubmit",e.UseSubmitFetcher="useSubmitFetcher",e.UseFetcher="useFetcher"})(hm||(hm={}));var ym;(function(e){e.UseFetchers="useFetchers",e.UseScrollRestoration="useScrollRestoration"})(ym||(ym={}));function lv(e,t){let{target:n,replace:i,state:a,preventScrollReset:o,relative:r}=t===void 0?{}:t,s=z1(),l=Is(),c=Jy(e,{relative:r});return v.useCallback(d=>{if(nv(d,n)){d.preventDefault();let f=i!==void 0?i:Xr(l)===Xr(c);s(e,{replace:f,state:a,preventScrollReset:o,relative:r})}},[l,s,c,i,a,n,e,o,r])}const cv="/aiida-registry/pr-preview/pr-280/assets/logo-white-text-16948862.svg",dv="/aiida-registry/pr-preview/pr-280/assets/MARVEL-32e738c9.png",uv="/aiida-registry/pr-preview/pr-280/assets/MaX-099f261c.png";const pv={"aiida-QECpWorkChain":{code_home:"https://github.com/rikigigi/aiida-QECpWorkChain",development_status:"beta",entry_point_prefix:"qecpworkchain",pip_url:"git+https://github.com/rikigigi/aiida-QECpWorkChain",name:"aiida-QECpWorkChain",package_name:"aiida_QECpWorkChain",hosted_on:"github.com",metadata:{author:"Riccardo Bertossa",author_email:"rbertoss@sissa.it",version:"0.2.0a0",description:"Car-Parrinello Work Chain with Quantum Espresso. This workchain does a full CP simulation, from the choice of the electronic mass and the timestep, to the choice of the best parallelization options, and then it does the NPT equilibration and a final NVE simulation at the prescribed P and T. Automates as much as possible.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: GNU General Public License v3 (GPLv3)","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.workflows":{"qecpworkchain.cp":{description:["No description available"],spec:{inputs:[{name:"cp_code",required:!0,valid_types:"Code",info:""},{name:"cp_resources_cg_list",required:!0,valid_types:"List",info:"Same as cp_resources_cp_list but when doing a CG. The CG uses a different amount of resource and can use no band or task group parallelization."},{name:"cp_resources_cp_list",required:!0,valid_types:"List",info:`List of dictionary like the following:
{
 'resources' : {
   'num_machines' : 2,
   'num_mpiprocs_per_machine' : 48,
 },
 'wallclock' : 3600,
 'queue' : 'queue_name',
 'account': 'account_name',
}
c,porturrently only the first element of the list is used.
'wallclock' is the maximum time that can be requested to the scheduler. This code can decide to ask for less.
`},{name:"ecutwfc",required:!0,valid_types:"Float",info:"wavefunction cutoff (Ry), like in the QE input"},{name:"pseudo_family",required:!0,valid_types:"Str",info:"pseudopotential family to use, as in usual aiida operations"},{name:"pw_code",required:!0,valid_types:"Code",info:"input pw code (used to calculate force ratio)"},{name:"pw_resources_list",required:!0,valid_types:"List",info:"Same as cp_resources_cp_list but for pw.x code."},{name:"structure",required:!0,valid_types:"StructureData, TrajectoryData",info:"Input structure. If a trajectory is given, the workchain will use its last step to start the CG. If velocities are present, they will be used to initialize the simulation. Note that if you use a trajectory, usually kind information (like mass) are not included, so default values will be used. If you want to include kind information or override those provided with the input structure, use the input structure_kinds"},{name:"thermobarostat_points",required:!0,valid_types:"List",info:'List of dicts, each with the format [ { "temperature_K": 1000, "pressure_KBar": 10 , "equilibration_time_ps": 5.0, "thermostat_time_ps": 5.0} ]. The simulation will loop over this list of dictionaries, in the same order, equilibrating for the specified time at the given P,T point. Every point is repeated if the average T and P are not within the specified ranges'},{name:"additional_parameters_cp",required:!1,valid_types:"Dict",info:"parameters that will be included in the settings input of the QE CP plugin. These settings will be added on top of the default one. Same format as plugin input"},{name:"adjust_ionic_mass",required:!1,valid_types:"Bool",info:"Multiply the mass of the ions by the corresponding force ration between the cp forces and pw forces -- that is less than 1. Note that averages of static properties do not depend on the ionic masses."},{name:"benchmark_emass_dt_walltime_s",required:!1,valid_types:"Float",info:"same as benchmark_parallel_walltime_s but for dermining the best electronic mass and timestep."},{name:"benchmark_parallel_walltime_s",required:!1,valid_types:"Float",info:"time requested to the scheduler during the test for finding the best parallelization parameters."},{name:"cmdline_cp",required:!1,valid_types:"List, NoneType",info:"additional command line parameters of the cp verlet caclulations only (for example parallelization options)"},{name:"default_nose_frequency",required:!1,valid_types:"Float",info:"default nose frequency when a frequency cannot be estimated from the vibrational spectrum"},{name:"dt",required:!1,valid_types:"Float, NoneType",info:"timestep in atomic units, if not automatically chosen."},{name:"dt_start_stop_step",required:!1,valid_types:"List",info:"list of timesteps to try. Timesteps are changed to better integrate the equation of motion. When a new electronic mass is selected by this workchain timesteps are automatically adjusted."},{name:"emass",required:!1,valid_types:"Float, NoneType",info:"electronic mass, atomic mass units, if not automatically chosen"},{name:"emass_list",required:!1,valid_types:"List",info:"list of electronic masses to try. The emass is selected in order to satisfy the requested CP/DFT force ratio."},{name:"initial_atomic_velocities_A_ps",required:!1,valid_types:"ArrayData, NoneType",info:"optional input initial velocities in angstrom over picoseconds"},{name:"max_slope_const",required:!1,valid_types:"Float",info:"max slope in K/ps of the constant of motion linear fit."},{name:"max_slope_ekinc",required:!1,valid_types:"Float",info:"max slope in K/ps of the ekinc linear fit. If not satisfied try to change emass"},{name:"max_slope_min_emass",required:!1,valid_types:"Float",info:"minimum possible value of electronic mass that can be set by the max_slope correction routine. Will not go lower than that."},{name:"max_slope_min_ps",required:!1,valid_types:"Float",info:"minimum required lenght in ps of the last trajectory to do the linear fit on ekinc and const of motion"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_traj_steps_vdos",required:!1,valid_types:"Int",info:"minimum number of steps to consider the calculated vibrational spectrum maximum valid, to set the thermostat frequency"},{name:"minimum_nose_frequency",required:!1,valid_types:"Float",info:"minimum nose frequency: if the frequency estimated from the vibrational spectrum is lower than this value, this value is used"},{name:"nstep_initial_cg",required:!1,valid_types:"Int",info:"At the beginning of the simulation the CP algorithm is not used. This is the number of steps to do using Born-Oppenheimer molecular dynamics algorithm with a conjugate gradient minimization of the electronic ground state."},{name:"nstep_parallel_test",required:!1,valid_types:"Int",info:"the benchmark simulations will be that long, if performed"},{name:"number_of_pw_per_trajectory",required:!1,valid_types:"Int",info:"Number of pw submitted for every trajectory during calculation of force ratio."},{name:"nve_required_picoseconds",required:!1,valid_types:"Float",info:"The equilibrated NVE simulation will last at least this number of picoseconds. How much picoseconds do you want?"},{name:"pressure_tolerance",required:!1,valid_types:"Float",info:"Pressure tolerance in kBar used to say if the npt is equilibrated. If not setted, use the standard deviation of the P time series"},{name:"skip_emass_dt_test",required:!1,valid_types:"Bool",info:""},{name:"skip_parallel_test",required:!1,valid_types:"Bool",info:"do not run run benchmarks to discover a good internal Quantum Espresso parallelization scheme for the current system"},{name:"skip_thermobarostat",required:!1,valid_types:"Bool",info:""},{name:"structure_kinds",required:!1,valid_types:"List, NoneType",info:'These kinds will be used to override or set the masses of the various atomic types. Note that the workflow, if skip_emass_dt_test is True, will calculate the ratio between cp forces and pw forces and adjust the provided masses automatically according to this ratio. So if you provide this input, make sure to set skip_emass_dt_test to True and set also the inputs emass and dt, or "bad things can happen"'},{name:"target_force_ratio",required:!1,valid_types:"Float",info:"The forces calculated by the Car-Parrinello method are affected by two types of error: one is due to the oscillations of the electrons around the DFT energy minimum, and the second is due to the finite mass of the electronic fluid that produces a _sistematic_ error in the forces, as if the electrons add mass to the ionic core. This second kind of error is can be controlled by this parameter, that tries to adjust the electronic mass to obtain the desidered ratio between CP forces and true DFT forces. Then you may want to modify the ionic mass to correct the leading factor of this error."},{name:"temperature_tolerance",required:!1,valid_types:"Float",info:"Temperature tolerance in K used to say if the npt is equilibrated. If not setted, use the standard deviation of the T time series"},{name:"tempw_initial_random",required:!1,valid_types:"Float, NoneType",info:"If provided, sets the initial temperature when randomly initializing the starting velocities."}],outputs:[{name:"cmdline_cp",required:!0,valid_types:"",info:""},{name:"dt",required:!0,valid_types:"",info:""},{name:"emass",required:!0,valid_types:"",info:""},{name:"full_traj",required:!0,valid_types:"",info:""},{name:"kinds",required:!0,valid_types:"",info:""},{name:"nve_prod_traj",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The initial cg steps failed. I cannot start to work."},{status:402,message:"Nose-Hoover thermostat failed."},{status:403,message:"Final cg after Nose-Hoover failed."},{status:404,message:"Error in the NVE simulation"},{status:405,message:"The simulations are calculating very expensive random numbers. There is something wrong (cutoff? metal? boo?)"},{status:406,message:"Wrong input parameters"},{status:407,message:"Parallel test was not succesful, maybe there is something more wrong."},{status:408,message:"Multiple errors in the simulation that cannot fix."},{status:409,message:"This is a bug in the workchain."}]},class:"aiida_QECpWorkChain.workflow:CpWorkChain"}}},commits_count:5,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/rikigigi/aiida-QECpWorkChain",is_installable:"True"},"aiida-abinit":{code_home:"https://github.com/sponce24/aiida-abinit",entry_point_prefix:"abinit",pip_url:"aiida-abinit",plugin_info:"https://raw.github.com/sponce24/aiida-abinit/master/setup.json",name:"aiida-abinit",package_name:"aiida_abinit",hosted_on:"github.com",metadata:{release_date:"2023-02-03",description:"The AiiDA plugin for ABINIT.",author_email:"Samuel Ponce <samuel.pon@gmail.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"0.4.0"},aiida_version:">=1.6.3,<1.7.0",entry_points:{"aiida.calculations":{abinit:{description:["AiiDA calculation plugin wrapping the abinit executable."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The k-point mesh or path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The ABINIT input parameters."},{name:"pseudos",required:!0,valid_types:"Psp8Data, JthXmlData",info:"The pseudopotentials."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData",info:"A remote folder used for restarts."},{name:"settings",required:!1,valid_types:"Dict",info:"Various special settings."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Various output quantities."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Final electronic bands if present."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final structure of the calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:"Trajectory of various output quantities over the calculation if present."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"Calculation did not produce all expected output files."},{status:101,message:"Calculation did not produce the expected `[prefix]o_GSR.nc` output file."},{status:102,message:"Calculation did not produce the expected `[prefix]o_HIST.nc` output file."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the `stdout` output file."},{status:301,message:"The `stdout` output file could not be read."},{status:302,message:"The `stdout` output file could not be parsed."},{status:303,message:"The `abipy` `EventsParser` reports that the runw as not completed."},{status:304,message:"The output file contains one or more error messages."},{status:305,message:"The output file contains one or more warning messages."},{status:312,message:"The output structure could not be parsed."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:500,message:"The SCF minimization cycle did not converge."},{status:501,message:"The ionic minimization cycle did not converge."}]},class:"aiida_abinit.calculations:AbinitCalculation"}},"aiida.parsers":{abinit:"aiida_abinit.parsers:AbinitParser"},"aiida.workflows":{"abinit.base":{description:["Base Abinit Workchain to perform a DFT calculation. Validates parameters and restart."],spec:{inputs:[{name:"abinit",required:!0,valid_types:"",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"An explicit k-points mesh or list. Either this or `kpoints_distance` must be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-point mesh will be generated automatically by a calculation function based on the input structure."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Various output quantities."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Final electronic bands if present."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final structure of the calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:"Trajectory of various output quantities over the calculation if present."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"`pseudos` could not be used to get the necessary pseudos."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:203,message:"Neither the `options` nor `automatic_parallelization` input was specified."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_abinit.workflows.base:AbinitBaseWorkChain"}}},commits_count:11,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-abinit",is_installable:"True"},"aiida-aenet":{code_home:"https://gitlab.com/lattice737/aiida-aenet",development_status:"planning",entry_point_prefix:"aenet",pip_url:"https://gitlab.com/lattice737/aiida-aenet",name:"aiida-aenet",package_name:"aiida_aenet",hosted_on:"gitlab.com",metadata:{author:"Nicholas Martinez",author_email:"nicholasmartinez@my.unt.edu",version:"0.1.0",description:"AiiDA plugin to construct machine-learning potentials using aenet",classifiers:["Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Development Status :: 0 - Alpha"]},aiida_version:"~=1.2",entry_points:{"aiida.data":{"aenet.algorithm":"aiida_aenet.data.algorithm:AenetAlgorithm","aenet.potential":"aiida_aenet.data.potentials:AenetPotential"},"aiida.calculations":{"aenet.cur":"aiida_aenet.calculations.cur:CurCalculation","aenet.generate":"aiida_aenet.calculations.generate:AenetGenerateCalculation","aenet.predict":"aiida_aenet.calculations.predict:AenetPredictCalculation","aenet.simulate":"aiida_aenet.calculations.simulate:AenetLammpsMdCalculation","aenet.train":"aiida_aenet.calculations.train:AenetTrainCalculation","aenet.transform":"aiida_aenet.calculations.transform:TransformCalculation"},"aiida.parsers":{"aenet.generate":"aiida_aenet.parsers.generate:AenetGenerateParser","aenet.predict":"aiida_aenet.parsers.predict:AenetPredictParser","aenet.simulate":"aiida_aenet.parsers.simulate:AenetLammpsMdParser","aenet.train":"aiida_aenet.parsers.train:AenetTrainParser"},"aiida.workflows":{"aenet.build_reference":"aiida_aenet.workflows.build_reference:BuildReferenceWorkChain","aenet.compare_simulations":"aiida_aenet.workflows.compare_simulations:CompareSimulationsWorkChain","aenet.make_potential":"aiida_aenet.workflows.make_potential:MakePotentialWorkChain","aenet.make_structures":"aiida_aenet.workflows.make_structures:MakeStructuresWorkChain"},"aenet.potentials":{"lammps.ann":"aiida_aenet.data.potentials.lammps:ANN"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:4},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:4},{colorclass:"orange",text:"Other (Aenet potentials)",count:1}],pip_install_cmd:"pip install https://gitlab.com/lattice737/aiida-aenet"},"aiida-alloy":{code_home:"https://github.com/DanielMarchand/aiida-alloy",development_status:"beta",entry_point_prefix:"alloy",pip_url:"git+https://github.com/DanielMarchand/aiida-alloy",name:"aiida-alloy",package_name:"aiida_alloy",hosted_on:"github.com",metadata:{author:"The AiiDA developers group",author_email:"",version:"0.1.0a0",description:"Aiida Workflows for Elastic Constants using Quantum Espresso",classifiers:["Programming Language :: Python"]},aiida_version:">=1.0.0a0",entry_points:{"aiida.workflows":{elastic:"aiida_alloy.workflows.ElasticWorkChain:ElasticWorkChain"}},commits_count:1,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'elastic' does not start with prefix 'alloy.'"],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/DanielMarchand/aiida-alloy",is_installable:"False",errors:[`Failed to install plugin aiida-alloy
Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-798msj2t
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-798msj2t
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-798msj2t/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
`]},"aiida-ase":{code_home:"https://github.com/aiidateam/aiida-ase",documentation_url:"https://aiida-ase.readthedocs.io/",entry_point_prefix:"ase",pip_url:"aiida-ase",plugin_info:"https://raw.github.com/aiidateam/aiida-ase/master/setup.json",name:"aiida-ase",package_name:"aiida_ase",hosted_on:"github.com",metadata:{release_date:"2023-03-17",description:"The official AiiDA plugin for ASE.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"2.0.0"},aiida_version:">=1.6,<2.0",entry_points:{"aiida.calculations":{"ase.ase":{description:["`CalcJob` implementation that can be used to wrap around the ASE calculators."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the namelists."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The k-points to use for the calculation."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"settings",required:!1,valid_types:"Dict",info:"Optional settings that control the plugin."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array",required:!1,valid_types:"ArrayData",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:""},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"One of the expected output files was missing."},{status:301,message:"The log file from the DFT code was not written out."},{status:302,message:"Relaxation did not complete."},{status:303,message:"SCF Failed."},{status:305,message:"Cannot identify what went wrong."},{status:306,message:"gpaw could not find the PAW potentials."},{status:307,message:"Attribute Error found in the stderr file."},{status:308,message:"Fermi level is infinite."},{status:400,message:"The calculation ran out of walltime."}]},class:"aiida_ase.calculations.ase:AseCalculation"}},"aiida.parsers":{"ase.ase":"aiida_ase.parsers.ase:AseParser","ase.gpaw":"aiida_ase.parsers.gpaw:GpawParser"},"aiida.workflows":{"ase.gpaw.base":{description:["Workchain to run a GPAW calculation with automated error handling and restarts."],spec:{inputs:[{name:"gpaw",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"k-points to use for the calculation."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array",required:!1,valid_types:"ArrayData",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:""},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_ase.workflows.base:GpawBaseWorkChain"}}},commits_count:7,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-ase",is_installable:"True"},"aiida-autocas":{entry_point_prefix:"autocas",code_home:"https://github.com/microsoft/aiida-autocas",version_file:"https://raw.githubusercontent.com/microsoft/aiida-autocas/main/aiida_autocas/__init__.py",pip_url:"git+https://github.com/microsoft/aiida-autocas",name:"aiida-autocas",package_name:"aiida_autocas",hosted_on:"github.com",metadata:{version:"0.1.0",description:"AiiDA AutoCAS Plugin",classifiers:[]},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{autocas:"aiida_autocas.calculations:AutoCASCalculation"},"aiida.parsers":{autocas:"aiida_autocas.parsers:AutoCASParser"}},commits_count:11,development_status:"planning",warnings:["Missing classifier 'Framework :: AiiDA'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/microsoft/aiida-autocas"},"aiida-bands-inspect":{code_home:"https://github.com/greschd/aiida-bands-inspect",documentation_url:"https://aiida-bands-inspect.readthedocs.io",entry_point_prefix:"bands_inspect",pip_url:"aiida-bands-inspect",name:"aiida-bands-inspect",package_name:"aiida_bands_inspect",hosted_on:"github.com",metadata:{release_date:"2020-03-26",description:"AiiDA Plugin for running bands_inspect",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-bands-inspect.readthedocs.io",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.4.0"},aiida_version:null,entry_points:{"aiida.calculations":{"bands_inspect.align":{description:["Calculation class for the ``bands-inspect align`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.data.array.bands.BandsData","        First band structure to compare.","    bands2 : aiida.orm.data.array.bands.BandsData","        Second band structure to compare."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be aligned"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be aligned"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands1_shifted",required:!0,valid_types:"BandsData",info:""},{name:"bands2_shifted",required:!0,valid_types:"BandsData",info:""},{name:"difference",required:!0,valid_types:"Float",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"shift",required:!0,valid_types:"Float",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"At least one of the expected output files is missing from the retrieved folder."},{status:220,message:"The text output file content is not in the expected format."}]},class:"aiida_bands_inspect.calculations.align:AlignCalculation"},"bands_inspect.difference":{description:["Calculation class for the ``bands-inspect difference`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.nodes.data.array.bands.BandsData","        First band structure to compare.","    bands2 : aiida.orm.nodes.data.array.bands.BandsData","        Second band structure to compare."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be compared"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be compared"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"difference",required:!0,valid_types:"Float",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder does not contain the difference output file."}]},class:"aiida_bands_inspect.calculations.difference:DifferenceCalculation"},"bands_inspect.plot":{description:["Calculation class for the ``bands_inspect plot`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.nodes.data.array.bands.BandsData","        First band structure to plot.","    bands2 : aiida.orm.nodes.data.array.bands.BandsData","        Second band structure to plot."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be plotted"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be plotted"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"plot",required:!0,valid_types:"SinglefileData",info:"The created band-structure comparison plot."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder does not contain the plot output file."}]},class:"aiida_bands_inspect.calculations.plot:PlotCalculation"}},"aiida.parsers":{"bands_inspect.bands":"aiida_bands_inspect.parsers.bands:BandsParser","bands_inspect.difference":"aiida_bands_inspect.parsers.difference:DifferenceParser","bands_inspect.align":"aiida_bands_inspect.parsers.align:AlignParser","bands_inspect.plot":"aiida_bands_inspect.parsers.plot:PlotParser"}},commits_count:0,development_status:"beta",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:4}],pip_install_cmd:"pip install aiida-bands-inspect",is_installable:"True"},"aiida-bigdft":{code_home:"https://github.com/BigDFT-group/aiida-bigdft-plugin",development_status:"beta",entry_point_prefix:"bigdft",pip_url:"aiida-bigdft",plugin_info:"https://raw.github.com/BigDFT-group/aiida-bigdft-plugin/master/setup.json",name:"aiida-bigdft",package_name:"aiida_bigdft",hosted_on:"github.com",metadata:{release_date:"2021-03-16",description:"Aiida plugin for BigDFT code",author:"The BigDFT Team",author_email:"bigdft-developers@lists.launchpad.net",license:"MIT",home_page:"https://github.com/BigDFT-group/aiida-bigdft-plugin",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.6"},aiida_version:">=1.1.1,<2.0.0",entry_points:{"aiida.calculations":{bigdft:{description:["AiiDA calculation plugin wrapping the BigDFT python interface."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"BigDFTParameters",info:"Command line parameters for BigDFT"},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:100,message:"Calculation did not produce all expected output files."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_bigdft.calculations.bigdft:BigDFTCalculation"},"bigdft.postscript":{description:["AiiDA calculation to add post treatments to a computation workcahin.","    post treatment scripts are to be registered as codes in aiida.","    They are python scripts accepting one argument : a remotefolder where data is stored","    Output files are not specified and can be added to the extra_retrieved_files list"],spec:{inputs:[{name:"bigdft_data_folder",required:!0,valid_types:"RemoteData",info:"Folder to the BigDFT data folder"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"retrieved_files",required:!1,valid_types:"List",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"Script execution failed"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_bigdft.calculations.postscript:ScriptCalculation"}},"aiida.cmdline.data":{bigdft:"aiida_bigdft.cli:data_cli"},"aiida.data":{bigdft:"aiida_bigdft.data:BigDFTParameters",bigdft_logfile:"aiida_bigdft.data:BigDFTLogfile"},"aiida.parsers":{bigdft:"aiida_bigdft.parsers:BigDFTParser"},"aiida.workflows":{bigdft:{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"BigDFTParameters",info:"Command line parameters for BigDFT"},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"run_opts",required:!1,valid_types:"Dict",info:"metadata"},{name:"show_warnings",required:!1,valid_types:"Bool",info:"turn the warnings on/off."},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"BigDFT input error"},{status:200,message:"BigDFT runtime error"},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_bigdft.workflows.base:BigDFTBaseWorkChain"},"bigdft.relax":{description:["Structure relaxation workchain."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"relax",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"BigDFTParameters",info:"param dictionary"},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"run_opts",required:!1,valid_types:"Dict",info:"metadata"},{name:"show_warnings",required:!1,valid_types:"Bool",info:"turn the warnings on/off."},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"forces",required:!1,valid_types:"ArrayData",info:""},{name:"relaxed_structure",required:!1,valid_types:"StructureData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"total_energy",required:!1,valid_types:"Float",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess failed for relaxation"}]},class:"aiida_bigdft.workflows.relax:BigDFTRelaxWorkChain"}}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:2},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-bigdft",is_installable:"True"},"aiida-castep":{code_home:"https://gitlab.com/bz1/aiida-castep",development_status:"stable",documentation_url:"https://aiida-castep.readthedocs.io/",entry_point_prefix:"castep",pip_url:"aiida-castep",plugin_info:"https://gitlab.com/bz1/aiida-castep/raw/master/setup.json",name:"aiida-castep",package_name:"aiida_castep",hosted_on:"gitlab.com",metadata:{release_date:"2022-05-26",description:"AiiDA plugin for CASTEP",author:"Bonan Zhu",author_email:"zhubonan@outlook.com",license:"MIT License",home_page:"https://github.com/zhubonan/aiida-castep",classifiers:["Framework :: AiiDA","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.1"},aiida_version:">=2.0,<3.0",entry_points:{"aiida.calculations":{"castep.castep":{description:["Class representing a generic CASTEP calculation -","    This class should work for all types of calculations."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"A node that defines the input parameters"},{name:"pseudos",required:!0,valid_types:"",info:"Use nodes for the pseudopotentails of one ofthe element in the structure. You should pass aa dictionary specifying the pseudpotential node foreach kind such as {O: <PsudoNode>}"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bs_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: bandstructure"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"elnes_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: elnes"},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Use a node defining the kpoints for the calculation"},{name:"magres_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: magres"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"optics_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: optics"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"phonon_fine_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"phonon_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"A node for additional settings"},{name:"spectral_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: spectral"},{name:"supercell_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Parsed results in a dictionary format."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation terminated gracefully, end found"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"SCF Cycles failed to reach convergence"},{status:103,message:"Stopped execuation due to detection of 'stop ' keyword in param file."},{status:104,message:"CASTEP generate error files. Check them for details"},{status:105,message:"Cannot find the end of calculation"},{status:106,message:"No output .castep files found"},{status:107,message:"Calculation self-terminated due to time limit"},{status:108,message:"No retrieve folder is found"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"UNKOWN ERROR"},{status:501,message:"At least one kpoints/spin has no empty bands - please rerun with increased nextra_bands."}]},class:"aiida_castep.calculations.castep:CastepCalculation"},"castep.ts":{description:["CASTEP calculation for transition state search. Use an extra input product structure."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"A node that defines the input parameters"},{name:"product_structure",required:!0,valid_types:"StructureData",info:"Product structure for transition state search."},{name:"pseudos",required:!0,valid_types:"",info:"Use nodes for the pseudopotentails of one ofthe element in the structure. You should pass aa dictionary specifying the pseudpotential node foreach kind such as {O: <PsudoNode>}"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bs_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: bandstructure"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"elnes_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: elnes"},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Use a node defining the kpoints for the calculation"},{name:"magres_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: magres"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"optics_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: optics"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"phonon_fine_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"phonon_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"A node for additional settings"},{name:"spectral_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: spectral"},{name:"supercell_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Parsed results in a dictionary format."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation terminated gracefully, end found"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"SCF Cycles failed to reach convergence"},{status:103,message:"Stopped execuation due to detection of 'stop ' keyword in param file."},{status:104,message:"CASTEP generate error files. Check them for details"},{status:105,message:"Cannot find the end of calculation"},{status:106,message:"No output .castep files found"},{status:107,message:"Calculation self-terminated due to time limit"},{status:108,message:"No retrieve folder is found"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"UNKOWN ERROR"},{status:501,message:"At least one kpoints/spin has no empty bands - please rerun with increased nextra_bands."}]},class:"aiida_castep.calculations.castep:CastepTSCalculation"}},"aiida.cmdline.data":{"castep-helper":"aiida_castep.cmdline.helper_cmd:helper_cmd","castep-pseudos":"aiida_castep.cmdline.otfg_cmd:pseudos_cmd"},"aiida.data":{"castep.otfgdata":"aiida_castep.data.otfg:OTFGData","castep.uspdata":"aiida_castep.data.usp:UspData"},"aiida.groups":{"castep.otfg":"aiida_castep.data.otfg:OTFGGroup"},"aiida.parsers":{"castep.castep":"aiida_castep.parsers.castep:CastepParser"},"aiida.tests":{"castep.calculation":"aiida_castep.tests.dbtests.dbtestcalculation"},"aiida.tools.calculations":{"castep.castep":"aiida_castep.calculations.tools:CastepCalcTools"},"aiida.workflows":{"castep.altrelax":{description:["A relaxation workflow that alternates between fixed cell and unfixed cell","    This is meidate the problem in CASTEP where if the cell is partially constraints","    the convergence would be very slow.","","    To overcome this problem, the structure should be relaxed with cell constraints","    then restart with fixed cell and repeat.","","    Following fields can be used in ``relax_options``","","    :var_cell_iter_max: Maximum iterations in variable cell relaxation, default to 10","","    :fix_cell_iter_max: Maximum iterations in fixed cell relaxation, default to 20"],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:""},{name:"calc",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for relaxation."},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations at the end of the workchain. The default is not performing any cleaning."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax_options",required:!1,valid_types:"Dict, NoneType",info:"Options for relaxation."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess lauched has failed in the relax stage"},{status:102,message:"Geometry optimisation is not converged but the maximum iteration is exceeded."},{status:201,message:"NO cell_constraints find in the input"}]},class:"aiida_castep.workflows.relax:CastepAlterRelaxWorkChain"},"castep.bands":{description:["Workchain for running bands calculation.","","    This workchain does the following:","","    1. Relax the structure if requested (eg. inputs passed to the relax namespace).","    2. Optionally: Do a SCF singlepoint calculation","    3. Do combined SCF + non-SCF calculation for bands and dos.","","    Inputs must be passed for the SCF calculation (dispatched to bands and DOS),","    others are optional.","","    Input for bands and dos calculations are optional. However, if they are needed, the full list of inputs must","    be passed. For the `parameters` node, one may choose to only specify those fields that need to be updated."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:"Inputs for SCF workchain, mandatory. Used as template for bands/dos if not supplied separately"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bands",required:!1,valid_types:"Data",info:"Inputs for bands calculation, if needed"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Explicit kpoints for the bands"},{name:"bands_kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"Spacing for band distances, used by seekpath"},{name:"clean_children_workdir",required:!1,valid_types:"Str, NoneType",info:"What part of the called children to clean"},{name:"dos",required:!1,valid_types:"Data",info:"Inputs for DOS calculation, if needed"},{name:"dos_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Kpoints for running DOS calculations"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"only_dos",required:!1,valid_types:"",info:"Flag for running only DOS calculations"},{name:"options",required:!1,valid_types:"",info:"Options for this workchain. Supported keywords: dos_smearing, dos_npoints."},{name:"relax",required:!1,valid_types:"Data",info:"Inputs for Relaxation workchain, if needed"},{name:"run_separate_scf",required:!1,valid_types:"",info:"Flag for running a separate SCF calculation, default to False"}],outputs:[{name:"band_structure",required:!0,valid_types:"",info:"Computed band structure with labels"},{name:"dos_bands",required:!1,valid_types:"",info:"Bands from the DOS calculation"},{name:"primitive_structure",required:!1,valid_types:"",info:"Primitive structure used for band structure calculations"},{name:"seekpath_parameters",required:!1,valid_types:"",info:"Parameters used by seekpath"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:501,message:"Relaxation workchain failed"},{status:502,message:"SCF workchain failed"},{status:503,message:"Band structure workchain failed"},{status:504,message:"DOS workchain failed"}]},class:"aiida_castep.workflows.bands:CastepBandsWorkChain"},"castep.base":{description:["A basic workchain for generic CASTEP calculations.","    We try to handle erros such as walltime exceeded or SCF not converged"],spec:{inputs:[{name:"calc",required:!0,valid_types:"Data",info:""},{name:"calc_options",required:!1,valid_types:"Dict, NoneType",info:"Options to be passed to calculations's metadata.options"},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations or not, the default is not clean."},{name:"continuation_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"ensure_gamma_centering",required:!1,valid_types:"Bool, NoneType",info:"Ensure the kpoint grid is gamma centred."},{name:"kpoints_spacing",required:!1,valid_types:"Float, NoneType",info:"Kpoint spacing"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of restarts"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Options specific to the workchain.Avaliable options: queue_wallclock_limit, use_castep_bin"},{name:"pseudos_family",required:!1,valid_types:"Str, NoneType",info:"Pseudopotential family to be used"},{name:"reuse_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"The maximum number of iterations has been exceeded"},{status:201,message:"The maximum length of the wallclocks has been exceeded"},{status:301,message:"CASTEP generated error files and is not recoverable"},{status:302,message:"Cannot reach SCF convergence despite restart efforts"},{status:400,message:"The stop flag has been put in the .param file to request termination of the calculation."},{status:900,message:"Input validate is failed"},{status:901,message:"Completed one iteration but found not calculation returned"},{status:1e3,message:"Error is not known"}]},class:"aiida_castep.workflows.base:CastepBaseWorkChain"},"castep.relax":{description:["WorkChain to relax structures.","    Restart the relaxation calculation until the structure is fully relaxed.","    Each CASTEP relaxation may finish without error with not fully relaxed structure","    if the number of iteration is exceeded (*geom_max_iter*).","    This workchain try to restart such calculations (wrapped in CastepBaseWorkChain)","    until the structure is fully relaxed","","    ``relax_options`` is a Dict of the options avaliable fields are:","","    - restart_mode: mode of restart, choose from ``reuse`` (default), ``structure``,","      ``continuation``.","    - bypass: Bypass relaxation control - e.g. no checking of the convergence.","      Can be used for doing singlepoint calculation."],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:""},{name:"calc",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for relaxation."},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations at the end of the workchain. The default is not performing any cleaning."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax_options",required:!1,valid_types:"Dict, NoneType",info:"Options for relaxation."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess lauched has failed in the relax stage"},{status:102,message:"Geometry optimisation is not converged but the maximum iteration is exceeded."}]},class:"aiida_castep.workflows.relax:CastepRelaxWorkChain"}},console_scripts:{"castep.mock":"aiida_castep.cmdline.mock_castep:mock_castep"}},commits_count:6,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:4},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Groups, Tests, ...)",count:5}],pip_install_cmd:"pip install aiida-castep",is_installable:"True"},"aiida-catmap":{code_home:"https://github.com/sudarshanv01/aiida-catmap",entry_point_prefix:"catmap",name:"aiida-catmap",package_name:"aiida_catmap",hosted_on:"github.com",metadata:{author:"Sudarshan Vijay",author_email:"vijays@fysik.dtu.dk",version:"0.2.0a0",description:"AiiDA package that interfaces with Kinetic modelling code CatMAP",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.calculations":{catmap:"aiida_catmap.calculations.catmap:CatMAPCalculation"},"aiida.parsers":{catmap:"aiida_catmap.parsers.catmap:CatMAPParser"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"See source code repository."},"aiida-catmat":{code_home:"https://github.com/pzarabadip/aiida-catmat",entry_point_prefix:"catmat",development_status:"beta",documentation_url:"https://aiida-catmat.readthedocs.io/",pip_url:"aiida-catmat",name:"aiida-catmat",package_name:"aiida_catmat",hosted_on:"github.com",metadata:{release_date:"2022-07-21",description:"Collection of AiiDA WorkChains Developed in Morgan Group",author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",license:"MIT License",home_page:"https://github.com/pzarabadip/aiida-catmat",classifiers:["Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.0.0b0"},aiida_version:null,entry_points:{"aiida.parsers":{vasp_base_parser:"aiida_catmat.parsers:VaspBaseParser"},"aiida.workflows":{"vasp.base":"aiida_catmat.workchains:VaspBaseWorkChain","catmat.vasp_multistage":"aiida_catmat.workchains:VaspMultiStageWorkChain","catmat.vasp_converge":"aiida_catmat.workchains:VaspConvergeWorkChain","catmat.vasp_catmat":"aiida_catmat.workchains:VaspCatMatWorkChain","catmat.vasp_multistage_ddec":"aiida_catmat.workchains:VaspMultiStageDdecWorkChain"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'vasp_base_parser' does not start with prefix 'catmat.'","Entry point 'vasp.base' does not start with prefix 'catmat.'"],summaryinfo:[{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:5}],pip_install_cmd:"pip install --pre aiida-catmat",is_installable:"False",errors:[`Failed to install plugin aiida-catmat
Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
`]},"aiida-ce":{code_home:"https://github.com/unkcpz/aiida-ce",development_status:"beta",entry_point_prefix:"ce",pip_url:"git+https://github.com/unkcpz/aiida-ce",name:"aiida-ce",package_name:"aiida_ce",hosted_on:"github.com",metadata:{author:"unkcpz",author_email:"morty.yu@yahoo.com",version:"0.1.0a0",description:"AiiDA plugin for running cluster expansion using icet.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.0.0,<2.0.0",entry_points:{"aiida.data":{ce:"aiida_ce.data:DiffParameters","ce.structures":"aiida_ce.data.structure_set:StructureSet","ce.cluster":"aiida_ce.data.cluster:ClusterSpaceData"},"aiida.calculations":{"ce.genenum":"aiida_ce.calculations.genenum:EnumCalculation","ce.gensqs":"aiida_ce.calculations.gensqs:SqsCalculation","ce.train":"aiida_ce.calculations.train:TrainCalculation"},"aiida.parsers":{"ce.genenum":"aiida_ce.parsers.genenum:EnumParser","ce.gensqs":"aiida_ce.parsers.gensqs:SqsParser","ce.train":"aiida_ce.parsers.train:TrainParser"},"aiida.cmdline.data":{ce:"aiida_ce.cli:data_cli"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:3},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/unkcpz/aiida-ce",is_installable:"True"},"aiida-champ":{code_home:"https://github.com/TREX-CoE/aiida-champ",development_status:"beta",documentation_url:"http://aiida-champ.readthedocs.io/",entry_point_prefix:"champ",pip_url:"aiida-champ",name:"aiida-champ",package_name:"aiida_champ",hosted_on:"github.com",metadata:{release_date:"2021-12-27",description:"AiiDA plugin that wraps the vmc executable of CHAMP code for computing the total energy and much more stuff.",author:"Ravindra Shinde",author_email:"r.l.shinde@utwente.nl",license:"MIT",home_page:"https://github.com/neelravi/aiida-champ",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"1.2.6"},aiida_version:null,entry_points:{"aiida.data":{CHAMP:"aiida_champ.data:CHAMPParameters"},"aiida.calculations":{CHAMP:{description:["AiiDA calculation plugin wrapping the CHAMP's vmc executable.","","    aiida-champ can be used to manage the workflow of a vmc/dmc calculation of the CHAMP code.","","    Author :: Ravindra Shinde","    Email  :: r.l.shinde@utwente.nl"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"determinants",required:!0,valid_types:"SinglefileData",info:"Input determinants file"},{name:"filemain",required:!0,valid_types:"SinglefileData",info:"Input File"},{name:"molecule",required:!0,valid_types:"SinglefileData",info:"Molecule structure File"},{name:"ecp1",required:!1,valid_types:"SinglefileData",info:"Input ECP file for atom type 1"},{name:"ecp2",required:!1,valid_types:"SinglefileData",info:"Input ECP file for atom type 2"},{name:"jastrow",required:!1,valid_types:"SinglefileData",info:"Input jastrow file"},{name:"jastrowder",required:!1,valid_types:"SinglefileData",info:"Input jastrowder file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"numericalbasis1",required:!1,valid_types:"SinglefileData",info:"Input numerical basis file atom 1"},{name:"numericalbasis2",required:!1,valid_types:"SinglefileData",info:"Input numerical basis file atom 2"},{name:"numericalbasisinfo",required:!1,valid_types:"SinglefileData",info:"Input numerical basis information file"},{name:"orbitals",required:!1,valid_types:"SinglefileData",info:"Input orbitals file"},{name:"symmetry",required:!1,valid_types:"SinglefileData",info:"Input symmetry file"},{name:"trexio",required:!1,valid_types:"SinglefileData",info:"Input trexio hdf5 file"}],outputs:[{name:"Output",required:!0,valid_types:"SinglefileData",info:"Output file of the VMC/DMC calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"Energy",required:!1,valid_types:"Float",info:"Output total energy of the VMC/DMC calculation"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_champ.calculations:CHAMPCalculation"}},"aiida.parsers":{CHAMP:"aiida_champ.parsers:CHAMPParser"},"aiida.cmdline.data":{CHAMP:"aiida_champ.cli:data_cli"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-champ",is_installable:"True"},"aiida-codtools":{code_home:"https://github.com/aiidateam/aiida-codtools",documentation_url:"https://aiida-codtools.readthedocs.io/",entry_point_prefix:"codtools",pip_url:"aiida-codtools",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-codtools/master/setup.json",name:"aiida-codtools",package_name:"aiida_codtools",hosted_on:"github.com",metadata:{release_date:"2023-02-02",description:"The Official AiiDA plugin for the cod-tools package.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"3.1.0"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.calculations":{"codtools.cif_base":{description:["Generic `CalcJob` implementation that can easily be extended to work with any of the `cod-tools` scripts."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_base:CifBaseCalculation"},"codtools.cif_cell_contents":{description:["CalcJob plugin for the `cif_cell_contents` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"formulae",required:!0,valid_types:"Dict",info:"A dictionary of formulae present in the CIF."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cell_contents:CifCellContentsCalculation"},"codtools.cif_cod_check":{description:["CalcJob plugin for the `cif_cod_check` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"messages",required:!0,valid_types:"Dict",info:"Warning and error messages returned by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cod_check:CifCodCheckCalculation"},"codtools.cif_cod_deposit":{description:["CalcJob plugin for the `cif_cod_deposit` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:300,message:"The deposition failed for unknown reasons."},{status:310,message:"The deposition failed because the input was invalid."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."},{status:410,message:"The deposition failed because one or more CIFs already exist in the COD."},{status:420,message:"The structure is unchanged and so deposition is unnecessary."}]},class:"aiida_codtools.calculations.cif_cod_deposit:CifCodDepositCalculation"},"codtools.cif_cod_numbers":{description:["CalcJob plugin for the `cif_cod_numbers` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"numbers",required:!0,valid_types:"Dict",info:"Mapping of COD IDs found with their formula and count."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cod_numbers:CifCodNumbersCalculation"},"codtools.cif_filter":{description:["CalcJob plugin for the `cif_filter` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_filter:CifFilterCalculation"},"codtools.cif_select":{description:["CalcJob plugin for the `cif_select` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_select:CifSelectCalculation"},"codtools.cif_split_primitive":{description:["CalcJob plugin for the `cif_split_primitive` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cifs",required:!0,valid_types:"CifData",info:"The CIFs produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_split_primitive:CifSplitPrimitiveCalculation"},"codtools.primitive_structure_from_cif":{description:["Attempt to parse the given `CifData` and create a `StructureData` from it.","","    First the raw CIF file is parsed with the given `parse_engine`. The resulting `StructureData` is then passed through","    SeeKpath to try and get the primitive cell. If that is successful, important structural parameters as determined by","    SeeKpath will be set as extras on the structure node which is then returned as output.","","    :param cif: the `CifData` node","    :param parse_engine: the parsing engine, supported libraries 'ase' and 'pymatgen'","    :param symprec: a `Float` node with symmetry precision for determining primitive cell in SeeKpath","    :param site_tolerance: a `Float` node with the fractional coordinate distance tolerance for finding overlapping","        sites. This will only be used if the parse_engine is pymatgen","    :return: the primitive `StructureData` as determined by SeeKpath"],spec:{inputs:[{name:"cif",required:!0,valid_types:"Data",info:"the `CifData` node"},{name:"parse_engine",required:!0,valid_types:"Data",info:"the parsing engine, supported libraries 'ase' and 'pymatgen'"},{name:"site_tolerance",required:!0,valid_types:"Data",info:"a `Float` node with the fractional coordinate distance tolerance for finding overlapping\nsites. This will only be used if the parse_engine is pymatgen"},{name:"symprec",required:!0,valid_types:"Data",info:"a `Float` node with symmetry precision for determining primitive cell in SeeKpath"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_codtools.calculations.functions.primitive_structure_from_cif:primitive_structure_from_cif"}},"aiida.parsers":{"codtools.cif_base":"aiida_codtools.parsers.cif_base:CifBaseParser","codtools.cif_cell_contents":"aiida_codtools.parsers.cif_cell_contents:CifCellContentsParser","codtools.cif_cod_check":"aiida_codtools.parsers.cif_cod_check:CifCodCheckParser","codtools.cif_cod_deposit":"aiida_codtools.parsers.cif_cod_deposit:CifCodDepositParser","codtools.cif_cod_numbers":"aiida_codtools.parsers.cif_cod_numbers:CifCodNumbersParser","codtools.cif_split_primitive":"aiida_codtools.parsers.cif_split_primitive:CifSplitPrimitiveParser"},"aiida.workflows":{"codtools.cif_clean":{description:["WorkChain to clean a `CifData` node using the `cif_filter` and `cif_select` scripts of `cod-tools`.","","    It will first run `cif_filter` to correct syntax errors, followed by `cif_select` which will canonicalize the tags.","    If a group is passed for the `group_structure` input, the atomic structure library defined by the `engine` input","    will be used to parse the final cleaned `CifData` to construct a `StructureData` object, which will then be passed","    to the `SeeKpath` library to analyze it and return the primitive structure"],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CifData node that is to be cleaned."},{name:"cif_filter",required:!0,valid_types:"Data",info:""},{name:"cif_select",required:!0,valid_types:"Data",info:""},{name:"group_cif",required:!1,valid_types:"Group, NoneType",info:"An optional Group to which the final cleaned CifData node will be added."},{name:"group_structure",required:!1,valid_types:"Group, NoneType",info:"An optional Group to which the final reduced StructureData node will be added."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parse_engine",required:!1,valid_types:"Str",info:"The atomic structure engine to parse the cif and create the structure."},{name:"site_tolerance",required:!1,valid_types:"Float",info:"The fractional coordinate distance tolerance for finding overlapping sites (pymatgen only)."},{name:"symprec",required:!1,valid_types:"Float",info:"The symmetry precision used by SeeKpath for crystal symmetry refinement."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The cleaned CifData node."},{name:"structure",required:!1,valid_types:"StructureData",info:"The primitive cell structure created with SeeKpath from the cleaned CifData."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The CifFilterCalculation step failed."},{status:402,message:"The CifSelectCalculation step failed."},{status:410,message:"The cleaned CifData contains sites with unknown species."},{status:411,message:"The cleaned CifData defines no atomic sites."},{status:412,message:"The cleaned CifData defines sites with attached hydrogens with incomplete positional data."},{status:413,message:"The cleaned CifData defines sites with invalid atomic occupancies."},{status:414,message:"Failed to parse a StructureData from the cleaned CifData."},{status:420,message:"SeeKpath failed to determine the primitive structure."},{status:421,message:"SeeKpath detected inconsistent symmetry operations."}]},class:"aiida_codtools.workflows.cif_clean:CifCleanWorkChain"}},console_scripts:{"aiida-codtools":"aiida_codtools.cli:cmd_root"}},commits_count:4,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:9},{colorclass:"brown",text:"Parsers",count:6},{colorclass:"green",text:"Workflows",count:1},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-codtools",is_installable:"True"},"aiida-core":{code_home:"https://github.com/aiidateam/aiida-core",development_status:"stable",documentation_url:"https://aiida-core.readthedocs.io/",entry_point_prefix:"",package_name:"aiida",pip_url:"aiida-core",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-core/master/setup.json",name:"aiida-core",hosted_on:"github.com",metadata:{release_date:"2023-06-23",description:"AiiDA is a workflow manager for computational science with a strong focus on provenance, performance and extensibility.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"2.4.0"},aiida_version:"==2.4.0",entry_points:{"aiida.calculations":{"core.arithmetic.add":{description:["`CalcJob` implementation to add two numbers using bash for testing and demonstration purposes."],spec:{inputs:[{name:"x",required:!0,valid_types:"Int, Float",info:"The left operand."},{name:"y",required:!0,valid_types:"Int, Float",info:"The right operand."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"sum",required:!0,valid_types:"Int, Float",info:"The sum of the left and right operand."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:310,message:"The output file could not be read."},{status:320,message:"The output file contains invalid output."},{status:410,message:"The sum of the operands is a negative number."}]},class:"aiida.calculations.arithmetic.add:ArithmeticAddCalculation"},"core.templatereplacer":{description:["Simple stub of a plugin that can be used to replace some text in a given template.","    Can be used for many different codes, or as a starting point to develop a new plugin.","","    This simple plugin takes two node inputs, both of type Dict, with the labels","    'parameters' and 'template'","","    You can also add other SinglefileData nodes as input, that will be copied according to","    what is written in 'template' (see below).","","    * parameters: a set of parameters that will be used for substitution.","","    * template: can contain the following parameters:","","        * input_file_template: a string with substitutions to be managed with the format()","          function of python, i.e. if you want to substitute a variable called 'varname', you write","          {varname} in the text. See http://www.python.org/dev/peps/pep-3101/ for more","          details. The replaced file will be the input file.","","        * input_file_name: a string with the file name for the input. If it is not provided, no","          file will be created.","","        * output_file_name: a string with the file name for the output. If it is not provided, no","          redirection will be done and the output will go in the scheduler output file.","","        * cmdline_params: a list of strings, to be passed as command line parameters.","          Each one is substituted with the same rule of input_file_template. Optional","","        * input_through_stdin: if True, the input file name is passed via stdin. Default is False if missing.","","        * files_to_copy: if defined, a list of tuple pairs, with format ('link_name', 'dest_rel_path');","            for each tuple, an input link to this calculation is looked for, with link labeled 'link_label',","            and with file type 'Singlefile', and the content is copied to a remote file named 'dest_rel_path'","            Errors are raised in the input links are non-existent, or of the wrong type, or if there are","            unused input files.","","        * retrieve_temporary_files: a list of relative filepaths, that if defined, will be retrieved and","            temporarily stored in an unstored FolderData node that will be available during the","            Parser.parser_with_retrieved call under the key specified by the Parser.retrieved_temporary_folder key"],spec:{inputs:[{name:"template",required:!0,valid_types:"Dict",info:"A template for the input file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"files",required:!1,valid_types:"RemoteData, SinglefileData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters used to replace placeholders in the template."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The temporary retrieved folder data node could not be accessed."},{status:305,message:"The `template` input node did not specify the key `output_file_name`."},{status:310,message:"The output file could not be read from the retrieved folder."},{status:311,message:"A temporary retrieved file could not be read from the temporary retrieved folder."},{status:320,message:"The output file contains invalid output."}]},class:"aiida.calculations.templatereplacer:TemplatereplacerCalculation"},"core.transfer":{description:["Utility to copy files from different FolderData and RemoteData nodes into a single place.","","    The final destination for these files can be either the local repository (by creating a","    new FolderData node to store them) or in the remote computer (by leaving the files in a","    new remote folder saved in a RemoteData node).","","    Only files from the local computer and from remote folders in the same external computer","    can be moved at the same time with a single instance of this CalcJob.","","    The user needs to provide three inputs:","","        * ``instructions``: a dict node specifying which files to copy from which nodes.","        * ``source_nodes``: a dict of nodes, each with a unique identifier label as its key.","        * ``metadata.computer``: the computer that contains the remote files and will contain","          the final RemoteData node.","","    The ``instructions`` dict must have the ``retrieve_files`` flag. The CalcJob will create a","    new folder in the remote machine (``RemoteData``) and put all the files there and will either:","","        (1) leave them there (``retrieve_files = False``) or ...","        (2) retrieve all the files and store them locally in a ``FolderData``  (``retrieve_files = True``)","","    The `instructions` dict must also contain at least one list with specifications of which files","    to copy and from where. All these lists take tuples of 3 that have the following format:","","    .. code-block:: python","","        ( source_node_key, path_to_file_in_source, path_to_file_in_target)","","    where the ``source_node_key`` has to be the respective one used when providing the node in the","    ``source_nodes`` input nodes dictionary.","","","    The two main lists to include are ``local_files`` (for files to be taken from FolderData nodes)","    and ``remote_files`` (for files to be taken from RemoteData nodes). Alternatively, files inside","    of RemoteData nodes can instead be put in the ``symlink_files`` list: the only difference is that","    files from the first list will be fully copied in the target RemoteData folder, whereas for the","    files in second list only a symlink to the original file will be created there. This will only","    affect the content of the final RemoteData target folder, but in both cases the full file will","    be copied back in the local target FolderData (if ``retrieve_files = True``)."],spec:{inputs:[{name:"instructions",required:!0,valid_types:"Dict",info:"A dictionary containing the `retrieve_files` flag and at least one of the file lists:`local_files`, `remote_files` and/or `symlink_files`."},{name:"source_nodes",required:!0,valid_types:"FolderData, RemoteData",info:"All the nodes that contain files referenced in the instructions."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida.calculations.transfer:TransferCalculation"}},"aiida.calculations.importers":{"core.arithmetic.add":"aiida.calculations.importers.arithmetic.add:ArithmeticAddCalculationImporter"},"aiida.calculations.monitors":{"core.always_kill":"aiida.calculations.monitors.base:always_kill"},"aiida.cmdline.computer.configure":{"core.local":"aiida.transports.plugins.local:CONFIGURE_LOCAL_CMD","core.ssh":"aiida.transports.plugins.ssh:CONFIGURE_SSH_CMD"},"aiida.cmdline.data":{"core.array":"aiida.cmdline.commands.cmd_data.cmd_array:array","core.bands":"aiida.cmdline.commands.cmd_data.cmd_bands:bands","core.cif":"aiida.cmdline.commands.cmd_data.cmd_cif:cif","core.dict":"aiida.cmdline.commands.cmd_data.cmd_dict:dictionary","core.remote":"aiida.cmdline.commands.cmd_data.cmd_remote:remote","core.singlefile":"aiida.cmdline.commands.cmd_data.cmd_singlefile:singlefile","core.structure":"aiida.cmdline.commands.cmd_data.cmd_structure:structure","core.trajectory":"aiida.cmdline.commands.cmd_data.cmd_trajectory:trajectory","core.upf":"aiida.cmdline.commands.cmd_data.cmd_upf:upf"},"aiida.cmdline.data.structure.import":{},"aiida.data":{"core.array":"aiida.orm.nodes.data.array.array:ArrayData","core.array.bands":"aiida.orm.nodes.data.array.bands:BandsData","core.array.kpoints":"aiida.orm.nodes.data.array.kpoints:KpointsData","core.array.projection":"aiida.orm.nodes.data.array.projection:ProjectionData","core.array.trajectory":"aiida.orm.nodes.data.array.trajectory:TrajectoryData","core.array.xy":"aiida.orm.nodes.data.array.xy:XyData","core.base":"aiida.orm.nodes.data:BaseType","core.bool":"aiida.orm.nodes.data.bool:Bool","core.cif":"aiida.orm.nodes.data.cif:CifData","core.code":"aiida.orm.nodes.data.code.legacy:Code","core.code.containerized":"aiida.orm.nodes.data.code.containerized:ContainerizedCode","core.code.installed":"aiida.orm.nodes.data.code.installed:InstalledCode","core.code.portable":"aiida.orm.nodes.data.code.portable:PortableCode","core.dict":"aiida.orm.nodes.data.dict:Dict","core.enum":"aiida.orm.nodes.data.enum:EnumData","core.float":"aiida.orm.nodes.data.float:Float","core.folder":"aiida.orm.nodes.data.folder:FolderData","core.int":"aiida.orm.nodes.data.int:Int","core.jsonable":"aiida.orm.nodes.data.jsonable:JsonableData","core.list":"aiida.orm.nodes.data.list:List","core.numeric":"aiida.orm.nodes.data.numeric:NumericType","core.orbital":"aiida.orm.nodes.data.orbital:OrbitalData","core.remote":"aiida.orm.nodes.data.remote.base:RemoteData","core.remote.stash":"aiida.orm.nodes.data.remote.stash.base:RemoteStashData","core.remote.stash.folder":"aiida.orm.nodes.data.remote.stash.folder:RemoteStashFolderData","core.singlefile":"aiida.orm.nodes.data.singlefile:SinglefileData","core.str":"aiida.orm.nodes.data.str:Str","core.structure":"aiida.orm.nodes.data.structure:StructureData","core.upf":"aiida.orm.nodes.data.upf:UpfData"},"aiida.groups":{core:"aiida.orm.groups:Group","core.auto":"aiida.orm.groups:AutoGroup","core.import":"aiida.orm.groups:ImportGroup","core.upf":"aiida.orm.groups:UpfFamily"},"aiida.node":{data:"aiida.orm.nodes.data.data:Data",process:"aiida.orm.nodes.process.process:ProcessNode","process.calculation":"aiida.orm.nodes.process.calculation.calculation:CalculationNode","process.calculation.calcfunction":"aiida.orm.nodes.process.calculation.calcfunction:CalcFunctionNode","process.calculation.calcjob":"aiida.orm.nodes.process.calculation.calcjob:CalcJobNode","process.workflow":"aiida.orm.nodes.process.workflow.workflow:WorkflowNode","process.workflow.workchain":"aiida.orm.nodes.process.workflow.workchain:WorkChainNode","process.workflow.workfunction":"aiida.orm.nodes.process.workflow.workfunction:WorkFunctionNode"},"aiida.parsers":{"core.arithmetic.add":"aiida.parsers.plugins.arithmetic.add:ArithmeticAddParser","core.templatereplacer":"aiida.parsers.plugins.templatereplacer.parser:TemplatereplacerParser"},"aiida.schedulers":{"core.direct":"aiida.schedulers.plugins.direct:DirectScheduler","core.lsf":"aiida.schedulers.plugins.lsf:LsfScheduler","core.pbspro":"aiida.schedulers.plugins.pbspro:PbsproScheduler","core.sge":"aiida.schedulers.plugins.sge:SgeScheduler","core.slurm":"aiida.schedulers.plugins.slurm:SlurmScheduler","core.torque":"aiida.schedulers.plugins.torque:TorqueScheduler"},"aiida.storage":{"core.psql_dos":"aiida.storage.psql_dos.backend:PsqlDosBackend","core.sqlite_temp":"aiida.storage.sqlite_temp.backend:SqliteTempBackend","core.sqlite_zip":"aiida.storage.sqlite_zip.backend:SqliteZipBackend"},"aiida.tools.calculations":{},"aiida.tools.data.orbitals":{"core.orbital":"aiida.tools.data.orbital.orbital:Orbital","core.realhydrogen":"aiida.tools.data.orbital.realhydrogen:RealhydrogenOrbital"},"aiida.tools.dbexporters":{},"aiida.tools.dbimporters":{"core.cod":"aiida.tools.dbimporters.plugins.cod:CodDbImporter","core.icsd":"aiida.tools.dbimporters.plugins.icsd:IcsdDbImporter","core.materialsproject":"aiida.tools.dbimporters.plugins.materialsproject:MaterialsProjectImporter","core.mpds":"aiida.tools.dbimporters.plugins.mpds:MpdsDbImporter","core.mpod":"aiida.tools.dbimporters.plugins.mpod:MpodDbImporter","core.nninc":"aiida.tools.dbimporters.plugins.nninc:NnincDbImporter","core.oqmd":"aiida.tools.dbimporters.plugins.oqmd:OqmdDbImporter","core.pcod":"aiida.tools.dbimporters.plugins.pcod:PcodDbImporter","core.tcod":"aiida.tools.dbimporters.plugins.tcod:TcodDbImporter"},"aiida.transports":{"core.local":"aiida.transports.plugins.local:LocalTransport","core.ssh":"aiida.transports.plugins.ssh:SshTransport"},"aiida.workflows":{"core.arithmetic.add_multiply":{description:["Add two numbers and multiply it with a third."],spec:{inputs:[{name:"x",required:!0,valid_types:"Data",info:""},{name:"y",required:!0,valid_types:"Data",info:""},{name:"z",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida.workflows.arithmetic.add_multiply:add_multiply"},"core.arithmetic.multiply_add":{description:["WorkChain to multiply two numbers and add a third, for testing and demonstration purposes."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:""},{name:"x",required:!0,valid_types:"Int",info:""},{name:"y",required:!0,valid_types:"Int",info:""},{name:"z",required:!0,valid_types:"Int",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"result",required:!0,valid_types:"Int",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The result is a negative number."}]},class:"aiida.workflows.arithmetic.multiply_add:MultiplyAddWorkChain"}},console_scripts:{runaiida:"aiida.cmdline.commands.cmd_run:run",verdi:"aiida.cmdline.commands.cmd_verdi:verdi"}},commits_count:363,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:29},{colorclass:"green",text:"Workflows",count:2},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Calculations importers, Calculations monitors, Cmdline computer configure, ...)",count:47}],pip_install_cmd:"pip install aiida-core",is_installable:"True"},"aiida-cp2k":{code_home:"https://github.com/cp2k/aiida-cp2k",entry_point_prefix:"cp2k",pip_url:"aiida-cp2k",plugin_info:"https://raw.githubusercontent.com/cp2k/aiida-cp2k/master/setup.json",name:"aiida-cp2k",package_name:"aiida_cp2k",hosted_on:"github.com",metadata:{release_date:"2023-03-06",description:"The official AiiDA plugin for CP2K.",author:"The AiiDA team",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3"],version:"2.0.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{cp2k:{description:["This is a Cp2kCalculation, subclass of JobCalculation, to prepare input for an ab-initio CP2K calculation.","","    For information on CP2K, refer to: https://www.cp2k.org."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters."},{name:"basissets",required:!1,valid_types:"",info:"A dictionary of basissets to be used in the calculations: key is the atomic symbol, value is either a single basisset or a list of basissets. If multiple basissets for a single symbol are passed, it is mandatory to specify a KIND section with a BASIS_SET keyword matching the names (or aliases) of the basissets."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"file",required:!1,valid_types:"SinglefileData, StructureData",info:"Additional input files."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Input kpoint mesh."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Working directory of a previously ran calculation to restart from."},{name:"pseudos",required:!1,valid_types:"",info:"A dictionary of pseudopotentials to be used in the calculations: key is the atomic symbol, value is either a single pseudopotential or a list of pseudopotentials. If multiple pseudos for a single symbol are passed, it is mandatory to specify a KIND section with a PSEUDOPOTENTIAL keyword matching the names (or aliases) of the pseudopotentials."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional input parameters."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"The main input structure."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output dictionary containing results of the calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Computed electronic band structure."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required output file."},{status:301,message:"The output file could not be read."},{status:302,message:"The output file could not be parsed."},{status:303,message:"The output file was incomplete."},{status:304,message:'The output file contains the word "ABORT".'},{status:312,message:"The output structure could not be parsed."},{status:350,message:"The parser raised an unexpected exception."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"The maximum number of optimization steps reached."}]},class:"aiida_cp2k.calculations:Cp2kCalculation"}},"aiida.parsers":{cp2k_advanced_parser:"aiida_cp2k.parsers:Cp2kAdvancedParser",cp2k_base_parser:"aiida_cp2k.parsers:Cp2kBaseParser",cp2k_tools_parser:"aiida_cp2k.parsers:Cp2kToolsParser"},"aiida.workflows":{"cp2k.base":{description:["Workchain to run a CP2K calculation with automated error handling and restarts."],spec:{inputs:[{name:"cp2k",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output dictionary containing results of the calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"final_input_parameters",required:!1,valid_types:"Dict",info:"The input parameters used for the final calculation."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Computed electronic band structure."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed with a known unrecoverable error."},{status:400,message:"The calculation didn't produce any data to restart from."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_cp2k.workchains:Cp2kBaseWorkChain"}}},commits_count:23,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-cp2k",is_installable:"True"},"aiida-crystal-dft":{code_home:"https://github.com/tilde-lab/aiida-crystal-dft",development_status:"beta",documentation_url:"https://github.com/tilde-lab/aiida-crystal-dft",entry_point_prefix:"crystal_dft",pip_url:"git+https://github.com/tilde-lab/aiida-crystal-dft",name:"aiida-crystal-dft",package_name:"aiida_crystal_dft",hosted_on:"github.com",metadata:{description:`Yet another AiiDA plugin for CRYSTAL code, mainly intended for use with the cloud infrastructures
(currently, MPDS)`,classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Intended Audience :: Science/Research","Operating System :: OS Independent","Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Python :: 3.10","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Information Analysis"],author:"Andrey Sobolev, based on aiida-crystal17 plugin by Chris Sewell",author_email:"as@tilde.pro"},aiida_version:">=2.0.2",entry_points:{"aiida.data":{"crystal_dft.basis":"aiida_crystal_dft.data.basis:CrystalBasisData","crystal_dft.basis_family":"aiida_crystal_dft.data.basis_family:CrystalBasisFamilyData"},"aiida.calculations":{"crystal_dft.serial":{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"basis",required:!1,valid_types:"CrystalBasisData",info:""},{name:"basis_family",required:!1,valid_types:"CrystalBasisFamilyData, NoneType",info:""},{name:"guess_oxistates",required:!1,valid_types:"Bool, NoneType",info:""},{name:"high_spin_preferred",required:!1,valid_types:"Bool, NoneType",info:""},{name:"is_magnetic",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"spinlock_steps",required:!1,valid_types:"Int, NoneType",info:""},{name:"use_oxistates",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"oxidation_states",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"SCF calculation not converged"},{status:301,message:"Geometry optimization failed"},{status:302,message:"Unit cell not neutral"},{status:303,message:"Basis set linearly dependent"},{status:304,message:"Neighbour list too large"},{status:305,message:"No G-vectors left"},{status:306,message:"Collapsed geometry"},{status:307,message:"Closed shell run - spin polarization not allowed"},{status:308,message:"Parameters for model hessian not defined"},{status:309,message:"Fermi energy not in interval"},{status:310,message:"Insufficient indices for Madelung sums"},{status:350,message:"Internal memory error"},{status:360,message:"Inadequate elastic calculation: additional optimization needed"},{status:400,message:"Unknown error"},{status:401,message:"The retrieved folder data node could not be accessed"}]},class:"aiida_crystal_dft.calculations.serial:CrystalSerialCalculation"},"crystal_dft.parallel":{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"basis",required:!1,valid_types:"CrystalBasisData",info:""},{name:"basis_family",required:!1,valid_types:"CrystalBasisFamilyData, NoneType",info:""},{name:"guess_oxistates",required:!1,valid_types:"Bool, NoneType",info:""},{name:"high_spin_preferred",required:!1,valid_types:"Bool, NoneType",info:""},{name:"is_magnetic",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"spinlock_steps",required:!1,valid_types:"Int, NoneType",info:""},{name:"use_oxistates",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"oxidation_states",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"SCF calculation not converged"},{status:301,message:"Geometry optimization failed"},{status:302,message:"Unit cell not neutral"},{status:303,message:"Basis set linearly dependent"},{status:304,message:"Neighbour list too large"},{status:305,message:"No G-vectors left"},{status:306,message:"Collapsed geometry"},{status:307,message:"Closed shell run - spin polarization not allowed"},{status:308,message:"Parameters for model hessian not defined"},{status:309,message:"Fermi energy not in interval"},{status:310,message:"Insufficient indices for Madelung sums"},{status:350,message:"Internal memory error"},{status:360,message:"Inadequate elastic calculation: additional optimization needed"},{status:400,message:"Unknown error"},{status:401,message:"The retrieved folder data node could not be accessed"}]},class:"aiida_crystal_dft.calculations.parallel:CrystalParallelCalculation"},"crystal_dft.properties":{description:["AiiDA calculation plugin wrapping the properties executable."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"wavefunction",required:!0,valid_types:"SinglefileData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:""},{name:"output_bands_down",required:!1,valid_types:"BandsData",info:""},{name:"output_dos",required:!1,valid_types:"ArrayData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_crystal_dft.calculations.properties:PropertiesCalculation"}},"aiida.parsers":{crystal_dft:"aiida_crystal_dft.parsers.cry_pycrystal:CrystalParser","crystal_dft.properties":"aiida_crystal_dft.parsers.properties:PropertiesParser"},"aiida.workflows":{"crystal_dft.base":{description:["Run CRYSTAL calculation"],spec:{inputs:[{name:"basis_family",required:!0,valid_types:"CrystalBasisFamilyData",info:""},{name:"code",required:!0,valid_types:"Code",info:""},{name:"options",required:!0,valid_types:"Dict",info:"Calculation options"},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_params",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"oxidation_states",required:!1,valid_types:"Dict",info:""},{name:"primitive_structure",required:!1,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"CRYSTAL error"},{status:400,message:"Unknown error"}]},class:"aiida_crystal_dft.workflows.base:BaseCrystalWorkChain"}},"aiida.cmdline.data":{crystal_dft:"aiida_crystal_dft.cli.basis:basis_set"}},commits_count:18,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/tilde-lab/aiida-crystal-dft",is_installable:"True"},"aiida-crystal17":{code_home:"https://github.com/aiidaplugins/aiida-crystal17",development_status:"beta",documentation_url:"https://aiida-crystal17.readthedocs.io",entry_point_prefix:"crystal17",pip_url:"aiida-crystal17",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-crystal17/master/setup.json",name:"aiida-crystal17",package_name:"aiida_crystal17",hosted_on:"github.com",metadata:{release_date:"2020-09-29",description:"AiiDA plugin for running the CRYSTAL17 code",author:"Chris Sewell",author_email:"chrisj_sewell@hotmail.com",license:"MIT",home_page:"https://github.com/chrisjsewell/aiida-crystal17",classifiers:["Framework :: AiiDA","Programming Language :: Python","Programming Language :: Python :: 2.7","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"0.11.0"},aiida_version:">=1.4.0,<2.0.0",entry_points:{"aiida.calculations":{"crystal17.basic":{description:["AiiDA calculation plugin to run the crystal17 executable,","    by supplying a normal .d12 input file and (optional) .gui file"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"input_file",required:!0,valid_types:"SinglefileData",info:"the input .d12 file content."},{name:"input_external",required:!1,valid_types:"SinglefileData",info:"optional input fort.34 (gui) file content (for use with EXTERNAL keyword)."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:301,message:"An error occurred parsing the 'opta'/'optc' geometry files"},{status:302,message:"The crystal exec stdout file denoted that the run was a testgeom"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:411,message:"SCF convergence did not finalise (usually due to reaching step limit)"},{status:412,message:"Geometry convergence did not finalise (usually due to reaching step limit)"},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"},{status:510,message:"inconsistency in the input and output symmetry"},{status:520,message:"primitive symmops were not found in the output file"}]},class:"aiida_crystal17.calculations.cry_basic:CryBasicCalculation"},"crystal17.doss":{description:["AiiDA calculation plugin to run the ``properties`` executable,","    for DOSS calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"arrays",required:!1,valid_types:"ArrayData",info:"energies and DoS arrays"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output isovalue (fort.25) file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output isovalue (fort.25) file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_doss:CryDossCalculation"},"crystal17.ech3":{description:["AiiDA calculation plugin to run the ``properties`` executable, for 3D charge density (ECH3)."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"charge",required:!0,valid_types:"GaussianCube",info:"The charge density cube"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"spin",required:!1,valid_types:"GaussianCube",info:"The spin density cube"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output density file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output density file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_ech3:CryEch3Calculation"},"crystal17.main":{description:["AiiDA calculation plugin to run the crystal17 executable,","    by supplying aiida nodes, with data sufficient to create the","    .d12 input file and .gui file"],spec:{inputs:[{name:"basissets",required:!0,valid_types:"BasisSetData",info:"Use a node for the basis set of one of the elements in the structure. You have to pass an additional parameter ('element') specifying the atomic element symbol for which you want to use this basis set."},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"CryInputParamsData",info:"the input parameters to create the .d12 file content."},{name:"structure",required:!0,valid_types:"StructureData",info:"structure used to construct the input fort.34 (gui) file"},{name:"kinds",required:!1,valid_types:"KindData",info:"additional structure kind specific data (e.g. initial spin)"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry of the structure, used to construct the input .gui file (fort.34)"},{name:"wf_folder",required:!1,valid_types:"RemoteData",info:"An optional working directory, of a previously completed calculation, containing a fort.9 wavefunction file to restart from"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"optimisation",required:!1,valid_types:"TrajectoryData",info:"atomic configurations, for each optimisation step"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:301,message:"An error occurred parsing the 'opta'/'optc' geometry files"},{status:302,message:"The crystal exec stdout file denoted that the run was a testgeom"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:411,message:"SCF convergence did not finalise (usually due to reaching step limit)"},{status:412,message:"Geometry convergence did not finalise (usually due to reaching step limit)"},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"},{status:510,message:"inconsistency in the input and output symmetry"},{status:520,message:"primitive symmops were not found in the output file"}]},class:"aiida_crystal17.calculations.cry_main:CryMainCalculation"},"crystal17.newk":{description:["AiiDA calculation plugin to run the properties17 executable,","    for NEWK calculations (to return the fermi energy)"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_newk:CryNewkCalculation"},"crystal17.ppan":{description:["AiiDA calculation plugin to run the ``properties`` executable,","    for PPAN (Mulliken population analysis) calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output PPAN.dat file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output PPAN.dat file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_ppan:CryPpanCalculation"}},"aiida.cmdline.data":{"crystal17.basis":"aiida_crystal17.cmndline.basis_set:basisset","crystal17.parse":"aiida_crystal17.cmndline.cmd_parser:parse","crystal17.symmetry":"aiida_crystal17.cmndline.symmetry:symmetry"},"aiida.data":{"crystal17.basisset":"aiida_crystal17.data.basis_set:BasisSetData","crystal17.gcube":"aiida_crystal17.data.gcube:GaussianCube","crystal17.kinds":"aiida_crystal17.data.kinds:KindData","crystal17.parameters":"aiida_crystal17.data.input_params:CryInputParamsData","crystal17.symmetry":"aiida_crystal17.data.symmetry:SymmetryData"},"aiida.groups":{"crystal17.basisset":"aiida_crystal17.data.basis_set:BasisSetFamily"},"aiida.parsers":{"crystal17.doss":"aiida_crystal17.parsers.cry_doss:CryDossParser","crystal17.ech3":"aiida_crystal17.parsers.cry_ech3:CryEch3Parser","crystal17.main":"aiida_crystal17.parsers.cry_main:CryMainParser","crystal17.newk":"aiida_crystal17.parsers.cry_newk:CryNewkParser","crystal17.ppan":"aiida_crystal17.parsers.cry_ppan:CryPpanParser"},"aiida.workflows":{"crystal17.main.base":{description:["Workchain to run a standard CRYSTAL17 calculation,","    with automated error handling and restarts."],spec:{inputs:[{name:"cry",required:!0,valid_types:"",info:""},{name:"basis_family",required:!1,valid_types:"Str",info:"An alternative to specifying the basis sets manually: one can specify the name of an existing basis set family and the work chain will generate the basis sets automatically based on the input structure."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints_distance",required:!1,valid_types:"Float",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by the input structure, and will replace the SHRINK IS value in the input parameters.Note: This methods assumes the PRIMITIVE unit cell is provided"},{name:"kpoints_force_parity",required:!1,valid_types:"Bool",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"The parameters could not be validated against the jsonschema."},{status:202,message:"The explicit `basis_sets` or `basis_family` could not be used to get the necessary basis sets."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:320,message:"The initialization calculation failed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_crystal17.workflows.crystal_main.base:CryMainBaseWorkChain"},"crystal17.properties":{description:["A WorkChain to compute properties of a structure, using CRYSTAL.","","    Either a pre-computed wavefunction (fort.9) file,","    or inputs for a CryMainCalculation, should be supplied.","    Inputs for property calculations can then be added","    (currently available; doss, ech3)."],spec:{inputs:[{name:"check_remote",required:!1,valid_types:"Bool",info:"If a RemoteData wf_folder is input, check it contains the wavefunction file, before launching calculations. Note, this will fail if the remote computer is not immediately available"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"doss",required:!1,valid_types:"",info:""},{name:"ech3",required:!1,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"ppan",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"",info:""},{name:"test_run",required:!1,valid_types:"Bool",info:"break off the workchain before submitting a calculation"},{name:"wf_folder",required:!1,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"}],outputs:[{name:"doss",required:!1,valid_types:"",info:""},{name:"ech3",required:!1,valid_types:"",info:""},{name:"ppan",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"Workchain ended before submitting calculation."},{status:201,message:"Neither a wf_folder nor scf calculation was supplied."},{status:202,message:"No property calculation inputs were supplied."},{status:203,message:"The supplied folder does contain the wavefunction file."},{status:210,message:"The SCF calculation submission failed."},{status:301,message:"The SCF calculation failed."},{status:302,message:"One or more property calculations failed."}]},class:"aiida_crystal17.workflows.crystal_props.base:CryPropertiesWorkChain"},"crystal17.sym3d":{description:["modify an AiiDa structure instance and compute its symmetry","","    Inequivalent atomic sites are dictated by atom kinds"],spec:{inputs:[{name:"settings",required:!0,valid_types:"Dict",info:""},{name:"cif",required:!1,valid_types:"CifData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"structure",required:!1,valid_types:"StructureData",info:""}],outputs:[{name:"symmetry",required:!0,valid_types:"SymmetryData",info:""},{name:"structure",required:!1,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"one of either a structure or cif input must be supplied"},{status:301,message:'the supplied structure must be 3D (i.e. have all dimensions pbc=True)"'},{status:302,message:"idealize can only be used when standardize=True"},{status:303,message:"the kind names supplied are not compatible with the structure"},{status:304,message:"error creating new structure"},{status:305,message:"error computing symmetry operations"}]},class:"aiida_crystal17.workflows.symmetrise_3d_struct:Symmetrise3DStructure"}},console_scripts:{mock_crystal17:"aiida_crystal17.tests.mock_crystal17:main",mock_properties17:"aiida_crystal17.tests.mock_properties17:main"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:5},{colorclass:"red",text:"Data",count:5},{colorclass:"green",text:"Workflows",count:3},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:4}],pip_install_cmd:"pip install aiida-crystal17",is_installable:"True"},"aiida-cusp":{code_home:"https://github.com/aiida-cusp/aiida-cusp",documentation_url:"https://aiida-cusp.readthedocs.io",entry_point_prefix:"cusp",pip_url:"https://pypi.org/project/aiida-cusp",name:"aiida-cusp",package_name:"aiida_cusp",hosted_on:"github.com",metadata:{author:"Andreas Stamminger",author_email:"stammingera@gmail.com",version:"0.1.0b2",description:"Custodian based VASP Plugin for AiiDA",classifiers:["Development Status :: 4 - Beta","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Chemistry","Environment :: Plugins","Framework :: AiiDA"]},aiida_version:">=1.3.0,<2.0.0",entry_points:{"aiida.data":{"cusp.kpoints":"aiida_cusp.data.inputs.vasp_kpoint:VaspKpointData","cusp.poscar":"aiida_cusp.data.inputs.vasp_poscar:VaspPoscarData","cusp.incar":"aiida_cusp.data.inputs.vasp_incar:VaspIncarData","cusp.potcar":"aiida_cusp.data.inputs.vasp_potcar:VaspPotcarData","cusp.vasprun":"aiida_cusp.data.outputs.vasp_vasprun:VaspVasprunData","cusp.outcar":"aiida_cusp.data.outputs.vasp_outcar:VaspOutcarData","cusp.contcar":"aiida_cusp.data.outputs.vasp_contcar:VaspContcarData","cusp.chgcar":"aiida_cusp.data.outputs.vasp_chgcar:VaspChgcarData","cusp.wavecar":"aiida_cusp.data.outputs.vasp_wavecar:VaspWavecarData","cusp.generic":"aiida_cusp.data.outputs.vasp_generic:VaspGenericData","cusp.potcarfile":"aiida_cusp.data.inputs.vasp_potcar:VaspPotcarFile"},"aiida.calculations":{"cusp.vasp":"aiida_cusp.calculators.vasp_calculation:VaspCalculation"},"aiida.parsers":{"cusp.default":"aiida_cusp.parsers.vasp_file_parser:VaspFileParser"},"aiida.cmdline.data":{potcar:"aiida_cusp.cli.potcar_cmd:potcar"}},commits_count:30,development_status:"beta",warnings:["Entry point 'potcar' does not start with prefix 'cusp.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:11},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install https://pypi.org/project/aiida-cusp",is_installable:"False",errors:[`Failed to install plugin aiida-cusp
Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 15.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-pfx89340/aiida-cusp (downloaded from /tmp/pip-req-build-scgbjz4p, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-scgbjz4p
`]},"aiida-dataframe":{entry_point_prefix:"dataframe",plugin_info:"https://raw.github.com/janssenhenning/aiida-dataframe/main/pyproject.toml",code_home:"https://github.com/janssenhenning/aiida-dataframe",version_file:"https://raw.githubusercontent.com/janssenhenning/aiida-dataframe/main/aiida_dataframe/__init__.py",pip_url:"aiida-dataframe",documentation_url:"https://aiida-dataframe.readthedocs.io/en/latest/",name:"aiida-dataframe",package_name:"aiida_dataframe",hosted_on:"github.com",metadata:{release_date:"2023-05-05",description:"AiiDA data plugin for pandas DataFrame objects",author_email:"Henning Janßen <henning.janssen@gmx.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"0.1.3"},aiida_version:">=1.0,<3",entry_points:{"aiida.cmdline.data":{dataframe:"aiida_dataframe.cli:data_cli"},"aiida.data":{"dataframe.frame":"aiida_dataframe.data.dataframe:PandasFrameData"}},commits_count:11,development_status:"beta",summaryinfo:[{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-dataframe",is_installable:"True"},"aiida-ddec":{code_home:"https://github.com/lsmo-epfl/aiida-ddec",entry_point_prefix:"ddec",pip_url:"git+https://github.com/yakutovicha/aiida-ddec",name:"aiida-ddec",package_name:"aiida_ddec",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:13,development_status:"planning",warnings:["  > WARNING! Unable to retrieve plugin info from: https://raw.githubusercontent.com/lsmo-epfl/aiida-ddec/master/setup.json","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/yakutovicha/aiida-ddec"},"aiida-defects":{code_home:"https://github.com/epfl-theos/aiida-defects",entry_point_prefix:"defects",pip_url:"aiida-defects",plugin_info:"https://raw.githubusercontent.com/epfl-theos/aiida-defects/master/pyproject.toml",name:"aiida-defects",package_name:"aiida_defects",hosted_on:"github.com",metadata:{release_date:"2023-03-29",description:"AiiDA-Defects is a plugin for the AiiDA computational materials science framework, and provides tools and automated workflows for the study of defects in materials.",author:"The AiiDA-Defects developers",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"1.0.1"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{"defects.array.stability":"aiida_defects.data.data:StabilityData"},"aiida.workflows":{"defects.formation_energy.chemical_potential":"aiida_defects.formation_energy.chemical_potential.chemical_potential:ChemicalPotentialWorkchain","defects.formation_energy.corrections.gaussian_countercharge":"aiida_defects.formation_energy.corrections.gaussian_countercharge.gaussian_countercharge:GaussianCounterChargeWorkchain","defects.formation_energy.corrections.gaussian_countercharge.model_potential":"aiida_defects.formation_energy.corrections.gaussian_countercharge.model_potential.model_potential:ModelPotentialWorkchain","defects.formation_energy.corrections.point_countercharge":"aiida_defects.formation_energy.corrections.point_countercharge.point_countercharge:PointCounterChargeWorkchain","defects.formation_energy.potential_alignment":"aiida_defects.formation_energy.potential_alignment.potential_alignment:PotentialAlignmentWorkchain","defects.formation_energy.qe":"aiida_defects.formation_energy.formation_energy_qe:FormationEnergyWorkchainQE","defects.formation_energy.siesta":"aiida_defects.formation_energy.formation_energy_siesta:FormatonEnergyWorkchainSiesta"}},commits_count:10,development_status:"beta",summaryinfo:[{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:7}],pip_install_cmd:"pip install aiida-defects",is_installable:"True",errors:[`Failed to fetch entry point metadata for package aiida_defects
Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.9/site-packages/aiida/plugins/entry_point.py", line 239, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.9/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/conda/lib/python3.9/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.9/site-packages/aiida/plugins/entry_point.py", line 239, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.9/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
`]},"aiida-diff":{code_home:"https://github.com/aiidateam/aiida-diff",development_status:"stable",documentation_url:"https://aiida-diff.readthedocs.io/",entry_point_prefix:"diff",pip_url:"git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0",name:"aiida-diff",package_name:"aiida_diff",hosted_on:"github.com",metadata:{description:"AiiDA demo plugin that wraps the `diff` executable for computing the difference between two files.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 3 - Alpha","Framework :: AiiDA"],author:"The AiiDA Team"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{diff:"aiida_diff.data:DiffParameters"},"aiida.calculations":{diff:"aiida_diff.calculations:DiffCalculation"},"aiida.parsers":{diff:"aiida_diff.parsers:DiffParser"},"aiida.cmdline.data":{diff:"aiida_diff.cli:data_cli"}},commits_count:0,warnings:["Development status in classifiers (alpha) does not match development_status in metadata (stable)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0",is_installable:"False",errors:[`Failed to install plugin aiida-diff
Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-oo47x2fk/aiida-diff-0-1-0a0_d435db8ecf3b4e87b0fc8cb182426116
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-oo47x2fk/aiida-diff-0-1-0a0_d435db8ecf3b4e87b0fc8cb182426116
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: expected 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
`]},"aiida-donothing":{code_home:"https://github.com/atztogo/aiida-donothing",entry_point_prefix:"donothing",name:"aiida-donothing",package_name:"aiida_donothing",hosted_on:"github.com",metadata:{author:"Atsushi Togo",author_email:"atz.togo@gmail.com",version:"0.1",description:"AiiDA calculation plugin for doing nothing",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.5,<2.0.0",entry_points:{"aiida.calculations":{"donothing.donothing":"aiida_donothing.calculations.donothing:DoNothingCalculation"},"aiida.parsers":{"donothing.donothing":"aiida_donothing.parsers.donothing:DoNothingParser"}},commits_count:1,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"See source code repository."},"aiida-dynamic-workflows":{code_home:"https://github.com/microsoft/aiida-dynamic-workflows",entry_point_prefix:"dynamic_workflows",name:"aiida-dynamic-workflows",package_name:"aiida_dynamic_workflows",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-environ":{code_home:"https://github.com/environ-developers/aiida-environ",entry_point_prefix:"environ",pip_url:"git+https://github.com/environ-developers/aiida-environ",name:"aiida-environ",package_name:"aiida_environ",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",warnings:["  > WARNING! Unable to retrieve plugin info from: https://raw.github.com/environ-developers/aiida-environ/master/setup.json","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/environ-developers/aiida-environ"},"aiida-eon":{code_home:"https://github.com/HaoZeke/aiida-eon",entry_point_prefix:"eon",name:"aiida-eon",package_name:"aiida_eon",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-eonclient":{code_home:"https://github.com/HaoZeke/aiida-eonclient",entry_point_prefix:"eonclient",name:"aiida-eonclient",package_name:"aiida_eonclient",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-fenics":{code_home:"https://github.com/sphuber/aiida-fenics/tree/master",entry_point_prefix:"fenics",pip_url:"git+https://github.com/sphuber/aiida-fenics",name:"aiida-fenics",package_name:"aiida_fenics",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:-1,development_status:"planning",warnings:["  > WARNING! Unable to retrieve plugin info from: https://raw.github.com/sphuber/aiida-fenics/master/setup.json","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/sphuber/aiida-fenics"},"aiida-firecrest":{code_home:"https://github.com/aiidateam/aiida-firecrest",entry_point_prefix:"firecrest",pip_url:"aiida-firecrest",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-firecrest/main/pyproject.toml",name:"aiida-firecrest",package_name:"aiida_firecrest",hosted_on:"github.com",metadata:{release_date:"2022-01-14",description:"AiiDA Transport/Scheduler plugins for interfacing with FirecREST.",author_email:"Chris Sewell <chrisj_sewell@hotmail.com>",classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Python :: Implementation :: CPython","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.1.0a1"},aiida_version:"<2",entry_points:{"aiida.schedulers":{firecrest:"aiida_firecrest.scheduler:FirecrestScheduler"},"aiida.transports":{firecrest:"aiida_firecrest.transport:FirecrestTransport"},console_scripts:{"aiida-firecrest-cli":"aiida_firecrest.cli:main"}},commits_count:19,development_status:"alpha",summaryinfo:[{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Schedulers, Transports)",count:2}],pip_install_cmd:"pip install --pre aiida-firecrest",is_installable:"True"},"aiida-fireworks-scheduler":{code_home:"https://github.com/zhubonan/aiida-fireworks-scheduler",development_status:"beta",documentation_url:"https://aiida-fireworks-scheduler.readthedocs.io",entry_point_prefix:"fireworks_scheduler",pip_url:"git+https://github.com/zhubonan/aiida-fireworks-scheduler",name:"aiida-fireworks-scheduler",package_name:"aiida_fireworks_scheduler",hosted_on:"github.com",metadata:{author:"Bonan Zhu",author_email:"zhubonan@outlook.com",version:"1.2.0",description:"AiiDA plugin to allow using `fireworks` as the execution engine for `CalcJob`.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:null,entry_points:{"aiida.schedulers":{fireworks:"aiida_fireworks_scheduler.fwscheduler:FwScheduler","fireworks_scheduler.default":"aiida_fireworks_scheduler.fwscheduler:FwScheduler","fireworks_scheduler.keepenv":"aiida_fireworks_scheduler.fwscheduler:FwSchedulerKeepEnv"},"aiida.cmdline.data":{"fireworks-scheduler":"aiida_fireworks_scheduler.cmdline:fw_cli"},console_scripts:{arlaunch:"aiida_fireworks_scheduler.scripts.arlaunch_run:arlaunch"}},commits_count:0,warnings:["AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'fireworks' does not start with prefix 'fireworks_scheduler.'","Entry point 'fireworks-scheduler' does not start with prefix 'fireworks_scheduler.'"],summaryinfo:[{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Schedulers)",count:4}],pip_install_cmd:"pip install git+https://github.com/zhubonan/aiida-fireworks-scheduler",is_installable:"True"},"aiida-fleur":{code_home:"https://github.com/JuDFTteam/aiida-fleur/tree/develop",development_status:"stable",documentation_url:"https://aiida-fleur.readthedocs.io/",entry_point_prefix:"fleur",pip_url:"aiida-fleur",plugin_info:"https://raw.github.com/JuDFTteam/aiida-fleur/develop/setup.json",name:"aiida-fleur",package_name:"aiida_fleur",hosted_on:"github.com",metadata:{release_date:"2023-05-03",description:"AiiDA Plugin for running the FLEUR code and its input generator. Also includes high-level workchains and utilities",author_email:"The JuDFT team <j.broeder@fz-juelich.de>",classifiers:["Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.0.0"},aiida_version:">=2.0.1,<3.0.0",entry_points:{"aiida.calculations":{"fleur.fleur":{description:["A CalcJob class that represents FLEUR DFT calculation.","    For more information about the FLEUR-code family go to http://www.flapw.de/"],spec:{inputs:[{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:"Use a FleurinpData node that specifies the input parametersusually copy from the parent calculation, basically makesthe inp.xml file visible in the db and makes sure it has the files needed."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote or local repository folder as parent folder (also for restarts and similar). It should contain all the needed files for a Fleur calc, only edited files should be uploaded from the repository."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"error_params",required:!1,valid_types:"Dict",info:""},{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_params_complex",required:!1,valid_types:"Dict",info:""},{name:"relax_parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"No retrieved folder found."},{status:301,message:"One of the output files can not be opened."},{status:302,message:"FLEUR calculation failed for unknown reason."},{status:303,message:"XML output file was not found."},{status:304,message:"Parsing of XML output file failed."},{status:305,message:"Parsing of relax XML output file failed."},{status:310,message:"FLEUR calculation failed due to lack of memory."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:312,message:"FLEUR calculation failed due to MT overlap."},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:314,message:"Problem with cdn is suspected. Consider removing cdn"},{status:315,message:"The LDA+U density matrix contains invalid elements."},{status:316,message:"Calculation failed due to time limits."},{status:318,message:"Calculation failed due to missing dependency ({name}) for given calculation."}]},class:"aiida_fleur.calculation.fleur:FleurCalculation"},"fleur.inpgen":{description:["JobCalculationClass for the inpgen, which is a preprocessor for a FLEUR calculation.","    For more information about produced files and the FLEUR-code family, go to http://www.flapw.de/."],spec:{inputs:[{name:"structure",required:!0,valid_types:"StructureData",info:"Choose the input structure to use"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Use a node that specifies the input parameters for the namelists"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"fleurinp",required:!0,valid_types:"FleurinpData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"No retrieved folder found."},{status:301,message:"One of the output files can not be opened."},{status:306,message:"XML input file was not found."},{status:307,message:"Some required files were not retrieved."},{status:308,message:"During parsing: FleurinpData could not be initialized, see log. "},{status:309,message:"During parsing: FleurinpData failed validation."},{status:310,message:"The profile {profile} is not known to the used inpgen code"}]},class:"aiida_fleur.calculation.fleurinputgen:FleurinputgenCalculation"}},"aiida.data":{"fleur.fleurinp":"aiida_fleur.data.fleurinp:FleurinpData"},"aiida.parsers":{"fleur.fleurinpgenparser":"aiida_fleur.parsers.fleur_inputgen:Fleur_inputgenParser","fleur.fleurparser":"aiida_fleur.parsers.fleur:FleurParser"},"aiida.workflows":{"fleur.banddos":{description:["This workflow calculated a bandstructure from a Fleur calculation","","    :Params: a Fleurcalculation node","    :returns: Success, last result node, list with convergence behavior"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"banddos_calc",required:!0,valid_types:"",info:""},{name:"output_banddos_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_banddos_wc_bands",required:!1,valid_types:"BandsData",info:""},{name:"output_banddos_wc_dos",required:!1,valid_types:"XyData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"SCF calculation failed."},{status:335,message:"Found no SCF calculation remote repository."}]},class:"aiida_fleur.workflows.banddos:FleurBandDosWorkChain"},"fleur.base":{description:["Workchain to run a FLEUR calculation with automated error handling and restarts"],spec:{inputs:[{name:"options",required:!0,valid_types:"Dict",info:"Optional parameters to set up computational details."},{name:"add_comp_para",required:!1,valid_types:"Dict",info:"Gives additional control over computational parametersonly_even_MPI: set to true if you want to suppress odd number of MPI processes in parallelisation.This might speedup a calculation for machines having even number of sockets per node.max_queue_nodes: maximal number of nodes allowed on the remote machine. Used only to automatically solve some FLEUR failures.max_queue_wallclock_sec: maximal wallclock time allowed on the remote machine. Used only to automatically solve some FLEUR failures."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"description",required:!1,valid_types:"str, NoneType",info:"Calculation description."},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:"Use a FleurinpData node that specifies the input parametersusually copy from the parent calculation, basically makesthe inp.xml file visible in the db and makes sure it has the files needed."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"label",required:!1,valid_types:"str, NoneType",info:"Calculation label."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote or local repository folder as parent folder (also for restarts and similar). It should contain all the needed files for a Fleur calc, only edited files should be uploaded from the repository."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"error_params",required:!1,valid_types:"Dict",info:""},{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_params_complex",required:!1,valid_types:"Dict",info:""},{name:"relax_parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:388,message:"Computational resources are not optimal."},{status:389,message:"Computational resources are not optimal."},{status:390,message:"Computational resources are not optimal."},{status:399,message:"FleurCalculation failed and FleurBaseWorkChain has no strategy to resolve this"},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_fleur.workflows.base_fleur:FleurBaseWorkChain"},"fleur.base_relax":{description:["Workchain to run Relax WorkChain with automated error handling and restarts"],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"description",required:!1,valid_types:"str, NoneType",info:"Calculation description."},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"label",required:!1,valid_types:"str, NoneType",info:"Calculation label."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"last_scf",required:!0,valid_types:"",info:""},{name:"optimized_structure",required:!0,valid_types:"StructureData",info:""},{name:"output_relax_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:399,message:"FleurRelaxWorkChain failed and FleurBaseRelaxWorkChain has no strategy to resolve this"},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_fleur.workflows.base_relax:FleurBaseRelaxWorkChain"},"fleur.cfcoeff":{description:["Workflow for calculating rare-earth crystal field coefficients"],spec:{inputs:[{name:"metadata",required:!1,valid_types:"",info:""},{name:"orbcontrol",required:!1,valid_types:"Data",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"scf_rare_earth_analogue",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_cfcoeff_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_cfcoeff_wc_charge_densities",required:!1,valid_types:"XyData",info:""},{name:"output_cfcoeff_wc_potentials",required:!1,valid_types:"XyData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:345,message:"Convergence scf workflow failed."},{status:451,message:"Convergence orbcontrol workflow failed."},{status:452,message:"CF calculation failed."}]},class:"aiida_fleur.workflows.cfcoeff:FleurCFCoeffWorkChain"},"fleur.corehole":{description:["Turn key solution for a corehole calculation with the FLEUR code.","    Has different protocols for different core-hole types (valence, charge).","","    Calculates supercells. Extracts binding energies","    for certain corelevels from the total energy differences a the calculation with","    corehole and without.","","    Documentation:","    See help for details.","","    Two paths are possible:","","    (1) Start from a structure -> workchains run inpgen first (recommended)","    (2) Start from a Fleurinp data object","","    Also it is recommended to provide a calc parameter node for the structure","","    :param wf_parameters: Dict node, specify, resources and what should be calculated","    :param structure: structureData node, crystal structure","    :param calc_parameters: Dict node, inpgen parameters for the crystal structure","    :param fleurinp:  fleurinpData node,","    :param inpgen: Code node,","    :param fleur: Code node,","","    :return: output_corehole_wc_para Dict node,  successful=True if no error","","    :uses workchains: fleur_scf_wc, fleur_relax_wc","    :uses calcfunctions: supercell, create_corehole_result_node, prepare_struc_corehole_wf"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"inpgen",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_corehole_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:1,message:"The input resources are invalid."},{status:2,message:"The process failed with legacy failure mode."},{status:2,message:"Input resources are missing."},{status:3,message:"The code provided is invalid, or not of the right kind."},{status:4,message:"Inpgen calculation FAILED, check output"},{status:5,message:"Changing of the FLEURINP data went wrong, check log."},{status:6,message:"The FLEUR input file for the calculation did not validate."},{status:7,message:"At least one FLEUR calculation FAILED, check the output and log."},{status:8,message:"At least one FLEUR calculation did not/could not reach thedesired convergece Criteria, with the current parameters."},{status:9,message:"Something went wrong in the determiation what coreholes to calculate, probably the input format was not correct. Check log."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.corehole:FleurCoreholeWorkChain"},"fleur.create_magnetic":{description:["This workflow creates relaxed magnetic film on a substrate."],spec:{inputs:[{name:"distance_suggestion",required:!1,valid_types:"Dict, NoneType",info:""},{name:"eos",required:!1,valid_types:"Data",info:""},{name:"eos_output",required:!1,valid_types:"Dict, NoneType",info:""},{name:"interlayer_dist",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"optimized_structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"relax",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"magnetic_structure",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:380,message:"Specified substrate has to be bcc or fcc."},{status:382,message:"Relaxation calculation failed."},{status:383,message:"EOS WorkChain failed."}]},class:"aiida_fleur.workflows.create_magnetic_film:FleurCreateMagneticWorkChain"},"fleur.dmi":{description:["This workflow calculates DMI energy dispersion of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_dmi_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.dmi:FleurDMIWorkChain"},"fleur.dos":{description:["DEPRECATED: Use FleurBandDosWorkChain instead (entrypoint fleur.banddos)","    This workflow calculated a DOS from a Fleur calculation","","    :Params: a Fleurcalculation node","    :returns: Success, last result node, list with convergence behavior","","    wf_parameters: {  'tria', 'nkpts', 'sigma', 'emin', 'emax'}","    defaults : tria = True, nkpts = 800, sigma=0.005, emin= -0.3, emax = 0.8"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_data",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.dos:fleur_dos_wc"},"fleur.eos":{description:["This workflow calculates the equation of states of a structure.","    Calculates several unit cells with different volumes.","    A Birch_Murnaghan  equation of states fit determines the Bulk modulus and the","    groundstate volume of the cell.","","    :params wf_parameters: Dict node, optional 'wf_parameters', protocol specifying parameter dict","    :params structure: StructureData node, 'structure' crystal structure","    :params calc_parameters: Dict node, optional 'calc_parameters' parameters for inpgen","    :params inpgen: Code node,","    :params fleur: Code node,","","","    :return output_eos_wc_para: Dict node, contains relevant output information.","                                about general succeed, fit results and so on."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_eos_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_eos_wc_structure",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:400,message:"At least one of the SCF sub processes did not finish successfully."}]},class:"aiida_fleur.workflows.eos:FleurEosWorkChain"},"fleur.init_cls":{description:["Turn key solution for the calculation of core level shift"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_initial_cls_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.initial_cls:FleurInitialCLSWorkChain"},"fleur.mae":{description:["This workflow calculates the Magnetic Anisotropy Energy of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_mae_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.mae:FleurMaeWorkChain"},"fleur.mae_conv":{description:["This workflow calculates the Magnetic Anisotropy Energy of a structure."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_mae_conv_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:343,message:"Convergence MAE calculation failed for all SQAs."},{status:344,message:"Convergence MAE calculation failed for some SQAs."}]},class:"aiida_fleur.workflows.mae_conv:FleurMaeConvWorkChain"},"fleur.orbcontrol":{description:["Workchain for determining the groundstate density matrix in an DFT+U","    calculation. This is done in 2 or 3 steps:","","        1. Converge the system without DFT+U (a converged calculation can be","           provided to skip this step)","        2. A fixed number of iterations is run with fixed density matrices","           either generated as all distinct permutations for the given occupations","           or the explicitly given configurations","        3. The system and density matrix is relaxed","","    :param wf_parameters: (Dict), Workchain Specifications","    :param scf_no_ldau: (Dict), Inputs to a FleurScfWorkChain providing the initial system","                                either converged or staring from a structure","    :param scf_with_ldau: (Dict), Inputs to a FleurScfWorkChain. Only the wf_parameters are valid","    :param fleurinp: (FleurinpData) FleurinpData to start from if no SCF should be done","    :param remote: (RemoteData) RemoteData to start from if no SCF should be done","    :param structure: (StructureData) Structure to start from if no SCF should be done","    :param calc_parameters: (Dict), Inpgen Parameters","    :param settings: (Dict), additional settings for e.g retrieving files","    :param options: (Dict), Options for the submission of the jobs","    :param inpgen: (Code)","    :param fleur: (Code)"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fixed_remotes",required:!1,valid_types:"RemoteData",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"options_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"relaxed_remotes",required:!1,valid_types:"RemoteData",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf_no_ldau",required:!1,valid_types:"Data",info:"Inputs for SCF Workchain before adding LDA+U"},{name:"scf_with_ldau",required:!1,valid_types:"Data",info:"Inputs for SCF Workchain after the LDA+U matrix was fixed"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"groundstate_scf",required:!0,valid_types:"",info:""},{name:"output_orbcontrol_wc_para",required:!0,valid_types:"Dict",info:""},{name:"groundstate_denmat",required:!1,valid_types:"SinglefileData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Input codes do not correspond to fleur or inpgen respectively."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:342,message:"Convergence LDA+U calculation failed for some Initial configurations."},{status:343,message:"Convergence LDA+U calculation failed for all Initial configurations."},{status:360,message:"Inpgen calculation failed."},{status:450,message:"Convergence workflow without LDA+U failed."}]},class:"aiida_fleur.workflows.orbcontrol:FleurOrbControlWorkChain"},"fleur.relax":{description:["This workflow performs structure optimization."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"last_scf",required:!0,valid_types:"",info:""},{name:"optimized_structure",required:!0,valid_types:"StructureData",info:""},{name:"output_relax_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"If you want to run a final scf inpgen has to be there."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:350,message:"Optimization cycle did not lead to convergence of forces."},{status:351,message:"SCF Workchains failed for some reason."},{status:352,message:"Found no relaxed structure info in the output of SCF"},{status:353,message:"Found no SCF output"},{status:354,message:"Force is small, switch to BFGS"}]},class:"aiida_fleur.workflows.relax:FleurRelaxWorkChain"},"fleur.relax_torque":{description:["This workflow performs spin structure optimization."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_relax_torque_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"If you want to run a final scf inpgen has to be there."},{status:350,message:"Optimization cycle did not lead to convergence."},{status:351,message:"An SCF Workchain failed for some reason."}]},class:"aiida_fleur.workflows.relax_torque:FleurRelaxTorqueWorkChain"},"fleur.scf":{description:["Workchain for converging a FLEUR calculation (SCF).","","    It converges the charge density, total energy or the largest force.","    Two paths are possible:","","    (1) Start from a structure and run the inpgen first optional with calc_parameters","    (2) Start from a Fleur calculation, with optional remoteData","","    :param wf_parameters: (Dict), Workchain Specifications","    :param structure: (StructureData), Crystal structure","    :param calc_parameters: (Dict), Inpgen Parameters","    :param fleurinp: (FleurinpData), to start with a Fleur calculation","    :param remote_data: (RemoteData), from a Fleur calculation","    :param inpgen: (Code)","    :param fleur: (Code)","","    :return: output_scf_wc_para (Dict), Information of workflow results","        like Success, last result node, list with convergence behavior"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_data",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"fleurinp",required:!0,valid_types:"FleurinpData",info:""},{name:"last_calc",required:!0,valid_types:"",info:""},{name:"output_scf_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Input codes do not correspond to fleur or inpgen respectively."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:360,message:"Inpgen calculation failed."},{status:361,message:"Fleur calculation failed."},{status:362,message:"SCF cycle did not lead to convergence."}]},class:"aiida_fleur.workflows.scf:FleurScfWorkChain"},"fleur.ssdisp":{description:["This workflow calculates spin spiral dispersion of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_ssdisp_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.ssdisp:FleurSSDispWorkChain"},"fleur.ssdisp_conv":{description:["This workflow calculates the Spin Spiral Dispersion of a structure."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_ssdisp_conv_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:340,message:"Convergence SSDisp calculation failed for all q-vectors."},{status:341,message:"Convergence SSDisp calculation failed for some q-vectors."}]},class:"aiida_fleur.workflows.ssdisp_conv:FleurSSDispConvWorkChain"},"fleur.strain":{description:["This workflow calculates the deformation potential a structure = -BdEg/dP = d(Eg)/d(ln(V)).","    Calculates several unit cells with different volumes.","    A Birch_Murnaghan  equation of states fit determines the Bulk modulus(B) and the","    ground-state volume of the cell.","","    :params wf_parameters: Dict node, optional 'wf_parameters', protocol specifying parameter dict","    :params structure: StructureData node, 'structure' crystal structure","    :params calc_parameters: Dict node, optional 'calc_parameters' parameters for inpgen","    :params inpgen: Code node,","    :params fleur: Code node,","","","    :return output_strain_wc_para: Dict node, contains relevant output information.","                                about general succeed, fit results and so on."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"inpgen",required:!0,valid_types:"Code",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_strain_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:331,message:"Invalid code node specified, check inpgen and fleur code nodes."}]},class:"aiida_fleur.workflows.strain:FleurStrainWorkChain"}},console_scripts:{"aiida-fleur":"aiida_fleur.cmdline:cmd_root"}},commits_count:201,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:19},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-fleur",is_installable:"True"},"aiida-flexpart":{code_home:"https://github.com/aiidaplugins/aiida-flexpart",entry_point_prefix:"flexpart",pip_url:"git+https://github.com/aiidaplugins/aiida-flexpart",name:"aiida-flexpart",package_name:"aiida_flexpart",hosted_on:"github.com",metadata:{author:"The AiiDA Team",author_email:"aliaksandr.yakutovich@empa.ch",version:"0.1.0a0",description:"AiiDA plugin for the FLEXPART code (simulation of atmospheric transport processes).",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.5,<3.0.0",entry_points:{"aiida.calculations":{"flexpart.cosmo":"aiida_flexpart.calculations.cosmo:FlexpartCosmoCalculation"},"aiida.parsers":{"flexpart.cosmo":"aiida_flexpart.parsers.cosmo:FlexpartCosmoParser"},"aiida.workflows":{"flexpart.multi_dates":"aiida_flexpart.workflows.multi_dates_workflow:FlexpartMultipleDatesWorkflow"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidaplugins/aiida-flexpart"},"aiida-gaussian":{code_home:"https://github.com/nanotech-empa/aiida-gaussian",entry_point_prefix:"gaussian",pip_url:"aiida-gaussian",plugin_info:"https://raw.githubusercontent.com/nanotech-empa/aiida-gaussian/master/pyproject.toml",name:"aiida-gaussian",package_name:"aiida_gaussian",hosted_on:"github.com",metadata:{release_date:"2023-08-31",description:"AiiDA plugin for the Gaussian quantum chemistry software.",author:"Kristjan Eimre, Pezhman Zarabadi-Poor, Aliaksandr Yakutovich",license:"MIT",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: OS Independent","Programming Language :: Python :: 3","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Software Development :: Libraries :: Python Modules"],version:"2.1.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{gaussian:{description:["AiiDA calculation plugin wrapping Gaussian","","    Template:","","    parameters = Dict(dict={","        'link0_parameters': {","            '%chk':'aiida.chk',","            '%mem': '1024MB',","            '%nprocshared': '2',","        },","        'functional':'PBE1PBE',","        'basis_set':'6-31g',","        'charge': 0,","        'multiplicity': 1,","        'route_parameters': {","            'scf': {'cdiis': None}","            'nosymm': None,","            'opt': 'tight',","        },","    })"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"the folder of a completed gaussian calculation"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"additional input parameters"},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"Input structure; will be converted to pymatgen object"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The result parameters of the calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"energy_ev",required:!1,valid_types:"Float",info:"Final energy in electronvolts"},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final optimized structure, if available"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the output file."},{status:211,message:"The retrieved output log could not be read."},{status:220,message:"The output file could not be parsed."},{status:301,message:"The SCF did not converge and the calculation was terminated."},{status:302,message:"The calculation was terminated due to a logic error in ASyTop."},{status:303,message:"The calculation was terminated due to an inaccurate quadrature in CalDSu."},{status:390,message:"The calculation was terminated due to an error."},{status:391,message:"The log did not contain 'Normal termination' (probably out of time)."}]},class:"aiida_gaussian.calculations:GaussianCalculation"},"gaussian.cubegen":{description:["Plugin to run the cubegen utility","","    Example:","","    parameters = {",'        "homo-5": {','            "kind": "AMO=16",','            "npts": -2,',"        },",'        "spin": {','            "kind": "Spin=SCF",','            "npts": 0,',"        },","    }","    Each key corresponds to one produced cube.","    key specifies the name of the output node","",'    In case of "npts": -1, you have to use the stencil file input:',"","        IFlag X0 Y0 Z0  # Output unit number and initial point.","        N1 X1 Y1 Z1     # Number of points and step-size in the X-direction.","        N2 X2 Y2 Z2     # Number of points and step-size in the Y-direction.","        N3 X3 Y3 Z3     # Number of points and step-size in the Z-direction.","","    See more details at https://gaussian.com/cubegen/"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"dictionary containing entries for cubes to be printed."},{name:"parent_calc_folder",required:!0,valid_types:"RemoteData",info:"the folder of a containing the .fchk"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"gauss_memdef",required:!1,valid_types:"Int, NoneType",info:"Set the GAUSS_MEMDEF env variable to set the max memory in MB."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieve_cubes",required:!1,valid_types:"Bool, NoneType",info:"should the cubes be retrieved?"},{name:"stencil",required:!1,valid_types:"SinglefileData, NoneType",info:"In case of npts=-1, use this cube specification."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"The retrieved folder could not be accessed."},{status:301,message:"The retrieved temporary folder could not be accessed."}]},class:"aiida_gaussian.calculations:CubegenCalculation"},"gaussian.formchk":{description:["Very simple plugin to run the formchk utility"],spec:{inputs:[{name:"parent_calc_folder",required:!0,valid_types:"RemoteData",info:"the folder of a containing the .chk"},{name:"chk_name",required:!1,valid_types:"Str, NoneType",info:"name of the checkpoint file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieve_fchk",required:!1,valid_types:"Bool, NoneType",info:"retrieve the fchk file"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_gaussian.calculations:FormchkCalculation"}},"aiida.parsers":{"gaussian.advanced":"aiida_gaussian.parsers.gaussian:GaussianAdvancedParser","gaussian.base":"aiida_gaussian.parsers.gaussian:GaussianBaseParser","gaussian.cubegen_base":"aiida_gaussian.parsers.cubegen:CubegenBaseParser"},"aiida.workflows":{"gaussian.base":{description:["Workchain to run a Gaussian calculation with automated error handling and restarts."],spec:{inputs:[{name:"gaussian",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:350,message:"The calculation failed with an unrecoverable SCF convergence error."},{status:399,message:"The calculation failed with an unrecoverable error."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_gaussian.workchains:GaussianBaseWorkChain"},"gaussian.cubes":{description:["No description available"],spec:{inputs:[{name:"cubegen_code",required:!0,valid_types:"Code",info:""},{name:"formchk_code",required:!0,valid_types:"Code",info:""},{name:"gaussian_calc_folder",required:!0,valid_types:"RemoteData",info:"The gaussian calculation output folder."},{name:"gaussian_output_params",required:!0,valid_types:"Dict",info:"The gaussian calculation output parameters."},{name:"cubegen_parser_name",required:!1,valid_types:"str",info:""},{name:"cubegen_parser_params",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters to cubegen parser."},{name:"dx",required:!1,valid_types:"Float, NoneType",info:"Cube file spacing [ang]."},{name:"edge_space",required:!1,valid_types:"Float, NoneType",info:"Extra cube space in addition to molecule bounding box [ang]."},{name:"generate_density",required:!1,valid_types:"Bool, NoneType",info:"Generate density cube."},{name:"generate_spin_density",required:!1,valid_types:"Bool, NoneType",info:"Generate spin density cube (if applicable)."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"natural_orbitals",required:!1,valid_types:"Bool, NoneType",info:"The cube files are natural orbitals."},{name:"orbital_index_ref",required:!1,valid_types:"Str, NoneType",info:"Reference index, possible choices: 'half_num_el', 'abs'."},{name:"orbital_indexes",required:!1,valid_types:"List, NoneType",info:"Indexes of the orbital cubes to generate."},{name:"retrieve_cubes",required:!1,valid_types:"Bool, NoneType",info:"should the cubes be retrieved?"}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:302,message:"Input options are invalid."},{status:390,message:"One or more steps of the work chain failed."}]},class:"aiida_gaussian.workchains:GaussianCubesWorkChain"}}},commits_count:23,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"green",text:"Workflows",count:2}],pip_install_cmd:"pip install aiida-gaussian",is_installable:"True"},"aiida-gaussian-datatypes":{code_home:"https://github.com/dev-zero/aiida-gaussian-datatypes",documentation_url:"https://github.com/dev-zero/aiida-gaussian-datatypes/blob/master/README.md",entry_point_prefix:"gaussian",pip_url:"aiida-gaussian-datatypes",plugin_info:"https://raw.github.com/dev-zero/aiida-gaussian-datatypes/master/setup.json",name:"aiida-gaussian-datatypes",package_name:"aiida_gaussian_datatypes",hosted_on:"github.com",metadata:{release_date:"2022-07-22",description:"AiiDA data plugin to manage gaussian datatypes (basis sets and pseudopotentials) as first-class citizens",author:"Tiziano Müller",author_email:"tiziano.mueller@chem.uzh.ch",license:"MIT License",home_page:"https://github.com/dev-zero/aiida-gaussian-datatypes",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.5.1"},aiida_version:">=1.6.2",entry_points:{"aiida.cmdline.data":{"gaussian.basisset":"aiida_gaussian_datatypes.basisset.cli:cli","gaussian.pseudo":"aiida_gaussian_datatypes.pseudopotential.cli:cli"},"aiida.data":{"gaussian.basisset":"aiida_gaussian_datatypes.basisset.data:BasisSet","gaussian.pseudo":"aiida_gaussian_datatypes.pseudopotential.data:Pseudopotential"},"aiida.groups":{"gaussian.basisset":"aiida_gaussian_datatypes.groups:BasisSetGroup","gaussian.pseudo":"aiida_gaussian_datatypes.groups:PseudopotentialGroup"}},commits_count:0,development_status:"beta",warnings:["Prefix 'gaussian' does not follow naming convention."],summaryinfo:[{colorclass:"red",text:"Data",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:4}],pip_install_cmd:"pip install aiida-gaussian-datatypes",is_installable:"True"},"aiida-gollum":{code_home:"https://github.com/garsua/aiida-gollum/",documentation_url:"https://aiida-gollum.readthedocs.io/",entry_point_prefix:"gollum",pip_url:"git+https://github.com/garsua/aiida-gollum",name:"aiida-gollum",package_name:"aiida_gollum",hosted_on:"github.com",metadata:{author:"Victor M. Garcia-Suarez",author_email:"vm.garcia@cinn.es",version:"0.12.0",description:"A plugin for Gollum functionality within AiiDA framework.",classifiers:["License :: OSI Approved :: MIT License","Framework :: AiiDA","Programming Language :: Python :: 2.7","Development Status :: 1 - Alpha"]},aiida_version:">=0.12.0",entry_points:{"aiida.calculations":{"gollum.gollum":"aiida_gollum.calculations.gollum:GollumCalculation"},"aiida.parsers":{"gollum.parser":"aiida_gollum.parsers.gollum:GollumParser"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/garsua/aiida-gollum"},"aiida-graphql":{code_home:"https://github.com/dev-zero/aiida-graphql",entry_point_prefix:"graphql",pip_url:"aiida-graphql",name:"aiida-graphql",package_name:"aiida_graphql",hosted_on:"github.com",metadata:{release_date:"2019-10-28",description:"Strawberry-based GraphQL API Server for AiiDA",author:"Tiziano Müller",author_email:"tiziano.mueller@chem.uzh.ch",license:"MIT",home_page:"https://github.com/dev-zero/aiida-graphql",classifiers:["Development Status :: 3 - Alpha","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.0.2"},aiida_version:">=1.0.0b6,<2.0.0",entry_points:{},commits_count:0,development_status:"alpha",warnings:["Unable to read wheel file from PyPI release: No entry_points.txt found in wheel","Missing classifier 'Framework :: AiiDA'"],summaryinfo:[],pip_install_cmd:"pip install aiida-graphql",is_installable:"False",errors:[`Failed to install plugin aiida-graphql
Collecting aiida-graphql
  Downloading aiida_graphql-0.0.2-py3-none-any.whl (6.6 kB)
Collecting aiida<2.0.0,>=1.0.0b6 (from aiida-graphql)
  Downloading aiida-1.0.1.tar.gz (2.8 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting strawberry-graphql<0.17.0,>=0.16.7 (from aiida-graphql)
  Downloading strawberry_graphql-0.16.10-py3-none-any.whl (29 kB)
Requirement already satisfied: aiida-core in /opt/conda/lib/python3.9/site-packages (from aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.4.0.post0)
Collecting click<8.0,>=7.0 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 12.0 MB/s eta 0:00:00
Collecting graphql-core<4.0.0,>=3.0.0a0 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Obtaining dependency information for graphql-core<4.0.0,>=3.0.0a0 from https://files.pythonhosted.org/packages/95/74/5ec674eb611ba6d70a8622a58ffe9c087afee079f8688ef2b836adca8616/graphql_core-3.3.0a3-py3-none-any.whl.metadata
  Downloading graphql_core-3.3.0a3-py3-none-any.whl.metadata (11 kB)
Collecting hupper<2.0,>=1.5 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading hupper-1.12-py3-none-any.whl (22 kB)
Requirement already satisfied: pygments<3.0,>=2.3 in /opt/conda/lib/python3.9/site-packages (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql) (2.16.1)
Collecting starlette==0.12.10 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading starlette-0.12.10.tar.gz (46 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.3/46.3 kB 14.9 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting uvicorn==0.10.0 (from strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading uvicorn-0.10.0.tar.gz (26 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting h11==0.8.* (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading h11-0.8.1-py2.py3-none-any.whl (55 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 7.1 MB/s eta 0:00:00
Collecting websockets==8.* (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading websockets-8.1.tar.gz (58 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.9/58.9 kB 13.9 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting httptools==0.0.13 (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading httptools-0.0.13.tar.gz (104 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 104.2/104.2 kB 36.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting uvloop==0.14.0rc2 (from uvicorn==0.10.0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql)
  Downloading uvloop-0.14.0rc2.tar.gz (2.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 41.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: typing-extensions<5.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from graphql-core<4.0.0,>=3.0.0a0->strawberry-graphql<0.17.0,>=0.16.7->aiida-graphql) (4.7.1)
Requirement already satisfied: alembic~=1.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.12.0)
Requirement already satisfied: archive-path~=0.4.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.4.2)
Requirement already satisfied: aio-pika~=6.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (6.8.1)
Requirement already satisfied: circus~=0.18.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.18.0)
Requirement already satisfied: click-spinner~=0.1.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.1.10)
INFO: pip is looking at multiple versions of aiida-core to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Obtaining dependency information for aiida-core from https://files.pythonhosted.org/packages/2b/ec/a99338a82592fb94c5741288143d34281162fe4e19228e059cfec67d5589/aiida_core-2.4.0-py3-none-any.whl.metadata
  Downloading aiida_core-2.4.0-py3-none-any.whl.metadata (10 kB)
  Obtaining dependency information for aiida-core from https://files.pythonhosted.org/packages/d9/96/c88f1af662144765c15acdbada6d33f92e57a0c2311f6aa09fa8fcc7c91a/aiida_core-2.3.1-py3-none-any.whl.metadata
  Downloading aiida_core-2.3.1-py3-none-any.whl.metadata (11 kB)
  Downloading aiida_core-2.3.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 77.3 MB/s eta 0:00:00
  Downloading aiida_core-2.2.2-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 96.3 MB/s eta 0:00:00
Collecting click-config-file~=0.6.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading click_config_file-0.6.0-py2.py3-none-any.whl (6.0 kB)
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aiida_core-2.2.1-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 91.9 MB/s eta 0:00:00
  Downloading aiida_core-2.2.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 70.1 MB/s eta 0:00:00
  Downloading aiida_core-2.1.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 100.0 MB/s eta 0:00:00
Collecting circus~=0.17.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading circus-0.17.2-py3-none-any.whl (204 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 204.2/204.2 kB 53.6 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of aiida-core to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aiida_core-2.1.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 43.0 MB/s eta 0:00:00
  Downloading aiida_core-2.1.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 102.0 MB/s eta 0:00:00
  Downloading aiida_core-2.0.4-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 106.2 MB/s eta 0:00:00
  Downloading aiida_core-2.0.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 104.7 MB/s eta 0:00:00
  Downloading aiida_core-2.0.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 60.4 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading aiida_core-2.0.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 102.6 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 102.8 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0b1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 104.8 MB/s eta 0:00:00
Collecting archive-path~=0.3.6 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading archive_path-0.3.6-py3-none-any.whl (18 kB)
Collecting aiida-core (from aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aiida_core-1.6.9-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 97.9 MB/s eta 0:00:00
Collecting aldjemy~=0.9.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading aldjemy-0.9.1-py3-none-any.whl (26 kB)
Collecting archive-path~=0.2.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading archive_path-0.2.1-py3-none-any.whl (17 kB)
Collecting click-completion~=0.5.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading click-completion-0.5.2.tar.gz (10 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting django~=2.2 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading Django-2.2.28-py3-none-any.whl (7.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.5/7.5 MB 105.4 MB/s eta 0:00:00
Collecting ete3~=3.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading ete3-3.1.3.tar.gz (4.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 106.7 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: graphviz~=0.13 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.20.1)
Collecting ipython~=7.20 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 793.8/793.8 kB 89.9 MB/s eta 0:00:00
Collecting jinja2~=2.10 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 41.0 MB/s eta 0:00:00
Requirement already satisfied: jsonschema~=3.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.2.0)
Requirement already satisfied: kiwipy[rmq]~=0.7.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.7.7)
Collecting markupsafe<2.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading MarkupSafe-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)
Requirement already satisfied: numpy~=1.17 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.25.2)
Requirement already satisfied: pamqp~=2.3 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.3.0)
Requirement already satisfied: paramiko>=2.7.2,~=2.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.12.0)
Collecting plumpy~=0.20.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading plumpy-0.20.0-py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 19.2 MB/s eta 0:00:00
Requirement already satisfied: pgsu~=0.2.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.2.4)
Requirement already satisfied: psutil~=5.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (5.9.5)
Collecting psycopg2-binary~=2.8.3 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading psycopg2_binary-2.8.6-cp39-cp39-manylinux1_x86_64.whl (3.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 108.7 MB/s eta 0:00:00
Collecting python-dateutil~=2.8 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 59.9 MB/s eta 0:00:00
Collecting pytz~=2019.3 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 kB 79.6 MB/s eta 0:00:00
Collecting pyyaml~=5.4 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 630.1/630.1 kB 93.2 MB/s eta 0:00:00
Collecting reentry~=1.3 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading reentry-1.3.3-py3-none-any.whl (17 kB)
Collecting simplejson~=3.16 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading simplejson-3.19.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.4/137.4 kB 43.4 MB/s eta 0:00:00
Collecting sqlalchemy-utils~=0.36.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading SQLAlchemy-Utils-0.36.5.tar.gz (131 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.2/131.2 kB 33.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sqlalchemy~=1.3.10 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading SQLAlchemy-1.3.24-cp39-cp39-manylinux2010_x86_64.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 71.6 MB/s eta 0:00:00
Requirement already satisfied: tabulate~=0.8.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.8.10)
Requirement already satisfied: tqdm~=4.45 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (4.66.1)
Collecting tzlocal~=2.0 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: upf-to-json~=0.9.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.9.5)
Collecting wrapt~=1.11.1 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading wrapt-1.11.2.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: aiormq<4,>=3.2.3 in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.3.1)
Requirement already satisfied: yarl in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.9.2)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.2.4)
Requirement already satisfied: pyzmq>=17.0 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (25.1.1)
Requirement already satisfied: tornado>=5.0.2 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (6.3.3)
Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from click-completion~=0.5.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.16.0)
Collecting shellingham (from click-completion~=0.5.1->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Obtaining dependency information for shellingham from https://files.pythonhosted.org/packages/57/70/0265437683625b2e6491736706d3d679d90e2a26f6bff59f4e46e09872b9/shellingham-1.5.3-py2.py3-none-any.whl.metadata
  Downloading shellingham-1.5.3-py2.py3-none-any.whl.metadata (3.4 kB)
Collecting configobj>=5.0.6 (from click-config-file~=0.6.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)
Collecting sqlparse>=0.2.2 (from django~=2.2->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 13.6 MB/s eta 0:00:00
Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (68.1.2)
Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.19.0)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (5.1.1)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.7.5)
Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (5.9.0)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.0.39)
Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.2.0)
Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.1.6)
Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (4.8.0)
Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (23.1.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.19.3)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.0.11)
Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.10)
Requirement already satisfied: pytray<0.4.0,>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.3.4)
Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.1.0)
INFO: pip is looking at multiple versions of kiwipy[rmq] to determine which version is compatible with other requirements. This could take a while.
Collecting kiwipy[rmq]~=0.7.5 (from aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading kiwipy-0.7.6-py3-none-any.whl (29 kB)
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (4.0.1)
Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (41.0.3)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.5.0)
Collecting nest-asyncio~=1.4.0 (from plumpy~=0.20.0->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql)
  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (1.15.1)
Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.8.3)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.7.0)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython~=7.20->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (0.2.6)
Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from deprecation->kiwipy[rmq]~=0.7.5->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (23.1)
Requirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (6.0.4)
Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (3.4)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core->aiida<2.0.0,>=1.0.0b6->aiida-graphql) (2.21)
Downloading graphql_core-3.3.0a3-py3-none-any.whl (209 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.9/209.9 kB 50.3 MB/s eta 0:00:00
Downloading shellingham-1.5.3-py2.py3-none-any.whl (9.7 kB)
Building wheels for collected packages: aiida, starlette, uvicorn, httptools, uvloop, websockets, click-completion, ete3, sqlalchemy-utils, wrapt
  Building wheel for aiida (setup.py): started
  Building wheel for aiida (setup.py): finished with status 'done'
  Created wheel for aiida: filename=aiida-1.0.1-py3-none-any.whl size=2647 sha256=730cd8c1f36c1635ac4165bae1cd13433f3b2e5eb28379756c1485d0af6f996e
  Stored in directory: /home/aiida/.cache/pip/wheels/6a/40/75/657e47e83c88bd0540e6c7cf1011f86f2ebe801418960774ae
  Building wheel for starlette (setup.py): started
  Building wheel for starlette (setup.py): finished with status 'done'
  Created wheel for starlette: filename=starlette-0.12.10-py3-none-any.whl size=57408 sha256=00f61d1f6966368f94dd0e9222104adc167de69004fdfcc86e734136dd1c90f9
  Stored in directory: /home/aiida/.cache/pip/wheels/61/a2/3b/69592c9f46018f222ed7231684cb01dcd01e154c421612e6cf
  Building wheel for uvicorn (setup.py): started
  Building wheel for uvicorn (setup.py): finished with status 'done'
  Created wheel for uvicorn: filename=uvicorn-0.10.0-py3-none-any.whl size=40800 sha256=1bb4e3bb570866e3d3a17feee4d8355df0416328db6ac83f2edaafa19bf84716
  Stored in directory: /home/aiida/.cache/pip/wheels/3f/eb/c3/f5bb5247cf7f29c58eedd827460b2c3d186be85ad2f4bfeaf5
  Building wheel for httptools (setup.py): started
  Building wheel for httptools (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [160 lines of output]
      running bdist_wheel
      running build
      running build_py
      creating build
      creating build/lib.linux-x86_64-cpython-39
      creating build/lib.linux-x86_64-cpython-39/httptools
      copying httptools/__init__.py -> build/lib.linux-x86_64-cpython-39/httptools
      creating build/lib.linux-x86_64-cpython-39/httptools/parser
      copying httptools/parser/errors.py -> build/lib.linux-x86_64-cpython-39/httptools/parser
      copying httptools/parser/__init__.py -> build/lib.linux-x86_64-cpython-39/httptools/parser
      running egg_info
      writing httptools.egg-info/PKG-INFO
      writing dependency_links to httptools.egg-info/dependency_links.txt
      writing top-level names to httptools.egg-info/top_level.txt
      reading manifest file 'httptools.egg-info/SOURCES.txt'
      reading manifest template 'MANIFEST.in'
      adding license file 'LICENSE'
      writing manifest file 'httptools.egg-info/SOURCES.txt'
      copying httptools/parser/parser.c -> build/lib.linux-x86_64-cpython-39/httptools/parser
      running build_ext
      building 'httptools.parser.parser' extension
      creating build/temp.linux-x86_64-cpython-39
      creating build/temp.linux-x86_64-cpython-39/httptools
      creating build/temp.linux-x86_64-cpython-39/httptools/parser
      creating build/temp.linux-x86_64-cpython-39/vendor
      creating build/temp.linux-x86_64-cpython-39/vendor/http-parser
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.9 -c httptools/parser/parser.c -o build/temp.linux-x86_64-cpython-39/httptools/parser/parser.o -O2
      httptools/parser/parser.c: In function ‘__Pyx_modinit_type_init_code’:
      httptools/parser/parser.c:8977:51: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       8977 |   __pyx_type_9httptools_6parser_6parser_HttpParser.tp_print = 0;
            |                                                   ^
      httptools/parser/parser.c:8988:58: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       8988 |   __pyx_type_9httptools_6parser_6parser_HttpRequestParser.tp_print = 0;
            |                                                          ^
      httptools/parser/parser.c:9000:59: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       9000 |   __pyx_type_9httptools_6parser_6parser_HttpResponseParser.tp_print = 0;
            |                                                           ^
      httptools/parser/parser.c:9009:44: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       9009 |   __pyx_type_9httptools_6parser_6parser_URL.tp_print = 0;
            |                                            ^
      httptools/parser/parser.c: In function ‘__Pyx_ParseOptionalKeywords’:
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10115:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10115 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c:10131:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      10131 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      httptools/parser/parser.c: In function ‘__Pyx_decode_c_bytes’:
      httptools/parser/parser.c:10316:9: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
      10316 |         return PyUnicode_FromUnicode(NULL, 0);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from httptools/parser/parser.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      error: command '/usr/bin/gcc' failed with exit code 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for httptools
  Running setup.py clean for httptools
  Building wheel for uvloop (setup.py): started
  Building wheel for uvloop (setup.py): finished with status 'done'
  Created wheel for uvloop: filename=uvloop-0.14.0rc2-cp39-cp39-linux_x86_64.whl size=1832544 sha256=3f19f73ee0488e91703c908e4124d8a63f9bc711faff95c23c67e1443d4522a5
  Stored in directory: /home/aiida/.cache/pip/wheels/1a/97/63/2785095a0e950600bf7a9c8b0b047da9b4fd04c8b6ba2dd5d8
  Building wheel for websockets (setup.py): started
  Building wheel for websockets (setup.py): finished with status 'done'
  Created wheel for websockets: filename=websockets-8.1-cp39-cp39-linux_x86_64.whl size=66218 sha256=6b05f33f4d07eb97056f73a8e479c4a8f4014dd32e25859e5cedb970293f3aac
  Stored in directory: /home/aiida/.cache/pip/wheels/d8/b9/a0/b97b211aeda2ebd6ac2e43fc300d308dbf1f9df520ed390cae
  Building wheel for click-completion (setup.py): started
  Building wheel for click-completion (setup.py): finished with status 'done'
  Created wheel for click-completion: filename=click_completion-0.5.2-py3-none-any.whl size=11189 sha256=1863f935b524bacc84e95e9abf2aac25609243c1272ba5191b25cfdb031f389b
  Stored in directory: /home/aiida/.cache/pip/wheels/f1/23/55/8287077a0e274c8d7ddf94fb623cb481cd0f4512d1a5062603
  Building wheel for ete3 (setup.py): started
  Building wheel for ete3 (setup.py): finished with status 'done'
  Created wheel for ete3: filename=ete3-3.1.3-py3-none-any.whl size=2273785 sha256=8eacd4ce3061081eb0ac4c1be26cca37e37393e28092055f3f1b53d1a42c766b
  Stored in directory: /home/aiida/.cache/pip/wheels/ad/2e/cc/edcca721b423e1604c84f480a1e8e0547a223bfc068d373259
  Building wheel for sqlalchemy-utils (setup.py): started
  Building wheel for sqlalchemy-utils (setup.py): finished with status 'done'
  Created wheel for sqlalchemy-utils: filename=SQLAlchemy_Utils-0.36.5-py2.py3-none-any.whl size=93140 sha256=757962e830b73ae68dddb8331daa41539f77dfce5989e4041166ad34038bfc96
  Stored in directory: /home/aiida/.cache/pip/wheels/09/42/92/638b45c458a59b25b1b83e8771a9744f4219512a683c76af15
  Building wheel for wrapt (setup.py): started
  Building wheel for wrapt (setup.py): finished with status 'done'
  Created wheel for wrapt: filename=wrapt-1.11.2-cp39-cp39-linux_x86_64.whl size=36723 sha256=19921160c314a4e8e31d0224e85426be540cb383ab55ab54f51900a12eedf607
  Stored in directory: /home/aiida/.cache/pip/wheels/76/e9/66/d4e35bfa6cde3925ff1c497043d7a2ccb305c07ac51fef0e31
Successfully built aiida starlette uvicorn uvloop websockets click-completion ete3 sqlalchemy-utils wrapt
Failed to build httptools
ERROR: Could not build wheels for httptools, which is required to install pyproject.toml-based projects
`]},"aiida-gromacs":{code_home:"https://github.com/jimboid/aiida-gromacs",documentation_url:"https://aiida-gromacs.readthedocs.io/",entry_point_prefix:"gromacs",pip_url:"git+https://github.com/jimboid/aiida-gromacs",name:"aiida-gromacs",package_name:"aiida_gromacs",hosted_on:"github.com",metadata:{description:"A plugin for using GROMACS with AiiDA for molecular dymanics simulations.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 3 - Alpha","Framework :: AiiDA"],author:"James Gebbie-Rayet",author_email:"james.gebbie@stfc.ac.uk"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{"gromacs.pdb2gmx":"aiida_gromacs.data.pdb2gmx:Pdb2gmxParameters","gromacs.editconf":"aiida_gromacs.data.editconf:EditconfParameters","gromacs.genion":"aiida_gromacs.data.genion:GenionParameters","gromacs.grompp":"aiida_gromacs.data.grompp:GromppParameters","gromacs.mdrun":"aiida_gromacs.data.mdrun:MdrunParameters","gromacs.solvate":"aiida_gromacs.data.solvate:SolvateParameters"},"aiida.calculations":{"gromacs.pdb2gmx":{description:["AiiDA calculation plugin wrapping the 'gmx pdb2gmx' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Pdb2gmxParameters",info:"Command line parameters for gmx pdb2gmx"},{name:"pdbfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"itpfile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"n_file",required:!1,valid_types:"SinglefileData",info:"Output index file"},{name:"q_file",required:!1,valid_types:"SinglefileData",info:"Output Structure file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.pdb2gmx:Pdb2gmxCalculation"},"gromacs.editconf":{description:["AiiDA calculation plugin wrapping the 'gmx editconf' executable.","","    AiiDA plugin wrapper for adding a simulation box to structure file."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure file."},{name:"parameters",required:!0,valid_types:"EditconfParameters",info:"Command line parameters for gmx editconf."},{name:"bf_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Generic data file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output file containing simulation box."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"mead_file",required:!1,valid_types:"SinglefileData",info:"Coordination file for MEAD"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.editconf:EditconfCalculation"},"gromacs.genion":{description:["AiiDA calculation plugin wrapping the 'gmx genion' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"GenionParameters",info:"Command line parameters for gmx genion"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology file."},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Input tpr file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output gro file with ions added."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output topology with ions added."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.genion:GenionCalculation"},"gromacs.grompp":{description:["AiiDA calculation plugin wrapping the 'gmx grompp' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure"},{name:"mdpfile",required:!0,valid_types:"SinglefileData",info:"grompp run file."},{name:"parameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"e_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Energy file"},{name:"itpfile",required:!1,valid_types:"SinglefileData, NoneType",info:"Restraint file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file"},{name:"qmi_file",required:!1,valid_types:"SinglefileData, NoneType",info:"QM input file"},{name:"r_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Structure file"},{name:"rb_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Structure file"},{name:"ref_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Full precision trajectory file"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"t_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Full precision trajectory file"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Output gro file ready for adding ions."},{name:"imd_file",required:!1,valid_types:"SinglefileData",info:"Coordinate file in Gromos-87 format"},{name:"po_file",required:!1,valid_types:"SinglefileData",info:"grompp input file with MD parameters"},{name:"pp_file",required:!1,valid_types:"SinglefileData",info:"Topology file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.grompp:GromppCalculation"},"gromacs.mdrun":{description:["AiiDA calculation plugin wrapping the 'gmx mdrun' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun"},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"awh_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"cpi_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Checkpoint file"},{name:"ei_file",required:!1,valid_types:"SinglefileData, NoneType",info:"ED sampling input"},{name:"membed_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Generic data file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"mn_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file"},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"mp_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Topology file"},{name:"multidir_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Run directory"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"rerun_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Trajectory: xtc trr cpt gro g96 pdb tng"},{name:"table_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"tableb_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"tablep_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"}],outputs:[{name:"enfile",required:!0,valid_types:"SinglefileData",info:"Output energy file."},{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output structure file."},{name:"logfile",required:!0,valid_types:"SinglefileData",info:"Output log file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"trrfile",required:!0,valid_types:"SinglefileData",info:"Output trajectory."},{name:"cpo_file",required:!1,valid_types:"SinglefileData",info:"Checkpoint file."},{name:"dhdl_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"eo_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"field_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"if_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"mtx_file",required:!1,valid_types:"SinglefileData",info:"Hessian Matrix"},{name:"pf_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"px_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"ra_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"ro_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"rs_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"rt_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"swap_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"tpi_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"tpid_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"x_file",required:!1,valid_types:"SinglefileData",info:"Compressed trajectory (tng format or portable xdr format)"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.mdrun:MdrunCalculation"},"gromacs.solvate":{description:["AiiDA calculation plugin wrapping the 'gmx solvate' executable.","","    AiiDA plugin wrapper for solvating a molecular system."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure"},{name:"parameters",required:!0,valid_types:"SolvateParameters",info:"Command line parameters for gmx solvate."},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output solvated gro file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output topology file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.solvate:SolvateCalculation"},genericMD:{description:["AiiDA calculation plugin wrapping an executable with user defined","    input and output files."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"command",required:!1,valid_types:"Str, NoneType",info:"The command used to execute the job."},{name:"input_files",required:!1,valid_types:"SinglefileData",info:"Dictionary of input files."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"output_files",required:!1,valid_types:"List, NoneType",info:"List of output file names."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"log",required:!1,valid_types:"SinglefileData",info:"link to the default file.out."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."},{status:301,message:"Specified output file not produced by command."}]},class:"aiida_gromacs.calculations.genericMD:GenericCalculation"}},"aiida.parsers":{"gromacs.pdb2gmx":"aiida_gromacs.parsers.pdb2gmx:Pdb2gmxParser","gromacs.editconf":"aiida_gromacs.parsers.editconf:EditconfParser","gromacs.genion":"aiida_gromacs.parsers.genion:GenionParser","gromacs.grompp":"aiida_gromacs.parsers.grompp:GromppParser","gromacs.mdrun":"aiida_gromacs.parsers.mdrun:MdrunParser","gromacs.solvate":"aiida_gromacs.parsers.solvate:SolvateParser",genericMD:"aiida_gromacs.parsers.genericMD:GenericParser"},"aiida.workflows":{"gromacs.setup":{description:["WorkChain for setting up a gromacs simulation automatically."],spec:{inputs:[{name:"editconfparameters",required:!0,valid_types:"EditconfParameters",info:"Command line parameters for gmx editconf"},{name:"genionparameters",required:!0,valid_types:"GenionParameters",info:"Command line parameters for gmx genion"},{name:"gromppionsparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp"},{name:"gromppminparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp minimisation run"},{name:"gromppnptparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp npt equilibration run"},{name:"gromppnvtparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp nvt equilibration run"},{name:"gromppprodparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp production run"},{name:"ionsmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for adding ions."},{name:"local_code",required:!0,valid_types:"Code",info:""},{name:"mdrunparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun production run"},{name:"minimiseparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun minimisation run"},{name:"minmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for minimisation."},{name:"nptmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for NPT equilibration."},{name:"nptparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun npt equilibration run"},{name:"nvtmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for NVT equilibration."},{name:"nvtparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun nvt equilibration run"},{name:"pdb2gmxparameters",required:!0,valid_types:"Pdb2gmxParameters",info:"Command line parameters for gmx pdb2gmx"},{name:"pdbfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"prodmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for production run."},{name:"solvateparameters",required:!0,valid_types:"SolvateParameters",info:"Command line parameters for gmx solvate"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"remote_code",required:!1,valid_types:"Code, NoneType",info:""}],outputs:[{name:"result",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_gromacs.workflows.simsetup:SetupWorkChain"}}},commits_count:187,development_status:"alpha",warnings:["Entry point 'genericMD' does not start with prefix 'gromacs.'","Entry point 'genericMD' does not start with prefix 'gromacs.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:7},{colorclass:"brown",text:"Parsers",count:7},{colorclass:"red",text:"Data",count:6},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/jimboid/aiida-gromacs",is_installable:"True"},"aiida-grouppathx":{code_home:"https://github.com/zhubonan/aiida-grouppathx",development_status:"beta",entry_point_prefix:"grouppathx",pip_url:"aiida-grouppathx",name:"aiida-grouppathx",package_name:"aiida_grouppathx",hosted_on:"github.com",metadata:{release_date:"2022-05-25",description:"AiiDA plugin provides the GroupPathX class",author_email:"Bonan Zhu <zhubonan@outlook.com>",classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.0"},aiida_version:">=1.6.4,<3",entry_points:{"aiida.cmdline.data":{gpx:"aiida_grouppathx.cli:grouppathx_cli"}},commits_count:3,warnings:["Unable to read wheel file from PyPI release: No entry_points.txt found in wheel","Development status in classifiers (alpha) does not match development_status in metadata (beta)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'gpx' does not start with prefix 'grouppathx.'"],summaryinfo:[{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-grouppathx",is_installable:"True",errors:[`Failed to import package aiida_grouppathx
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.9/site-packages/aiida_grouppathx/__init__.py", line 6, in <module>
    from aiida_grouppathx.pathx import *
  File "/opt/conda/lib/python3.9/site-packages/aiida_grouppathx/pathx.py", line 122, in <module>
    class GroupPathX(GroupPath):
  File "/opt/conda/lib/python3.9/site-packages/aiida_grouppathx/pathx.py", line 130, in GroupPathX
    cls: orm.groups.GroupMeta = orm.Group,
AttributeError: module 'aiida.orm.groups' has no attribute 'GroupMeta'
`]},"aiida-gudhi":{code_home:"https://github.com/ltalirz/aiida-gudhi",development_status:"beta",entry_point_prefix:"gudhi",pip_url:"aiida-gudhi",plugin_info:"https://raw.github.com/ltalirz/aiida-gudhi/master/setup.json",name:"aiida-gudhi",package_name:"aiida_gudhi",hosted_on:"github.com",metadata:{release_date:"2018-06-21",description:"AiiDA plugin for the [GUDHI](http://gudhi.gforge.inria.fr/) library for topological data analysis.",author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-gudhi",classifiers:["Programming Language :: Python"],version:"0.1.0a3"},aiida_version:"*",entry_points:{"aiida.calculations":{"gudhi.rdm":"aiida_gudhi.calculations.rips:RipsDistanceMatrixCalculation"},"aiida.data":{"gudhi.rdm":"aiida_gudhi.data.rips:RipsDistanceMatrixParameters"},"aiida.parsers":{"gudhi.rdm":"aiida_gudhi.parsers.rips:RipsParser"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install --pre aiida-gudhi",is_installable:"True"},"aiida-gulp":{code_home:"https://github.com/aiidaplugins/aiida-gulp",development_status:"beta",documentation_url:"https://aiida-gulp.readthedocs.io",entry_point_prefix:"gulp",pip_url:"aiida-gulp",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-gulp/master/setup.json",name:"aiida-gulp",package_name:"aiida_gulp",hosted_on:"github.com",metadata:{release_date:"2019-10-30",description:"AiiDA plugin for running the GULP MD code",author:"Chris Sewell",author_email:"chrisj_sewell@hotmail.com",license:"MIT",home_page:"https://github.com/chrisjsewell/aiida-gulp",classifiers:["Framework :: AiiDA","Programming Language :: Python","Programming Language :: Python :: 2.7","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"0.10.0b5"},aiida_version:"1.0.0b5",entry_points:{"aiida.calculations":{"gulp.fitting":"aiida_gulp.calculations.gulp_fitting:GulpFittingCalculation","gulp.optimize":"aiida_gulp.calculations.gulp_optimize:GulpOptCalculation","gulp.single":"aiida_gulp.calculations.gulp_single:GulpSingleCalculation"},"aiida.cmdline.data":{"gulp.potentials":"aiida_gulp.cmndline.potentials:potentials"},"aiida.data":{"gulp.potential":"aiida_gulp.data.potential:EmpiricalPotential","gulp.symmetry":"aiida_gulp.data.symmetry:SymmetryData"},"aiida.parsers":{"gulp.fitting":"aiida_gulp.parsers.parse_fitting:GulpFittingParser","gulp.optimize":"aiida_gulp.parsers.parse_opt:GulpOptParser","gulp.single":"aiida_gulp.parsers.parse_single:GulpSingleParser"},"aiida.workflows":{},console_scripts:{gulp_mock:"aiida_gulp.tests.mock_gulp:main"},"gulp.potentials":{lj:"aiida_gulp.potentials.lj:PotentialWriterLJ",reaxff:"aiida_gulp.potentials.reaxff:PotentialWriterReaxff"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:2},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Gulp potentials)",count:3}],pip_install_cmd:"pip install --pre aiida-gulp",is_installable:"False",errors:[`Failed to install plugin aiida-gulp
Collecting aiida-gulp
  Downloading aiida_gulp-0.10.0b5-py3-none-any.whl (287 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.6/287.6 kB 14.0 MB/s eta 0:00:00
Collecting aiida-core==1.0.0b5 (from aiida-gulp)
  Downloading aiida-core-1.0.0b5.tar.gz (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 75.6 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from aiida-gulp) (1.16.0)
Requirement already satisfied: ruamel.yaml in /opt/conda/lib/python3.9/site-packages (from aiida-gulp) (0.17.32)
Collecting jsonextended>=0.7.10 (from aiida-gulp)
  Downloading jsonextended-0.7.11-py2.py3-none-any.whl (466 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 466.9/466.9 kB 51.0 MB/s eta 0:00:00
Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from aiida-gulp) (3.2.0)
Collecting spglib<2.0.0,>=1.10.0 (from aiida-gulp)
  Downloading spglib-1.16.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 325.5/325.5 kB 73.4 MB/s eta 0:00:00
Collecting importlib-resources (from aiida-gulp)
  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata
  Downloading importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)
Collecting ase<4.0.0,>=3.12.0 (from aiida-gulp)
  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 92.8 MB/s eta 0:00:00
Collecting PyCifRW==4.4 (from aiida-gulp)
  Downloading PyCifRW-4.4.tar.gz (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 92.0 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting reentry>=1.3.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Collecting python-dateutil==2.8.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading python_dateutil-2.8.0-py2.py3-none-any.whl (226 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.8/226.8 kB 42.9 MB/s eta 0:00:00
Collecting django==1.11.20 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading Django-1.11.20-py2.py3-none-any.whl (6.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 84.0 MB/s eta 0:00:00
Collecting tzlocal==1.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading tzlocal-1.5.1.tar.gz (16 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting pytz==2018.9 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading pytz-2018.9-py2.py3-none-any.whl (510 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.7/510.7 kB 79.7 MB/s eta 0:00:00
Collecting PyYAML==3.13 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading PyYAML-3.13.tar.gz (270 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 270.6/270.6 kB 55.8 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting six>=1.12.0 (from aiida-gulp)
  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)
Collecting psutil==5.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading psutil-5.5.1.tar.gz (426 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 426.8/426.8 kB 80.0 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mock==2.0.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading mock-2.0.0-py2.py3-none-any.whl (56 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 19.7 MB/s eta 0:00:00
Collecting numpy==1.16.4 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading numpy-1.16.4.zip (5.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 100.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting SQLAlchemy==1.3.3 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading SQLAlchemy-1.3.3.tar.gz (5.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 121.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting SQLAlchemy-Utils==0.33.11 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading SQLAlchemy-Utils-0.33.11.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.0/128.0 kB 41.8 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting alembic==1.0.7 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading alembic-1.0.7.tar.gz (1.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 100.3 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aldjemy==0.9.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading aldjemy-0.9.1-py3-none-any.whl (26 kB)
Collecting passlib==1.7.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading passlib-1.7.1-py2.py3-none-any.whl (498 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 498.8/498.8 kB 77.2 MB/s eta 0:00:00
Collecting click==7.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.3/81.3 kB 30.2 MB/s eta 0:00:00
Collecting click-completion==0.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading click-completion-0.5.1.tar.gz (9.9 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting click-config-file==0.5.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading click_config_file-0.5.0-py2.py3-none-any.whl (5.8 kB)
Collecting click-spinner==0.1.8 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading click-spinner-0.1.8.tar.gz (18 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting tabulate==0.8.3 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading tabulate-0.8.3.tar.gz (46 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.2/46.2 kB 13.0 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting ete3==3.1.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading ete3-3.1.1.tar.gz (10.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.5/10.5 MB 13.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting uritools==2.2.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading uritools-2.2.0-py2.py3-none-any.whl (14 kB)
Collecting psycopg2-binary==2.8 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading psycopg2-binary-2.8.tar.gz (368 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 368.4/368.4 kB 76.5 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting paramiko==2.6.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading paramiko-2.6.0-py2.py3-none-any.whl (199 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.9/199.9 kB 52.0 MB/s eta 0:00:00
Collecting ipython<6.0,>=4.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading ipython-5.10.0-py3-none-any.whl (760 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760.3/760.3 kB 89.9 MB/s eta 0:00:00
Collecting plumpy==0.14.2 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading plumpy-0.14.2-py2.py3-none-any.whl (55 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.5/55.5 kB 20.6 MB/s eta 0:00:00
Collecting kiwipy[rmq]==0.5.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading kiwipy-0.5.1-py2.py3-none-any.whl (21 kB)
Collecting pika==1.0.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading pika-1.0.0-py2.py3-none-any.whl (148 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.5/148.5 kB 48.6 MB/s eta 0:00:00
Collecting circus==0.15.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading circus-0.15.0-py3-none-any.whl (190 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.8/190.8 kB 57.9 MB/s eta 0:00:00
Collecting tornado<5.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading tornado-4.5.3.tar.gz (484 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 484.2/484.2 kB 78.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting wrapt==1.11.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading wrapt-1.11.1.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting simplejson==3.16.0 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading simplejson-3.16.0.tar.gz (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.2/81.2 kB 25.2 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting graphviz==0.10.1 (from aiida-core==1.0.0b5->aiida-gulp)
  Downloading graphviz-0.10.1-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic==1.0.7->aiida-core==1.0.0b5->aiida-gulp) (1.2.4)
Collecting python-editor>=0.3 (from alembic==1.0.7->aiida-core==1.0.0b5->aiida-gulp)
  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)
Collecting pyzmq<17.0,>=13.1.0 (from circus==0.15.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading pyzmq-16.0.4.tar.gz (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 106.0 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from click-completion==0.5.1->aiida-core==1.0.0b5->aiida-gulp) (3.1.2)
Collecting shellingham (from click-completion==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Obtaining dependency information for shellingham from https://files.pythonhosted.org/packages/57/70/0265437683625b2e6491736706d3d679d90e2a26f6bff59f4e46e09872b9/shellingham-1.5.3-py2.py3-none-any.whl.metadata
  Downloading shellingham-1.5.3-py2.py3-none-any.whl.metadata (3.4 kB)
Collecting configobj>=5.0.6 (from click-config-file==0.5.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp) (1.0.11)
Collecting topika<0.3.0,>=0.2.0 (from kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Downloading topika-0.2.2-py2.py3-none-any.whl (36 kB)
Collecting pbr>=0.11 (from mock==2.0.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.7/112.7 kB 35.2 MB/s eta 0:00:00
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (4.0.1)
Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (41.0.3)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (1.5.0)
Collecting frozendict (from plumpy==0.14.2->aiida-core==1.0.0b5->aiida-gulp)
  Downloading frozendict-2.3.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.8/114.8 kB 36.5 MB/s eta 0:00:00
Collecting matplotlib>=3.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/e0/8b/b62bc50b01bb2d4af96bc0045c39d60209e2701e172789ceace20a0866b2/matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)
Collecting scipy>=1.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 22.3 MB/s eta 0:00:00
Collecting pathlib2 (from jsonextended>=0.7.10->aiida-gulp)
  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)
Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from importlib-resources->aiida-gulp) (3.16.2)
Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->aiida-gulp) (23.1.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->aiida-gulp) (0.19.3)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from jsonschema->aiida-gulp) (68.1.2)
Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.9/site-packages (from ruamel.yaml->aiida-gulp) (0.2.7)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (5.1.1)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (0.7.5)
Collecting simplegeneric>0.8 (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading simplegeneric-0.8.1.zip (12 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (5.9.0)
Collecting prompt-toolkit<2.0.0,>=1.0.4 (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading prompt_toolkit-1.0.18-py3-none-any.whl (245 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 245.4/245.4 kB 59.4 MB/s eta 0:00:00
Collecting pygments<2.6 (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp)
  Downloading Pygments-2.5.2-py2.py3-none-any.whl (896 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 896.1/896.1 kB 99.5 MB/s eta 0:00:00
Requirement already satisfied: pexpect in /opt/conda/lib/python3.9/site-packages (from ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (4.8.0)
Collecting contourpy>=1.0.1 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/2b/c0/24c34c41a180f875419b536125799c61e2330b997d77a5a818a3bc3e08cd/contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)
Collecting cycler>=0.10 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/49/50/2e31753c088d364756daa5bed0dab6a5928ebfd6e6d26f975c8b6d6f754a/fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.0/151.0 kB 47.6 MB/s eta 0:00:00
Collecting kiwisolver>=1.0.1 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata
  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)
INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.
Collecting matplotlib>=3.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/51/ce/5d08045689fbf933cb4481913e1320f8d9a8a1da8674ce2fb4a0cf020c52/matplotlib-3.8.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/ae/13/e2e86809b8d080a346aaaae78c89005b142683ec0af04acc4311837fc1c6/matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/47/b9/6c0daa9b953a80b4e6933bf6a11a2d0633f257e84ee5995c5fd35de564c9/matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)
  Downloading matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 94.3 MB/s eta 0:00:00
  Downloading matplotlib-3.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 97.4 MB/s eta 0:00:00
  Downloading matplotlib-3.7.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 15.0 MB/s eta 0:00:00
  Downloading matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 106.0 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.
  Downloading matplotlib-3.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 105.0 MB/s eta 0:00:00
  Downloading matplotlib-3.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 103.0 MB/s eta 0:00:00
  Downloading matplotlib-3.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 106.6 MB/s eta 0:00:00
  Downloading matplotlib-3.6.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 24.4 MB/s eta 0:00:00
  Downloading matplotlib-3.6.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 19.7 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading matplotlib-3.5.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 108.3 MB/s eta 0:00:00
  Downloading matplotlib-3.5.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 108.8 MB/s eta 0:00:00
  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 109.1 MB/s eta 0:00:00
  Downloading matplotlib-3.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 16.0 MB/s eta 0:00:00
  Downloading matplotlib-3.5.0rc1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.3/10.3 MB 96.2 MB/s eta 0:00:00
  Downloading matplotlib-3.5.0b1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.3/10.3 MB 121.5 MB/s eta 0:00:00
  Downloading matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.3/10.3 MB 133.0 MB/s eta 0:00:00
Collecting pillow>=6.2.0 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/0a/20/a94a0462495de73e248643fb24667270f2e67f44792456ab7207764e80cc/Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata
  Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
Collecting pyparsing>=2.2.1 (from matplotlib>=3.1.0->ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for pyparsing>=2.2.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata
  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)
INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.
Collecting scipy>=1.1.0 (from ase<4.0.0,>=3.12.0->aiida-gulp)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/08/25/035fe07fc32c5a8b314f882faa9d4817223fa5faf524d3fedcf17a4b9d22/scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 21.4 MB/s eta 0:00:00
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/4f/fa/fc40251f769228ce4c74166cd6c1c9dc67a726d3ec178cf45ff8b39f4125/scipy-1.11.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 23.9 MB/s eta 0:00:00
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/2b/f3/d8e1860f67fbc2c0967f9d5465abf8aa4a9c85cf7d2d38d8bbae9d732d61/scipy-1.11.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 22.4 MB/s eta 0:00:00
  Downloading scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 64.4 MB/s eta 0:00:00
  Downloading scipy-1.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 52.8 MB/s eta 0:00:00
  Downloading scipy-1.10.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 60.9 MB/s eta 0:00:00
  Downloading scipy-1.10.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.4/34.4 MB 45.2 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.
  Downloading scipy-1.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.8/33.8 MB 62.0 MB/s eta 0:00:00
  Downloading scipy-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.8/33.8 MB 54.7 MB/s eta 0:00:00
  Downloading scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 14.4 MB/s eta 0:00:00
  Downloading scipy-1.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 51.1 MB/s eta 0:00:00
  Downloading scipy-1.9.0rc3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 22.2 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading scipy-1.9.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 13.3 MB/s eta 0:00:00
  Downloading scipy-1.9.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.9/43.9 MB 23.3 MB/s eta 0:00:00
  Downloading scipy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.2/42.2 MB 54.2 MB/s eta 0:00:00
  Downloading scipy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 52.8 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.1/42.1 MB 8.6 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.5/42.5 MB 26.9 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.5/42.5 MB 24.3 MB/s eta 0:00:00
  Downloading scipy-1.8.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.0/103.0 MB 11.4 MB/s eta 0:00:00
  Downloading scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.8/39.8 MB 52.8 MB/s eta 0:00:00
  Downloading scipy-1.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.8/39.8 MB 45.1 MB/s eta 0:00:00
  Downloading scipy-1.7.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.5/28.5 MB 60.3 MB/s eta 0:00:00
  Downloading scipy-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.4/28.4 MB 63.6 MB/s eta 0:00:00
  Downloading scipy-1.6.3-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 63.0 MB/s eta 0:00:00
  Downloading scipy-1.6.2-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 69.2 MB/s eta 0:00:00
  Downloading scipy-1.6.1-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 40.2 MB/s eta 0:00:00
  Downloading scipy-1.6.0-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.3/27.3 MB 64.7 MB/s eta 0:00:00
  Downloading scipy-1.5.4-cp39-cp39-manylinux1_x86_64.whl (25.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.8/25.8 MB 71.4 MB/s eta 0:00:00
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (1.15.1)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (0.2.6)
Collecting furl (from topika<0.3.0,>=0.2.0->kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Downloading furl-2.1.3-py2.py3-none-any.whl (20 kB)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->click-completion==0.5.1->aiida-core==1.0.0b5->aiida-gulp) (2.1.3)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect->ipython<6.0,>=4.0->aiida-core==1.0.0b5->aiida-gulp) (0.7.0)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko==2.6.0->aiida-core==1.0.0b5->aiida-gulp) (2.21)
Collecting orderedmultidict>=1.0.1 (from furl->topika<0.3.0,>=0.2.0->kiwipy[rmq]==0.5.1->aiida-core==1.0.0b5->aiida-gulp)
  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)
Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)
Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 55.2 MB/s eta 0:00:00
Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl (3.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 124.2 MB/s eta 0:00:00
Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 30.4 MB/s eta 0:00:00
Downloading shellingham-1.5.3-py2.py3-none-any.whl (9.7 kB)
Building wheels for collected packages: aiida-core, PyCifRW, alembic, click-completion, click-spinner, ete3, numpy, psutil, psycopg2-binary, PyYAML, simplejson, SQLAlchemy, SQLAlchemy-Utils, tabulate, tzlocal, wrapt, tornado, pyzmq, simplegeneric
  Building wheel for aiida-core (pyproject.toml): started
  Building wheel for aiida-core (pyproject.toml): finished with status 'done'
  Created wheel for aiida-core: filename=aiida_core-1.0.0b5-py3-none-any.whl size=1644685 sha256=882b5eed3f857a77dd4ab175d7e25dd4abc37f58204bb7ced6eb6b125fd93ecc
  Stored in directory: /home/aiida/.cache/pip/wheels/8a/72/83/372726a098884bcb5312014dd9afea8d656001214d9cf1f87e
  Building wheel for PyCifRW (setup.py): started
  Building wheel for PyCifRW (setup.py): finished with status 'done'
  Created wheel for PyCifRW: filename=PyCifRW-4.4-cp39-cp39-linux_x86_64.whl size=140950 sha256=4e7ab9aa77af87e8be2795ffa5437fe43c8f1ac657bb94131c4ba93f91f008be
  Stored in directory: /home/aiida/.cache/pip/wheels/0f/58/a7/cc7faa4fb4aca4aa925bb632cd9ede3f97520dbdceb7975b49
  Building wheel for alembic (setup.py): started
  Building wheel for alembic (setup.py): finished with status 'done'
  Created wheel for alembic: filename=alembic-1.0.7-py2.py3-none-any.whl size=159962 sha256=5b86f7615993fc6d9259fb158b275ae6d80bb5fcd67a1a2e3e2205d6f9e2a293
  Stored in directory: /home/aiida/.cache/pip/wheels/82/b8/9e/c185107e13961fb24d40591e1462184822350e9e1726256548
  Building wheel for click-completion (setup.py): started
  Building wheel for click-completion (setup.py): finished with status 'done'
  Created wheel for click-completion: filename=click_completion-0.5.1-py3-none-any.whl size=11139 sha256=cad51f0c2cf03db6ed32a42711fc136681298c86639a0b4a5b8c724caeae31db
  Stored in directory: /home/aiida/.cache/pip/wheels/ca/96/9b/cbfb172bf9db477384dc8a81aeb271c9a3f8823014518c4a1e
  Building wheel for click-spinner (setup.py): started
  Building wheel for click-spinner (setup.py): finished with status 'done'
  Created wheel for click-spinner: filename=click_spinner-0.1.8-py2.py3-none-any.whl size=3090 sha256=003770ab5ee490e8c771123b8d4ee7565f6f89822448eeabef48d725de09465b
  Stored in directory: /home/aiida/.cache/pip/wheels/ef/24/c6/ce0be37cb054b4accfee5709b8673ebe6b728e560a20ec0347
  Building wheel for ete3 (setup.py): started
  Building wheel for ete3 (setup.py): finished with status 'done'
  Created wheel for ete3: filename=ete3-3.1.1-py3-none-any.whl size=2226275 sha256=71e1b411e150b39d946d793edafb7730775523544e185bccbd7899e9bed11baf
  Stored in directory: /home/aiida/.cache/pip/wheels/a2/cc/4d/a94e20c2d23e79a31e217bbc5fb0c6d1b0ab0bf90ffe04cd26
  Building wheel for numpy (setup.py): started
  Building wheel for numpy (setup.py): still running...
  Building wheel for numpy (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [3102 lines of output]
      Running from numpy source directory.
      /tmp/pip-install-whim332k/numpy_35cbd35d05c1408b84843595a36bd63c/numpy/distutils/misc_util.py:476: SyntaxWarning: "is" with a literal. Did you mean "=="?
        return is_string(s) and ('*' in s or '?' is s)
      blas_opt_info:
      blas_mkl_info:
      customize UnixCCompiler
        libraries mkl_rt not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      blis_info:
      customize UnixCCompiler
        libraries blis not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      openblas_info:
      customize UnixCCompiler
      customize UnixCCompiler
        libraries openblas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_3_10_blas_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries tatlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_3_10_blas_info:
      customize UnixCCompiler
        libraries satlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_blas_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_blas_info:
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      accelerate_info:
        NOT AVAILABLE
      
      /tmp/pip-install-whim332k/numpy_35cbd35d05c1408b84843595a36bd63c/numpy/distutils/system_info.py:639: UserWarning:
          Atlas (http://math-atlas.sourceforge.net/) libraries not found.
          Directories to search for the libraries can be specified in the
          numpy/distutils/site.cfg file (section [atlas]) or by setting
          the ATLAS environment variable.
        self.calc_info()
      blas_info:
      customize UnixCCompiler
        libraries blas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      /tmp/pip-install-whim332k/numpy_35cbd35d05c1408b84843595a36bd63c/numpy/distutils/system_info.py:639: UserWarning:
          Blas (http://www.netlib.org/blas/) libraries not found.
          Directories to search for the libraries can be specified in the
          numpy/distutils/site.cfg file (section [blas]) or by setting
          the BLAS environment variable.
        self.calc_info()
      blas_src_info:
        NOT AVAILABLE
      
      /tmp/pip-install-whim332k/numpy_35cbd35d05c1408b84843595a36bd63c/numpy/distutils/system_info.py:639: UserWarning:
          Blas (http://www.netlib.org/blas/) sources not found.
          Directories to search for the sources can be specified in the
          numpy/distutils/site.cfg file (section [blas_src]) or by setting
          the BLAS_SRC environment variable.
        self.calc_info()
        NOT AVAILABLE
      
      /bin/sh: 1: svnversion: not found
      non-existing path in 'numpy/distutils': 'site.cfg'
      lapack_opt_info:
      lapack_mkl_info:
      customize UnixCCompiler
        libraries mkl_rt not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      openblas_lapack_info:
      customize UnixCCompiler
      customize UnixCCompiler
        libraries openblas not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      openblas_clapack_info:
      customize UnixCCompiler
      customize UnixCCompiler
        libraries openblas,lapack not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      atlas_3_10_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries tatlas,tatlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>
        NOT AVAILABLE
      
      atlas_3_10_info:
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries satlas,satlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries satlas,satlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_3_10_info'>
        NOT AVAILABLE
      
      atlas_threads_info:
      Setting PTATLAS=ATLAS
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries ptf77blas,ptcblas,atlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_threads_info'>
        NOT AVAILABLE
      
      atlas_info:
      customize UnixCCompiler
        libraries lapack_atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /opt/conda/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/local/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/lib64
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/lib
      customize UnixCCompiler
        libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu
      customize UnixCCompiler
        libraries f77blas,cblas,atlas not found in /usr/lib/x86_64-linux-gnu
      <class 'numpy.distutils.system_info.atlas_info'>
        NOT AVAILABLE
      
      lapack_info:
      customize UnixCCompiler
        libraries lapack not found in ['/opt/conda/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']
        NOT AVAILABLE
      
      /tmp/pip-install-whim332k/numpy_35cbd35d05c1408b84843595a36bd63c/numpy/distutils/system_info.py:639: UserWarning:
          Lapack (http://www.netlib.org/lapack/) libraries not found.
          Directories to search for the libraries can be specified in the
          numpy/distutils/site.cfg file (section [lapack]) or by setting
          the LAPACK environment variable.
        self.calc_info()
      lapack_src_info:
        NOT AVAILABLE
      
      /tmp/pip-install-whim332k/numpy_35cbd35d05c1408b84843595a36bd63c/numpy/distutils/system_info.py:639: UserWarning:
          Lapack (http://www.netlib.org/lapack/) sources not found.
          Directories to search for the sources can be specified in the
          numpy/distutils/site.cfg file (section [lapack_src]) or by setting
          the LAPACK_SRC environment variable.
        self.calc_info()
        NOT AVAILABLE
      
      /opt/conda/lib/python3.9/site-packages/setuptools/_distutils/dist.py:265: UserWarning: Unknown distribution option: 'define_macros'
        warnings.warn(msg)
      running bdist_wheel
      running build
      running config_cc
      unifing config_cc, config, build_clib, build_ext, build commands --compiler options
      running config_fc
      unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options
      running build_src
      build_src
      building py_modules sources
      creating build
      creating build/src.linux-x86_64-3.9
      creating build/src.linux-x86_64-3.9/numpy
      creating build/src.linux-x86_64-3.9/numpy/distutils
      building library "npymath" sources
      get_default_fcompiler: matching types: '['gnu95', 'intel', 'lahey', 'pg', 'absoft', 'nag', 'vast', 'compaq', 'intele', 'intelem', 'gnu', 'g95', 'pathf95', 'nagfor']'
      customize Gnu95FCompiler
      Could not locate executable gfortran
      Could not locate executable f95
      customize IntelFCompiler
      Could not locate executable ifort
      Could not locate executable ifc
      customize LaheyFCompiler
      Could not locate executable lf95
      customize PGroupFCompiler
      Could not locate executable pgfortran
      customize AbsoftFCompiler
      Could not locate executable f90
      Could not locate executable f77
      customize NAGFCompiler
      customize VastFCompiler
      customize CompaqFCompiler
      Could not locate executable fort
      customize IntelItaniumFCompiler
      Could not locate executable efort
      Could not locate executable efc
      customize IntelEM64TFCompiler
      customize GnuFCompiler
      Could not locate executable g77
      customize G95FCompiler
      Could not locate executable g95
      customize PathScaleFCompiler
      Could not locate executable pathf95
      customize NAGFORCompiler
      Could not locate executable nagfor
      don't know how to compile Fortran code on platform 'posix'
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      /opt/conda/compiler_compat/ld: _configtest.o: in function \`main':
      _configtest.c:(.text.startup+0x9): undefined reference to \`exp'
      collect2: error: ld returned 1 exit status
      failure.
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      creating build/src.linux-x86_64-3.9/numpy/core
      creating build/src.linux-x86_64-3.9/numpy/core/src
      creating build/src.linux-x86_64-3.9/numpy/core/src/npymath
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_internal.h
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/npymath' to include_dirs.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.c
      None - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_internal.h']
      building library "npysort" sources
      creating build/src.linux-x86_64-3.9/numpy/core/src/common
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/npy_sort.h
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/common' to include_dirs.
      creating build/src.linux-x86_64-3.9/numpy/core/src/npysort
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/mergesort.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/heapsort.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/npy_partition.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/selection.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/npy_binsearch.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/npysort/binsearch.c
      None - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/src/common/npy_sort.h', 'build/src.linux-x86_64-3.9/numpy/core/src/common/npy_partition.h', 'build/src.linux-x86_64-3.9/numpy/core/src/common/npy_binsearch.h']
      building extension "numpy.core._dummy" sources
      Generating build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:10: fatal error: sys/endian.h: No such file or directory
          1 | #include <sys/endian.h>
            |          ^~~~~~~~~~~~~~
      compilation terminated.
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 4)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 16)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:12: error: ‘SIZEOF_LONGDOUBLE’ undeclared (first use in this function); did you mean ‘SIZEOF_LONG_DOUBLE’?
          7 |     (void) SIZEOF_LONGDOUBLE;
            |            ^~~~~~~~~~~~~~~~~
            |            SIZEOF_LONG_DOUBLE
      _configtest.c:7:12: note: each undeclared identifier is reported only once for each function it appears in
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 16)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 32)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          7 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) >= 0)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:16: warning: variable ‘test_array’ set but not used [-Wunused-but-set-variable]
          5 |     static int test_array [1 - 2 * !(((long) (sizeof (npy_check_sizeof_type))) == 8)];
            |                ^~~~~~~~~~
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      /opt/conda/compiler_compat/ld: _configtest.o: in function \`main':
      _configtest.c:(.text.startup+0x9): undefined reference to \`exp'
      collect2: error: ld returned 1 exit status
      failure.
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘sin’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int sin (void);
            |     ^~~
      _configtest.c:1:1: note: ‘sin’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int sin (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cos’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cos (void);
            |     ^~~
      _configtest.c:2:5: note: ‘cos’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘tan’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          3 | int tan (void);
            |     ^~~
      _configtest.c:3:5: note: ‘tan’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘sinh’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          4 | int sinh (void);
            |     ^~~~
      _configtest.c:4:5: note: ‘sinh’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘cosh’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          5 | int cosh (void);
            |     ^~~~
      _configtest.c:5:5: note: ‘cosh’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘tanh’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          6 | int tanh (void);
            |     ^~~~
      _configtest.c:6:5: note: ‘tanh’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘fabs’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          7 | int fabs (void);
            |     ^~~~
      _configtest.c:7:5: note: ‘fabs’ is declared in header ‘<math.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘floor’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          8 | int floor (void);
            |     ^~~~~
      _configtest.c:8:5: note: ‘floor’ is declared in header ‘<math.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ceil’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ceil (void);
            |     ^~~~
      _configtest.c:9:5: note: ‘ceil’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘sqrt’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         10 | int sqrt (void);
            |     ^~~~
      _configtest.c:10:5: note: ‘sqrt’ is declared in header ‘<math.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘log10’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         11 | int log10 (void);
            |     ^~~~~
      _configtest.c:11:5: note: ‘log10’ is declared in header ‘<math.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘log’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         12 | int log (void);
            |     ^~~
      _configtest.c:12:5: note: ‘log’ is declared in header ‘<math.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         13 | int exp (void);
            |     ^~~
      _configtest.c:13:5: note: ‘exp’ is declared in header ‘<math.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘asin’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         14 | int asin (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘asin’ is declared in header ‘<math.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘acos’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         15 | int acos (void);
            |     ^~~~
      _configtest.c:15:5: note: ‘acos’ is declared in header ‘<math.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘atan’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         16 | int atan (void);
            |     ^~~~
      _configtest.c:16:5: note: ‘atan’ is declared in header ‘<math.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘fmod’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
         17 | int fmod (void);
            |     ^~~~
      _configtest.c:17:5: note: ‘fmod’ is declared in header ‘<math.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘modf’; expected ‘double(double,  double *)’ [-Wbuiltin-declaration-mismatch]
         18 | int modf (void);
            |     ^~~~
      _configtest.c:18:5: note: ‘modf’ is declared in header ‘<math.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘frexp’; expected ‘double(double,  int *)’ [-Wbuiltin-declaration-mismatch]
         19 | int frexp (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘frexp’ is declared in header ‘<math.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘ldexp’; expected ‘double(double,  int)’ [-Wbuiltin-declaration-mismatch]
         20 | int ldexp (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘ldexp’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘rint’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int rint (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘rint’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int rint (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘trunc’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          2 | int trunc (void);
            |     ^~~~~
      _configtest.c:2:5: note: ‘trunc’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘exp2’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          3 | int exp2 (void);
            |     ^~~~
      _configtest.c:3:5: note: ‘exp2’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘log2’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          4 | int log2 (void);
            |     ^~~~
      _configtest.c:4:5: note: ‘log2’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘atan2’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
          5 | int atan2 (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘atan2’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘pow’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
          6 | int pow (void);
            |     ^~~
      _configtest.c:6:5: note: ‘pow’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘nextafter’; expected ‘double(double,  double)’ [-Wbuiltin-declaration-mismatch]
          7 | int nextafter (void);
            |     ^~~~~~~~~
      _configtest.c:7:5: note: ‘nextafter’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘cbrt’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
         10 | int cbrt (void);
            |     ^~~~
      _configtest.c:10:5: note: ‘cbrt’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:10: fatal error: xlocale.h: No such file or directory
          1 | #include <xlocale.h>
            |          ^~~~~~~~~~~
      compilation terminated.
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_isnan(5.);
            |   ^~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_isinf(5.);
            |   ^~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_isfinite(5.);
            |   ^~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_bswap32(5u);
            |   ^~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_bswap64(5u);
            |   ^~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: statement with no effect [-Wunused-value]
          5 |   __builtin_expect(5, 0);
            |   ^~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:5:3: warning: right-hand operand of comma expression has no effect [-Wunused-value]
          5 |   __builtin_mul_overflow(5, 5, (int*)5);
            |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:7:16: warning: unused variable ‘r’ [-Wunused-variable]
          7 |   volatile int r = __builtin_cpu_supports("sse");
            |                ^
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      _configtest.c: In function ‘__declspec’:
      _configtest.c:5:24: error: expected declaration specifiers before ‘foo’
          5 | int __declspec(thread) foo;
            |                        ^~~
      _configtest.c:9:1: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘{’ token
          9 | {
            | ^
      _configtest.c:5:5: warning: type of ‘thread’ defaults to ‘int’ [-Wimplicit-int]
          5 | int __declspec(thread) foo;
            |     ^~~~~~~~~~
      _configtest.c:12: error: expected ‘{’ at end of input
      _configtest.c:12: warning: control reaches end of non-void function [-Wreturn-type]
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘sinf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          1 | int sinf (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘sinf’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int sinf (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cosf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          2 | int cosf (void);
            |     ^~~~
      _configtest.c:2:5: note: ‘cosf’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘tanf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          3 | int tanf (void);
            |     ^~~~
      _configtest.c:3:5: note: ‘tanf’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘sinhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          4 | int sinhf (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘sinhf’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘coshf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          5 | int coshf (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘coshf’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘tanhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          6 | int tanhf (void);
            |     ^~~~~
      _configtest.c:6:5: note: ‘tanhf’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘fabsf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          7 | int fabsf (void);
            |     ^~~~~
      _configtest.c:7:5: note: ‘fabsf’ is declared in header ‘<math.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘floorf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          8 | int floorf (void);
            |     ^~~~~~
      _configtest.c:8:5: note: ‘floorf’ is declared in header ‘<math.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ceilf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
          9 | int ceilf (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ceilf’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘rintf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         10 | int rintf (void);
            |     ^~~~~
      _configtest.c:10:5: note: ‘rintf’ is declared in header ‘<math.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘truncf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         11 | int truncf (void);
            |     ^~~~~~
      _configtest.c:11:5: note: ‘truncf’ is declared in header ‘<math.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘sqrtf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         12 | int sqrtf (void);
            |     ^~~~~
      _configtest.c:12:5: note: ‘sqrtf’ is declared in header ‘<math.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘log10f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         13 | int log10f (void);
            |     ^~~~~~
      _configtest.c:13:5: note: ‘log10f’ is declared in header ‘<math.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘logf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         14 | int logf (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘logf’ is declared in header ‘<math.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘log1pf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         15 | int log1pf (void);
            |     ^~~~~~
      _configtest.c:15:5: note: ‘log1pf’ is declared in header ‘<math.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘expf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         16 | int expf (void);
            |     ^~~~
      _configtest.c:16:5: note: ‘expf’ is declared in header ‘<math.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘expm1f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         17 | int expm1f (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘expm1f’ is declared in header ‘<math.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘asinf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         18 | int asinf (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘asinf’ is declared in header ‘<math.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘acosf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         19 | int acosf (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘acosf’ is declared in header ‘<math.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘atanf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         20 | int atanf (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘atanf’ is declared in header ‘<math.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘asinhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         21 | int asinhf (void);
            |     ^~~~~~
      _configtest.c:21:5: note: ‘asinhf’ is declared in header ‘<math.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘acoshf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         22 | int acoshf (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘acoshf’ is declared in header ‘<math.h>’
      _configtest.c:23:5: warning: conflicting types for built-in function ‘atanhf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         23 | int atanhf (void);
            |     ^~~~~~
      _configtest.c:23:5: note: ‘atanhf’ is declared in header ‘<math.h>’
      _configtest.c:24:5: warning: conflicting types for built-in function ‘hypotf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         24 | int hypotf (void);
            |     ^~~~~~
      _configtest.c:24:5: note: ‘hypotf’ is declared in header ‘<math.h>’
      _configtest.c:25:5: warning: conflicting types for built-in function ‘atan2f’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         25 | int atan2f (void);
            |     ^~~~~~
      _configtest.c:25:5: note: ‘atan2f’ is declared in header ‘<math.h>’
      _configtest.c:26:5: warning: conflicting types for built-in function ‘powf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         26 | int powf (void);
            |     ^~~~
      _configtest.c:26:5: note: ‘powf’ is declared in header ‘<math.h>’
      _configtest.c:27:5: warning: conflicting types for built-in function ‘fmodf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         27 | int fmodf (void);
            |     ^~~~~
      _configtest.c:27:5: note: ‘fmodf’ is declared in header ‘<math.h>’
      _configtest.c:28:5: warning: conflicting types for built-in function ‘modff’; expected ‘float(float,  float *)’ [-Wbuiltin-declaration-mismatch]
         28 | int modff (void);
            |     ^~~~~
      _configtest.c:28:5: note: ‘modff’ is declared in header ‘<math.h>’
      _configtest.c:29:5: warning: conflicting types for built-in function ‘frexpf’; expected ‘float(float,  int *)’ [-Wbuiltin-declaration-mismatch]
         29 | int frexpf (void);
            |     ^~~~~~
      _configtest.c:29:5: note: ‘frexpf’ is declared in header ‘<math.h>’
      _configtest.c:30:5: warning: conflicting types for built-in function ‘ldexpf’; expected ‘float(float,  int)’ [-Wbuiltin-declaration-mismatch]
         30 | int ldexpf (void);
            |     ^~~~~~
      _configtest.c:30:5: note: ‘ldexpf’ is declared in header ‘<math.h>’
      _configtest.c:31:5: warning: conflicting types for built-in function ‘exp2f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         31 | int exp2f (void);
            |     ^~~~~
      _configtest.c:31:5: note: ‘exp2f’ is declared in header ‘<math.h>’
      _configtest.c:32:5: warning: conflicting types for built-in function ‘log2f’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         32 | int log2f (void);
            |     ^~~~~
      _configtest.c:32:5: note: ‘log2f’ is declared in header ‘<math.h>’
      _configtest.c:33:5: warning: conflicting types for built-in function ‘copysignf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         33 | int copysignf (void);
            |     ^~~~~~~~~
      _configtest.c:33:5: note: ‘copysignf’ is declared in header ‘<math.h>’
      _configtest.c:34:5: warning: conflicting types for built-in function ‘nextafterf’; expected ‘float(float,  float)’ [-Wbuiltin-declaration-mismatch]
         34 | int nextafterf (void);
            |     ^~~~~~~~~~
      _configtest.c:34:5: note: ‘nextafterf’ is declared in header ‘<math.h>’
      _configtest.c:35:5: warning: conflicting types for built-in function ‘cbrtf’; expected ‘float(float)’ [-Wbuiltin-declaration-mismatch]
         35 | int cbrtf (void);
            |     ^~~~~
      _configtest.c:35:5: note: ‘cbrtf’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘sinl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          1 | int sinl (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘sinl’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int sinl (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cosl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cosl (void);
            |     ^~~~
      _configtest.c:2:5: note: ‘cosl’ is declared in header ‘<math.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘tanl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          3 | int tanl (void);
            |     ^~~~
      _configtest.c:3:5: note: ‘tanl’ is declared in header ‘<math.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘sinhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          4 | int sinhl (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘sinhl’ is declared in header ‘<math.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘coshl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          5 | int coshl (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘coshl’ is declared in header ‘<math.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘tanhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          6 | int tanhl (void);
            |     ^~~~~
      _configtest.c:6:5: note: ‘tanhl’ is declared in header ‘<math.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘fabsl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          7 | int fabsl (void);
            |     ^~~~~
      _configtest.c:7:5: note: ‘fabsl’ is declared in header ‘<math.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘floorl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          8 | int floorl (void);
            |     ^~~~~~
      _configtest.c:8:5: note: ‘floorl’ is declared in header ‘<math.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ceill’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ceill (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ceill’ is declared in header ‘<math.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘rintl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         10 | int rintl (void);
            |     ^~~~~
      _configtest.c:10:5: note: ‘rintl’ is declared in header ‘<math.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘truncl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         11 | int truncl (void);
            |     ^~~~~~
      _configtest.c:11:5: note: ‘truncl’ is declared in header ‘<math.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘sqrtl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         12 | int sqrtl (void);
            |     ^~~~~
      _configtest.c:12:5: note: ‘sqrtl’ is declared in header ‘<math.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘log10l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         13 | int log10l (void);
            |     ^~~~~~
      _configtest.c:13:5: note: ‘log10l’ is declared in header ‘<math.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘logl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         14 | int logl (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘logl’ is declared in header ‘<math.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘log1pl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         15 | int log1pl (void);
            |     ^~~~~~
      _configtest.c:15:5: note: ‘log1pl’ is declared in header ‘<math.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘expl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         16 | int expl (void);
            |     ^~~~
      _configtest.c:16:5: note: ‘expl’ is declared in header ‘<math.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘expm1l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         17 | int expm1l (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘expm1l’ is declared in header ‘<math.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘asinl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         18 | int asinl (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘asinl’ is declared in header ‘<math.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘acosl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         19 | int acosl (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘acosl’ is declared in header ‘<math.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘atanl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         20 | int atanl (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘atanl’ is declared in header ‘<math.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘asinhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         21 | int asinhl (void);
            |     ^~~~~~
      _configtest.c:21:5: note: ‘asinhl’ is declared in header ‘<math.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘acoshl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         22 | int acoshl (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘acoshl’ is declared in header ‘<math.h>’
      _configtest.c:23:5: warning: conflicting types for built-in function ‘atanhl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         23 | int atanhl (void);
            |     ^~~~~~
      _configtest.c:23:5: note: ‘atanhl’ is declared in header ‘<math.h>’
      _configtest.c:24:5: warning: conflicting types for built-in function ‘hypotl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         24 | int hypotl (void);
            |     ^~~~~~
      _configtest.c:24:5: note: ‘hypotl’ is declared in header ‘<math.h>’
      _configtest.c:25:5: warning: conflicting types for built-in function ‘atan2l’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         25 | int atan2l (void);
            |     ^~~~~~
      _configtest.c:25:5: note: ‘atan2l’ is declared in header ‘<math.h>’
      _configtest.c:26:5: warning: conflicting types for built-in function ‘powl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         26 | int powl (void);
            |     ^~~~
      _configtest.c:26:5: note: ‘powl’ is declared in header ‘<math.h>’
      _configtest.c:27:5: warning: conflicting types for built-in function ‘fmodl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         27 | int fmodl (void);
            |     ^~~~~
      _configtest.c:27:5: note: ‘fmodl’ is declared in header ‘<math.h>’
      _configtest.c:28:5: warning: conflicting types for built-in function ‘modfl’; expected ‘long double(long double,  long double *)’ [-Wbuiltin-declaration-mismatch]
         28 | int modfl (void);
            |     ^~~~~
      _configtest.c:28:5: note: ‘modfl’ is declared in header ‘<math.h>’
      _configtest.c:29:5: warning: conflicting types for built-in function ‘frexpl’; expected ‘long double(long double,  int *)’ [-Wbuiltin-declaration-mismatch]
         29 | int frexpl (void);
            |     ^~~~~~
      _configtest.c:29:5: note: ‘frexpl’ is declared in header ‘<math.h>’
      _configtest.c:30:5: warning: conflicting types for built-in function ‘ldexpl’; expected ‘long double(long double,  int)’ [-Wbuiltin-declaration-mismatch]
         30 | int ldexpl (void);
            |     ^~~~~~
      _configtest.c:30:5: note: ‘ldexpl’ is declared in header ‘<math.h>’
      _configtest.c:31:5: warning: conflicting types for built-in function ‘exp2l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         31 | int exp2l (void);
            |     ^~~~~
      _configtest.c:31:5: note: ‘exp2l’ is declared in header ‘<math.h>’
      _configtest.c:32:5: warning: conflicting types for built-in function ‘log2l’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         32 | int log2l (void);
            |     ^~~~~
      _configtest.c:32:5: note: ‘log2l’ is declared in header ‘<math.h>’
      _configtest.c:33:5: warning: conflicting types for built-in function ‘copysignl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         33 | int copysignl (void);
            |     ^~~~~~~~~
      _configtest.c:33:5: note: ‘copysignl’ is declared in header ‘<math.h>’
      _configtest.c:34:5: warning: conflicting types for built-in function ‘nextafterl’; expected ‘long double(long double,  long double)’ [-Wbuiltin-declaration-mismatch]
         34 | int nextafterl (void);
            |     ^~~~~~~~~~
      _configtest.c:34:5: note: ‘nextafterl’ is declared in header ‘<math.h>’
      _configtest.c:35:5: warning: conflicting types for built-in function ‘cbrtl’; expected ‘long double(long double)’ [-Wbuiltin-declaration-mismatch]
         35 | int cbrtl (void);
            |     ^~~~~
      _configtest.c:35:5: note: ‘cbrtl’ is declared in header ‘<math.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c: In function ‘main’:
      _configtest.c:8:12: error: ‘HAVE_DECL_SIGNBIT’ undeclared (first use in this function); did you mean ‘HAVE_DECL_ISNAN’?
          8 |     (void) HAVE_DECL_SIGNBIT;
            |            ^~~~~~~~~~~~~~~~~
            |            HAVE_DECL_ISNAN
      _configtest.c:8:12: note: each undeclared identifier is reported only once for each function it appears in
      failure.
      removing: _configtest.c _configtest.o
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘cabs’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          1 | int cabs (void);
            |     ^~~~
      _configtest.c:1:1: note: ‘cabs’ is declared in header ‘<complex.h>’
        +++ |+#include <complex.h>
          1 | int cabs (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cacos’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cacos (void);
            |     ^~~~~
      _configtest.c:2:5: note: ‘cacos’ is declared in header ‘<complex.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘cacosh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          3 | int cacosh (void);
            |     ^~~~~~
      _configtest.c:3:5: note: ‘cacosh’ is declared in header ‘<complex.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘carg’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          4 | int carg (void);
            |     ^~~~
      _configtest.c:4:5: note: ‘carg’ is declared in header ‘<complex.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘casin’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          5 | int casin (void);
            |     ^~~~~
      _configtest.c:5:5: note: ‘casin’ is declared in header ‘<complex.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘casinh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          6 | int casinh (void);
            |     ^~~~~~
      _configtest.c:6:5: note: ‘casinh’ is declared in header ‘<complex.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘catan’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          7 | int catan (void);
            |     ^~~~~
      _configtest.c:7:5: note: ‘catan’ is declared in header ‘<complex.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘catanh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          8 | int catanh (void);
            |     ^~~~~~
      _configtest.c:8:5: note: ‘catanh’ is declared in header ‘<complex.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ccos’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ccos (void);
            |     ^~~~
      _configtest.c:9:5: note: ‘ccos’ is declared in header ‘<complex.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘ccosh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         10 | int ccosh (void);
            |     ^~~~~
      _configtest.c:10:5: note: ‘ccosh’ is declared in header ‘<complex.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘cexp’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         11 | int cexp (void);
            |     ^~~~
      _configtest.c:11:5: note: ‘cexp’ is declared in header ‘<complex.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘cimag’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         12 | int cimag (void);
            |     ^~~~~
      _configtest.c:12:5: note: ‘cimag’ is declared in header ‘<complex.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘clog’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         13 | int clog (void);
            |     ^~~~
      _configtest.c:13:5: note: ‘clog’ is declared in header ‘<complex.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘conj’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         14 | int conj (void);
            |     ^~~~
      _configtest.c:14:5: note: ‘conj’ is declared in header ‘<complex.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘cpow’; expected ‘_Complex double(_Complex double,  _Complex double)’ [-Wbuiltin-declaration-mismatch]
         15 | int cpow (void);
            |     ^~~~
      _configtest.c:15:5: note: ‘cpow’ is declared in header ‘<complex.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘cproj’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         16 | int cproj (void);
            |     ^~~~~
      _configtest.c:16:5: note: ‘cproj’ is declared in header ‘<complex.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘creal’; expected ‘double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         17 | int creal (void);
            |     ^~~~~
      _configtest.c:17:5: note: ‘creal’ is declared in header ‘<complex.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘csin’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         18 | int csin (void);
            |     ^~~~
      _configtest.c:18:5: note: ‘csin’ is declared in header ‘<complex.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘csinh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         19 | int csinh (void);
            |     ^~~~~
      _configtest.c:19:5: note: ‘csinh’ is declared in header ‘<complex.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘csqrt’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         20 | int csqrt (void);
            |     ^~~~~
      _configtest.c:20:5: note: ‘csqrt’ is declared in header ‘<complex.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘ctan’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         21 | int ctan (void);
            |     ^~~~
      _configtest.c:21:5: note: ‘ctan’ is declared in header ‘<complex.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘ctanh’; expected ‘_Complex double(_Complex double)’ [-Wbuiltin-declaration-mismatch]
         22 | int ctanh (void);
            |     ^~~~~
      _configtest.c:22:5: note: ‘ctanh’ is declared in header ‘<complex.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘cabsf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          1 | int cabsf (void);
            |     ^~~~~
      _configtest.c:1:1: note: ‘cabsf’ is declared in header ‘<complex.h>’
        +++ |+#include <complex.h>
          1 | int cabsf (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cacosf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          2 | int cacosf (void);
            |     ^~~~~~
      _configtest.c:2:5: note: ‘cacosf’ is declared in header ‘<complex.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘cacoshf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          3 | int cacoshf (void);
            |     ^~~~~~~
      _configtest.c:3:5: note: ‘cacoshf’ is declared in header ‘<complex.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘cargf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          4 | int cargf (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘cargf’ is declared in header ‘<complex.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘casinf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          5 | int casinf (void);
            |     ^~~~~~
      _configtest.c:5:5: note: ‘casinf’ is declared in header ‘<complex.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘casinhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          6 | int casinhf (void);
            |     ^~~~~~~
      _configtest.c:6:5: note: ‘casinhf’ is declared in header ‘<complex.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘catanf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          7 | int catanf (void);
            |     ^~~~~~
      _configtest.c:7:5: note: ‘catanf’ is declared in header ‘<complex.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘catanhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          8 | int catanhf (void);
            |     ^~~~~~~
      _configtest.c:8:5: note: ‘catanhf’ is declared in header ‘<complex.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ccosf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
          9 | int ccosf (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ccosf’ is declared in header ‘<complex.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘ccoshf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         10 | int ccoshf (void);
            |     ^~~~~~
      _configtest.c:10:5: note: ‘ccoshf’ is declared in header ‘<complex.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘cexpf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         11 | int cexpf (void);
            |     ^~~~~
      _configtest.c:11:5: note: ‘cexpf’ is declared in header ‘<complex.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘cimagf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         12 | int cimagf (void);
            |     ^~~~~~
      _configtest.c:12:5: note: ‘cimagf’ is declared in header ‘<complex.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘clogf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         13 | int clogf (void);
            |     ^~~~~
      _configtest.c:13:5: note: ‘clogf’ is declared in header ‘<complex.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘conjf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         14 | int conjf (void);
            |     ^~~~~
      _configtest.c:14:5: note: ‘conjf’ is declared in header ‘<complex.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘cpowf’; expected ‘_Complex float(_Complex float,  _Complex float)’ [-Wbuiltin-declaration-mismatch]
         15 | int cpowf (void);
            |     ^~~~~
      _configtest.c:15:5: note: ‘cpowf’ is declared in header ‘<complex.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘cprojf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         16 | int cprojf (void);
            |     ^~~~~~
      _configtest.c:16:5: note: ‘cprojf’ is declared in header ‘<complex.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘crealf’; expected ‘float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         17 | int crealf (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘crealf’ is declared in header ‘<complex.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘csinf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         18 | int csinf (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘csinf’ is declared in header ‘<complex.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘csinhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         19 | int csinhf (void);
            |     ^~~~~~
      _configtest.c:19:5: note: ‘csinhf’ is declared in header ‘<complex.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘csqrtf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         20 | int csqrtf (void);
            |     ^~~~~~
      _configtest.c:20:5: note: ‘csqrtf’ is declared in header ‘<complex.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘ctanf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         21 | int ctanf (void);
            |     ^~~~~
      _configtest.c:21:5: note: ‘ctanf’ is declared in header ‘<complex.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘ctanhf’; expected ‘_Complex float(_Complex float)’ [-Wbuiltin-declaration-mismatch]
         22 | int ctanhf (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘ctanhf’ is declared in header ‘<complex.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘cabsl’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          1 | int cabsl (void);
            |     ^~~~~
      _configtest.c:1:1: note: ‘cabsl’ is declared in header ‘<complex.h>’
        +++ |+#include <complex.h>
          1 | int cabsl (void);
      _configtest.c:2:5: warning: conflicting types for built-in function ‘cacosl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          2 | int cacosl (void);
            |     ^~~~~~
      _configtest.c:2:5: note: ‘cacosl’ is declared in header ‘<complex.h>’
      _configtest.c:3:5: warning: conflicting types for built-in function ‘cacoshl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          3 | int cacoshl (void);
            |     ^~~~~~~
      _configtest.c:3:5: note: ‘cacoshl’ is declared in header ‘<complex.h>’
      _configtest.c:4:5: warning: conflicting types for built-in function ‘cargl’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          4 | int cargl (void);
            |     ^~~~~
      _configtest.c:4:5: note: ‘cargl’ is declared in header ‘<complex.h>’
      _configtest.c:5:5: warning: conflicting types for built-in function ‘casinl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          5 | int casinl (void);
            |     ^~~~~~
      _configtest.c:5:5: note: ‘casinl’ is declared in header ‘<complex.h>’
      _configtest.c:6:5: warning: conflicting types for built-in function ‘casinhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          6 | int casinhl (void);
            |     ^~~~~~~
      _configtest.c:6:5: note: ‘casinhl’ is declared in header ‘<complex.h>’
      _configtest.c:7:5: warning: conflicting types for built-in function ‘catanl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          7 | int catanl (void);
            |     ^~~~~~
      _configtest.c:7:5: note: ‘catanl’ is declared in header ‘<complex.h>’
      _configtest.c:8:5: warning: conflicting types for built-in function ‘catanhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          8 | int catanhl (void);
            |     ^~~~~~~
      _configtest.c:8:5: note: ‘catanhl’ is declared in header ‘<complex.h>’
      _configtest.c:9:5: warning: conflicting types for built-in function ‘ccosl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
          9 | int ccosl (void);
            |     ^~~~~
      _configtest.c:9:5: note: ‘ccosl’ is declared in header ‘<complex.h>’
      _configtest.c:10:5: warning: conflicting types for built-in function ‘ccoshl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         10 | int ccoshl (void);
            |     ^~~~~~
      _configtest.c:10:5: note: ‘ccoshl’ is declared in header ‘<complex.h>’
      _configtest.c:11:5: warning: conflicting types for built-in function ‘cexpl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         11 | int cexpl (void);
            |     ^~~~~
      _configtest.c:11:5: note: ‘cexpl’ is declared in header ‘<complex.h>’
      _configtest.c:12:5: warning: conflicting types for built-in function ‘cimagl’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         12 | int cimagl (void);
            |     ^~~~~~
      _configtest.c:12:5: note: ‘cimagl’ is declared in header ‘<complex.h>’
      _configtest.c:13:5: warning: conflicting types for built-in function ‘clogl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         13 | int clogl (void);
            |     ^~~~~
      _configtest.c:13:5: note: ‘clogl’ is declared in header ‘<complex.h>’
      _configtest.c:14:5: warning: conflicting types for built-in function ‘conjl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         14 | int conjl (void);
            |     ^~~~~
      _configtest.c:14:5: note: ‘conjl’ is declared in header ‘<complex.h>’
      _configtest.c:15:5: warning: conflicting types for built-in function ‘cpowl’; expected ‘_Complex long double(_Complex long double,  _Complex long double)’ [-Wbuiltin-declaration-mismatch]
         15 | int cpowl (void);
            |     ^~~~~
      _configtest.c:15:5: note: ‘cpowl’ is declared in header ‘<complex.h>’
      _configtest.c:16:5: warning: conflicting types for built-in function ‘cprojl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         16 | int cprojl (void);
            |     ^~~~~~
      _configtest.c:16:5: note: ‘cprojl’ is declared in header ‘<complex.h>’
      _configtest.c:17:5: warning: conflicting types for built-in function ‘creall’; expected ‘long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         17 | int creall (void);
            |     ^~~~~~
      _configtest.c:17:5: note: ‘creall’ is declared in header ‘<complex.h>’
      _configtest.c:18:5: warning: conflicting types for built-in function ‘csinl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         18 | int csinl (void);
            |     ^~~~~
      _configtest.c:18:5: note: ‘csinl’ is declared in header ‘<complex.h>’
      _configtest.c:19:5: warning: conflicting types for built-in function ‘csinhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         19 | int csinhl (void);
            |     ^~~~~~
      _configtest.c:19:5: note: ‘csinhl’ is declared in header ‘<complex.h>’
      _configtest.c:20:5: warning: conflicting types for built-in function ‘csqrtl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         20 | int csqrtl (void);
            |     ^~~~~~
      _configtest.c:20:5: note: ‘csqrtl’ is declared in header ‘<complex.h>’
      _configtest.c:21:5: warning: conflicting types for built-in function ‘ctanl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         21 | int ctanl (void);
            |     ^~~~~
      _configtest.c:21:5: note: ‘ctanl’ is declared in header ‘<complex.h>’
      _configtest.c:22:5: warning: conflicting types for built-in function ‘ctanhl’; expected ‘_Complex long double(_Complex long double)’ [-Wbuiltin-declaration-mismatch]
         22 | int ctanhl (void);
            |     ^~~~~~
      _configtest.c:22:5: note: ‘ctanhl’ is declared in header ‘<complex.h>’
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:2:12: warning: ‘static_func’ defined but not used [-Wunused-function]
          2 | static int static_func (char * restrict a)
            |            ^~~~~~~~~~~
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      removing: _configtest.c _configtest.o _configtest.o.d
      File: build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h
      #define HAVE_ENDIAN_H 1
      #define SIZEOF_PY_INTPTR_T 8
      #define SIZEOF_OFF_T 8
      #define SIZEOF_PY_LONG_LONG 8
      #define MATHLIB m
      #define HAVE_SIN 1
      #define HAVE_COS 1
      #define HAVE_TAN 1
      #define HAVE_SINH 1
      #define HAVE_COSH 1
      #define HAVE_TANH 1
      #define HAVE_FABS 1
      #define HAVE_FLOOR 1
      #define HAVE_CEIL 1
      #define HAVE_SQRT 1
      #define HAVE_LOG10 1
      #define HAVE_LOG 1
      #define HAVE_EXP 1
      #define HAVE_ASIN 1
      #define HAVE_ACOS 1
      #define HAVE_ATAN 1
      #define HAVE_FMOD 1
      #define HAVE_MODF 1
      #define HAVE_FREXP 1
      #define HAVE_LDEXP 1
      #define HAVE_RINT 1
      #define HAVE_TRUNC 1
      #define HAVE_EXP2 1
      #define HAVE_LOG2 1
      #define HAVE_ATAN2 1
      #define HAVE_POW 1
      #define HAVE_NEXTAFTER 1
      #define HAVE_STRTOLL 1
      #define HAVE_STRTOULL 1
      #define HAVE_CBRT 1
      #define HAVE_STRTOLD_L 1
      #define HAVE_FALLOCATE 1
      #define HAVE_BACKTRACE 1
      #define HAVE_MADVISE 1
      #define HAVE_XMMINTRIN_H 1
      #define HAVE_EMMINTRIN_H 1
      #define HAVE_FEATURES_H 1
      #define HAVE_DLFCN_H 1
      #define HAVE_SYS_MMAN_H 1
      #define HAVE___BUILTIN_ISNAN 1
      #define HAVE___BUILTIN_ISINF 1
      #define HAVE___BUILTIN_ISFINITE 1
      #define HAVE___BUILTIN_BSWAP32 1
      #define HAVE___BUILTIN_BSWAP64 1
      #define HAVE___BUILTIN_EXPECT 1
      #define HAVE___BUILTIN_MUL_OVERFLOW 1
      #define HAVE___BUILTIN_CPU_SUPPORTS 1
      #define HAVE__M_FROM_INT64 1
      #define HAVE__MM_LOAD_PS 1
      #define HAVE__MM_PREFETCH 1
      #define HAVE__MM_LOAD_PD 1
      #define HAVE___BUILTIN_PREFETCH 1
      #define HAVE_LINK_AVX 1
      #define HAVE_LINK_AVX2 1
      #define HAVE_XGETBV 1
      #define HAVE_ATTRIBUTE_OPTIMIZE_UNROLL_LOOPS 1
      #define HAVE_ATTRIBUTE_OPTIMIZE_OPT_3 1
      #define HAVE_ATTRIBUTE_NONNULL 1
      #define HAVE_ATTRIBUTE_TARGET_AVX 1
      #define HAVE_ATTRIBUTE_TARGET_AVX2 1
      #define HAVE___THREAD 1
      #define HAVE_SINF 1
      #define HAVE_COSF 1
      #define HAVE_TANF 1
      #define HAVE_SINHF 1
      #define HAVE_COSHF 1
      #define HAVE_TANHF 1
      #define HAVE_FABSF 1
      #define HAVE_FLOORF 1
      #define HAVE_CEILF 1
      #define HAVE_RINTF 1
      #define HAVE_TRUNCF 1
      #define HAVE_SQRTF 1
      #define HAVE_LOG10F 1
      #define HAVE_LOGF 1
      #define HAVE_LOG1PF 1
      #define HAVE_EXPF 1
      #define HAVE_EXPM1F 1
      #define HAVE_ASINF 1
      #define HAVE_ACOSF 1
      #define HAVE_ATANF 1
      #define HAVE_ASINHF 1
      #define HAVE_ACOSHF 1
      #define HAVE_ATANHF 1
      #define HAVE_HYPOTF 1
      #define HAVE_ATAN2F 1
      #define HAVE_POWF 1
      #define HAVE_FMODF 1
      #define HAVE_MODFF 1
      #define HAVE_FREXPF 1
      #define HAVE_LDEXPF 1
      #define HAVE_EXP2F 1
      #define HAVE_LOG2F 1
      #define HAVE_COPYSIGNF 1
      #define HAVE_NEXTAFTERF 1
      #define HAVE_CBRTF 1
      #define HAVE_SINL 1
      #define HAVE_COSL 1
      #define HAVE_TANL 1
      #define HAVE_SINHL 1
      #define HAVE_COSHL 1
      #define HAVE_TANHL 1
      #define HAVE_FABSL 1
      #define HAVE_FLOORL 1
      #define HAVE_CEILL 1
      #define HAVE_RINTL 1
      #define HAVE_TRUNCL 1
      #define HAVE_SQRTL 1
      #define HAVE_LOG10L 1
      #define HAVE_LOGL 1
      #define HAVE_LOG1PL 1
      #define HAVE_EXPL 1
      #define HAVE_EXPM1L 1
      #define HAVE_ASINL 1
      #define HAVE_ACOSL 1
      #define HAVE_ATANL 1
      #define HAVE_ASINHL 1
      #define HAVE_ACOSHL 1
      #define HAVE_ATANHL 1
      #define HAVE_HYPOTL 1
      #define HAVE_ATAN2L 1
      #define HAVE_POWL 1
      #define HAVE_FMODL 1
      #define HAVE_MODFL 1
      #define HAVE_FREXPL 1
      #define HAVE_LDEXPL 1
      #define HAVE_EXP2L 1
      #define HAVE_LOG2L 1
      #define HAVE_COPYSIGNL 1
      #define HAVE_NEXTAFTERL 1
      #define HAVE_CBRTL 1
      #define HAVE_DECL_SIGNBIT
      #define HAVE_COMPLEX_H 1
      #define HAVE_CABS 1
      #define HAVE_CACOS 1
      #define HAVE_CACOSH 1
      #define HAVE_CARG 1
      #define HAVE_CASIN 1
      #define HAVE_CASINH 1
      #define HAVE_CATAN 1
      #define HAVE_CATANH 1
      #define HAVE_CCOS 1
      #define HAVE_CCOSH 1
      #define HAVE_CEXP 1
      #define HAVE_CIMAG 1
      #define HAVE_CLOG 1
      #define HAVE_CONJ 1
      #define HAVE_CPOW 1
      #define HAVE_CPROJ 1
      #define HAVE_CREAL 1
      #define HAVE_CSIN 1
      #define HAVE_CSINH 1
      #define HAVE_CSQRT 1
      #define HAVE_CTAN 1
      #define HAVE_CTANH 1
      #define HAVE_CABSF 1
      #define HAVE_CACOSF 1
      #define HAVE_CACOSHF 1
      #define HAVE_CARGF 1
      #define HAVE_CASINF 1
      #define HAVE_CASINHF 1
      #define HAVE_CATANF 1
      #define HAVE_CATANHF 1
      #define HAVE_CCOSF 1
      #define HAVE_CCOSHF 1
      #define HAVE_CEXPF 1
      #define HAVE_CIMAGF 1
      #define HAVE_CLOGF 1
      #define HAVE_CONJF 1
      #define HAVE_CPOWF 1
      #define HAVE_CPROJF 1
      #define HAVE_CREALF 1
      #define HAVE_CSINF 1
      #define HAVE_CSINHF 1
      #define HAVE_CSQRTF 1
      #define HAVE_CTANF 1
      #define HAVE_CTANHF 1
      #define HAVE_CABSL 1
      #define HAVE_CACOSL 1
      #define HAVE_CACOSHL 1
      #define HAVE_CARGL 1
      #define HAVE_CASINL 1
      #define HAVE_CASINHL 1
      #define HAVE_CATANL 1
      #define HAVE_CATANHL 1
      #define HAVE_CCOSL 1
      #define HAVE_CCOSHL 1
      #define HAVE_CEXPL 1
      #define HAVE_CIMAGL 1
      #define HAVE_CLOGL 1
      #define HAVE_CONJL 1
      #define HAVE_CPOWL 1
      #define HAVE_CPROJL 1
      #define HAVE_CREALL 1
      #define HAVE_CSINL 1
      #define HAVE_CSINHL 1
      #define HAVE_CSQRTL 1
      #define HAVE_CTANL 1
      #define HAVE_CTANHL 1
      #define NPY_RESTRICT restrict
      #define NPY_RELAXED_STRIDES_CHECKING 1
      #define HAVE_LDOUBLE_INTEL_EXTENDED_16_BYTES_LE 1
      #define NPY_PY3K 1
      #ifndef __cplusplus
      /* #undef inline */
      #endif
      
      #ifndef _NPY_NPY_CONFIG_H_
      #error config.h should never be included directly, include npy_config.h instead
      #endif
      
      EOF
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h' to sources.
      Generating build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -o _configtest
      /opt/conda/compiler_compat/ld: _configtest.o: in function \`main':
      _configtest.c:(.text.startup+0x9): undefined reference to \`exp'
      collect2: error: ld returned 1 exit status
      failure.
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:1:5: warning: conflicting types for built-in function ‘exp’; expected ‘double(double)’ [-Wbuiltin-declaration-mismatch]
          1 | int exp (void);
            |     ^~~
      _configtest.c:1:1: note: ‘exp’ is declared in header ‘<math.h>’
        +++ |+#include <math.h>
          1 | int exp (void);
      gcc -pthread -B /opt/conda/compiler_compat _configtest.o -lm -o _configtest
      success!
      removing: _configtest.c _configtest.o _configtest.o.d _configtest
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -c'
      gcc: _configtest.c
      _configtest.c:3: warning: ignoring ‘#pragma clang diagnostic’ [-Wunknown-pragmas]
          3 | #pragma clang diagnostic error "-Wattributes"
            |
      success!
      removing: _configtest.c _configtest.o _configtest.o.d
      File: build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h
      #define NPY_HAVE_ENDIAN_H 1
      #define NPY_SIZEOF_SHORT SIZEOF_SHORT
      #define NPY_SIZEOF_INT SIZEOF_INT
      #define NPY_SIZEOF_LONG SIZEOF_LONG
      #define NPY_SIZEOF_FLOAT 4
      #define NPY_SIZEOF_COMPLEX_FLOAT 8
      #define NPY_SIZEOF_DOUBLE 8
      #define NPY_SIZEOF_COMPLEX_DOUBLE 16
      #define NPY_SIZEOF_LONGDOUBLE 16
      #define NPY_SIZEOF_COMPLEX_LONGDOUBLE 32
      #define NPY_SIZEOF_PY_INTPTR_T 8
      #define NPY_SIZEOF_OFF_T 8
      #define NPY_SIZEOF_PY_LONG_LONG 8
      #define NPY_SIZEOF_LONGLONG 8
      #define NPY_NO_SMP 0
      #define NPY_HAVE_DECL_ISNAN
      #define NPY_HAVE_DECL_ISINF
      #define NPY_HAVE_DECL_ISFINITE
      #define NPY_HAVE_DECL_SIGNBIT
      #define NPY_USE_C99_COMPLEX 1
      #define NPY_HAVE_COMPLEX_DOUBLE 1
      #define NPY_HAVE_COMPLEX_FLOAT 1
      #define NPY_HAVE_COMPLEX_LONG_DOUBLE 1
      #define NPY_RELAXED_STRIDES_CHECKING 1
      #define NPY_USE_C99_FORMATS 1
      #define NPY_VISIBILITY_HIDDEN __attribute__((visibility("hidden")))
      #define NPY_ABI_VERSION 0x01000009
      #define NPY_API_VERSION 0x0000000D
      
      #ifndef __STDC_FORMAT_MACROS
      #define __STDC_FORMAT_MACROS 1
      #endif
      
      EOF
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h' to sources.
      executing numpy/core/code_generators/generate_numpy_api.py
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h' to sources.
      numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h']
      building extension "numpy.core._multiarray_tests" sources
      creating build/src.linux-x86_64-3.9/numpy/core/src/multiarray
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/_multiarray_tests.c
      building extension "numpy.core._multiarray_umath" sources
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h' to sources.
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h' to sources.
      executing numpy/core/code_generators/generate_numpy_api.py
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h' to sources.
      executing numpy/core/code_generators/generate_ufunc_api.py
        adding 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__ufunc_api.h' to sources.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/arraytypes.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/einsum.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/lowlevel_strided_loops.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/nditer_templ.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/multiarray/scalartypes.c
      creating build/src.linux-x86_64-3.9/numpy/core/src/umath
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/funcs.inc
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/umath' to include_dirs.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/simd.inc
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.h
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.c
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/scalarmath.c
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/npymath' to include_dirs.
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/common/templ_common.h
        adding 'build/src.linux-x86_64-3.9/numpy/core/src/common' to include_dirs.
      numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.9/numpy/core/src/umath/funcs.inc', 'build/src.linux-x86_64-3.9/numpy/core/src/umath/simd.inc', 'build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.h', 'build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.h', 'build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_internal.h', 'build/src.linux-x86_64-3.9/numpy/core/src/common/templ_common.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__multiarray_api.h', 'build/src.linux-x86_64-3.9/numpy/core/include/numpy/__ufunc_api.h']
      building extension "numpy.core._umath_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_umath_tests.c
      building extension "numpy.core._rational_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_rational_tests.c
      building extension "numpy.core._struct_ufunc_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_struct_ufunc_tests.c
      building extension "numpy.core._operand_flag_tests" sources
      conv_template:> build/src.linux-x86_64-3.9/numpy/core/src/umath/_operand_flag_tests.c
      building extension "numpy.fft.fftpack_lite" sources
      building extension "numpy.linalg.lapack_lite" sources
      creating build/src.linux-x86_64-3.9/numpy/linalg
      ### Warning:  Using unoptimized lapack ###
        adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_z_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_d_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_s_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_blas.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_config.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c.c' to sources.
      building extension "numpy.linalg._umath_linalg" sources
      ### Warning:  Using unoptimized lapack ###
        adding 'numpy/linalg/lapack_lite/python_xerbla.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_z_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_d_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_s_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_lapack.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_blas.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c_config.c' to sources.
        adding 'numpy/linalg/lapack_lite/f2c.c' to sources.
      conv_template:> build/src.linux-x86_64-3.9/numpy/linalg/umath_linalg.c
      building extension "numpy.random.mtrand" sources
      creating build/src.linux-x86_64-3.9/numpy/random
      building data_files sources
      build_src: building npy-pkg config files
      /opt/conda/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
      !!
      
              ********************************************************************************
              Please avoid running \`\`setup.py\`\` directly.
              Instead, use pypa/build, pypa/installer or other
              standards-based tools.
      
              See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
              ********************************************************************************
      
      !!
        self.initialize_options()
      running build_py
      creating build/lib.linux-x86_64-cpython-39
      creating build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/matlib.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/ctypeslib.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/_pytesttester.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/version.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/dual.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/_globals.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/setup.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/conftest.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying numpy/_distributor_init.py -> build/lib.linux-x86_64-cpython-39/numpy
      copying build/src.linux-x86_64-3.9/numpy/__config__.py -> build/lib.linux-x86_64-cpython-39/numpy
      creating build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/_inspect.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/py3k.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      copying numpy/compat/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/compat
      creating build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/multiarray.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_dtype_ctypes.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_type_aliases.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_aliased_types.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_methods.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/arrayprint.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/cversions.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_dtype.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_string_helpers.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/records.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/numeric.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/machar.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/umath.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/umath_tests.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/numerictypes.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/info.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/getlimits.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/einsumfunc.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/memmap.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/overrides.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/function_base.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_internal.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/setup_common.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/defchararray.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/shape_base.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/fromnumeric.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/_add_newdocs.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      copying numpy/core/code_generators/generate_numpy_api.py -> build/lib.linux-x86_64-cpython-39/numpy/core
      creating build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/pathccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/msvccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/log.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/conv_template.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/npy_pkg_config.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/ccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/numpy_distribution.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/misc_util.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/intelccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/core.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/mingw32ccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/info.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/lib2def.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/_shell_utils.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/system_info.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/exec_command.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/compat.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/from_template.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/cpuinfo.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/__version__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/msvc9compiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/unixccompiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/line_endings.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying numpy/distutils/extension.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      copying build/src.linux-x86_64-3.9/numpy/distutils/__config__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils
      creating build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/config_compiler.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_scripts.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/sdist.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_ext.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/bdist_rpm.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_clib.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install_headers.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/config.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/develop.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_src.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/build_py.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install_data.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/egg_info.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install_clib.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/autodist.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      copying numpy/distutils/command/install.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/command
      creating build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/absoft.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/pg.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/environment.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/intel.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/pathf95.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/compaq.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/nag.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/mips.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/lahey.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/gnu.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/none.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/g95.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/vast.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/sun.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/ibm.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      copying numpy/distutils/fcompiler/hpux.py -> build/lib.linux-x86_64-cpython-39/numpy/distutils/fcompiler
      creating build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/basics.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/glossary.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/structured_arrays.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/byteswapping.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/internals.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/ufuncs.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/indexing.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/creation.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/broadcasting.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/misc.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/constants.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      copying numpy/doc/subclassing.py -> build/lib.linux-x86_64-cpython-39/numpy/doc
      creating build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/diagnose.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/cfuncs.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/cb_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/common_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/f2py2e.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/use_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/func2subr.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/info.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/__main__.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/f2py_testing.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/__version__.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/crackfortran.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/auxfuncs.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/capi_maps.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      copying numpy/f2py/f90mod_rules.py -> build/lib.linux-x86_64-cpython-39/numpy/f2py
      creating build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/fftpack.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/helper.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/info.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      copying numpy/fft/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/fft
      creating build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/index_tricks.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/format.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/npyio.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/mixins.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/scimath.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/arrayterator.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/info.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/histograms.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/_iotools.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/_version.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/arraysetops.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/user_array.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/function_base.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/financial.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/polynomial.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/stride_tricks.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/shape_base.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/ufunclike.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/_datasource.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/twodim_base.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/arraypad.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/recfunctions.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/type_check.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/utils.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      copying numpy/lib/nanfunctions.py -> build/lib.linux-x86_64-cpython-39/numpy/lib
      creating build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/info.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      copying numpy/linalg/linalg.py -> build/lib.linux-x86_64-cpython-39/numpy/linalg
      creating build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/mrecords.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/timer_comparison.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/extras.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/version.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/core.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/bench.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      copying numpy/ma/testutils.py -> build/lib.linux-x86_64-cpython-39/numpy/ma
      creating build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      copying numpy/matrixlib/defmatrix.py -> build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      copying numpy/matrixlib/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      copying numpy/matrixlib/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/matrixlib
      creating build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/legendre.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/laguerre.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/chebyshev.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/polyutils.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/_polybase.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/polynomial.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/hermite_e.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      copying numpy/polynomial/hermite.py -> build/lib.linux-x86_64-cpython-39/numpy/polynomial
      creating build/lib.linux-x86_64-cpython-39/numpy/random
      copying numpy/random/info.py -> build/lib.linux-x86_64-cpython-39/numpy/random
      copying numpy/random/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/random
      copying numpy/random/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/random
      creating build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/decorators.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/nosetester.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/setup.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/print_coercion_tables.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/noseclasses.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      copying numpy/testing/utils.py -> build/lib.linux-x86_64-cpython-39/numpy/testing
      creating build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/decorators.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/parameterized.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/nosetester.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/__init__.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/noseclasses.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      copying numpy/testing/_private/utils.py -> build/lib.linux-x86_64-cpython-39/numpy/testing/_private
      running build_clib
      customize UnixCCompiler
      customize UnixCCompiler using build_clib
      building 'npymath' library
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39
      creating build/temp.linux-x86_64-cpython-39/numpy
      creating build/temp.linux-x86_64-cpython-39/numpy/core
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/npymath
      creating build/temp.linux-x86_64-cpython-39/build
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npymath
      compile options: '-Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/core/src/npymath/npy_math.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.c
      gcc: numpy/core/src/npymath/halffloat.c
      ar: adding 4 object files to build/temp.linux-x86_64-cpython-39/libnpymath.a
      building 'npysort' library
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npysort
      compile options: '-Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/mergesort.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/heapsort.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/selection.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npysort/binsearch.c
      ar: adding 5 object files to build/temp.linux-x86_64-cpython-39/libnpysort.a
      running build_ext
      customize UnixCCompiler
      customize UnixCCompiler using build_ext
      building 'numpy.core._dummy' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/core/src/dummymodule.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/core/src/dummymodule.o -Lbuild/temp.linux-x86_64-cpython-39 -lm -o build/lib.linux-x86_64-cpython-39/numpy/core/_dummy.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._multiarray_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/common
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/_multiarray_tests.c
      gcc: numpy/core/src/common/mem_overlap.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/_multiarray_tests.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/mem_overlap.o -Lbuild/temp.linux-x86_64-cpython-39 -lnpymath -o build/lib.linux-x86_64-cpython-39/numpy/core/_multiarray_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._multiarray_umath' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray
      creating build/temp.linux-x86_64-cpython-39/numpy/core/src/umath
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/core/src/multiarray/alloc.c
      gcc: numpy/core/src/multiarray/common.c
      numpy/core/src/multiarray/common.c: In function ‘PyArray_DTypeFromObjectHelper’:
      numpy/core/src/multiarray/common.c:187:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        187 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:187:17: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        187 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:187:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        187 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:239:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        239 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:239:17: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        239 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:239:17: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        239 |                 itemsize = PyUnicode_GET_DATA_SIZE(temp);
            |                 ^~~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:282:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        282 |         int itemsize = PyUnicode_GET_DATA_SIZE(obj);
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:282:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        282 |         int itemsize = PyUnicode_GET_DATA_SIZE(obj);
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/common.c:282:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        282 |         int itemsize = PyUnicode_GET_DATA_SIZE(obj);
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/common.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/arrayobject.c
      gcc: numpy/core/src/multiarray/convert.c
      gcc: numpy/core/src/multiarray/convert_datatype.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/arraytypes.c
      numpy/core/src/multiarray/arraytypes.c.src: In function ‘UNICODE_setitem’:
      numpy/core/src/multiarray/arraytypes.c.src:489:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        489 |     ptr = PyUnicode_AS_UNICODE(temp);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/arraytypes.c.src:494:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        494 |     datalen = PyUnicode_GET_DATA_SIZE(temp);
            |     ^~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/arraytypes.c.src:494:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        494 |     datalen = PyUnicode_GET_DATA_SIZE(temp);
            |     ^~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/arraytypes.c.src:494:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        494 |     datalen = PyUnicode_GET_DATA_SIZE(temp);
            |     ^~~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/arraytypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/conversion_utils.c
      gcc: numpy/core/src/multiarray/ctors.c
      numpy/core/src/multiarray/ctors.c: In function ‘_is_default_descr’:
      numpy/core/src/multiarray/ctors.c:2263:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       2263 |     if (!(PyUString_Check(name) && PyUString_GET_SIZE(name) == 0)) {
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/ctors.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/ctors.c:2263:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       2263 |     if (!(PyUString_Check(name) && PyUString_GET_SIZE(name) == 0)) {
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/ctors.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/ctors.c:2263:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       2263 |     if (!(PyUString_Check(name) && PyUString_GET_SIZE(name) == 0)) {
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/ctors.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/datetime.c
      gcc: numpy/core/src/multiarray/datetime_strings.c
      gcc: numpy/core/src/multiarray/datetime_busday.c
      gcc: numpy/core/src/multiarray/datetime_busdaycal.c
      gcc: numpy/core/src/multiarray/descriptor.c
      numpy/core/src/multiarray/descriptor.c: In function ‘_convert_from_array_descr’:
      numpy/core/src/multiarray/descriptor.c:440:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        440 |         if (PyUString_GET_SIZE(name) == 0) {
            |         ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:440:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        440 |         if (PyUString_GET_SIZE(name) == 0) {
            |         ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:440:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        440 |         if (PyUString_GET_SIZE(name) == 0) {
            |         ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:447:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        447 |             else if (PyUString_Check(title) && PyUString_GET_SIZE(title) > 0) {
            |             ^~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:447:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        447 |             else if (PyUString_Check(title) && PyUString_GET_SIZE(title) > 0) {
            |             ^~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/descriptor.c:447:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        447 |             else if (PyUString_Check(title) && PyUString_GET_SIZE(title) > 0) {
            |             ^~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/descriptor.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/dragon4.c
      gcc: numpy/core/src/multiarray/dtype_transfer.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/einsum.c
      gcc: numpy/core/src/multiarray/array_assign_scalar.c
      gcc: numpy/core/src/multiarray/array_assign_array.c
      gcc: numpy/core/src/multiarray/arrayfunction_override.c
      gcc: numpy/core/src/multiarray/buffer.c
      gcc: numpy/core/src/multiarray/calculation.c
      gcc: numpy/core/src/multiarray/compiled_base.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/lowlevel_strided_loops.c
      gcc: numpy/core/src/multiarray/flagsobject.c
      gcc: numpy/core/src/multiarray/getset.c
      gcc: numpy/core/src/multiarray/hashdescr.c
      gcc: numpy/core/src/multiarray/item_selection.c
      gcc: numpy/core/src/multiarray/iterators.c
      gcc: numpy/core/src/multiarray/refcount.c
      gcc: numpy/core/src/multiarray/sequence.c
      gcc: numpy/core/src/multiarray/shape.c
      gcc: numpy/core/src/multiarray/scalarapi.c
      numpy/core/src/multiarray/scalarapi.c: In function ‘scalar_value’:
      numpy/core/src/multiarray/scalarapi.c:74:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
         74 |             return (void *)PyUnicode_AS_DATA(scalar);
            |             ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c:135:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        135 |             return (void *)PyUnicode_AS_DATA(scalar);
            |             ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c: In function ‘PyArray_DescrFromScalar’:
      numpy/core/src/multiarray/scalarapi.c:568:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        568 |             descr->elsize = PyUnicode_GET_DATA_SIZE(sc);
            |             ^~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c:568:13: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        568 |             descr->elsize = PyUnicode_GET_DATA_SIZE(sc);
            |             ^~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalarapi.c:568:13: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        568 |             descr->elsize = PyUnicode_GET_DATA_SIZE(sc);
            |             ^~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalarapi.c:2:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/scalartypes.c
      numpy/core/src/multiarray/scalartypes.c.src: In function ‘unicodetype_repr’:
      numpy/core/src/multiarray/scalartypes.c.src:475:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        475 |     ip = dptr = Py@Name@_AS_@NAME@(self);
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:481:5: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
        481 |     new = Py@Name@_From@Name@@extra@(ip, len);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src: In function ‘unicodetype_str’:
      numpy/core/src/multiarray/scalartypes.c.src:475:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        475 |     ip = dptr = Py@Name@_AS_@NAME@(self);
            |     ^~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
        476 |     len = Py@Name@_GET_SIZE(self);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:481:5: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
        481 |     new = Py@Name@_From@Name@@extra@(ip, len);
            |     ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src: In function ‘gentype_reduce’:
      numpy/core/src/multiarray/scalartypes.c.src:1849:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       1849 |         buffer = PyUnicode_AS_DATA(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/multiarray/scalartypes.c.src:3:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/strfuncs.c
      numpy/core/src/multiarray/strfuncs.c: In function ‘array_repr’:
      numpy/core/src/multiarray/strfuncs.c:178:9: warning: ‘PyEval_CallObjectWithKeywords’ is deprecated [-Wdeprecated-declarations]
        178 |         s = PyEval_CallObject(PyArray_ReprFunction, arglist);
            |         ^
      In file included from /opt/conda/include/python3.9/Python.h:140,
                       from numpy/core/src/multiarray/strfuncs.c:4:
      /opt/conda/include/python3.9/ceval.h:17:43: note: declared here
         17 | Py_DEPRECATED(3.9) PyAPI_FUNC(PyObject *) PyEval_CallObjectWithKeywords(
            |                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/core/src/multiarray/strfuncs.c: In function ‘array_str’:
      numpy/core/src/multiarray/strfuncs.c:195:9: warning: ‘PyEval_CallObjectWithKeywords’ is deprecated [-Wdeprecated-declarations]
        195 |         s = PyEval_CallObject(PyArray_StrFunction, arglist);
            |         ^
      In file included from /opt/conda/include/python3.9/Python.h:140,
                       from numpy/core/src/multiarray/strfuncs.c:4:
      /opt/conda/include/python3.9/ceval.h:17:43: note: declared here
         17 | Py_DEPRECATED(3.9) PyAPI_FUNC(PyObject *) PyEval_CallObjectWithKeywords(
            |                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/temp_elide.c
      gcc: numpy/core/src/multiarray/typeinfo.c
      gcc: numpy/core/src/multiarray/usertypes.c
      gcc: numpy/core/src/multiarray/vdot.c
      gcc: numpy/core/src/umath/umathmodule.c
      gcc: numpy/core/src/umath/reduction.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.c
      numpy/core/src/umath/loops.c.src: In function ‘PyUFunc_On_Om’:
      numpy/core/src/umath/loops.c.src:655:9: warning: ‘PyEval_CallObjectWithKeywords’ is deprecated [-Wdeprecated-declarations]
        655 |         result = PyEval_CallObject(tocall, arglist);
            |         ^~~~~~
      In file included from /opt/conda/include/python3.9/Python.h:140,
                       from numpy/core/src/umath/loops.c.src:7:
      /opt/conda/include/python3.9/ceval.h:17:43: note: declared here
         17 | Py_DEPRECATED(3.9) PyAPI_FUNC(PyObject *) PyEval_CallObjectWithKeywords(
            |                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/multiarray/mapping.c
      gcc: numpy/core/src/multiarray/methods.c
      gcc: numpy/core/src/multiarray/multiarraymodule.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/multiarray/nditer_templ.c
      gcc: numpy/core/src/multiarray/nditer_api.c
      gcc: numpy/core/src/multiarray/nditer_constr.c
      gcc: numpy/core/src/multiarray/nditer_pywrap.c
      gcc: numpy/core/src/multiarray/number.c
      gcc: numpy/core/src/umath/ufunc_type_resolution.c
      gcc: numpy/core/src/umath/override.c
      gcc: numpy/core/src/npymath/npy_math.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.c
      gcc: numpy/core/src/npymath/halffloat.c
      gcc: numpy/core/src/common/array_assign.c
      gcc: numpy/core/src/common/mem_overlap.c
      gcc: numpy/core/src/common/npy_longdouble.c
      gcc: numpy/core/src/common/ucsnarrow.c
      numpy/core/src/common/ucsnarrow.c: In function ‘PyUnicode_FromUCS4’:
      numpy/core/src/common/ucsnarrow.c:139:9: warning: ‘PyUnicode_FromUnicode’ is deprecated [-Wdeprecated-declarations]
        139 |         ret = (PyUnicodeObject *)PyUnicode_FromUnicode((Py_UNICODE*)buf,
            |         ^~~
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/core/src/common/ucsnarrow.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:551:42: note: declared here
        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(
            |                                          ^~~~~~~~~~~~~~~~~~~~~
      gcc: numpy/core/src/common/ufunc_override.c
      gcc: numpy/core/src/common/numpyos.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.c
      gcc: numpy/core/src/umath/ufunc_object.c
      numpy/core/src/umath/ufunc_object.c: In function ‘_parse_signature’:
      numpy/core/src/umath/ufunc_object.c:657:19: warning: comparison of integer expressions of different signedness: ‘int’ and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]
        657 |     for (i = 0; i < len; i++) {
            |                   ^
      gcc: numpy/core/src/umath/extobj.c
      gcc: numpy/core/src/umath/cpuid.c
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/scalarmath.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/alloc.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/arrayobject.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/arraytypes.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/array_assign_scalar.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/array_assign_array.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/arrayfunction_override.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/buffer.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/calculation.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/compiled_base.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/common.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/convert.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/convert_datatype.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/conversion_utils.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/ctors.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime_strings.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime_busday.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/datetime_busdaycal.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/descriptor.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/dragon4.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/dtype_transfer.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/einsum.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/flagsobject.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/getset.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/hashdescr.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/item_selection.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/iterators.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/lowlevel_strided_loops.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/mapping.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/methods.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/multiarraymodule.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/nditer_templ.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/nditer_api.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/nditer_constr.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/nditer_pywrap.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/number.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/refcount.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/sequence.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/shape.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/scalarapi.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/multiarray/scalartypes.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/strfuncs.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/temp_elide.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/typeinfo.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/usertypes.o build/temp.linux-x86_64-cpython-39/numpy/core/src/multiarray/vdot.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/umathmodule.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/reduction.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/loops.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/matmul.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/ufunc_object.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/extobj.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/cpuid.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/scalarmath.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/ufunc_type_resolution.o build/temp.linux-x86_64-cpython-39/numpy/core/src/umath/override.o build/temp.linux-x86_64-cpython-39/numpy/core/src/npymath/npy_math.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npymath/ieee754.o build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/npymath/npy_math_complex.o build/temp.linux-x86_64-cpython-39/numpy/core/src/npymath/halffloat.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/array_assign.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/mem_overlap.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/npy_longdouble.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/ucsnarrow.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/ufunc_override.o build/temp.linux-x86_64-cpython-39/numpy/core/src/common/numpyos.o -Lbuild/temp.linux-x86_64-cpython-39 -lnpymath -lnpysort -lm -o build/lib.linux-x86_64-cpython-39/numpy/core/_multiarray_umath.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._umath_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_umath_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_umath_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_umath_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._rational_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_rational_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_rational_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_rational_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._struct_ufunc_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_struct_ufunc_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_struct_ufunc_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_struct_ufunc_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.core._operand_flag_tests' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/core/src/umath/_operand_flag_tests.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/core/src/umath/_operand_flag_tests.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/core/_operand_flag_tests.cpython-39-x86_64-linux-gnu.so
      building 'numpy.fft.fftpack_lite' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/fft
      compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/fft/fftpack_litemodule.c
      gcc: numpy/fft/fftpack.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/fft/fftpack_litemodule.o build/temp.linux-x86_64-cpython-39/numpy/fft/fftpack.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/fft/fftpack_lite.cpython-39-x86_64-linux-gnu.so
      building 'numpy.linalg.lapack_lite' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/linalg
      creating build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite
      compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/linalg/lapack_litemodule.c
      gcc: numpy/linalg/lapack_lite/f2c_z_lapack.c
      gcc: numpy/linalg/lapack_lite/python_xerbla.c
      gcc: numpy/linalg/lapack_lite/f2c_d_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_c_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_s_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_lapack.c
      gcc: numpy/linalg/lapack_lite/f2c_blas.c
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘cgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:383:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
        383 |     static integer ncola;
            |                    ^~~~~
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘dgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:6853:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
       6853 |     static integer ncola;
            |                    ^~~~~
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘sgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:11457:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
      11457 |     static integer ncola;
            |                    ^~~~~
      numpy/linalg/lapack_lite/f2c_blas.c: In function ‘zgemm_’:
      numpy/linalg/lapack_lite/f2c_blas.c:15670:20: warning: variable ‘ncola’ set but not used [-Wunused-but-set-variable]
      15670 |     static integer ncola;
            |                    ^~~~~
      gcc: numpy/linalg/lapack_lite/f2c_config.c
      gcc: numpy/linalg/lapack_lite/f2c.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_litemodule.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/python_xerbla.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_z_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_d_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_s_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_blas.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_config.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c.o -Lbuild/temp.linux-x86_64-cpython-39 -o build/lib.linux-x86_64-cpython-39/numpy/linalg/lapack_lite.cpython-39-x86_64-linux-gnu.so
      building 'numpy.linalg._umath_linalg' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/linalg
      compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: build/src.linux-x86_64-3.9/numpy/linalg/umath_linalg.c
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/build/src.linux-x86_64-3.9/numpy/linalg/umath_linalg.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/python_xerbla.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_z_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_d_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_s_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_lapack.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_blas.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c_config.o build/temp.linux-x86_64-cpython-39/numpy/linalg/lapack_lite/f2c.o -Lbuild/temp.linux-x86_64-cpython-39 -lnpymath -o build/lib.linux-x86_64-cpython-39/numpy/linalg/_umath_linalg.cpython-39-x86_64-linux-gnu.so
      building 'numpy.random.mtrand' extension
      compiling C sources
      C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC
      
      creating build/temp.linux-x86_64-cpython-39/numpy/random
      creating build/temp.linux-x86_64-cpython-39/numpy/random/mtrand
      compile options: '-D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c'
      gcc: numpy/random/mtrand/mtrand.c
      gcc: numpy/random/mtrand/randomkit.c
      gcc: numpy/random/mtrand/initarray.c
      gcc: numpy/random/mtrand/distributions.c
      numpy/random/mtrand/mtrand.c: In function ‘__Pyx_modinit_type_init_code’:
      numpy/random/mtrand/mtrand.c:40560:33: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
      40560 |   __pyx_type_6mtrand_RandomState.tp_print = 0;
            |                                 ^
      numpy/random/mtrand/mtrand.c: In function ‘__Pyx_ParseOptionalKeywords’:
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42833:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42833 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      numpy/random/mtrand/mtrand.c:42849:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
      42849 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from numpy/random/mtrand/mtrand.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      error: Command "gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.9 -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.9/numpy/core/src/common -Ibuild/src.linux-x86_64-3.9/numpy/core/src/npymath -c numpy/random/mtrand/mtrand.c -o build/temp.linux-x86_64-cpython-39/numpy/random/mtrand/mtrand.o -MMD -MF build/temp.linux-x86_64-cpython-39/numpy/random/mtrand/mtrand.o.d" failed with exit status 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for numpy
  Running setup.py clean for numpy
  error: subprocess-exited-with-error
  
  × python setup.py clean did not run successfully.
  │ exit code: 1
  ╰─> [10 lines of output]
      Running from numpy source directory.
      
      \`setup.py clean\` is not supported, use one of the following instead:
      
        - \`git clean -xdf\` (cleans all files)
        - \`git clean -Xdf\` (cleans all versioned files, doesn't touch
                            files that aren't checked into the git repo)
      
      Add \`--force\` to your command to use it anyway if you must (unsupported).
      
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed cleaning build dir for numpy
  Building wheel for psutil (setup.py): started
  Building wheel for psutil (setup.py): finished with status 'done'
  Created wheel for psutil: filename=psutil-5.5.1-cp39-cp39-linux_x86_64.whl size=214935 sha256=9d3cc16088badf550098f555df49233e139907dcfa391a811ecd0a14f113d779
  Stored in directory: /home/aiida/.cache/pip/wheels/8c/76/71/81b1aeeea8b23c1f889efe5662e3230bd511aaee41a636cb6d
  Building wheel for psycopg2-binary (setup.py): started
  Building wheel for psycopg2-binary (setup.py): finished with status 'done'
  Created wheel for psycopg2-binary: filename=psycopg2_binary-2.8-cp39-cp39-linux_x86_64.whl size=154718 sha256=b4e333f22be368031c3b2edf9492ad0cf536555d48db79c207e1b9af8ebbf928
  Stored in directory: /home/aiida/.cache/pip/wheels/59/8c/3c/53082ac2b0135e96329263c06547dc0bfb8d53e55fba549dd6
  Building wheel for PyYAML (setup.py): started
  Building wheel for PyYAML (setup.py): finished with status 'done'
  Created wheel for PyYAML: filename=PyYAML-3.13-cp39-cp39-linux_x86_64.whl size=43099 sha256=8e36bc7b80d269e228df589e0a3c0861c80d19a5d95ed7a5c12b5fb82be4382d
  Stored in directory: /home/aiida/.cache/pip/wheels/81/6e/87/725bed1db7f86e1c7091ef5f4a4f11b0fcf7023c2be4fc29db
  Building wheel for simplejson (setup.py): started
  Building wheel for simplejson (setup.py): finished with status 'done'
  Created wheel for simplejson: filename=simplejson-3.16.0-cp39-cp39-linux_x86_64.whl size=75790 sha256=a4e7675740fc03d609a9b95520c72d29ff9652b80e45635d32424e63338cf8cd
  Stored in directory: /home/aiida/.cache/pip/wheels/32/25/4a/a4c110dbbef9e26e7813c89a1e66b3f8b14dbf0d4f5012c98f
  Building wheel for SQLAlchemy (setup.py): started
  Building wheel for SQLAlchemy (setup.py): finished with status 'done'
  Created wheel for SQLAlchemy: filename=SQLAlchemy-1.3.3-cp39-cp39-linux_x86_64.whl size=1140156 sha256=6099c6c46272c44f658c3114746b2a6d025058d8dedfb04aa5ded203d2d415a8
  Stored in directory: /home/aiida/.cache/pip/wheels/66/01/59/e60921afa861ef0f7365a03208aac0c1fd70b748f3c6a6f345
  Building wheel for SQLAlchemy-Utils (setup.py): started
  Building wheel for SQLAlchemy-Utils (setup.py): finished with status 'done'
  Created wheel for SQLAlchemy-Utils: filename=SQLAlchemy_Utils-0.33.11-py2.py3-none-any.whl size=89352 sha256=a9fa59eb4f12bb422a94c8f82f858421457dc8f480d53ae86900abc13bdeaacd
  Stored in directory: /home/aiida/.cache/pip/wheels/7f/0d/38/0e28b2368702114374c9e1bc47e40a32c335687130ba2d07ac
  Building wheel for tabulate (setup.py): started
  Building wheel for tabulate (setup.py): finished with status 'done'
  Created wheel for tabulate: filename=tabulate-0.8.3-py3-none-any.whl size=23372 sha256=2c54de4e683f6435b75b766abdf30100e1cb528d2491e18abb6a016f11893702
  Stored in directory: /home/aiida/.cache/pip/wheels/6a/27/1a/19cd0775f6cda4160ca55ce3eb4c968e7f41b253b068adf037
  Building wheel for tzlocal (setup.py): started
  Building wheel for tzlocal (setup.py): finished with status 'done'
  Created wheel for tzlocal: filename=tzlocal-1.5.1-py3-none-any.whl size=17543 sha256=4a543b7783fc45a00ef6f808ac610cad0db09f3af9c097e8588262e7076a2da4
  Stored in directory: /home/aiida/.cache/pip/wheels/7d/2a/d3/9b83608fd158b23f4d04b92572b93ab2d643faa2a3c46b6f34
  Building wheel for wrapt (setup.py): started
  Building wheel for wrapt (setup.py): finished with status 'done'
  Created wheel for wrapt: filename=wrapt-1.11.1-cp39-cp39-linux_x86_64.whl size=36666 sha256=331118552ce5f3a6d08bfb2241693a9a8ff1638d904e292c310fcf6d1d67ee56
  Stored in directory: /home/aiida/.cache/pip/wheels/c8/6a/06/a9a8e9bf8ad2e6cc4fccdc713f67593cb7e1f5117212b0d8b5
  Building wheel for tornado (setup.py): started
  Building wheel for tornado (setup.py): finished with status 'done'
  Created wheel for tornado: filename=tornado-4.5.3-cp39-cp39-linux_x86_64.whl size=423442 sha256=50f4e5868f5240483f03fb03946cb43698a850e8fbb3989eae334f31a5b9c33a
  Stored in directory: /home/aiida/.cache/pip/wheels/83/38/94/6e1e08dd9ed83e2fc92914d24bf950c39e622dfbb12bf753d8
  Building wheel for pyzmq (setup.py): started
  Building wheel for pyzmq (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [705 lines of output]
      running bdist_wheel
      running build
      running build_py
      creating build
      creating build/lib.linux-x86_64-cpython-39
      creating build/lib.linux-x86_64-cpython-39/zmq
      copying zmq/error.py -> build/lib.linux-x86_64-cpython-39/zmq
      copying zmq/decorators.py -> build/lib.linux-x86_64-cpython-39/zmq
      copying zmq/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq
      creating build/lib.linux-x86_64-cpython-39/zmq/log
      copying zmq/log/handlers.py -> build/lib.linux-x86_64-cpython-39/zmq/log
      copying zmq/log/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/log
      creating build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/context.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/stopwatch.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/socket.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/version.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/attrsettr.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/tracker.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/frame.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/poll.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      copying zmq/sugar/constants.py -> build/lib.linux-x86_64-cpython-39/zmq/sugar
      creating build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/monitoredqueuedevice.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/basedevice.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/monitoredqueue.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/devices/proxydevice.py -> build/lib.linux-x86_64-cpython-39/zmq/devices
      creating build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/thread.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/certs.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      copying zmq/auth/base.py -> build/lib.linux-x86_64-cpython-39/zmq/auth
      creating build/lib.linux-x86_64-cpython-39/zmq/auth/asyncio
      copying zmq/auth/asyncio/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/auth/asyncio
      creating build/lib.linux-x86_64-cpython-39/zmq/asyncio
      copying zmq/asyncio/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/asyncio
      creating build/lib.linux-x86_64-cpython-39/zmq/ssh
      copying zmq/ssh/tunnel.py -> build/lib.linux-x86_64-cpython-39/zmq/ssh
      copying zmq/ssh/forward.py -> build/lib.linux-x86_64-cpython-39/zmq/ssh
      copying zmq/ssh/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/ssh
      creating build/lib.linux-x86_64-cpython-39/zmq/backend
      copying zmq/backend/select.py -> build/lib.linux-x86_64-cpython-39/zmq/backend
      copying zmq/backend/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/backend
      creating build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/message.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/error.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/context.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/socket.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/devices.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/_cffi.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/constants.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/_poll.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/utils.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      creating build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      creating build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/device.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/core.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      copying zmq/green/poll.py -> build/lib.linux-x86_64-cpython-39/zmq/green
      creating build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      copying zmq/green/eventloop/zmqstream.py -> build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      copying zmq/green/eventloop/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      copying zmq/green/eventloop/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/green/eventloop
      creating build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/strtypes.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/win32.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/sixcerpt.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/monitor.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/garbage.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/z85.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/constant_names.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/jsonapi.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/interop.py -> build/lib.linux-x86_64-cpython-39/zmq/utils
      creating build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/zmqstream.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      copying zmq/eventloop/future.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop
      creating build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/concurrent.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/log.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/stack_context.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      copying zmq/eventloop/minitornado/util.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado
      creating build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/common.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/interface.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/windows.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/posix.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      copying zmq/eventloop/minitornado/platform/auto.py -> build/lib.linux-x86_64-cpython-39/zmq/eventloop/minitornado/platform
      creating build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_pubsub.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_device.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_socket.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_log.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_version.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_retry_eintr.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_ioloop.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_zmqstream.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_reqrep.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_pair.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_z85.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_monitor.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_security.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_etc.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_decorators.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_ssh.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_multipart.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_cffi_backend.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_context.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_error.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_includes.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_imports.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_win32_shim.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_message.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_poll.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_auth.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_future.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_monqueue.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      copying zmq/tests/test_constants.py -> build/lib.linux-x86_64-cpython-39/zmq/tests
      creating build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/tests/asyncio/test_asyncio.py -> build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/tests/asyncio/__init__.py -> build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/tests/asyncio/_test_asyncio.py -> build/lib.linux-x86_64-cpython-39/zmq/tests/asyncio
      copying zmq/devices/monitoredqueue.pxd -> build/lib.linux-x86_64-cpython-39/zmq/devices
      copying zmq/backend/cffi/_cdefs.h -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cffi/_verify.c -> build/lib.linux-x86_64-cpython-39/zmq/backend/cffi
      copying zmq/backend/cython/checkrc.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/message.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/libzmq.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/context.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/socket.pxd -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/constant_enums.pxi -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/backend/cython/constants.pxi -> build/lib.linux-x86_64-cpython-39/zmq/backend/cython
      copying zmq/utils/buffers.pxd -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/zmq_compat.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/ipcmaxlen.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/pyversion_compat.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/getpid_compat.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      copying zmq/utils/zmq_constants.h -> build/lib.linux-x86_64-cpython-39/zmq/utils
      running build_ext
      running configure
      pkg-config not found
      {'libraries': ['zmq'], 'include_dirs': [], 'library_dirs': [], 'runtime_library_dirs': [], 'extra_link_args': []}
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c build/temp.linux-x86_64-cpython-39/scratch/check_sys_un.c -o build/temp.linux-x86_64-cpython-39/scratch/check_sys_un.o
      gcc -pthread -B /opt/conda/compiler_compat build/temp.linux-x86_64-cpython-39/scratch/check_sys_un.o -o build/temp.linux-x86_64-cpython-39/scratch/check_sys_un
      ************************************************
      Configure: Autodetecting ZMQ settings...
          Custom ZMQ dir:
      creating build/temp.linux-x86_64-cpython-39/scratch/tmp
      cc -c /tmp/timer_create6gg1ssk6.c -o build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_create6gg1ssk6.o
      cc build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_create6gg1ssk6.o -o build/temp.linux-x86_64-cpython-39/scratch/a.out
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -Izmq/utils -Izmq/backend/cython -Izmq/devices -c build/temp.linux-x86_64-cpython-39/scratch/vers.c -o build/temp.linux-x86_64-cpython-39/scratch/vers.o
      build/temp.linux-x86_64-cpython-39/scratch/vers.c:4:10: fatal error: zmq.h: No such file or directory
          4 | #include "zmq.h"
            |          ^~~~~~~
      compilation terminated.
      
      error: command '/usr/bin/gcc' failed with exit code 1
      
      Failed with default libzmq, trying again with /usr/local
      {'libraries': ['zmq'], 'include_dirs': ['/usr/local/include'], 'library_dirs': ['/usr/local/lib'], 'runtime_library_dirs': [], 'extra_link_args': []}
      ************************************************
      Configure: Autodetecting ZMQ settings...
          Custom ZMQ dir:       /usr/local
      cc -c /tmp/timer_create2ukivx3w.c -o build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_create2ukivx3w.o
      Assembler messages:
      Fatal error: can't create build/temp.linux-x86_64-cpython-39/scratch/tmp/timer_create2ukivx3w.o: No such file or directory
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/usr/local/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -c build/temp.linux-x86_64-cpython-39/scratch/vers.c -o build/temp.linux-x86_64-cpython-39/scratch/vers.o
      build/temp.linux-x86_64-cpython-39/scratch/vers.c:4:10: fatal error: zmq.h: No such file or directory
          4 | #include "zmq.h"
            |          ^~~~~~~
      compilation terminated.
      
      error: command '/usr/bin/gcc' failed with exit code 1
      
      ************************************************
      Warning: Couldn't find an acceptable libzmq on the system.
      
      If you expected pyzmq to link against an installed libzmq, please check to make sure:
      
          * You have a C compiler installed
          * A development version of Python is installed (including headers)
          * A development version of ZMQ >= 3.2 is installed (including headers)
          * If ZMQ is not in a default location, supply the argument --zmq=<path>
          * If you did recently install ZMQ to a default location,
            try rebuilding the ld cache with \`sudo ldconfig\`
            or specify zmq's location with \`--zmq=/usr/local\`
      
      You can skip all this detection/waiting nonsense if you know
      you want pyzmq to bundle libzmq as an extension by passing:
      
          \`--zmq=bundled\`
      
      I will now try to build libzmq as a Python extension
      unless you interrupt me (^C) in the next 10 seconds...
      
      
      10...
       9...
       8...
       7...
       6...
       5...
       4...
       3...
       2...
       1...
      ************************************************
      Using bundled libzmq
      already have bundled/zeromq
      attempting ./configure to generate platform.hpp
      Warning: failed to configure libzmq:
      b'/bin/sh: 1: ./configure: not found\\n'
      staging platform.hpp from: /tmp/pip-install-whim332k/pyzmq_957ed786eb924fe1b213884f0e3d627d/buildutils/include_linux
      ************************************************
      checking for timer_create
      creating build/temp.linux-x86_64-cpython-39/tmp
      cc -c /tmp/timer_createj63aj6c0.c -o build/temp.linux-x86_64-cpython-39/tmp/timer_createj63aj6c0.o
      cc build/temp.linux-x86_64-cpython-39/tmp/timer_createj63aj6c0.o -o build/temp.linux-x86_64-cpython-39/a.out
      ok
      ************************************************
      building 'zmq.libzmq' extension
      creating build/temp.linux-x86_64-cpython-39/buildutils
      creating build/temp.linux-x86_64-cpython-39/bundled
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/src
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib/randombytes
      creating build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/src
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c buildutils/initlibzmq.c -o build/temp.linux-x86_64-cpython-39/buildutils/initlibzmq.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/clock.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/clock.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ctx.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ctx.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/curve_client.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_client.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/curve_server.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_server.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/dealer.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dealer.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/devpoll.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/devpoll.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/dist.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dist.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/epoll.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/epoll.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/err.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/err.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/fq.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/fq.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/gssapi_client.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_client.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/gssapi_mechanism_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_mechanism_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/gssapi_server.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_server.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/io_object.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_object.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/io_thread.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_thread.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ip.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ip.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ipc_address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ipc_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/ipc_listener.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_listener.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/kqueue.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/kqueue.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/lb.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/lb.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/mailbox.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mailbox.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/mechanism.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mechanism.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/metadata.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/metadata.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/msg.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/msg.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/mtrie.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mtrie.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/norm_engine.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/norm_engine.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/null_mechanism.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/null_mechanism.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/object.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/object.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/options.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/options.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/own.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/own.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pair.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pair.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pgm_receiver.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_receiver.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pgm_sender.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_sender.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pgm_socket.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_socket.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pipe.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pipe.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/plain_client.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_client.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/plain_server.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_server.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/poll.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poll.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/poller_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poller_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/precompiled.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/precompiled.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/proxy.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/proxy.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/pull.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pull.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/push.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/push.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/random.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/random.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/raw_decoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_decoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/raw_encoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_encoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/reaper.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/reaper.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/rep.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/rep.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/req.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/req.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/router.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/router.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/select.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/select.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/session_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/session_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/signaler.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/signaler.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/socket_base.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socket_base.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/socks.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/socks_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/stream.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/stream_engine.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream_engine.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/sub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/sub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp_address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tcp_listener.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_listener.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/thread.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/thread.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tipc_address.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_address.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tipc_connecter.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_connecter.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/tipc_listener.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_listener.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/trie.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/trie.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v1_decoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_decoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v1_encoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_encoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v2_decoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_decoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/v2_encoder.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_encoder.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/xpub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xpub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/xsub.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xsub.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/zmq.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/src/zmq_utils.cpp -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq_utils.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/tweetnacl/contrib/randombytes/devurandom.c -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib/randombytes/devurandom.o
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DZMQ_HAVE_CURVE=1 -DZMQ_USE_TWEETNACL=1 -DZMQ_USE_EPOLL=1 -Ibundled/zeromq/include -Ibundled/zeromq/tweetnacl/src -Ibundled/zeromq/tweetnacl/contrib/randombytes -Ibundled -I/opt/conda/include/python3.9 -c bundled/zeromq/tweetnacl/src/tweetnacl.c -o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/src/tweetnacl.o
      bundled/zeromq/tweetnacl/src/tweetnacl.c: In function ‘vn’:
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘u32’ {aka ‘long unsigned int’} and ‘int’ [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:66:3: note: in expansion of macro ‘FOR’
         66 |   FOR(i,n) d |= x[i]^y[i];
            |   ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c: In function ‘crypto_sign’:
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘i64’ {aka ‘long long int’} and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:732:3: note: in expansion of macro ‘FOR’
        732 |   FOR(i,n) sm[64 + i] = m[i];
            |   ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c: In function ‘crypto_sign_open’:
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:799:3: note: in expansion of macro ‘FOR’
        799 |   FOR(i,n) m[i] = sm[i];
            |   ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:811:5: note: in expansion of macro ‘FOR’
        811 |     FOR(i,n) m[i] = 0;
            |     ^~~
      bundled/zeromq/tweetnacl/src/tweetnacl.c:9:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘u64’ {aka ‘long long unsigned int’} [-Wsign-compare]
          9 | #define FOR(i,n) for (i = 0;i < n;++i)
            |                               ^
      bundled/zeromq/tweetnacl/src/tweetnacl.c:815:3: note: in expansion of macro ‘FOR’
        815 |   FOR(i,n) m[i] = sm[i + 64];
            |   ^~~
      g++ -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/buildutils/initlibzmq.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/clock.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ctx.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_client.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/curve_server.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dealer.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/devpoll.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/dist.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/epoll.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/err.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/fq.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_client.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_mechanism_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/gssapi_server.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_object.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/io_thread.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ip.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/ipc_listener.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/kqueue.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/lb.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mailbox.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mechanism.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/metadata.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/msg.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/mtrie.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/norm_engine.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/null_mechanism.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/object.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/options.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/own.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pair.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_receiver.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_sender.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pgm_socket.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pipe.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_client.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/plain_server.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poll.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/poller_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/precompiled.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/proxy.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/pull.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/push.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/random.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_decoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/raw_encoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/reaper.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/rep.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/req.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/router.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/select.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/session_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/signaler.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socket_base.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/socks_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/stream_engine.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/sub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tcp_listener.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/thread.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_address.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_connecter.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/tipc_listener.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/trie.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_decoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v1_encoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_decoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/v2_encoder.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xpub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/xsub.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/src/zmq_utils.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/contrib/randombytes/devurandom.o build/temp.linux-x86_64-cpython-39/bundled/zeromq/tweetnacl/src/tweetnacl.o -o build/lib.linux-x86_64-cpython-39/zmq/libzmq.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython._device' extension
      creating build/temp.linux-x86_64-cpython-39/zmq
      creating build/temp.linux-x86_64-cpython-39/zmq/backend
      creating build/temp.linux-x86_64-cpython-39/zmq/backend/cython
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/_device.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_device.o
      zmq/backend/cython/_device.c: In function ‘__Pyx_ParseOptionalKeywords’:
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3074:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3074 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_device.c:3090:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3090 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_device.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_device.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/_device.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython._poll' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/_poll.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_poll.o
      zmq/backend/cython/_poll.c: In function ‘__Pyx_ParseOptionalKeywords’:
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3574:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3574 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/_poll.c:3590:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       3590 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/_poll.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_poll.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/_poll.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython._version' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/_version.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_version.o
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/_version.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/_version.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython.constants' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/constants.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/constants.o
      gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-cpython-39/zmq/backend/cython/constants.o -o build/lib.linux-x86_64-cpython-39/zmq/backend/cython/constants.cpython-39-x86_64-linux-gnu.so
      building 'zmq.backend.cython.context' extension
      gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DHAVE_SYS_UN_H=1 -Ibundled/zeromq/include -Izmq/utils -Izmq/backend/cython -Izmq/devices -I/opt/conda/include/python3.9 -c zmq/backend/cython/context.c -o build/temp.linux-x86_64-cpython-39/zmq/backend/cython/context.o
      zmq/backend/cython/context.c: In function ‘PyInit_context’:
      zmq/backend/cython/context.c:4483:52: error: ‘PyTypeObject’ {aka ‘struct _typeobject’} has no member named ‘tp_print’
       4483 |   __pyx_type_3zmq_7backend_6cython_7context_Context.tp_print = 0;
            |                                                    ^
      zmq/backend/cython/context.c: In function ‘__Pyx_ParseOptionalKeywords’:
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4767:21: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4767 |                     (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                     ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘PyUnicode_AsUnicode’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:580:45: note: declared here
        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(
            |                                             ^~~~~~~~~~~~~~~~~~~
      zmq/backend/cython/context.c:4783:25: warning: ‘_PyUnicode_get_wstr_length’ is deprecated [-Wdeprecated-declarations]
       4783 |                         (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
            |                         ^
      In file included from /opt/conda/include/python3.9/unicodeobject.h:1026,
                       from /opt/conda/include/python3.9/Python.h:93,
                       from zmq/backend/cython/context.c:4:
      /opt/conda/include/python3.9/cpython/unicodeobject.h:446:26: note: declared here
        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {
            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~
      error: command '/usr/bin/gcc' failed with exit code 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for pyzmq
  Running setup.py clean for pyzmq
  Building wheel for simplegeneric (setup.py): started
  Building wheel for simplegeneric (setup.py): finished with status 'done'
  Created wheel for simplegeneric: filename=simplegeneric-0.8.1-py3-none-any.whl size=5057 sha256=9320e53f242675796ac99ce093b465ba14b58cd7a287aef9d5f047e22053d55b
  Stored in directory: /home/aiida/.cache/pip/wheels/a7/bd/0d/d95b629ee4a7368830202858e45ac76cd837a42cafa50da81e
Successfully built aiida-core PyCifRW alembic click-completion click-spinner ete3 psutil psycopg2-binary PyYAML simplejson SQLAlchemy SQLAlchemy-Utils tabulate tzlocal wrapt tornado simplegeneric
Failed to build numpy pyzmq
ERROR: Could not build wheels for numpy, pyzmq, which is required to install pyproject.toml-based projects
`]},"aiida-kkr":{code_home:"https://github.com/JuDFTteam/aiida-kkr/tree/develop",development_status:"stable",documentation_url:"https://aiida-kkr.readthedocs.io/",entry_point_prefix:"kkr",pip_url:"aiida-kkr",name:"aiida-kkr",package_name:"aiida_kkr",hosted_on:"github.com",metadata:{release_date:"2023-04-05",description:"AiiDA plugin for the JuKKR codes",author_email:"Philipp Ruessmann <p.ruessmann@fz-juelich.de>, Jens Broeder <j.broeder@fz-juelich.de>, Fabian Bertoldo <f.bertoldo@fz-juelich.de>",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.0.0"},aiida_version:null,entry_points:{},commits_count:78,warnings:["No bdist_wheel available for PyPI release","  > WARNING! Unable to retrieve plugin info from: https://raw.github.com/JuDFTteam/aiida-kkr/develop/setup.json","AiiDA version not found","Development status in classifiers (beta) does not match development_status in metadata (stable)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install aiida-kkr",is_installable:"True"},"aiida-lammps":{code_home:"https://github.com/aiidaplugins/aiida-lammps",development_status:"beta",entry_point_prefix:"lammps",pip_url:"git+https://github.com/aiidaplugins/aiida-lammps",name:"aiida-lammps",package_name:"aiida_lammps",hosted_on:"github.com",metadata:{author:"Abel Carreras, Chris Sewell",author_email:"chrisj_sewell@hotmail.com",version:"0.8.0",description:"AiiDA plugin for LAMMPS",classifiers:["Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Framework :: AiiDA"]},aiida_version:">=1.4.0,<2.0.0",entry_points:{"aiida.calculations":{"lammps.combinate":"aiida_lammps.calculations.lammps.combinate:CombinateCalculation","lammps.force":"aiida_lammps.calculations.lammps.force:ForceCalculation","lammps.md":"aiida_lammps.calculations.lammps.md:MdCalculation","lammps.md.multi":"aiida_lammps.calculations.lammps.md_multi:MdMultiCalculation","lammps.optimize":"aiida_lammps.calculations.lammps.optimize:OptimizeCalculation",dynaphopy:"aiida_lammps.calculations.dynaphopy: DynaphopyCalculation"},"aiida.parsers":{"lammps.force":"aiida_lammps.parsers.lammps.force:ForceParser","lammps.md":"aiida_lammps.parsers.lammps.md:MdParser","lammps.md.multi":"aiida_lammps.parsers.lammps.md_multi:MdMultiParser","lammps.optimize":"aiida_lammps.parsers.lammps.optimize:OptimizeParser",dynaphopy:"aiida_lammps.parsers.dynaphopy: DynaphopyParser"},"aiida.data":{"lammps.potential":"aiida_lammps.data.potential:EmpiricalPotential","lammps.trajectory":"aiida_lammps.data.trajectory:LammpsTrajectory"},"lammps.potentials":{eam:"aiida_lammps.data.pot_plugins.eam:EAM",lennard_jones:"aiida_lammps.data.pot_plugins.lennard_jones:LennardJones",reaxff:"aiida_lammps.data.pot_plugins.reaxff:Reaxff",tersoff:"aiida_lammps.data.pot_plugins.tersoff:Tersoff"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'dynaphopy' does not start with prefix 'lammps.'","Entry point 'dynaphopy' does not start with prefix 'lammps.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:5},{colorclass:"red",text:"Data",count:2},{colorclass:"orange",text:"Other (Lammps potentials)",count:4}],pip_install_cmd:"pip install git+https://github.com/aiidaplugins/aiida-lammps",is_installable:"True"},"aiida-lsmo":{code_home:"https://github.com/lsmo-epfl/aiida-lsmo",development_status:"stable",entry_point_prefix:"lsmo",pip_url:"git+https://github.com/lsmo-epfl/aiida-lsmo",name:"aiida-lsmo",package_name:"aiida_lsmo",hosted_on:"github.com",metadata:{author:"Aliaksandr Yakutovich, Daniele Ongari, Leopold Talirz",author_email:"aliaksandr.yakutovich@epfl.ch",version:"1.0.0",description:"AiiDA workflows for the LSMO laboratory at EPFL",classifiers:["Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7"]},aiida_version:">=1.0.0",entry_points:{"aiida.calculations":{"lsmo.ff_builder":"aiida_lsmo.calcfunctions:ff_builder","lsmo.calc_ch4_working_cap":"aiida_lsmo.calcfunctions:calc_ch4_working_cap","lsmo.calc_h2_working_cap":"aiida_lsmo.calcfunctions:calc_h2_working_cap","lsmo.calc_o2_working_cap":"aiida_lsmo.calcfunctions:calc_o2_working_cap","lsmo.calc_selectivity":"aiida_lsmo.calcfunctions:calc_selectivity"},"aiida.parsers":{"lsmo.cp2k_bsse_parser":"aiida_lsmo.parsers:Cp2kBsseParser","lsmo.cp2k_advanced_parser":"aiida_lsmo.parsers:Cp2kAdvancedParser"},"aiida.workflows":{"lsmo.binding_site":"aiida_lsmo.workchains:BindingSiteWorkChain","lsmo.cp2k_binding_energy":"aiida_lsmo.workchains.cp2k_binding_energy:Cp2kBindingEnergyWorkChain","lsmo.cp2k_multistage":"aiida_lsmo.workchains:Cp2kMultistageWorkChain","lsmo.cp2k_multistage_ddec":"aiida_lsmo.workchains:Cp2kMultistageDdecWorkChain","lsmo.isotherm":"aiida_lsmo.workchains:IsothermWorkChain","lsmo.isotherm_multi_temp":"aiida_lsmo.workchains:IsothermMultiTempWorkChain","lsmo.isotherm_calc_pe":"aiida_lsmo.workchains:IsothermCalcPEWorkChain","lsmo.zeopp_multistage_ddec":"aiida_lsmo.workchains:ZeoppMultistageDdecWorkChain","lsmo.sim_annealing":"aiida_lsmo.workchains.sim_annealing:SimAnnealingWorkChain","lsmo.nanoporous_screening_1":"aiida_lsmo.workchains:NanoporousScreening1WorkChain"}},commits_count:17,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:5},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:10}],pip_install_cmd:"pip install git+https://github.com/lsmo-epfl/aiida-lsmo",is_installable:"False",errors:[`Failed to install plugin aiida-lsmo
Collecting git+https://github.com/lsmo-epfl/aiida-lsmo
  Cloning https://github.com/lsmo-epfl/aiida-lsmo to /tmp/pip-req-build-lp6ncci0
  Running command git clone --filter=blob:none --quiet https://github.com/lsmo-epfl/aiida-lsmo /tmp/pip-req-build-lp6ncci0
  Resolved https://github.com/lsmo-epfl/aiida-lsmo to commit 6bf08fa42e545dadf889ea8095d7fcdd8d1be15c
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting aiida-core~=1.0 (from aiida-lsmo==1.0.0)
  Downloading aiida_core-1.6.9-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 32.0 MB/s eta 0:00:00
Collecting aiida-cp2k~=1.4 (from aiida-lsmo==1.0.0)
  Obtaining dependency information for aiida-cp2k~=1.4 from https://files.pythonhosted.org/packages/65/a8/8024bfb7c10760806b6d0d2aa09589898cda7ec7d391eef946d1609bb6c5/aiida_cp2k-1.6.0-py3-none-any.whl.metadata
  Downloading aiida_cp2k-1.6.0-py3-none-any.whl.metadata (3.9 kB)
Collecting aiida-ddec~=1.0 (from aiida-lsmo==1.0.0)
  Downloading aiida-ddec-1.1.0.tar.gz (12 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Installing backend dependencies: started
  Installing backend dependencies: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting aiida-zeopp>=1.0.3,~=1.0 (from aiida-lsmo==1.0.0)
  Downloading aiida-zeopp-1.1.2.tar.gz (17 kB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Installing backend dependencies: started
  Installing backend dependencies: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting aiida-raspa~=1.1 (from aiida-lsmo==1.0.0)
  Downloading aiida-raspa-1.2.0.tar.gz (15 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting calc-pe>=1.0.1,~=1.0 (from aiida-lsmo==1.0.0)
  Downloading calc_pe-1.0.1-py2.py3-none-any.whl (9.9 kB)
Collecting ruamel.yaml~=0.16.5 (from aiida-lsmo==1.0.0)
  Downloading ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 111.9/111.9 kB 31.5 MB/s eta 0:00:00
Collecting ase<3.20 (from aiida-lsmo==1.0.0)
  Downloading ase-3.19.3-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 83.1 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of aiida-lsmo to determine which version is compatible with other requirements. This could take a while.
ERROR: Ignored the following versions that require a different python version: 0.1a0 Requires-Python >=3.6.0,<3.8.0; 0.2.1 Requires-Python >=3.6.0,<3.8.0; 0.2.5 Requires-Python >=3.6.0,<3.8.0; 0.2a0 Requires-Python >=3.6.0,<3.8.0; 1.0.2 Requires-Python >=3.6.0,<3.8.0; 1.1.0 Requires-Python >=3.6,<3.9; 1.1.2 Requires-Python >=3.6,<3.9; 1.1.3 Requires-Python >=3.6,<3.9; 1.2.0 Requires-Python >=3.6,<3.9; 1.3.0 Requires-Python >=3.6,<3.9; 1.4.0 Requires-Python >=3.7,<3.9
ERROR: Could not find a version that satisfies the requirement oximachinerunner~=1.4.0 (from aiida-lsmo) (from versions: none)
ERROR: No matching distribution found for oximachinerunner~=1.4.0
`]},"aiida-metavo-scheduler":{code_home:"https://github.com/pzarabadip/aiida-metavo-scheduler",development_status:"stable",entry_point_prefix:"metavo_scheduler",pip_url:"git+https://github.com/pzarabadip/aiida-metavo-scheduler",name:"aiida-metavo-scheduler",package_name:"aiida_metavo_scheduler",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"1.0.0",description:"",classifiers:["Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering"]},aiida_version:">=1.0.0,<1.6",entry_points:{"aiida.cmdline.computer.configure":{sshmetavo:"aiida_metavo_scheduler.metavo.ssh_metavo:CONFIGURE_SSH_CMD"},"aiida.schedulers":{pbsprometavo:"aiida_metavo_scheduler.metavo.pbspro_metavo:PbsproSchedulerMetaVO"},"aiida.transports":{sshmetavo:"aiida_metavo_scheduler.metavo.ssh_metavo:SshTransport"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'sshmetavo' does not start with prefix 'metavo_scheduler.'","Entry point 'pbsprometavo' does not start with prefix 'metavo_scheduler.'","Entry point 'sshmetavo' does not start with prefix 'metavo_scheduler.'"],summaryinfo:[{colorclass:"orange",text:"Other (Cmdline computer configure, Schedulers, Transports)",count:3}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-metavo-scheduler",is_installable:"True"},"aiida-mpds":{code_home:"https://github.com/mpds-io/mpds-aiida",development_status:"beta",documentation_url:"https://github.com/mpds-io/mpds-aiida",entry_point_prefix:"mpds",pip_url:"git+https://github.com/mpds-io/mpds-aiida",name:"aiida-mpds",package_name:"aiida_mpds",hosted_on:"github.com",metadata:{author:"Andrey Sobolev",author_email:"as@tilde.pro",version:"",description:"Aiida workflows for MPDS based on CRYSTAL",classifiers:["Programming Language :: Python","Programming Language :: Python :: 3.5","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Information Analysis","Framework :: AiiDA"]},aiida_version:">=1.0.1",entry_points:{"aiida.workflows":{"crystal.mpds":"mpds_aiida.workflows.mpds:MPDSStructureWorkchain","crystal.cif":"mpds_aiida.workflows.cif:CIFStructureWorkchain","crystal.aiida":"mpds_aiida.workflows.aiida:AiidaStructureWorkchain"}},commits_count:6,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'crystal.mpds' does not start with prefix 'mpds.'","Entry point 'crystal.cif' does not start with prefix 'mpds.'","Entry point 'crystal.aiida' does not start with prefix 'mpds.'"],summaryinfo:[{colorclass:"green",text:"Workflows",count:3}],pip_install_cmd:"pip install git+https://github.com/mpds-io/mpds-aiida",is_installable:"False",errors:[`Failed to install plugin aiida-mpds
Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-3skqottj
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-3skqottj
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs (from mpds-aiida==0.10.0)
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-ya49tn4l/mpds-ml-labs_4201e173022f4588a8fab180706fe693
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-ya49tn4l/mpds-ml-labs_4201e173022f4588a8fab180706fe693
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft (from mpds-aiida==0.10.0)
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-ya49tn4l/aiida-crystal-dft_e66a410074fc43ee80a349dbf4b6df76
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-ya49tn4l/aiida-crystal-dft_e66a410074fc43ee80a349dbf4b6df76
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1 (from mpds-aiida==0.10.0)
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.9/site-packages (from mpds-aiida==0.10.0) (1.25.2)
Collecting ase>=3.19 (from mpds-aiida==0.10.0)
  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 55.4 MB/s eta 0:00:00
Collecting yascheduler>=1.0.12 (from mpds-aiida==0.10.0)
  Obtaining dependency information for yascheduler>=1.0.12 from https://files.pythonhosted.org/packages/ce/1d/8be161fa909c5f81282cc83c7c18e7030bcc9eb6e057ec7992b49b4770d1/yascheduler-1.2.0-py3-none-any.whl.metadata
  Downloading yascheduler-1.2.0-py3-none-any.whl.metadata (12 kB)
Collecting matplotlib>=3.1.0 (from ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for matplotlib>=3.1.0 from https://files.pythonhosted.org/packages/e0/8b/b62bc50b01bb2d4af96bc0045c39d60209e2701e172789ceace20a0866b2/matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)
Collecting scipy>=1.1.0 (from ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 21.1 MB/s eta 0:00:00
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.9/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (68.1.2)
Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.7)
Collecting aiohttp~=3.8 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for aiohttp~=3.8 from https://files.pythonhosted.org/packages/5b/8d/821fcb268cfc056964a75da3823896b17eabaa4968a2414121bc93b0c501/aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Collecting asyncssh~=2.11 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for asyncssh~=2.11 from https://files.pythonhosted.org/packages/c8/82/df5365b647cabf9f0f77135b7d7e845c14c6016f8f320b2a172ffe7e9af3/asyncssh-2.13.2-py3-none-any.whl.metadata
  Downloading asyncssh-2.13.2-py3-none-any.whl.metadata (9.8 kB)
Collecting asyncstdlib~=3.10 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for asyncstdlib~=3.10 from https://files.pythonhosted.org/packages/4a/62/0ac4017cc89d02410deda3c4848221bc807bbf77201058b68bc6ceb1c670/asyncstdlib-3.10.8-py3-none-any.whl.metadata
  Downloading asyncstdlib-3.10.8-py3-none-any.whl.metadata (3.5 kB)
Collecting attrs~=21.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 19.1 MB/s eta 0:00:00
Collecting azure-identity~=1.10.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 40.9 MB/s eta 0:00:00
Collecting azure-mgmt-compute~=27.2.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 101.8 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 72.2 MB/s eta 0:00:00
Collecting backoff~=2.1.2 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting hcloud~=1.17 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for hcloud~=1.17 from https://files.pythonhosted.org/packages/e5/35/a1a134f0aebc3b3494efbb1f47b0e6f6bf3138ddad2a4079350b6eff7604/hcloud-1.28.0-py3-none-any.whl.metadata
  Downloading hcloud-1.28.0-py3-none-any.whl.metadata (4.6 kB)
Collecting pg8000~=1.19 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for pg8000~=1.19 from https://files.pythonhosted.org/packages/6e/2c/9d7ba4b76ad65a56bf0ff128b995b2caaa15eb7ac430268e10cfbcf99228/pg8000-1.30.2-py3-none-any.whl.metadata
  Downloading pg8000-1.30.2-py3-none-any.whl.metadata (78 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.0/79.0 kB 23.7 MB/s eta 0:00:00
Collecting python-daemon~=2.3 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.7.1)
Collecting upcloud_api~=2.0 (from yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for upcloud_api~=2.0 from https://files.pythonhosted.org/packages/4d/5f/39b65e4412146ff1bdb75146b084a15cefc1a0c09d7db55476cc6c3876c5/upcloud_api-2.5.1-py3-none-any.whl.metadata
  Downloading upcloud_api-2.5.1-py3-none-any.whl.metadata (7.8 kB)
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.4.0.post0)
Collecting pycrystal>=1.0.10 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds_client>=0.24 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting pyparsing>2.3.1 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for pyparsing>2.3.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata
  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)
Collecting spglib>=1.16.0 (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for spglib>=1.16.0 from https://files.pythonhosted.org/packages/86/a9/a35a6c9355d819a7c419a6ac13cd108130af2748efc7f7d94c38161aa3d7/spglib-2.1.0-cp39-cp39-manylinux_2_17_x86_64.whl.metadata
  Downloading spglib-2.1.0-cp39-cp39-manylinux_2_17_x86_64.whl.metadata (3.3 kB)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Collecting seekpath (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for seekpath from https://files.pythonhosted.org/packages/30/2c/fcb31e185a3a74d4098d9c44ac108ddcf1a4c88d7d3cea5a569dd812c62b/seekpath-2.1.0-py2.py3-none-any.whl.metadata
  Downloading seekpath-2.1.0-py2.py3-none-any.whl.metadata (4.7 kB)
Collecting pycodcif (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 26.5 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting imblearn (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)
Collecting progressbar (from mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Downloading progressbar-2.5.tar.gz (10 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: alembic~=1.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.12.0)
Requirement already satisfied: archive-path~=0.4.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.4.2)
Requirement already satisfied: aio-pika~=6.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (6.8.1)
Requirement already satisfied: circus~=0.18.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.18.0)
Requirement already satisfied: click-spinner~=0.1.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.1.10)
Requirement already satisfied: disk-objectstore~=0.6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.6.0)
Requirement already satisfied: docstring-parser in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.15)
Requirement already satisfied: get-annotations~=0.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.1.2)
Requirement already satisfied: graphviz~=0.19 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.20.1)
Requirement already satisfied: ipython>=7 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (8.15.0)
Requirement already satisfied: kiwipy[rmq]~=0.7.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.7.7)
Requirement already satisfied: importlib-metadata~=4.13 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.13.0)
Requirement already satisfied: paramiko>=2.7.2,~=2.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.12.0)
Requirement already satisfied: plumpy~=0.21.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.21.8)
Requirement already satisfied: pgsu~=0.2.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.4)
Requirement already satisfied: psutil~=5.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (5.9.5)
Requirement already satisfied: psycopg2-binary~=2.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.9.7)
Requirement already satisfied: pytz~=2021.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2021.3)
Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (6.0.1)
Requirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.31.0)
Requirement already satisfied: sqlalchemy~=1.4.22 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.4.49)
Requirement already satisfied: tabulate~=0.8.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.8.10)
Requirement already satisfied: tqdm~=4.45 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.66.1)
Requirement already satisfied: upf_to_json~=0.9.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.9.5)
Requirement already satisfied: wrapt~=1.11 in /opt/conda/lib/python3.9/site-packages (from aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.15.0)
Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0) (3.2.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0) (6.0.4)
Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata
  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)
Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0) (1.9.2)
Collecting frozenlist>=1.1.1 (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b5/03/7dec2e257bd173b5ca1f74477863b97d322149f6f0284d7decead8c5ceeb/frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)
Collecting aiosignal>=1.1.2 (from aiohttp~=3.8->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Requirement already satisfied: cryptography>=3.1 in /opt/conda/lib/python3.9/site-packages (from asyncssh~=2.11->yascheduler>=1.0.12->mpds-aiida==0.10.0) (41.0.3)
Collecting azure-core<2.0.0,>=1.11.0 (from azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for azure-core<2.0.0,>=1.11.0 from https://files.pythonhosted.org/packages/98/3a/d53e2b8a75c448ef45d7ae4b0659eb6c0d48978f25a709e2a39894a48704/azure_core-1.29.4-py3-none-any.whl.metadata
  Downloading azure_core-1.29.4-py3-none-any.whl.metadata (36 kB)
Collecting msal<2.0.0,>=1.12.0 (from azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for msal<2.0.0,>=1.12.0 from https://files.pythonhosted.org/packages/8f/71/5c385d104814fede34da5e10102bc0f4a0d05ef42eae052dac787381b2bc/msal-1.24.0-py2.py3-none-any.whl.metadata
  Downloading msal-1.24.0-py2.py3-none-any.whl.metadata (11 kB)
Collecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)
Collecting msrest>=0.6.21 (from azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 22.7 MB/s eta 0:00:00
Collecting azure-common~=1.1 (from azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)
Collecting azure-mgmt-core<2.0.0,>=1.3.1 (from azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)
Collecting python-dateutil>=2.7.5 (from hcloud~=1.17->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 64.6 MB/s eta 0:00:00
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2>=2.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.1.3)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0.1->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.19.3)
Collecting contourpy>=1.0.1 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/2b/c0/24c34c41a180f875419b536125799c61e2330b997d77a5a818a3bc3e08cd/contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)
Collecting cycler>=0.10 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/49/50/2e31753c088d364756daa5bed0dab6a5928ebfd6e6d26f975c8b6d6f754a/fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.0/151.0 kB 44.6 MB/s eta 0:00:00
Collecting kiwisolver>=1.0.1 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata
  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)
Collecting pillow>=6.2.0 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/0a/20/a94a0462495de73e248643fb24667270f2e67f44792456ab7207764e80cc/Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata
  Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
Collecting importlib-resources>=3.2.0 (from matplotlib>=3.1.0->ase>=3.19->mpds-aiida==0.10.0)
  Obtaining dependency information for importlib-resources>=3.2.0 from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata
  Downloading importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)
Collecting httplib2 (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.9/96.9 kB 31.7 MB/s eta 0:00:00
Collecting ujson (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for ujson from https://files.pythonhosted.org/packages/ed/2f/04fb635a03e11630ae8fd0dff8617442251a4845b7622e359fdf1256e172/ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)
Collecting pandas (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/83/f0/2765daac3c58165460b127df5c0ef7b3a039f3bfe7ea7a51f3d20b01371b/pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Collecting jmespath (from mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting scramp>=1.4.4 (from pg8000~=1.19->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading scramp-1.4.4-py3-none-any.whl (13 kB)
Collecting bs4 (from pycrystal>=1.0.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading bs4-0.0.1.tar.gz (1.1 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting docutils (from python-daemon~=2.3->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for docutils from https://files.pythonhosted.org/packages/26/87/f238c0670b94533ac0353a4e2a1a771a0cc73277b88bff23d3ae35a256c1/docutils-0.20.1-py3-none-any.whl.metadata
  Downloading docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)
Collecting lockfile>=0.10 (from python-daemon~=2.3->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)
Collecting imbalanced-learn (from imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/a3/9e/fbe60a768502af54563dcb59ca7856f5a8833b3ad5ada658922e1ab09b7f/imbalanced_learn-0.11.0-py3-none-any.whl.metadata
  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)
Requirement already satisfied: aiormq<4,>=3.2.3 in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.3.1)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.2.4)
Requirement already satisfied: pyzmq>=17.0 in /opt/conda/lib/python3.9/site-packages (from circus~=0.18.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (25.1.1)
Requirement already satisfied: tornado>=5.0.2 in /opt/conda/lib/python3.9/site-packages (from circus~=0.18.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (6.3.3)
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=3.1->asyncssh~=2.11->yascheduler>=1.0.12->mpds-aiida==0.10.0) (1.15.1)
Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata~=4.13->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.16.2)
Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.0)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (5.1.1)
Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.19.0)
Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.1.6)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.7.5)
Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.39)
Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.16.1)
Requirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.6.2)
Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (5.9.0)
Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.1.3)
Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.8.0)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.0.11)
Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.10)
Requirement already satisfied: pytray<0.4.0,>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.3.4)
Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.1.0)
Requirement already satisfied: pamqp~=2.0 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.0)
Collecting PyJWT[crypto]<3,>=1.0.0 (from msal<2.0.0,>=1.12.0->azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for PyJWT[crypto]<3,>=1.0.0 from https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl.metadata
  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)
Collecting portalocker<3,>=1.0 (from msal-extensions<2.0.0,>=0.3.0->azure-identity~=1.10.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Obtaining dependency information for portalocker<3,>=1.0 from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata
  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)
Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0) (2023.7.22)
Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 15.0 MB/s eta 0:00:00
Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (4.0.1)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.5.0)
Requirement already satisfied: nest_asyncio~=1.5 in /opt/conda/lib/python3.9/site-packages (from plumpy~=0.21.6->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.5.7)
Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.4)
Collecting asn1crypto>=1.5.1 (from scramp>=1.4.4->pg8000~=1.19->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 kB 30.2 MB/s eta 0:00:00
Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy~=1.4.22->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Collecting beautifulsoup4 (from bs4->pycrystal>=1.0.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.0/143.0 kB 36.6 MB/s eta 0:00:00
Collecting scikit-learn>=1.0.2 (from imbalanced-learn->imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for scikit-learn>=1.0.2 from https://files.pythonhosted.org/packages/d4/61/966d3238f6cbcbb13350d31bd0accfc5efdf9e349cd2a42d9761b8b67a18/scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)
Collecting joblib>=1.1.1 (from imbalanced-learn->imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata
  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)
Collecting threadpoolctl>=2.0.0 (from imbalanced-learn->imblearn->mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs->mpds-aiida==0.10.0)
  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata
  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)
Collecting tzdata>=2022.1 (from pandas->mpds_client>=0.24->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 kB 66.1 MB/s eta 0:00:00
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.1->asyncssh~=2.11->yascheduler>=1.0.12->mpds-aiida==0.10.0) (2.21)
Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.8.3)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.7.0)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.6)
Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-mgmt-compute~=27.2.0->yascheduler>=1.0.12->mpds-aiida==0.10.0)
  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 35.4 MB/s eta 0:00:00
Collecting soupsieve>1.2 (from beautifulsoup4->bs4->pycrystal>=1.0.10->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0)
  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata
  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)
Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.2.0)
Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.4.0)
Requirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=7->aiida-core>=2.0.2->aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (0.2.2)
Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 18.1 MB/s eta 0:00:00
Downloading aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 98.3 MB/s eta 0:00:00
Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 78.2 MB/s eta 0:00:00
Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 31.4 MB/s eta 0:00:00
Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 103.1 MB/s eta 0:00:00
Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 16.0 MB/s eta 0:00:00
Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 39.1 MB/s eta 0:00:00
Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.5/36.5 MB 58.7 MB/s eta 0:00:00
Downloading spglib-2.1.0-cp39-cp39-manylinux_2_17_x86_64.whl (802 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 802.1/802.1 kB 96.7 MB/s eta 0:00:00
Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Downloading seekpath-2.1.0-py2.py3-none-any.whl (77 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.5/77.5 kB 27.8 MB/s eta 0:00:00
Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)
Downloading azure_core-1.29.4-py3-none-any.whl (192 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 192.4/192.4 kB 53.8 MB/s eta 0:00:00
Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.9/301.9 kB 38.3 MB/s eta 0:00:00
Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 38.6 MB/s eta 0:00:00
Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.0/228.0 kB 62.1 MB/s eta 0:00:00
Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)
Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 104.2 MB/s eta 0:00:00
Downloading msal-1.24.0-py2.py3-none-any.whl (91 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.3/91.3 kB 36.2 MB/s eta 0:00:00
Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl (3.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 120.8 MB/s eta 0:00:00
Downloading docutils-0.20.1-py3-none-any.whl (572 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 572.7/572.7 kB 90.7 MB/s eta 0:00:00
Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 235.6/235.6 kB 57.0 MB/s eta 0:00:00
Downloading pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.7/12.7 MB 109.7 MB/s eta 0:00:00
Downloading ujson-5.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 16.3 MB/s eta 0:00:00
Downloading joblib-1.3.2-py3-none-any.whl (302 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.2/302.2 kB 72.7 MB/s eta 0:00:00
Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)
Downloading scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 110.2 MB/s eta 0:00:00
Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)
Downloading soupsieve-2.5-py3-none-any.whl (36 kB)
Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)
Building wheels for collected packages: mpds-aiida, aiida-crystal-dft, mpds-ml-labs, mpds_client, pycrystal, progressbar, pycodcif, sklearn, bs4
  Building wheel for mpds-aiida (setup.py): started
  Building wheel for mpds-aiida (setup.py): finished with status 'done'
  Created wheel for mpds-aiida: filename=mpds_aiida-0.10.0-py3-none-any.whl size=26465 sha256=5654303c57de0d6c5cc590d64357949946c568f324e42e1b13292ed0e3885edc
  Stored in directory: /tmp/pip-ephem-wheel-cache-bsjtmbnh/wheels/b0/06/8e/e50124efa87968a6d000ac392f488a8381db0c99360bc56d28
  Building wheel for aiida-crystal-dft (pyproject.toml): started
  Building wheel for aiida-crystal-dft (pyproject.toml): finished with status 'done'
  Created wheel for aiida-crystal-dft: filename=aiida_crystal_dft-0.9.0-py3-none-any.whl size=615034 sha256=eee0c57a43a616aa2af33081da79325e932f62a70995cd21656d6f32c7be1f5b
  Stored in directory: /tmp/pip-ephem-wheel-cache-bsjtmbnh/wheels/35/4e/8b/d0c50c1944f5a32b7e9cf5a628dd09bed51de5b4623743f1d3
  Building wheel for mpds-ml-labs (setup.py): started
  Building wheel for mpds-ml-labs (setup.py): finished with status 'done'
  Created wheel for mpds-ml-labs: filename=mpds_ml_labs-0.0.7-py3-none-any.whl size=36846 sha256=770730febf525bb81e44dd6c3e7bed749f370c080e176a09543d5401b99a9f38
  Stored in directory: /tmp/pip-ephem-wheel-cache-bsjtmbnh/wheels/5d/93/92/e3750b9bf7d3ffd0d83691009b13f45e86e5cbabfe59e7747d
  Building wheel for mpds_client (setup.py): started
  Building wheel for mpds_client (setup.py): finished with status 'done'
  Created wheel for mpds_client: filename=mpds_client-0.24-py3-none-any.whl size=9964 sha256=7e240bae94fd95f4e47ace6aca3532aebf96dded1bca90e2a6005fb3ba413060
  Stored in directory: /home/aiida/.cache/pip/wheels/93/b3/59/e20f7bf029c83fbeadc49a864bc70312197114776f10aa9442
  Building wheel for pycrystal (setup.py): started
  Building wheel for pycrystal (setup.py): finished with status 'done'
  Created wheel for pycrystal: filename=pycrystal-1.0.16-py3-none-any.whl size=27472 sha256=04112ca171948f95b38966f13acb0add95c1f22368eacf41b772c5d2fa85d390
  Stored in directory: /home/aiida/.cache/pip/wheels/b5/e3/5f/ac959ea648bd0f96552d2f20b71c5a640bf956589a88beb8b1
  Building wheel for progressbar (setup.py): started
  Building wheel for progressbar (setup.py): finished with status 'done'
  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12067 sha256=81355bfa481c07ae71892e37110e505edc515c4b6b56b67197e4a9c9e7c0d7c4
  Stored in directory: /home/aiida/.cache/pip/wheels/d7/d9/89/a3f31c76ff6d51dc3b1575628f59afe59e4ceae3f2748cd7ad
  Building wheel for pycodcif (setup.py): started
  Building wheel for pycodcif (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [8 lines of output]
      running bdist_wheel
      running build
      running build_py
      running build_ext
      building 'pycodcif._pycodcif' extension
      swigging pycodcif.i to pycodcif_wrap.c
      swig -python -o pycodcif_wrap.c pycodcif.i
      error: command 'swig' failed: No such file or directory
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for pycodcif
  Running setup.py clean for pycodcif
  Building wheel for sklearn (setup.py): started
  Building wheel for sklearn (setup.py): finished with status 'done'
  Created wheel for sklearn: filename=sklearn-0.0.post9-py3-none-any.whl size=2952 sha256=810618b19251751f589d80c8a207cc0ecdd4cf3b7fd0c924b7b4d1b85a98b46b
  Stored in directory: /home/aiida/.cache/pip/wheels/e2/4f/96/3b01e8981cb6f333764a2443a1f4777896180da6e46efe95c1
  Building wheel for bs4 (setup.py): started
  Building wheel for bs4 (setup.py): finished with status 'done'
  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=a8497e4da6f4a293645e9e50c683ca9afc6a1a0eb644e25d639edffd8e4df590
  Stored in directory: /home/aiida/.cache/pip/wheels/73/2b/cb/099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3
Successfully built mpds-aiida aiida-crystal-dft mpds-ml-labs mpds_client pycrystal progressbar sklearn bs4
Failed to build pycodcif
ERROR: Could not build wheels for pycodcif, which is required to install pyproject.toml-based projects
`]},"aiida-muon":{entry_point_prefix:"muon",code_home:"https://github.com/positivemuon/aiida-muon",version_file:"https://raw.githubusercontent.com/positivemuon/aiida-muon/main/aiida_muon/__init__.py",pip_url:"git+https://github.com/positivemuon/aiida-muon",name:"aiida-muon",package_name:"aiida_muon",hosted_on:"github.com",metadata:{description:"aiida-muon is allows to find candiate muon implantation sites and hyperfine field by DFT supercell relaxations and from further symmetry and kinetics analysis.  ",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 2 - Pre-Alpha","Framework :: AiiDA"],author:"Muon  group Parma"},aiida_version:">=2.0,<3",entry_points:{"aiida.workflows":{"muon.find_muon":{description:["FindMuonWorkChain finds the candidate implantation site for a positive muon.","    It first performs DFT relaxation calculations for a set of initial muon sites.","    It then analyzes the results of these calculations and finds candidate muon sites.","    If there are magnetic inequivalent sites not initially, they are recalculated","    It further calculates the muon contact hyperfine field at these candidate sites."],spec:{inputs:[{name:"sc_matrix",required:!0,valid_types:"List",info:" List of length 1 for supercell size "},{name:"structure",required:!0,valid_types:"StructureData",info:"Input initial structure"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"mu_spacing",required:!1,valid_types:"Float, NoneType",info:"Minimum distance in Angstrom between two starting muon positions  generated on a grid."},{name:"qe",required:!1,valid_types:"",info:"Input parameters, settings and options for QE DFT calculations"}],outputs:[{name:"all_index_uuid",required:!0,valid_types:"Dict",info:""},{name:"all_sites",required:!0,valid_types:"Dict",info:""},{name:"unique_sites",required:!0,valid_types:"Dict",info:""},{name:"unique_sites_dipolar",required:!1,valid_types:"List",info:""},{name:"unique_sites_hyperfine",required:!1,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:405,message:"One of the PwRelaxWorkChain subprocesses failed"},{status:406,message:"One of the PwBaseWorkChain subprocesses failed"},{status:407,message:"One of the PPWorkChain subprocesses failed"}]},class:"aiida_muon.workflows.find_muon:FindMuonWorkChain"}}},commits_count:21,development_status:"pre-alpha",summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/positivemuon/aiida-muon",is_installable:"True"},"aiida-musconv":{entry_point_prefix:"musconv",code_home:"https://github.com/positivemuon/aiida-musconv",version_file:"raw.githubusercontent.com/positivemuon/aiida-musconv/main/aiida_musconv/__init__.py",pip_url:"git+https://github.com/positivemuon/aiida-musconv",name:"aiida-musconv",package_name:"aiida_musconv",hosted_on:"github.com",metadata:{description:"aiida-musconv is a plugin that allows to obtain converged supercell size for an interstitial impurity calculation.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 2 - Pre-Alpha","Framework :: AiiDA"],author:"Muon  group Parma"},aiida_version:">=2.0,<3",entry_points:{"aiida.workflows":{musconv:{description:["WorkChain for finding converged supercell for interstitial impurity calculation"],spec:{inputs:[{name:"pwscf",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Input initial structure"},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space."},{name:"max_iter_num",required:!1,valid_types:"Int, NoneType",info:"Maximum number of iteration in the supercell convergence loop"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_length",required:!1,valid_types:"Float, NoneType",info:"The minimum length of the smallest lattice vector for the first generated supercell "},{name:"pseudofamily",required:!1,valid_types:"Str, NoneType",info:"The label of the pseudo family"}],outputs:[{name:"Converged_SCmatrix",required:!0,valid_types:"ArrayData",info:""},{name:"Converged_supercell",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:402,message:"one of the PwCalculation subprocesses failed"},{status:702,message:"Max number of supercell convergence reached "},{status:704,message:"Error in fitting the forces to an exponential"}]},class:"aiida_musconv.workflows.musconv:MusconvWorkChain"}}},commits_count:43,development_status:"pre-alpha",summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/positivemuon/aiida-musconv",is_installable:"True"},"aiida-nanotech-empa":{code_home:"https://github.com/nanotech-empa/aiida-nanotech-empa",development_status:"beta",entry_point_prefix:"nanotech_empa",pip_url:"git+https://github.com/nanotech-empa/aiida-nanotech-empa",name:"aiida-nanotech-empa",package_name:"aiida_nanotech_empa",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:31,warnings:["  > WARNING! Unable to retrieve plugin info from: https://raw.githubusercontent.com/nanotech-empa/aiida-nanotech-empa/master/setup.json","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/nanotech-empa/aiida-nanotech-empa",is_installable:"True"},"aiida-nims-scheduler":{code_home:"https://github.com/atztogo/aiida-nims-scheduler",development_status:"stable",documentation_url:"https://github.com/atztogo/aiida-nims-scheduler",entry_point_prefix:"nims_scheduler",pip_url:"git+https://github.com/atztogo/aiida-nims-scheduler",name:"aiida-nims-scheduler",package_name:"aiida_nims_scheduler",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:25,warnings:["  > WARNING! Unable to retrieve plugin info from: https://raw.githubusercontent.com/atztogo/aiida-nims-scheduler/master/setup.json","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/atztogo/aiida-nims-scheduler",is_installable:"True"},"aiida-nwchem":{code_home:"https://github.com/aiidateam/aiida-nwchem",documentation_url:"https://aiida-nwchem.readthedocs.io/",entry_point_prefix:"nwchem",pip_url:"aiida-nwchem",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-nwchem/master/setup.json",name:"aiida-nwchem",package_name:"aiida_nwchem",hosted_on:"github.com",metadata:{release_date:"2023-08-22",description:"The official AiiDA plugin for NWChem",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"3.0.1"},aiida_version:">=2.0,<3.0",entry_points:{"aiida.calculations":{"nwchem.base":{description:["Base calculation class for NWChem."],spec:{inputs:[{name:"input_file",required:!0,valid_types:"SinglefileData",info:"NWChem input file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, FolderData, NoneType",info:"Remote directory of a completed NWChem calculation to restart from."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Required output files are missing."},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"The stdout output file could not be read."},{status:312,message:"The stdout output file was incomplete."},{status:313,message:"The stdout contains multiple calculations"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception."}]},class:"aiida_nwchem.calculations.nwchem:NwchemBaseCalculation"},"nwchem.nwchem":{description:["Base calculation class for NWChem.","","    Synthesizes NWChem input file from parameter dictionary and StructureData."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure, with or without a cell"},{name:"add_cell",required:!1,valid_types:"Bool",info:"The input structure, with or without a cell"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, FolderData, NoneType",info:"Remote directory of a completed NWChem calculation to restart from."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Required output files are missing."},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"The stdout output file could not be read."},{status:312,message:"The stdout output file was incomplete."},{status:313,message:"The stdout contains multiple calculations"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception."}]},class:"aiida_nwchem.calculations.nwchem:NwchemCalculation"}},"aiida.parsers":{"nwchem.nwchem":"aiida_nwchem.parsers.nwchem:NwchemBaseParser"},"aiida.workflows":{"nwchem.base":{description:["Workchain to run an NWChem calculation with automated error handling and restarts."],spec:{inputs:[{name:"nwchem",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_nwchem.workflows.base:NwchemBaseWorkChain"}}},commits_count:22,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-nwchem",is_installable:"True"},"aiida-open_circuit_voltage":{entry_point_prefix:"quantumespresso.ocv",code_home:"https://github.com/tsthakur/aiida-open_circuit_voltage",name:"aiida-open_circuit_voltage",package_name:"aiida_open_circuit_voltage",hosted_on:"github.com",metadata:{author:"Tushar Thakur",author_email:"tushar.thakur@epfl.ch",version:"0.1.0",description:"The AiiDA plugin to calculate ocv at various charge of states using QE",classifiers:["Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Development Status :: 3 - Alpha","Natural Language :: English","Intended Audience :: Science/Research"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.workflows":{"quantumespresso.ocv.ocvwc":"aiida_open_circuit_voltage.workflows.workchain:OCVWorkChain"}},commits_count:26,development_status:"alpha",warnings:["Prefix 'quantumespresso.ocv' does not follow naming convention."],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"See source code repository."},"aiida-optimize":{code_home:"https://github.com/greschd/aiida-optimize",documentation_url:"https://aiida-optimize.readthedocs.io",entry_point_prefix:"optimize",pip_url:"aiida-optimize",plugin_info:"https://raw.githubusercontent.com/greschd/aiida-optimize/master/setup.json",name:"aiida-optimize",package_name:"aiida_optimize",hosted_on:"github.com",metadata:{release_date:"2023-03-30",description:"AiiDA Plugin for running optimization algorithms.",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-optimize.readthedocs.io/",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"1.0.2"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.workflows":{"optimize.optimize":{description:["Runs an optimization procedure, given an optimization engine that defines the optimization","    algorithm, and a process which evaluates the function to be optimized."],spec:{inputs:[{name:"engine",required:!0,valid_types:"Str",info:"Engine that runs the optimization."},{name:"engine_kwargs",required:!0,valid_types:"Dict",info:"Keyword arguments passed to the optimization engine."},{name:"evaluate_process",required:!0,valid_types:"Str",info:"Process which produces the result to be optimized."},{name:"evaluate",required:!1,valid_types:"",info:"Inputs that are passed to all evaluation processes."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"optimal_process_output",required:!0,valid_types:"",info:"Output value of the optimal evaluation process."},{name:"optimal_process_uuid",required:!0,valid_types:"",info:"UUID of the optimal evaluation process."},{name:"engine_outputs",required:!1,valid_types:"",info:""},{name:"optimal_process_input",required:!1,valid_types:"",info:"Input value of the optimal evaluation process."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Optimization failed because one of the evaluate processes did not finish ok."},{status:202,message:"Optimization failed because the engine did not finish ok."}]},class:"aiida_optimize._optimization_workchain:OptimizationWorkChain"},"optimize.wrappers.add_inputs":{description:["Wrapper workchain that takes inputs as keys and values and passes it","    on to a sub-process. This enables taking a process which was not","    designed to be used in optimization, and optimize with respect to","    some arbitrary input. Inputs which always remain the same can be","    specified in the ``inputs`` namespace, whereas the inputs to be","    optimized are given through the ``added_input_keys`` and","    ``added_input_values`` inputs.","","    The outputs of the wrapper workchain are the same as those of","    the wrapped process.","",'    The "added" inputs can only be BaseType sub-classes, or',"    attributes of a Dict. For each input, its port location is given",'    in the "added_input_keys" input. For example, ``x.y`` would set',"    the ``y`` input in the ``x`` namespace.","","    For cases where the input is a Dict attribute, the (possibly nested) attribute name is given after a colon. That means ``x:a.b`` would","    set the ``['a']['b']`` attribute of the ``Dict`` given in the ``x``","    input.","","    In cases where only a single input needs to be added, they can be","    specified directly instead of wrapped in a List."],spec:{inputs:[{name:"added_input_keys",required:!0,valid_types:"List, Str",info:"Specifies the location of each added input."},{name:"added_input_values",required:!0,valid_types:"List, BaseType",info:"Values of the added inputs to be passed into the sub-process."},{name:"sub_process",required:!0,valid_types:"Str",info:"The class of the process that should be wrapped."},{name:"inputs",required:!1,valid_types:"",info:"Inputs to be passed on to the sub-process."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Workchain failed because the sub-process did not finish ok."}]},class:"aiida_optimize.wrappers._add_inputs:AddInputsWorkChain"},"optimize.wrappers.concatenate":{description:["Allows concatenating an arbitrary number of sub-processes.","","    A wrapper workchain that allows concatenating an arbitrary number","    of sub-processes. Outputs of one processes can be configured to","    be passed to the next one."],spec:{inputs:[{name:"output_input_mappings",required:!0,valid_types:"List",info:"Defines how inputs are passed between sub-processes. Each list entry entry has the form `((process_label_a, process_label_b), mapping)`, and defines outputs of process A to be passed to process B. The `mapping` values are dictionaries `{'output_name': 'input_name'}` giving the output name (in process A) and input name (in process B) for each value to pass."},{name:"process_inputs",required:!0,valid_types:"",info:"Inputs which are passed on to the sub-processes. The inputs should be grouped into a namespace identified by the process label."},{name:"process_labels",required:!0,valid_types:"List",info:"A list of pairs (label, process_name). The labels can be any string, the process_name needs to be loadable by `aiida_optimize.process_inputs.load_object`, and defines which process is being run."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"process_outputs",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"Workchain failed because a sub-process failed."}]},class:"aiida_optimize.wrappers._concatenate:ConcatenateWorkChain"},"optimize.wrappers.create_evaluate":{description:["Wrapper workchain to combine two processes: The first process _creates_","    a result, and the second _evaluates_ that result.","","    The purpose of this workchain is to facilitate optimization of processes","    which don't natively produce an output that can be optimized, by only","    having to add the 'evaluation' part."],spec:{inputs:[{name:"create",required:!0,valid_types:"",info:"Inputs which are passed on to the create sub-process."},{name:"create_process",required:!0,valid_types:"Str",info:"The sub-process which performs the create step."},{name:"evaluate_process",required:!0,valid_types:"Str",info:"The sub-process which performs the evaluate step."},{name:"output_input_mapping",required:!0,valid_types:"Dict",info:"A mapping from output names of the create process to input names of the evaluate process. These outputs (if present) are forwarded to the evaluate process."},{name:"evaluate",required:!1,valid_types:"",info:"Inputs which are passed on to the evaluate sub-process."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"create",required:!0,valid_types:"",info:""},{name:"evaluate",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Workchain failed because the 'create' sub-process failed."},{status:202,message:"Workchain failed because the 'evaluate' sub-process failed."}]},class:"aiida_optimize.wrappers._create_evaluate:CreateEvaluateWorkChain"}}},commits_count:2,development_status:"stable",summaryinfo:[{colorclass:"green",text:"Workflows",count:4}],pip_install_cmd:"pip install aiida-optimize",is_installable:"True"},"aiida-orca":{code_home:"https://github.com/pzarabadip/aiida-orca",development_status:"stable",documentation_url:"https://aiida-orca.readthedocs.io/",entry_point_prefix:"orca",pip_url:"git+https://github.com/pzarabadip/aiida-orca",name:"aiida-orca",package_name:"aiida_orca",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"0.5.1",description:"AiiDA plugin for ORCA code",classifiers:["Environment :: Plugins","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Framework :: AiiDA"]},aiida_version:">=1.0.0,<2.0.0",entry_points:{"aiida.calculations":{orca_main:"aiida_orca.calculations:OrcaCalculation",orca_asa:"aiida_orca.calculations:OrcaAsaCalculation"},"aiida.parsers":{orca_base_parser:"aiida_orca.parsers:OrcaBaseParser"},"aiida.workflows":{"orca.base":{description:["Workchain to run a orca calculation with automated error handling and restarts."],spec:{inputs:[{name:"orca",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"the results of the calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"relaxed_structure",required:!1,valid_types:"StructureData",info:"relaxed structure"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:301,message:"The calculation failed with an unrecoverable error coming from aiida-orca."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_orca.workchains:OrcaBaseWorkChain"}}},commits_count:40,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-orca",is_installable:"True"},"aiida-phonopy":{code_home:"https://github.com/aiida-phonopy/aiida-phonopy",documentation_url:"https://aiida-phonopy.readthedocs.io/",entry_point_prefix:"phonopy",pip_url:"aiida-phonopy",plugin_info:"https://raw.githubusercontent.com/aiida-phonopy/aiida-phonopy/master/setup.json",name:"aiida-phonopy",package_name:"aiida_phonopy",hosted_on:"github.com",metadata:{release_date:"2023-05-24",description:"The official AiiDA plugin for Phonopy",author_email:"Lorenzo Bastonero <bastonero.lorenzo@gmail.com>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"1.1.3"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{"phonopy.phonopy":{description:["Base `CalcJob` implementation for Phonopy post-processing."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:`Phonopy parameters (\`setting tags\`) for post processing. The following tags, along their type, are allowed:
PRIMITIVE_AXES
PRIMITIVE_AXIS
EIGENVECTORS
BAND
BAND_PATHS
BAND_POINTS
BAND_LABELS
BAND_CONNECTION
BAND_INDICES
MESH
MP
MESH_NUMBERS
MP_SHIFT
GAMMA_CENTER
WRITE_MESH
DOS
DOS_RANGE
FMIN
FMAX
FPITCH
PDOS
PROJECTION_DIRECTION
XYZ_DIRECTION
SIGMA
DEBYE_MODEL
MOMEMT
MOMENT_ORDER
TPROP
TMIN
TMAX
TSTEP
PRETEND_REAL
CUTOFF_FREQUENCY
TDISP
TDISPMAT
TDISPMAT_CIF
QPOINTS
WRITEDM
NAC_METHOD
Q_DIRECTION
GROUP_VELOCITY
GV_DELTA_Q
SYMMETRY_TOLERANCE
SYMMETRY
MESH_SYMMETRY
FC_SYMMETRY
FULL_FORCE_CONSTANTS
WRITE_FORCE_CONSTANTS
ANIME_TYPE
ANIME
MODULATION
IRREPS
SHOW_IRREPS
LITTLE_COGROUP`},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"force_constants",required:!1,valid_types:"ForceConstantsData, NoneType",info:"Force constants of the input structure."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"phonopy_data",required:!1,valid_types:"PhonopyData, NoneType",info:"The preprocess output info of a previous ForceConstantsWorkChain."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Settings for phonopy calculation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"irreducible_representations",required:!1,valid_types:"Dict",info:"Irreducible representation output."},{name:"modulation",required:!1,valid_types:"Dict",info:"Modulation information."},{name:"output_force_constants",required:!1,valid_types:"ArrayData",info:"Calculated force constants."},{name:"output_parameters",required:!1,valid_types:"Dict",info:"Sum up info of phonopy calculation."},{name:"phonon_bands",required:!1,valid_types:"BandsData",info:"Calculated phonon band structure."},{name:"projected_phonon_dos",required:!1,valid_types:"XyData",info:"Calculated projected DOS."},{name:"qpoints",required:!1,valid_types:"BandsData",info:"Calculated qpoints."},{name:"qpoints_mesh",required:!1,valid_types:"BandsData",info:"Calculated qpoint mesh."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"thermal_displacement_matrices",required:!1,valid_types:"Dict",info:"Calculated thermal displacements matrices."},{name:"thermal_displacements",required:!1,valid_types:"Dict",info:"Calculated thermal displacements."},{name:"thermal_properties",required:!1,valid_types:"XyData",info:"Calculated thermal properties."},{name:"total_phonon_dos",required:!1,valid_types:"XyData",info:"Calculated total DOS."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required phonopy file."},{status:304,message:"The retrieved folder did not contain one or more expected output files."},{status:305,message:"No run mode has been selected."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The loading of yaml file got an unexpected error."},{status:321,message:"The file loading via numpy got an unexpected error."},{status:350,message:"The parser raised an unexpected exception."},{status:400,message:"The parser was not able to parse one or more files."}]},class:"aiida_phonopy.calculations.phonopy:PhonopyCalculation"}},"aiida.data":{"phonopy.force_constants":"aiida_phonopy.data.force_constants:ForceConstantsData","phonopy.phonopy":"aiida_phonopy.data.phonopy:PhonopyData","phonopy.preprocess":"aiida_phonopy.data.preprocess:PreProcessData","phonopy.raw":"aiida_phonopy.data.raw:RawData"},"aiida.parsers":{"phonopy.phonopy":"aiida_phonopy.parsers.phonopy:PhonopyParser"},"aiida.workflows":{"phonopy.phonopy":{description:["Abstract workflow for automated frozen phonons.","","    Phonopy is used to produce structures with displacements,","    while the forces are calculated with a quantum engine of choice.","","    This workchain is meant to be used as a base for other specific force calculato plugin workchains,","    or as an example on how to set a possible workchain/workflow. For this reason, the outline of","    this class is not defined, while it provides the inputs and a `setup` method, which can be used","    in a specific workflow outline. Ideally, the workflow would look like:","","    1. Setup the preprocess data.","","        This is already provided in this class. It setups a `PreProcessData` node, from where","        supercell, primitive cell and supercells with displacements can be easily extracted using","        the methods of the nodes. This node can be taken from `self.ctx.preprocess_data`, and used","        during the outline of the workflow.","","    2. Run supercells using the selected quantum engine/force calculator code.","","        In specific code implementations, a force calculation on supercells needs to be run.","        To get these supercells, one need simply to run:","","        ```self.ctx.preprocess_data.calcfunctions.get_supercells_with_displacements()```","","        This will return a dictionary with all the supercells as StructureData to run for the phonon calculation.","        The keys of this dictionary are of the type `supercell_{number}`, where `number` is an integer.","        These numbers are essentials since the `phonopy` force sets is generated following these numbers,","        in order to make sure to refer to the correct displacement. Thus, it is required to keep track","        of them.","        Moreover,a calculation over the pristine supercell structure should be run before hand as reference.","        This structure can instead be gotten via:","","        ```self.ctx.preprocess_data.calcfunctions.get_supercell()```","","        This will return a StructureData without any label.","","        For an example of implementation, refer to aiidateam/aiida-common-worfklows.","","        * Note: some type of force calculation needs to map some variables from the unitcell to the supercell","        (and in certain case even the primitive cell), e.g. the atomic spin in VASP. Since this is code dependent,","        you will need to map these parameters before launching the force calculation of a certain supercell","        with displacement. This information can be gotten via:","","        ```self.ctx.preprocess_data.get_cells_mappings()```","","        Moreover, consider that cells in phonopy will always (re)fold the atoms in order to have positive coordinates.","","    3. Inspect all runs and expose the forces and energies (not mandatory) outputs.","","        * Suggested: when the calculation on each supercell has finished (correctly)","        expose the output forces (and energies) in the dynamical `supercells_forces(energies)` namespace(s).","        Provide each supercell forces as an `ArrayData` with the forces stored as `forces`","        (e.g. if your code plugin stores  the forces in `TrajectoryData`, extract them with a `calcfunction`).","        Expose each `ArrayData` choosing a **common prefix**, while as **suffix use","        _{number}**, with `{number}` referring to the correspective supercell label suffix (that you are supposed to","        keep track somewhere, e.g. in the label of the code calculation/workchain).","        Now you can gather all the information in one data noe, i.e. in a `PhonopyData` node.","        To do so, you can simple run:","","        ```self.ctx.preprocess_data.calcfunctions.generate_phonopy_data(**self.outputs.supercells_forces)```","","        and then expose it as output in the `output_phonopy_data` namespace.","","        * Alternatively: instead of exposing the supercell forces as outputs, you can directly gather all the forces","        in a dictionary and run directly to the `generate_phonopy_data` method using this dictionary (always using","        the double *).","","        See the implementation in aiidateam/aiida-common-workflows for an example.","","    4. (optional) Run the non-analytical constants on the primitive cell.","","        Non-analytical constants should be run for polar insulators. These require usually a linear response code","        or a finite difference approach (e.g. using the electric enthalpy). Since this is usually the most expensive","        part, you should run them on the primitive cell. To get it, use:","","        ```self.ctx.preprocess_data.calcfunctions.get_primitive_cell()```","","        If you compute also these, collect the dielectric tensor and the effectic born charges in an ArrayData,","        with the arraynames `dielectric` and `born_charges` (in Cartesian coordinates!).","        Then, gather all the information of nac and forces in a unique `PhonopyData` via:","","        ```","        self.ctx.preprocess_data.calcfunctions.generate_phonopy_data(","            nac_parameters=nac_paramters,","            **self.outputs.supercells_forces","            )","        ```","","        and expose the output.","","        * Note: we require in the input for generating the full phonopy data, to give the nac in the primitive cell.","        The primitive cell of phonopy will just rotate the lattice vectors, thus mantaining the Cartasian coordinate","        system. It can happen, though, that the unitcell is not the primitive cell of the system, meaning that the","        primitive cell will contain less atoms. We expect in input the nac computed on this number of atoms. If you","        want, for some reason, compute the nac on the unitcell, you will need to get the reduced nac.","        To do so, you can consider using a built-in function in phonopy, namely:","","        :py:func:`phonopy.structure.symmetry.elaborate_borns_and_epsilon`"],spec:{inputs:[{name:"options",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"displacement_generator",required:!1,valid_types:"Dict, NoneType",info:`Info for displacements generation. The following flags are allowed:
 distance
 is_plusminus
 is_diagonal
 is_trigonal
 number_of_snapshots
 random_seed
 temperature
 cutoff_frequency`},{name:"fc_options",required:!1,valid_types:"Dict, NoneType",info:`Options for force constants calculation (optional). The following flags are allowed:
 calculate_full_force_constants
 fc_calculator
 fc_calculator_options`},{name:"is_symmetry",required:!1,valid_types:"Bool, NoneType",info:"Whether using or not the space group symmetries."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"nac_parameters",required:!1,valid_types:"ArrayData, NoneType",info:"Non-analytical parameters."},{name:"preprocess_data",required:!1,valid_types:"PhonopyData, PreProcessData, NoneType",info:"The preprocess data for frozen phonon calcualtion."},{name:"primitive_matrix",required:!1,valid_types:"List, NoneType",info:"The matrix used to generate the primitive cell from the input structure in the List format. Allowed shapes are 3x1 and 3x3 lists."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"The structure at equilibrium volume."},{name:"supercell_matrix",required:!1,valid_types:"List, NoneType",info:"The matrix used to generate the supercell from the input structure in the List format. Allowed shapes are 3x1 and 3x3 lists."},{name:"symmetry_tolerance",required:!1,valid_types:"Float, NoneType",info:"Symmetry tolerance for space group analysis on the input structure."}],outputs:[{name:"output_phonopy_data",required:!0,valid_types:"PhonopyData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"supercells_forces",required:!0,valid_types:"ArrayData",info:"The forces acting on the atoms of each supercell."},{name:"output_force_constants",required:!1,valid_types:"ForceConstantsData",info:"The matrix of force constants computed with finite displacements."},{name:"supercells",required:!1,valid_types:"StructureData",info:"The supercells with displacements."},{name:"supercells_energies",required:!1,valid_types:"Float",info:"The total energy of each supercell."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_phonopy.workflows.phonopy:PhonopyWorkChain"}}},commits_count:64,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:4},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-phonopy",is_installable:"True"},"aiida-phtools":{code_home:"https://github.com/ltalirz/aiida-phtools",entry_point_prefix:"phtools",pip_url:"aiida-phtools",plugin_info:"https://raw.github.com/ltalirz/aiida-phtools/master/setup.json",name:"aiida-phtools",package_name:"aiida_phtools",hosted_on:"github.com",metadata:{release_date:"2018-06-21",description:"AiiDA plugin for persistence homology tools, used to analyze nanoporous materials.",author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-phtools",classifiers:["Programming Language :: Python"],version:"0.1.0a1"},aiida_version:"*",entry_points:{"aiida.calculations":{"phtools.dmatrix":"aiida_phtools.calculations.distance_matrix:DistanceMatrixCalculation","phtools.surface":"aiida_phtools.calculations.pore_surface:PoreSurfaceCalculation"},"aiida.data":{"phtools.surface":"aiida_phtools.data.pore_surface:PoreSurfaceParameters"},"aiida.parsers":{"phtools.dmatrix":"aiida_phtools.parsers.distance_matrix:DistanceMatrixParser","phtools.surface":"aiida_phtools.parsers.pore_surface:PoreSurfaceParser"}},commits_count:0,development_status:"planning",warnings:["Missing classifier 'Framework :: AiiDA'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install --pre aiida-phtools"},"aiida-plumed":{code_home:"https://github.com/ConradJohnston/aiida-plumed",entry_point_prefix:"plumed",pip_url:"aiida-plumed",plugin_info:"https://raw.github.com/ConradJohnston/aiida-plumed/AiiDA-v1.0-compatibility/setup.json",name:"aiida-plumed",package_name:"aiida_plumed",hosted_on:"github.com",metadata:{release_date:"2019-09-16",description:"AiiDA plugin providing support for Plumed2",author:"Conrad Johnston",author_email:"conrad.s.johnston@googlemail.com",license:"MIT",home_page:"https://github.com/ConradJohnston/aiida-plumed",classifiers:["Development Status :: 2 - Pre-Alpha","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0a0"},aiida_version:">=1.0.0b3,<2.0.0",entry_points:{"aiida.calculations":{plumed:"aiida_plumed.calculations:DiffCalculation"},"aiida.cmdline.data":{plumed:"aiida_plumed.cli:data_cli"},"aiida.data":{plumed:"aiida_plumed.data:DiffParameters"},"aiida.parsers":{plumed:"aiida_plumed.parsers:DiffParser"}},commits_count:0,development_status:"pre-alpha",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install --pre aiida-plumed",is_installable:"True"},"aiida-porousmaterials":{code_home:"https://github.com/pzarabadip/aiida-porousmaterials",development_status:"stable",entry_point_prefix:"porousmaterials",pip_url:"aiida-porousmaterials",name:"aiida-porousmaterials",package_name:"aiida_porousmaterials",hosted_on:"github.com",metadata:{release_date:"2020-03-05",description:"AiiDA plugin for PorousMaterials code",author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",license:"MIT",home_page:"https://github.com/pzarabadip/aiida-porousmaterials",classifiers:["Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8"],version:"1.0.0a3"},aiida_version:null,entry_points:{"aiida.calculations":{porousmaterials:{description:["This is PorousMaterialsCalculation as the subclass","    of AiiDA CalcJob to prepare input for the PorousMaterials","    suite of Julia codes.","    Please refer to : https://github.com/SimonEnsemble/PorousMaterials.jl"],spec:{inputs:[{name:"acc_voronoi_nodes",required:!0,valid_types:"SinglefileData",info:"Accessible Voronoi nodes calculated by Zeo++"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"parameters such as cutoff and mixing rules."},{name:"structure",required:!0,valid_types:"CifData",info:"Framework input file as CIF"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"settings",required:!1,valid_types:"Dict",info:"Additional input parameters"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"dictionary of calculated Voronoi energies"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"ev_output_file",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"The retrieved folder does not contain an output file."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_porousmaterials.calculations:PorousMaterialsCalculation"}},"aiida.parsers":{porousmaterials:"aiida_porousmaterials.parser:PorousMaterialsParser"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install --pre aiida-porousmaterials",is_installable:"True"},"aiida-pseudo":{code_home:"https://github.com/aiidateam/aiida-pseudo",entry_point_prefix:"pseudo",pip_url:"aiida-pseudo",plugin_info:"https://raw.github.com/aiidateam/aiida-pseudo/master/setup.cfg",name:"aiida-pseudo",package_name:"aiida_pseudo",hosted_on:"github.com",metadata:{release_date:"2023-08-23",description:"AiiDA plugin that simplifies working with pseudo potentials.",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>',classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.2.0"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.data":{pseudo:"aiida_pseudo.data.pseudo.pseudo:PseudoPotentialData","pseudo.jthxml":"aiida_pseudo.data.pseudo.jthxml:JthXmlData","pseudo.psf":"aiida_pseudo.data.pseudo.psf:PsfData","pseudo.psml":"aiida_pseudo.data.pseudo.psml:PsmlData","pseudo.psp8":"aiida_pseudo.data.pseudo.psp8:Psp8Data","pseudo.upf":"aiida_pseudo.data.pseudo.upf:UpfData","pseudo.vps":"aiida_pseudo.data.pseudo.vps:VpsData"},"aiida.groups":{"pseudo.family":"aiida_pseudo.groups.family.pseudo:PseudoPotentialFamily","pseudo.family.cutoffs":"aiida_pseudo.groups.family.cutoffs:CutoffsPseudoPotentialFamily","pseudo.family.pseudo_dojo":"aiida_pseudo.groups.family.pseudo_dojo:PseudoDojoFamily","pseudo.family.sssp":"aiida_pseudo.groups.family.sssp:SsspFamily"},console_scripts:{"aiida-pseudo":"aiida_pseudo.cli:cmd_root"}},commits_count:27,development_status:"stable",summaryinfo:[{colorclass:"red",text:"Data",count:7},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Groups)",count:4}],pip_install_cmd:"pip install aiida-pseudo",is_installable:"True"},"aiida-psi4":{code_home:"https://github.com/ltalirz/aiida-psi4/tree/master",development_status:"beta",entry_point_prefix:"psi4",pip_url:"git+https://github.com/ltalirz/aiida-psi4",name:"aiida-psi4",package_name:"aiida_psi4",hosted_on:"github.com",metadata:{author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",version:"0.1.0a0",description:"AiiDA plugin for the Psi4 Quantum Chemistry package.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.4,<2.0.0",entry_points:{"aiida.data":{"psi4.atomic_input":"aiida_psi4.data:AtomicInput"},"aiida.calculations":{psi4:"aiida_psi4.calculations:Psi4Calculation"},"aiida.parsers":{psi4:"aiida_psi4.parsers:QCSchemaParser"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install git+https://github.com/ltalirz/aiida-psi4",is_installable:"True"},"aiida-pyscf":{code_home:"https://github.com/microsoft/aiida-pyscf",entry_point_prefix:"pyscf",pip_url:"aiida-pyscf",plugin_info:"https://raw.githubusercontent.com/microsoft/aiida-pyscf/main/pyproject.toml",name:"aiida-pyscf",package_name:"aiida_pyscf",hosted_on:"github.com",metadata:{release_date:"2023-08-16",description:"AiiDA plugin for the Python-based Simulations of Chemistry Framework (PySCF).",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>, Adam Grofe <v-adamgrofe@microsoft.com>',classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"0.4.1"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"pyscf.base":{description:["``CalcJob`` plugin for PySCF."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"structure",required:!0,valid_types:"StructureData",info:"Input structure with molecular structure definition."},{name:"checkpoint",required:!1,valid_types:"SinglefileData, NoneType",info:"Checkpoint of a previously completed calculation that failed to converge."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Input parameters used to render the PySCF script template."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cubegen",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"checkpoint",required:!1,valid_types:"SinglefileData",info:"The checkpoint file in case the calculation did not converge. Can be used as an input for a restart."},{name:"fcidump",required:!1,valid_types:"SinglefileData",info:"Computed fcidump files."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The computed Hessian."},{name:"model",required:!1,valid_types:"PickledData",info:"The model in serialized form. Can be deserialized and used without having to run the kernel again."},{name:"parameters",required:!1,valid_types:"Dict",info:"Various computed properties parsed from the `FILENAME_RESULTS` output file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"The optimized structure if the input parameters contained the `optimizer` key."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The geometry optimization trajectory if the input parameters contained the `optimizer` key."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The stdout output file was not retrieved."},{status:303,message:"The results JSON file was not retrieved."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."}]},class:"aiida_pyscf.calculations.base:PyscfCalculation"}},"aiida.parsers":{"pyscf.base":"aiida_pyscf.parsers.base:PyscfParser"},"aiida.workflows":{"pyscf.base":{description:["Workchain to run a pyscf calculation with automated error handling and restarts."],spec:{inputs:[{name:"pyscf",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"cubegen",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"checkpoint",required:!1,valid_types:"SinglefileData",info:"The checkpoint file in case the calculation did not converge. Can be used as an input for a restart."},{name:"fcidump",required:!1,valid_types:"SinglefileData",info:"Computed fcidump files."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The computed Hessian."},{name:"model",required:!1,valid_types:"PickledData",info:"The model in serialized form. Can be deserialized and used without having to run the kernel again."},{name:"parameters",required:!1,valid_types:"Dict",info:"Various computed properties parsed from the `FILENAME_RESULTS` output file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"The optimized structure if the input parameters contained the `optimizer` key."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The geometry optimization trajectory if the input parameters contained the `optimizer` key."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed and did not retrieve a checkpoint file from which can be restarted."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_pyscf.workflows.base:PyscfBaseWorkChain"}}},commits_count:67,development_status:"alpha",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-pyscf",is_installable:"True"},"aiida-python":{entry_point_prefix:"aiidapython",code_home:"https://github.com/addman2/aiida-python",name:"aiida-python",package_name:"aiida_python",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:44,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found","Prefix 'aiidapython' does not follow naming convention."],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-qeq":{code_home:"https://github.com/ltalirz/aiida-qeq",development_status:"stable",entry_point_prefix:"qeq",pip_url:"aiida-qeq",plugin_info:"https://raw.githubusercontent.com/ltalirz/aiida-qeq/master/setup.json",name:"aiida-qeq",package_name:"aiida_qeq",hosted_on:"github.com",metadata:{release_date:"2018-11-21",description:"AiiDA plugin for computing electronic charges on atoms using equilibration-type models (QEq, EQEq, ...).",author:"Leopold Talirz, Daniele Ongari",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-qeq",classifiers:["Programming Language :: Python"],version:"0.1.0"},aiida_version:">=0.12.2,<1.0.0",entry_points:{"aiida.calculations":{"qeq.eqeq":{description:["AiiDA calculation plugin for the EQeq code."],spec:{inputs:[{name:"charge_data",required:!0,valid_types:"SinglefileData",info:"File containing information on common oxidation state of the elements."},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"ionization_data",required:!0,valid_types:"SinglefileData",info:"File containing ionization data on the elements."},{name:"parameters",required:!0,valid_types:"EQeqParameters",info:"Command line parameters for EQEQ"},{name:"structure",required:!0,valid_types:"CifData",info:"Input structure, for which atomic charges are to be computed."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_qeq.calculations.eqeq:EQeqCalculation"},"qeq.qeq":{description:["AiiDA calculation plugin for the Qeq code."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"SinglefileData",info:"File containing electronegativity and Idempotential data of the elements."},{name:"structure",required:!0,valid_types:"CifData",info:"Input structure, for which atomic charges are to be computed."},{name:"configure",required:!1,valid_types:"QeqParameters",info:"Configuration input for QEQ (configure.input file)"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_qeq.calculations.qeq:QeqCalculation"}},"aiida.data":{"qeq.eqeq":"aiida_qeq.data.eqeq:EQeqParameters","qeq.qeq":"aiida_qeq.data.qeq:QeqParameters"},"aiida.parsers":{"qeq.eqeq":"aiida_qeq.parsers.eqeq:EQeqParser","qeq.qeq":"aiida_qeq.parsers.qeq:QeqParser"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:2}],pip_install_cmd:"pip install aiida-qeq",is_installable:"True"},"aiida-qp2":{code_home:"https://github.com/TREX-CoE/aiida-qp2",entry_point_prefix:"qp2",pip_url:"aiida-qp2",documentation_url:"https://trex-coe.github.io/aiida-qp2/index.html",name:"aiida-qp2",package_name:"aiida_qp2",hosted_on:"github.com",metadata:{release_date:"2022-02-26",description:"AiiDA plugin for the Quantum Package 2.0",author:"Evgeny Posenitskiy",author_email:"posenitskiy@irsamc.ups-tlse.fr",license:"MIT",home_page:"https://github.com/TREX-CoE/aiida-qp2",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.calculations":{qp2:{description:["AiiDA calculation plugin wrapping the Quantum Package code."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters to generate the input file."},{name:"basissets",required:!1,valid_types:"",info:"A dictionary of basissets to be used in the calculations: key is the atomic symbol, value is either a single basisset."},{name:"code",required:!1,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"",info:"A dictionary of pseudopotentials to be used in the calculations: key is the atomic symbol, value is a single pseudopotential."},{name:"settings",required:!1,valid_types:"Dict",info:"Additional input parameters."},{name:"structure",required:!1,valid_types:"StructureData",info:"Input structrure"},{name:"wavefunction",required:!1,valid_types:"SinglefileData",info:"The wavefunction file (EZFIO or TREXIO)."}],outputs:[{name:"output_wavefunction",required:!0,valid_types:"SinglefileData",info:"The wave function file (EZFIO or TREXIO)"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_energy",required:!1,valid_types:"Float",info:"The result of the calculation"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"Calculation did not produce all expected output files."},{status:400,message:"Energy value is not present in the output file."}]},class:"aiida_qp2.calculations:QP2Calculation"}},"aiida.parsers":{qp2:"aiida_qp2.parsers:QP2Parser"}},commits_count:0,development_status:"beta",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-qp2",is_installable:"True"},"aiida-quantumespresso":{code_home:"https://github.com/aiidateam/aiida-quantumespresso",documentation_url:"https://aiida-quantumespresso.readthedocs.io/",entry_point_prefix:"quantumespresso",pip_url:"aiida-quantumespresso",plugin_info:"https://raw.github.com/aiidateam/aiida-quantumespresso/master/setup.json",name:"aiida-quantumespresso",package_name:"aiida_quantumespresso",hosted_on:"github.com",metadata:{release_date:"2023-07-24",description:"The official AiiDA plugin for Quantum ESPRESSO",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"4.4.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"quantumespresso.cp":{description:["`CalcJob` implementation for the cp.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_trajectory",required:!0,valid_types:"TrajectoryData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The required XML file is not present in the retrieved folder."},{status:304,message:"The retrieved folder contains multiple XML files."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The required XML file could not be read."},{status:330,message:"The required POS file could not be read."},{status:340,message:"The required trajectory data could not be read."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."}]},class:"aiida_quantumespresso.calculations.cp:CpCalculation"},"quantumespresso.create_kpoints_from_distance":{description:["Generate a uniformly spaced kpoint mesh for a given structure.","","    The spacing between kpoints in reciprocal space is guaranteed to be at least the defined distance.","","    :param structure: the StructureData to which the mesh should apply","    :param distance: a Float with the desired distance between kpoints in reciprocal space","    :param force_parity: a Bool to specify whether the generated mesh should maintain parity","    :returns: a KpointsData with the generated mesh"],spec:{inputs:[{name:"distance",required:!0,valid_types:"Data",info:"a Float with the desired distance between kpoints in reciprocal space"},{name:"force_parity",required:!0,valid_types:"Data",info:"a Bool to specify whether the generated mesh should maintain parity"},{name:"structure",required:!0,valid_types:"Data",info:"the StructureData to which the mesh should apply"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.create_kpoints_from_distance:create_kpoints_from_distance"},"quantumespresso.create_magnetic_configuration":{description:["Create a new magnetic configuration from the given structure based on a list of magnetic moments per site.","","    To create the new list of kinds, the algorithm loops over all the elements in the structure and makes a list of the","    sites with that element and their corresponding magnetic moment. Next, it splits this list in three lists:","","    * Zero magnetic moments: Any site that has an absolute magnetic moment lower than ``ztol``","    * Positive magnetic moments","    * Negative magnetic moments","","    The algorithm then sorts the positive and negative lists from large to small absolute value, and loops over each of","    list. New magnetic kinds will be created when the absolute difference between the magnetic moment of the current","    kind and the site exceeds ``atol``.","","    The positive and negative magnetic moments are handled separately to avoid assigning two sites with opposite signs","    in their magnetic moment to the same kind and make sure that each kind has the correct magnetic moment, i.e. the","    largest magnetic moment in absolute value of the sites corresponding to that kind.","","    .. important:: the function currently does not support alloys.","","    :param structure: a `StructureData` instance.","    :param magnetic_moment_per_site: list of magnetic moments for each site in the structure.","    :param atol: the absolute tolerance on determining if two sites have the same magnetic moment.","    :param ztol: threshold for considering a kind to have non-zero magnetic moment."],spec:{inputs:[{name:"magnetic_moment_per_site",required:!0,valid_types:"Data",info:"list of magnetic moments for each site in the structure."},{name:"structure",required:!0,valid_types:"Data",info:"a `StructureData` instance."},{name:"atol",required:!1,valid_types:"Data",info:"the absolute tolerance on determining if two sites have the same magnetic moment."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"ztol",required:!1,valid_types:"Data",info:"threshold for considering a kind to have non-zero magnetic moment."}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.create_magnetic_configuration:create_magnetic_configuration"},"quantumespresso.dos":{description:["`CalcJob` implementation for the dos.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_dos",required:!0,valid_types:"XyData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The dos file could not be read from the retrieved folder."}]},class:"aiida_quantumespresso.calculations.dos:DosCalculation"},"quantumespresso.epw":{description:["`CalcJob` implementation for the epw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"kfpoints",required:!0,valid_types:"KpointsData",info:"fine kpoint mesh"},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"coarse kpoint mesh"},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"parent_folder_nscf",required:!0,valid_types:"RemoteData",info:"the folder of a completed nscf `PwCalculation`"},{name:"parent_folder_ph",required:!0,valid_types:"RemoteData",info:"the folder of a completed `PhCalculation`"},{name:"qfpoints",required:!0,valid_types:"KpointsData",info:"fine qpoint mesh"},{name:"qpoints",required:!0,valid_types:"KpointsData",info:"coarse qpoint mesh"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_quantumespresso.calculations.epw:EpwCalculation"},"quantumespresso.matdyn":{description:["`CalcJob` implementation for the matdyn.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"Kpoints on which to calculate the phonon frequencies."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"parent_folder",required:!1,valid_types:"RemoteData, FolderData, SinglefileData, NoneType",info:"Use a local or remote folder as parent folder (for restarts and similar)"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_phonon_bands",required:!0,valid_types:"BandsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The output frequencies file could not be read from the retrieved folder."},{status:410,message:"Number of kpoints not found in the output data"},{status:411,message:"Number of kpoints in the inputs is not commensurate with those in the output"}]},class:"aiida_quantumespresso.calculations.matdyn:MatdynCalculation"},"quantumespresso.merge_ph_outputs":{description:["Calcfunction to merge outputs from multiple `ph.x` calculations with different q-points."],spec:{inputs:[{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.merge_ph_outputs:merge_ph_outputs"},"quantumespresso.namelists":{description:["`CalcJob` implementation to serve as base class for simple post-processing tools of Quantum ESPRESSO."],spec:{inputs:[{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"parent_folder",required:!1,valid_types:"RemoteData, FolderData, SinglefileData, NoneType",info:"Use a local or remote folder as parent folder (for restarts and similar)"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."}]},class:"aiida_quantumespresso.calculations.namelists:NamelistsCalculation"},"quantumespresso.neb":{description:["Nudged Elastic Band code (neb.x) of Quantum ESPRESSO distribution."],spec:{inputs:[{name:"first_structure",required:!0,valid_types:"StructureData",info:"Initial structure"},{name:"last_structure",required:!0,valid_types:"StructureData",info:"Final structure"},{name:"parameters",required:!0,valid_types:"Dict",info:"NEB-specific input parameters"},{name:"pw",required:!0,valid_types:"Data",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."}],outputs:[{name:"output_mep",required:!0,valid_types:"ArrayData",info:"The original and interpolated energy profiles along the minimum-energy path (mep)"},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output parameters dictionary of the NEB calculation"},{name:"output_trajectory",required:!0,valid_types:"TrajectoryData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"iteration_array",required:!1,valid_types:"ArrayData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:303,message:"The required XML file is not present in the retrieved folder."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.neb:NebCalculation"},"quantumespresso.open_grid":{description:["``CalcJob`` implementation for the ``open_grid.x`` code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a completed `PwCalculation` on an irreducible Brillouin zone"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The explicit list of kpoints of the unfolded kmesh"},{name:"kpoints_mesh",required:!0,valid_types:"KpointsData",info:"The dimensions of the unfolded kmesh"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"The retrieved folder data node could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:312,message:"Found rotation or fractional translation not compatible with FFT grid."},{status:350,message:"Mismatch between kmesh dimensions and number of kpoints."}]},class:"aiida_quantumespresso.calculations.open_grid:OpenGridCalculation"},"quantumespresso.ph":{description:["`CalcJob` implementation for the ph.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"the folder of a completed `PwCalculation`"},{name:"qpoints",required:!0,valid_types:"KpointsData",info:"qpoint mesh"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The minimization cycle did not reach self-consistency."},{status:462,message:"The code failed during the cholesky factorization."}]},class:"aiida_quantumespresso.calculations.ph:PhCalculation"},"quantumespresso.pp":{description:["`CalcJob` implementation for the pp.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Use a node that specifies the input parameters for the namelists"},{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"Output folder of a completed `PwCalculation`"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job is performed."}],outputs:[{name:"output_data",required:!0,valid_types:"ArrayData",info:""},{name:"output_data_multiple",required:!0,valid_types:"ArrayData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The parent folder did not contain the required XML output file."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete."},{status:330,message:"The formatted data output file `{filename}` was not present in the retrieved (temporary) folder."},{status:331,message:"The formatted data output file `{filename}` could not be read."},{status:332,message:"The data file format is not supported by the parser"},{status:333,message:"The formatted data output file `{filename}` could not be parsed: {exception}"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pp:PpCalculation"},"quantumespresso.projwfc":{description:["`CalcJob` implementation for the projwfc.x code of Quantum ESPRESSO.","","    Projwfc.x code of the Quantum ESPRESSO distribution, handles the the computation of projections of bloch","    wavefunctions onto atomic orbitals.","","    <Psi(n,k) | Y(theta,phi)R(r) >. For more information, refer to http://www.quantum-espresso.org/"],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a pw.x calculation"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"Dos",required:!0,valid_types:"XyData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:""},{name:"bands_down",required:!1,valid_types:"BandsData",info:""},{name:"bands_up",required:!1,valid_types:"BandsData",info:""},{name:"projections",required:!1,valid_types:"ProjectionData",info:""},{name:"projections_down",required:!1,valid_types:"ProjectionData",info:""},{name:"projections_up",required:!1,valid_types:"ProjectionData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:330,message:"The pdos_tot file could not be read from the retrieved folder."},{status:340,message:"An exception was raised parsing bands and projections."}]},class:"aiida_quantumespresso.calculations.projwfc:ProjwfcCalculation"},"quantumespresso.pw":{description:["`CalcJob` implementation for the pw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"kpoint mesh or kpoint path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"hubbard_file",required:!1,valid_types:"SinglefileData, NoneType",info:"SinglefileData node containing the output Hubbard parameters from a HpCalculation"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
npool  : The number of 'pools', each taking care of a group of k-points.
nband  : The number of 'band groups', each taking care of a group of Kohn-Sham orbitals.
ntg    : The number of 'task groups' across which the FFT planes are distributed.
ndiag  : The number of 'linear algebra groups' used when parallelizing the subspace diagonalization / iterative orthonormalization. By default, no parameter is passed to Quantum ESPRESSO, meaning it will use its default.`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:304,message:"The retrieved folder contained multiple XML files."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:360,message:"The code failed in finding a valid reciprocal lattice vector."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:461,message:"The code failed with negative dexx in the exchange calculation."},{status:462,message:"The code failed during the cholesky factorization."},{status:463,message:"Too many bands failed to converge during the diagonalization."},{status:464,message:"The S matrix was found to be not positive definite."},{status:465,message:"The `zhegvd` failed in the PPCG diagonalization."},{status:466,message:"The `[Q, R] = qr(X, 0)` failed in the PPCG diagonalization."},{status:467,message:"The eigenvector failed to converge."},{status:468,message:"The factorization in the Broyden routine failed."},{status:481,message:'The k-point parallelization "npools" is too high, some nodes have no k-points.'},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:502,message:"The ionic minimization cycle did not converge after the maximum number of steps."},{status:503,message:"The ionic minimization cycle did not finish because the calculation was interrupted but a partial trajectory and output structure was successfully parsed which can be used for a restart."},{status:510,message:"The electronic minimization cycle failed during an ionic minimization cycle."},{status:511,message:"The ionic minimization cycle converged, but electronic convergence was not reached in the final SCF."},{status:520,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm."},{status:521,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm and electronic convergence failed in the final SCF."},{status:531,message:"The electronic minimization cycle did not reach self-consistency."},{status:541,message:"The variable cell optimization broke the symmetry of the k-points."},{status:542,message:"The cell relaxation caused a significant volume contraction and there is not enough space allocated for radial FFT."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.calculations.pw:PwCalculation"},"quantumespresso.pw2gw":{description:["`CalcJob` implementation for the pw2gw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"Output folder of a completed `PwCalculation`"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"eps",required:!0,valid_types:"ArrayData",info:"The `eps` output node containing 5 arrays `energy`, `epsX`, `epsY`, `epsZ`, `epsTOT`"},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation.`"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:305,message:"The eps*.dat output files could not be read or parsed."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The eps*.dat output files do not have the expected shape (N, 2)."},{status:331,message:"The eps*.dat output files contains different values of energies."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pw2gw:Pw2gwCalculation"},"quantumespresso.pw2wannier90":{description:["`CalcJob` implementation for the pw2wannier.x code of Quantum ESPRESSO.","","    For more information, refer to http://www.quantum-espresso.org/ and http://www.wannier.org/"],spec:{inputs:[{name:"nnkp_file",required:!0,valid_types:"SinglefileData",info:"A SinglefileData containing the .nnkp file generated by wannier90.x -pp"},{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a pw.x calculation"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:340,message:"Encountered a generic error message"},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pw2wannier90:Pw2wannier90Calculation"},"quantumespresso.pwimmigrant":{description:["Create a PwCalculation object that can be used to import old jobs.","","    This is a sublass of aiida_quantumespresso.calculations.PwCalculation","    with slight modifications to some of the class variables and additional","    methods that","","        a. parse the job's input file to create the calculation's input","           nodes that would exist if the calculation were submitted using AiiDa,","        b. bypass the functions of the daemon, and prepare the node's attributes","           such that all the processes (copying of the files to the repository,","           results parsing, ect.) can be performed","","    .. note:: The keyword arguments of PwCalculation are also available.","","    :param remote_workdir: Absolute path to the directory where the job was run.","        The transport of the computer you link ask input to the calculation is","        the transport that will be used to retrieve the calculation's files.","        Therefore, ``remote_workdir`` should be the absolute path to the job's","        directory on that computer.","    :type remote_workdir: str","","    :param input_file_name: The file name of the job's input file.","    :type input_file_name: str","","    :param output_file_name: The file name of the job's output file (i.e. the","        file containing the stdout of QE).","    :type output_file_name: str"],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"kpoint mesh or kpoint path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"hubbard_file",required:!1,valid_types:"SinglefileData, NoneType",info:"SinglefileData node containing the output Hubbard parameters from a HpCalculation"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
npool  : The number of 'pools', each taking care of a group of k-points.
nband  : The number of 'band groups', each taking care of a group of Kohn-Sham orbitals.
ntg    : The number of 'task groups' across which the FFT planes are distributed.
ndiag  : The number of 'linear algebra groups' used when parallelizing the subspace diagonalization / iterative orthonormalization. By default, no parameter is passed to Quantum ESPRESSO, meaning it will use its default.`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:304,message:"The retrieved folder contained multiple XML files."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:360,message:"The code failed in finding a valid reciprocal lattice vector."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:461,message:"The code failed with negative dexx in the exchange calculation."},{status:462,message:"The code failed during the cholesky factorization."},{status:463,message:"Too many bands failed to converge during the diagonalization."},{status:464,message:"The S matrix was found to be not positive definite."},{status:465,message:"The `zhegvd` failed in the PPCG diagonalization."},{status:466,message:"The `[Q, R] = qr(X, 0)` failed in the PPCG diagonalization."},{status:467,message:"The eigenvector failed to converge."},{status:468,message:"The factorization in the Broyden routine failed."},{status:481,message:'The k-point parallelization "npools" is too high, some nodes have no k-points.'},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:502,message:"The ionic minimization cycle did not converge after the maximum number of steps."},{status:503,message:"The ionic minimization cycle did not finish because the calculation was interrupted but a partial trajectory and output structure was successfully parsed which can be used for a restart."},{status:510,message:"The electronic minimization cycle failed during an ionic minimization cycle."},{status:511,message:"The ionic minimization cycle converged, but electronic convergence was not reached in the final SCF."},{status:520,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm."},{status:521,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm and electronic convergence failed in the final SCF."},{status:531,message:"The electronic minimization cycle did not reach self-consistency."},{status:541,message:"The variable cell optimization broke the symmetry of the k-points."},{status:542,message:"The cell relaxation caused a significant volume contraction and there is not enough space allocated for radial FFT."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.calculations.pwimmigrant:PwimmigrantCalculation"},"quantumespresso.q2r":{description:["`CalcJob` implementation for the q2r.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The force constants file could not be read."}]},class:"aiida_quantumespresso.calculations.q2r:Q2rCalculation"},"quantumespresso.seekpath_structure_analysis":{description:["Primitivize the structure with SeeKpath and generate the high symmetry k-point path through its Brillouin zone.","","    This calcfunction will take a structure and pass it through SeeKpath to get the normalized primitive cell and the","    path of high symmetry k-points through its Brillouin zone. Note that the returned primitive cell may differ from the","    original structure in which case the k-points are only congruent with the primitive cell.","","    The keyword arguments can be used to specify various Seekpath parameters, such as:","","        with_time_reversal: True","        reference_distance: 0.025","        recipe: 'hpkot'","        threshold: 1e-07","        symprec: 1e-05","        angle_tolerance: -1.0","","    Note that exact parameters that are available and their defaults will depend on your Seekpath version."],spec:{inputs:[{name:"structure",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.seekpath_structure_analysis:seekpath_structure_analysis"},"quantumespresso.xspectra":{description:["CalcJob implementation for the xspectra.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"core_wfc_data",required:!0,valid_types:"SinglefileData",info:"Core wavefunction data, generated by the upf2plotcore.sh utility"},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The K-point sampling to be used for the XSpectra calculation"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"gamma_file",required:!1,valid_types:"SinglefileData, NoneType",info:"An optional file containing the data for the broadening function used when `gamma_mode=file`"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"spectra",required:!0,valid_types:"XyData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:313,message:"xiabs was set incorrectly, check and ensure that the index value correctly refers to the atomic species containing the core-hole (where the index starts from 1)."},{status:314,message:"xiabs was either set to 0 or less, or was greater than ntyp."},{status:330,message:"The xspectra output file could not be read from the retrieved folder."},{status:331,message:"The spectrum data file could not be read using NumPy genfromtxt"},{status:400,message:"The time limit set for the calculation was exceeded, and the job wrote a save file before exiting."}]},class:"aiida_quantumespresso.calculations.xspectra:XspectraCalculation"}},"aiida.data":{"quantumespresso.force_constants":"aiida_quantumespresso.data.force_constants:ForceConstantsData","quantumespresso.hubbard_structure":"aiida_quantumespresso.data.hubbard_structure:HubbardStructureData"},"aiida.parsers":{"quantumespresso.cp":"aiida_quantumespresso.parsers.cp:CpParser","quantumespresso.dos":"aiida_quantumespresso.parsers.dos:DosParser","quantumespresso.matdyn":"aiida_quantumespresso.parsers.matdyn:MatdynParser","quantumespresso.neb":"aiida_quantumespresso.parsers.neb:NebParser","quantumespresso.open_grid":"aiida_quantumespresso.parsers.open_grid:OpenGridParser","quantumespresso.ph":"aiida_quantumespresso.parsers.ph:PhParser","quantumespresso.pp":"aiida_quantumespresso.parsers.pp:PpParser","quantumespresso.projwfc":"aiida_quantumespresso.parsers.projwfc:ProjwfcParser","quantumespresso.pw":"aiida_quantumespresso.parsers.pw:PwParser","quantumespresso.pw2gw":"aiida_quantumespresso.parsers.pw2gw:Pw2gwParser","quantumespresso.pw2wannier90":"aiida_quantumespresso.parsers.pw2wannier90:Pw2wannier90Parser","quantumespresso.q2r":"aiida_quantumespresso.parsers.q2r:Q2rParser","quantumespresso.xspectra":"aiida_quantumespresso.parsers.xspectra:XspectraParser"},"aiida.tools.calculations":{"quantumespresso.pw":"aiida_quantumespresso.tools.calculations.pw:PwCalculationTools"},"aiida.tools.data.orbitals":{noncollinearhydrogen:"aiida_quantumespresso.tools.data.orbital.noncollinearhydrogen:NoncollinearHydrogenOrbital",spinorbithydrogen:"aiida_quantumespresso.tools.data.orbital.spinorbithydrogen:SpinorbitHydrogenOrbital"},"aiida.workflows":{"quantumespresso.matdyn.base":{description:["Workchain to run a Quantum ESPRESSO matdyn.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"matdyn",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_phonon_bands",required:!0,valid_types:"BandsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.matdyn.base:MatdynBaseWorkChain"},"quantumespresso.pdos":{description:["A WorkChain to compute Total & Partial Density of States of a structure, using Quantum Espresso."],spec:{inputs:[{name:"dos",required:!0,valid_types:"Data",info:"Input parameters for the `dos.x` calculation. Note that the `Emin`, `Emax` and `DeltaE` values have to match with those in the `projwfc` inputs."},{name:"nscf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` of the `nscf` calculation."},{name:"projwfc",required:!0,valid_types:"Data",info:"Input parameters for the `projwfc.x` calculation. Note that the `Emin`, `Emax` and `DeltaE` values have to match with those in the `dos` inputs."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"align_to_fermi",required:!1,valid_types:"Bool",info:"If true, Emin=>Emin-Efermi & Emax=>Emax-Efermi, where Efermi is taken from the `nscf` calculation. Note that it only makes sense to align `Emax` and `Emin` to the fermi level in case they are actually provided by in the `dos` and `projwfc` inputs, since otherwise the "},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If ``True``, work directories of all called calculation will be cleaned at the end of execution."},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` of the `scf` calculation."},{name:"serial_clean",required:!1,valid_types:"Bool, NoneType",info:"If ``True``, calculations will be run in serial, and work directories will be cleaned before the next step."}],outputs:[{name:"dos",required:!0,valid_types:"",info:""},{name:"nscf",required:!0,valid_types:"",info:""},{name:"projwfc",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified for base or nscf namespaces."},{status:401,message:"the SCF sub process failed"},{status:402,message:"the NSCF sub process failed"},{status:403,message:"the DOS sub process failed"},{status:404,message:"the PROJWFC sub process failed"},{status:404,message:"both the DOS and PROJWFC sub process failed"}]},class:"aiida_quantumespresso.workflows.pdos:PdosWorkChain"},"quantumespresso.ph.base":{description:["Workchain to run a Quantum ESPRESSO ph.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"ph",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"only_initialization",required:!1,valid_types:"Bool",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:401,message:"The work chain failed to merge the q-points data from multiple `PhCalculation`s because not all q-points were parsed."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.ph.base:PhBaseWorkChain"},"quantumespresso.pw.bands":{description:["Workchain to compute a band structure for a given structure using Quantum ESPRESSO pw.x.","","    The logic for the computation of various parameters for the BANDS step is as follows:","","    Number of bands:","        One can specify the number of bands to be used in the BANDS step either directly through the input parameters","        `bands.pw.parameters.SYSTEM.nbnd` or through `nbands_factor`. Note that specifying both is not allowed. When","        neither is specified nothing will be set by the work chain and the default of Quantum ESPRESSO will end up being","        used. If the `nbands_factor` is specified the maximum value of the following values will be used:","","        * `nbnd` of the preceding SCF calculation","        * 0.5 * nelectrons * nbands_factor","        * 0.5 * nelectrons + 4","","    Kpoints:","        There are three options; specify either an existing `KpointsData` through `bands_kpoints`, or specify the","        `bands_kpoint_distance`, or specify neither. For the former those exact kpoints will be used for the BANDS step.","        In the two other cases, the structure will first be normalized using SeekPath and the path along high-symmetry","        k-points will be generated on that structure. The distance between kpoints for the path will be equal to that","        of `bands_kpoints_distance` or the SeekPath default if not specified."],spec:{inputs:[{name:"bands",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the BANDS calculation."},{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the SCF calculation."},{name:"structure",required:!0,valid_types:"StructureData",info:"The inputs structure."},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Explicit kpoints to use for the BANDS calculation. Specify either this or `bands_kpoints_distance`."},{name:"bands_kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"Minimum kpoints distance for the BANDS calculation. Specify either this or `bands_kpoints`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"nbands_factor",required:!1,valid_types:"Float, NoneType",info:"The number of bands for the BANDS calculation is that used for the SCF multiplied by this factor."},{name:"relax",required:!1,valid_types:"Data",info:"Inputs for the `PwRelaxWorkChain`, if not specified at all, the relaxation step is skipped."}],outputs:[{name:"band_parameters",required:!0,valid_types:"Dict",info:"The output parameters of the BANDS `PwBaseWorkChain`."},{name:"band_structure",required:!0,valid_types:"BandsData",info:"The computed band structure."},{name:"scf_parameters",required:!0,valid_types:"Dict",info:"The output parameters of the SCF `PwBaseWorkChain`."},{name:"primitive_structure",required:!1,valid_types:"StructureData",info:"The normalized and primitivized structure for which the bands are computed."},{name:"seekpath_parameters",required:!1,valid_types:"Dict",info:"The parameters used in the SeeKpath call to normalize the input or relaxed structure."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Cannot specify both `nbands_factor` and `bands.pw.parameters.SYSTEM.nbnd`."},{status:202,message:"Cannot specify both `bands_kpoints` and `bands_kpoints_distance`."},{status:401,message:"The PwRelaxWorkChain sub process failed"},{status:402,message:"The scf PwBasexWorkChain sub process failed"},{status:403,message:"The bands PwBasexWorkChain sub process failed"}]},class:"aiida_quantumespresso.workflows.pw.bands:PwBandsWorkChain"},"quantumespresso.pw.base":{description:["Workchain to run a Quantum ESPRESSO pw.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"pw",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"An explicit k-points list or mesh. Either this or `kpoints_distance` has to be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by a calculation function based on the input structure."},{name:"kpoints_force_parity",required:!1,valid_types:"Bool, NoneType",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"The explicit `pseudos` or `pseudo_family` could not be used to get the necessary pseudos."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:203,message:"Neither the `options` nor `automatic_parallelization` input was specified. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:210,message:"Required key for `automatic_parallelization` was not specified.This exit status has been deprecated as the automatic parallellization feature was removed."},{status:211,message:"Unrecognized keys were specified for `automatic_parallelization`.This exit status has been deprecated as the automatic parallellization feature was removed."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed with a known unrecoverable error."},{status:320,message:"The initialization calculation failed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.workflows.pw.base:PwBaseWorkChain"},"quantumespresso.pw.relax":{description:["Workchain to relax a structure using Quantum ESPRESSO pw.x."],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the main relax loop."},{name:"structure",required:!0,valid_types:"StructureData",info:"The inputs structure."},{name:"base_final_scf",required:!1,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the final scf."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"max_meta_convergence_iterations",required:!1,valid_types:"Int",info:"The maximum number of variable cell relax iterations in the meta convergence cycle."},{name:"meta_convergence",required:!1,valid_types:"Bool",info:"If `True` the workchain will perform a meta-convergence on the cell volume."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"volume_convergence",required:!1,valid_types:"Float",info:"The volume difference threshold between two consecutive meta convergence iterations."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The successfully relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"the relax PwBaseWorkChain sub process failed"},{status:402,message:"the final scf PwBaseWorkChain sub process failed"}]},class:"aiida_quantumespresso.workflows.pw.relax:PwRelaxWorkChain"},"quantumespresso.q2r.base":{description:["Workchain to run a Quantum ESPRESSO q2r.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"q2r",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.q2r.base:Q2rBaseWorkChain"},"quantumespresso.xps":{description:["Workchain to compute X-ray photoelectron spectra (XPS) for a given structure.","","    The WorkChain itself firstly calls the PwRelaxWorkChain to relax the input structure if","    required. Then determines the input settings for each XPS calculation automatically using","    ``get_xspectra_structures()``. The input structures are generated from the standardized","    structure by converting each to a supercell with cell dimensions of at least 8.0 angstrom","    in each periodic dimension in order to sufficiently reduce the unphysical interaction","    of the core-hole with neighbouring images. The size of the minimum size requirement can be","    overriden by the user if required. Then the standard Delta-Self-Consistent-Field (ΔSCF)","    method is used to get the XPS binding energy. Finally, the XPS spectrum is calculated","    using the Voigt profile."],spec:{inputs:[{name:"ch_scf",required:!0,valid_types:"Data",info:"Input parameters for the basic xps workflow (core-hole SCF)."},{name:"core_hole_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of excited-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"gipaw_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of ground-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation."},{name:"abs_atom_marker",required:!1,valid_types:"Str",info:"The name for the Kind representing the absorbing atom in the structure. Will be used in all structures generated in ``get_xspectra_structures`` step."},{name:"calc_binding_energy",required:!1,valid_types:"Bool",info:"If `True`, run scf calculation for the supercell."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculations will be cleaned at the end of execution."},{name:"core_hole_treatments",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set core-hole treatment to all elements present. The default full-core-hole treatment will be used if not specified."},{name:"correction_energies",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set the correction energy to all elements present. "},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"elements_list",required:!1,valid_types:"List, NoneType",info:"The list of elements to be considered for analysis, each must be valid elements of the periodic table."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"Data",info:"Input parameters for the relax process. If not specified at all, the relaxation step is skipped."},{name:"spglib_settings",required:!1,valid_types:"Dict, NoneType",info:"Optional settings dictionary for the spglib call within ``get_xspectra_structures``."},{name:"structure_preparation_settings",required:!1,valid_types:"Dict, Float, Int, Bool, Str",info:"Optional settings dictionary for the ``get_xspectra_structures()`` method."},{name:"voight_gamma",required:!1,valid_types:"Float",info:"The gamma parameter for the Lorenzian broadening in the Voight method."},{name:"voight_sigma",required:!1,valid_types:"Float",info:"The sigma parameter for the gaussian broadening in the Voight method."}],outputs:[{name:"binding_energies",required:!0,valid_types:"Dict",info:"All the binding energy values for each element calculated by the WorkChain."},{name:"chemical_shifts",required:!0,valid_types:"Dict",info:"All the chemical shift values for each element calculated by the WorkChain."},{name:"final_spectra_be",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element based on binding energy."},{name:"final_spectra_cls",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element based on chemical shift."},{name:"output_parameters_ch_scf",required:!0,valid_types:"Dict",info:"The output parameters of each ``PwBaseWorkChain`` performed``."},{name:"supercell_structure",required:!0,valid_types:"StructureData",info:"The supercell of ``outputs.standardized_structure`` used to generate structures for XPS sub-processes."},{name:"symmetry_analysis_data",required:!0,valid_types:"Dict",info:"The output parameters from ``get_xspectra_structures()``."},{name:"optimized_structure",required:!1,valid_types:"StructureData",info:"The optimized structure from the ``relax`` process."},{name:"output_parameters_relax",required:!1,valid_types:"Dict",info:"The output_parameters of the relax step."},{name:"output_parameters_scf",required:!1,valid_types:"Dict",info:"The output_parameters of the scf step."},{name:"standardized_structure",required:!1,valid_types:"StructureData",info:"The standardized crystal structure used to generate structures for XPS sub-processes."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The Relax sub process failed"},{status:402,message:"The SCF Pw sub processes failed"},{status:402,message:"One or more CH_SCF Pw sub processes failed"}]},class:"aiida_quantumespresso.workflows.xps:XpsWorkChain"},"quantumespresso.xspectra.base":{description:["Workchain to run a Quantum ESPRESSO xspectra.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"xspectra",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"An explicit k-points mesh. Either this or `kpoints_distance` has to be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by a calculation function based on the input structure."},{name:"kpoints_force_parity",required:!1,valid_types:"Bool, NoneType",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"spectra",required:!0,valid_types:"XyData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.xspectra.base:XspectraBaseWorkChain"},"quantumespresso.xspectra.core":{description:["Workchain to compute X-ray absorption spectra for a given structure using Quantum ESPRESSO.","","    The workflow follows the process required to compute the XAS of an input structure: an SCF calculation is performed","    using the provided structure, which is then followed by the calculation of the XAS itself by XSpectra. The","    calculations performed by the WorkChain in a typical run will be:","","    - PwSCF calculation with pw.x of the input structure with a core-hole present.","    - Generation of core-wavefunction data with upf2plotcore.sh (if requested).","    - XAS calculation with xspectra.x to compute the Lanczos coefficients and print the XANES spectra for the","      polarisation vectors requested in the input.","    - Collation of output data from pw.x and xspectra.x calculations, including a combination of XANES dipole spectra","      based on polarisation vectors to represent the powder spectrum of the structure (if requested).","","    If ``run_replot = True`` is set in the inputs (defaults to False), the WorkChain will run a second xspectra.x","    calculation which replots the spectra produced from the ``xs_prod`` step. This option can be very useful for","    obtaining a final spectrum at low levels of broadening (relative to the default of 0.5 eV), particularly as higher","    levels of broadening significantly speed up the convergence of the Lanczos procedure. Inputs for the replot","    calculation are found in the ``xs_plot`` namespace.","","    The core-wavefunction plot derived from the ground-state of the absorbing element can be provided as a top-level","    input or produced by the WorkChain. If left to the WorkChain, the ground-state pseudopotential assigned to the","    absorbing element will be used to generate this data using the upf2plotcore.sh utility script (via the","    ``aiida-shell`` plugin).","","    In its current stage of development, the workflow requires the following:","","    - An input structure where the desired absorbing atom in the system is marked as a separate Kind. The default","      behaviour for the WorkChain is to set the Kind name as 'X', however this can be changed via the `overrides`","      dictionary.","    - A code node for ``upf2plotcore``, configured for the ``aiida-shell`` plugin","      (https://github.com/sphuber/aiida-shell). Alternatively, a ``SinglefileData`` node from a previous ``ShellJob``","      run can be supplied under ``inputs.core_wfc_data``.","    - A suitable pair of pseudopotentials for the element type of the absorbing atom, one for the ground-state occupancy","      which contains GIPAW informtation for the core level of interest for the XAS (e.g. 1s in the case of a K-edge","      calculation) and the other containing a core hole. (For the moment this can be passed either via the","      ``core_hole_pseudos`` field in ``get_builder_from_protocol`` or via the overrides, but will be changed later once","      full families of core-hole pseudopotentials become available)."],spec:{inputs:[{name:"eps_vectors",required:!0,valid_types:"List",info:"The list of 3-vectors to use in XSpectra sub-processes. The number of sub-lists will subsequently define the number of XSpectra calculations to perform"},{name:"scf",required:!0,valid_types:"Data",info:"Input parameters for the `pw.x` calculation."},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation, with at least one site containing the `abs_atom_marker` as the kind label."},{name:"xs_prod",required:!0,valid_types:"Data",info:"Input parameters for the `xspectra.x` calculation to compute the Lanczos."},{name:"abs_atom_marker",required:!1,valid_types:"Str, NoneType",info:"The name for the Kind representing the absorbing atom in the structure. Must corespond to a Kind within the StructureData node supplied to the calculation."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"core_wfc_data",required:!1,valid_types:"SinglefileData, NoneType",info:"The core wavefunction data file extracted from the ground-state pseudo for the absorbing atom."},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"get_powder_spectrum",required:!1,valid_types:"Bool",info:"If `True`, the WorkChain will combine XANES dipole spectra computed using the XAS basis vectors defined according to the `get_powder_spectrum` CalcFunction."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"run_replot",required:!1,valid_types:"Bool",info:""},{name:"upf2plotcore_code",required:!1,valid_types:"Code, NoneType",info:"The code node required for upf2plotcore.sh configured for ``aiida-shell``. Must be provided if `core_wfc_data` is not provided."},{name:"xs_plot",required:!1,valid_types:"Data",info:"Input parameters for the re-plot `xspectra.x` calculation of the Lanczos."}],outputs:[{name:"parameters_scf",required:!0,valid_types:"Dict",info:"The output parameters of the SCF `PwBaseWorkChain`."},{name:"parameters_xspectra",required:!0,valid_types:"Dict",info:"The output dictionaries of each `XspectraBaseWorkChain` performed"},{name:"spectra",required:!0,valid_types:"XyData",info:"An XyData node containing all the final spectra produced by the WorkChain."},{name:"powder_spectrum",required:!1,valid_types:"XyData",info:"The simulated powder spectrum"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The SCF sub process failed"},{status:402,message:"One or more XSpectra sub processes failed"},{status:403,message:"The pseudo for the absorbing element contains no GIPAW information."}]},class:"aiida_quantumespresso.workflows.xspectra.core:XspectraCoreWorkChain"},"quantumespresso.xspectra.crystal":{description:["Workchain to compute all X-ray absorption spectra for a given structure using Quantum ESPRESSO.","","    The WorkChain follows the process required to compute all the K-edge XAS spectra for each","    element in a given structure. The WorkChain itself firstly calls the PwRelaxWorkChain to","    relax the input structure, then determines the input settings for each XAS","    calculation automatically using ``get_xspectra_structures()``:","","        - Firstly the input structure is converted to its conventional standard cell using","          ``spglib`` and detects the space group number for the conventional cell.","        - Symmetry analysis of the standardized structure using ``spglib`` is then used to","          determine the number of non-equivalent atomic sites in the structure for each","          element considered for analysis.","","    Using the symmetry data returned from ``get_xspectra_structures``, input structures for","    the XspectraCoreWorkChain are generated from the standardized structure by converting each","    to a supercell with cell dimensions of at least 8.0 angstroms in each periodic dimension -","    required in order to sufficiently reduce the unphysical interaction of the core-hole with","    neighbouring images. The size of the minimum size requirement can be overriden by the","    user if required. The WorkChain then uses the space group number to set the list of","    polarisation vectors for the ``XspectraCoreWorkChain`` to compute for all subsequent","    calculations."],spec:{inputs:[{name:"core",required:!0,valid_types:"Data",info:"Input parameters for the basic xspectra workflow (core-hole SCF + XAS."},{name:"core_hole_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of excited-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"elements_list",required:!0,valid_types:"List",info:"The list of elements to be considered for analysis, each must be a valid element of the periodic table."},{name:"gipaw_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of ground-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}.'},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation."},{name:"abs_atom_marker",required:!1,valid_types:"Str",info:"The name for the Kind representing the absorbing atom in the structure. Will be used in all structures generated in ``get_xspectra_structures`` step."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculations will be cleaned at the end of execution."},{name:"core_hole_treatments",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set core-hole treatment to given elements present. The default full-core-hole treatment will be used if not specified."},{name:"core_wfc_data",required:!1,valid_types:"SinglefileData",info:"Input namespace to provide core wavefunction inputs for each element. Must follow the format: ``core_wfc_data__{symbol} = {node}``"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"Data",info:"Input parameters for the relax process. If not specified at all, the relaxation step is skipped."},{name:"return_all_powder_spectra",required:!1,valid_types:"Bool",info:"If ``True``, the WorkChain will return all ``powder_spectrum`` nodes from each ``XspectraCoreWorkChain`` sub-process."},{name:"spglib_settings",required:!1,valid_types:"Dict, NoneType",info:"Optional settings dictionary for the spglib call within ``get_xspectra_structures``."},{name:"structure_preparation_settings",required:!1,valid_types:"Dict, Float, Int, Bool, Str",info:"Optional settings dictionary for the ``get_xspectra_structures()`` method."},{name:"upf2plotcore_code",required:!1,valid_types:"Code, NoneType",info:"Code node for the upf2plotcore.sh ShellJob code."}],outputs:[{name:"final_spectra",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element"},{name:"supercell_structure",required:!0,valid_types:"StructureData",info:"The supercell of ``outputs.standardized_structure`` used to generate structures for XSpectra sub-processes."},{name:"symmetry_analysis_data",required:!0,valid_types:"Dict",info:"The output parameters from ``get_xspectra_structures()``."},{name:"optimized_structure",required:!1,valid_types:"StructureData",info:"The optimized structure from the ``relax`` process."},{name:"parameters_relax",required:!1,valid_types:"Dict",info:"The output_parameters of the relax step."},{name:"parameters_scf",required:!1,valid_types:"Dict",info:"The output parameters of each ``PwBaseWorkChain`` performed in each ``XspectraCoreWorkChain``."},{name:"parameters_xspectra",required:!1,valid_types:"Dict",info:"The output dictionaries of each `XspectraCalculation` performed"},{name:"powder_spectra",required:!1,valid_types:"XyData",info:"All the spectra generated by the WorkChain."},{name:"standardized_structure",required:!1,valid_types:"StructureData",info:"The standardized crystal structure used to generate structures for XSpectra sub-processes."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The Relax sub process failed"},{status:402,message:"One or more XSpectra workflows failed"},{status:403,message:"The pseudos for one or more absorbing elements contain no GIPAW information."}]},class:"aiida_quantumespresso.workflows.xspectra.crystal:XspectraCrystalWorkChain"}},console_scripts:{"aiida-quantumespresso":"aiida_quantumespresso.cli:cmd_root"}},commits_count:93,development_status:"stable",warnings:["Entry point 'noncollinearhydrogen' does not start with prefix 'quantumespresso.'","Entry point 'spinorbithydrogen' does not start with prefix 'quantumespresso.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:20},{colorclass:"brown",text:"Parsers",count:13},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:11},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Tools calculations, Tools data orbitals)",count:3}],pip_install_cmd:"pip install aiida-quantumespresso",is_installable:"True"},"aiida-quantumespresso-hp":{code_home:"https://github.com/sphuber/aiida-quantumespresso-hp",entry_point_prefix:"quantumespresso.hp",pip_url:"git+https://github.com/sphuber/aiida-quantumespresso-hp",name:"aiida-quantumespresso-hp",package_name:"aiida_quantumespresso_hp",hosted_on:"github.com",metadata:{author:"Sebastiaan P. Huber",author_email:"mail@sphuber.net",version:"0.1.0",description:"The AiiDA plugin for the Hubbard module of Quantum ESPRESSO",classifiers:["License :: OSI Approved :: MIT License","Programming Language :: Python :: 2.7","Development Status :: 4 - Beta"]},aiida_version:">=1.0.0b6,<2.0",entry_points:{"aiida.calculations":{"quantumespresso.hp":"aiida_quantumespresso_hp.calculations.hp:HpCalculation"},"aiida.parsers":{"quantumespresso.hp":"aiida_quantumespresso_hp.parsers.hp:HpParser"},"aiida.workflows":{"quantumespresso.hp.main":"aiida_quantumespresso_hp.workflows.hp.main:HpWorkChain","quantumespresso.hp.parallelize_atoms":"aiida_quantumespresso_hp.workflows.hp.parallelize_atoms:HpParallelizeAtomsWorkChain","quantumespresso.hp.base":"aiida_quantumespresso_hp.workflows.hp.base:HpBaseWorkChain","quantumespresso.hp.hubbard":"aiida_quantumespresso_hp.workflows.hubbard:SelfConsistentHubbardWorkChain"},console_scripts:{launch_calculation_hp:"aiida_quantumespresso_hp.cli.calculations.hp:launch",launch_workflow_hp_base:"aiida_quantumespresso_hp.cli.workflows.hp.base:launch",launch_workflow_hp_main:"aiida_quantumespresso_hp.cli.workflows.hp.main:launch",launch_workflow_hp_hubbard:"aiida_quantumespresso_hp.cli.workflows.hubbard:launch"}},commits_count:0,development_status:"beta",warnings:["Missing classifier 'Framework :: AiiDA'","Prefix 'quantumespresso.hp' does not follow naming convention."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:4},{colorclass:"purple",text:"Console scripts",count:4}],pip_install_cmd:"pip install git+https://github.com/sphuber/aiida-quantumespresso-hp",is_installable:"True"},"aiida-raspa":{code_home:"https://github.com/yakutovicha/aiida-raspa",entry_point_prefix:"raspa",pip_url:"aiida-raspa",plugin_info:"https://raw.github.com/yakutovicha/aiida-raspa/master/setup.json",name:"aiida-raspa",package_name:"aiida_raspa",hosted_on:"github.com",metadata:{release_date:"2023-08-26",description:"AiiDA plugin for RASPA code",author_email:"Aliaksandr Yakutovich <aliaksandr.yakutovich@epfl.ch>, Miriam Pougin <miriam.pougin@epfl.ch>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{raspa:{description:["This is a RaspaCalculation, subclass of CalcJob, to prepare input for RASPA code.","    For information on RASPA, refer to: https://github.com/iraspa/raspa2."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"block_pocket",required:!1,valid_types:"SinglefileData",info:"Zeo++ block pocket file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"file",required:!1,valid_types:"SinglefileData",info:"Additional input file(s)"},{name:"framework",required:!1,valid_types:"CifData",info:"Input framework(s)"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote folder used to continue the same simulation stating from the binary restarts."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieved_parent_folder",required:!1,valid_types:"FolderData, NoneType",info:"To use an old calculation as a starting poing for a new one."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional input parameters"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The results of a calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"warnings",required:!1,valid_types:"List",info:"Warnings that appeared during the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"The retrieved folder does not contain an output file."},{status:102,message:'The output does not contain "Starting simulation".'},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:500,message:"The calculation could not be completed due to the lack of time."}]},class:"aiida_raspa.calculations:RaspaCalculation"}},"aiida.parsers":{raspa:"aiida_raspa.parsers:RaspaParser"},"aiida.workflows":{"raspa.base":{description:["Workchain to run a RASPA calculation with automated error handling and restarts."],spec:{inputs:[{name:"raspa",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The results of a calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"warnings",required:!1,valid_types:"List",info:"Warnings that appeared during the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_raspa.workchains:RaspaBaseWorkChain"}}},commits_count:3,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-raspa",is_installable:"True"},"aiida-shell":{code_home:"https://github.com/sphuber/aiida-shell",entry_point_prefix:"core",pip_url:"aiida-shell",plugin_info:"https://raw.github.com/sphuber/aiida-shell/master/pyproject.toml",name:"aiida-shell",package_name:"aiida_shell",hosted_on:"github.com",metadata:{release_date:"2023-06-14",description:"AiiDA plugin that makes running shell commands easy.",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>',classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"0.5.3"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.calculations":{"core.shell":{description:["Implementation of :class:`aiida.engine.CalcJob` to run a simple shell command."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"arguments",required:!1,valid_types:"List, NoneType",info:""},{name:"filenames",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"nodes",required:!1,valid_types:"Data",info:""},{name:"outputs",required:!1,valid_types:"List, NoneType",info:""},{name:"parser",required:!1,valid_types:"PickledData, NoneType",info:""},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Exit status could not be determined: exit status file was not retrieved."},{status:301,message:"Exit status could not be determined: exit status file does not contain a valid integer."},{status:302,message:"The stdout file was not retrieved."},{status:303,message:"One or more output files defined in the `outputs` input were not retrieved: {missing_filepaths}."},{status:310,message:"Callable specified in the `parser` input excepted: {exception}."},{status:400,message:"The command exited with a non-zero status: {status} {stderr}."},{status:410,message:"The command exited with a zero status but the stderr was not empty."}]},class:"aiida_shell.calculations.shell:ShellJob"}},"aiida.data":{"core.code.installed.shell":"aiida_shell.data.code:ShellCode","core.pickled":"aiida_shell.data.pickled:PickledData"},"aiida.parsers":{"core.shell":"aiida_shell.parsers.shell:ShellParser"}},commits_count:46,development_status:"alpha",warnings:["Prefix 'core' does not follow naming convention."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2}],pip_install_cmd:"pip install aiida-shell",is_installable:"True"},"aiida-siesta":{code_home:"https://github.com/siesta-project/aiida_siesta_plugin/tree/master",documentation_url:"https://aiida-siesta-plugin.readthedocs.io/",entry_point_prefix:"siesta",pip_url:"aiida-siesta",name:"aiida-siesta",package_name:"aiida_siesta",hosted_on:"github.com",metadata:{release_date:"2022-07-17",description:"A plugin for Siesta's basic functionality within the AiiDA framework.",author_email:'Albero Garcia <albertog@icmab.es>, "Victor M. Garcia-Suarez" <garciavictor@uniovi.es>, Emanuele Bosoni <ebosoni@icmab.es>, Vladimir Dikan <vdikan@icmab.es>, Pol Febrer <pol.febrer@icn2.cat>',classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{},commits_count:8,development_status:"stable",warnings:["No bdist_wheel available for PyPI release","  > WARNING! Unable to retrieve plugin info from: https://raw.github.com/siesta-project/aiida_siesta_plugin/master/setup.json"],summaryinfo:[],pip_install_cmd:"pip install aiida-siesta",is_installable:"True"},"aiida-spex":{code_home:"https://github.com/JuDFTteam/aiida-spex",entry_point_prefix:"spex",pip_url:"git+https://github.com/JuDFTteam/aiida-spex",name:"aiida-spex",package_name:"aiida_spex",hosted_on:"github.com",metadata:{author:"The SPEX Team",author_email:"a.chandran@fz-juelich.de",version:"1.1.2",description:"AiiDA plugin for SPEX code",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.0.0b3,<3.0.0",entry_points:{"aiida.calculations":{"spex.spex":"aiida_spex.calculations.spex:SpexCalculation"},"aiida.data":{"spex.spexinp":"aiida_spex.data.spexinp:SpexinpData"},"aiida.parsers":{"spex.spexparser":"aiida_spex.parsers.spex:SpexParser"},"aiida.workflows":{"spex.job":"aiida_spex.workflows.job:SpexJobWorkchain"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/JuDFTteam/aiida-spex"},"aiida-spirit":{code_home:"https://github.com/JuDFTteam/aiida-spirit/tree/main",documentation_url:"https://aiida-spirit.readthedocs.io/",entry_point_prefix:"spirit",name:"aiida-spirit",pip_url:"aiida-spirit",package_name:"aiida_spirit",hosted_on:"github.com",metadata:{release_date:"2023-06-23",description:"AiiDA plugin for the spirit code",author:"The JuDFT Team",author_email:"p.ruessmann@fz-juelich.de",license:"MIT",home_page:"https://github.com/JuDFTteam/aiida-spirit",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.2"},aiida_version:null,entry_points:{"aiida.calculations":{spirit:"aiida_spirit.calculations:SpiritCalculation"},"aiida.parsers":{spirit:"aiida_spirit.parsers:SpiritParser"}},commits_count:9,development_status:"planning",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-spirit"},"aiida-ssh2win":{entry_point_prefix:"ssh2win",code_home:"https://github.com/edan-bainglass/aiida-ssh2win",version_file:"https://raw.githubusercontent.com/edan-bainglass/aiida-ssh2win/develop/aiida_ssh2win/__init__.py",pip_url:"git+https://github.com/edan-bainglass/aiida-ssh2win",name:"aiida-ssh2win",package_name:"aiida_ssh2win",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:13,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/edan-bainglass/aiida-ssh2win"},"aiida-sshonly":{code_home:"https://github.com/adegomme/aiida-sshonly",development_status:"beta",entry_point_prefix:"sshonly",pip_url:"aiida-sshonly",plugin_info:"https://raw.github.com/adegomme/aiida-sshonly/master/setup.json",name:"aiida-sshonly",package_name:"aiida_sshonly",hosted_on:"github.com",metadata:{release_date:"2020-10-07",description:"AiiDA plugin adding a sshonly transport option, using only SSH to transfer files, avoiding SFTP, in case it's blocked or non functional on a remote system",author:"adegomme",license:"MIT",home_page:"https://github.com/adegomme/aiida-sshonly",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0a3"},aiida_version:">=1.3.0,<2.0.0",entry_points:{"aiida.transports":{ssh_only:"aiida_sshonly.transports.sshonly:SshOnlyTransport"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'ssh_only' does not start with prefix 'sshonly.'"],summaryinfo:[{colorclass:"orange",text:"Other (Transports)",count:1}],pip_install_cmd:"pip install --pre aiida-sshonly",is_installable:"True"},"aiida-sssp-workflow":{entry_point_prefix:"sssp_workflow",code_home:"https://github.com/aiidateam/aiida-sssp-workflow",version_file:"https://github.com/aiidateam/aiida-sssp-workflow/blob/main/aiida_sssp_workflow/version.py",documentation_url:"https://github.com/aiidateam/aiida-sssp-workflow#readme",pip_url:"aiida-sssp-workflow",plugin_info:"https://github.com/aiidateam/aiida-sssp-workflow/blob/main/setup.cfg",name:"aiida-sssp-workflow",package_name:"aiida_sssp_workflow",hosted_on:"github.com",metadata:{release_date:"2023-09-20",description:"Package for the AiiDA SSSP workflow",author:"Jusong Yu",author_email:"jusong.yu@psi.ch",license:"MIT",home_page:"https://github.com/aiidateam/aiida-sssp-workflow",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3 :: Only","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"4.1.0"},aiida_version:">=2.4.0,<2.5.0",entry_points:{"aiida.calculations":{"sssp_workflow.birch_murnaghan_fit":{description:["doc"],spec:{inputs:[{name:"volume_energy",required:!0,valid_types:"Dict",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_sssp_workflow.calculations.birch_murnaghan_fit:birch_murnaghan_fit"}},"aiida.workflows":{"sssp_workflow.convergence.bands":{description:["WorkChain to converge test on cohisive energy of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.bands:ConvergenceBandsWorkChain"},"sssp_workflow.convergence.cohesive_energy":{description:["WorkChain to converge test on cohisive energy of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.cohesive_energy:ConvergenceCohesiveEnergyWorkChain"},"sssp_workflow.convergence.delta":{description:["WorkChain to converge test on delta factor of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.delta:ConvergenceDeltaWorkChain"},"sssp_workflow.convergence.phonon_frequencies":{description:["WorkChain to converge test on cohisive energy of input structure"],spec:{inputs:[{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"ph_code",required:!0,valid_types:"AbstractCode",info:"The `ph.x` code  use for the `PhCalculation`."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"pw_code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.phonon_frequencies:ConvergencePhononFrequenciesWorkChain"},"sssp_workflow.convergence.pressure":{description:["WorkChain to converge test on pressure of input structure"],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"criteria",required:!0,valid_types:"Str",info:"Criteria for convergence measurement to give recommend cutoff pair."},{name:"cutoff_control",required:!0,valid_types:"Str",info:"The cutoff control list to use for the workchain."},{name:"protocol",required:!0,valid_types:"Str",info:"The calculation protocol to use for the workchain."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configuration",required:!1,valid_types:"Str, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"preset_ecutwfc",required:!1,valid_types:"Int, NoneType",info:"Preset wavefunction cutoff will be used and skip wavefunction test."}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:"The output parameters of two stage convergence test."},{name:"output_parameters_rho_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all rho test calculations."},{name:"output_parameters_wfc_test",required:!1,valid_types:"Dict",info:"The output parameters include results of all wfc test calculations."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The reference calculation failed."},{status:402,message:"The sub process for `{label}` did not finish successfully."}]},class:"aiida_sssp_workflow.workflows.convergence.pressure:ConvergencePressureWorkChain"},"sssp_workflow.measure.bands":{description:["WorkChain to run bands measure,","    run without sym for distance compare and band structure along the path"],spec:{inputs:[{name:"charge_density_cutoff",required:!0,valid_types:"Float",info:"The charge density cutoff."},{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"options",required:!0,valid_types:"Dict",info:"Optional `options` to use for the `PwCalculations`."},{name:"parallelization",required:!0,valid_types:"Dict",info:"Parallelization options for the `PwCalculations`."},{name:"protocol",required:!0,valid_types:"Str",info:"The protocol which define input calculation parameters."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"wavefunction_cutoff",required:!0,valid_types:"Float",info:"The wavefunction cutoff."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configurations",required:!1,valid_types:"List, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands",required:!0,valid_types:"",info:""},{name:"ecutrho",required:!0,valid_types:"Int",info:""},{name:"ecutwfc",required:!0,valid_types:"Int",info:""},{name:"band_structure",required:!1,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_sssp_workflow.workflows.measure.bands:BandsMeasureWorkChain"},"sssp_workflow.measure.precision":{description:["Workchain to calculate delta factor of specific pseudopotential"],spec:{inputs:[{name:"charge_density_cutoff",required:!0,valid_types:"Float",info:"The charge density cutoff."},{name:"code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"options",required:!0,valid_types:"Dict",info:"Optional `options` to use for the `PwCalculations`."},{name:"parallelization",required:!0,valid_types:"Dict",info:"Parallelization options for the `PwCalculations`."},{name:"protocol",required:!0,valid_types:"Str",info:"The protocol which define input calculation parameters."},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"wavefunction_cutoff",required:!0,valid_types:"Float",info:"The wavefunction cutoff."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"configurations",required:!1,valid_types:"List, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"",info:"The summary output parameters of all delta measures to describe the precision of EOS compare  with the AE equation of state."},{name:"BCC",required:!1,valid_types:"",info:"Delta calculation result of BCC EOS."},{name:"Diamond",required:!1,valid_types:"",info:"Delta calculation result of Diamond EOS."},{name:"FCC",required:!1,valid_types:"",info:"Delta calculation result of FCC EOS."},{name:"GS",required:!1,valid_types:"",info:"Delta calculation result of GS EOS."},{name:"RE",required:!1,valid_types:"",info:"Delta calculation result of RE EOS."},{name:"SC",required:!1,valid_types:"",info:"Delta calculation result of SC EOS."},{name:"X2O",required:!1,valid_types:"",info:"Delta calculation result of X2O EOS."},{name:"X2O3",required:!1,valid_types:"",info:"Delta calculation result of X2O3 EOS."},{name:"X2O5",required:!1,valid_types:"",info:"Delta calculation result of X2O5 EOS."},{name:"XO",required:!1,valid_types:"",info:"Delta calculation result of XO EOS."},{name:"XO2",required:!1,valid_types:"",info:"Delta calculation result of XO2 EOS."},{name:"XO3",required:!1,valid_types:"",info:"Delta calculation result of XO3 EOS."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The metric workchain of configuration {confs} not finished ok."}]},class:"aiida_sssp_workflow.workflows.measure.precision:PrecisionMeasureWorkChain"},"sssp_workflow.verification":{description:["The verification workflow to run all test for the given pseudopotential"],spec:{inputs:[{name:"convergence",required:!0,valid_types:"Data",info:""},{name:"measure",required:!0,valid_types:"Data",info:""},{name:"pseudo",required:!0,valid_types:"UpfData",info:"Pseudopotential to be verified"},{name:"pw_code",required:!0,valid_types:"AbstractCode",info:"The `pw.x` code use for the `PwCalculation`."},{name:"charge_density_cutoff",required:!1,valid_types:"Float, NoneType",info:"The charge density cutoff for the Measure properties."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called non-cached calculations will be cleaned at the end of execution, and cached calculations will invalid from cache."},{name:"label",required:!1,valid_types:"Str, NoneType",info:"label store for display as extra attributes."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Optional `options`"},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:"Parallelization options"},{name:"ph_code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `ph.x` code use for the `PhCalculation`."},{name:"properties_list",required:!1,valid_types:"List",info:"The preperties will be calculated, passed as a list."},{name:"wavefunction_cutoff",required:!1,valid_types:"Float, NoneType",info:"The wavefunction cutoff for the Measure properties."}],outputs:[{name:"convergence",required:!0,valid_types:"",info:""},{name:"measure",required:!0,valid_types:"",info:""},{name:"pseudo_info",required:!0,valid_types:"Dict",info:"pseudopotential info"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The caching is triggered but failed."},{status:811,message:"The sub-workflows {processes} is not finished ok."}]},class:"aiida_sssp_workflow.workflows.verifications:VerificationWorkChain"}},console_scripts:{"aiida-sssp-workflow":"aiida_sssp_workflow.cli:cmd_root"}},commits_count:69,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"green",text:"Workflows",count:8},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-sssp-workflow",is_installable:"True"},"aiida-statefile-schedulers":{code_home:"https://github.com/dev-zero/aiida-statefile-schedulers",development_status:"beta",entry_point_prefix:"statefile_schedulers",pip_url:"aiida-statefile-schedulers",name:"aiida-statefile-schedulers",package_name:"aiida_statefile_schedulers",hosted_on:"github.com",metadata:{release_date:"2021-11-23",description:"Simple statefile-driven task schedulers for AiiDA",author:"Tiziano Müller",author_email:"tm@dev-zero.ch",license:"MIT",home_page:"https://github.com/dev-zero/aiida-statefile-schedulers",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.1"},aiida_version:null,entry_points:{"aiida.schedulers":{"statefile_schedulers.direct":"aiida_statefile_schedulers.schedulers.direct:StatefileDirectScheduler"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"orange",text:"Other (Schedulers)",count:1}],pip_install_cmd:"pip install aiida-statefile-schedulers",is_installable:"True"},"aiida-strain":{code_home:"https://github.com/greschd/aiida-strain",documentation_url:"https://aiida-strain.readthedocs.io",entry_point_prefix:"strain",pip_url:"aiida-strain",name:"aiida-strain",package_name:"aiida_strain",hosted_on:"github.com",metadata:{release_date:"2019-11-22",description:"AiiDA Plugin for applying strain to structures",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-strain.readthedocs.io",classifiers:["Development Status :: 3 - Alpha","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.workflows":{"strain.apply_strains":{description:["Workchain to create strained structures from a given input structure."],spec:{inputs:[{name:"strain_kind",required:!0,valid_types:"Str",info:""},{name:"strain_parameters",required:!0,valid_types:"Str",info:""},{name:"strain_strengths",required:!0,valid_types:"List",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_strain:ApplyStrains"},"strain.apply_strains_with_symmetry":{description:["Workchain to create strained structures from an input structure, and select the symmetries which are compatible with the strained structure from a set of given input symmetries."],spec:{inputs:[{name:"strain_kind",required:!0,valid_types:"Str",info:""},{name:"strain_parameters",required:!0,valid_types:"Str",info:""},{name:"strain_strengths",required:!0,valid_types:"List",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:""},{name:"symmetry_repr_code",required:!0,valid_types:"Code",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_strain:ApplyStrainsWithSymmetry"}}},commits_count:0,development_status:"alpha",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"green",text:"Workflows",count:2}],pip_install_cmd:"pip install aiida-strain",is_installable:"True"},"aiida-supercell":{code_home:"https://github.com/pzarabadip/aiida-supercell",development_status:"stable",documentation_url:"https://aiida-supercell.readthedocs.io/",entry_point_prefix:"supercell",pip_url:"git+https://github.com/pzarabadip/aiida-supercell",name:"aiida-supercell",package_name:"aiida_supercell",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"1.0.1",description:"AiiDA Plugin for Supercell program",classifiers:["Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"]},aiida_version:">=1.0.0,<2.0",entry_points:{"aiida.calculations":{supercell:{description:["This is a SupercellCalculation, subclass of JobCalculation,","    to prepare input for enumerating structures using Supercell program"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"structure",required:!0,valid_types:"StructureData, SinglefileData",info:"Input structure"},{name:"supercell_size",required:!0,valid_types:"List",info:"Supercell size for enumeration"},{name:"calculate_coulomb_energies",required:!1,valid_types:"Bool",info:"Whether to calculate Coulomb energies"},{name:"charge_balance_method",required:!1,valid_types:"Str",info:"Method to use for charge balancing"},{name:"charges",required:!1,valid_types:"Dict",info:"Dictionary of formal charges to be used"},{name:"merge_symmetric",required:!1,valid_types:"Bool",info:"Whether to merge symmetrically distinct configurations"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"random_seed",required:!1,valid_types:"Int",info:"Random seed number"},{name:"sample_structures",required:!1,valid_types:"Dict",info:"How to sample structures from huge configuration space"},{name:"save_as_archive",required:!1,valid_types:"Bool",info:"Whether to save resulting structures as archive"},{name:"tolerance",required:!1,valid_types:"Float",info:"The maximum distance (in Angstroms) between sites that should be contained within the same group."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"the results of the calculation"},{name:"output_structures",required:!0,valid_types:"StructureData",info:"relaxed structure"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"Input structure could not be processed."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_supercell.calculations:SupercellCalculation"}},"aiida.parsers":{supercell:"aiida_supercell.parsers:SupercellParser"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-supercell",is_installable:"True"},"aiida-symmetry-representation":{code_home:"https://github.com/greschd/aiida_symmetry_representation",documentation_url:"https://aiida-symmetry-representation.readthedocs.io",entry_point_prefix:"symmetry_representation",pip_url:"aiida-symmetry-representation",name:"aiida-symmetry-representation",package_name:"aiida_symmetry_representation",hosted_on:"github.com",metadata:{release_date:"2019-11-18",description:"AiiDA Plugin for symmetry representations.",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-symmetry-representation.readthedocs.io",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.calculations":{"symmetry_representation.filter_symmetries":{description:["Calculation class to run the ``symmetry-repr filter_symmetries`` command."],spec:{inputs:[{name:"structure",required:!0,valid_types:"StructureData",info:"Structure with which the filtered symmetries should be compatible."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"File containing the symmetries (in HDF5 format)."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"The HDF5 file containing the symmetries which are compatible with the structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_symmetry_representation.calculations.filter_symmetries:FilterSymmetriesCalculation"}},"aiida.parsers":{"symmetry_representation.symmetry":"aiida_symmetry_representation.parsers.symmetries:SymmetriesParser"}},commits_count:0,development_status:"stable",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-symmetry-representation",is_installable:"True"},"aiida-tbextraction":{code_home:"https://github.com/greschd/aiida-tbextraction",documentation_url:"https://aiida-tbextraction.readthedocs.io/",entry_point_prefix:"tbextraction",pip_url:"aiida-tbextraction",name:"aiida-tbextraction",package_name:"aiida_tbextraction",hosted_on:"github.com",metadata:{release_date:"2020-02-25",description:"AiiDA Plugin for extracting tight-binding models",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-tbextraction.readthedocs.io",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0b1"},aiida_version:null,entry_points:{"aiida.workflows":{"tbextraction.fp_run.base":"aiida_tbextraction.fp_run:FirstPrinciplesRunBase","tbextraction.fp_run.reference_bands.base":"aiida_tbextraction.fp_run.reference_bands:ReferenceBandsBase","tbextraction.fp_run.wannier_input.base":"aiida_tbextraction.fp_run.wannier_input:WannierInputBase","tbextraction.calculate_tb":"aiida_tbextraction.calculate_tb:TightBindingCalculation","tbextraction.model_evaluation.base":"aiida_tbextraction.model_evaluation:ModelEvaluationBase","tbextraction.model_evaluation.band_difference":"aiida_tbextraction.model_evaluation:BandDifferenceModelEvaluation","tbextraction.energy_windows.run_window":"aiida_tbextraction.energy_windows.run_window:RunWindow","tbextraction.energy_windows.window_search":"aiida_tbextraction.energy_windows.window_search:WindowSearch","tbextraction.optimize_fp_tb":"aiida_tbextraction.optimize_fp_tb:OptimizeFirstPrinciplesTightBinding","tbextraction.optimize_strained_fp_tb":"aiida_tbextraction.optimize_strained_fp_tb:OptimizeStrainedFirstPrinciplesTightBinding"}},commits_count:0,development_status:"beta",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"green",text:"Workflows",count:10}],pip_install_cmd:"pip install --pre aiida-tbextraction",is_installable:"False",errors:[`Failed to install plugin aiida-tbextraction
Collecting aiida-tbextraction
  Downloading aiida-tbextraction-0.2.0b1.tar.gz (19 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [20 lines of output]
      /opt/conda/lib/python3.9/site-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.
      !!
      
              ********************************************************************************
              Requirements should be satisfied by a PEP 517 installer.
              If you are using pip, you can try \`pip install --use-pep517\`.
              ********************************************************************************
      
      !!
        dist.fetch_build_eggs(dist.setup_requires)
      [ REENTRY ] registering entry points with reentry...
      [ REENTRY ] ... registered to /home/aiida/.config/reentry/data/fb804e5deb254c259a00b9e16a29b7b797b2c8f0a8a97f3aa7401e8a85ce8cdb
      [ REENTRY ] Following entrypoints were registered
      
          aiida-tbextraction -> {'aiida.workflows': {'tbextraction.fp_run.base': 'tbextraction.fp_run.base = aiida_tbextraction.fp_run:FirstPrinciplesRunBase', 'tbextraction.fp_run.reference_bands.base': 'tbextraction.fp_run.reference_bands.base = aiida_tbextraction.fp_run.reference_bands:ReferenceBandsBase', 'tbextraction.fp_run.wannier_input.base': 'tbextraction.fp_run.wannier_input.base = aiida_tbextraction.fp_run.wannier_input:WannierInputBase', 'tbextraction.calculate_tb': 'tbextraction.calculate_tb = aiida_tbextraction.calculate_tb:TightBindingCalculation', 'tbextraction.model_evaluation.base': 'tbextraction.model_evaluation.base = aiida_tbextraction.model_evaluation:ModelEvaluationBase', 'tbextraction.model_evaluation.band_difference': 'tbextraction.model_evaluation.band_difference = aiida_tbextraction.model_evaluation:BandDifferenceModelEvaluation', 'tbextraction.energy_windows.run_window': 'tbextraction.energy_windows.run_window = aiida_tbextraction.energy_windows.run_window:RunWindow', 'tbextraction.energy_windows.window_search': 'tbextraction.energy_windows.window_search = aiida_tbextraction.energy_windows.window_search:WindowSearch', 'tbextraction.optimize_fp_tb': 'tbextraction.optimize_fp_tb = aiida_tbextraction.optimize_fp_tb:OptimizeFirstPrinciplesTightBinding', 'tbextraction.optimize_strained_fp_tb': 'tbextraction.optimize_strained_fp_tb = aiida_tbextraction.optimize_strained_fp_tb:OptimizeStrainedFirstPrinciplesTightBinding'}}
      [ REENTRY ] Current entry point map at /home/aiida/.config/reentry/data/fb804e5deb254c259a00b9e16a29b7b797b2c8f0a8a97f3aa7401e8a85ce8cdb:
          aiida-tbextraction -> {'aiida.workflows': {'tbextraction.fp_run.base': 'tbextraction.fp_run.base = aiida_tbextraction.fp_run:FirstPrinciplesRunBase', 'tbextraction.fp_run.reference_bands.base': 'tbextraction.fp_run.reference_bands.base = aiida_tbextraction.fp_run.reference_bands:ReferenceBandsBase', 'tbextraction.fp_run.wannier_input.base': 'tbextraction.fp_run.wannier_input.base = aiida_tbextraction.fp_run.wannier_input:WannierInputBase', 'tbextraction.calculate_tb': 'tbextraction.calculate_tb = aiida_tbextraction.calculate_tb:TightBindingCalculation', 'tbextraction.model_evaluation.base': 'tbextraction.model_evaluation.base = aiida_tbextraction.model_evaluation:ModelEvaluationBase', 'tbextraction.model_evaluation.band_difference': 'tbextraction.model_evaluation.band_difference = aiida_tbextraction.model_evaluation:BandDifferenceModelEvaluation', 'tbextraction.energy_windows.run_window': 'tbextraction.energy_windows.run_window = aiida_tbextraction.energy_windows.run_window:RunWindow', 'tbextraction.energy_windows.window_search': 'tbextraction.energy_windows.window_search = aiida_tbextraction.energy_windows.window_search:WindowSearch', 'tbextraction.optimize_fp_tb': 'tbextraction.optimize_fp_tb = aiida_tbextraction.optimize_fp_tb:OptimizeFirstPrinciplesTightBinding', 'tbextraction.optimize_strained_fp_tb': 'tbextraction.optimize_strained_fp_tb = aiida_tbextraction.optimize_strained_fp_tb:OptimizeStrainedFirstPrinciplesTightBinding'}}
      error in aiida-tbextraction setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier)
          aiida-core>=1.0.0<2
                    ~~~~~~~^
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
`]},"aiida-tbmodels":{code_home:"https://github.com/greschd/aiida-tbmodels",documentation_url:"https://aiida-tbmodels.readthedocs.io",entry_point_prefix:"tbmodels",pip_url:"aiida-tbmodels",name:"aiida-tbmodels",package_name:"aiida_tbmodels",hosted_on:"github.com",metadata:{release_date:"2020-03-03",description:"AiiDA Plugin for running TBmodels",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-tbmodels.readthedocs.io",classifiers:["Development Status :: 3 - Alpha","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.3.0"},aiida_version:null,entry_points:{"aiida.calculations":{"tbmodels.eigenvals":{description:["Calculation class for the 'tbmodels eigenvals' command, which computes the eigenvalues from a given tight-binding model."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"Kpoints for which the eigenvalues are calculated."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands",required:!0,valid_types:"BandsData",info:"The calculated eigenvalues of the model at given k-points."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The result HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."}]},class:"aiida_tbmodels.calculations.eigenvals:EigenvalsCalculation"},"tbmodels.parse":{description:["Calculation plugin for the 'tbmodels parse' command, which creates a","    TBmodels tight-binding model from the Wannier90 output."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"wannier_folder",required:!0,valid_types:"FolderData",info:"Folder containing the Wannier90 output data."},{name:"distance_ratio_threshold",required:!1,valid_types:"Float",info:"Determines the minimum ratio between nearest and next-nearest atom when parsing with 'nearest_atom' mode."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pos_kind",required:!1,valid_types:"Str",info:"Determines how the orbital positions are parsed."},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."},{status:301,message:"The seedname_wsvec.dat file is empty or incomplete."},{status:401,message:"The nearest atom to use for position parsing is ambiguous."}]},class:"aiida_tbmodels.calculations.parse:ParseCalculation"},"tbmodels.slice":{description:["Calculation plugin for the 'tbmodels slice' command, which re-orders or slices orbitals of a tight-binding model."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"slice_idx",required:!0,valid_types:"List",info:"Indices of the orbitals which are sliced from the model."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."}]},class:"aiida_tbmodels.calculations.slice:SliceCalculation"},"tbmodels.symmetrize":{description:["Calculation class for the 'tbmodels symmetrize' command, which creates a symmetrized tight-binding model from a tight-binding model and symmetry representations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"File containing the symmetries in HDF5 format."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."},{status:301,message:"The type of the given symmetries object is incorrect."}]},class:"aiida_tbmodels.calculations.symmetrize:SymmetrizeCalculation"}},"aiida.parsers":{"tbmodels.model":"aiida_tbmodels.parsers.model:ModelParser"}},commits_count:0,development_status:"alpha",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:4},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-tbmodels",is_installable:"True"},"aiida-tcod":{code_home:"https://github.com/aiidateam/aiida-tcod",development_status:"beta",entry_point_prefix:"tcod",pip_url:"git+https://github.com/aiidateam/aiida-tcod",name:"aiida-tcod",package_name:"aiida_tcod",hosted_on:"github.com",metadata:{author:"The AiiDA team",author_email:"developers@aiida.net",version:"0.1.0a0",description:"AiiDA plugin to interact with the TCOD",classifiers:["Programming Language :: Python"]},aiida_version:">=1.0.0b1",entry_points:{"aiida.tools.dbexporters":{tcod:"aiida.tools.dbexporters.tcod"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"orange",text:"Other (Database Exporters)",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidateam/aiida-tcod",is_installable:"True"},"aiida-uppasd":{code_home:"https://github.com/uppasd/aiida-uppasd",documentation_url:"https://github.com/uppasd/aiida-uppasd/blob/master/README.md",entry_point_prefix:"uppasd",pip_url:"git+https://github.com/unkcpz/aiida-uppasd",name:"aiida-uppasd",package_name:"aiida_uppasd",hosted_on:"github.com",metadata:{author:"Qichen Xu, Anders Bergman, Anna Delin, Jonathan Chico",author_email:"qichenx@kth.se",version:"0.1.0",description:"Interface for UppASD and AiiDA",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.calculations":{UppASD_core_calculations:"UppASD_AiiDA.calculations.core_calcs:UppASD"},"aiida.parsers":{UppASD_core_parsers:"UppASD_AiiDA.parsers.core_parser:SpinDynamic_core_parser"}},commits_count:0,development_status:"planning",warnings:["Entry point 'UppASD_core_calculations' does not start with prefix 'uppasd.'","Entry point 'UppASD_core_parsers' does not start with prefix 'uppasd.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/unkcpz/aiida-uppasd"},"aiida-vasp":{code_home:"https://github.com/aiida-vasp/aiida-vasp",documentation_url:"https://aiida-vasp.readthedocs.io/",entry_point_prefix:"vasp",pip_url:"aiida-vasp",plugin_info:"https://raw.githubusercontent.com/aiida-vasp/aiida-vasp/master/setup.json",name:"aiida-vasp",package_name:"aiida_vasp",hosted_on:"github.com",metadata:{release_date:"2023-07-03",description:"AiiDA plugin for running VASP calculations and workflows.",author_email:"Espen Flage-Larsen <espen.flage-larsen@sigma2.no>",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"3.0.1"},aiida_version:">=2.4,<3.0",entry_points:{"aiida.calculations":{"vasp.immigrant":{description:["Parse VASP output objects stored in a specified directory.","","    Simulate running the VaspCalculation up to the point where it can be","    retrieved and parsed, then hand over control to the runner for the rest.","","    Usage examples","    --------------","    Immigrant calculation can be perfomed as follows.","","    ::","","       code = Code.get_from_string('vasp@local')","       folder = '/home/username/vasp-calc-dir'","       settings = {'parser_settings': {'add_energies': True,","                                       'add_forces': True,","                                       'electronic_step_energies': True}}","       VaspImmigrant = CalculationFactory('vasp.immigrant')","       builder = VaspImmigrant.get_builder_from_folder(code,","                                                       folder,","                                                       settings=settings)","       submit(builder)","","    Instead of ``builder``, inputs dict is obtained similarly as","","    ::","","       code = Code.get_from_string('vasp@local')","       folder = '/home/username/vasp-calc-dir'","       settings = {'parser_settings': {'add_energies': True,","                                       'add_forces': True,","                                       'electronic_step_energies': True}}","       VaspImmigrant = CalculationFactory('vasp.immigrant')","       inputs = VaspImmigrant.get_inputs_from_folder(code,","                                                     folder,","                                                     settings=settings)","       submit(VaspImmigrant, **inputs)","","    Note","    ----","    The defaul metadata is set automatically as follows::","","       {'options': {'max_wallclock_seconds': 1,","        'resources': {'num_machines': 1, 'num_mpiprocs_per_machine': 1}}}","","    Specific scheduler may require setting ``resources`` differently","    (e.g., sge ``'parallel_env'``).","","    ``get_inputs_from_folder`` and ``get_builder_from_folder`` accept several","    kwargs, see the docstring of ``get_inputs_from_folder``."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData, NoneType",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"remote_workdir",required:!1,valid_types:"str, NoneType",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData, NoneType",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.immigrant:VaspImmigrant"},"vasp.neb":{description:["NEB calculations using VASP","","    ------------------------------------","    Calculations for performing NEB calculations.","    NEB calculations requires standard VASP inputs, but POSCAR are placed in","    folder names 00, 01, 02... N for N-1 number of images.","","    Input frames should be placed under the ``neb_images`` input namespace as a dictionary like::","      {","          'image_00': structure_1,","          'image_01': structure_2","          ....","      }","","    Output of individual frames are placed in the corresponding namespace under the same convention."],spec:{inputs:[{name:"final_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for the final image."},{name:"initial_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for initial image."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"neb_images",required:!0,valid_types:"StructureData, CifData",info:"Starting structure for the NEB images"},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"Per-image misc output."},{name:"neb_misc",required:!0,valid_types:"Dict",info:"NEB related data combined for each image"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"structure",required:!0,valid_types:"StructureData",info:"NEB images"},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"Kpoints for each image."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization for each image."},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output file containing the plane wave coefficients."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output files and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:352,message:"a file that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure the `neb_data` and `run_status` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1001,message:"parsing a file has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.neb:VaspNEBCalculation"},"vasp.vasp":{description:["General-purpose VASP calculation.","","    ---------------------------------","    By default retrieves only the 'OUTCAR', 'vasprun.xml', 'EIGENVAL', 'DOSCAR'","    and Wannier90 input / output objects. These objects are deleted after parsing.","    Additional retrieve objects can be specified via the","    ``settings['ADDITIONAL_RETRIEVE_TEMPORARY_LIST']`` input. In addition, if you want to keep","    any objects after parsing, put them in ``settings['ADDITIONAL_RETRIEVE_LIST']`` which is empty","    by default.","","    Floating point precision for writing POSCAR objects can be adjusted using","    ``settings['poscar_precision']``, default: 10","","    The following assumes you are familiar with the AiiDA data structures and","    how to set up and run an AiiDA calculation in general.","","    Example usage::","","        from aiida.orm import CalculationFactory, DataFactory","        from aiida.work import submit","","        proc = CalculationFactory('vasp.vasp').process()","        inputs = proc.get_inputs_template()","        inputs.parameter = <Dict with INCAR params>","        inputs.structure = <StructureData>","        inputs.kpoints = <KpointsData>","        inputs.settings = <Dict with parser settings etc.>","        inputs.potential = DataFactory('vasp.potcar').get_potcars_from_structure(structure, ...)","        inputs.code = <Code representing vasp on your cluster>","","        submit(proc, **inputs)","","    Which is very similar to the workchain example.","","    Since we do not want the content parsers to know about the AiiDA infrastructure,","    i.e. processes etc. we have no access to the exit codes defined on the CalcJob.","    We thus have to deal with failures in parsing directly in the write calls here."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData, NoneType",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData, NoneType",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.vasp:VaspCalculation"},"vasp.vasp2w90":{description:["General purpose Calculation for using vasp with the vasp2wannier90 interface."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData, NoneType",info:"The charge density. (CHGCAR)"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"dynamics",required:!1,valid_types:"Dict, NoneType",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"wannier_parameters",required:!1,valid_types:"Dict, NoneType",info:"Input parameters for the Wannier90 interface."},{name:"wannier_projections",required:!1,valid_types:"OrbitalData, List, NoneType",info:"Projections to be defined in the Wannier90 input."},{name:"wavefunctions",required:!1,valid_types:"WavefunData, NoneType",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"}]},class:"aiida_vasp.calcs.vasp2w90:Vasp2w90Calculation"}},"aiida.cmdline.data":{"vasp-potcar":"aiida_vasp.commands.potcar:potcar"},"aiida.data":{"vasp.archive":"aiida_vasp.data.archive:ArchiveData","vasp.chargedensity":"aiida_vasp.data.chargedensity:ChargedensityData","vasp.potcar":"aiida_vasp.data.potcar:PotcarData","vasp.potcar_file":"aiida_vasp.data.potcar:PotcarFileData","vasp.wavefun":"aiida_vasp.data.wavefun:WavefunData"},"aiida.groups":{"vasp.potcar":"aiida_vasp.data.potcar:PotcarGroup"},"aiida.parsers":{"vasp.neb":"aiida_vasp.parsers.neb:VtstNebParser","vasp.vasp":"aiida_vasp.parsers.vasp:VaspParser","vasp.vasp2w90":"aiida_vasp.parsers.vasp2w90:Vasp2w90Parser"},"aiida.workflows":{"vasp.bands":{description:["Extract the band structure using k-point paths fetched from SeeKpath."],spec:{inputs:[{name:"bands",required:!0,valid_types:"",info:""},{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"restart_folder",required:!0,valid_types:"RemoteData",info:`
            The folder to restart in, which contains the outputs from the prerun to extract the charge density.
            `},{name:"smearing",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"bands",required:!0,valid_types:"BandsData",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the bands workchain"},{status:2001,message:"BandsData not found in exposed_outputs"}]},class:"aiida_vasp.workchains.bands:BandsWorkChain"},"vasp.converge":{description:["A workchain to perform convergence tests."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"converge",required:!0,valid_types:"",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"converge",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"relax",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the converge workchain"}]},class:"aiida_vasp.workchains.converge:ConvergeWorkChain"},"vasp.immigrant":{description:["Import a VASP run executed in the directory specified by folder_path."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"folder_path",required:!1,valid_types:"Str, NoneType",info:"Deprecated."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"potential_family",required:!1,valid_types:"Str, NoneType",info:""},{name:"potential_mapping",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_workdir",required:!1,valid_types:"str, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"use_chgcar",required:!1,valid_types:"Bool, NoneType",info:`
            If True, WavefunData (of WAVECAR) is attached.
            `},{name:"use_wavecar",required:!1,valid_types:"Bool, NoneType",info:`
            If True, WavefunData (of WAVECAR) is attached.
            `},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_vasp.workchains.immigrant:VaspImmigrantWorkChain"},"vasp.master":{description:["The master workchain that selects sub workchains to perform necessary calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"converge",required:!0,valid_types:"",info:""},{name:"dos",required:!0,valid_types:"",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"extract_bands",required:!1,valid_types:"Bool, NoneType",info:"Do you want to extract the band structure?"},{name:"extract_dos",required:!1,valid_types:"Bool, NoneType",info:"Do you want to extract the density of states?"},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The maximum distance between k-points in inverse AA."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"bands",required:!1,valid_types:"",info:""},{name:"dos",required:!1,valid_types:"",info:""}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the master workchain"}]},class:"aiida_vasp.workchains.master:MasterWorkChain"},"vasp.neb":{description:["The NEB workchain.","","    -------------------","    Error handling enriched wrapper around VaspNEBCalculation.","","    Deliberately conserves most of the interface (required inputs) of the VaspNEBCalculation class, but","    makes it possible for a user to interact with a workchain and not a calculation.","","    In addition, implement restarts of calculation when the calculation is net full converged for error handling."],spec:{inputs:[{name:"dynamics",required:!0,valid_types:"",info:""},{name:"final_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for the final image."},{name:"initial_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for initial image."},{name:"neb_images",required:!0,valid_types:"StructureData, CifData",info:"Starting structure for the NEB images"},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"kpoints_spacing",required:!1,valid_types:"Float, NoneType",info:"Spacing for the kpoints in units A^-1 * 2pi (CASTEP style `kpoints_mp_spacing`)"},{name:"kpoints_spacing_vasp",required:!1,valid_types:"Float, NoneType",info:"Spacing for the kpoints in units A^-1 (VASP style)"},{name:"ldau_mapping",required:!1,valid_types:"Dict, NoneType",info:"Mappings, see the doc string of 'get_ldau_keys'"},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters not related to VASP itself."},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"Per-image misc output."},{name:"neb_misc",required:!0,valid_types:"Dict",info:"NEB related data combined for each image"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"structure",required:!0,valid_types:"StructureData",info:"NEB images"},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"Kpoints for each image."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization for each image."},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output file containing the plane wave coefficients."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."},{status:501,message:"Unrecoverable error in launched NEB calculations."},{status:700,message:"the user did not supply a potential family name"},{status:701,message:"ValueError was returned from get_potcars_from_structure"},{status:702,message:"the potential does not exist"},{status:703,message:"the exception: {exception} was thrown while massaging the parameters"}]},class:"aiida_vasp.workchains.neb:VaspNEBWorkChain"},"vasp.relax":{description:["Structure relaxation workchain."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"relax",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"relax",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"the called workchain does not contain the necessary relaxed output structure"},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the relax workchain"},{status:502,message:"there was an error overriding the parameters"}]},class:"aiida_vasp.workchains.relax:RelaxWorkChain"},"vasp.vasp":{description:["The VASP workchain.","","    -------------------","    Error handling enriched wrapper around VaspCalculation.","","    Deliberately conserves most of the interface (required inputs) of the VaspCalculation class, but","    makes it possible for a user to interact with a workchain and not a calculation.","","    This is intended to be used instead of directly submitting a VaspCalculation,","    so that future features like","    automatic restarting, error checking etc. can be propagated to higher level workchains","    automatically by implementing them here.","","    Handlers are implemented to try fix common problems and improves the robustness.","    Individual handlers can be enabled/disabled by setting the ``handler_overrides`` input port.",'    Additional settings may be passed under the "settings" input, which is also forwarded to the',"    calculations. The available options are:","","    - ``USE_WAVECAR_FOR_RESTART`` wether calculation restarts should use the WAVECAR. The default is ``True``.","","    Usage::","","        from aiida.common.extendeddicts import AttributeDict","        from aiida.work import submit","        basevasp = WorkflowFactory('vasp.vasp')","        inputs = basevasp.get_builder()","        inputs = AttributeDict()","        ## ... set inputs","        submit(basevasp, **inputs)","","    To see a working example, including generation of input nodes from scratch, please","    refer to ``examples/run_vasp_lean.py``."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData, NoneType",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:`
            If True, clean the work dir upon the completion of a successful calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int, NoneType",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData, NoneType",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict, NoneType",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool, NoneType",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData, NoneType",info:""}],outputs:[{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"custom_outputs",required:!1,valid_types:"",info:""},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"the calculation is missing at least one required output in the restart workchain"},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:400,message:"the run_calculation step did not successfully add a calculation node to the context"},{status:401,message:"the maximum number of iterations was exceeded"},{status:402,message:"the calculation finished with an unexpected calculation state"},{status:403,message:"the calculation experienced and unexpected failure"},{status:404,message:"the calculation failed to submit, twice in a row"},{status:405,message:"the calculation failed for an unknown reason, twice in a row"},{status:500,message:"Missing critical output for inspecting the status of the calculation."},{status:501,message:"Cannot handle the error - inputs are likely need to be revised manually. Message: {message}"},{status:502,message:"Cannot handle the error - the last calculation did not reach the end of execution."},{status:503,message:"Cannot handle the error - the last calculation did not reach electronic convergence."},{status:504,message:"The ionic relaxation is not converged."},{status:505,message:"At least one of the ionic steps during the relaxation has did not have converged electronic structure."},{status:700,message:"the user did not supply a potential family name"},{status:701,message:"ValueError was returned from get_potcars_from_structure"},{status:702,message:"the potential does not exist"},{status:703,message:"the exception: {exception} was thrown while massaging the parameters"}]},class:"aiida_vasp.workchains.vasp:VaspWorkChain"}},console_scripts:{"mock-vasp":"aiida_vasp.commands.mock_vasp:mock_vasp","mock-vasp-strict":"aiida_vasp.commands.mock_vasp:mock_vasp_strict"}},commits_count:101,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:4},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:5},{colorclass:"green",text:"Workflows",count:7},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:2}],pip_install_cmd:"pip install aiida-vasp",is_installable:"True"},"aiida-vibroscopy":{entry_point_prefix:"vibroscopy",plugin_info:"https://raw.githubusercontent.com/bastonero/aiida-vibroscopy/main/pyproject.toml",code_home:"https://github.com/bastonero/aiida-vibroscopy",version_file:"https://raw.githubusercontent.com/bastonero/aiida-vibroscopy/main/src/aiida_vibroscopy/__init__.py",pip_url:"aiida-vibroscopy",documentation_url:"https://aiida-vibroscopy.readthedocs.io/en/latest/",name:"aiida-vibroscopy",package_name:"aiida_vibroscopy",hosted_on:"github.com",metadata:{release_date:"2023-08-10",description:"AiiDA plugin for vibrational spectoscopy using Quantum ESPRESSO.",author_email:"Lorenzo Bastonero <bastonero.lorenzo@gmail.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: Other/Proprietary License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.0.2"},aiida_version:">=2.2.2,<3.0.0",entry_points:{"aiida.data":{"vibroscopy.fp":"aiida_vibroscopy.data.vibro_fp:VibrationalFrozenPhononData","vibroscopy.vibrational":"aiida_vibroscopy.data.vibro_lr:VibrationalData"},"aiida.workflows":{"vibroscopy.dielectric":{description:["Workchain computing different second and third order tensors.","","    It computes the high frequency dielectric tensor, the Born effective charges,","    the non-linear optical susceptibility and Raman tensors","    using homogeneous small electric fields via the electric enthalpy functional."],spec:{inputs:[{name:"central_difference",required:!0,valid_types:"",info:"The inputs for the central difference scheme."},{name:"property",required:!0,valid_types:"str",info:`irValid inputs are: 
 
 * born-chargesValid inputs are: 
 
 * dielectricValid inputs are: 
 
 * nacValid inputs are: 
 
 * becValid inputs are: 
 
 * ramanValid inputs are: 
 
 * susceptibility-derivativeValid inputs are: 
 
 * non-linear-susceptibility`},{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` that will be used to run the electric enthalpy scfs."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"kpoints_parallel_distance",required:!1,valid_types:"Float, NoneType",info:"Distance of the k-points in reciprocal space along the parallel direction of each applied electric field."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parent_scf",required:!1,valid_types:"RemoteData, NoneType",info:"Scf parent folder from where restarting the scfs with electric fields."}],outputs:[{name:"fields_data",required:!0,valid_types:"",info:"Namespace for passing TrajectoryData containing forces and polarization."},{name:"tensors",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric and Born effectivecharges tensors computed in Cartesian coordinates. Depending on the inputs, it can also contain the derivatives of the susceptibility in respect to the atomic positions (called `Raman tensors`) and the non linear optical susceptibility, always expressed in Cartesian coordinates."},{name:"accuracy_order",required:!1,valid_types:"Int",info:""},{name:"critical_electric_field",required:!1,valid_types:"Float",info:""},{name:"electric_field_step",required:!1,valid_types:"Float",info:""},{name:"units",required:!1,valid_types:"Dict",info:"Units of the susceptibility derivatives tensors."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The initial scf work chain failed."},{status:401,message:"The nscf work chain failed."},{status:402,message:"The electric field scf work chain failed for direction {direction}."},{status:403,message:"The numerical derivatives calculation failed."},{status:404,message:"The scf PwBaseWorkChain sub process in iteration returned a non integer total magnetization (threshold exceeded)."}]},class:"aiida_vibroscopy.workflows.dielectric.base:DielectricWorkChain"},"vibroscopy.dielectric.numerical_derivatives":{description:["Workchain carrying out numerical derivatives.","","    It computes the first and second order derivatives","    of forces and polarization in respect to electric field,","    to obtain dielectric tensor, Born effective charges,","    non linear optical susceptibility and Raman tensors.","","    Forces and polarization must be passed as TrajectoryData","    as a dictionary in `data`. Numerical derivatives can have","    different number of evaluation points, depending on order and accuracy.","    The price to pay is the standardization of the structure of","    the dictionary to pass to this namespace.","","    To understand, let's review the approach.In central differencs approach","    we need the evaluation of the function at the value we want","    the derivative (in our case at :math:`\\mathcal{E}=0`,","    E is the electric field), and at","    displaced positions from this value.","    The evaluation of the function at these points will","    have weights (or coefficients), which depend on order and accuracy.","    For example:","","    - :math:`\\frac{df}{dx} = \\frac{ 0.5 \\cdot f(+1.0 \\cdot h) -0.5 \\cdot f(-1.0 \\cdot h) }{h} +\\mathcal{O}(h^2)`","    - :math:`\\frac{d^2 f}{dx^2} = \\frac{ 1.0 \\cdot f(+1.0 \\cdot h) -2.0 \\cdot f(0. \\cdot h) +1.0 \\cdot f(-1.0 \\cdot h) }{h^2} +\\mathcal{O}(h^2)`","","    Referring to the coefficients for each step as :math:`c_i`,","    where `i` is an integer, our convention is","    to put in sequence the Trajectory data with increasing","    numbers as labels, for example:","","    | '0': TrajectoryData for :math:`c_1`,","    | '1': TrajectoryData for :math:`c_{-1}`,","    | '2': TrajectoryData for :math:`c_2`,","    | '3': TrajectoryData for :math:`c_{-2}`,","    | ...","","    This way to creating an analogous of an array with","    coefficients :math:`[c_1,c_{-1},c_2,c_{-2}, \\dots]`.","","    These dictionaries are going to be put as sub-dictionary","    in a general `data` dictionary. Each sub-dict","    has to be put with a key with suffix a number indicating","    which tensor component is referring to.","    In our case, we use a similar Voigt notation.","    Namely we have two cases:","","    * first order derivatives: keys suffices are 0,1,2;","        0 for :math:`[i,x]`, 1 for :math:`[i,y]`, 2 for","        :math:`[i,z]` (with :math:`i={x,y,z}`)","    * second order derivatives: keys suffices are 0,...5;","        0 for :math:`[i,x,x]`, :math:`\\dots` (as in Voigt),","        5 for :math:`[i,x,y]` (with :math:`i={x,y,z}`)","","    The prefix can be anything. Best practice is using ``field_``","    with and underscorre as prefix. The Trajectory data for the","    :math:`c_0` coefficient (i.e. the one with :math:`\\mathcal{E}=0`)","    must be passed with a different key, namely ``null_field``.","    This is to avoid errors and due to the fact that is common","    to the all derivatives."],spec:{inputs:[{name:"central_difference",required:!0,valid_types:"",info:"The inputs for the central difference scheme."},{name:"data",required:!0,valid_types:"",info:"Namespace for passing TrajectoryData containing forces and polarization."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"tensors",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric and Born effectivecharges tensors computed in Cartesian coordinates. Depending on the inputs, it can also contain the derivatives of the susceptibility in respect to the atomic positions (called `Raman tensors`) and the non linear optical susceptibility, always expressed in Cartesian coordinates."},{name:"units",required:!1,valid_types:"Dict",info:"Units of the susceptibility derivatives tensors."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_vibroscopy.workflows.dielectric.numerical_derivatives:NumericalDerivativesWorkChain"},"vibroscopy.phonons.harmonic":{description:["Workchain for frozen phonons calculations.","","    Non-analytical constants (NAC) and higher order mixed  derivatives are computed","    via finite differences through finite electric fields.","    See :class:`~aiida_vibroscopy.workflows.DielectricWorkChain`","    for more details on how they are carried out."],spec:{inputs:[{name:"phonon",required:!0,valid_types:"Data",info:"Inputs for the `PhononWorkChain` that will beused to calculate the force constants."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"dielectric",required:!1,valid_types:"Data",info:"Inputs for the `DielectricWorkChain` that will beused to calculate the mixed derivatives with electric field."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"phonopy",required:!1,valid_types:"Data",info:"Inputs for the `PhonopyCalculation` that willbe used to calculate the inter-atomic force constants, or for post-processing."}],outputs:[{name:"output_phonon",required:!0,valid_types:"",info:"Outputs of the `PhononWorkChain`."},{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"output_dielectric",required:!1,valid_types:"",info:"Outputs of the `DielectricWorkChain`."},{name:"output_phonopy",required:!1,valid_types:"",info:"Outputs of the post-processing via `phonopy`."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The phonon workchain failed."},{status:401,message:"The dielectric workchain failed."},{status:402,message:"The phonopy calculation failed."}]},class:"aiida_vibroscopy.workflows.phonons.harmonic:HarmonicWorkChain"},"vibroscopy.phonons.phonon":{description:["Class for computing force constants of phonons, without non-analytical corrections."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` that will be used to run the electric enthalpy scfs."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"displacement_generator",required:!1,valid_types:"Dict, NoneType",info:`Info for displacements generation. The following flags are allowed:
 distance
 is_plusminus
 is_diagonal
 is_trigonal
 number_of_snapshots
 random_seed
 cutoff_frequency`},{name:"metadata",required:!1,valid_types:"",info:""},{name:"phonopy",required:!1,valid_types:"Data",info:"Inputs for the `PhonopyCalculation` that willbe used to calculate the inter-atomic force constants, or for post-processing."},{name:"primitive_matrix",required:!1,valid_types:"List, NoneType",info:"Primitive matrix that defines the primitive cell from the unitcell."},{name:"supercell_matrix",required:!1,valid_types:"List, NoneType",info:"Supercell matrix that defines the supercell from the unitcell."}],outputs:[{name:"phonopy_data",required:!0,valid_types:"PhonopyData",info:"The phonopy data with supercells displacements, forces to use in the post-processing calculation."},{name:"supercells_forces",required:!0,valid_types:"ArrayData, TrajectoryData",info:"The forces acting on the atoms of each supercell."},{name:"output_phonopy",required:!1,valid_types:"",info:""},{name:"supercells",required:!1,valid_types:"StructureData",info:"The supercells with displacements."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The initial supercell scf work chain failed."},{status:401,message:"The initial PwBaseWorkChain sub process returned a non integer total magnetization."},{status:402,message:"At least one sub processe did not finish successfully."},{status:403,message:"The phonopy calculation did not finish correctly."}]},class:"aiida_vibroscopy.workflows.phonons.base:PhononWorkChain"},"vibroscopy.spectra.intensities_average":{description:["Workchain that computes IR and Raman spatial and q-direction average spectra."],spec:{inputs:[{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"Vibrational data containing force constants or frozen phonons forces, nac parameters and/or susceptibility derivatives."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:"Options for averaging on the non-analytical directions."}],outputs:[{name:"ir_averaged",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric tensor computed in Cartesian coordinates."},{name:"raman_averaged",required:!1,valid_types:"ArrayData",info:"Contains Born effective charges tensors computed in Cartesian coordinates."},{name:"units",required:!1,valid_types:"Dict",info:"Units of intensities and frequencies."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_vibroscopy.workflows.spectra.intensities_average:IntensitiesAverageWorkChain"},"vibroscopy.spectra.iraman":{description:["Workchain for automatically compute IR and Raman spectra using finite displacements and fields.","","    For other details of the sub-workchains used, see also:","        * :class:`~aiida_vibroscopy.workflows.dielectric.base.DielectricWorkChain` for finite fields","        * :class:`~aiida_vibroscopy.workflows.phonons.base.PhononWorkChain` for finite displacements"],spec:{inputs:[{name:"dielectric",required:!0,valid_types:"Data",info:"Inputs for the `DielectricWorkChain` that will beused to calculate the mixed derivatives with electric field."},{name:"phonon",required:!0,valid_types:"Data",info:"Inputs for the `PhononWorkChain` that will beused to calculate the force constants."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"intensities_average",required:!1,valid_types:"Data",info:"Inputs for the `IntensitiesAverageWorkChain` that willbe used to run the average calculation over intensities."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_phonon",required:!0,valid_types:"",info:"Outputs of the `PhononWorkChain`."},{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"fake",required:!1,valid_types:"",info:""},{name:"output_dielectric",required:!1,valid_types:"",info:"Outputs of the `DielectricWorkChain`."},{name:"output_intensities_average",required:!1,valid_types:"",info:"Intensities average over space and q-points."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The averaging procedure for intensities had an unexpected error."},{status:401,message:"The averaging procedure for intensities had an unexpected error."}]},class:"aiida_vibroscopy.workflows.spectra.iraman:IRamanSpectraWorkChain"}}},commits_count:71,development_status:"beta",summaryinfo:[{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:6}],pip_install_cmd:"pip install aiida-vibroscopy",is_installable:"True"},"aiida-wannier90":{code_home:"https://github.com/aiidateam/aiida-wannier90",documentation_url:"https://aiida-wannier90.readthedocs.io/",entry_point_prefix:"wannier90",pip_url:"aiida-wannier90",plugin_info:"https://raw.github.com/aiidateam/aiida-wannier90/master/setup.json",name:"aiida-wannier90",package_name:"aiida_wannier90",hosted_on:"github.com",metadata:{release_date:"2023-07-03",description:"AiiDA Plugin for the Wannier90 code",author:"Junfeng Qiao, Dominik Gresch, Antimo Marrazzo, Daniel Marchand, Giovanni Pizzi, Norma Rivano, The AiiDA team",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.1.0"},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{"wannier90.postw90":{description:["Plugin for Wannier90.","","    Wannier90 is a code for computing maximally-localized Wannier functions.","    See http://www.wannier.org/ for more details."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the Wannier90 code"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``RemoteData`` possibly stored in a remote computer."},{name:"structure",required:!0,valid_types:"StructureData",info:"input crystal structure"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"A list of k-points along a path to be used for bands interpolation; it should contain `labels`. Specify either this or `kpoint_path`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"kpoint_path",required:!1,valid_types:"Dict, NoneType",info:"Description of the k-points path to be used for bands interpolation; it should contain two properties: a list ``path`` of length-2 tuples with the labels of the endpoints of the path; and a dictionary ``point_coords`` giving the scaled coordinates for each high-symmetry endpoint."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"k-point mesh used in the NSCF calculation."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"projections",required:!1,valid_types:"OrbitalData, Dict, List, NoneType",info:"Starting projections for the Wannierisation procedure."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional settings to manage the Wannier90 calculation."}],outputs:[{name:"boltzwann",required:!0,valid_types:"",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The ``output_parameters`` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"interpolated_bands",required:!1,valid_types:"BandsData",info:"The interpolated band structure by Wannier90 (if any)."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required stdout output file."},{status:300,message:"A Wannier90 error file (.werr) has been found."},{status:400,message:'The string "Exiting..." has been found in the Wannier90 output (some partial output might have been parsed).'},{status:401,message:"An error related to bvectors has been found in the Wannier90 output."},{status:402,message:"Energy window contains fewer states than number of target WFs."},{status:403,message:"Error plotting Wanier functions in cube format."},{status:404,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:405,message:"Some output files were missing probably because the calculation got interrupted."},{status:406,message:"The retrieved temporary folder could not be accessed."}]},class:"aiida_wannier90.calculations:Postw90Calculation"},"wannier90.wannier90":{description:["Plugin for Wannier90.","","    Wannier90 is a code for computing maximally-localized Wannier functions.","    See http://www.wannier.org/ for more details."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"k-point mesh used in the NSCF calculation."},{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the Wannier90 code"},{name:"structure",required:!0,valid_types:"StructureData",info:"input crystal structure"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"A list of k-points along a path to be used for bands interpolation; it should contain `labels`. Specify either this or `kpoint_path`."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"kpoint_path",required:!1,valid_types:"Dict, NoneType",info:"Description of the k-points path to be used for bands interpolation; it should contain two properties: a list ``path`` of length-2 tuples with the labels of the endpoints of the path; and a dictionary ``point_coords`` giving the scaled coordinates for each high-symmetry endpoint."},{name:"local_input_folder",required:!1,valid_types:"FolderData, NoneType",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``FolderData`` stored in the AiiDA repository."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"projections",required:!1,valid_types:"OrbitalData, Dict, List, NoneType",info:"Starting projections for the Wannierisation procedure."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"remote_input_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``RemoteData`` possibly stored in a remote computer."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional settings to manage the Wannier90 calculation."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The ``output_parameters`` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"interpolated_bands",required:!1,valid_types:"BandsData",info:"The interpolated band structure by Wannier90 (if any)."},{name:"nnkp_file",required:!1,valid_types:"SinglefileData",info:"The ``.nnkp`` file, produced only in -pp (postproc) mode."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required stdout output file."},{status:300,message:"A Wannier90 error file (.werr) has been found."},{status:400,message:'The string "Exiting..." has been found in the Wannier90 output (some partial output might have been parsed).'},{status:401,message:"An error related to bvectors has been found in the Wannier90 output."},{status:402,message:"Energy window contains fewer states than number of target WFs."},{status:403,message:"Error plotting Wanier functions in cube format."},{status:404,message:"The stdout output file was incomplete probably because the calculation got interrupted."}]},class:"aiida_wannier90.calculations:Wannier90Calculation"}},"aiida.parsers":{"wannier90.postw90":"aiida_wannier90.parsers:Postw90Parser","wannier90.wannier90":"aiida_wannier90.parsers:Wannier90Parser"},"aiida.workflows":{"wannier90.minimal":{description:["Workchain to run a full stack of Quantum ESPRESSO + Wannier90 for GaAs.","","    Note that this is mostly to be used as an example, as there is no","    error checking and runs directly Quantum ESPRESSO calculations rather","    than the base workflows."],spec:{inputs:[{name:"kpoint_path",required:!0,valid_types:"Dict",info:"The kpoints path for the NSCF run and Wannierisation."},{name:"kpoints_nscf",required:!0,valid_types:"KpointsData",info:"The kpoints for the NSCF run and Wannierisation."},{name:"kpoints_scf",required:!0,valid_types:"KpointsData",info:"The kpoints for the SCF run."},{name:"projections",required:!0,valid_types:"OrbitalData",info:"The projections for the Wannierisation."},{name:"pseudo_family",required:!0,valid_types:"Str",info:"The name of a pseudopotential family to use."},{name:"pw2wannier90_code",required:!0,valid_types:"Code",info:"The `pw2wannier90.x` code to use for the `Pw2Wannier90Calculation`s."},{name:"pw_code",required:!0,valid_types:"Code",info:"The `pw.x` code to use for the `PwCalculation`s."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"wannier_code",required:!0,valid_types:"Code",info:"The `wannier90.x` code to use for the `Wannier90Calculation`s."},{name:"max_wallclock_seconds",required:!1,valid_types:"Int, NoneType",info:"Maximum wallclock time in seconds"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"num_machines",required:!1,valid_types:"Int, NoneType",info:"The number of machines (nodes) to use"}],outputs:[{name:"matrices_folder",required:!0,valid_types:"FolderData",info:""},{name:"nnkp_file",required:!0,valid_types:"SinglefileData",info:""},{name:"nscf_output",required:!0,valid_types:"Dict",info:""},{name:"p2wannier_output",required:!0,valid_types:"Dict",info:""},{name:"pw2wan_remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"scf_output",required:!0,valid_types:"Dict",info:""},{name:"wannier_bands",required:!0,valid_types:"BandsData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_wannier90.workflows.minimal:MinimalW90WorkChain"}}},commits_count:20,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-wannier90",is_installable:"True"},"aiida-wannier90-workflows":{code_home:"https://github.com/aiidateam/aiida-wannier90-workflows",development_status:"stable",entry_point_prefix:"wannier90_workflows",pip_url:"aiida-wannier90-workflows",plugin_info:"https://raw.github.com/aiidateam/aiida-wannier90-workflows/master/setup.json",name:"aiida-wannier90-workflows",package_name:"aiida_wannier90_workflows",hosted_on:"github.com",metadata:{release_date:"2023-07-04",description:"Advanced AiiDA workflows for Wannier90",author:"Junfeng Qiao, Antimo Marrazzo, Giovanni Pizzi",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.1.0"},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{"wannier90_workflows.split":"aiida_wannier90_workflows.calculations.split:Wannier90SplitCalculation"},"aiida.parsers":{"wannier90_workflows.split":"aiida_wannier90_workflows.parsers.split:Wannier90SplitParser"},"aiida.workflows":{"wannier90_workflows.bands":"aiida_wannier90_workflows.workflows.bands:Wannier90BandsWorkChain","wannier90_workflows.base.open_grid":"aiida_wannier90_workflows.workflows.base.open_grid:OpenGridBaseWorkChain","wannier90_workflows.base.projwfc":"aiida_wannier90_workflows.workflows.base.projwfc:ProjwfcBaseWorkChain","wannier90_workflows.base.pw2wannier90":"aiida_wannier90_workflows.workflows.base.pw2wannier90:Pw2wannier90BaseWorkChain","wannier90_workflows.base.wannier90":"aiida_wannier90_workflows.workflows.base.wannier90:Wannier90BaseWorkChain","wannier90_workflows.open_grid":"aiida_wannier90_workflows.workflows.open_grid:Wannier90OpenGridWorkChain","wannier90_workflows.optimize":"aiida_wannier90_workflows.workflows.optimize:Wannier90OptimizeWorkChain","wannier90_workflows.projwfcbands":"aiida_wannier90_workflows.workflows.projwfcbands:ProjwfcBandsWorkChain","wannier90_workflows.split":"aiida_wannier90_workflows.workflows.split:Wannier90SplitWorkChain","wannier90_workflows.wannier90":"aiida_wannier90_workflows.workflows.wannier90:Wannier90WorkChain"},console_scripts:{"aiida-wannier90-workflows":"aiida_wannier90_workflows.cli:cmd_root"}},commits_count:40,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:10},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-wannier90-workflows",is_installable:"True",errors:[`Failed to fetch entry point metadata for package aiida_wannier90_workflows
Traceback (most recent call last):
  File "/opt/conda/lib/python3.9/site-packages/plumpy/processes.py", line 185, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'Protect' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.9/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "/tmp/scripts/./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.9/site-packages/aiida/engine/processes/workchains/workchain.py", line 138, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.9/site-packages/aiida/engine/processes/process.py", line 88, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.9/site-packages/plumpy/processes.py", line 190, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.9/site-packages/aiida_wannier90_workflows/workflows/bands.py", line 50, in define
    super().define(spec)
  File "/opt/conda/lib/python3.9/site-packages/aiida_wannier90_workflows/workflows/open_grid.py", line 45, in define
    super().define(spec)
  File "/opt/conda/lib/python3.9/site-packages/aiida_wannier90_workflows/workflows/wannier90.py", line 109, in define
    spec.inputs["nscf"]["pw"].validator = PwCalculation.validate_inputs_base
AttributeError: type object 'PwCalculation' has no attribute 'validate_inputs_base'
`]},"aiida-wien2k":{code_home:"https://github.com/rubel75/aiida-wien2k",entry_point_prefix:"wien2k",name:"aiida-wien2k",package_name:"aiida_wien2k",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:7,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-yambo":{code_home:"https://github.com/yambo-code/yambo-aiida/",development_status:"stable",entry_point_prefix:"yambo",pip_url:"aiida-yambo",plugin_info:"https://raw.github.com/yambo-code/yambo-aiida/master/setup.json",name:"aiida-yambo",package_name:"aiida_yambo",hosted_on:"github.com",metadata:{release_date:"2020-11-05",description:"YAMBO plugin and workflows for AiiDA",author:"Miki Bonacci, Michael Atambo, Antimo Marrazzo, Prandini Gianluca",author_email:"miki.bonacci@unimore.it",license:"MIT",home_page:"https://github.com/yambo-code/yambo-aiida",classifiers:["Environment :: Plugins","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Topic :: Scientific/Engineering :: Physics"],version:"1.3.0"},aiida_version:">=1.0.0a2",entry_points:{"aiida.calculations":{"yambo.yambo":{description:["AiiDA plugin for the Yambo code.","    For more information, refer to http://www.yambo-code.org/","    https://github.com/yambo-code/yambo-aiida and http://aiida-yambo.readthedocs.io/en/latest/"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"Use a main code for yambo calculation"},{name:"parameters",required:!0,valid_types:"Dict",info:"Use a node that specifies the input parameters"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:'Use a remote folder as parent folder (for "restarts and similar"'},{name:"settings",required:!0,valid_types:"Dict",info:"Use an additional node for special settings"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"precode_parameters",required:!1,valid_types:"Dict",info:"Use a node that specifies the input parameters for the yambo precode"},{name:"preprocessing_code",required:!1,valid_types:"Code",info:"Use a preprocessing code for starting yambo"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"returns the output parameters"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array_alpha",required:!1,valid_types:"ArrayData",info:"returns the alpha array"},{name:"array_alpha_array",required:!1,valid_types:"ArrayData",info:"returns the alpha array"},{name:"array_alpha_bands",required:!1,valid_types:"ArrayData",info:"returns the alpha array bands"},{name:"array_eels",required:!1,valid_types:"ArrayData",info:"returns the eels array"},{name:"array_eps",required:!1,valid_types:"ArrayData",info:"returns the eps array"},{name:"array_ndb",required:!1,valid_types:"ArrayData",info:"returns the array for ndb"},{name:"array_ndb_HFlocXC",required:!1,valid_types:"ArrayData",info:"returns the array ndb for HFlocXC"},{name:"array_ndb_QP",required:!1,valid_types:"ArrayData",info:"returns the array for ndbQP"},{name:"array_qp",required:!1,valid_types:"ArrayData",info:"returns the quasiparticle array band structure"},{name:"bands_quasiparticle",required:!1,valid_types:"BandsData",info:"returns the quasiparticle band structure"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"system_info",required:!1,valid_types:"Dict",info:"returns some system information after a p2y"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:500,message:"The retrieved folder data node could not be accessed."},{status:501,message:"time exceeded the max walltime"},{status:502,message:"failed calculation for some reason: could be a low number of conduction bands"},{status:503,message:"Unexpected behavior of YamboFolder"},{status:504,message:"parallelization error"},{status:505,message:"general memory error"},{status:506,message:"x_par allocation memory error"}]},class:"aiida_yambo.calculations.yambo:YamboCalculation"}},"aiida.data":{},"aiida.parsers":{"yambo.yambo":"aiida_yambo.parsers.parsers:YamboParser"}},commits_count:77,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-yambo",is_installable:"True"},"aiida-yambo-wannier90":{code_home:"https://github.com/aiidaplugins/aiida-yambo-wannier90",entry_point_prefix:"yambo_wannier90",pip_url:"aiida-yambo-wannier90",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-yambo-wannier90/main/pyproject.toml",documentation_url:"https://aiida-yambo-wannier90.readthedocs.io/en/latest/",version_file:"https://raw.githubusercontent.com/aiidaplugins/aiida-yambo-wannier90/main/aiida_yambo_wannier90/__init__.py",name:"aiida-yambo-wannier90",package_name:"aiida_yambo_wannier90",hosted_on:"github.com",metadata:{release_date:"2022-07-06",description:"Plugin to combine Wannier90 interpolations with GW corrections computed by Yambo",author:"The AiiDA Team",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0b0"},aiida_version:">=1.6.4,<3",entry_points:{"aiida.calculations":{"yambo_wannier90.gw2wannier90":"aiida_yambo_wannier90.calculations.gw2wannier90:Gw2wannier90Calculation"},"aiida.parsers":{"yambo_wannier90.gw2wannier90":"aiida_yambo_wannier90.parsers.gw2wannier90:Gw2wannier90Parser"},"aiida.workflows":{yambo_wannier90:"aiida_yambo_wannier90.workflows:YamboWannier90WorkChain"},console_scripts:{"aiida-yambo-wannier90":"aiida_yambo_wannier90.cli:cmd_root"}},commits_count:0,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install --pre aiida-yambo-wannier90",is_installable:"False",errors:[`Failed to install plugin aiida-yambo-wannier90
Collecting aiida-yambo-wannier90
  Downloading aiida_yambo_wannier90-0.1.0b0-py3-none-any.whl (27 kB)
Requirement already satisfied: aiida-core<3,>=1.6.4 in /opt/conda/lib/python3.9/site-packages (from aiida-yambo-wannier90) (2.4.0.post0)
Collecting voluptuous (from aiida-yambo-wannier90)
  Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)
Collecting aiida-yambo>=1.3.0 (from aiida-yambo-wannier90)
  Downloading aiida_yambo-1.3.0-py3-none-any.whl (57 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.8/57.8 kB 18.9 MB/s eta 0:00:00
Collecting aiida-wannier90-workflows>=1.0.1 (from aiida-yambo-wannier90)
  Obtaining dependency information for aiida-wannier90-workflows>=1.0.1 from https://files.pythonhosted.org/packages/fd/b8/41d408f6f17f79e95e01c15192d31b941f0393fe9c7d0f0f6787fc9886ce/aiida_wannier90_workflows-2.1.0-py3-none-any.whl.metadata
  Downloading aiida_wannier90_workflows-2.1.0-py3-none-any.whl.metadata (4.7 kB)
Requirement already satisfied: alembic~=1.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.12.0)
Requirement already satisfied: archive-path~=0.4.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.4.2)
Requirement already satisfied: aio-pika~=6.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.8.1)
Requirement already satisfied: circus~=0.18.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.18.0)
Requirement already satisfied: click-spinner~=0.1.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.1.10)
Requirement already satisfied: click~=8.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (8.1.7)
Requirement already satisfied: disk-objectstore~=0.6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.6.0)
Requirement already satisfied: docstring-parser in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.15)
Requirement already satisfied: get-annotations~=0.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.1.2)
Requirement already satisfied: graphviz~=0.19 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.20.1)
Requirement already satisfied: ipython>=7 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (8.15.0)
Requirement already satisfied: jinja2~=3.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.1.2)
Requirement already satisfied: jsonschema~=3.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.2.0)
Requirement already satisfied: kiwipy[rmq]~=0.7.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.7.7)
Requirement already satisfied: importlib-metadata~=4.13 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.13.0)
Requirement already satisfied: numpy~=1.21 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.25.2)
Requirement already satisfied: paramiko>=2.7.2,~=2.7 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.12.0)
Requirement already satisfied: plumpy~=0.21.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.21.8)
Requirement already satisfied: pgsu~=0.2.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.4)
Requirement already satisfied: psutil~=5.6 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (5.9.5)
Requirement already satisfied: psycopg2-binary~=2.8 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.9.7)
Requirement already satisfied: pytz~=2021.1 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2021.3)
Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.0.1)
Requirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.31.0)
Requirement already satisfied: sqlalchemy~=1.4.22 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.4.49)
Requirement already satisfied: tabulate~=0.8.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.8.10)
Requirement already satisfied: tqdm~=4.45 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.66.1)
Requirement already satisfied: upf_to_json~=0.9.2 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.9.5)
Requirement already satisfied: wrapt~=1.11 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.15.0)
Collecting aiida-pseudo>=0.6 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-pseudo>=0.6 from https://files.pythonhosted.org/packages/6a/96/203eb64f3775f093e6ff0c17aeea52c3d127759d18542a58663dd7822e5c/aiida_pseudo-1.2.0-py3-none-any.whl.metadata
  Downloading aiida_pseudo-1.2.0-py3-none-any.whl.metadata (10 kB)
Collecting aiida-quantumespresso>=4.3 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-quantumespresso>=4.3 from https://files.pythonhosted.org/packages/44/b7/dd5cc31567b448f5fa84cdbb2d80ce51e07267868cac3d21525df9d0a6ed/aiida_quantumespresso-4.4.0-py3-none-any.whl.metadata
  Downloading aiida_quantumespresso-4.4.0-py3-none-any.whl.metadata (32 kB)
Collecting aiida-wannier90>=2.1 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-wannier90>=2.1 from https://files.pythonhosted.org/packages/52/da/4215feadd7ec82c13834fed9ed4f4bbc18b36b3b2fbc0bdb0d9765e9e0b8/aiida_wannier90-2.1.0-py3-none-any.whl.metadata
  Downloading aiida_wannier90-2.1.0-py3-none-any.whl.metadata (4.1 kB)
Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90) (0.4.6)
INFO: pip is looking at multiple versions of aiida-yambo to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-wannier90-workflows>=1.0.1 (from aiida-yambo-wannier90)
  Downloading aiida_wannier90_workflows-1.0.2-py3-none-any.whl (22 kB)
Collecting aiida-core<3,>=1.6.4 (from aiida-yambo-wannier90)
  Downloading aiida_core-1.6.9-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 61.0 MB/s eta 0:00:00
Collecting aiida-quantumespresso>=3.0.0a6 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading aiida_quantumespresso-3.5.2-py3-none-any.whl (729 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 729.3/729.3 kB 84.5 MB/s eta 0:00:00
Collecting netcdf4 (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for netcdf4 from https://files.pythonhosted.org/packages/f9/06/d677c7c5e9c46ddbbc07a7952bfe931f4a598eef0dea7683cb7c1a08cdcf/netCDF4-1.6.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading netCDF4-1.6.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting h5py (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for h5py from https://files.pythonhosted.org/packages/4f/79/8e6e05bc4954ebdb8b9c587f780a11f28790585798bd15a8e4870cfc02bc/h5py-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading h5py-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)
Collecting pytest (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for pytest from https://files.pythonhosted.org/packages/df/d0/e192c4275aecabf74faa1aacd75ef700091913236ec78b1a98f62a2412ee/pytest-7.4.2-py3-none-any.whl.metadata
  Downloading pytest-7.4.2-py3-none-any.whl.metadata (7.9 kB)
Collecting psycopg2-binary<2.9 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading psycopg2_binary-2.8.6-cp39-cp39-manylinux1_x86_64.whl (3.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 100.7 MB/s eta 0:00:00
Collecting aiida-pseudo~=0.6.1 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-pseudo~=0.6.1 from https://files.pythonhosted.org/packages/b7/6d/8432b84a538ac479235b043cb7ce1eba59e8f8c195a369a52395f41bf5e6/aiida_pseudo-0.6.5-py3-none-any.whl.metadata
  Downloading aiida_pseudo-0.6.5-py3-none-any.whl.metadata (3.3 kB)
Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90) (23.1)
Collecting qe-tools~=2.0rc1 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading qe_tools-2.0.0-py3-none-any.whl (23 kB)
Collecting xmlschema>=1.2.5,~=1.2 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading xmlschema-1.11.3-py3-none-any.whl (356 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 356.5/356.5 kB 76.6 MB/s eta 0:00:00
Collecting importlib_resources (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Obtaining dependency information for importlib_resources from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata
  Downloading importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)
Collecting aldjemy~=0.9.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading aldjemy-0.9.1-py3-none-any.whl (26 kB)
Collecting archive-path~=0.2.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading archive_path-0.2.1-py3-none-any.whl (17 kB)
Collecting circus~=0.17.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading circus-0.17.2-py3-none-any.whl (204 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 204.2/204.2 kB 49.1 MB/s eta 0:00:00
Collecting click-completion~=0.5.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading click-completion-0.5.2.tar.gz (10 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting click-config-file~=0.6.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading click_config_file-0.6.0-py2.py3-none-any.whl (6.0 kB)
Collecting click~=7.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 25.1 MB/s eta 0:00:00
Collecting django~=2.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Django-2.2.28-py3-none-any.whl (7.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.5/7.5 MB 86.7 MB/s eta 0:00:00
Collecting ete3~=3.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading ete3-3.1.3.tar.gz (4.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 66.3 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting ipython~=7.20 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 793.8/793.8 kB 61.5 MB/s eta 0:00:00
Collecting jinja2~=2.10 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 39.8 MB/s eta 0:00:00
Collecting markupsafe<2.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading MarkupSafe-2.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)
Requirement already satisfied: pamqp~=2.3 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.3.0)
Collecting plumpy~=0.20.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading plumpy-0.20.0-py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 13.7 MB/s eta 0:00:00
Collecting python-dateutil~=2.8 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 57.9 MB/s eta 0:00:00
Collecting pytz~=2019.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 kB 86.6 MB/s eta 0:00:00
Collecting pyyaml~=5.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 630.1/630.1 kB 85.7 MB/s eta 0:00:00
Collecting reentry~=1.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading reentry-1.3.3-py3-none-any.whl (17 kB)
Collecting simplejson~=3.16 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading simplejson-3.19.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.4/137.4 kB 36.9 MB/s eta 0:00:00
Collecting sqlalchemy-utils~=0.36.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading SQLAlchemy-Utils-0.36.5.tar.gz (131 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.2/131.2 kB 40.4 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sqlalchemy~=1.3.10 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading SQLAlchemy-1.3.24-cp39-cp39-manylinux2010_x86_64.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 103.1 MB/s eta 0:00:00
Collecting tzlocal~=2.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)
Collecting wrapt~=1.11.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading wrapt-1.11.2.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
INFO: pip is looking at multiple versions of aiida-core[atomic-tools,docs] to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-core[atomic_tools,docs]>=1.0.0a2 (from aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Obtaining dependency information for aiida-core[atomic_tools,docs]>=1.0.0a2 from https://files.pythonhosted.org/packages/2b/ec/a99338a82592fb94c5741288143d34281162fe4e19228e059cfec67d5589/aiida_core-2.4.0-py3-none-any.whl.metadata
  Downloading aiida_core-2.4.0-py3-none-any.whl.metadata (10 kB)
  Obtaining dependency information for aiida-core[atomic_tools,docs]>=1.0.0a2 from https://files.pythonhosted.org/packages/d9/96/c88f1af662144765c15acdbada6d33f92e57a0c2311f6aa09fa8fcc7c91a/aiida_core-2.3.1-py3-none-any.whl.metadata
  Downloading aiida_core-2.3.1-py3-none-any.whl.metadata (11 kB)
  Downloading aiida_core-2.3.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 104.7 MB/s eta 0:00:00
  Downloading aiida_core-2.2.2-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 105.6 MB/s eta 0:00:00
  Downloading aiida_core-2.2.1-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 110.6 MB/s eta 0:00:00
  Downloading aiida_core-2.2.0-py3-none-any.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 108.5 MB/s eta 0:00:00
  Downloading aiida_core-2.1.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 64.8 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of aiida-core[atomic-tools,docs] to determine which version is compatible with other requirements. This could take a while.
  Downloading aiida_core-2.1.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 94.4 MB/s eta 0:00:00
  Downloading aiida_core-2.1.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 108.0 MB/s eta 0:00:00
  Downloading aiida_core-2.0.4-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 111.3 MB/s eta 0:00:00
  Downloading aiida_core-2.0.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 99.3 MB/s eta 0:00:00
  Downloading aiida_core-2.0.2-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 108.6 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading aiida_core-2.0.1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 100.9 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 109.8 MB/s eta 0:00:00
  Downloading aiida_core-2.0.0b1-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 105.3 MB/s eta 0:00:00
Collecting PyCifRW~=4.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading PyCifRW-4.4.5-cp39-cp39-manylinux_2_5_x86_64.whl (162 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.4/162.4 kB 53.4 MB/s eta 0:00:00
Collecting ase~=3.18 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 106.5 MB/s eta 0:00:00
Collecting matplotlib>=3.3.4,~=3.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for matplotlib>=3.3.4,~=3.3 from https://files.pythonhosted.org/packages/e0/8b/b62bc50b01bb2d4af96bc0045c39d60209e2701e172789ceace20a0866b2/matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)
Collecting pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pymatgen-2022.2.1.tar.gz (2.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 103.0 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Installing backend dependencies: started
  Installing backend dependencies: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting pymysql~=0.9.3 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading PyMySQL-0.9.3-py2.py3-none-any.whl (47 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.7/47.7 kB 14.9 MB/s eta 0:00:00
Collecting seekpath>=1.9.3,~=1.9 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading seekpath-1.9.7-py2.py3-none-any.whl (86 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.9/86.9 kB 26.9 MB/s eta 0:00:00
Collecting spglib~=1.14 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading spglib-1.16.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 325.5/325.5 kB 71.3 MB/s eta 0:00:00
Collecting sphinx-copybutton~=0.3.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinx_copybutton-0.3.3-py3-none-any.whl (12 kB)
Collecting sphinxcontrib-details-directive~=0.1.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinxcontrib_details_directive-0.1.0-py2.py3-none-any.whl (10 kB)
Collecting pydata-sphinx-theme~=0.4.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pydata_sphinx_theme-0.4.3-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 102.5 MB/s eta 0:00:00
Collecting sphinx~=3.2.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Sphinx-3.2.1-py3-none-any.whl (2.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 122.0 MB/s eta 0:00:00
Requirement already satisfied: pygments~=2.5 in /opt/conda/lib/python3.9/site-packages (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.16.1)
Collecting sphinx-notfound-page~=0.5 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinx_notfound_page-0.8.3-py2.py3-none-any.whl (8.5 kB)
Collecting flask-restful~=0.3.7 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for flask-restful~=0.3.7 from https://files.pythonhosted.org/packages/d7/7b/f0b45f0df7d2978e5ae51804bb5939b7897b2ace24306009da0cc34d8d1f/Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata
  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata (1.0 kB)
Collecting pyparsing~=2.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 24.6 MB/s eta 0:00:00
Collecting sphinx-panels~=0.5.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinx_panels-0.5.2-py3-none-any.whl (87 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.8/87.8 kB 29.6 MB/s eta 0:00:00
Collecting docutils==0.15.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 547.6/547.6 kB 93.1 MB/s eta 0:00:00
Collecting flask~=1.1 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Flask-1.1.4-py2.py3-none-any.whl (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.6/94.6 kB 32.5 MB/s eta 0:00:00
Collecting flask-cors~=3.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)
Collecting python-memcached~=1.59 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading python_memcached-1.59-py2.py3-none-any.whl (16 kB)
Collecting sphinxext-rediraffe~=0.2.4 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinxext_rediraffe-0.2.7-py3-none-any.whl (8.3 kB)
INFO: pip is looking at multiple versions of aiida-wannier90 to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-wannier90>=2.0.0 (from aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading aiida_wannier90-2.0.1-py2.py3-none-any.whl (28 kB)
Requirement already satisfied: aiormq<4,>=3.2.3 in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.3.1)
Requirement already satisfied: yarl in /opt/conda/lib/python3.9/site-packages (from aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.9.2)
Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.2.4)
Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.9/site-packages (from alembic~=1.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.7.1)
Requirement already satisfied: pyzmq>=17.0 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (25.1.1)
Requirement already satisfied: tornado>=5.0.2 in /opt/conda/lib/python3.9/site-packages (from circus~=0.17.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.3.3)
Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from click-completion~=0.5.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.16.0)
Collecting shellingham (from click-completion~=0.5.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for shellingham from https://files.pythonhosted.org/packages/57/70/0265437683625b2e6491736706d3d679d90e2a26f6bff59f4e46e09872b9/shellingham-1.5.3-py2.py3-none-any.whl.metadata
  Downloading shellingham-1.5.3-py2.py3-none-any.whl.metadata (3.4 kB)
Collecting configobj>=5.0.6 (from click-config-file~=0.6.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)
Collecting sqlparse>=0.2.2 (from django~=2.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 15.8 MB/s eta 0:00:00
Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (68.1.2)
Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.19.0)
Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (5.1.1)
Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.7.5)
Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (5.9.0)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.0.39)
Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.0)
Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.1.6)
Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.8.0)
Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (23.1.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema~=3.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.19.3)
Requirement already satisfied: shortuuid in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.0.11)
Requirement already satisfied: async-generator in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.10)
Requirement already satisfied: pytray<0.4.0,>=0.2.2 in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.3.4)
Requirement already satisfied: deprecation in /opt/conda/lib/python3.9/site-packages (from kiwipy[rmq]~=0.7.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.1.0)
INFO: pip is looking at multiple versions of kiwipy[rmq] to determine which version is compatible with other requirements. This could take a while.
Collecting kiwipy[rmq]~=0.7.5 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading kiwipy-0.7.6-py3-none-any.whl (29 kB)
Requirement already satisfied: bcrypt>=3.1.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (4.0.1)
Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (41.0.3)
Requirement already satisfied: pynacl>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.5.0)
Collecting nest-asyncio~=1.4.0 (from plumpy~=0.20.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)
Collecting cftime (from netcdf4->aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Downloading cftime-1.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 101.0 MB/s eta 0:00:00
Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from netcdf4->aiida-yambo>=1.3.0->aiida-yambo-wannier90) (2023.7.22)
Collecting iniconfig (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.9/site-packages (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90) (1.3.0)
Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.9/site-packages (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90) (1.1.3)
Collecting tomli>=1.0.0 (from pytest->aiida-yambo>=1.3.0->aiida-yambo-wannier90)
  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)
Collecting pint~=0.16.1 (from aiida-pseudo~=0.6.1->aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading Pint-0.16.1-py2.py3-none-any.whl (205 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 205.9/205.9 kB 56.5 MB/s eta 0:00:00
Collecting scipy>=1.1.0 (from ase~=3.18->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for scipy>=1.1.0 from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 18.7 MB/s eta 0:00:00
Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (1.15.1)
Collecting Werkzeug<2.0,>=0.15 (from flask~=1.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.6/298.6 kB 70.4 MB/s eta 0:00:00
Collecting itsdangerous<2.0,>=0.24 (from flask~=1.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting aniso8601>=0.82 (from flask-restful~=0.3.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 18.8 MB/s eta 0:00:00
Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.8.3)
Collecting contourpy>=1.0.1 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/2b/c0/24c34c41a180f875419b536125799c61e2330b997d77a5a818a3bc3e08cd/contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)
Collecting cycler>=0.10 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/49/50/2e31753c088d364756daa5bed0dab6a5928ebfd6e6d26f975c8b6d6f754a/fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading fonttools-4.42.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.0/151.0 kB 46.5 MB/s eta 0:00:00
Collecting kiwisolver>=1.0.1 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata
  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)
Collecting pillow>=6.2.0 (from matplotlib>=3.3.4,~=3.3->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/0a/20/a94a0462495de73e248643fb24667270f2e67f44792456ab7207764e80cc/Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata
  Downloading Pillow-10.0.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from importlib_resources->aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90) (3.16.2)
Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.7.0)
Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython~=7.20->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.6)
Requirement already satisfied: ruamel.yaml>=0.15.6 in /opt/conda/lib/python3.9/site-packages (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.17.32)
Collecting monty>=3.0.2 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for monty>=3.0.2 from https://files.pythonhosted.org/packages/e4/f6/48d2daf13a8bc8f636091a1465a037ac5804268cef22d03e2d7ccef6ee90/monty-2023.9.5-py3-none-any.whl.metadata
  Downloading monty-2023.9.5-py3-none-any.whl.metadata (2.9 kB)
Collecting networkx>=2.2 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 106.3 MB/s eta 0:00:00
Collecting palettable>=3.1.1 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading palettable-3.3.3-py2.py3-none-any.whl (332 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 332.3/332.3 kB 73.8 MB/s eta 0:00:00
Collecting sympy (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 121.3 MB/s eta 0:00:00
Collecting pandas (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/83/f0/2765daac3c58165460b127df5c0ef7b3a039f3bfe7ea7a51f3d20b01371b/pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Collecting plotly>=4.5.0 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for plotly>=4.5.0 from https://files.pythonhosted.org/packages/df/79/c80174d711ee26ee5da55a9cc3e248f1ec7a0188b5e4d6bbbbcd09b974b0/plotly-5.17.0-py2.py3-none-any.whl.metadata
  Downloading plotly-5.17.0-py2.py3-none-any.whl.metadata (7.0 kB)
Collecting uncertainties>=3.1.4 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading uncertainties-3.1.7-py2.py3-none-any.whl (98 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.4/98.4 kB 36.4 MB/s eta 0:00:00
Collecting Cython>=0.29.23 (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for Cython>=0.29.23 from https://files.pythonhosted.org/packages/18/f1/c3918a7a367a17d5c07d8e576c51ba78fc807f214f748026876352f8b0c2/Cython-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Using cached Cython-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)
Collecting pybtex (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 561.4/561.4 kB 90.9 MB/s eta 0:00:00
Collecting future>=0.15 (from seekpath>=1.9.3,~=1.9->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading future-0.18.3.tar.gz (840 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 840.9/840.9 kB 101.4 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sphinxcontrib-applehelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/c0/0c/261c0949083c0ac635853528bb0070c89e927841d4e533ba0b5563365c06/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata
  Downloading sphinxcontrib_applehelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)
Collecting sphinxcontrib-devhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/c0/03/010ac733ec7b7f71c1dc88e7115743ee466560d6d85373b56fb9916e4586/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata
  Downloading sphinxcontrib_devhelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)
Collecting sphinxcontrib-jsmath (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)
Collecting sphinxcontrib-htmlhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-htmlhelp from https://files.pythonhosted.org/packages/28/7a/958f8e3e6abe8219d0d1f1224886de847ab227b218f4a07b61bc337f64be/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata
  Downloading sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl.metadata (2.2 kB)
Collecting sphinxcontrib-serializinghtml (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/95/d6/2e0bda62b2a808070ac922d21a950aa2cb5e4fcfb87e5ff5f86bc43a2201/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl.metadata (2.3 kB)
Collecting sphinxcontrib-qthelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/1f/e5/1850f3f118e95581c1e30b57028ac979badee1eb29e70ee72b0241f5a185/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata
  Downloading sphinxcontrib_qthelp-1.0.6-py3-none-any.whl.metadata (2.2 kB)
Collecting snowballstemmer>=1.1 (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.0/93.0 kB 32.3 MB/s eta 0:00:00
Collecting babel>=1.3 (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 106.9 MB/s eta 0:00:00
Collecting alabaster<0.8,>=0.7 (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)
Collecting imagesize (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)
Collecting elementpath<3.0.0,>=2.5.0 (from xmlschema>=1.2.5,~=1.2->aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading elementpath-2.5.3-py3-none-any.whl (181 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.4/181.4 kB 50.7 MB/s eta 0:00:00
Requirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (6.0.4)
Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.9/site-packages (from yarl->aio-pika~=6.6->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.4)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko>=2.7.2,~=2.7->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.21)
Collecting tenacity>=6.2.0 (from plotly>=4.5.0->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for tenacity>=6.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata
  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (3.2.0)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests~=2.0->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (2.0.4)
Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.9/site-packages (from ruamel.yaml>=0.15.6->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90) (0.2.7)
INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.
Collecting pandas (from pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/9f/80/5faa1875236ded526a5572bf1f2bdd3c46ec4dcc0e5b49b3b8a889a7b567/pandas-2.1.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.1.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/9e/0d/91a9fd2c202f2b1d97a38ab591890f86480ecbb596cbc56d035f6f23fdcc/pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/9f/cc/cc8135de2a574fd87940b1d41c9c52d226d3ebc9fc8f6e9f18a7b0a81b57/pandas-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pandas-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
  Downloading pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 113.6 MB/s eta 0:00:00
  Downloading pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 100.5 MB/s eta 0:00:00
  Downloading pandas-2.0.0rc1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 101.7 MB/s eta 0:00:00
  Downloading pandas-2.0.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 102.7 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.
  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 103.0 MB/s eta 0:00:00
  Downloading pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 113.9 MB/s eta 0:00:00
  Downloading pandas-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 115.5 MB/s eta 0:00:00
  Downloading pandas-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 94.6 MB/s eta 0:00:00
  Downloading pandas-1.5.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 107.5 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 117.6 MB/s eta 0:00:00
  Downloading pandas-1.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 104.4 MB/s eta 0:00:00
  Downloading pandas-1.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 96.7 MB/s eta 0:00:00
  Downloading pandas-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 116.3 MB/s eta 0:00:00
  Downloading pandas-1.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 105.3 MB/s eta 0:00:00
  Downloading pandas-1.4.0rc0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 104.6 MB/s eta 0:00:00
  Downloading pandas-1.3.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.5/11.5 MB 107.0 MB/s eta 0:00:00
Collecting latexcodec>=1.0.4 (from pybtex->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)
INFO: pip is looking at multiple versions of sphinxcontrib-applehelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-applehelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/b1/db/2c9a62f9d7c8abf45fa79d28a9d0c80e16cb42deac58a699cbd952efda1a/sphinxcontrib_applehelp-1.0.6-py3-none-any.whl.metadata
  Downloading sphinxcontrib_applehelp-1.0.6-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-applehelp from https://files.pythonhosted.org/packages/57/57/1cdaff9321329139ffb0616b9907f2ddf46fa9a6a9488a93f049b2325472/sphinxcontrib_applehelp-1.0.5-py3-none-any.whl.metadata
  Downloading sphinxcontrib_applehelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 120.6/120.6 kB 42.2 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-devhelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-devhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/5d/b6/7f58acb86c93e54236ca8b5b79dd3873138397060a74a143b1c1e30ba6bf/sphinxcontrib_devhelp-1.0.4-py3-none-any.whl.metadata
  Downloading sphinxcontrib_devhelp-1.0.4-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-devhelp from https://files.pythonhosted.org/packages/30/68/7e7c2e823a50cc4d0835b962425924fe7006afa2bc7151a79c30b91fcf52/sphinxcontrib_devhelp-1.0.3-py3-none-any.whl.metadata
  Downloading sphinxcontrib_devhelp-1.0.3-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.7/84.7 kB 27.1 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-htmlhelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-htmlhelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-htmlhelp from https://files.pythonhosted.org/packages/d0/a1/5b678486ce3f7f3135ac5396db4591e967fc6709f27aa57fe13c97180953/sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl.metadata
  Downloading sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-htmlhelp from https://files.pythonhosted.org/packages/57/41/ad44d14fd5273a7b20905fa4dd8444abf1795f6581666f6272e7d8cabf5a/sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl.metadata
  Downloading sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.8/99.8 kB 33.6 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-qthelp to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-qthelp (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/c1/54/d3f8d78634c43be776bbec969cce56cf6a6ba49fc950774179b6cc20176b/sphinxcontrib_qthelp-1.0.5-py3-none-any.whl.metadata
  Downloading sphinxcontrib_qthelp-1.0.5-py3-none-any.whl.metadata (2.2 kB)
  Obtaining dependency information for sphinxcontrib-qthelp from https://files.pythonhosted.org/packages/8d/57/6edeb937dbc2858d980242ffc5913303c19774048b68654e5bee9556e146/sphinxcontrib_qthelp-1.0.4-py3-none-any.whl.metadata
  Downloading sphinxcontrib_qthelp-1.0.4-py3-none-any.whl.metadata (2.2 kB)
  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.6/90.6 kB 35.4 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of sphinxcontrib-serializinghtml to determine which version is compatible with other requirements. This could take a while.
Collecting sphinxcontrib-serializinghtml (from sphinx~=3.2.1->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/dc/85/ea34b6be0494eff8ae281107bb4a83f6c83066b358f2525a251dc852817c/sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl.metadata (2.3 kB)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/36/c6/0d5b3f258fdb107558163e88607eb6c245d8785fbd707e027f2da7fbc795/sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl.metadata (2.3 kB)
  Obtaining dependency information for sphinxcontrib-serializinghtml from https://files.pythonhosted.org/packages/82/a2/962548d13ceddff95eac7843c9ff37b451c02b69429007b93d6a10a353d3/sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl.metadata
  Downloading sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl.metadata (2.3 kB)
  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.0/94.0 kB 36.9 MB/s eta 0:00:00
Collecting mpmath>=0.19 (from sympy->pymatgen!=2019.9.7,<=2022.02.03,>=2019.7.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 93.5 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of disk-objectstore to determine which version is compatible with other requirements. This could take a while.
Collecting aiida-pseudo~=0.6.1 (from aiida-quantumespresso>=3.0.0a6->aiida-wannier90-workflows>=1.0.1->aiida-yambo-wannier90)
  Downloading aiida_pseudo-0.6.4-py3-none-any.whl (74 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 74.0/74.0 kB 25.8 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of sphinxcontrib-serializinghtml to determine which version is compatible with other requirements. This could take a while.
  Downloading aiida_pseudo-0.6.3-py3-none-any.whl (73 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.7/73.7 kB 22.7 MB/s eta 0:00:00
INFO: pip is still looking at multiple versions of sphinxcontrib-applehelp to determine which version is compatible with other requirements. This could take a while.
INFO: pip is still looking at multiple versions of sphinxcontrib-devhelp to determine which version is compatible with other requirements. This could take a while.
INFO: pip is still looking at multiple versions of sphinxcontrib-htmlhelp to determine which version is compatible with other requirements. This could take a while.
INFO: pip is still looking at multiple versions of sphinxcontrib-qthelp to determine which version is compatible with other requirements. This could take a while.
  Downloading aiida_pseudo-0.6.2-py3-none-any.whl (73 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.2/73.2 kB 16.7 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading aiida_pseudo-0.6.1-py3-none-any.whl (68 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.7/68.7 kB 23.4 MB/s eta 0:00:00
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
INFO: pip is still looking at multiple versions of disk-objectstore to determine which version is compatible with other requirements. This could take a while.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
Collecting sqlalchemy-utils~=0.36.0 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading SQLAlchemy-Utils-0.36.4.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.6/128.6 kB 37.5 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.3.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.3/128.3 kB 39.4 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.2.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 39.5 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.1.tar.gz (128 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.0/128.0 kB 40.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading SQLAlchemy-Utils-0.36.0.tar.gz (127 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.5/127.5 kB 27.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
Collecting alembic~=1.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/a2/8b/46919127496036c8e990b2b236454a0d8655fd46e1df2fd35610a9cbc842/alembic-1.12.0-py3-none-any.whl.metadata
  Downloading alembic-1.12.0-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
INFO: pip is still looking at multiple versions of kiwipy[rmq] to determine which version is compatible with other requirements. This could take a while.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/ab/7d/b572fc6a51bc430b1fa0ef59591db32b14105093324d472eed8ea296d2df/alembic-1.11.3-py3-none-any.whl.metadata
  Downloading alembic-1.11.3-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/34/fe/eebb260c86c71d9ed861aa1434fc50601df657425b18329994af8c0bd789/alembic-1.11.2-py3-none-any.whl.metadata
  Downloading alembic-1.11.2-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/11/00/46a4f66ad54c661350a1cd5daae4b4ab2232486c55635ee12ff12958b03f/alembic-1.11.1-py3-none-any.whl.metadata
  Downloading alembic-1.11.1-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Obtaining dependency information for alembic~=1.2 from https://files.pythonhosted.org/packages/59/4d/28b13ff3a9c26988f8c32f460cc34ee806ac46038232ee493b9baaaf6164/alembic-1.11.0-py3-none-any.whl.metadata
  Downloading alembic-1.11.0-py3-none-any.whl.metadata (7.2 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.9/212.9 kB 53.7 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.3/212.3 kB 55.7 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.2/212.2 kB 55.3 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.1-py3-none-any.whl (212 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.2/212.2 kB 51.8 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.10.0-py3-none-any.whl (211 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.9/211.9 kB 53.5 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.5/210.5 kB 54.3 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.3-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.6/210.6 kB 57.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.6/210.6 kB 55.5 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.1-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.4/210.4 kB 57.9 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.9.0-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.2/210.2 kB 55.9 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.8/209.8 kB 52.0 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.3/209.3 kB 55.0 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.7/210.7 kB 56.3 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.4/210.4 kB 51.5 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.7/209.7 kB 57.1 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.4-py3-none-any.whl (209 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.1/209.1 kB 58.3 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.3-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.7/208.7 kB 53.0 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.2-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.7/208.7 kB 49.9 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.1-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.4/208.4 kB 51.0 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.7.0-py3-none-any.whl (208 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.2/208.2 kB 57.4 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 164.7/164.7 kB 47.4 MB/s eta 0:00:00
Collecting python-editor>=0.3 (from alembic~=1.2->aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
Collecting alembic~=1.2 (from aiida-core<3,>=1.6.4->aiida-yambo-wannier90)
  Downloading alembic-1.6.4-py2.py3-none-any.whl (164 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 164.7/164.7 kB 44.0 MB/s eta 0:00:00
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
WARNING: aiida-core 1.6.9 does not provide the extra 'atomic-tools'
ERROR: Exception:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/cli/base_command.py", line 180, in exc_logging_wrapper
    status = run_func(*args)
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/cli/req_command.py", line 248, in wrapper
    return func(self, options, args)
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/commands/install.py", line 377, in run
    requirement_set = resolver.resolve(
  File "/opt/conda/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py", line 92, in resolve
    result = self._result = resolver.resolve(
  File "/opt/conda/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py", line 546, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
  File "/opt/conda/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py", line 457, in resolve
    raise ResolutionTooDeep(max_rounds)
pip._vendor.resolvelib.resolvers.ResolutionTooDeep: 200000
`]},"aiida-yascheduler":{code_home:"https://github.com/tilde-lab/yascheduler",documentation_url:"https://github.com/tilde-lab/yascheduler",entry_point_prefix:"yascheduler",pip_url:"yascheduler",plugin_info:"https://raw.githubusercontent.com/tilde-lab/yascheduler/master/setup.json",name:"aiida-yascheduler",package_name:"aiida_yascheduler",hosted_on:"github.com",metadata:{release_date:"2023-07-29",description:"Yet another computing scheduler and cloud orchestration engine",author:"Andrey Sobolev",author_email:"Evgeny Blokhin <eb@tilde.pro>, Sergei Korolev <knopki@duck.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Information Analysis","Topic :: Scientific/Engineering :: Physics","Topic :: Software Development :: Libraries :: Python Modules"],version:"1.2.0"},aiida_version:null,entry_points:{"aiida.schedulers":{yascheduler:"yascheduler.aiida_plugin:YaScheduler"},console_scripts:{yainit:"yascheduler.utils:init",yanodes:"yascheduler.utils:show_nodes",yascheduler:"yascheduler.utils:daemonize",yasetnode:"yascheduler.utils:manage_node",yastatus:"yascheduler.utils:check_status",yasubmit:"yascheduler.utils:submit"}},commits_count:54,development_status:"beta",warnings:["AiiDA version not found"],summaryinfo:[{colorclass:"purple",text:"Console scripts",count:6},{colorclass:"orange",text:"Other (Schedulers)",count:1}],pip_install_cmd:"pip install yascheduler",is_installable:"True",errors:[`Failed to import package aiida_yascheduler
Traceback (most recent call last):
  File "<string>", line 1, in <module>
ModuleNotFoundError: No module named 'aiida_yascheduler'
`]},"aiida-z2pack":{code_home:"https://github.com/AntimoMarrazzo/aiida-z2pack",entry_point_prefix:"z2pack",pip_url:"git+https://github.com/AntimoMarrazzo/aiida-z2pack",name:"aiida-z2pack",package_name:"aiida_z2pack",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:18,development_status:"planning",warnings:["  > WARNING! Unable to retrieve plugin info from: https://raw.githubusercontent.com/antimomarrazzo/aiida-z2pack/master/setup.json","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/AntimoMarrazzo/aiida-z2pack"},"aiida-zeopp":{code_home:"https://github.com/lsmo-epfl/aiida-zeopp",development_status:"stable",entry_point_prefix:"zeopp",pip_url:"aiida-zeopp",plugin_info:"https://raw.github.com/lsmo-epfl/aiida-zeopp/master/setup.json",name:"aiida-zeopp",package_name:"aiida_zeopp",hosted_on:"github.com",metadata:{release_date:"2023-08-26",description:"AiiDA plugin for zeo++",author_email:"Leopold Talirz <leopold.talirz@epfl.ch>, Miriam Pougin <miriam.pougin@epfl.ch>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"zeopp.network":{description:["AiiDA calculation plugin for the zeo++ network binary"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"NetworkParameters",info:"command line parameters for zeo++"},{name:"structure",required:!0,valid_types:"CifData",info:"input structure to be analyzed"},{name:"atomic_radii",required:!1,valid_types:"SinglefileData, NoneType",info:"atomic radii file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"key-value pairs parsed from zeo++ output file(s)."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"block",required:!1,valid_types:"SinglefileData",info:"Blocked pockets fileoutput file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation completed successfully."},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"Not all expected output files were found."},{status:102,message:"Empty block file. This indicates the calculation of blocked pockets did not finish."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_zeopp.calculations.network:NetworkCalculation"}},"aiida.data":{"zeopp.parameters":"aiida_zeopp.data.parameters:NetworkParameters"},"aiida.parsers":{"zeopp.network":"aiida_zeopp.parsers.network:NetworkParser"}},commits_count:4,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install aiida-zeopp",is_installable:"True"}},mv=[{name:"Calculations",colorclass:"blue",num_entries:54,total_num:132},{name:"Parsers",colorclass:"brown",num_entries:54,total_num:109},{name:"Data",colorclass:"red",num_entries:30,total_num:103},{name:"Workflows",colorclass:"green",num_entries:40,total_num:143},{name:"Console scripts",colorclass:"purple",num_entries:16,total_num:27},{name:"Other",tooltip:"Aenet potentials, Calculations importers, Calculations monitors, ...",colorclass:"orange",num_entries:26,total_num:99}],fv={planning:["Not yet ready to use. Developers welcome!","status-planning-d9644d.svg"],"pre-alpha":["Not yet ready to use. Developers welcome!","status-planning-d9644d.svg"],alpha:["Adds new functionality, not yet ready for production. Testing welcome!","status-alpha-d6af23.svg"],beta:["Adds new functionality, not yet ready for production. Testing welcome!","status-beta-d6af23.svg"],stable:["Ready for production calculations. Bug reports welcome!","status-stable-4cc61e.svg"],mature:["Ready for production calculations. Bug reports welcome!","status-stable-4cc61e.svg"],inactive:["No longer maintained.","status-inactive-bbbbbb.svg"]},hv={"aiida.calculations":"CalcJobs and calculation functions","aiida.parsers":"CalcJob parsers","aiida.data":"Data node types","aiida.cmdline.data":"verdi data commands","aiida.groups":"Group types","aiida.workflows":"WorkChains and work functions","aiida.schedulers":"Job scheduler support","aiida.transports":"Data transport protocols","aiida.tests":"Development test modules","aiida.tools.dbexporters":"Support for exporting to external databases","aiida.tools.dbimporters":"Support for importing from external databases",console_scripts:"Console scripts"},sn={plugins:pv,globalsummary:mv,status_dict:fv,entrypointtypes:hv};var bu={},ng={exports:{}};(function(e){function t(n){return n&&n.__esModule?n:{default:n}}e.exports=t,e.exports.__esModule=!0,e.exports.default=e.exports})(ng);var vu=ng.exports,Ml={};function T(){return T=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},T.apply(this,arguments)}function li(e){return e!==null&&typeof e=="object"&&e.constructor===Object}function ig(e){if(!li(e))return e;const t={};return Object.keys(e).forEach(n=>{t[n]=ig(e[n])}),t}function Bt(e,t,n={clone:!0}){const i=n.clone?T({},e):e;return li(e)&&li(t)&&Object.keys(t).forEach(a=>{a!=="__proto__"&&(li(t[a])&&a in e&&li(e[a])?i[a]=Bt(e[a],t[a],n):n.clone?i[a]=li(t[a])?ig(t[a]):t[a]:i[a]=t[a])}),i}function Kn(e){let t="https://mui.com/production-error/?code="+e;for(let n=1;n<arguments.length;n+=1)t+="&args[]="+encodeURIComponent(arguments[n]);return"Minified MUI error #"+e+"; visit "+t+" for the full message."}var ue={};/**
 * @license React
 * react-is.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var wu=Symbol.for("react.element"),xu=Symbol.for("react.portal"),qs=Symbol.for("react.fragment"),Cs=Symbol.for("react.strict_mode"),Ds=Symbol.for("react.profiler"),Ps=Symbol.for("react.provider"),Ss=Symbol.for("react.context"),yv=Symbol.for("react.server_context"),As=Symbol.for("react.forward_ref"),Es=Symbol.for("react.suspense"),Ns=Symbol.for("react.suspense_list"),Bs=Symbol.for("react.memo"),Rs=Symbol.for("react.lazy"),gv=Symbol.for("react.offscreen"),ag;ag=Symbol.for("react.module.reference");function zt(e){if(typeof e=="object"&&e!==null){var t=e.$$typeof;switch(t){case wu:switch(e=e.type,e){case qs:case Ds:case Cs:case Es:case Ns:return e;default:switch(e=e&&e.$$typeof,e){case yv:case Ss:case As:case Rs:case Bs:case Ps:return e;default:return t}}case xu:return t}}}ue.ContextConsumer=Ss;ue.ContextProvider=Ps;ue.Element=wu;ue.ForwardRef=As;ue.Fragment=qs;ue.Lazy=Rs;ue.Memo=Bs;ue.Portal=xu;ue.Profiler=Ds;ue.StrictMode=Cs;ue.Suspense=Es;ue.SuspenseList=Ns;ue.isAsyncMode=function(){return!1};ue.isConcurrentMode=function(){return!1};ue.isContextConsumer=function(e){return zt(e)===Ss};ue.isContextProvider=function(e){return zt(e)===Ps};ue.isElement=function(e){return typeof e=="object"&&e!==null&&e.$$typeof===wu};ue.isForwardRef=function(e){return zt(e)===As};ue.isFragment=function(e){return zt(e)===qs};ue.isLazy=function(e){return zt(e)===Rs};ue.isMemo=function(e){return zt(e)===Bs};ue.isPortal=function(e){return zt(e)===xu};ue.isProfiler=function(e){return zt(e)===Ds};ue.isStrictMode=function(e){return zt(e)===Cs};ue.isSuspense=function(e){return zt(e)===Es};ue.isSuspenseList=function(e){return zt(e)===Ns};ue.isValidElementType=function(e){return typeof e=="string"||typeof e=="function"||e===qs||e===Ds||e===Cs||e===Es||e===Ns||e===gv||typeof e=="object"&&e!==null&&(e.$$typeof===Rs||e.$$typeof===Bs||e.$$typeof===Ps||e.$$typeof===Ss||e.$$typeof===As||e.$$typeof===ag||e.getModuleId!==void 0)};ue.typeOf=zt;function Z(e){if(typeof e!="string")throw new Error(Kn(7));return e.charAt(0).toUpperCase()+e.slice(1)}function ed(...e){return e.reduce((t,n)=>n==null?t:function(...a){t.apply(this,a),n.apply(this,a)},()=>{})}function Os(e,t=166){let n;function i(...a){const o=()=>{e.apply(this,a)};clearTimeout(n),n=setTimeout(o,t)}return i.clear=()=>{clearTimeout(n)},i}function _v(e,t){return()=>null}function wr(e,t){return v.isValidElement(e)&&t.indexOf(e.type.muiName)!==-1}function mt(e){return e&&e.ownerDocument||document}function rn(e){return mt(e).defaultView||window}function bv(e,t){return()=>null}function es(e,t){typeof e=="function"?e(t):e&&(e.current=t)}const vv=typeof window<"u"?v.useLayoutEffect:v.useEffect,Xn=vv;let gm=0;function wv(e){const[t,n]=v.useState(e),i=e||t;return v.useEffect(()=>{t==null&&(gm+=1,n(`mui-${gm}`))},[t]),i}const _m=qr["useId".toString()];function og(e){if(_m!==void 0){const t=_m();return e??t}return wv(e)}function xv(e,t,n,i,a){return null}function td({controlled:e,default:t,name:n,state:i="value"}){const{current:a}=v.useRef(e!==void 0),[o,r]=v.useState(t),s=a?e:o,l=v.useCallback(c=>{a||r(c)},[]);return[s,l]}function fi(e){const t=v.useRef(e);return Xn(()=>{t.current=e}),v.useCallback((...n)=>(0,t.current)(...n),[])}function Ke(...e){return v.useMemo(()=>e.every(t=>t==null)?null:t=>{e.forEach(n=>{es(n,t)})},e)}let zs=!0,nd=!1,bm;const Tv={text:!0,search:!0,url:!0,tel:!0,email:!0,password:!0,number:!0,date:!0,month:!0,week:!0,time:!0,datetime:!0,"datetime-local":!0};function kv(e){const{type:t,tagName:n}=e;return!!(n==="INPUT"&&Tv[t]&&!e.readOnly||n==="TEXTAREA"&&!e.readOnly||e.isContentEditable)}function Iv(e){e.metaKey||e.altKey||e.ctrlKey||(zs=!0)}function Ll(){zs=!1}function qv(){this.visibilityState==="hidden"&&nd&&(zs=!0)}function Cv(e){e.addEventListener("keydown",Iv,!0),e.addEventListener("mousedown",Ll,!0),e.addEventListener("pointerdown",Ll,!0),e.addEventListener("touchstart",Ll,!0),e.addEventListener("visibilitychange",qv,!0)}function Dv(e){const{target:t}=e;try{return t.matches(":focus-visible")}catch{}return zs||kv(t)}function rg(){const e=v.useCallback(a=>{a!=null&&Cv(a.ownerDocument)},[]),t=v.useRef(!1);function n(){return t.current?(nd=!0,window.clearTimeout(bm),bm=window.setTimeout(()=>{nd=!1},100),t.current=!1,!0):!1}function i(a){return Dv(a)?(t.current=!0,!0):!1}return{isFocusVisibleRef:t,onFocus:i,onBlur:n,ref:e}}function sg(e){const t=e.documentElement.clientWidth;return Math.abs(window.innerWidth-t)}function lg(e,t){const n=T({},t);return Object.keys(e).forEach(i=>{if(i.toString().match(/^(components|slots)$/))n[i]=T({},e[i],n[i]);else if(i.toString().match(/^(componentsProps|slotProps)$/)){const a=e[i]||{},o=t[i];n[i]={},!o||!Object.keys(o)?n[i]=a:!a||!Object.keys(a)?n[i]=o:(n[i]=T({},o),Object.keys(a).forEach(r=>{n[i][r]=lg(a[r],o[r])}))}else n[i]===void 0&&(n[i]=e[i])}),n}function me(e,t,n=void 0){const i={};return Object.keys(e).forEach(a=>{i[a]=e[a].reduce((o,r)=>{if(r){const s=t(r);s!==""&&o.push(s),n&&n[r]&&o.push(n[r])}return o},[]).join(" ")}),i}const vm=e=>e,Pv=()=>{let e=vm;return{configure(t){e=t},generate(t){return e(t)},reset(){e=vm}}},Sv=Pv(),Tu=Sv,Av={active:"active",checked:"checked",completed:"completed",disabled:"disabled",error:"error",expanded:"expanded",focused:"focused",focusVisible:"focusVisible",open:"open",readOnly:"readOnly",required:"required",selected:"selected"};function pe(e,t,n="Mui"){const i=Av[t];return i?`${n}-${i}`:`${Tu.generate(e)}-${t}`}function oe(e,t,n="Mui"){const i={};return t.forEach(a=>{i[a]=pe(e,a,n)}),i}function U(e,t){if(e==null)return{};var n={},i=Object.keys(e),a,o;for(o=0;o<i.length;o++)a=i[o],!(t.indexOf(a)>=0)&&(n[a]=e[a]);return n}function cg(e){var t,n,i="";if(typeof e=="string"||typeof e=="number")i+=e;else if(typeof e=="object")if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(n=cg(e[t]))&&(i&&(i+=" "),i+=n);else for(t in e)e[t]&&(i&&(i+=" "),i+=t);return i}function V(){for(var e,t,n=0,i="";n<arguments.length;)(e=arguments[n++])&&(t=cg(e))&&(i&&(i+=" "),i+=t);return i}function dg(e){var t=Object.create(null);return function(n){return t[n]===void 0&&(t[n]=e(n)),t[n]}}var Ev=/^((children|dangerouslySetInnerHTML|key|ref|autoFocus|defaultValue|defaultChecked|innerHTML|suppressContentEditableWarning|suppressHydrationWarning|valueLink|abbr|accept|acceptCharset|accessKey|action|allow|allowUserMedia|allowPaymentRequest|allowFullScreen|allowTransparency|alt|async|autoComplete|autoPlay|capture|cellPadding|cellSpacing|challenge|charSet|checked|cite|classID|className|cols|colSpan|content|contentEditable|contextMenu|controls|controlsList|coords|crossOrigin|data|dateTime|decoding|default|defer|dir|disabled|disablePictureInPicture|download|draggable|encType|enterKeyHint|form|formAction|formEncType|formMethod|formNoValidate|formTarget|frameBorder|headers|height|hidden|high|href|hrefLang|htmlFor|httpEquiv|id|inputMode|integrity|is|keyParams|keyType|kind|label|lang|list|loading|loop|low|marginHeight|marginWidth|max|maxLength|media|mediaGroup|method|min|minLength|multiple|muted|name|nonce|noValidate|open|optimum|pattern|placeholder|playsInline|poster|preload|profile|radioGroup|readOnly|referrerPolicy|rel|required|reversed|role|rows|rowSpan|sandbox|scope|scoped|scrolling|seamless|selected|shape|size|sizes|slot|span|spellCheck|src|srcDoc|srcLang|srcSet|start|step|style|summary|tabIndex|target|title|translate|type|useMap|value|width|wmode|wrap|about|datatype|inlist|prefix|property|resource|typeof|vocab|autoCapitalize|autoCorrect|autoSave|color|incremental|fallback|inert|itemProp|itemScope|itemType|itemID|itemRef|on|option|results|security|unselectable|accentHeight|accumulate|additive|alignmentBaseline|allowReorder|alphabetic|amplitude|arabicForm|ascent|attributeName|attributeType|autoReverse|azimuth|baseFrequency|baselineShift|baseProfile|bbox|begin|bias|by|calcMode|capHeight|clip|clipPathUnits|clipPath|clipRule|colorInterpolation|colorInterpolationFilters|colorProfile|colorRendering|contentScriptType|contentStyleType|cursor|cx|cy|d|decelerate|descent|diffuseConstant|direction|display|divisor|dominantBaseline|dur|dx|dy|edgeMode|elevation|enableBackground|end|exponent|externalResourcesRequired|fill|fillOpacity|fillRule|filter|filterRes|filterUnits|floodColor|floodOpacity|focusable|fontFamily|fontSize|fontSizeAdjust|fontStretch|fontStyle|fontVariant|fontWeight|format|from|fr|fx|fy|g1|g2|glyphName|glyphOrientationHorizontal|glyphOrientationVertical|glyphRef|gradientTransform|gradientUnits|hanging|horizAdvX|horizOriginX|ideographic|imageRendering|in|in2|intercept|k|k1|k2|k3|k4|kernelMatrix|kernelUnitLength|kerning|keyPoints|keySplines|keyTimes|lengthAdjust|letterSpacing|lightingColor|limitingConeAngle|local|markerEnd|markerMid|markerStart|markerHeight|markerUnits|markerWidth|mask|maskContentUnits|maskUnits|mathematical|mode|numOctaves|offset|opacity|operator|order|orient|orientation|origin|overflow|overlinePosition|overlineThickness|panose1|paintOrder|pathLength|patternContentUnits|patternTransform|patternUnits|pointerEvents|points|pointsAtX|pointsAtY|pointsAtZ|preserveAlpha|preserveAspectRatio|primitiveUnits|r|radius|refX|refY|renderingIntent|repeatCount|repeatDur|requiredExtensions|requiredFeatures|restart|result|rotate|rx|ry|scale|seed|shapeRendering|slope|spacing|specularConstant|specularExponent|speed|spreadMethod|startOffset|stdDeviation|stemh|stemv|stitchTiles|stopColor|stopOpacity|strikethroughPosition|strikethroughThickness|string|stroke|strokeDasharray|strokeDashoffset|strokeLinecap|strokeLinejoin|strokeMiterlimit|strokeOpacity|strokeWidth|surfaceScale|systemLanguage|tableValues|targetX|targetY|textAnchor|textDecoration|textRendering|textLength|to|transform|u1|u2|underlinePosition|underlineThickness|unicode|unicodeBidi|unicodeRange|unitsPerEm|vAlphabetic|vHanging|vIdeographic|vMathematical|values|vectorEffect|version|vertAdvY|vertOriginX|vertOriginY|viewBox|viewTarget|visibility|widths|wordSpacing|writingMode|x|xHeight|x1|x2|xChannelSelector|xlinkActuate|xlinkArcrole|xlinkHref|xlinkRole|xlinkShow|xlinkTitle|xlinkType|xmlBase|xmlns|xmlnsXlink|xmlLang|xmlSpace|y|y1|y2|yChannelSelector|z|zoomAndPan|for|class|autofocus)|(([Dd][Aa][Tt][Aa]|[Aa][Rr][Ii][Aa]|x)-.*))$/,Nv=dg(function(e){return Ev.test(e)||e.charCodeAt(0)===111&&e.charCodeAt(1)===110&&e.charCodeAt(2)<91});function Bv(e){if(e.sheet)return e.sheet;for(var t=0;t<document.styleSheets.length;t++)if(document.styleSheets[t].ownerNode===e)return document.styleSheets[t]}function Rv(e){var t=document.createElement("style");return t.setAttribute("data-emotion",e.key),e.nonce!==void 0&&t.setAttribute("nonce",e.nonce),t.appendChild(document.createTextNode("")),t.setAttribute("data-s",""),t}var Ov=function(){function e(n){var i=this;this._insertTag=function(a){var o;i.tags.length===0?i.insertionPoint?o=i.insertionPoint.nextSibling:i.prepend?o=i.container.firstChild:o=i.before:o=i.tags[i.tags.length-1].nextSibling,i.container.insertBefore(a,o),i.tags.push(a)},this.isSpeedy=n.speedy===void 0?!0:n.speedy,this.tags=[],this.ctr=0,this.nonce=n.nonce,this.key=n.key,this.container=n.container,this.prepend=n.prepend,this.insertionPoint=n.insertionPoint,this.before=null}var t=e.prototype;return t.hydrate=function(i){i.forEach(this._insertTag)},t.insert=function(i){this.ctr%(this.isSpeedy?65e3:1)===0&&this._insertTag(Rv(this));var a=this.tags[this.tags.length-1];if(this.isSpeedy){var o=Bv(a);try{o.insertRule(i,o.cssRules.length)}catch{}}else a.appendChild(document.createTextNode(i));this.ctr++},t.flush=function(){this.tags.forEach(function(i){return i.parentNode&&i.parentNode.removeChild(i)}),this.tags=[],this.ctr=0},e}(),Je="-ms-",ts="-moz-",ne="-webkit-",ug="comm",ku="rule",Iu="decl",zv="@import",pg="@keyframes",Wv="@layer",jv=Math.abs,Ws=String.fromCharCode,Mv=Object.assign;function Lv(e,t){return He(e,0)^45?(((t<<2^He(e,0))<<2^He(e,1))<<2^He(e,2))<<2^He(e,3):0}function mg(e){return e.trim()}function Fv(e,t){return(e=t.exec(e))?e[0]:e}function ie(e,t,n){return e.replace(t,n)}function id(e,t){return e.indexOf(t)}function He(e,t){return e.charCodeAt(t)|0}function To(e,t,n){return e.slice(t,n)}function Xt(e){return e.length}function qu(e){return e.length}function or(e,t){return t.push(e),e}function Uv(e,t){return e.map(t).join("")}var js=1,ua=1,fg=0,ft=0,Oe=0,va="";function Ms(e,t,n,i,a,o,r){return{value:e,root:t,parent:n,type:i,props:a,children:o,line:js,column:ua,length:r,return:""}}function Ea(e,t){return Mv(Ms("",null,null,"",null,null,0),e,{length:-e.length},t)}function Gv(){return Oe}function $v(){return Oe=ft>0?He(va,--ft):0,ua--,Oe===10&&(ua=1,js--),Oe}function vt(){return Oe=ft<fg?He(va,ft++):0,ua++,Oe===10&&(ua=1,js++),Oe}function on(){return He(va,ft)}function xr(){return ft}function No(e,t){return To(va,e,t)}function ko(e){switch(e){case 0:case 9:case 10:case 13:case 32:return 5;case 33:case 43:case 44:case 47:case 62:case 64:case 126:case 59:case 123:case 125:return 4;case 58:return 3;case 34:case 39:case 40:case 91:return 2;case 41:case 93:return 1}return 0}function hg(e){return js=ua=1,fg=Xt(va=e),ft=0,[]}function yg(e){return va="",e}function Tr(e){return mg(No(ft-1,ad(e===91?e+2:e===40?e+1:e)))}function Vv(e){for(;(Oe=on())&&Oe<33;)vt();return ko(e)>2||ko(Oe)>3?"":" "}function Hv(e,t){for(;--t&&vt()&&!(Oe<48||Oe>102||Oe>57&&Oe<65||Oe>70&&Oe<97););return No(e,xr()+(t<6&&on()==32&&vt()==32))}function ad(e){for(;vt();)switch(Oe){case e:return ft;case 34:case 39:e!==34&&e!==39&&ad(Oe);break;case 40:e===41&&ad(e);break;case 92:vt();break}return ft}function Zv(e,t){for(;vt()&&e+Oe!==47+10;)if(e+Oe===42+42&&on()===47)break;return"/*"+No(t,ft-1)+"*"+Ws(e===47?e:vt())}function Qv(e){for(;!ko(on());)vt();return No(e,ft)}function Kv(e){return yg(kr("",null,null,null,[""],e=hg(e),0,[0],e))}function kr(e,t,n,i,a,o,r,s,l){for(var c=0,d=0,f=r,h=0,u=0,y=0,m=1,k=1,_=1,g=0,b="",w=a,I=o,q=i,x=b;k;)switch(y=g,g=vt()){case 40:if(y!=108&&He(x,f-1)==58){id(x+=ie(Tr(g),"&","&\f"),"&\f")!=-1&&(_=-1);break}case 34:case 39:case 91:x+=Tr(g);break;case 9:case 10:case 13:case 32:x+=Vv(y);break;case 92:x+=Hv(xr()-1,7);continue;case 47:switch(on()){case 42:case 47:or(Xv(Zv(vt(),xr()),t,n),l);break;default:x+="/"}break;case 123*m:s[c++]=Xt(x)*_;case 125*m:case 59:case 0:switch(g){case 0:case 125:k=0;case 59+d:_==-1&&(x=ie(x,/\f/g,"")),u>0&&Xt(x)-f&&or(u>32?xm(x+";",i,n,f-1):xm(ie(x," ","")+";",i,n,f-2),l);break;case 59:x+=";";default:if(or(q=wm(x,t,n,c,d,a,s,b,w=[],I=[],f),o),g===123)if(d===0)kr(x,t,q,q,w,o,f,s,I);else switch(h===99&&He(x,3)===110?100:h){case 100:case 108:case 109:case 115:kr(e,q,q,i&&or(wm(e,q,q,0,0,a,s,b,a,w=[],f),I),a,I,f,s,i?w:I);break;default:kr(x,q,q,q,[""],I,0,s,I)}}c=d=u=0,m=_=1,b=x="",f=r;break;case 58:f=1+Xt(x),u=y;default:if(m<1){if(g==123)--m;else if(g==125&&m++==0&&$v()==125)continue}switch(x+=Ws(g),g*m){case 38:_=d>0?1:(x+="\f",-1);break;case 44:s[c++]=(Xt(x)-1)*_,_=1;break;case 64:on()===45&&(x+=Tr(vt())),h=on(),d=f=Xt(b=x+=Qv(xr())),g++;break;case 45:y===45&&Xt(x)==2&&(m=0)}}return o}function wm(e,t,n,i,a,o,r,s,l,c,d){for(var f=a-1,h=a===0?o:[""],u=qu(h),y=0,m=0,k=0;y<i;++y)for(var _=0,g=To(e,f+1,f=jv(m=r[y])),b=e;_<u;++_)(b=mg(m>0?h[_]+" "+g:ie(g,/&\f/g,h[_])))&&(l[k++]=b);return Ms(e,t,n,a===0?ku:s,l,c,d)}function Xv(e,t,n){return Ms(e,t,n,ug,Ws(Gv()),To(e,2,-2),0)}function xm(e,t,n,i){return Ms(e,t,n,Iu,To(e,0,i),To(e,i+1,-1),i)}function na(e,t){for(var n="",i=qu(e),a=0;a<i;a++)n+=t(e[a],a,e,t)||"";return n}function Yv(e,t,n,i){switch(e.type){case Wv:if(e.children.length)break;case zv:case Iu:return e.return=e.return||e.value;case ug:return"";case pg:return e.return=e.value+"{"+na(e.children,i)+"}";case ku:e.value=e.props.join(",")}return Xt(n=na(e.children,i))?e.return=e.value+"{"+n+"}":""}function Jv(e){var t=qu(e);return function(n,i,a,o){for(var r="",s=0;s<t;s++)r+=e[s](n,i,a,o)||"";return r}}function ew(e){return function(t){t.root||(t=t.return)&&e(t)}}var tw=function(t,n,i){for(var a=0,o=0;a=o,o=on(),a===38&&o===12&&(n[i]=1),!ko(o);)vt();return No(t,ft)},nw=function(t,n){var i=-1,a=44;do switch(ko(a)){case 0:a===38&&on()===12&&(n[i]=1),t[i]+=tw(ft-1,n,i);break;case 2:t[i]+=Tr(a);break;case 4:if(a===44){t[++i]=on()===58?"&\f":"",n[i]=t[i].length;break}default:t[i]+=Ws(a)}while(a=vt());return t},iw=function(t,n){return yg(nw(hg(t),n))},Tm=new WeakMap,aw=function(t){if(!(t.type!=="rule"||!t.parent||t.length<1)){for(var n=t.value,i=t.parent,a=t.column===i.column&&t.line===i.line;i.type!=="rule";)if(i=i.parent,!i)return;if(!(t.props.length===1&&n.charCodeAt(0)!==58&&!Tm.get(i))&&!a){Tm.set(t,!0);for(var o=[],r=iw(n,o),s=i.props,l=0,c=0;l<r.length;l++)for(var d=0;d<s.length;d++,c++)t.props[c]=o[l]?r[l].replace(/&\f/g,s[d]):s[d]+" "+r[l]}}},ow=function(t){if(t.type==="decl"){var n=t.value;n.charCodeAt(0)===108&&n.charCodeAt(2)===98&&(t.return="",t.value="")}};function gg(e,t){switch(Lv(e,t)){case 5103:return ne+"print-"+e+e;case 5737:case 4201:case 3177:case 3433:case 1641:case 4457:case 2921:case 5572:case 6356:case 5844:case 3191:case 6645:case 3005:case 6391:case 5879:case 5623:case 6135:case 4599:case 4855:case 4215:case 6389:case 5109:case 5365:case 5621:case 3829:return ne+e+e;case 5349:case 4246:case 4810:case 6968:case 2756:return ne+e+ts+e+Je+e+e;case 6828:case 4268:return ne+e+Je+e+e;case 6165:return ne+e+Je+"flex-"+e+e;case 5187:return ne+e+ie(e,/(\w+).+(:[^]+)/,ne+"box-$1$2"+Je+"flex-$1$2")+e;case 5443:return ne+e+Je+"flex-item-"+ie(e,/flex-|-self/,"")+e;case 4675:return ne+e+Je+"flex-line-pack"+ie(e,/align-content|flex-|-self/,"")+e;case 5548:return ne+e+Je+ie(e,"shrink","negative")+e;case 5292:return ne+e+Je+ie(e,"basis","preferred-size")+e;case 6060:return ne+"box-"+ie(e,"-grow","")+ne+e+Je+ie(e,"grow","positive")+e;case 4554:return ne+ie(e,/([^-])(transform)/g,"$1"+ne+"$2")+e;case 6187:return ie(ie(ie(e,/(zoom-|grab)/,ne+"$1"),/(image-set)/,ne+"$1"),e,"")+e;case 5495:case 3959:return ie(e,/(image-set\([^]*)/,ne+"$1$`$1");case 4968:return ie(ie(e,/(.+:)(flex-)?(.*)/,ne+"box-pack:$3"+Je+"flex-pack:$3"),/s.+-b[^;]+/,"justify")+ne+e+e;case 4095:case 3583:case 4068:case 2532:return ie(e,/(.+)-inline(.+)/,ne+"$1$2")+e;case 8116:case 7059:case 5753:case 5535:case 5445:case 5701:case 4933:case 4677:case 5533:case 5789:case 5021:case 4765:if(Xt(e)-1-t>6)switch(He(e,t+1)){case 109:if(He(e,t+4)!==45)break;case 102:return ie(e,/(.+:)(.+)-([^]+)/,"$1"+ne+"$2-$3$1"+ts+(He(e,t+3)==108?"$3":"$2-$3"))+e;case 115:return~id(e,"stretch")?gg(ie(e,"stretch","fill-available"),t)+e:e}break;case 4949:if(He(e,t+1)!==115)break;case 6444:switch(He(e,Xt(e)-3-(~id(e,"!important")&&10))){case 107:return ie(e,":",":"+ne)+e;case 101:return ie(e,/(.+:)([^;!]+)(;|!.+)?/,"$1"+ne+(He(e,14)===45?"inline-":"")+"box$3$1"+ne+"$2$3$1"+Je+"$2box$3")+e}break;case 5936:switch(He(e,t+11)){case 114:return ne+e+Je+ie(e,/[svh]\w+-[tblr]{2}/,"tb")+e;case 108:return ne+e+Je+ie(e,/[svh]\w+-[tblr]{2}/,"tb-rl")+e;case 45:return ne+e+Je+ie(e,/[svh]\w+-[tblr]{2}/,"lr")+e}return ne+e+Je+e+e}return e}var rw=function(t,n,i,a){if(t.length>-1&&!t.return)switch(t.type){case Iu:t.return=gg(t.value,t.length);break;case pg:return na([Ea(t,{value:ie(t.value,"@","@"+ne)})],a);case ku:if(t.length)return Uv(t.props,function(o){switch(Fv(o,/(::plac\w+|:read-\w+)/)){case":read-only":case":read-write":return na([Ea(t,{props:[ie(o,/:(read-\w+)/,":"+ts+"$1")]})],a);case"::placeholder":return na([Ea(t,{props:[ie(o,/:(plac\w+)/,":"+ne+"input-$1")]}),Ea(t,{props:[ie(o,/:(plac\w+)/,":"+ts+"$1")]}),Ea(t,{props:[ie(o,/:(plac\w+)/,Je+"input-$1")]})],a)}return""})}},sw=[rw],lw=function(t){var n=t.key;if(n==="css"){var i=document.querySelectorAll("style[data-emotion]:not([data-s])");Array.prototype.forEach.call(i,function(m){var k=m.getAttribute("data-emotion");k.indexOf(" ")!==-1&&(document.head.appendChild(m),m.setAttribute("data-s",""))})}var a=t.stylisPlugins||sw,o={},r,s=[];r=t.container||document.head,Array.prototype.forEach.call(document.querySelectorAll('style[data-emotion^="'+n+' "]'),function(m){for(var k=m.getAttribute("data-emotion").split(" "),_=1;_<k.length;_++)o[k[_]]=!0;s.push(m)});var l,c=[aw,ow];{var d,f=[Yv,ew(function(m){d.insert(m)})],h=Jv(c.concat(a,f)),u=function(k){return na(Kv(k),h)};l=function(k,_,g,b){d=g,u(k?k+"{"+_.styles+"}":_.styles),b&&(y.inserted[_.name]=!0)}}var y={key:n,sheet:new Ov({key:n,container:r,nonce:t.nonce,speedy:t.speedy,prepend:t.prepend,insertionPoint:t.insertionPoint}),nonce:t.nonce,inserted:o,registered:{},insert:l};return y.sheet.hydrate(s),y},_g={exports:{}},ce={};/** @license React v16.13.1
 * react-is.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Ue=typeof Symbol=="function"&&Symbol.for,Cu=Ue?Symbol.for("react.element"):60103,Du=Ue?Symbol.for("react.portal"):60106,Ls=Ue?Symbol.for("react.fragment"):60107,Fs=Ue?Symbol.for("react.strict_mode"):60108,Us=Ue?Symbol.for("react.profiler"):60114,Gs=Ue?Symbol.for("react.provider"):60109,$s=Ue?Symbol.for("react.context"):60110,Pu=Ue?Symbol.for("react.async_mode"):60111,Vs=Ue?Symbol.for("react.concurrent_mode"):60111,Hs=Ue?Symbol.for("react.forward_ref"):60112,Zs=Ue?Symbol.for("react.suspense"):60113,cw=Ue?Symbol.for("react.suspense_list"):60120,Qs=Ue?Symbol.for("react.memo"):60115,Ks=Ue?Symbol.for("react.lazy"):60116,dw=Ue?Symbol.for("react.block"):60121,uw=Ue?Symbol.for("react.fundamental"):60117,pw=Ue?Symbol.for("react.responder"):60118,mw=Ue?Symbol.for("react.scope"):60119;function kt(e){if(typeof e=="object"&&e!==null){var t=e.$$typeof;switch(t){case Cu:switch(e=e.type,e){case Pu:case Vs:case Ls:case Us:case Fs:case Zs:return e;default:switch(e=e&&e.$$typeof,e){case $s:case Hs:case Ks:case Qs:case Gs:return e;default:return t}}case Du:return t}}}function bg(e){return kt(e)===Vs}ce.AsyncMode=Pu;ce.ConcurrentMode=Vs;ce.ContextConsumer=$s;ce.ContextProvider=Gs;ce.Element=Cu;ce.ForwardRef=Hs;ce.Fragment=Ls;ce.Lazy=Ks;ce.Memo=Qs;ce.Portal=Du;ce.Profiler=Us;ce.StrictMode=Fs;ce.Suspense=Zs;ce.isAsyncMode=function(e){return bg(e)||kt(e)===Pu};ce.isConcurrentMode=bg;ce.isContextConsumer=function(e){return kt(e)===$s};ce.isContextProvider=function(e){return kt(e)===Gs};ce.isElement=function(e){return typeof e=="object"&&e!==null&&e.$$typeof===Cu};ce.isForwardRef=function(e){return kt(e)===Hs};ce.isFragment=function(e){return kt(e)===Ls};ce.isLazy=function(e){return kt(e)===Ks};ce.isMemo=function(e){return kt(e)===Qs};ce.isPortal=function(e){return kt(e)===Du};ce.isProfiler=function(e){return kt(e)===Us};ce.isStrictMode=function(e){return kt(e)===Fs};ce.isSuspense=function(e){return kt(e)===Zs};ce.isValidElementType=function(e){return typeof e=="string"||typeof e=="function"||e===Ls||e===Vs||e===Us||e===Fs||e===Zs||e===cw||typeof e=="object"&&e!==null&&(e.$$typeof===Ks||e.$$typeof===Qs||e.$$typeof===Gs||e.$$typeof===$s||e.$$typeof===Hs||e.$$typeof===uw||e.$$typeof===pw||e.$$typeof===mw||e.$$typeof===dw)};ce.typeOf=kt;_g.exports=ce;var fw=_g.exports,vg=fw,hw={$$typeof:!0,render:!0,defaultProps:!0,displayName:!0,propTypes:!0},yw={$$typeof:!0,compare:!0,defaultProps:!0,displayName:!0,propTypes:!0,type:!0},wg={};wg[vg.ForwardRef]=hw;wg[vg.Memo]=yw;var gw=!0;function _w(e,t,n){var i="";return n.split(" ").forEach(function(a){e[a]!==void 0?t.push(e[a]+";"):i+=a+" "}),i}var xg=function(t,n,i){var a=t.key+"-"+n.name;(i===!1||gw===!1)&&t.registered[a]===void 0&&(t.registered[a]=n.styles)},Tg=function(t,n,i){xg(t,n,i);var a=t.key+"-"+n.name;if(t.inserted[n.name]===void 0){var o=n;do t.insert(n===o?"."+a:"",o,t.sheet,!0),o=o.next;while(o!==void 0)}};function bw(e){for(var t=0,n,i=0,a=e.length;a>=4;++i,a-=4)n=e.charCodeAt(i)&255|(e.charCodeAt(++i)&255)<<8|(e.charCodeAt(++i)&255)<<16|(e.charCodeAt(++i)&255)<<24,n=(n&65535)*1540483477+((n>>>16)*59797<<16),n^=n>>>24,t=(n&65535)*1540483477+((n>>>16)*59797<<16)^(t&65535)*1540483477+((t>>>16)*59797<<16);switch(a){case 3:t^=(e.charCodeAt(i+2)&255)<<16;case 2:t^=(e.charCodeAt(i+1)&255)<<8;case 1:t^=e.charCodeAt(i)&255,t=(t&65535)*1540483477+((t>>>16)*59797<<16)}return t^=t>>>13,t=(t&65535)*1540483477+((t>>>16)*59797<<16),((t^t>>>15)>>>0).toString(36)}var vw={animationIterationCount:1,aspectRatio:1,borderImageOutset:1,borderImageSlice:1,borderImageWidth:1,boxFlex:1,boxFlexGroup:1,boxOrdinalGroup:1,columnCount:1,columns:1,flex:1,flexGrow:1,flexPositive:1,flexShrink:1,flexNegative:1,flexOrder:1,gridRow:1,gridRowEnd:1,gridRowSpan:1,gridRowStart:1,gridColumn:1,gridColumnEnd:1,gridColumnSpan:1,gridColumnStart:1,msGridRow:1,msGridRowSpan:1,msGridColumn:1,msGridColumnSpan:1,fontWeight:1,lineHeight:1,opacity:1,order:1,orphans:1,tabSize:1,widows:1,zIndex:1,zoom:1,WebkitLineClamp:1,fillOpacity:1,floodOpacity:1,stopOpacity:1,strokeDasharray:1,strokeDashoffset:1,strokeMiterlimit:1,strokeOpacity:1,strokeWidth:1},ww=/[A-Z]|^ms/g,xw=/_EMO_([^_]+?)_([^]*?)_EMO_/g,kg=function(t){return t.charCodeAt(1)===45},km=function(t){return t!=null&&typeof t!="boolean"},Fl=dg(function(e){return kg(e)?e:e.replace(ww,"-$&").toLowerCase()}),Im=function(t,n){switch(t){case"animation":case"animationName":if(typeof n=="string")return n.replace(xw,function(i,a,o){return Yt={name:a,styles:o,next:Yt},a})}return vw[t]!==1&&!kg(t)&&typeof n=="number"&&n!==0?n+"px":n};function Io(e,t,n){if(n==null)return"";if(n.__emotion_styles!==void 0)return n;switch(typeof n){case"boolean":return"";case"object":{if(n.anim===1)return Yt={name:n.name,styles:n.styles,next:Yt},n.name;if(n.styles!==void 0){var i=n.next;if(i!==void 0)for(;i!==void 0;)Yt={name:i.name,styles:i.styles,next:Yt},i=i.next;var a=n.styles+";";return a}return Tw(e,t,n)}case"function":{if(e!==void 0){var o=Yt,r=n(e);return Yt=o,Io(e,t,r)}break}}if(t==null)return n;var s=t[n];return s!==void 0?s:n}function Tw(e,t,n){var i="";if(Array.isArray(n))for(var a=0;a<n.length;a++)i+=Io(e,t,n[a])+";";else for(var o in n){var r=n[o];if(typeof r!="object")t!=null&&t[r]!==void 0?i+=o+"{"+t[r]+"}":km(r)&&(i+=Fl(o)+":"+Im(o,r)+";");else if(Array.isArray(r)&&typeof r[0]=="string"&&(t==null||t[r[0]]===void 0))for(var s=0;s<r.length;s++)km(r[s])&&(i+=Fl(o)+":"+Im(o,r[s])+";");else{var l=Io(e,t,r);switch(o){case"animation":case"animationName":{i+=Fl(o)+":"+l+";";break}default:i+=o+"{"+l+"}"}}}return i}var qm=/label:\s*([^\s;\n{]+)\s*(;|$)/g,Yt,Su=function(t,n,i){if(t.length===1&&typeof t[0]=="object"&&t[0]!==null&&t[0].styles!==void 0)return t[0];var a=!0,o="";Yt=void 0;var r=t[0];r==null||r.raw===void 0?(a=!1,o+=Io(i,n,r)):o+=r[0];for(var s=1;s<t.length;s++)o+=Io(i,n,t[s]),a&&(o+=r[s]);qm.lastIndex=0;for(var l="",c;(c=qm.exec(o))!==null;)l+="-"+c[1];var d=bw(o)+l;return{name:d,styles:o,next:Yt}},kw=function(t){return t()},Ig=qr["useInsertionEffect"]?qr["useInsertionEffect"]:!1,Iw=Ig||kw,Cm=Ig||v.useLayoutEffect,qg=v.createContext(typeof HTMLElement<"u"?lw({key:"css"}):null);qg.Provider;var Cg=function(t){return v.forwardRef(function(n,i){var a=v.useContext(qg);return t(n,a,i)})},Au=v.createContext({}),qw=Cg(function(e,t){var n=e.styles,i=Su([n],void 0,v.useContext(Au)),a=v.useRef();return Cm(function(){var o=t.key+"-global",r=new t.sheet.constructor({key:o,nonce:t.sheet.nonce,container:t.sheet.container,speedy:t.sheet.isSpeedy}),s=!1,l=document.querySelector('style[data-emotion="'+o+" "+i.name+'"]');return t.sheet.tags.length&&(r.before=t.sheet.tags[0]),l!==null&&(s=!0,l.setAttribute("data-emotion",o),r.hydrate([l])),a.current=[r,s],function(){r.flush()}},[t]),Cm(function(){var o=a.current,r=o[0],s=o[1];if(s){o[1]=!1;return}if(i.next!==void 0&&Tg(t,i.next,!0),r.tags.length){var l=r.tags[r.tags.length-1].nextElementSibling;r.before=l,r.flush()}t.insert("",i,r,!1)},[t,i.name]),null});function Cw(){for(var e=arguments.length,t=new Array(e),n=0;n<e;n++)t[n]=arguments[n];return Su(t)}var Eu=function(){var t=Cw.apply(void 0,arguments),n="animation-"+t.name;return{name:n,styles:"@keyframes "+n+"{"+t.styles+"}",anim:1,toString:function(){return"_EMO_"+this.name+"_"+this.styles+"_EMO_"}}},Dw=Nv,Pw=function(t){return t!=="theme"},Dm=function(t){return typeof t=="string"&&t.charCodeAt(0)>96?Dw:Pw},Pm=function(t,n,i){var a;if(n){var o=n.shouldForwardProp;a=t.__emotion_forwardProp&&o?function(r){return t.__emotion_forwardProp(r)&&o(r)}:o}return typeof a!="function"&&i&&(a=t.__emotion_forwardProp),a},Sw=function(t){var n=t.cache,i=t.serialized,a=t.isStringTag;return xg(n,i,a),Iw(function(){return Tg(n,i,a)}),null},Aw=function e(t,n){var i=t.__emotion_real===t,a=i&&t.__emotion_base||t,o,r;n!==void 0&&(o=n.label,r=n.target);var s=Pm(t,n,i),l=s||Dm(a),c=!l("as");return function(){var d=arguments,f=i&&t.__emotion_styles!==void 0?t.__emotion_styles.slice(0):[];if(o!==void 0&&f.push("label:"+o+";"),d[0]==null||d[0].raw===void 0)f.push.apply(f,d);else{f.push(d[0][0]);for(var h=d.length,u=1;u<h;u++)f.push(d[u],d[0][u])}var y=Cg(function(m,k,_){var g=c&&m.as||a,b="",w=[],I=m;if(m.theme==null){I={};for(var q in m)I[q]=m[q];I.theme=v.useContext(Au)}typeof m.className=="string"?b=_w(k.registered,w,m.className):m.className!=null&&(b=m.className+" ");var x=Su(f.concat(w),k.registered,I);b+=k.key+"-"+x.name,r!==void 0&&(b+=" "+r);var C=c&&s===void 0?Dm(g):l,S={};for(var P in m)c&&P==="as"||C(P)&&(S[P]=m[P]);return S.className=b,S.ref=_,v.createElement(v.Fragment,null,v.createElement(Sw,{cache:k,serialized:x,isStringTag:typeof g=="string"}),v.createElement(g,S))});return y.displayName=o!==void 0?o:"Styled("+(typeof a=="string"?a:a.displayName||a.name||"Component")+")",y.defaultProps=t.defaultProps,y.__emotion_real=y,y.__emotion_base=a,y.__emotion_styles=f,y.__emotion_forwardProp=s,Object.defineProperty(y,"toString",{value:function(){return"."+r}}),y.withComponent=function(m,k){return e(m,T({},n,k,{shouldForwardProp:Pm(y,k,!0)})).apply(void 0,f)},y}},Ew=["a","abbr","address","area","article","aside","audio","b","base","bdi","bdo","big","blockquote","body","br","button","canvas","caption","cite","code","col","colgroup","data","datalist","dd","del","details","dfn","dialog","div","dl","dt","em","embed","fieldset","figcaption","figure","footer","form","h1","h2","h3","h4","h5","h6","head","header","hgroup","hr","html","i","iframe","img","input","ins","kbd","keygen","label","legend","li","link","main","map","mark","marquee","menu","menuitem","meta","meter","nav","noscript","object","ol","optgroup","option","output","p","param","picture","pre","progress","q","rp","rt","ruby","s","samp","script","section","select","small","source","span","strong","style","sub","summary","sup","table","tbody","td","textarea","tfoot","th","thead","time","title","tr","track","u","ul","var","video","wbr","circle","clipPath","defs","ellipse","foreignObject","g","image","line","linearGradient","mask","path","pattern","polygon","polyline","radialGradient","rect","stop","svg","text","tspan"],od=Aw.bind();Ew.forEach(function(e){od[e]=od(e)});function Nw(e){return e==null||Object.keys(e).length===0}function Bw(e){const{styles:t,defaultTheme:n={}}=e,i=typeof t=="function"?a=>t(Nw(a)?n:a):t;return p.jsx(qw,{styles:i})}/**
 * @mui/styled-engine v5.14.10
 *
 * @license MIT
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */function Dg(e,t){return od(e,t)}const Rw=(e,t)=>{Array.isArray(e.__emotion_styles)&&(e.__emotion_styles=t(e.__emotion_styles))},Ow=["values","unit","step"],zw=e=>{const t=Object.keys(e).map(n=>({key:n,val:e[n]}))||[];return t.sort((n,i)=>n.val-i.val),t.reduce((n,i)=>T({},n,{[i.key]:i.val}),{})};function Ww(e){const{values:t={xs:0,sm:600,md:900,lg:1200,xl:1536},unit:n="px",step:i=5}=e,a=U(e,Ow),o=zw(t),r=Object.keys(o);function s(h){return`@media (min-width:${typeof t[h]=="number"?t[h]:h}${n})`}function l(h){return`@media (max-width:${(typeof t[h]=="number"?t[h]:h)-i/100}${n})`}function c(h,u){const y=r.indexOf(u);return`@media (min-width:${typeof t[h]=="number"?t[h]:h}${n}) and (max-width:${(y!==-1&&typeof t[r[y]]=="number"?t[r[y]]:u)-i/100}${n})`}function d(h){return r.indexOf(h)+1<r.length?c(h,r[r.indexOf(h)+1]):s(h)}function f(h){const u=r.indexOf(h);return u===0?s(r[1]):u===r.length-1?l(r[u]):c(h,r[r.indexOf(h)+1]).replace("@media","@media not all and")}return T({keys:r,values:o,up:s,down:l,between:c,only:d,not:f,unit:n},a)}const jw={borderRadius:4},Mw=jw;function eo(e,t){return t?Bt(e,t,{clone:!1}):e}const Nu={xs:0,sm:600,md:900,lg:1200,xl:1536},Sm={keys:["xs","sm","md","lg","xl"],up:e=>`@media (min-width:${Nu[e]}px)`};function xn(e,t,n){const i=e.theme||{};if(Array.isArray(t)){const o=i.breakpoints||Sm;return t.reduce((r,s,l)=>(r[o.up(o.keys[l])]=n(t[l]),r),{})}if(typeof t=="object"){const o=i.breakpoints||Sm;return Object.keys(t).reduce((r,s)=>{if(Object.keys(o.values||Nu).indexOf(s)!==-1){const l=o.up(s);r[l]=n(t[s],s)}else{const l=s;r[l]=t[l]}return r},{})}return n(t)}function Lw(e={}){var t;return((t=e.keys)==null?void 0:t.reduce((i,a)=>{const o=e.up(a);return i[o]={},i},{}))||{}}function Fw(e,t){return e.reduce((n,i)=>{const a=n[i];return(!a||Object.keys(a).length===0)&&delete n[i],n},t)}function Xs(e,t,n=!0){if(!t||typeof t!="string")return null;if(e&&e.vars&&n){const i=`vars.${t}`.split(".").reduce((a,o)=>a&&a[o]?a[o]:null,e);if(i!=null)return i}return t.split(".").reduce((i,a)=>i&&i[a]!=null?i[a]:null,e)}function ns(e,t,n,i=n){let a;return typeof e=="function"?a=e(n):Array.isArray(e)?a=e[n]||i:a=Xs(e,n)||i,t&&(a=t(a,i,e)),a}function re(e){const{prop:t,cssProperty:n=e.prop,themeKey:i,transform:a}=e,o=r=>{if(r[t]==null)return null;const s=r[t],l=r.theme,c=Xs(l,i)||{};return xn(r,s,f=>{let h=ns(c,a,f);return f===h&&typeof f=="string"&&(h=ns(c,a,`${t}${f==="default"?"":Z(f)}`,f)),n===!1?h:{[n]:h}})};return o.propTypes={},o.filterProps=[t],o}function Uw(e){const t={};return n=>(t[n]===void 0&&(t[n]=e(n)),t[n])}const Gw={m:"margin",p:"padding"},$w={t:"Top",r:"Right",b:"Bottom",l:"Left",x:["Left","Right"],y:["Top","Bottom"]},Am={marginX:"mx",marginY:"my",paddingX:"px",paddingY:"py"},Vw=Uw(e=>{if(e.length>2)if(Am[e])e=Am[e];else return[e];const[t,n]=e.split(""),i=Gw[t],a=$w[n]||"";return Array.isArray(a)?a.map(o=>i+o):[i+a]}),Bu=["m","mt","mr","mb","ml","mx","my","margin","marginTop","marginRight","marginBottom","marginLeft","marginX","marginY","marginInline","marginInlineStart","marginInlineEnd","marginBlock","marginBlockStart","marginBlockEnd"],Ru=["p","pt","pr","pb","pl","px","py","padding","paddingTop","paddingRight","paddingBottom","paddingLeft","paddingX","paddingY","paddingInline","paddingInlineStart","paddingInlineEnd","paddingBlock","paddingBlockStart","paddingBlockEnd"];[...Bu,...Ru];function Bo(e,t,n,i){var a;const o=(a=Xs(e,t,!1))!=null?a:n;return typeof o=="number"?r=>typeof r=="string"?r:o*r:Array.isArray(o)?r=>typeof r=="string"?r:o[r]:typeof o=="function"?o:()=>{}}function Pg(e){return Bo(e,"spacing",8)}function Ro(e,t){if(typeof t=="string"||t==null)return t;const n=Math.abs(t),i=e(n);return t>=0?i:typeof i=="number"?-i:`-${i}`}function Hw(e,t){return n=>e.reduce((i,a)=>(i[a]=Ro(t,n),i),{})}function Zw(e,t,n,i){if(t.indexOf(n)===-1)return null;const a=Vw(n),o=Hw(a,i),r=e[n];return xn(e,r,o)}function Sg(e,t){const n=Pg(e.theme);return Object.keys(e).map(i=>Zw(e,t,i,n)).reduce(eo,{})}function Se(e){return Sg(e,Bu)}Se.propTypes={};Se.filterProps=Bu;function Ae(e){return Sg(e,Ru)}Ae.propTypes={};Ae.filterProps=Ru;function Qw(e=8){if(e.mui)return e;const t=Pg({spacing:e}),n=(...i)=>(i.length===0?[1]:i).map(o=>{const r=t(o);return typeof r=="number"?`${r}px`:r}).join(" ");return n.mui=!0,n}function Ys(...e){const t=e.reduce((i,a)=>(a.filterProps.forEach(o=>{i[o]=a}),i),{}),n=i=>Object.keys(i).reduce((a,o)=>t[o]?eo(a,t[o](i)):a,{});return n.propTypes={},n.filterProps=e.reduce((i,a)=>i.concat(a.filterProps),[]),n}function en(e){return typeof e!="number"?e:`${e}px solid`}const Kw=re({prop:"border",themeKey:"borders",transform:en}),Xw=re({prop:"borderTop",themeKey:"borders",transform:en}),Yw=re({prop:"borderRight",themeKey:"borders",transform:en}),Jw=re({prop:"borderBottom",themeKey:"borders",transform:en}),ex=re({prop:"borderLeft",themeKey:"borders",transform:en}),tx=re({prop:"borderColor",themeKey:"palette"}),nx=re({prop:"borderTopColor",themeKey:"palette"}),ix=re({prop:"borderRightColor",themeKey:"palette"}),ax=re({prop:"borderBottomColor",themeKey:"palette"}),ox=re({prop:"borderLeftColor",themeKey:"palette"}),Js=e=>{if(e.borderRadius!==void 0&&e.borderRadius!==null){const t=Bo(e.theme,"shape.borderRadius",4),n=i=>({borderRadius:Ro(t,i)});return xn(e,e.borderRadius,n)}return null};Js.propTypes={};Js.filterProps=["borderRadius"];Ys(Kw,Xw,Yw,Jw,ex,tx,nx,ix,ax,ox,Js);const el=e=>{if(e.gap!==void 0&&e.gap!==null){const t=Bo(e.theme,"spacing",8),n=i=>({gap:Ro(t,i)});return xn(e,e.gap,n)}return null};el.propTypes={};el.filterProps=["gap"];const tl=e=>{if(e.columnGap!==void 0&&e.columnGap!==null){const t=Bo(e.theme,"spacing",8),n=i=>({columnGap:Ro(t,i)});return xn(e,e.columnGap,n)}return null};tl.propTypes={};tl.filterProps=["columnGap"];const nl=e=>{if(e.rowGap!==void 0&&e.rowGap!==null){const t=Bo(e.theme,"spacing",8),n=i=>({rowGap:Ro(t,i)});return xn(e,e.rowGap,n)}return null};nl.propTypes={};nl.filterProps=["rowGap"];const rx=re({prop:"gridColumn"}),sx=re({prop:"gridRow"}),lx=re({prop:"gridAutoFlow"}),cx=re({prop:"gridAutoColumns"}),dx=re({prop:"gridAutoRows"}),ux=re({prop:"gridTemplateColumns"}),px=re({prop:"gridTemplateRows"}),mx=re({prop:"gridTemplateAreas"}),fx=re({prop:"gridArea"});Ys(el,tl,nl,rx,sx,lx,cx,dx,ux,px,mx,fx);function ia(e,t){return t==="grey"?t:e}const hx=re({prop:"color",themeKey:"palette",transform:ia}),yx=re({prop:"bgcolor",cssProperty:"backgroundColor",themeKey:"palette",transform:ia}),gx=re({prop:"backgroundColor",themeKey:"palette",transform:ia});Ys(hx,yx,gx);function gt(e){return e<=1&&e!==0?`${e*100}%`:e}const _x=re({prop:"width",transform:gt}),Ou=e=>{if(e.maxWidth!==void 0&&e.maxWidth!==null){const t=n=>{var i,a;const o=((i=e.theme)==null||(i=i.breakpoints)==null||(i=i.values)==null?void 0:i[n])||Nu[n];return o?((a=e.theme)==null||(a=a.breakpoints)==null?void 0:a.unit)!=="px"?{maxWidth:`${o}${e.theme.breakpoints.unit}`}:{maxWidth:o}:{maxWidth:gt(n)}};return xn(e,e.maxWidth,t)}return null};Ou.filterProps=["maxWidth"];const bx=re({prop:"minWidth",transform:gt}),vx=re({prop:"height",transform:gt}),wx=re({prop:"maxHeight",transform:gt}),xx=re({prop:"minHeight",transform:gt});re({prop:"size",cssProperty:"width",transform:gt});re({prop:"size",cssProperty:"height",transform:gt});const Tx=re({prop:"boxSizing"});Ys(_x,Ou,bx,vx,wx,xx,Tx);const kx={border:{themeKey:"borders",transform:en},borderTop:{themeKey:"borders",transform:en},borderRight:{themeKey:"borders",transform:en},borderBottom:{themeKey:"borders",transform:en},borderLeft:{themeKey:"borders",transform:en},borderColor:{themeKey:"palette"},borderTopColor:{themeKey:"palette"},borderRightColor:{themeKey:"palette"},borderBottomColor:{themeKey:"palette"},borderLeftColor:{themeKey:"palette"},borderRadius:{themeKey:"shape.borderRadius",style:Js},color:{themeKey:"palette",transform:ia},bgcolor:{themeKey:"palette",cssProperty:"backgroundColor",transform:ia},backgroundColor:{themeKey:"palette",transform:ia},p:{style:Ae},pt:{style:Ae},pr:{style:Ae},pb:{style:Ae},pl:{style:Ae},px:{style:Ae},py:{style:Ae},padding:{style:Ae},paddingTop:{style:Ae},paddingRight:{style:Ae},paddingBottom:{style:Ae},paddingLeft:{style:Ae},paddingX:{style:Ae},paddingY:{style:Ae},paddingInline:{style:Ae},paddingInlineStart:{style:Ae},paddingInlineEnd:{style:Ae},paddingBlock:{style:Ae},paddingBlockStart:{style:Ae},paddingBlockEnd:{style:Ae},m:{style:Se},mt:{style:Se},mr:{style:Se},mb:{style:Se},ml:{style:Se},mx:{style:Se},my:{style:Se},margin:{style:Se},marginTop:{style:Se},marginRight:{style:Se},marginBottom:{style:Se},marginLeft:{style:Se},marginX:{style:Se},marginY:{style:Se},marginInline:{style:Se},marginInlineStart:{style:Se},marginInlineEnd:{style:Se},marginBlock:{style:Se},marginBlockStart:{style:Se},marginBlockEnd:{style:Se},displayPrint:{cssProperty:!1,transform:e=>({"@media print":{display:e}})},display:{},overflow:{},textOverflow:{},visibility:{},whiteSpace:{},flexBasis:{},flexDirection:{},flexWrap:{},justifyContent:{},alignItems:{},alignContent:{},order:{},flex:{},flexGrow:{},flexShrink:{},alignSelf:{},justifyItems:{},justifySelf:{},gap:{style:el},rowGap:{style:nl},columnGap:{style:tl},gridColumn:{},gridRow:{},gridAutoFlow:{},gridAutoColumns:{},gridAutoRows:{},gridTemplateColumns:{},gridTemplateRows:{},gridTemplateAreas:{},gridArea:{},position:{},zIndex:{themeKey:"zIndex"},top:{},right:{},bottom:{},left:{},boxShadow:{themeKey:"shadows"},width:{transform:gt},maxWidth:{style:Ou},minWidth:{transform:gt},height:{transform:gt},maxHeight:{transform:gt},minHeight:{transform:gt},boxSizing:{},fontFamily:{themeKey:"typography"},fontSize:{themeKey:"typography"},fontStyle:{themeKey:"typography"},fontWeight:{themeKey:"typography"},letterSpacing:{},textTransform:{},lineHeight:{},textAlign:{},typography:{cssProperty:!1,themeKey:"typography"}},il=kx;function Ix(...e){const t=e.reduce((i,a)=>i.concat(Object.keys(a)),[]),n=new Set(t);return e.every(i=>n.size===Object.keys(i).length)}function qx(e,t){return typeof e=="function"?e(t):e}function Cx(){function e(n,i,a,o){const r={[n]:i,theme:a},s=o[n];if(!s)return{[n]:i};const{cssProperty:l=n,themeKey:c,transform:d,style:f}=s;if(i==null)return null;if(c==="typography"&&i==="inherit")return{[n]:i};const h=Xs(a,c)||{};return f?f(r):xn(r,i,y=>{let m=ns(h,d,y);return y===m&&typeof y=="string"&&(m=ns(h,d,`${n}${y==="default"?"":Z(y)}`,y)),l===!1?m:{[l]:m}})}function t(n){var i;const{sx:a,theme:o={}}=n||{};if(!a)return null;const r=(i=o.unstable_sxConfig)!=null?i:il;function s(l){let c=l;if(typeof l=="function")c=l(o);else if(typeof l!="object")return l;if(!c)return null;const d=Lw(o.breakpoints),f=Object.keys(d);let h=d;return Object.keys(c).forEach(u=>{const y=qx(c[u],o);if(y!=null)if(typeof y=="object")if(r[u])h=eo(h,e(u,y,o,r));else{const m=xn({theme:o},y,k=>({[u]:k}));Ix(m,y)?h[u]=t({sx:y,theme:o}):h=eo(h,m)}else h=eo(h,e(u,y,o,r))}),Fw(f,h)}return Array.isArray(a)?a.map(s):s(a)}return t}const Ag=Cx();Ag.filterProps=["sx"];const al=Ag,Dx=["breakpoints","palette","spacing","shape"];function zu(e={},...t){const{breakpoints:n={},palette:i={},spacing:a,shape:o={}}=e,r=U(e,Dx),s=Ww(n),l=Qw(a);let c=Bt({breakpoints:s,direction:"ltr",components:{},palette:T({mode:"light"},i),spacing:l,shape:T({},Mw,o)},r);return c=t.reduce((d,f)=>Bt(d,f),c),c.unstable_sxConfig=T({},il,r==null?void 0:r.unstable_sxConfig),c.unstable_sx=function(f){return al({sx:f,theme:this})},c}function Px(e){return Object.keys(e).length===0}function Sx(e=null){const t=v.useContext(Au);return!t||Px(t)?e:t}const Ax=zu();function ol(e=Ax){return Sx(e)}function Ex({styles:e,themeId:t,defaultTheme:n={}}){const i=ol(n),a=typeof e=="function"?e(t&&i[t]||i):e;return p.jsx(Bw,{styles:a})}const Nx=["sx"],Bx=e=>{var t,n;const i={systemProps:{},otherProps:{}},a=(t=e==null||(n=e.theme)==null?void 0:n.unstable_sxConfig)!=null?t:il;return Object.keys(e).forEach(o=>{a[o]?i.systemProps[o]=e[o]:i.otherProps[o]=e[o]}),i};function Eg(e){const{sx:t}=e,n=U(e,Nx),{systemProps:i,otherProps:a}=Bx(n);let o;return Array.isArray(t)?o=[i,...t]:typeof t=="function"?o=(...r)=>{const s=t(...r);return li(s)?T({},i,s):i}:o=T({},i,t),T({},a,{sx:o})}const Rx=["className","component"];function Ox(e={}){const{themeId:t,defaultTheme:n,defaultClassName:i="MuiBox-root",generateClassName:a}=e,o=Dg("div",{shouldForwardProp:s=>s!=="theme"&&s!=="sx"&&s!=="as"})(al);return v.forwardRef(function(l,c){const d=ol(n),f=Eg(l),{className:h,component:u="div"}=f,y=U(f,Rx);return p.jsx(o,T({as:u,ref:c,className:V(h,a?a(i):i),theme:t&&d[t]||d},y))})}const zx=["variant"];function Em(e){return e.length===0}function Ng(e){const{variant:t}=e,n=U(e,zx);let i=t||"";return Object.keys(n).sort().forEach(a=>{a==="color"?i+=Em(i)?e[a]:Z(e[a]):i+=`${Em(i)?a:Z(a)}${Z(e[a].toString())}`}),i}const Wx=["name","slot","skipVariantsResolver","skipSx","overridesResolver"];function jx(e){return Object.keys(e).length===0}function Mx(e){return typeof e=="string"&&e.charCodeAt(0)>96}const Lx=(e,t)=>t.components&&t.components[e]&&t.components[e].styleOverrides?t.components[e].styleOverrides:null,Fx=(e,t)=>{let n=[];t&&t.components&&t.components[e]&&t.components[e].variants&&(n=t.components[e].variants);const i={};return n.forEach(a=>{const o=Ng(a.props);i[o]=a.style}),i},Ux=(e,t,n,i)=>{var a;const{ownerState:o={}}=e,r=[],s=n==null||(a=n.components)==null||(a=a[i])==null?void 0:a.variants;return s&&s.forEach(l=>{let c=!0;Object.keys(l.props).forEach(d=>{o[d]!==l.props[d]&&e[d]!==l.props[d]&&(c=!1)}),c&&r.push(t[Ng(l.props)])}),r};function to(e){return e!=="ownerState"&&e!=="theme"&&e!=="sx"&&e!=="as"}const Gx=zu(),$x=e=>e&&e.charAt(0).toLowerCase()+e.slice(1);function Na({defaultTheme:e,theme:t,themeId:n}){return jx(t)?e:t[n]||t}function Vx(e){return e?(t,n)=>n[e]:null}function Hx(e={}){const{themeId:t,defaultTheme:n=Gx,rootShouldForwardProp:i=to,slotShouldForwardProp:a=to}=e,o=r=>al(T({},r,{theme:Na(T({},r,{defaultTheme:n,themeId:t}))}));return o.__mui_systemSx=!0,(r,s={})=>{Rw(r,w=>w.filter(I=>!(I!=null&&I.__mui_systemSx)));const{name:l,slot:c,skipVariantsResolver:d,skipSx:f,overridesResolver:h=Vx($x(c))}=s,u=U(s,Wx),y=d!==void 0?d:c&&c!=="Root"&&c!=="root"||!1,m=f||!1;let k,_=to;c==="Root"||c==="root"?_=i:c?_=a:Mx(r)&&(_=void 0);const g=Dg(r,T({shouldForwardProp:_,label:k},u)),b=(w,...I)=>{const q=I?I.map(P=>typeof P=="function"&&P.__emotion_real!==P?B=>P(T({},B,{theme:Na(T({},B,{defaultTheme:n,themeId:t}))})):P):[];let x=w;l&&h&&q.push(P=>{const B=Na(T({},P,{defaultTheme:n,themeId:t})),O=Lx(l,B);if(O){const M={};return Object.entries(O).forEach(([E,R])=>{M[E]=typeof R=="function"?R(T({},P,{theme:B})):R}),h(P,M)}return null}),l&&!y&&q.push(P=>{const B=Na(T({},P,{defaultTheme:n,themeId:t}));return Ux(P,Fx(l,B),B,l)}),m||q.push(o);const C=q.length-I.length;if(Array.isArray(w)&&C>0){const P=new Array(C).fill("");x=[...w,...P],x.raw=[...w.raw,...P]}else typeof w=="function"&&w.__emotion_real!==w&&(x=P=>w(T({},P,{theme:Na(T({},P,{defaultTheme:n,themeId:t}))})));const S=g(x,...q);return r.muiName&&(S.muiName=r.muiName),S};return g.withConfig&&(b.withConfig=g.withConfig),b}}function Zx(e){const{theme:t,name:n,props:i}=e;return!t||!t.components||!t.components[n]||!t.components[n].defaultProps?i:lg(t.components[n].defaultProps,i)}function Qx({props:e,name:t,defaultTheme:n,themeId:i}){let a=ol(n);return i&&(a=a[i]||a),Zx({theme:a,name:t,props:e})}function Wu(e,t=0,n=1){return Math.min(Math.max(t,e),n)}function Kx(e){e=e.slice(1);const t=new RegExp(`.{1,${e.length>=6?2:1}}`,"g");let n=e.match(t);return n&&n[0].length===1&&(n=n.map(i=>i+i)),n?`rgb${n.length===4?"a":""}(${n.map((i,a)=>a<3?parseInt(i,16):Math.round(parseInt(i,16)/255*1e3)/1e3).join(", ")})`:""}function ki(e){if(e.type)return e;if(e.charAt(0)==="#")return ki(Kx(e));const t=e.indexOf("("),n=e.substring(0,t);if(["rgb","rgba","hsl","hsla","color"].indexOf(n)===-1)throw new Error(Kn(9,e));let i=e.substring(t+1,e.length-1),a;if(n==="color"){if(i=i.split(" "),a=i.shift(),i.length===4&&i[3].charAt(0)==="/"&&(i[3]=i[3].slice(1)),["srgb","display-p3","a98-rgb","prophoto-rgb","rec-2020"].indexOf(a)===-1)throw new Error(Kn(10,a))}else i=i.split(",");return i=i.map(o=>parseFloat(o)),{type:n,values:i,colorSpace:a}}function rl(e){const{type:t,colorSpace:n}=e;let{values:i}=e;return t.indexOf("rgb")!==-1?i=i.map((a,o)=>o<3?parseInt(a,10):a):t.indexOf("hsl")!==-1&&(i[1]=`${i[1]}%`,i[2]=`${i[2]}%`),t.indexOf("color")!==-1?i=`${n} ${i.join(" ")}`:i=`${i.join(", ")}`,`${t}(${i})`}function Xx(e){e=ki(e);const{values:t}=e,n=t[0],i=t[1]/100,a=t[2]/100,o=i*Math.min(a,1-a),r=(c,d=(c+n/30)%12)=>a-o*Math.max(Math.min(d-3,9-d,1),-1);let s="rgb";const l=[Math.round(r(0)*255),Math.round(r(8)*255),Math.round(r(4)*255)];return e.type==="hsla"&&(s+="a",l.push(t[3])),rl({type:s,values:l})}function Nm(e){e=ki(e);let t=e.type==="hsl"||e.type==="hsla"?ki(Xx(e)).values:e.values;return t=t.map(n=>(e.type!=="color"&&(n/=255),n<=.03928?n/12.92:((n+.055)/1.055)**2.4)),Number((.2126*t[0]+.7152*t[1]+.0722*t[2]).toFixed(3))}function Yx(e,t){const n=Nm(e),i=Nm(t);return(Math.max(n,i)+.05)/(Math.min(n,i)+.05)}function yn(e,t){return e=ki(e),t=Wu(t),(e.type==="rgb"||e.type==="hsl")&&(e.type+="a"),e.type==="color"?e.values[3]=`/${t}`:e.values[3]=t,rl(e)}function rd(e,t){if(e=ki(e),t=Wu(t),e.type.indexOf("hsl")!==-1)e.values[2]*=1-t;else if(e.type.indexOf("rgb")!==-1||e.type.indexOf("color")!==-1)for(let n=0;n<3;n+=1)e.values[n]*=1-t;return rl(e)}function sd(e,t){if(e=ki(e),t=Wu(t),e.type.indexOf("hsl")!==-1)e.values[2]+=(100-e.values[2])*t;else if(e.type.indexOf("rgb")!==-1)for(let n=0;n<3;n+=1)e.values[n]+=(255-e.values[n])*t;else if(e.type.indexOf("color")!==-1)for(let n=0;n<3;n+=1)e.values[n]+=(1-e.values[n])*t;return rl(e)}function Jx(e,t){return T({toolbar:{minHeight:56,[e.up("xs")]:{"@media (orientation: landscape)":{minHeight:48}},[e.up("sm")]:{minHeight:64}}},t)}const e2={black:"#000",white:"#fff"},qo=e2,t2={50:"#fafafa",100:"#f5f5f5",200:"#eeeeee",300:"#e0e0e0",400:"#bdbdbd",500:"#9e9e9e",600:"#757575",700:"#616161",800:"#424242",900:"#212121",A100:"#f5f5f5",A200:"#eeeeee",A400:"#bdbdbd",A700:"#616161"},n2=t2,i2={50:"#f3e5f5",100:"#e1bee7",200:"#ce93d8",300:"#ba68c8",400:"#ab47bc",500:"#9c27b0",600:"#8e24aa",700:"#7b1fa2",800:"#6a1b9a",900:"#4a148c",A100:"#ea80fc",A200:"#e040fb",A400:"#d500f9",A700:"#aa00ff"},Si=i2,a2={50:"#ffebee",100:"#ffcdd2",200:"#ef9a9a",300:"#e57373",400:"#ef5350",500:"#f44336",600:"#e53935",700:"#d32f2f",800:"#c62828",900:"#b71c1c",A100:"#ff8a80",A200:"#ff5252",A400:"#ff1744",A700:"#d50000"},Ai=a2,o2={50:"#fff3e0",100:"#ffe0b2",200:"#ffcc80",300:"#ffb74d",400:"#ffa726",500:"#ff9800",600:"#fb8c00",700:"#f57c00",800:"#ef6c00",900:"#e65100",A100:"#ffd180",A200:"#ffab40",A400:"#ff9100",A700:"#ff6d00"},Ba=o2,r2={50:"#e3f2fd",100:"#bbdefb",200:"#90caf9",300:"#64b5f6",400:"#42a5f5",500:"#2196f3",600:"#1e88e5",700:"#1976d2",800:"#1565c0",900:"#0d47a1",A100:"#82b1ff",A200:"#448aff",A400:"#2979ff",A700:"#2962ff"},Ei=r2,s2={50:"#e1f5fe",100:"#b3e5fc",200:"#81d4fa",300:"#4fc3f7",400:"#29b6f6",500:"#03a9f4",600:"#039be5",700:"#0288d1",800:"#0277bd",900:"#01579b",A100:"#80d8ff",A200:"#40c4ff",A400:"#00b0ff",A700:"#0091ea"},Ni=s2,l2={50:"#e8f5e9",100:"#c8e6c9",200:"#a5d6a7",300:"#81c784",400:"#66bb6a",500:"#4caf50",600:"#43a047",700:"#388e3c",800:"#2e7d32",900:"#1b5e20",A100:"#b9f6ca",A200:"#69f0ae",A400:"#00e676",A700:"#00c853"},Bi=l2,c2=["mode","contrastThreshold","tonalOffset"],Bm={text:{primary:"rgba(0, 0, 0, 0.87)",secondary:"rgba(0, 0, 0, 0.6)",disabled:"rgba(0, 0, 0, 0.38)"},divider:"rgba(0, 0, 0, 0.12)",background:{paper:qo.white,default:qo.white},action:{active:"rgba(0, 0, 0, 0.54)",hover:"rgba(0, 0, 0, 0.04)",hoverOpacity:.04,selected:"rgba(0, 0, 0, 0.08)",selectedOpacity:.08,disabled:"rgba(0, 0, 0, 0.26)",disabledBackground:"rgba(0, 0, 0, 0.12)",disabledOpacity:.38,focus:"rgba(0, 0, 0, 0.12)",focusOpacity:.12,activatedOpacity:.12}},Ul={text:{primary:qo.white,secondary:"rgba(255, 255, 255, 0.7)",disabled:"rgba(255, 255, 255, 0.5)",icon:"rgba(255, 255, 255, 0.5)"},divider:"rgba(255, 255, 255, 0.12)",background:{paper:"#121212",default:"#121212"},action:{active:qo.white,hover:"rgba(255, 255, 255, 0.08)",hoverOpacity:.08,selected:"rgba(255, 255, 255, 0.16)",selectedOpacity:.16,disabled:"rgba(255, 255, 255, 0.3)",disabledBackground:"rgba(255, 255, 255, 0.12)",disabledOpacity:.38,focus:"rgba(255, 255, 255, 0.12)",focusOpacity:.12,activatedOpacity:.24}};function Rm(e,t,n,i){const a=i.light||i,o=i.dark||i*1.5;e[t]||(e.hasOwnProperty(n)?e[t]=e[n]:t==="light"?e.light=sd(e.main,a):t==="dark"&&(e.dark=rd(e.main,o)))}function d2(e="light"){return e==="dark"?{main:Ei[200],light:Ei[50],dark:Ei[400]}:{main:Ei[700],light:Ei[400],dark:Ei[800]}}function u2(e="light"){return e==="dark"?{main:Si[200],light:Si[50],dark:Si[400]}:{main:Si[500],light:Si[300],dark:Si[700]}}function p2(e="light"){return e==="dark"?{main:Ai[500],light:Ai[300],dark:Ai[700]}:{main:Ai[700],light:Ai[400],dark:Ai[800]}}function m2(e="light"){return e==="dark"?{main:Ni[400],light:Ni[300],dark:Ni[700]}:{main:Ni[700],light:Ni[500],dark:Ni[900]}}function f2(e="light"){return e==="dark"?{main:Bi[400],light:Bi[300],dark:Bi[700]}:{main:Bi[800],light:Bi[500],dark:Bi[900]}}function h2(e="light"){return e==="dark"?{main:Ba[400],light:Ba[300],dark:Ba[700]}:{main:"#ed6c02",light:Ba[500],dark:Ba[900]}}function y2(e){const{mode:t="light",contrastThreshold:n=3,tonalOffset:i=.2}=e,a=U(e,c2),o=e.primary||d2(t),r=e.secondary||u2(t),s=e.error||p2(t),l=e.info||m2(t),c=e.success||f2(t),d=e.warning||h2(t);function f(m){return Yx(m,Ul.text.primary)>=n?Ul.text.primary:Bm.text.primary}const h=({color:m,name:k,mainShade:_=500,lightShade:g=300,darkShade:b=700})=>{if(m=T({},m),!m.main&&m[_]&&(m.main=m[_]),!m.hasOwnProperty("main"))throw new Error(Kn(11,k?` (${k})`:"",_));if(typeof m.main!="string")throw new Error(Kn(12,k?` (${k})`:"",JSON.stringify(m.main)));return Rm(m,"light",g,i),Rm(m,"dark",b,i),m.contrastText||(m.contrastText=f(m.main)),m},u={dark:Ul,light:Bm};return Bt(T({common:T({},qo),mode:t,primary:h({color:o,name:"primary"}),secondary:h({color:r,name:"secondary",mainShade:"A400",lightShade:"A200",darkShade:"A700"}),error:h({color:s,name:"error"}),warning:h({color:d,name:"warning"}),info:h({color:l,name:"info"}),success:h({color:c,name:"success"}),grey:n2,contrastThreshold:n,getContrastText:f,augmentColor:h,tonalOffset:i},u[t]),a)}const g2=["fontFamily","fontSize","fontWeightLight","fontWeightRegular","fontWeightMedium","fontWeightBold","htmlFontSize","allVariants","pxToRem"];function _2(e){return Math.round(e*1e5)/1e5}const Om={textTransform:"uppercase"},zm='"Roboto", "Helvetica", "Arial", sans-serif';function b2(e,t){const n=typeof t=="function"?t(e):t,{fontFamily:i=zm,fontSize:a=14,fontWeightLight:o=300,fontWeightRegular:r=400,fontWeightMedium:s=500,fontWeightBold:l=700,htmlFontSize:c=16,allVariants:d,pxToRem:f}=n,h=U(n,g2),u=a/14,y=f||(_=>`${_/c*u}rem`),m=(_,g,b,w,I)=>T({fontFamily:i,fontWeight:_,fontSize:y(g),lineHeight:b},i===zm?{letterSpacing:`${_2(w/g)}em`}:{},I,d),k={h1:m(o,96,1.167,-1.5),h2:m(o,60,1.2,-.5),h3:m(r,48,1.167,0),h4:m(r,34,1.235,.25),h5:m(r,24,1.334,0),h6:m(s,20,1.6,.15),subtitle1:m(r,16,1.75,.15),subtitle2:m(s,14,1.57,.1),body1:m(r,16,1.5,.15),body2:m(r,14,1.43,.15),button:m(s,14,1.75,.4,Om),caption:m(r,12,1.66,.4),overline:m(r,12,2.66,1,Om),inherit:{fontFamily:"inherit",fontWeight:"inherit",fontSize:"inherit",lineHeight:"inherit",letterSpacing:"inherit"}};return Bt(T({htmlFontSize:c,pxToRem:y,fontFamily:i,fontSize:a,fontWeightLight:o,fontWeightRegular:r,fontWeightMedium:s,fontWeightBold:l},k),h,{clone:!1})}const v2=.2,w2=.14,x2=.12;function Te(...e){return[`${e[0]}px ${e[1]}px ${e[2]}px ${e[3]}px rgba(0,0,0,${v2})`,`${e[4]}px ${e[5]}px ${e[6]}px ${e[7]}px rgba(0,0,0,${w2})`,`${e[8]}px ${e[9]}px ${e[10]}px ${e[11]}px rgba(0,0,0,${x2})`].join(",")}const T2=["none",Te(0,2,1,-1,0,1,1,0,0,1,3,0),Te(0,3,1,-2,0,2,2,0,0,1,5,0),Te(0,3,3,-2,0,3,4,0,0,1,8,0),Te(0,2,4,-1,0,4,5,0,0,1,10,0),Te(0,3,5,-1,0,5,8,0,0,1,14,0),Te(0,3,5,-1,0,6,10,0,0,1,18,0),Te(0,4,5,-2,0,7,10,1,0,2,16,1),Te(0,5,5,-3,0,8,10,1,0,3,14,2),Te(0,5,6,-3,0,9,12,1,0,3,16,2),Te(0,6,6,-3,0,10,14,1,0,4,18,3),Te(0,6,7,-4,0,11,15,1,0,4,20,3),Te(0,7,8,-4,0,12,17,2,0,5,22,4),Te(0,7,8,-4,0,13,19,2,0,5,24,4),Te(0,7,9,-4,0,14,21,2,0,5,26,4),Te(0,8,9,-5,0,15,22,2,0,6,28,5),Te(0,8,10,-5,0,16,24,2,0,6,30,5),Te(0,8,11,-5,0,17,26,2,0,6,32,5),Te(0,9,11,-5,0,18,28,2,0,7,34,6),Te(0,9,12,-6,0,19,29,2,0,7,36,6),Te(0,10,13,-6,0,20,31,3,0,8,38,7),Te(0,10,13,-6,0,21,33,3,0,8,40,7),Te(0,10,14,-6,0,22,35,3,0,8,42,7),Te(0,11,14,-7,0,23,36,3,0,9,44,8),Te(0,11,15,-7,0,24,38,3,0,9,46,8)],k2=T2,I2=["duration","easing","delay"],q2={easeInOut:"cubic-bezier(0.4, 0, 0.2, 1)",easeOut:"cubic-bezier(0.0, 0, 0.2, 1)",easeIn:"cubic-bezier(0.4, 0, 1, 1)",sharp:"cubic-bezier(0.4, 0, 0.6, 1)"},C2={shortest:150,shorter:200,short:250,standard:300,complex:375,enteringScreen:225,leavingScreen:195};function Wm(e){return`${Math.round(e)}ms`}function D2(e){if(!e)return 0;const t=e/36;return Math.round((4+15*t**.25+t/5)*10)}function P2(e){const t=T({},q2,e.easing),n=T({},C2,e.duration);return T({getAutoHeightDuration:D2,create:(a=["all"],o={})=>{const{duration:r=n.standard,easing:s=t.easeInOut,delay:l=0}=o;return U(o,I2),(Array.isArray(a)?a:[a]).map(c=>`${c} ${typeof r=="string"?r:Wm(r)} ${s} ${typeof l=="string"?l:Wm(l)}`).join(",")}},e,{easing:t,duration:n})}const S2={mobileStepper:1e3,fab:1050,speedDial:1050,appBar:1100,drawer:1200,modal:1300,snackbar:1400,tooltip:1500},A2=S2,E2=["breakpoints","mixins","spacing","palette","transitions","typography","shape"];function Bg(e={},...t){const{mixins:n={},palette:i={},transitions:a={},typography:o={}}=e,r=U(e,E2);if(e.vars)throw new Error(Kn(18));const s=y2(i),l=zu(e);let c=Bt(l,{mixins:Jx(l.breakpoints,n),palette:s,shadows:k2.slice(),typography:b2(s,o),transitions:P2(a),zIndex:T({},A2)});return c=Bt(c,r),c=t.reduce((d,f)=>Bt(d,f),c),c.unstable_sxConfig=T({},il,r==null?void 0:r.unstable_sxConfig),c.unstable_sx=function(f){return al({sx:f,theme:this})},c}const N2=Bg(),sl=N2,Oo="$$material";function fe({props:e,name:t}){return Qx({props:e,name:t,defaultTheme:sl,themeId:Oo})}const Ht=e=>to(e)&&e!=="classes",B2=to,R2=Hx({themeId:Oo,defaultTheme:sl,rootShouldForwardProp:Ht}),F=R2;function O2(e){return pe("MuiSvgIcon",e)}oe("MuiSvgIcon",["root","colorPrimary","colorSecondary","colorAction","colorError","colorDisabled","fontSizeInherit","fontSizeSmall","fontSizeMedium","fontSizeLarge"]);const z2=["children","className","color","component","fontSize","htmlColor","inheritViewBox","titleAccess","viewBox"],W2=e=>{const{color:t,fontSize:n,classes:i}=e,a={root:["root",t!=="inherit"&&`color${Z(t)}`,`fontSize${Z(n)}`]};return me(a,O2,i)},j2=F("svg",{name:"MuiSvgIcon",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.color!=="inherit"&&t[`color${Z(n.color)}`],t[`fontSize${Z(n.fontSize)}`]]}})(({theme:e,ownerState:t})=>{var n,i,a,o,r,s,l,c,d,f,h,u,y;return{userSelect:"none",width:"1em",height:"1em",display:"inline-block",fill:t.hasSvgAsChild?void 0:"currentColor",flexShrink:0,transition:(n=e.transitions)==null||(i=n.create)==null?void 0:i.call(n,"fill",{duration:(a=e.transitions)==null||(a=a.duration)==null?void 0:a.shorter}),fontSize:{inherit:"inherit",small:((o=e.typography)==null||(r=o.pxToRem)==null?void 0:r.call(o,20))||"1.25rem",medium:((s=e.typography)==null||(l=s.pxToRem)==null?void 0:l.call(s,24))||"1.5rem",large:((c=e.typography)==null||(d=c.pxToRem)==null?void 0:d.call(c,35))||"2.1875rem"}[t.fontSize],color:(f=(h=(e.vars||e).palette)==null||(h=h[t.color])==null?void 0:h.main)!=null?f:{action:(u=(e.vars||e).palette)==null||(u=u.action)==null?void 0:u.active,disabled:(y=(e.vars||e).palette)==null||(y=y.action)==null?void 0:y.disabled,inherit:void 0}[t.color]}}),Rg=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiSvgIcon"}),{children:a,className:o,color:r="inherit",component:s="svg",fontSize:l="medium",htmlColor:c,inheritViewBox:d=!1,titleAccess:f,viewBox:h="0 0 24 24"}=i,u=U(i,z2),y=v.isValidElement(a)&&a.type==="svg",m=T({},i,{color:r,component:s,fontSize:l,instanceFontSize:t.fontSize,inheritViewBox:d,viewBox:h,hasSvgAsChild:y}),k={};d||(k.viewBox=h);const _=W2(m);return p.jsxs(j2,T({as:s,className:V(_.root,o),focusable:"false",color:c,"aria-hidden":f?void 0:!0,role:f?"img":void 0,ref:n},k,u,y&&a.props,{ownerState:m,children:[y?a.props.children:a,f?p.jsx("title",{children:f}):null]}))});Rg.muiName="SvgIcon";const jm=Rg;function Ci(e,t){function n(i,a){return p.jsx(jm,T({"data-testid":`${t}Icon`,ref:a},i,{children:e}))}return n.muiName=jm.muiName,v.memo(v.forwardRef(n))}const M2={configure:e=>{Tu.configure(e)}},L2=Object.freeze(Object.defineProperty({__proto__:null,capitalize:Z,createChainedFunction:ed,createSvgIcon:Ci,debounce:Os,deprecatedPropType:_v,isMuiElement:wr,ownerDocument:mt,ownerWindow:rn,requirePropFactory:bv,setRef:es,unstable_ClassNameGenerator:M2,unstable_useEnhancedEffect:Xn,unstable_useId:og,unsupportedProp:xv,useControlled:td,useEventCallback:fi,useForkRef:Ke,useIsFocusVisible:rg},Symbol.toStringTag,{value:"Module"})),F2=j_(L2);var Mm;function ju(){return Mm||(Mm=1,function(e){"use client";Object.defineProperty(e,"__esModule",{value:!0}),Object.defineProperty(e,"default",{enumerable:!0,get:function(){return t.createSvgIcon}});var t=F2}(Ml)),Ml}var U2=vu;Object.defineProperty(bu,"__esModule",{value:!0});var Og=bu.default=void 0,G2=U2(ju()),$2=p,V2=(0,G2.default)((0,$2.jsx)("path",{d:"M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"}),"Search");Og=bu.default=V2;var Mu={},H2=vu;Object.defineProperty(Mu,"__esModule",{value:!0});var zg=Mu.default=void 0,Z2=H2(ju()),Q2=p,K2=(0,Z2.default)((0,Q2.jsx)("path",{d:"M19 7v4H5.83l3.58-3.59L8 6l-6 6 6 6 1.41-1.41L5.83 13H21V7z"}),"KeyboardReturn");zg=Mu.default=K2;function Tn(e){return Array.isArray?Array.isArray(e):Mg(e)==="[object Array]"}const X2=1/0;function Y2(e){if(typeof e=="string")return e;let t=e+"";return t=="0"&&1/e==-X2?"-0":t}function J2(e){return e==null?"":Y2(e)}function tn(e){return typeof e=="string"}function Wg(e){return typeof e=="number"}function e3(e){return e===!0||e===!1||t3(e)&&Mg(e)=="[object Boolean]"}function jg(e){return typeof e=="object"}function t3(e){return jg(e)&&e!==null}function yt(e){return e!=null}function Gl(e){return!e.trim().length}function Mg(e){return e==null?e===void 0?"[object Undefined]":"[object Null]":Object.prototype.toString.call(e)}const n3="Incorrect 'index' type",i3=e=>`Invalid value for key ${e}`,a3=e=>`Pattern length exceeds max of ${e}.`,o3=e=>`Missing ${e} property in key`,r3=e=>`Property 'weight' in key '${e}' must be a positive integer`,Lm=Object.prototype.hasOwnProperty;class s3{constructor(t){this._keys=[],this._keyMap={};let n=0;t.forEach(i=>{let a=Lg(i);n+=a.weight,this._keys.push(a),this._keyMap[a.id]=a,n+=a.weight}),this._keys.forEach(i=>{i.weight/=n})}get(t){return this._keyMap[t]}keys(){return this._keys}toJSON(){return JSON.stringify(this._keys)}}function Lg(e){let t=null,n=null,i=null,a=1,o=null;if(tn(e)||Tn(e))i=e,t=Fm(e),n=ld(e);else{if(!Lm.call(e,"name"))throw new Error(o3("name"));const r=e.name;if(i=r,Lm.call(e,"weight")&&(a=e.weight,a<=0))throw new Error(r3(r));t=Fm(r),n=ld(r),o=e.getFn}return{path:t,id:n,weight:a,src:i,getFn:o}}function Fm(e){return Tn(e)?e:e.split(".")}function ld(e){return Tn(e)?e.join("."):e}function l3(e,t){let n=[],i=!1;const a=(o,r,s)=>{if(yt(o))if(!r[s])n.push(o);else{let l=r[s];const c=o[l];if(!yt(c))return;if(s===r.length-1&&(tn(c)||Wg(c)||e3(c)))n.push(J2(c));else if(Tn(c)){i=!0;for(let d=0,f=c.length;d<f;d+=1)a(c[d],r,s+1)}else r.length&&a(c,r,s+1)}};return a(e,tn(t)?t.split("."):t,0),i?n:n[0]}const c3={includeMatches:!1,findAllMatches:!1,minMatchCharLength:1},d3={isCaseSensitive:!1,includeScore:!1,keys:[],shouldSort:!0,sortFn:(e,t)=>e.score===t.score?e.idx<t.idx?-1:1:e.score<t.score?-1:1},u3={location:0,threshold:.6,distance:100},p3={useExtendedSearch:!1,getFn:l3,ignoreLocation:!1,ignoreFieldNorm:!1,fieldNormWeight:1};var H={...d3,...c3,...u3,...p3};const m3=/[^ ]+/g;function f3(e=1,t=3){const n=new Map,i=Math.pow(10,t);return{get(a){const o=a.match(m3).length;if(n.has(o))return n.get(o);const r=1/Math.pow(o,.5*e),s=parseFloat(Math.round(r*i)/i);return n.set(o,s),s},clear(){n.clear()}}}class Lu{constructor({getFn:t=H.getFn,fieldNormWeight:n=H.fieldNormWeight}={}){this.norm=f3(n,3),this.getFn=t,this.isCreated=!1,this.setIndexRecords()}setSources(t=[]){this.docs=t}setIndexRecords(t=[]){this.records=t}setKeys(t=[]){this.keys=t,this._keysMap={},t.forEach((n,i)=>{this._keysMap[n.id]=i})}create(){this.isCreated||!this.docs.length||(this.isCreated=!0,tn(this.docs[0])?this.docs.forEach((t,n)=>{this._addString(t,n)}):this.docs.forEach((t,n)=>{this._addObject(t,n)}),this.norm.clear())}add(t){const n=this.size();tn(t)?this._addString(t,n):this._addObject(t,n)}removeAt(t){this.records.splice(t,1);for(let n=t,i=this.size();n<i;n+=1)this.records[n].i-=1}getValueForItemAtKeyId(t,n){return t[this._keysMap[n]]}size(){return this.records.length}_addString(t,n){if(!yt(t)||Gl(t))return;let i={v:t,i:n,n:this.norm.get(t)};this.records.push(i)}_addObject(t,n){let i={i:n,$:{}};this.keys.forEach((a,o)=>{let r=a.getFn?a.getFn(t):this.getFn(t,a.path);if(yt(r)){if(Tn(r)){let s=[];const l=[{nestedArrIndex:-1,value:r}];for(;l.length;){const{nestedArrIndex:c,value:d}=l.pop();if(yt(d))if(tn(d)&&!Gl(d)){let f={v:d,i:c,n:this.norm.get(d)};s.push(f)}else Tn(d)&&d.forEach((f,h)=>{l.push({nestedArrIndex:h,value:f})})}i.$[o]=s}else if(tn(r)&&!Gl(r)){let s={v:r,n:this.norm.get(r)};i.$[o]=s}}}),this.records.push(i)}toJSON(){return{keys:this.keys,records:this.records}}}function Fg(e,t,{getFn:n=H.getFn,fieldNormWeight:i=H.fieldNormWeight}={}){const a=new Lu({getFn:n,fieldNormWeight:i});return a.setKeys(e.map(Lg)),a.setSources(t),a.create(),a}function h3(e,{getFn:t=H.getFn,fieldNormWeight:n=H.fieldNormWeight}={}){const{keys:i,records:a}=e,o=new Lu({getFn:t,fieldNormWeight:n});return o.setKeys(i),o.setIndexRecords(a),o}function rr(e,{errors:t=0,currentLocation:n=0,expectedLocation:i=0,distance:a=H.distance,ignoreLocation:o=H.ignoreLocation}={}){const r=t/e.length;if(o)return r;const s=Math.abs(i-n);return a?r+s/a:s?1:r}function y3(e=[],t=H.minMatchCharLength){let n=[],i=-1,a=-1,o=0;for(let r=e.length;o<r;o+=1){let s=e[o];s&&i===-1?i=o:!s&&i!==-1&&(a=o-1,a-i+1>=t&&n.push([i,a]),i=-1)}return e[o-1]&&o-i>=t&&n.push([i,o-1]),n}const ci=32;function g3(e,t,n,{location:i=H.location,distance:a=H.distance,threshold:o=H.threshold,findAllMatches:r=H.findAllMatches,minMatchCharLength:s=H.minMatchCharLength,includeMatches:l=H.includeMatches,ignoreLocation:c=H.ignoreLocation}={}){if(t.length>ci)throw new Error(a3(ci));const d=t.length,f=e.length,h=Math.max(0,Math.min(i,f));let u=o,y=h;const m=s>1||l,k=m?Array(f):[];let _;for(;(_=e.indexOf(t,y))>-1;){let x=rr(t,{currentLocation:_,expectedLocation:h,distance:a,ignoreLocation:c});if(u=Math.min(x,u),y=_+d,m){let C=0;for(;C<d;)k[_+C]=1,C+=1}}y=-1;let g=[],b=1,w=d+f;const I=1<<d-1;for(let x=0;x<d;x+=1){let C=0,S=w;for(;C<S;)rr(t,{errors:x,currentLocation:h+S,expectedLocation:h,distance:a,ignoreLocation:c})<=u?C=S:w=S,S=Math.floor((w-C)/2+C);w=S;let P=Math.max(1,h-S+1),B=r?f:Math.min(h+S,f)+d,O=Array(B+2);O[B+1]=(1<<x)-1;for(let E=B;E>=P;E-=1){let R=E-1,z=n[e.charAt(R)];if(m&&(k[R]=+!!z),O[E]=(O[E+1]<<1|1)&z,x&&(O[E]|=(g[E+1]|g[E])<<1|1|g[E+1]),O[E]&I&&(b=rr(t,{errors:x,currentLocation:R,expectedLocation:h,distance:a,ignoreLocation:c}),b<=u)){if(u=b,y=R,y<=h)break;P=Math.max(1,2*h-y)}}if(rr(t,{errors:x+1,currentLocation:h,expectedLocation:h,distance:a,ignoreLocation:c})>u)break;g=O}const q={isMatch:y>=0,score:Math.max(.001,b)};if(m){const x=y3(k,s);x.length?l&&(q.indices=x):q.isMatch=!1}return q}function _3(e){let t={};for(let n=0,i=e.length;n<i;n+=1){const a=e.charAt(n);t[a]=(t[a]||0)|1<<i-n-1}return t}class Ug{constructor(t,{location:n=H.location,threshold:i=H.threshold,distance:a=H.distance,includeMatches:o=H.includeMatches,findAllMatches:r=H.findAllMatches,minMatchCharLength:s=H.minMatchCharLength,isCaseSensitive:l=H.isCaseSensitive,ignoreLocation:c=H.ignoreLocation}={}){if(this.options={location:n,threshold:i,distance:a,includeMatches:o,findAllMatches:r,minMatchCharLength:s,isCaseSensitive:l,ignoreLocation:c},this.pattern=l?t:t.toLowerCase(),this.chunks=[],!this.pattern.length)return;const d=(h,u)=>{this.chunks.push({pattern:h,alphabet:_3(h),startIndex:u})},f=this.pattern.length;if(f>ci){let h=0;const u=f%ci,y=f-u;for(;h<y;)d(this.pattern.substr(h,ci),h),h+=ci;if(u){const m=f-ci;d(this.pattern.substr(m),m)}}else d(this.pattern,0)}searchIn(t){const{isCaseSensitive:n,includeMatches:i}=this.options;if(n||(t=t.toLowerCase()),this.pattern===t){let y={isMatch:!0,score:0};return i&&(y.indices=[[0,t.length-1]]),y}const{location:a,distance:o,threshold:r,findAllMatches:s,minMatchCharLength:l,ignoreLocation:c}=this.options;let d=[],f=0,h=!1;this.chunks.forEach(({pattern:y,alphabet:m,startIndex:k})=>{const{isMatch:_,score:g,indices:b}=g3(t,y,m,{location:a+k,distance:o,threshold:r,findAllMatches:s,minMatchCharLength:l,includeMatches:i,ignoreLocation:c});_&&(h=!0),f+=g,_&&b&&(d=[...d,...b])});let u={isMatch:h,score:h?f/this.chunks.length:1};return h&&i&&(u.indices=d),u}}class ni{constructor(t){this.pattern=t}static isMultiMatch(t){return Um(t,this.multiRegex)}static isSingleMatch(t){return Um(t,this.singleRegex)}search(){}}function Um(e,t){const n=e.match(t);return n?n[1]:null}class b3 extends ni{constructor(t){super(t)}static get type(){return"exact"}static get multiRegex(){return/^="(.*)"$/}static get singleRegex(){return/^=(.*)$/}search(t){const n=t===this.pattern;return{isMatch:n,score:n?0:1,indices:[0,this.pattern.length-1]}}}class v3 extends ni{constructor(t){super(t)}static get type(){return"inverse-exact"}static get multiRegex(){return/^!"(.*)"$/}static get singleRegex(){return/^!(.*)$/}search(t){const i=t.indexOf(this.pattern)===-1;return{isMatch:i,score:i?0:1,indices:[0,t.length-1]}}}class w3 extends ni{constructor(t){super(t)}static get type(){return"prefix-exact"}static get multiRegex(){return/^\^"(.*)"$/}static get singleRegex(){return/^\^(.*)$/}search(t){const n=t.startsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[0,this.pattern.length-1]}}}class x3 extends ni{constructor(t){super(t)}static get type(){return"inverse-prefix-exact"}static get multiRegex(){return/^!\^"(.*)"$/}static get singleRegex(){return/^!\^(.*)$/}search(t){const n=!t.startsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[0,t.length-1]}}}class T3 extends ni{constructor(t){super(t)}static get type(){return"suffix-exact"}static get multiRegex(){return/^"(.*)"\$$/}static get singleRegex(){return/^(.*)\$$/}search(t){const n=t.endsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[t.length-this.pattern.length,t.length-1]}}}class k3 extends ni{constructor(t){super(t)}static get type(){return"inverse-suffix-exact"}static get multiRegex(){return/^!"(.*)"\$$/}static get singleRegex(){return/^!(.*)\$$/}search(t){const n=!t.endsWith(this.pattern);return{isMatch:n,score:n?0:1,indices:[0,t.length-1]}}}class Gg extends ni{constructor(t,{location:n=H.location,threshold:i=H.threshold,distance:a=H.distance,includeMatches:o=H.includeMatches,findAllMatches:r=H.findAllMatches,minMatchCharLength:s=H.minMatchCharLength,isCaseSensitive:l=H.isCaseSensitive,ignoreLocation:c=H.ignoreLocation}={}){super(t),this._bitapSearch=new Ug(t,{location:n,threshold:i,distance:a,includeMatches:o,findAllMatches:r,minMatchCharLength:s,isCaseSensitive:l,ignoreLocation:c})}static get type(){return"fuzzy"}static get multiRegex(){return/^"(.*)"$/}static get singleRegex(){return/^(.*)$/}search(t){return this._bitapSearch.searchIn(t)}}class $g extends ni{constructor(t){super(t)}static get type(){return"include"}static get multiRegex(){return/^'"(.*)"$/}static get singleRegex(){return/^'(.*)$/}search(t){let n=0,i;const a=[],o=this.pattern.length;for(;(i=t.indexOf(this.pattern,n))>-1;)n=i+o,a.push([i,n-1]);const r=!!a.length;return{isMatch:r,score:r?0:1,indices:a}}}const cd=[b3,$g,w3,x3,k3,T3,v3,Gg],Gm=cd.length,I3=/ +(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)/,q3="|";function C3(e,t={}){return e.split(q3).map(n=>{let i=n.trim().split(I3).filter(o=>o&&!!o.trim()),a=[];for(let o=0,r=i.length;o<r;o+=1){const s=i[o];let l=!1,c=-1;for(;!l&&++c<Gm;){const d=cd[c];let f=d.isMultiMatch(s);f&&(a.push(new d(f,t)),l=!0)}if(!l)for(c=-1;++c<Gm;){const d=cd[c];let f=d.isSingleMatch(s);if(f){a.push(new d(f,t));break}}}return a})}const D3=new Set([Gg.type,$g.type]);class P3{constructor(t,{isCaseSensitive:n=H.isCaseSensitive,includeMatches:i=H.includeMatches,minMatchCharLength:a=H.minMatchCharLength,ignoreLocation:o=H.ignoreLocation,findAllMatches:r=H.findAllMatches,location:s=H.location,threshold:l=H.threshold,distance:c=H.distance}={}){this.query=null,this.options={isCaseSensitive:n,includeMatches:i,minMatchCharLength:a,findAllMatches:r,ignoreLocation:o,location:s,threshold:l,distance:c},this.pattern=n?t:t.toLowerCase(),this.query=C3(this.pattern,this.options)}static condition(t,n){return n.useExtendedSearch}searchIn(t){const n=this.query;if(!n)return{isMatch:!1,score:1};const{includeMatches:i,isCaseSensitive:a}=this.options;t=a?t:t.toLowerCase();let o=0,r=[],s=0;for(let l=0,c=n.length;l<c;l+=1){const d=n[l];r.length=0,o=0;for(let f=0,h=d.length;f<h;f+=1){const u=d[f],{isMatch:y,indices:m,score:k}=u.search(t);if(y){if(o+=1,s+=k,i){const _=u.constructor.type;D3.has(_)?r=[...r,...m]:r.push(m)}}else{s=0,o=0,r.length=0;break}}if(o){let f={isMatch:!0,score:s/o};return i&&(f.indices=r),f}}return{isMatch:!1,score:1}}}const dd=[];function S3(...e){dd.push(...e)}function ud(e,t){for(let n=0,i=dd.length;n<i;n+=1){let a=dd[n];if(a.condition(e,t))return new a(e,t)}return new Ug(e,t)}const is={AND:"$and",OR:"$or"},pd={PATH:"$path",PATTERN:"$val"},md=e=>!!(e[is.AND]||e[is.OR]),A3=e=>!!e[pd.PATH],E3=e=>!Tn(e)&&jg(e)&&!md(e),$m=e=>({[is.AND]:Object.keys(e).map(t=>({[t]:e[t]}))});function Vg(e,t,{auto:n=!0}={}){const i=a=>{let o=Object.keys(a);const r=A3(a);if(!r&&o.length>1&&!md(a))return i($m(a));if(E3(a)){const l=r?a[pd.PATH]:o[0],c=r?a[pd.PATTERN]:a[l];if(!tn(c))throw new Error(i3(l));const d={keyId:ld(l),pattern:c};return n&&(d.searcher=ud(c,t)),d}let s={children:[],operator:o[0]};return o.forEach(l=>{const c=a[l];Tn(c)&&c.forEach(d=>{s.children.push(i(d))})}),s};return md(e)||(e=$m(e)),i(e)}function N3(e,{ignoreFieldNorm:t=H.ignoreFieldNorm}){e.forEach(n=>{let i=1;n.matches.forEach(({key:a,norm:o,score:r})=>{const s=a?a.weight:null;i*=Math.pow(r===0&&s?Number.EPSILON:r,(s||1)*(t?1:o))}),n.score=i})}function B3(e,t){const n=e.matches;t.matches=[],yt(n)&&n.forEach(i=>{if(!yt(i.indices)||!i.indices.length)return;const{indices:a,value:o}=i;let r={indices:a,value:o};i.key&&(r.key=i.key.src),i.idx>-1&&(r.refIndex=i.idx),t.matches.push(r)})}function R3(e,t){t.score=e.score}function O3(e,t,{includeMatches:n=H.includeMatches,includeScore:i=H.includeScore}={}){const a=[];return n&&a.push(B3),i&&a.push(R3),e.map(o=>{const{idx:r}=o,s={item:t[r],refIndex:r};return a.length&&a.forEach(l=>{l(o,s)}),s})}class wa{constructor(t,n={},i){this.options={...H,...n},this.options.useExtendedSearch,this._keyStore=new s3(this.options.keys),this.setCollection(t,i)}setCollection(t,n){if(this._docs=t,n&&!(n instanceof Lu))throw new Error(n3);this._myIndex=n||Fg(this.options.keys,this._docs,{getFn:this.options.getFn,fieldNormWeight:this.options.fieldNormWeight})}add(t){yt(t)&&(this._docs.push(t),this._myIndex.add(t))}remove(t=()=>!1){const n=[];for(let i=0,a=this._docs.length;i<a;i+=1){const o=this._docs[i];t(o,i)&&(this.removeAt(i),i-=1,a-=1,n.push(o))}return n}removeAt(t){this._docs.splice(t,1),this._myIndex.removeAt(t)}getIndex(){return this._myIndex}search(t,{limit:n=-1}={}){const{includeMatches:i,includeScore:a,shouldSort:o,sortFn:r,ignoreFieldNorm:s}=this.options;let l=tn(t)?tn(this._docs[0])?this._searchStringList(t):this._searchObjectList(t):this._searchLogical(t);return N3(l,{ignoreFieldNorm:s}),o&&l.sort(r),Wg(n)&&n>-1&&(l=l.slice(0,n)),O3(l,this._docs,{includeMatches:i,includeScore:a})}_searchStringList(t){const n=ud(t,this.options),{records:i}=this._myIndex,a=[];return i.forEach(({v:o,i:r,n:s})=>{if(!yt(o))return;const{isMatch:l,score:c,indices:d}=n.searchIn(o);l&&a.push({item:o,idx:r,matches:[{score:c,value:o,norm:s,indices:d}]})}),a}_searchLogical(t){const n=Vg(t,this.options),i=(s,l,c)=>{if(!s.children){const{keyId:f,searcher:h}=s,u=this._findMatches({key:this._keyStore.get(f),value:this._myIndex.getValueForItemAtKeyId(l,f),searcher:h});return u&&u.length?[{idx:c,item:l,matches:u}]:[]}const d=[];for(let f=0,h=s.children.length;f<h;f+=1){const u=s.children[f],y=i(u,l,c);if(y.length)d.push(...y);else if(s.operator===is.AND)return[]}return d},a=this._myIndex.records,o={},r=[];return a.forEach(({$:s,i:l})=>{if(yt(s)){let c=i(n,s,l);c.length&&(o[l]||(o[l]={idx:l,item:s,matches:[]},r.push(o[l])),c.forEach(({matches:d})=>{o[l].matches.push(...d)}))}}),r}_searchObjectList(t){const n=ud(t,this.options),{keys:i,records:a}=this._myIndex,o=[];return a.forEach(({$:r,i:s})=>{if(!yt(r))return;let l=[];i.forEach((c,d)=>{l.push(...this._findMatches({key:c,value:r[d],searcher:n}))}),l.length&&o.push({idx:s,item:r,matches:l})}),o}_findMatches({key:t,value:n,searcher:i}){if(!yt(n))return[];let a=[];if(Tn(n))n.forEach(({v:o,i:r,n:s})=>{if(!yt(o))return;const{isMatch:l,score:c,indices:d}=i.searchIn(o);l&&a.push({score:c,key:t,value:o,idx:r,norm:s,indices:d})});else{const{v:o,n:r}=n,{isMatch:s,score:l,indices:c}=i.searchIn(o);s&&a.push({score:l,key:t,value:o,norm:r,indices:c})}return a}}wa.version="6.6.2";wa.createIndex=Fg;wa.parseIndex=h3;wa.config=H;wa.parseQuery=Vg;S3(P3);const Hg=v.createContext(),zo=()=>v.useContext(Hg),z3=({children:e})=>{const[t,n]=v.useState(""),[i,a]=v.useState(),[o,r]=v.useState(!1);return p.jsx(Hg.Provider,{value:{searchQuery:t,setSearchQuery:n,searchResults:i,setSearchResults:a,isSearchSubmitted:o,setIsSearchSubmitted:r},children:e})};function Zg(e,t){const n=JSON.parse(e);let i=[];function a(s,l){if(typeof l=="string"&&l.toLowerCase().includes(t.toLowerCase()))return l.trim();if(typeof l=="object")for(const c in l){const d=a(c,l[c]);c>0&&typeof d=="string"?i.push(s+": "+l[(c-"1").toString()]+" "+d):c==0&&l.length>1&&typeof d=="string"?i.push(s+": "+d+" "+l[1]):typeof d=="string"&&i.push(c+": "+d)}}for(const s in n)a(s,n[s]);const o=i[0];let r=[];try{const s=o.toLowerCase(),l=t.toLowerCase(),c=s.indexOf(l);if(c!==-1){const d=o.substring(0,c),f=o.substring(c,c+l.length),h=o.substring(c+l.length);r=[d,f,h]}}catch{r=[null,null,null]}return r}const W3=sn.plugins;let Vm=["name","metadata.description","entry_point_prefix","metadata.author"];function j3(e){const t=[],n=JSON.parse(JSON.stringify(e));return Object.entries(n).forEach(([a,o])=>{Object.entries(o.entry_points).forEach(([r,s])=>{for(const l in s){let c=["entry_points",r,l];o.entry_points[r][l]=JSON.stringify(o.entry_points[r][l]),Vm.push(c)}}),t.push(o)}),new wa(t,{keys:Vm,includeScore:!0,ignoreLocation:!0,threshold:.1,includeMatches:!0})}const M3=j3(W3);function L3(){const{searchQuery:e,setSearchQuery:t,setSearchResults:n,isSearchSubmitted:i,setIsSearchSubmitted:a}=zo(),o=l=>{t(l),document.querySelector(".suggestions-list").style.display="block",document.querySelector(".dropdown-search").style.display="block",(l==""||i==!0)&&(a(!1),document.querySelector(".dropdown-search").style.display="none");const c=document.querySelector(".enter-symbol");c&&(c.style.opacity=l?"1":"0")};let r=M3.search(e);const s=l=>{l.preventDefault(),e&&(n(r),a(!0),document.querySelector(".suggestions-list").style.display="none",document.querySelector(".dropdown-search").style.display="none")};return p.jsx(p.Fragment,{children:p.jsxs("div",{className:"search",children:[p.jsxs("form",{className:"search-form",children:[p.jsx("button",{style:{fontSize:"20px",minWidth:"90px",backgroundColor:"white",border:"1px solid #ccc",borderRadius:"4px"},onClick:l=>{s(l)},children:p.jsx(Og,{})}),p.jsxs("div",{className:"input-container",children:[p.jsx("input",{type:"text",placeholder:"Search for plugins",value:e,label:"search",onChange:l=>o(l.target.value)}),p.jsx(zg,{className:"enter-symbol"})]})]}),p.jsxs("ul",{className:"suggestions-list",children:[r.slice(0,3).map(l=>p.jsxs(p.Fragment,{children:[p.jsx(Ti,{to:`/${l.item.name}`,children:p.jsxs("h3",{className:"suggestion-item",children:[l.item.name," "]},l.item.name)}),p.jsx("ul",{children:l.matches.filter(c=>typeof c.key=="object").slice(0,1).map(c=>p.jsxs(p.Fragment,{children:[p.jsx(Ti,{to:`/${l.item.name}#${c.key[1]}.${c.key[2]}`,children:p.jsxs("li",{className:"suggestion-item",children:[c.key[2]," "]},c.key)}),p.jsx(Qg,{match_value:c.value})]}))})]})),p.jsx("button",{className:"dropdown-search",onClick:l=>{s(l)},children:" Search"})]})]})})}function F3(){const{searchResults:e,searchQuery:t}=zo();return p.jsxs(p.Fragment,{children:[p.jsxs("h2",{children:["Showing ",e.length," pages matching the search query."]}),e.length===0&&p.jsx("div",{children:p.jsxs("h3",{className:"submenu-entry",style:{textAlign:"center",color:"black"},children:["Can't find what you're looking for?",p.jsx("br",{}),"Join the AiiDA community on Discourse and request a plugin ",p.jsx("a",{href:"https://aiida.discourse.group/new-topic?title=Request%20for%20Plugin...&category=community/plugin-requests",target:"_blank",children:"here."})]})}),e.map(n=>p.jsx(p.Fragment,{children:p.jsxs("div",{className:"submenu-entry",children:[p.jsx(Ti,{to:`/${n.item.name}`,children:p.jsx("h3",{className:"suggestion-item",children:n.item.name},n.item.name)}),p.jsx("ul",{children:n.matches.filter(i=>typeof i.key=="object").map(i=>p.jsx(p.Fragment,{children:Zg(i.value,t)[0]!=null&&p.jsxs(p.Fragment,{children:[p.jsx(Ti,{to:`/${n.item.name}#${i.key[1]}.${i.key[2]}`,children:p.jsx("li",{className:"suggestion-item",children:i.key[2]},i.key)}),p.jsx(Qg,{match_value:i.value})]})}))})]})}))]})}function Qg({match_value:e}){const{searchQuery:t}=zo(),[n,i,a]=Zg(e,t);return p.jsx(p.Fragment,{children:n!=null&&p.jsxs("p",{children:[n,p.jsx("span",{style:{backgroundColor:"yellow"},children:i}),a,"..."]})})}function xa(){const e=ol(sl);return e[Oo]||e}const U3=e=>{let t;return e<1?t=5.11916*e**2:t=4.5*Math.log(e+1)+2,(t/100).toFixed(2)},Hm=U3,G3=Bg(),$3=Ox({themeId:Oo,defaultTheme:G3,defaultClassName:"MuiBox-root",generateClassName:Tu.generate}),V3=$3;function Wo({props:e,states:t,muiFormControl:n}){return t.reduce((i,a)=>(i[a]=e[a],n&&typeof e[a]>"u"&&(i[a]=n[a]),i),{})}const H3=v.createContext(void 0),Fu=H3;function jo(){return v.useContext(Fu)}function Z3(e){return pe("MuiFormLabel",e)}const Q3=oe("MuiFormLabel",["root","colorSecondary","focused","disabled","error","filled","required","asterisk"]),no=Q3,K3=["children","className","color","component","disabled","error","filled","focused","required"],X3=e=>{const{classes:t,color:n,focused:i,disabled:a,error:o,filled:r,required:s}=e,l={root:["root",`color${Z(n)}`,a&&"disabled",o&&"error",r&&"filled",i&&"focused",s&&"required"],asterisk:["asterisk",o&&"error"]};return me(l,Z3,t)},Y3=F("label",{name:"MuiFormLabel",slot:"Root",overridesResolver:({ownerState:e},t)=>T({},t.root,e.color==="secondary"&&t.colorSecondary,e.filled&&t.filled)})(({theme:e,ownerState:t})=>T({color:(e.vars||e).palette.text.secondary},e.typography.body1,{lineHeight:"1.4375em",padding:0,position:"relative",[`&.${no.focused}`]:{color:(e.vars||e).palette[t.color].main},[`&.${no.disabled}`]:{color:(e.vars||e).palette.text.disabled},[`&.${no.error}`]:{color:(e.vars||e).palette.error.main}})),J3=F("span",{name:"MuiFormLabel",slot:"Asterisk",overridesResolver:(e,t)=>t.asterisk})(({theme:e})=>({[`&.${no.error}`]:{color:(e.vars||e).palette.error.main}})),e6=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiFormLabel"}),{children:a,className:o,component:r="label"}=i,s=U(i,K3),l=jo(),c=Wo({props:i,muiFormControl:l,states:["color","required","focused","disabled","error","filled"]}),d=T({},i,{color:c.color||"primary",component:r,disabled:c.disabled,error:c.error,filled:c.filled,focused:c.focused,required:c.required}),f=X3(d);return p.jsxs(Y3,T({as:r,ownerState:d,className:V(f.root,o),ref:n},s,{children:[a,c.required&&p.jsxs(J3,{ownerState:d,"aria-hidden":!0,className:f.asterisk,children:[" ","*"]})]}))}),t6=e6;function n6(e){return pe("MuiInputLabel",e)}oe("MuiInputLabel",["root","focused","disabled","error","required","asterisk","formControl","sizeSmall","shrink","animated","standard","filled","outlined"]);const i6=["disableAnimation","margin","shrink","variant","className"],a6=e=>{const{classes:t,formControl:n,size:i,shrink:a,disableAnimation:o,variant:r,required:s}=e,l={root:["root",n&&"formControl",!o&&"animated",a&&"shrink",i&&i!=="normal"&&`size${Z(i)}`,r],asterisk:[s&&"asterisk"]},c=me(l,n6,t);return T({},t,c)},o6=F(t6,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiInputLabel",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[{[`& .${no.asterisk}`]:t.asterisk},t.root,n.formControl&&t.formControl,n.size==="small"&&t.sizeSmall,n.shrink&&t.shrink,!n.disableAnimation&&t.animated,t[n.variant]]}})(({theme:e,ownerState:t})=>T({display:"block",transformOrigin:"top left",whiteSpace:"nowrap",overflow:"hidden",textOverflow:"ellipsis",maxWidth:"100%"},t.formControl&&{position:"absolute",left:0,top:0,transform:"translate(0, 20px) scale(1)"},t.size==="small"&&{transform:"translate(0, 17px) scale(1)"},t.shrink&&{transform:"translate(0, -1.5px) scale(0.75)",transformOrigin:"top left",maxWidth:"133%"},!t.disableAnimation&&{transition:e.transitions.create(["color","transform","max-width"],{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut})},t.variant==="filled"&&T({zIndex:1,pointerEvents:"none",transform:"translate(12px, 16px) scale(1)",maxWidth:"calc(100% - 24px)"},t.size==="small"&&{transform:"translate(12px, 13px) scale(1)"},t.shrink&&T({userSelect:"none",pointerEvents:"auto",transform:"translate(12px, 7px) scale(0.75)",maxWidth:"calc(133% - 24px)"},t.size==="small"&&{transform:"translate(12px, 4px) scale(0.75)"})),t.variant==="outlined"&&T({zIndex:1,pointerEvents:"none",transform:"translate(14px, 16px) scale(1)",maxWidth:"calc(100% - 24px)"},t.size==="small"&&{transform:"translate(14px, 9px) scale(1)"},t.shrink&&{userSelect:"none",pointerEvents:"auto",maxWidth:"calc(133% - 32px)",transform:"translate(14px, -9px) scale(0.75)"}))),r6=v.forwardRef(function(t,n){const i=fe({name:"MuiInputLabel",props:t}),{disableAnimation:a=!1,shrink:o,className:r}=i,s=U(i,i6),l=jo();let c=o;typeof c>"u"&&l&&(c=l.filled||l.focused||l.adornedStart);const d=Wo({props:i,muiFormControl:l,states:["size","variant","required"]}),f=T({},i,{disableAnimation:a,formControl:l,shrink:c,size:d.size,variant:d.variant,required:d.required}),h=a6(f);return p.jsx(o6,T({"data-shrink":c,ownerState:f,ref:n,className:V(h.root,r)},s,{classes:h}))}),s6=r6,l6=v.createContext({}),fd=l6;function hd(e,t){return hd=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(i,a){return i.__proto__=a,i},hd(e,t)}function Kg(e,t){e.prototype=Object.create(t.prototype),e.prototype.constructor=e,hd(e,t)}const Zm={disabled:!1},as=Ut.createContext(null);var c6=function(t){return t.scrollTop},Ga="unmounted",ri="exited",si="entering",zi="entered",yd="exiting",In=function(e){Kg(t,e);function t(i,a){var o;o=e.call(this,i,a)||this;var r=a,s=r&&!r.isMounting?i.enter:i.appear,l;return o.appearStatus=null,i.in?s?(l=ri,o.appearStatus=si):l=zi:i.unmountOnExit||i.mountOnEnter?l=Ga:l=ri,o.state={status:l},o.nextCallback=null,o}t.getDerivedStateFromProps=function(a,o){var r=a.in;return r&&o.status===Ga?{status:ri}:null};var n=t.prototype;return n.componentDidMount=function(){this.updateStatus(!0,this.appearStatus)},n.componentDidUpdate=function(a){var o=null;if(a!==this.props){var r=this.state.status;this.props.in?r!==si&&r!==zi&&(o=si):(r===si||r===zi)&&(o=yd)}this.updateStatus(!1,o)},n.componentWillUnmount=function(){this.cancelNextCallback()},n.getTimeouts=function(){var a=this.props.timeout,o,r,s;return o=r=s=a,a!=null&&typeof a!="number"&&(o=a.exit,r=a.enter,s=a.appear!==void 0?a.appear:r),{exit:o,enter:r,appear:s}},n.updateStatus=function(a,o){if(a===void 0&&(a=!1),o!==null)if(this.cancelNextCallback(),o===si){if(this.props.unmountOnExit||this.props.mountOnEnter){var r=this.props.nodeRef?this.props.nodeRef.current:ar.findDOMNode(this);r&&c6(r)}this.performEnter(a)}else this.performExit();else this.props.unmountOnExit&&this.state.status===ri&&this.setState({status:Ga})},n.performEnter=function(a){var o=this,r=this.props.enter,s=this.context?this.context.isMounting:a,l=this.props.nodeRef?[s]:[ar.findDOMNode(this),s],c=l[0],d=l[1],f=this.getTimeouts(),h=s?f.appear:f.enter;if(!a&&!r||Zm.disabled){this.safeSetState({status:zi},function(){o.props.onEntered(c)});return}this.props.onEnter(c,d),this.safeSetState({status:si},function(){o.props.onEntering(c,d),o.onTransitionEnd(h,function(){o.safeSetState({status:zi},function(){o.props.onEntered(c,d)})})})},n.performExit=function(){var a=this,o=this.props.exit,r=this.getTimeouts(),s=this.props.nodeRef?void 0:ar.findDOMNode(this);if(!o||Zm.disabled){this.safeSetState({status:ri},function(){a.props.onExited(s)});return}this.props.onExit(s),this.safeSetState({status:yd},function(){a.props.onExiting(s),a.onTransitionEnd(r.exit,function(){a.safeSetState({status:ri},function(){a.props.onExited(s)})})})},n.cancelNextCallback=function(){this.nextCallback!==null&&(this.nextCallback.cancel(),this.nextCallback=null)},n.safeSetState=function(a,o){o=this.setNextCallback(o),this.setState(a,o)},n.setNextCallback=function(a){var o=this,r=!0;return this.nextCallback=function(s){r&&(r=!1,o.nextCallback=null,a(s))},this.nextCallback.cancel=function(){r=!1},this.nextCallback},n.onTransitionEnd=function(a,o){this.setNextCallback(o);var r=this.props.nodeRef?this.props.nodeRef.current:ar.findDOMNode(this),s=a==null&&!this.props.addEndListener;if(!r||s){setTimeout(this.nextCallback,0);return}if(this.props.addEndListener){var l=this.props.nodeRef?[this.nextCallback]:[r,this.nextCallback],c=l[0],d=l[1];this.props.addEndListener(c,d)}a!=null&&setTimeout(this.nextCallback,a)},n.render=function(){var a=this.state.status;if(a===Ga)return null;var o=this.props,r=o.children;o.in,o.mountOnEnter,o.unmountOnExit,o.appear,o.enter,o.exit,o.timeout,o.addEndListener,o.onEnter,o.onEntering,o.onEntered,o.onExit,o.onExiting,o.onExited,o.nodeRef;var s=U(o,["children","in","mountOnEnter","unmountOnExit","appear","enter","exit","timeout","addEndListener","onEnter","onEntering","onEntered","onExit","onExiting","onExited","nodeRef"]);return Ut.createElement(as.Provider,{value:null},typeof r=="function"?r(a,s):Ut.cloneElement(Ut.Children.only(r),s))},t}(Ut.Component);In.contextType=as;In.propTypes={};function Ri(){}In.defaultProps={in:!1,mountOnEnter:!1,unmountOnExit:!1,appear:!1,enter:!0,exit:!0,onEnter:Ri,onEntering:Ri,onEntered:Ri,onExit:Ri,onExiting:Ri,onExited:Ri};In.UNMOUNTED=Ga;In.EXITED=ri;In.ENTERING=si;In.ENTERED=zi;In.EXITING=yd;const Uu=In;function d6(e){if(e===void 0)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}function Gu(e,t){var n=function(o){return t&&v.isValidElement(o)?t(o):o},i=Object.create(null);return e&&v.Children.map(e,function(a){return a}).forEach(function(a){i[a.key]=n(a)}),i}function u6(e,t){e=e||{},t=t||{};function n(d){return d in t?t[d]:e[d]}var i=Object.create(null),a=[];for(var o in e)o in t?a.length&&(i[o]=a,a=[]):a.push(o);var r,s={};for(var l in t){if(i[l])for(r=0;r<i[l].length;r++){var c=i[l][r];s[i[l][r]]=n(c)}s[l]=n(l)}for(r=0;r<a.length;r++)s[a[r]]=n(a[r]);return s}function hi(e,t,n){return n[t]!=null?n[t]:e.props[t]}function p6(e,t){return Gu(e.children,function(n){return v.cloneElement(n,{onExited:t.bind(null,n),in:!0,appear:hi(n,"appear",e),enter:hi(n,"enter",e),exit:hi(n,"exit",e)})})}function m6(e,t,n){var i=Gu(e.children),a=u6(t,i);return Object.keys(a).forEach(function(o){var r=a[o];if(v.isValidElement(r)){var s=o in t,l=o in i,c=t[o],d=v.isValidElement(c)&&!c.props.in;l&&(!s||d)?a[o]=v.cloneElement(r,{onExited:n.bind(null,r),in:!0,exit:hi(r,"exit",e),enter:hi(r,"enter",e)}):!l&&s&&!d?a[o]=v.cloneElement(r,{in:!1}):l&&s&&v.isValidElement(c)&&(a[o]=v.cloneElement(r,{onExited:n.bind(null,r),in:c.props.in,exit:hi(r,"exit",e),enter:hi(r,"enter",e)}))}}),a}var f6=Object.values||function(e){return Object.keys(e).map(function(t){return e[t]})},h6={component:"div",childFactory:function(t){return t}},$u=function(e){Kg(t,e);function t(i,a){var o;o=e.call(this,i,a)||this;var r=o.handleExited.bind(d6(o));return o.state={contextValue:{isMounting:!0},handleExited:r,firstRender:!0},o}var n=t.prototype;return n.componentDidMount=function(){this.mounted=!0,this.setState({contextValue:{isMounting:!1}})},n.componentWillUnmount=function(){this.mounted=!1},t.getDerivedStateFromProps=function(a,o){var r=o.children,s=o.handleExited,l=o.firstRender;return{children:l?p6(a,s):m6(a,r,s),firstRender:!1}},n.handleExited=function(a,o){var r=Gu(this.props.children);a.key in r||(a.props.onExited&&a.props.onExited(o),this.mounted&&this.setState(function(s){var l=T({},s.children);return delete l[a.key],{children:l}}))},n.render=function(){var a=this.props,o=a.component,r=a.childFactory,s=U(a,["component","childFactory"]),l=this.state.contextValue,c=f6(this.state.children).map(r);return delete s.appear,delete s.enter,delete s.exit,o===null?Ut.createElement(as.Provider,{value:l},c):Ut.createElement(as.Provider,{value:l},Ut.createElement(o,s,c))},t}(Ut.Component);$u.propTypes={};$u.defaultProps=h6;const y6=$u;function g6(e){const{className:t,classes:n,pulsate:i=!1,rippleX:a,rippleY:o,rippleSize:r,in:s,onExited:l,timeout:c}=e,[d,f]=v.useState(!1),h=V(t,n.ripple,n.rippleVisible,i&&n.ripplePulsate),u={width:r,height:r,top:-(r/2)+o,left:-(r/2)+a},y=V(n.child,d&&n.childLeaving,i&&n.childPulsate);return!s&&!d&&f(!0),v.useEffect(()=>{if(!s&&l!=null){const m=setTimeout(l,c);return()=>{clearTimeout(m)}}},[l,s,c]),p.jsx("span",{className:h,style:u,children:p.jsx("span",{className:y})})}const _6=oe("MuiTouchRipple",["root","ripple","rippleVisible","ripplePulsate","child","childLeaving","childPulsate"]),Pt=_6,b6=["center","classes","className"];let ll=e=>e,Qm,Km,Xm,Ym;const gd=550,v6=80,w6=Eu(Qm||(Qm=ll`
  0% {
    transform: scale(0);
    opacity: 0.1;
  }

  100% {
    transform: scale(1);
    opacity: 0.3;
  }
`)),x6=Eu(Km||(Km=ll`
  0% {
    opacity: 1;
  }

  100% {
    opacity: 0;
  }
`)),T6=Eu(Xm||(Xm=ll`
  0% {
    transform: scale(1);
  }

  50% {
    transform: scale(0.92);
  }

  100% {
    transform: scale(1);
  }
`)),k6=F("span",{name:"MuiTouchRipple",slot:"Root"})({overflow:"hidden",pointerEvents:"none",position:"absolute",zIndex:0,top:0,right:0,bottom:0,left:0,borderRadius:"inherit"}),I6=F(g6,{name:"MuiTouchRipple",slot:"Ripple"})(Ym||(Ym=ll`
  opacity: 0;
  position: absolute;

  &.${0} {
    opacity: 0.3;
    transform: scale(1);
    animation-name: ${0};
    animation-duration: ${0}ms;
    animation-timing-function: ${0};
  }

  &.${0} {
    animation-duration: ${0}ms;
  }

  & .${0} {
    opacity: 1;
    display: block;
    width: 100%;
    height: 100%;
    border-radius: 50%;
    background-color: currentColor;
  }

  & .${0} {
    opacity: 0;
    animation-name: ${0};
    animation-duration: ${0}ms;
    animation-timing-function: ${0};
  }

  & .${0} {
    position: absolute;
    /* @noflip */
    left: 0px;
    top: 0;
    animation-name: ${0};
    animation-duration: 2500ms;
    animation-timing-function: ${0};
    animation-iteration-count: infinite;
    animation-delay: 200ms;
  }
`),Pt.rippleVisible,w6,gd,({theme:e})=>e.transitions.easing.easeInOut,Pt.ripplePulsate,({theme:e})=>e.transitions.duration.shorter,Pt.child,Pt.childLeaving,x6,gd,({theme:e})=>e.transitions.easing.easeInOut,Pt.childPulsate,T6,({theme:e})=>e.transitions.easing.easeInOut),q6=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiTouchRipple"}),{center:a=!1,classes:o={},className:r}=i,s=U(i,b6),[l,c]=v.useState([]),d=v.useRef(0),f=v.useRef(null);v.useEffect(()=>{f.current&&(f.current(),f.current=null)},[l]);const h=v.useRef(!1),u=v.useRef(0),y=v.useRef(null),m=v.useRef(null);v.useEffect(()=>()=>{u.current&&clearTimeout(u.current)},[]);const k=v.useCallback(w=>{const{pulsate:I,rippleX:q,rippleY:x,rippleSize:C,cb:S}=w;c(P=>[...P,p.jsx(I6,{classes:{ripple:V(o.ripple,Pt.ripple),rippleVisible:V(o.rippleVisible,Pt.rippleVisible),ripplePulsate:V(o.ripplePulsate,Pt.ripplePulsate),child:V(o.child,Pt.child),childLeaving:V(o.childLeaving,Pt.childLeaving),childPulsate:V(o.childPulsate,Pt.childPulsate)},timeout:gd,pulsate:I,rippleX:q,rippleY:x,rippleSize:C},d.current)]),d.current+=1,f.current=S},[o]),_=v.useCallback((w={},I={},q=()=>{})=>{const{pulsate:x=!1,center:C=a||I.pulsate,fakeElement:S=!1}=I;if((w==null?void 0:w.type)==="mousedown"&&h.current){h.current=!1;return}(w==null?void 0:w.type)==="touchstart"&&(h.current=!0);const P=S?null:m.current,B=P?P.getBoundingClientRect():{width:0,height:0,left:0,top:0};let O,M,E;if(C||w===void 0||w.clientX===0&&w.clientY===0||!w.clientX&&!w.touches)O=Math.round(B.width/2),M=Math.round(B.height/2);else{const{clientX:R,clientY:z}=w.touches&&w.touches.length>0?w.touches[0]:w;O=Math.round(R-B.left),M=Math.round(z-B.top)}if(C)E=Math.sqrt((2*B.width**2+B.height**2)/3),E%2===0&&(E+=1);else{const R=Math.max(Math.abs((P?P.clientWidth:0)-O),O)*2+2,z=Math.max(Math.abs((P?P.clientHeight:0)-M),M)*2+2;E=Math.sqrt(R**2+z**2)}w!=null&&w.touches?y.current===null&&(y.current=()=>{k({pulsate:x,rippleX:O,rippleY:M,rippleSize:E,cb:q})},u.current=setTimeout(()=>{y.current&&(y.current(),y.current=null)},v6)):k({pulsate:x,rippleX:O,rippleY:M,rippleSize:E,cb:q})},[a,k]),g=v.useCallback(()=>{_({},{pulsate:!0})},[_]),b=v.useCallback((w,I)=>{if(clearTimeout(u.current),(w==null?void 0:w.type)==="touchend"&&y.current){y.current(),y.current=null,u.current=setTimeout(()=>{b(w,I)});return}y.current=null,c(q=>q.length>0?q.slice(1):q),f.current=I},[]);return v.useImperativeHandle(n,()=>({pulsate:g,start:_,stop:b}),[g,_,b]),p.jsx(k6,T({className:V(Pt.root,o.root,r),ref:m},s,{children:p.jsx(y6,{component:null,exit:!0,children:l})}))}),C6=q6;function D6(e){return pe("MuiButtonBase",e)}const P6=oe("MuiButtonBase",["root","disabled","focusVisible"]),S6=P6,A6=["action","centerRipple","children","className","component","disabled","disableRipple","disableTouchRipple","focusRipple","focusVisibleClassName","LinkComponent","onBlur","onClick","onContextMenu","onDragLeave","onFocus","onFocusVisible","onKeyDown","onKeyUp","onMouseDown","onMouseLeave","onMouseUp","onTouchEnd","onTouchMove","onTouchStart","tabIndex","TouchRippleProps","touchRippleRef","type"],E6=e=>{const{disabled:t,focusVisible:n,focusVisibleClassName:i,classes:a}=e,r=me({root:["root",t&&"disabled",n&&"focusVisible"]},D6,a);return n&&i&&(r.root+=` ${i}`),r},N6=F("button",{name:"MuiButtonBase",slot:"Root",overridesResolver:(e,t)=>t.root})({display:"inline-flex",alignItems:"center",justifyContent:"center",position:"relative",boxSizing:"border-box",WebkitTapHighlightColor:"transparent",backgroundColor:"transparent",outline:0,border:0,margin:0,borderRadius:0,padding:0,cursor:"pointer",userSelect:"none",verticalAlign:"middle",MozAppearance:"none",WebkitAppearance:"none",textDecoration:"none",color:"inherit","&::-moz-focus-inner":{borderStyle:"none"},[`&.${S6.disabled}`]:{pointerEvents:"none",cursor:"default"},"@media print":{colorAdjust:"exact"}}),B6=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiButtonBase"}),{action:a,centerRipple:o=!1,children:r,className:s,component:l="button",disabled:c=!1,disableRipple:d=!1,disableTouchRipple:f=!1,focusRipple:h=!1,LinkComponent:u="a",onBlur:y,onClick:m,onContextMenu:k,onDragLeave:_,onFocus:g,onFocusVisible:b,onKeyDown:w,onKeyUp:I,onMouseDown:q,onMouseLeave:x,onMouseUp:C,onTouchEnd:S,onTouchMove:P,onTouchStart:B,tabIndex:O=0,TouchRippleProps:M,touchRippleRef:E,type:R}=i,z=U(i,A6),L=v.useRef(null),D=v.useRef(null),N=Ke(D,E),{isFocusVisibleRef:W,onFocus:ee,onBlur:Q,ref:Ne}=rg(),[Y,ve]=v.useState(!1);c&&Y&&ve(!1),v.useImperativeHandle(a,()=>({focusVisible:()=>{ve(!0),L.current.focus()}}),[]);const[se,Ge]=v.useState(!1);v.useEffect(()=>{Ge(!0)},[]);const It=se&&!d&&!c;v.useEffect(()=>{Y&&h&&!d&&se&&D.current.pulsate()},[d,h,Y,se]);function Be($,dn,Ta=f){return fi(G=>(dn&&dn(G),!Ta&&D.current&&D.current[$](G),!0))}const rt=Be("start",q),ae=Be("stop",k),Ie=Be("stop",_),K=Be("stop",C),de=Be("stop",$=>{Y&&$.preventDefault(),x&&x($)}),we=Be("start",B),qn=Be("stop",S),qt=Be("stop",P),Ct=Be("stop",$=>{Q($),W.current===!1&&ve(!1),y&&y($)},!1),Wt=fi($=>{L.current||(L.current=$.currentTarget),ee($),W.current===!0&&(ve(!0),b&&b($)),g&&g($)}),Dt=()=>{const $=L.current;return l&&l!=="button"&&!($.tagName==="A"&&$.href)},qe=v.useRef(!1),ln=fi($=>{h&&!qe.current&&Y&&D.current&&$.key===" "&&(qe.current=!0,D.current.stop($,()=>{D.current.start($)})),$.target===$.currentTarget&&Dt()&&$.key===" "&&$.preventDefault(),w&&w($),$.target===$.currentTarget&&Dt()&&$.key==="Enter"&&!c&&($.preventDefault(),m&&m($))}),st=fi($=>{h&&$.key===" "&&D.current&&Y&&!$.defaultPrevented&&(qe.current=!1,D.current.stop($,()=>{D.current.pulsate($)})),I&&I($),m&&$.target===$.currentTarget&&Dt()&&$.key===" "&&!$.defaultPrevented&&m($)});let xe=l;xe==="button"&&(z.href||z.to)&&(xe=u);const Zt={};xe==="button"?(Zt.type=R===void 0?"button":R,Zt.disabled=c):(!z.href&&!z.to&&(Zt.role="button"),c&&(Zt["aria-disabled"]=c));const Cn=Ke(n,Ne,L),cn=T({},i,{centerRipple:o,component:l,disabled:c,disableRipple:d,disableTouchRipple:f,focusRipple:h,tabIndex:O,focusVisible:Y}),he=E6(cn);return p.jsxs(N6,T({as:xe,className:V(he.root,s),ownerState:cn,onBlur:Ct,onClick:m,onContextMenu:ae,onFocus:Wt,onKeyDown:ln,onKeyUp:st,onMouseDown:rt,onMouseLeave:de,onMouseUp:K,onDragLeave:Ie,onTouchEnd:qn,onTouchMove:qt,onTouchStart:we,ref:Cn,tabIndex:c?-1:O,type:R},Zt,z,{children:[r,It?p.jsx(C6,T({ref:N,center:o},M)):null]}))}),Xg=B6;function R6(e){return pe("MuiDivider",e)}const O6=oe("MuiDivider",["root","absolute","fullWidth","inset","middle","flexItem","light","vertical","withChildren","withChildrenVertical","textAlignRight","textAlignLeft","wrapper","wrapperVertical"]),Jm=O6,z6=["absolute","children","className","component","flexItem","light","orientation","role","textAlign","variant"],W6=e=>{const{absolute:t,children:n,classes:i,flexItem:a,light:o,orientation:r,textAlign:s,variant:l}=e;return me({root:["root",t&&"absolute",l,o&&"light",r==="vertical"&&"vertical",a&&"flexItem",n&&"withChildren",n&&r==="vertical"&&"withChildrenVertical",s==="right"&&r!=="vertical"&&"textAlignRight",s==="left"&&r!=="vertical"&&"textAlignLeft"],wrapper:["wrapper",r==="vertical"&&"wrapperVertical"]},R6,i)},j6=F("div",{name:"MuiDivider",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.absolute&&t.absolute,t[n.variant],n.light&&t.light,n.orientation==="vertical"&&t.vertical,n.flexItem&&t.flexItem,n.children&&t.withChildren,n.children&&n.orientation==="vertical"&&t.withChildrenVertical,n.textAlign==="right"&&n.orientation!=="vertical"&&t.textAlignRight,n.textAlign==="left"&&n.orientation!=="vertical"&&t.textAlignLeft]}})(({theme:e,ownerState:t})=>T({margin:0,flexShrink:0,borderWidth:0,borderStyle:"solid",borderColor:(e.vars||e).palette.divider,borderBottomWidth:"thin"},t.absolute&&{position:"absolute",bottom:0,left:0,width:"100%"},t.light&&{borderColor:e.vars?`rgba(${e.vars.palette.dividerChannel} / 0.08)`:yn(e.palette.divider,.08)},t.variant==="inset"&&{marginLeft:72},t.variant==="middle"&&t.orientation==="horizontal"&&{marginLeft:e.spacing(2),marginRight:e.spacing(2)},t.variant==="middle"&&t.orientation==="vertical"&&{marginTop:e.spacing(1),marginBottom:e.spacing(1)},t.orientation==="vertical"&&{height:"100%",borderBottomWidth:0,borderRightWidth:"thin"},t.flexItem&&{alignSelf:"stretch",height:"auto"}),({ownerState:e})=>T({},e.children&&{display:"flex",whiteSpace:"nowrap",textAlign:"center",border:0,"&::before, &::after":{content:'""',alignSelf:"center"}}),({theme:e,ownerState:t})=>T({},t.children&&t.orientation!=="vertical"&&{"&::before, &::after":{width:"100%",borderTop:`thin solid ${(e.vars||e).palette.divider}`}}),({theme:e,ownerState:t})=>T({},t.children&&t.orientation==="vertical"&&{flexDirection:"column","&::before, &::after":{height:"100%",borderLeft:`thin solid ${(e.vars||e).palette.divider}`}}),({ownerState:e})=>T({},e.textAlign==="right"&&e.orientation!=="vertical"&&{"&::before":{width:"90%"},"&::after":{width:"10%"}},e.textAlign==="left"&&e.orientation!=="vertical"&&{"&::before":{width:"10%"},"&::after":{width:"90%"}})),M6=F("span",{name:"MuiDivider",slot:"Wrapper",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.wrapper,n.orientation==="vertical"&&t.wrapperVertical]}})(({theme:e,ownerState:t})=>T({display:"inline-block",paddingLeft:`calc(${e.spacing(1)} * 1.2)`,paddingRight:`calc(${e.spacing(1)} * 1.2)`},t.orientation==="vertical"&&{paddingTop:`calc(${e.spacing(1)} * 1.2)`,paddingBottom:`calc(${e.spacing(1)} * 1.2)`})),Yg=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiDivider"}),{absolute:a=!1,children:o,className:r,component:s=o?"div":"hr",flexItem:l=!1,light:c=!1,orientation:d="horizontal",role:f=s!=="hr"?"separator":void 0,textAlign:h="center",variant:u="fullWidth"}=i,y=U(i,z6),m=T({},i,{absolute:a,component:s,flexItem:l,light:c,orientation:d,role:f,textAlign:h,variant:u}),k=W6(m);return p.jsx(j6,T({as:s,className:V(k.root,r),role:f,ref:n,ownerState:m},y,{children:o?p.jsx(M6,{className:k.wrapper,ownerState:m,children:o}):null}))});Yg.muiSkipListHighlight=!0;const ef=Yg,L6=oe("MuiListItemIcon",["root","alignItemsFlexStart"]),tf=L6;function F6(e){return pe("MuiTypography",e)}oe("MuiTypography",["root","h1","h2","h3","h4","h5","h6","subtitle1","subtitle2","body1","body2","inherit","button","caption","overline","alignLeft","alignRight","alignCenter","alignJustify","noWrap","gutterBottom","paragraph"]);const U6=["align","className","component","gutterBottom","noWrap","paragraph","variant","variantMapping"],G6=e=>{const{align:t,gutterBottom:n,noWrap:i,paragraph:a,variant:o,classes:r}=e,s={root:["root",o,e.align!=="inherit"&&`align${Z(t)}`,n&&"gutterBottom",i&&"noWrap",a&&"paragraph"]};return me(s,F6,r)},$6=F("span",{name:"MuiTypography",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.variant&&t[n.variant],n.align!=="inherit"&&t[`align${Z(n.align)}`],n.noWrap&&t.noWrap,n.gutterBottom&&t.gutterBottom,n.paragraph&&t.paragraph]}})(({theme:e,ownerState:t})=>T({margin:0},t.variant==="inherit"&&{font:"inherit"},t.variant!=="inherit"&&e.typography[t.variant],t.align!=="inherit"&&{textAlign:t.align},t.noWrap&&{overflow:"hidden",textOverflow:"ellipsis",whiteSpace:"nowrap"},t.gutterBottom&&{marginBottom:"0.35em"},t.paragraph&&{marginBottom:16})),nf={h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",h6:"h6",subtitle1:"h6",subtitle2:"h6",body1:"p",body2:"p",inherit:"p"},V6={primary:"primary.main",textPrimary:"text.primary",secondary:"secondary.main",textSecondary:"text.secondary",error:"error.main"},H6=e=>V6[e]||e,Z6=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiTypography"}),a=H6(i.color),o=Eg(T({},i,{color:a})),{align:r="inherit",className:s,component:l,gutterBottom:c=!1,noWrap:d=!1,paragraph:f=!1,variant:h="body1",variantMapping:u=nf}=o,y=U(o,U6),m=T({},o,{align:r,color:a,className:s,component:l,gutterBottom:c,noWrap:d,paragraph:f,variant:h,variantMapping:u}),k=l||(f?"p":u[h]||nf[h])||"span",_=G6(m);return p.jsx($6,T({as:k,ref:n,ownerState:m,className:V(_.root,s)},y))}),Jg=Z6,Q6=oe("MuiListItemText",["root","multiline","dense","inset","primary","secondary"]),af=Q6;function K6(e){return pe("MuiMenuItem",e)}const X6=oe("MuiMenuItem",["root","focusVisible","dense","disabled","divider","gutters","selected"]),Ra=X6,Y6=["autoFocus","component","dense","divider","disableGutters","focusVisibleClassName","role","tabIndex","className"],J6=(e,t)=>{const{ownerState:n}=e;return[t.root,n.dense&&t.dense,n.divider&&t.divider,!n.disableGutters&&t.gutters]},eT=e=>{const{disabled:t,dense:n,divider:i,disableGutters:a,selected:o,classes:r}=e,l=me({root:["root",n&&"dense",t&&"disabled",!a&&"gutters",i&&"divider",o&&"selected"]},K6,r);return T({},r,l)},tT=F(Xg,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiMenuItem",slot:"Root",overridesResolver:J6})(({theme:e,ownerState:t})=>T({},e.typography.body1,{display:"flex",justifyContent:"flex-start",alignItems:"center",position:"relative",textDecoration:"none",minHeight:48,paddingTop:6,paddingBottom:6,boxSizing:"border-box",whiteSpace:"nowrap"},!t.disableGutters&&{paddingLeft:16,paddingRight:16},t.divider&&{borderBottom:`1px solid ${(e.vars||e).palette.divider}`,backgroundClip:"padding-box"},{"&:hover":{textDecoration:"none",backgroundColor:(e.vars||e).palette.action.hover,"@media (hover: none)":{backgroundColor:"transparent"}},[`&.${Ra.selected}`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / ${e.vars.palette.action.selectedOpacity})`:yn(e.palette.primary.main,e.palette.action.selectedOpacity),[`&.${Ra.focusVisible}`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / calc(${e.vars.palette.action.selectedOpacity} + ${e.vars.palette.action.focusOpacity}))`:yn(e.palette.primary.main,e.palette.action.selectedOpacity+e.palette.action.focusOpacity)}},[`&.${Ra.selected}:hover`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / calc(${e.vars.palette.action.selectedOpacity} + ${e.vars.palette.action.hoverOpacity}))`:yn(e.palette.primary.main,e.palette.action.selectedOpacity+e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / ${e.vars.palette.action.selectedOpacity})`:yn(e.palette.primary.main,e.palette.action.selectedOpacity)}},[`&.${Ra.focusVisible}`]:{backgroundColor:(e.vars||e).palette.action.focus},[`&.${Ra.disabled}`]:{opacity:(e.vars||e).palette.action.disabledOpacity},[`& + .${Jm.root}`]:{marginTop:e.spacing(1),marginBottom:e.spacing(1)},[`& + .${Jm.inset}`]:{marginLeft:52},[`& .${af.root}`]:{marginTop:0,marginBottom:0},[`& .${af.inset}`]:{paddingLeft:36},[`& .${tf.root}`]:{minWidth:36}},!t.dense&&{[e.breakpoints.up("sm")]:{minHeight:"auto"}},t.dense&&T({minHeight:32,paddingTop:4,paddingBottom:4},e.typography.body2,{[`& .${tf.root} svg`]:{fontSize:"1.25rem"}}))),nT=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiMenuItem"}),{autoFocus:a=!1,component:o="li",dense:r=!1,divider:s=!1,disableGutters:l=!1,focusVisibleClassName:c,role:d="menuitem",tabIndex:f,className:h}=i,u=U(i,Y6),y=v.useContext(fd),m=v.useMemo(()=>({dense:r||y.dense||!1,disableGutters:l}),[y.dense,r,l]),k=v.useRef(null);Xn(()=>{a&&k.current&&k.current.focus()},[a]);const _=T({},i,{dense:m.dense,divider:s,disableGutters:l}),g=eT(i),b=Ke(k,n);let w;return i.disabled||(w=f!==void 0?f:-1),p.jsx(fd.Provider,{value:m,children:p.jsx(tT,T({ref:b,role:d,tabIndex:w,component:o,focusVisibleClassName:V(g.focusVisible,c),className:V(g.root,h)},u,{ownerState:_,classes:g}))})}),$l=nT;function of(e){return e!=null&&!(Array.isArray(e)&&e.length===0)}function os(e,t=!1){return e&&(of(e.value)&&e.value!==""||t&&of(e.defaultValue)&&e.defaultValue!=="")}function iT(e){return e.startAdornment}function aT(e){return pe("MuiFormControl",e)}oe("MuiFormControl",["root","marginNone","marginNormal","marginDense","fullWidth","disabled"]);const oT=["children","className","color","component","disabled","error","focused","fullWidth","hiddenLabel","margin","required","size","variant"],rT=e=>{const{classes:t,margin:n,fullWidth:i}=e,a={root:["root",n!=="none"&&`margin${Z(n)}`,i&&"fullWidth"]};return me(a,aT,t)},sT=F("div",{name:"MuiFormControl",slot:"Root",overridesResolver:({ownerState:e},t)=>T({},t.root,t[`margin${Z(e.margin)}`],e.fullWidth&&t.fullWidth)})(({ownerState:e})=>T({display:"inline-flex",flexDirection:"column",position:"relative",minWidth:0,padding:0,margin:0,border:0,verticalAlign:"top"},e.margin==="normal"&&{marginTop:16,marginBottom:8},e.margin==="dense"&&{marginTop:8,marginBottom:4},e.fullWidth&&{width:"100%"})),lT=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiFormControl"}),{children:a,className:o,color:r="primary",component:s="div",disabled:l=!1,error:c=!1,focused:d,fullWidth:f=!1,hiddenLabel:h=!1,margin:u="none",required:y=!1,size:m="medium",variant:k="outlined"}=i,_=U(i,oT),g=T({},i,{color:r,component:s,disabled:l,error:c,fullWidth:f,hiddenLabel:h,margin:u,required:y,size:m,variant:k}),b=rT(g),[w,I]=v.useState(()=>{let M=!1;return a&&v.Children.forEach(a,E=>{if(!wr(E,["Input","Select"]))return;const R=wr(E,["Select"])?E.props.input:E;R&&iT(R.props)&&(M=!0)}),M}),[q,x]=v.useState(()=>{let M=!1;return a&&v.Children.forEach(a,E=>{wr(E,["Input","Select"])&&(os(E.props,!0)||os(E.props.inputProps,!0))&&(M=!0)}),M}),[C,S]=v.useState(!1);l&&C&&S(!1);const P=d!==void 0&&!l?d:C;let B;const O=v.useMemo(()=>({adornedStart:w,setAdornedStart:I,color:r,disabled:l,error:c,filled:q,focused:P,fullWidth:f,hiddenLabel:h,size:m,onBlur:()=>{S(!1)},onEmpty:()=>{x(!1)},onFilled:()=>{x(!0)},onFocus:()=>{S(!0)},registerEffect:B,required:y,variant:k}),[w,r,l,c,q,P,f,h,B,y,m,k]);return p.jsx(Fu.Provider,{value:O,children:p.jsx(sT,T({as:s,ownerState:g,className:V(b.root,o),ref:n},_,{children:a}))})}),cT=lT;function rs(e){return typeof e=="string"}function dT(e,t,n){return e===void 0||rs(e)?t:T({},t,{ownerState:T({},t.ownerState,n)})}function e_(e,t=[]){if(e===void 0)return{};const n={};return Object.keys(e).filter(i=>i.match(/^on[A-Z]/)&&typeof e[i]=="function"&&!t.includes(i)).forEach(i=>{n[i]=e[i]}),n}function uT(e,t,n){return typeof e=="function"?e(t,n):e}function rf(e){if(e===void 0)return{};const t={};return Object.keys(e).filter(n=>!(n.match(/^on[A-Z]/)&&typeof e[n]=="function")).forEach(n=>{t[n]=e[n]}),t}function pT(e){const{getSlotProps:t,additionalProps:n,externalSlotProps:i,externalForwardedProps:a,className:o}=e;if(!t){const u=V(a==null?void 0:a.className,i==null?void 0:i.className,o,n==null?void 0:n.className),y=T({},n==null?void 0:n.style,a==null?void 0:a.style,i==null?void 0:i.style),m=T({},n,a,i);return u.length>0&&(m.className=u),Object.keys(y).length>0&&(m.style=y),{props:m,internalRef:void 0}}const r=e_(T({},a,i)),s=rf(i),l=rf(a),c=t(r),d=V(c==null?void 0:c.className,n==null?void 0:n.className,o,a==null?void 0:a.className,i==null?void 0:i.className),f=T({},c==null?void 0:c.style,n==null?void 0:n.style,a==null?void 0:a.style,i==null?void 0:i.style),h=T({},c,n,l,s);return d.length>0&&(h.className=d),Object.keys(f).length>0&&(h.style=f),{props:h,internalRef:c.ref}}const mT=["elementType","externalSlotProps","ownerState","skipResolvingSlotProps"];function pa(e){var t;const{elementType:n,externalSlotProps:i,ownerState:a,skipResolvingSlotProps:o=!1}=e,r=U(e,mT),s=o?{}:uT(i,a),{props:l,internalRef:c}=pT(T({},r,{externalSlotProps:s})),d=Ke(c,s==null?void 0:s.ref,(t=e.additionalProps)==null?void 0:t.ref);return dT(n,T({},l,{ref:d}),a)}function fT(e){return pe("MuiList",e)}oe("MuiList",["root","padding","dense","subheader"]);const hT=["children","className","component","dense","disablePadding","subheader"],yT=e=>{const{classes:t,disablePadding:n,dense:i,subheader:a}=e;return me({root:["root",!n&&"padding",i&&"dense",a&&"subheader"]},fT,t)},gT=F("ul",{name:"MuiList",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,!n.disablePadding&&t.padding,n.dense&&t.dense,n.subheader&&t.subheader]}})(({ownerState:e})=>T({listStyle:"none",margin:0,padding:0,position:"relative"},!e.disablePadding&&{paddingTop:8,paddingBottom:8},e.subheader&&{paddingTop:0})),_T=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiList"}),{children:a,className:o,component:r="ul",dense:s=!1,disablePadding:l=!1,subheader:c}=i,d=U(i,hT),f=v.useMemo(()=>({dense:s}),[s]),h=T({},i,{component:r,dense:s,disablePadding:l}),u=yT(h);return p.jsx(fd.Provider,{value:f,children:p.jsxs(gT,T({as:r,className:V(u.root,o),ref:n,ownerState:h},d,{children:[c,a]}))})}),bT=_T,vT=["actions","autoFocus","autoFocusItem","children","className","disabledItemsFocusable","disableListWrap","onKeyDown","variant"];function Vl(e,t,n){return e===t?e.firstChild:t&&t.nextElementSibling?t.nextElementSibling:n?null:e.firstChild}function sf(e,t,n){return e===t?n?e.firstChild:e.lastChild:t&&t.previousElementSibling?t.previousElementSibling:n?null:e.lastChild}function t_(e,t){if(t===void 0)return!0;let n=e.innerText;return n===void 0&&(n=e.textContent),n=n.trim().toLowerCase(),n.length===0?!1:t.repeating?n[0]===t.keys[0]:n.indexOf(t.keys.join(""))===0}function Oa(e,t,n,i,a,o){let r=!1,s=a(e,t,t?n:!1);for(;s;){if(s===e.firstChild){if(r)return!1;r=!0}const l=i?!1:s.disabled||s.getAttribute("aria-disabled")==="true";if(!s.hasAttribute("tabindex")||!t_(s,o)||l)s=a(e,s,n);else return s.focus(),!0}return!1}const wT=v.forwardRef(function(t,n){const{actions:i,autoFocus:a=!1,autoFocusItem:o=!1,children:r,className:s,disabledItemsFocusable:l=!1,disableListWrap:c=!1,onKeyDown:d,variant:f="selectedMenu"}=t,h=U(t,vT),u=v.useRef(null),y=v.useRef({keys:[],repeating:!0,previousKeyMatched:!0,lastTime:null});Xn(()=>{a&&u.current.focus()},[a]),v.useImperativeHandle(i,()=>({adjustStyleForScrollbar:(b,w)=>{const I=!u.current.style.width;if(b.clientHeight<u.current.clientHeight&&I){const q=`${sg(mt(b))}px`;u.current.style[w.direction==="rtl"?"paddingLeft":"paddingRight"]=q,u.current.style.width=`calc(100% + ${q})`}return u.current}}),[]);const m=b=>{const w=u.current,I=b.key,q=mt(w).activeElement;if(I==="ArrowDown")b.preventDefault(),Oa(w,q,c,l,Vl);else if(I==="ArrowUp")b.preventDefault(),Oa(w,q,c,l,sf);else if(I==="Home")b.preventDefault(),Oa(w,null,c,l,Vl);else if(I==="End")b.preventDefault(),Oa(w,null,c,l,sf);else if(I.length===1){const x=y.current,C=I.toLowerCase(),S=performance.now();x.keys.length>0&&(S-x.lastTime>500?(x.keys=[],x.repeating=!0,x.previousKeyMatched=!0):x.repeating&&C!==x.keys[0]&&(x.repeating=!1)),x.lastTime=S,x.keys.push(C);const P=q&&!x.repeating&&t_(q,x);x.previousKeyMatched&&(P||Oa(w,q,!1,l,Vl,x))?b.preventDefault():x.previousKeyMatched=!1}d&&d(b)},k=Ke(u,n);let _=-1;v.Children.forEach(r,(b,w)=>{if(!v.isValidElement(b)){_===w&&(_+=1,_>=r.length&&(_=-1));return}b.props.disabled||(f==="selectedMenu"&&b.props.selected||_===-1)&&(_=w),_===w&&(b.props.disabled||b.props.muiSkipListHighlight||b.type.muiSkipListHighlight)&&(_+=1,_>=r.length&&(_=-1))});const g=v.Children.map(r,(b,w)=>{if(w===_){const I={};return o&&(I.autoFocus=!0),b.props.tabIndex===void 0&&f==="selectedMenu"&&(I.tabIndex=0),v.cloneElement(b,I)}return b});return p.jsx(bT,T({role:"menu",ref:k,className:s,onKeyDown:m,tabIndex:a?0:-1},h,{children:g}))}),xT=wT,TT=["input","select","textarea","a[href]","button","[tabindex]","audio[controls]","video[controls]",'[contenteditable]:not([contenteditable="false"])'].join(",");function kT(e){const t=parseInt(e.getAttribute("tabindex")||"",10);return Number.isNaN(t)?e.contentEditable==="true"||(e.nodeName==="AUDIO"||e.nodeName==="VIDEO"||e.nodeName==="DETAILS")&&e.getAttribute("tabindex")===null?0:e.tabIndex:t}function IT(e){if(e.tagName!=="INPUT"||e.type!=="radio"||!e.name)return!1;const t=i=>e.ownerDocument.querySelector(`input[type="radio"]${i}`);let n=t(`[name="${e.name}"]:checked`);return n||(n=t(`[name="${e.name}"]`)),n!==e}function qT(e){return!(e.disabled||e.tagName==="INPUT"&&e.type==="hidden"||IT(e))}function CT(e){const t=[],n=[];return Array.from(e.querySelectorAll(TT)).forEach((i,a)=>{const o=kT(i);o===-1||!qT(i)||(o===0?t.push(i):n.push({documentOrder:a,tabIndex:o,node:i}))}),n.sort((i,a)=>i.tabIndex===a.tabIndex?i.documentOrder-a.documentOrder:i.tabIndex-a.tabIndex).map(i=>i.node).concat(t)}function DT(){return!0}function PT(e){const{children:t,disableAutoFocus:n=!1,disableEnforceFocus:i=!1,disableRestoreFocus:a=!1,getTabbable:o=CT,isEnabled:r=DT,open:s}=e,l=v.useRef(!1),c=v.useRef(null),d=v.useRef(null),f=v.useRef(null),h=v.useRef(null),u=v.useRef(!1),y=v.useRef(null),m=Ke(t.ref,y),k=v.useRef(null);v.useEffect(()=>{!s||!y.current||(u.current=!n)},[n,s]),v.useEffect(()=>{if(!s||!y.current)return;const b=mt(y.current);return y.current.contains(b.activeElement)||(y.current.hasAttribute("tabIndex")||y.current.setAttribute("tabIndex","-1"),u.current&&y.current.focus()),()=>{a||(f.current&&f.current.focus&&(l.current=!0,f.current.focus()),f.current=null)}},[s]),v.useEffect(()=>{if(!s||!y.current)return;const b=mt(y.current),w=x=>{k.current=x,!(i||!r()||x.key!=="Tab")&&b.activeElement===y.current&&x.shiftKey&&(l.current=!0,d.current&&d.current.focus())},I=()=>{const x=y.current;if(x===null)return;if(!b.hasFocus()||!r()||l.current){l.current=!1;return}if(x.contains(b.activeElement)||i&&b.activeElement!==c.current&&b.activeElement!==d.current)return;if(b.activeElement!==h.current)h.current=null;else if(h.current!==null)return;if(!u.current)return;let C=[];if((b.activeElement===c.current||b.activeElement===d.current)&&(C=o(y.current)),C.length>0){var S,P;const B=!!((S=k.current)!=null&&S.shiftKey&&((P=k.current)==null?void 0:P.key)==="Tab"),O=C[0],M=C[C.length-1];typeof O!="string"&&typeof M!="string"&&(B?M.focus():O.focus())}else x.focus()};b.addEventListener("focusin",I),b.addEventListener("keydown",w,!0);const q=setInterval(()=>{b.activeElement&&b.activeElement.tagName==="BODY"&&I()},50);return()=>{clearInterval(q),b.removeEventListener("focusin",I),b.removeEventListener("keydown",w,!0)}},[n,i,a,r,s,o]);const _=b=>{f.current===null&&(f.current=b.relatedTarget),u.current=!0,h.current=b.target;const w=t.props.onFocus;w&&w(b)},g=b=>{f.current===null&&(f.current=b.relatedTarget),u.current=!0};return p.jsxs(v.Fragment,{children:[p.jsx("div",{tabIndex:s?0:-1,onFocus:g,ref:c,"data-testid":"sentinelStart"}),v.cloneElement(t,{ref:m,onFocus:_}),p.jsx("div",{tabIndex:s?0:-1,onFocus:g,ref:d,"data-testid":"sentinelEnd"})]})}function ST(e){return typeof e=="function"?e():e}const AT=v.forwardRef(function(t,n){const{children:i,container:a,disablePortal:o=!1}=t,[r,s]=v.useState(null),l=Ke(v.isValidElement(i)?i.ref:null,n);if(Xn(()=>{o||s(ST(a)||document.body)},[a,o]),Xn(()=>{if(r&&!o)return es(n,r),()=>{es(n,null)}},[n,r,o]),o){if(v.isValidElement(i)){const c={ref:l};return v.cloneElement(i,c)}return p.jsx(v.Fragment,{children:i})}return p.jsx(v.Fragment,{children:r&&Ts.createPortal(i,r)})});function ET(e){const t=mt(e);return t.body===e?rn(e).innerWidth>t.documentElement.clientWidth:e.scrollHeight>e.clientHeight}function io(e,t){t?e.setAttribute("aria-hidden","true"):e.removeAttribute("aria-hidden")}function lf(e){return parseInt(rn(e).getComputedStyle(e).paddingRight,10)||0}function NT(e){const n=["TEMPLATE","SCRIPT","STYLE","LINK","MAP","META","NOSCRIPT","PICTURE","COL","COLGROUP","PARAM","SLOT","SOURCE","TRACK"].indexOf(e.tagName)!==-1,i=e.tagName==="INPUT"&&e.getAttribute("type")==="hidden";return n||i}function cf(e,t,n,i,a){const o=[t,n,...i];[].forEach.call(e.children,r=>{const s=o.indexOf(r)===-1,l=!NT(r);s&&l&&io(r,a)})}function Hl(e,t){let n=-1;return e.some((i,a)=>t(i)?(n=a,!0):!1),n}function BT(e,t){const n=[],i=e.container;if(!t.disableScrollLock){if(ET(i)){const r=sg(mt(i));n.push({value:i.style.paddingRight,property:"padding-right",el:i}),i.style.paddingRight=`${lf(i)+r}px`;const s=mt(i).querySelectorAll(".mui-fixed");[].forEach.call(s,l=>{n.push({value:l.style.paddingRight,property:"padding-right",el:l}),l.style.paddingRight=`${lf(l)+r}px`})}let o;if(i.parentNode instanceof DocumentFragment)o=mt(i).body;else{const r=i.parentElement,s=rn(i);o=(r==null?void 0:r.nodeName)==="HTML"&&s.getComputedStyle(r).overflowY==="scroll"?r:i}n.push({value:o.style.overflow,property:"overflow",el:o},{value:o.style.overflowX,property:"overflow-x",el:o},{value:o.style.overflowY,property:"overflow-y",el:o}),o.style.overflow="hidden"}return()=>{n.forEach(({value:o,el:r,property:s})=>{o?r.style.setProperty(s,o):r.style.removeProperty(s)})}}function RT(e){const t=[];return[].forEach.call(e.children,n=>{n.getAttribute("aria-hidden")==="true"&&t.push(n)}),t}class OT{constructor(){this.containers=void 0,this.modals=void 0,this.modals=[],this.containers=[]}add(t,n){let i=this.modals.indexOf(t);if(i!==-1)return i;i=this.modals.length,this.modals.push(t),t.modalRef&&io(t.modalRef,!1);const a=RT(n);cf(n,t.mount,t.modalRef,a,!0);const o=Hl(this.containers,r=>r.container===n);return o!==-1?(this.containers[o].modals.push(t),i):(this.containers.push({modals:[t],container:n,restore:null,hiddenSiblings:a}),i)}mount(t,n){const i=Hl(this.containers,o=>o.modals.indexOf(t)!==-1),a=this.containers[i];a.restore||(a.restore=BT(a,n))}remove(t,n=!0){const i=this.modals.indexOf(t);if(i===-1)return i;const a=Hl(this.containers,r=>r.modals.indexOf(t)!==-1),o=this.containers[a];if(o.modals.splice(o.modals.indexOf(t),1),this.modals.splice(i,1),o.modals.length===0)o.restore&&o.restore(),t.modalRef&&io(t.modalRef,n),cf(o.container,t.mount,t.modalRef,o.hiddenSiblings,!1),this.containers.splice(a,1);else{const r=o.modals[o.modals.length-1];r.modalRef&&io(r.modalRef,!1)}return i}isTopModal(t){return this.modals.length>0&&this.modals[this.modals.length-1]===t}}function zT(e){return typeof e=="function"?e():e}function WT(e){return e?e.props.hasOwnProperty("in"):!1}const jT=new OT;function MT(e){const{container:t,disableEscapeKeyDown:n=!1,disableScrollLock:i=!1,manager:a=jT,closeAfterTransition:o=!1,onTransitionEnter:r,onTransitionExited:s,children:l,onClose:c,open:d,rootRef:f}=e,h=v.useRef({}),u=v.useRef(null),y=v.useRef(null),m=Ke(y,f),[k,_]=v.useState(!d),g=WT(l);let b=!0;(e["aria-hidden"]==="false"||e["aria-hidden"]===!1)&&(b=!1);const w=()=>mt(u.current),I=()=>(h.current.modalRef=y.current,h.current.mount=u.current,h.current),q=()=>{a.mount(I(),{disableScrollLock:i}),y.current&&(y.current.scrollTop=0)},x=fi(()=>{const z=zT(t)||w().body;a.add(I(),z),y.current&&q()}),C=v.useCallback(()=>a.isTopModal(I()),[a]),S=fi(z=>{u.current=z,z&&(d&&C()?q():y.current&&io(y.current,b))}),P=v.useCallback(()=>{a.remove(I(),b)},[b,a]);v.useEffect(()=>()=>{P()},[P]),v.useEffect(()=>{d?x():(!g||!o)&&P()},[d,P,g,o,x]);const B=z=>L=>{var D;(D=z.onKeyDown)==null||D.call(z,L),!(L.key!=="Escape"||!C())&&(n||(L.stopPropagation(),c&&c(L,"escapeKeyDown")))},O=z=>L=>{var D;(D=z.onClick)==null||D.call(z,L),L.target===L.currentTarget&&c&&c(L,"backdropClick")};return{getRootProps:(z={})=>{const L=e_(e);delete L.onTransitionEnter,delete L.onTransitionExited;const D=T({},L,z);return T({role:"presentation"},D,{onKeyDown:B(D),ref:m})},getBackdropProps:(z={})=>{const L=z;return T({"aria-hidden":!0},L,{onClick:O(L),open:d})},getTransitionProps:()=>{const z=()=>{_(!1),r&&r()},L=()=>{_(!0),s&&s(),o&&P()};return{onEnter:ed(z,l==null?void 0:l.props.onEnter),onExited:ed(L,l==null?void 0:l.props.onExited)}},rootRef:m,portalRef:S,isTopModal:C,exited:k,hasTransition:g}}const LT=["onChange","maxRows","minRows","style","value"];function sr(e){return parseInt(e,10)||0}const FT={shadow:{visibility:"hidden",position:"absolute",overflow:"hidden",height:0,top:0,left:0,transform:"translateZ(0)"}};function df(e){return e==null||Object.keys(e).length===0||e.outerHeightStyle===0&&!e.overflow}const UT=v.forwardRef(function(t,n){const{onChange:i,maxRows:a,minRows:o=1,style:r,value:s}=t,l=U(t,LT),{current:c}=v.useRef(s!=null),d=v.useRef(null),f=Ke(n,d),h=v.useRef(null),u=v.useRef(0),[y,m]=v.useState({outerHeightStyle:0}),k=v.useCallback(()=>{const I=d.current,x=rn(I).getComputedStyle(I);if(x.width==="0px")return{outerHeightStyle:0};const C=h.current;C.style.width=x.width,C.value=I.value||t.placeholder||"x",C.value.slice(-1)===`
`&&(C.value+=" ");const S=x.boxSizing,P=sr(x.paddingBottom)+sr(x.paddingTop),B=sr(x.borderBottomWidth)+sr(x.borderTopWidth),O=C.scrollHeight;C.value="x";const M=C.scrollHeight;let E=O;o&&(E=Math.max(Number(o)*M,E)),a&&(E=Math.min(Number(a)*M,E)),E=Math.max(E,M);const R=E+(S==="border-box"?P+B:0),z=Math.abs(E-O)<=1;return{outerHeightStyle:R,overflow:z}},[a,o,t.placeholder]),_=(I,q)=>{const{outerHeightStyle:x,overflow:C}=q;return u.current<20&&(x>0&&Math.abs((I.outerHeightStyle||0)-x)>1||I.overflow!==C)?(u.current+=1,{overflow:C,outerHeightStyle:x}):I},g=v.useCallback(()=>{const I=k();df(I)||m(q=>_(q,I))},[k]),b=()=>{const I=k();df(I)||Ts.flushSync(()=>{m(q=>_(q,I))})};v.useEffect(()=>{const I=()=>{u.current=0,d.current&&b()},q=Os(()=>{u.current=0,d.current&&b()});let x;const C=d.current,S=rn(C);return S.addEventListener("resize",q),typeof ResizeObserver<"u"&&(x=new ResizeObserver(I),x.observe(C)),()=>{q.clear(),S.removeEventListener("resize",q),x&&x.disconnect()}}),Xn(()=>{g()}),v.useEffect(()=>{u.current=0},[s]);const w=I=>{u.current=0,c||g(),i&&i(I)};return p.jsxs(v.Fragment,{children:[p.jsx("textarea",T({value:s,onChange:w,ref:f,rows:o,style:T({height:y.outerHeightStyle,overflow:y.overflow?"hidden":void 0},r)},l)),p.jsx("textarea",{"aria-hidden":!0,className:t.className,readOnly:!0,ref:h,tabIndex:-1,style:T({},FT.shadow,r,{paddingTop:0,paddingBottom:0})})]})}),Vu=e=>e.scrollTop;function ma(e,t){var n,i;const{timeout:a,easing:o,style:r={}}=e;return{duration:(n=r.transitionDuration)!=null?n:typeof a=="number"?a:a[t.mode]||0,easing:(i=r.transitionTimingFunction)!=null?i:typeof o=="object"?o[t.mode]:o,delay:r.transitionDelay}}const GT=["addEndListener","appear","children","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"];function _d(e){return`scale(${e}, ${e**2})`}const $T={entering:{opacity:1,transform:_d(1)},entered:{opacity:1,transform:"none"}},Zl=typeof navigator<"u"&&/^((?!chrome|android).)*(safari|mobile)/i.test(navigator.userAgent)&&/(os |version\/)15(.|_)4/i.test(navigator.userAgent),n_=v.forwardRef(function(t,n){const{addEndListener:i,appear:a=!0,children:o,easing:r,in:s,onEnter:l,onEntered:c,onEntering:d,onExit:f,onExited:h,onExiting:u,style:y,timeout:m="auto",TransitionComponent:k=Uu}=t,_=U(t,GT),g=v.useRef(),b=v.useRef(),w=xa(),I=v.useRef(null),q=Ke(I,o.ref,n),x=R=>z=>{if(R){const L=I.current;z===void 0?R(L):R(L,z)}},C=x(d),S=x((R,z)=>{Vu(R);const{duration:L,delay:D,easing:N}=ma({style:y,timeout:m,easing:r},{mode:"enter"});let W;m==="auto"?(W=w.transitions.getAutoHeightDuration(R.clientHeight),b.current=W):W=L,R.style.transition=[w.transitions.create("opacity",{duration:W,delay:D}),w.transitions.create("transform",{duration:Zl?W:W*.666,delay:D,easing:N})].join(","),l&&l(R,z)}),P=x(c),B=x(u),O=x(R=>{const{duration:z,delay:L,easing:D}=ma({style:y,timeout:m,easing:r},{mode:"exit"});let N;m==="auto"?(N=w.transitions.getAutoHeightDuration(R.clientHeight),b.current=N):N=z,R.style.transition=[w.transitions.create("opacity",{duration:N,delay:L}),w.transitions.create("transform",{duration:Zl?N:N*.666,delay:Zl?L:L||N*.333,easing:D})].join(","),R.style.opacity=0,R.style.transform=_d(.75),f&&f(R)}),M=x(h),E=R=>{m==="auto"&&(g.current=setTimeout(R,b.current||0)),i&&i(I.current,R)};return v.useEffect(()=>()=>{clearTimeout(g.current)},[]),p.jsx(k,T({appear:a,in:s,nodeRef:I,onEnter:S,onEntered:P,onEntering:C,onExit:O,onExited:M,onExiting:B,addEndListener:E,timeout:m==="auto"?null:m},_,{children:(R,z)=>v.cloneElement(o,T({style:T({opacity:0,transform:_d(.75),visibility:R==="exited"&&!s?"hidden":void 0},$T[R],y,o.props.style),ref:q},z))}))});n_.muiSupportAuto=!0;const VT=n_,HT=["addEndListener","appear","children","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"],ZT={entering:{opacity:1},entered:{opacity:1}},QT=v.forwardRef(function(t,n){const i=xa(),a={enter:i.transitions.duration.enteringScreen,exit:i.transitions.duration.leavingScreen},{addEndListener:o,appear:r=!0,children:s,easing:l,in:c,onEnter:d,onEntered:f,onEntering:h,onExit:u,onExited:y,onExiting:m,style:k,timeout:_=a,TransitionComponent:g=Uu}=t,b=U(t,HT),w=v.useRef(null),I=Ke(w,s.ref,n),q=E=>R=>{if(E){const z=w.current;R===void 0?E(z):E(z,R)}},x=q(h),C=q((E,R)=>{Vu(E);const z=ma({style:k,timeout:_,easing:l},{mode:"enter"});E.style.webkitTransition=i.transitions.create("opacity",z),E.style.transition=i.transitions.create("opacity",z),d&&d(E,R)}),S=q(f),P=q(m),B=q(E=>{const R=ma({style:k,timeout:_,easing:l},{mode:"exit"});E.style.webkitTransition=i.transitions.create("opacity",R),E.style.transition=i.transitions.create("opacity",R),u&&u(E)}),O=q(y),M=E=>{o&&o(w.current,E)};return p.jsx(g,T({appear:r,in:c,nodeRef:w,onEnter:C,onEntered:S,onEntering:x,onExit:B,onExited:O,onExiting:P,addEndListener:M,timeout:_},b,{children:(E,R)=>v.cloneElement(s,T({style:T({opacity:0,visibility:E==="exited"&&!c?"hidden":void 0},ZT[E],k,s.props.style),ref:I},R))}))}),i_=QT;function KT(e){return pe("MuiBackdrop",e)}oe("MuiBackdrop",["root","invisible"]);const XT=["children","className","component","components","componentsProps","invisible","open","slotProps","slots","TransitionComponent","transitionDuration"],YT=e=>{const{classes:t,invisible:n}=e;return me({root:["root",n&&"invisible"]},KT,t)},JT=F("div",{name:"MuiBackdrop",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.invisible&&t.invisible]}})(({ownerState:e})=>T({position:"fixed",display:"flex",alignItems:"center",justifyContent:"center",right:0,bottom:0,top:0,left:0,backgroundColor:"rgba(0, 0, 0, 0.5)",WebkitTapHighlightColor:"transparent"},e.invisible&&{backgroundColor:"transparent"})),ek=v.forwardRef(function(t,n){var i,a,o;const r=fe({props:t,name:"MuiBackdrop"}),{children:s,className:l,component:c="div",components:d={},componentsProps:f={},invisible:h=!1,open:u,slotProps:y={},slots:m={},TransitionComponent:k=i_,transitionDuration:_}=r,g=U(r,XT),b=T({},r,{component:c,invisible:h}),w=YT(b),I=(i=y.root)!=null?i:f.root;return p.jsx(k,T({in:u,timeout:_},g,{children:p.jsx(JT,T({"aria-hidden":!0},I,{as:(a=(o=m.root)!=null?o:d.Root)!=null?a:c,className:V(w.root,l,I==null?void 0:I.className),ownerState:T({},b,I==null?void 0:I.ownerState),classes:w,ref:n,children:s}))}))}),a_=ek;function tk(e){return pe("MuiModal",e)}oe("MuiModal",["root","hidden","backdrop"]);const nk=["BackdropComponent","BackdropProps","classes","className","closeAfterTransition","children","container","component","components","componentsProps","disableAutoFocus","disableEnforceFocus","disableEscapeKeyDown","disablePortal","disableRestoreFocus","disableScrollLock","hideBackdrop","keepMounted","onBackdropClick","onClose","onTransitionEnter","onTransitionExited","open","slotProps","slots","theme"],ik=e=>{const{open:t,exited:n,classes:i}=e;return me({root:["root",!t&&n&&"hidden"],backdrop:["backdrop"]},tk,i)},ak=F("div",{name:"MuiModal",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,!n.open&&n.exited&&t.hidden]}})(({theme:e,ownerState:t})=>T({position:"fixed",zIndex:(e.vars||e).zIndex.modal,right:0,bottom:0,top:0,left:0},!t.open&&t.exited&&{visibility:"hidden"})),ok=F(a_,{name:"MuiModal",slot:"Backdrop",overridesResolver:(e,t)=>t.backdrop})({zIndex:-1}),rk=v.forwardRef(function(t,n){var i,a,o,r,s,l;const c=fe({name:"MuiModal",props:t}),{BackdropComponent:d=ok,BackdropProps:f,className:h,closeAfterTransition:u=!1,children:y,container:m,component:k,components:_={},componentsProps:g={},disableAutoFocus:b=!1,disableEnforceFocus:w=!1,disableEscapeKeyDown:I=!1,disablePortal:q=!1,disableRestoreFocus:x=!1,disableScrollLock:C=!1,hideBackdrop:S=!1,keepMounted:P=!1,onBackdropClick:B,open:O,slotProps:M,slots:E}=c,R=U(c,nk),z=T({},c,{closeAfterTransition:u,disableAutoFocus:b,disableEnforceFocus:w,disableEscapeKeyDown:I,disablePortal:q,disableRestoreFocus:x,disableScrollLock:C,hideBackdrop:S,keepMounted:P}),{getRootProps:L,getBackdropProps:D,getTransitionProps:N,portalRef:W,isTopModal:ee,exited:Q,hasTransition:Ne}=MT(T({},z,{rootRef:n})),Y=T({},z,{exited:Q}),ve=ik(Y),se={};if(y.props.tabIndex===void 0&&(se.tabIndex="-1"),Ne){const{onEnter:K,onExited:de}=N();se.onEnter=K,se.onExited=de}const Ge=(i=(a=E==null?void 0:E.root)!=null?a:_.Root)!=null?i:ak,It=(o=(r=E==null?void 0:E.backdrop)!=null?r:_.Backdrop)!=null?o:d,Be=(s=M==null?void 0:M.root)!=null?s:g.root,rt=(l=M==null?void 0:M.backdrop)!=null?l:g.backdrop,ae=pa({elementType:Ge,externalSlotProps:Be,externalForwardedProps:R,getSlotProps:L,additionalProps:{ref:n,as:k},ownerState:Y,className:V(h,Be==null?void 0:Be.className,ve==null?void 0:ve.root,!Y.open&&Y.exited&&(ve==null?void 0:ve.hidden))}),Ie=pa({elementType:It,externalSlotProps:rt,additionalProps:f,getSlotProps:K=>D(T({},K,{onClick:de=>{B&&B(de),K!=null&&K.onClick&&K.onClick(de)}})),className:V(rt==null?void 0:rt.className,f==null?void 0:f.className,ve==null?void 0:ve.backdrop),ownerState:Y});return!P&&!O&&(!Ne||Q)?null:p.jsx(AT,{ref:W,container:m,disablePortal:q,children:p.jsxs(Ge,T({},ae,{children:[!S&&d?p.jsx(It,T({},Ie)):null,p.jsx(PT,{disableEnforceFocus:w,disableAutoFocus:b,disableRestoreFocus:x,isEnabled:ee,open:O,children:v.cloneElement(y,se)})]}))})}),Hu=rk;function sk(e){return pe("MuiPaper",e)}oe("MuiPaper",["root","rounded","outlined","elevation","elevation0","elevation1","elevation2","elevation3","elevation4","elevation5","elevation6","elevation7","elevation8","elevation9","elevation10","elevation11","elevation12","elevation13","elevation14","elevation15","elevation16","elevation17","elevation18","elevation19","elevation20","elevation21","elevation22","elevation23","elevation24"]);const lk=["className","component","elevation","square","variant"],ck=e=>{const{square:t,elevation:n,variant:i,classes:a}=e,o={root:["root",i,!t&&"rounded",i==="elevation"&&`elevation${n}`]};return me(o,sk,a)},dk=F("div",{name:"MuiPaper",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,t[n.variant],!n.square&&t.rounded,n.variant==="elevation"&&t[`elevation${n.elevation}`]]}})(({theme:e,ownerState:t})=>{var n;return T({backgroundColor:(e.vars||e).palette.background.paper,color:(e.vars||e).palette.text.primary,transition:e.transitions.create("box-shadow")},!t.square&&{borderRadius:e.shape.borderRadius},t.variant==="outlined"&&{border:`1px solid ${(e.vars||e).palette.divider}`},t.variant==="elevation"&&T({boxShadow:(e.vars||e).shadows[t.elevation]},!e.vars&&e.palette.mode==="dark"&&{backgroundImage:`linear-gradient(${yn("#fff",Hm(t.elevation))}, ${yn("#fff",Hm(t.elevation))})`},e.vars&&{backgroundImage:(n=e.vars.overlays)==null?void 0:n[t.elevation]}))}),uk=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiPaper"}),{className:a,component:o="div",elevation:r=1,square:s=!1,variant:l="elevation"}=i,c=U(i,lk),d=T({},i,{component:o,elevation:r,square:s,variant:l}),f=ck(d);return p.jsx(dk,T({as:o,ownerState:d,className:V(f.root,a),ref:n},c))}),Mo=uk;function pk(e){return pe("MuiPopover",e)}oe("MuiPopover",["root","paper"]);const mk=["onEntering"],fk=["action","anchorEl","anchorOrigin","anchorPosition","anchorReference","children","className","container","elevation","marginThreshold","open","PaperProps","slots","slotProps","transformOrigin","TransitionComponent","transitionDuration","TransitionProps","disableScrollLock"],hk=["slotProps"];function uf(e,t){let n=0;return typeof t=="number"?n=t:t==="center"?n=e.height/2:t==="bottom"&&(n=e.height),n}function pf(e,t){let n=0;return typeof t=="number"?n=t:t==="center"?n=e.width/2:t==="right"&&(n=e.width),n}function mf(e){return[e.horizontal,e.vertical].map(t=>typeof t=="number"?`${t}px`:t).join(" ")}function Ql(e){return typeof e=="function"?e():e}const yk=e=>{const{classes:t}=e;return me({root:["root"],paper:["paper"]},pk,t)},gk=F(Hu,{name:"MuiPopover",slot:"Root",overridesResolver:(e,t)=>t.root})({}),o_=F(Mo,{name:"MuiPopover",slot:"Paper",overridesResolver:(e,t)=>t.paper})({position:"absolute",overflowY:"auto",overflowX:"hidden",minWidth:16,minHeight:16,maxWidth:"calc(100% - 32px)",maxHeight:"calc(100% - 32px)",outline:0}),_k=v.forwardRef(function(t,n){var i,a,o;const r=fe({props:t,name:"MuiPopover"}),{action:s,anchorEl:l,anchorOrigin:c={vertical:"top",horizontal:"left"},anchorPosition:d,anchorReference:f="anchorEl",children:h,className:u,container:y,elevation:m=8,marginThreshold:k=16,open:_,PaperProps:g={},slots:b,slotProps:w,transformOrigin:I={vertical:"top",horizontal:"left"},TransitionComponent:q=VT,transitionDuration:x="auto",TransitionProps:{onEntering:C}={},disableScrollLock:S=!1}=r,P=U(r.TransitionProps,mk),B=U(r,fk),O=(i=w==null?void 0:w.paper)!=null?i:g,M=v.useRef(),E=Ke(M,O.ref),R=T({},r,{anchorOrigin:c,anchorReference:f,elevation:m,marginThreshold:k,externalPaperSlotProps:O,transformOrigin:I,TransitionComponent:q,transitionDuration:x,TransitionProps:P}),z=yk(R),L=v.useCallback(()=>{if(f==="anchorPosition")return d;const K=Ql(l),we=(K&&K.nodeType===1?K:mt(M.current).body).getBoundingClientRect();return{top:we.top+uf(we,c.vertical),left:we.left+pf(we,c.horizontal)}},[l,c.horizontal,c.vertical,d,f]),D=v.useCallback(K=>({vertical:uf(K,I.vertical),horizontal:pf(K,I.horizontal)}),[I.horizontal,I.vertical]),N=v.useCallback(K=>{const de={width:K.offsetWidth,height:K.offsetHeight},we=D(de);if(f==="none")return{top:null,left:null,transformOrigin:mf(we)};const qn=L();let qt=qn.top-we.vertical,Ct=qn.left-we.horizontal;const Wt=qt+de.height,Dt=Ct+de.width,qe=rn(Ql(l)),ln=qe.innerHeight-k,st=qe.innerWidth-k;if(k!==null&&qt<k){const xe=qt-k;qt-=xe,we.vertical+=xe}else if(k!==null&&Wt>ln){const xe=Wt-ln;qt-=xe,we.vertical+=xe}if(k!==null&&Ct<k){const xe=Ct-k;Ct-=xe,we.horizontal+=xe}else if(Dt>st){const xe=Dt-st;Ct-=xe,we.horizontal+=xe}return{top:`${Math.round(qt)}px`,left:`${Math.round(Ct)}px`,transformOrigin:mf(we)}},[l,f,L,D,k]),[W,ee]=v.useState(_),Q=v.useCallback(()=>{const K=M.current;if(!K)return;const de=N(K);de.top!==null&&(K.style.top=de.top),de.left!==null&&(K.style.left=de.left),K.style.transformOrigin=de.transformOrigin,ee(!0)},[N]);v.useEffect(()=>(S&&window.addEventListener("scroll",Q),()=>window.removeEventListener("scroll",Q)),[l,S,Q]);const Ne=(K,de)=>{C&&C(K,de),Q()},Y=()=>{ee(!1)};v.useEffect(()=>{_&&Q()}),v.useImperativeHandle(s,()=>_?{updatePosition:()=>{Q()}}:null,[_,Q]),v.useEffect(()=>{if(!_)return;const K=Os(()=>{Q()}),de=rn(l);return de.addEventListener("resize",K),()=>{K.clear(),de.removeEventListener("resize",K)}},[l,_,Q]);let ve=x;x==="auto"&&!q.muiSupportAuto&&(ve=void 0);const se=y||(l?mt(Ql(l)).body:void 0),Ge=(a=b==null?void 0:b.root)!=null?a:gk,It=(o=b==null?void 0:b.paper)!=null?o:o_,Be=pa({elementType:It,externalSlotProps:T({},O,{style:W?O.style:T({},O.style,{opacity:0})}),additionalProps:{elevation:m,ref:E},ownerState:R,className:V(z.paper,O==null?void 0:O.className)}),rt=pa({elementType:Ge,externalSlotProps:(w==null?void 0:w.root)||{},externalForwardedProps:B,additionalProps:{ref:n,slotProps:{backdrop:{invisible:!0}},container:se,open:_},ownerState:R,className:V(z.root,u)}),{slotProps:ae}=rt,Ie=U(rt,hk);return p.jsx(Ge,T({},Ie,!rs(Ge)&&{slotProps:ae,disableScrollLock:S},{children:p.jsx(q,T({appear:!0,in:_,onEntering:Ne,onExited:Y,timeout:ve},P,{children:p.jsx(It,T({},Be,{children:h}))}))}))}),bk=_k;function vk(e){return pe("MuiMenu",e)}oe("MuiMenu",["root","paper","list"]);const wk=["onEntering"],xk=["autoFocus","children","className","disableAutoFocusItem","MenuListProps","onClose","open","PaperProps","PopoverClasses","transitionDuration","TransitionProps","variant","slots","slotProps"],Tk={vertical:"top",horizontal:"right"},kk={vertical:"top",horizontal:"left"},Ik=e=>{const{classes:t}=e;return me({root:["root"],paper:["paper"],list:["list"]},vk,t)},qk=F(bk,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiMenu",slot:"Root",overridesResolver:(e,t)=>t.root})({}),Ck=F(o_,{name:"MuiMenu",slot:"Paper",overridesResolver:(e,t)=>t.paper})({maxHeight:"calc(100% - 96px)",WebkitOverflowScrolling:"touch"}),Dk=F(xT,{name:"MuiMenu",slot:"List",overridesResolver:(e,t)=>t.list})({outline:0}),Pk=v.forwardRef(function(t,n){var i,a;const o=fe({props:t,name:"MuiMenu"}),{autoFocus:r=!0,children:s,className:l,disableAutoFocusItem:c=!1,MenuListProps:d={},onClose:f,open:h,PaperProps:u={},PopoverClasses:y,transitionDuration:m="auto",TransitionProps:{onEntering:k}={},variant:_="selectedMenu",slots:g={},slotProps:b={}}=o,w=U(o.TransitionProps,wk),I=U(o,xk),q=xa(),x=q.direction==="rtl",C=T({},o,{autoFocus:r,disableAutoFocusItem:c,MenuListProps:d,onEntering:k,PaperProps:u,transitionDuration:m,TransitionProps:w,variant:_}),S=Ik(C),P=r&&!c&&h,B=v.useRef(null),O=(N,W)=>{B.current&&B.current.adjustStyleForScrollbar(N,q),k&&k(N,W)},M=N=>{N.key==="Tab"&&(N.preventDefault(),f&&f(N,"tabKeyDown"))};let E=-1;v.Children.map(s,(N,W)=>{v.isValidElement(N)&&(N.props.disabled||(_==="selectedMenu"&&N.props.selected||E===-1)&&(E=W))});const R=(i=g.paper)!=null?i:Ck,z=(a=b.paper)!=null?a:u,L=pa({elementType:g.root,externalSlotProps:b.root,ownerState:C,className:[S.root,l]}),D=pa({elementType:R,externalSlotProps:z,ownerState:C,className:S.paper});return p.jsx(qk,T({onClose:f,anchorOrigin:{vertical:"bottom",horizontal:x?"right":"left"},transformOrigin:x?Tk:kk,slots:{paper:R,root:g.root},slotProps:{root:L,paper:D},open:h,ref:n,transitionDuration:m,TransitionProps:T({onEntering:O},w),ownerState:C},I,{classes:y,children:p.jsx(Dk,T({onKeyDown:M,actions:B,autoFocus:r&&(E===-1||c),autoFocusItem:P,variant:_},d,{className:V(S.list,d.className),children:s}))}))}),Sk=Pk;function Ak(e){return pe("MuiNativeSelect",e)}const Ek=oe("MuiNativeSelect",["root","select","multiple","filled","outlined","standard","disabled","icon","iconOpen","iconFilled","iconOutlined","iconStandard","nativeInput","error"]),Zu=Ek,Nk=["className","disabled","error","IconComponent","inputRef","variant"],Bk=e=>{const{classes:t,variant:n,disabled:i,multiple:a,open:o,error:r}=e,s={select:["select",n,i&&"disabled",a&&"multiple",r&&"error"],icon:["icon",`icon${Z(n)}`,o&&"iconOpen",i&&"disabled"]};return me(s,Ak,t)},r_=({ownerState:e,theme:t})=>T({MozAppearance:"none",WebkitAppearance:"none",userSelect:"none",borderRadius:0,cursor:"pointer","&:focus":T({},t.vars?{backgroundColor:`rgba(${t.vars.palette.common.onBackgroundChannel} / 0.05)`}:{backgroundColor:t.palette.mode==="light"?"rgba(0, 0, 0, 0.05)":"rgba(255, 255, 255, 0.05)"},{borderRadius:0}),"&::-ms-expand":{display:"none"},[`&.${Zu.disabled}`]:{cursor:"default"},"&[multiple]":{height:"auto"},"&:not([multiple]) option, &:not([multiple]) optgroup":{backgroundColor:(t.vars||t).palette.background.paper},"&&&":{paddingRight:24,minWidth:16}},e.variant==="filled"&&{"&&&":{paddingRight:32}},e.variant==="outlined"&&{borderRadius:(t.vars||t).shape.borderRadius,"&:focus":{borderRadius:(t.vars||t).shape.borderRadius},"&&&":{paddingRight:32}}),Rk=F("select",{name:"MuiNativeSelect",slot:"Select",shouldForwardProp:Ht,overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.select,t[n.variant],n.error&&t.error,{[`&.${Zu.multiple}`]:t.multiple}]}})(r_),s_=({ownerState:e,theme:t})=>T({position:"absolute",right:0,top:"calc(50% - .5em)",pointerEvents:"none",color:(t.vars||t).palette.action.active,[`&.${Zu.disabled}`]:{color:(t.vars||t).palette.action.disabled}},e.open&&{transform:"rotate(180deg)"},e.variant==="filled"&&{right:7},e.variant==="outlined"&&{right:7}),Ok=F("svg",{name:"MuiNativeSelect",slot:"Icon",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.icon,n.variant&&t[`icon${Z(n.variant)}`],n.open&&t.iconOpen]}})(s_),zk=v.forwardRef(function(t,n){const{className:i,disabled:a,error:o,IconComponent:r,inputRef:s,variant:l="standard"}=t,c=U(t,Nk),d=T({},t,{disabled:a,variant:l,error:o}),f=Bk(d);return p.jsxs(v.Fragment,{children:[p.jsx(Rk,T({ownerState:d,className:V(f.select,i),disabled:a,ref:s||n},c)),t.multiple?null:p.jsx(Ok,{as:r,ownerState:d,className:f.icon})]})}),Wk=zk;function jk(e){return pe("MuiSelect",e)}const Mk=oe("MuiSelect",["root","select","multiple","filled","outlined","standard","disabled","focused","icon","iconOpen","iconFilled","iconOutlined","iconStandard","nativeInput","error"]),za=Mk;var ff;const Lk=["aria-describedby","aria-label","autoFocus","autoWidth","children","className","defaultOpen","defaultValue","disabled","displayEmpty","error","IconComponent","inputRef","labelId","MenuProps","multiple","name","onBlur","onChange","onClose","onFocus","onOpen","open","readOnly","renderValue","SelectDisplayProps","tabIndex","type","value","variant"],Fk=F("div",{name:"MuiSelect",slot:"Select",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[{[`&.${za.select}`]:t.select},{[`&.${za.select}`]:t[n.variant]},{[`&.${za.error}`]:t.error},{[`&.${za.multiple}`]:t.multiple}]}})(r_,{[`&.${za.select}`]:{height:"auto",minHeight:"1.4375em",textOverflow:"ellipsis",whiteSpace:"nowrap",overflow:"hidden"}}),Uk=F("svg",{name:"MuiSelect",slot:"Icon",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.icon,n.variant&&t[`icon${Z(n.variant)}`],n.open&&t.iconOpen]}})(s_),Gk=F("input",{shouldForwardProp:e=>B2(e)&&e!=="classes",name:"MuiSelect",slot:"NativeInput",overridesResolver:(e,t)=>t.nativeInput})({bottom:0,left:0,position:"absolute",opacity:0,pointerEvents:"none",width:"100%",boxSizing:"border-box"});function hf(e,t){return typeof t=="object"&&t!==null?e===t:String(e)===String(t)}function $k(e){return e==null||typeof e=="string"&&!e.trim()}const Vk=e=>{const{classes:t,variant:n,disabled:i,multiple:a,open:o,error:r}=e,s={select:["select",n,i&&"disabled",a&&"multiple",r&&"error"],icon:["icon",`icon${Z(n)}`,o&&"iconOpen",i&&"disabled"],nativeInput:["nativeInput"]};return me(s,jk,t)},Hk=v.forwardRef(function(t,n){var i;const{"aria-describedby":a,"aria-label":o,autoFocus:r,autoWidth:s,children:l,className:c,defaultOpen:d,defaultValue:f,disabled:h,displayEmpty:u,error:y=!1,IconComponent:m,inputRef:k,labelId:_,MenuProps:g={},multiple:b,name:w,onBlur:I,onChange:q,onClose:x,onFocus:C,onOpen:S,open:P,readOnly:B,renderValue:O,SelectDisplayProps:M={},tabIndex:E,value:R,variant:z="standard"}=t,L=U(t,Lk),[D,N]=td({controlled:R,default:f,name:"Select"}),[W,ee]=td({controlled:P,default:d,name:"Select"}),Q=v.useRef(null),Ne=v.useRef(null),[Y,ve]=v.useState(null),{current:se}=v.useRef(P!=null),[Ge,It]=v.useState(),Be=Ke(n,k),rt=v.useCallback(G=>{Ne.current=G,G&&ve(G)},[]),ae=Y==null?void 0:Y.parentNode;v.useImperativeHandle(Be,()=>({focus:()=>{Ne.current.focus()},node:Q.current,value:D}),[D]),v.useEffect(()=>{d&&W&&Y&&!se&&(It(s?null:ae.clientWidth),Ne.current.focus())},[Y,s]),v.useEffect(()=>{r&&Ne.current.focus()},[r]),v.useEffect(()=>{if(!_)return;const G=mt(Ne.current).getElementById(_);if(G){const ye=()=>{getSelection().isCollapsed&&Ne.current.focus()};return G.addEventListener("click",ye),()=>{G.removeEventListener("click",ye)}}},[_]);const Ie=(G,ye)=>{G?S&&S(ye):x&&x(ye),se||(It(s?null:ae.clientWidth),ee(G))},K=G=>{G.button===0&&(G.preventDefault(),Ne.current.focus(),Ie(!0,G))},de=G=>{Ie(!1,G)},we=v.Children.toArray(l),qn=G=>{const ye=we.find($e=>$e.props.value===G.target.value);ye!==void 0&&(N(ye.props.value),q&&q(G,ye))},qt=G=>ye=>{let $e;if(ye.currentTarget.hasAttribute("tabindex")){if(b){$e=Array.isArray(D)?D.slice():[];const Di=D.indexOf(G.props.value);Di===-1?$e.push(G.props.value):$e.splice(Di,1)}else $e=G.props.value;if(G.props.onClick&&G.props.onClick(ye),D!==$e&&(N($e),q)){const Di=ye.nativeEvent||ye,ep=new Di.constructor(Di.type,Di);Object.defineProperty(ep,"target",{writable:!0,value:{value:$e,name:w}}),q(ep,G)}b||Ie(!1,ye)}},Ct=G=>{B||[" ","ArrowUp","ArrowDown","Enter"].indexOf(G.key)!==-1&&(G.preventDefault(),Ie(!0,G))},Wt=Y!==null&&W,Dt=G=>{!Wt&&I&&(Object.defineProperty(G,"target",{writable:!0,value:{value:D,name:w}}),I(G))};delete L["aria-invalid"];let qe,ln;const st=[];let xe=!1;(os({value:D})||u)&&(O?qe=O(D):xe=!0);const Zt=we.map(G=>{if(!v.isValidElement(G))return null;let ye;if(b){if(!Array.isArray(D))throw new Error(Kn(2));ye=D.some($e=>hf($e,G.props.value)),ye&&xe&&st.push(G.props.children)}else ye=hf(D,G.props.value),ye&&xe&&(ln=G.props.children);return v.cloneElement(G,{"aria-selected":ye?"true":"false",onClick:qt(G),onKeyUp:$e=>{$e.key===" "&&$e.preventDefault(),G.props.onKeyUp&&G.props.onKeyUp($e)},role:"option",selected:ye,value:void 0,"data-value":G.props.value})});xe&&(b?st.length===0?qe=null:qe=st.reduce((G,ye,$e)=>(G.push(ye),$e<st.length-1&&G.push(", "),G),[]):qe=ln);let Cn=Ge;!s&&se&&Y&&(Cn=ae.clientWidth);let cn;typeof E<"u"?cn=E:cn=h?null:0;const he=M.id||(w?`mui-component-select-${w}`:void 0),$=T({},t,{variant:z,value:D,open:Wt,error:y}),dn=Vk($),Ta=T({},g.PaperProps,(i=g.slotProps)==null?void 0:i.paper);return p.jsxs(v.Fragment,{children:[p.jsx(Fk,T({ref:rt,tabIndex:cn,role:"button","aria-disabled":h?"true":void 0,"aria-expanded":Wt?"true":"false","aria-haspopup":"listbox","aria-label":o,"aria-labelledby":[_,he].filter(Boolean).join(" ")||void 0,"aria-describedby":a,onKeyDown:Ct,onMouseDown:h||B?null:K,onBlur:Dt,onFocus:C},M,{ownerState:$,className:V(M.className,dn.select,c),id:he,children:$k(qe)?ff||(ff=p.jsx("span",{className:"notranslate",children:"​"})):qe})),p.jsx(Gk,T({"aria-invalid":y,value:Array.isArray(D)?D.join(","):D,name:w,ref:Q,"aria-hidden":!0,onChange:qn,tabIndex:-1,disabled:h,className:dn.nativeInput,autoFocus:r,ownerState:$},L)),p.jsx(Uk,{as:m,className:dn.icon,ownerState:$}),p.jsx(Sk,T({id:`menu-${w||""}`,anchorEl:ae,open:Wt,onClose:de,anchorOrigin:{vertical:"bottom",horizontal:"center"},transformOrigin:{vertical:"top",horizontal:"center"}},g,{MenuListProps:T({"aria-labelledby":_,role:"listbox",disableListWrap:!0},g.MenuListProps),slotProps:{paper:T({},Ta,{style:T({minWidth:Cn},Ta!=null?Ta.style:null)})},children:Zt}))]})}),Zk=Hk,Qk=Ci(p.jsx("path",{d:"M7 10l5 5 5-5z"}),"ArrowDropDown");function Kk(e){return p.jsx(Ex,T({},e,{defaultTheme:sl,themeId:Oo}))}function Xk(e){return pe("MuiInputBase",e)}const Yk=oe("MuiInputBase",["root","formControl","focused","disabled","adornedStart","adornedEnd","error","sizeSmall","multiline","colorSecondary","fullWidth","hiddenLabel","readOnly","input","inputSizeSmall","inputMultiline","inputTypeSearch","inputAdornedStart","inputAdornedEnd","inputHiddenLabel"]),fa=Yk,Jk=["aria-describedby","autoComplete","autoFocus","className","color","components","componentsProps","defaultValue","disabled","disableInjectingGlobalStyles","endAdornment","error","fullWidth","id","inputComponent","inputProps","inputRef","margin","maxRows","minRows","multiline","name","onBlur","onChange","onClick","onFocus","onKeyDown","onKeyUp","placeholder","readOnly","renderSuffix","rows","size","slotProps","slots","startAdornment","type","value"],cl=(e,t)=>{const{ownerState:n}=e;return[t.root,n.formControl&&t.formControl,n.startAdornment&&t.adornedStart,n.endAdornment&&t.adornedEnd,n.error&&t.error,n.size==="small"&&t.sizeSmall,n.multiline&&t.multiline,n.color&&t[`color${Z(n.color)}`],n.fullWidth&&t.fullWidth,n.hiddenLabel&&t.hiddenLabel]},dl=(e,t)=>{const{ownerState:n}=e;return[t.input,n.size==="small"&&t.inputSizeSmall,n.multiline&&t.inputMultiline,n.type==="search"&&t.inputTypeSearch,n.startAdornment&&t.inputAdornedStart,n.endAdornment&&t.inputAdornedEnd,n.hiddenLabel&&t.inputHiddenLabel]},eI=e=>{const{classes:t,color:n,disabled:i,error:a,endAdornment:o,focused:r,formControl:s,fullWidth:l,hiddenLabel:c,multiline:d,readOnly:f,size:h,startAdornment:u,type:y}=e,m={root:["root",`color${Z(n)}`,i&&"disabled",a&&"error",l&&"fullWidth",r&&"focused",s&&"formControl",h&&h!=="medium"&&`size${Z(h)}`,d&&"multiline",u&&"adornedStart",o&&"adornedEnd",c&&"hiddenLabel",f&&"readOnly"],input:["input",i&&"disabled",y==="search"&&"inputTypeSearch",d&&"inputMultiline",h==="small"&&"inputSizeSmall",c&&"inputHiddenLabel",u&&"inputAdornedStart",o&&"inputAdornedEnd",f&&"readOnly"]};return me(m,Xk,t)},ul=F("div",{name:"MuiInputBase",slot:"Root",overridesResolver:cl})(({theme:e,ownerState:t})=>T({},e.typography.body1,{color:(e.vars||e).palette.text.primary,lineHeight:"1.4375em",boxSizing:"border-box",position:"relative",cursor:"text",display:"inline-flex",alignItems:"center",[`&.${fa.disabled}`]:{color:(e.vars||e).palette.text.disabled,cursor:"default"}},t.multiline&&T({padding:"4px 0 5px"},t.size==="small"&&{paddingTop:1}),t.fullWidth&&{width:"100%"})),pl=F("input",{name:"MuiInputBase",slot:"Input",overridesResolver:dl})(({theme:e,ownerState:t})=>{const n=e.palette.mode==="light",i=T({color:"currentColor"},e.vars?{opacity:e.vars.opacity.inputPlaceholder}:{opacity:n?.42:.5},{transition:e.transitions.create("opacity",{duration:e.transitions.duration.shorter})}),a={opacity:"0 !important"},o=e.vars?{opacity:e.vars.opacity.inputPlaceholder}:{opacity:n?.42:.5};return T({font:"inherit",letterSpacing:"inherit",color:"currentColor",padding:"4px 0 5px",border:0,boxSizing:"content-box",background:"none",height:"1.4375em",margin:0,WebkitTapHighlightColor:"transparent",display:"block",minWidth:0,width:"100%",animationName:"mui-auto-fill-cancel",animationDuration:"10ms","&::-webkit-input-placeholder":i,"&::-moz-placeholder":i,"&:-ms-input-placeholder":i,"&::-ms-input-placeholder":i,"&:focus":{outline:0},"&:invalid":{boxShadow:"none"},"&::-webkit-search-decoration":{WebkitAppearance:"none"},[`label[data-shrink=false] + .${fa.formControl} &`]:{"&::-webkit-input-placeholder":a,"&::-moz-placeholder":a,"&:-ms-input-placeholder":a,"&::-ms-input-placeholder":a,"&:focus::-webkit-input-placeholder":o,"&:focus::-moz-placeholder":o,"&:focus:-ms-input-placeholder":o,"&:focus::-ms-input-placeholder":o},[`&.${fa.disabled}`]:{opacity:1,WebkitTextFillColor:(e.vars||e).palette.text.disabled},"&:-webkit-autofill":{animationDuration:"5000s",animationName:"mui-auto-fill"}},t.size==="small"&&{paddingTop:1},t.multiline&&{height:"auto",resize:"none",padding:0,paddingTop:0},t.type==="search"&&{MozAppearance:"textfield"})}),tI=p.jsx(Kk,{styles:{"@keyframes mui-auto-fill":{from:{display:"block"}},"@keyframes mui-auto-fill-cancel":{from:{display:"block"}}}}),nI=v.forwardRef(function(t,n){var i;const a=fe({props:t,name:"MuiInputBase"}),{"aria-describedby":o,autoComplete:r,autoFocus:s,className:l,components:c={},componentsProps:d={},defaultValue:f,disabled:h,disableInjectingGlobalStyles:u,endAdornment:y,fullWidth:m=!1,id:k,inputComponent:_="input",inputProps:g={},inputRef:b,maxRows:w,minRows:I,multiline:q=!1,name:x,onBlur:C,onChange:S,onClick:P,onFocus:B,onKeyDown:O,onKeyUp:M,placeholder:E,readOnly:R,renderSuffix:z,rows:L,slotProps:D={},slots:N={},startAdornment:W,type:ee="text",value:Q}=a,Ne=U(a,Jk),Y=g.value!=null?g.value:Q,{current:ve}=v.useRef(Y!=null),se=v.useRef(),Ge=v.useCallback(he=>{},[]),It=Ke(se,b,g.ref,Ge),[Be,rt]=v.useState(!1),ae=jo(),Ie=Wo({props:a,muiFormControl:ae,states:["color","disabled","error","hiddenLabel","size","required","filled"]});Ie.focused=ae?ae.focused:Be,v.useEffect(()=>{!ae&&h&&Be&&(rt(!1),C&&C())},[ae,h,Be,C]);const K=ae&&ae.onFilled,de=ae&&ae.onEmpty,we=v.useCallback(he=>{os(he)?K&&K():de&&de()},[K,de]);Xn(()=>{ve&&we({value:Y})},[Y,we,ve]);const qn=he=>{if(Ie.disabled){he.stopPropagation();return}B&&B(he),g.onFocus&&g.onFocus(he),ae&&ae.onFocus?ae.onFocus(he):rt(!0)},qt=he=>{C&&C(he),g.onBlur&&g.onBlur(he),ae&&ae.onBlur?ae.onBlur(he):rt(!1)},Ct=(he,...$)=>{if(!ve){const dn=he.target||se.current;if(dn==null)throw new Error(Kn(1));we({value:dn.value})}g.onChange&&g.onChange(he,...$),S&&S(he,...$)};v.useEffect(()=>{we(se.current)},[]);const Wt=he=>{se.current&&he.currentTarget===he.target&&se.current.focus(),P&&P(he)};let Dt=_,qe=g;q&&Dt==="input"&&(L?qe=T({type:void 0,minRows:L,maxRows:L},qe):qe=T({type:void 0,maxRows:w,minRows:I},qe),Dt=UT);const ln=he=>{we(he.animationName==="mui-auto-fill-cancel"?se.current:{value:"x"})};v.useEffect(()=>{ae&&ae.setAdornedStart(!!W)},[ae,W]);const st=T({},a,{color:Ie.color||"primary",disabled:Ie.disabled,endAdornment:y,error:Ie.error,focused:Ie.focused,formControl:ae,fullWidth:m,hiddenLabel:Ie.hiddenLabel,multiline:q,size:Ie.size,startAdornment:W,type:ee}),xe=eI(st),Zt=N.root||c.Root||ul,Cn=D.root||d.root||{},cn=N.input||c.Input||pl;return qe=T({},qe,(i=D.input)!=null?i:d.input),p.jsxs(v.Fragment,{children:[!u&&tI,p.jsxs(Zt,T({},Cn,!rs(Zt)&&{ownerState:T({},st,Cn.ownerState)},{ref:n,onClick:Wt},Ne,{className:V(xe.root,Cn.className,l,R&&"MuiInputBase-readOnly"),children:[W,p.jsx(Fu.Provider,{value:null,children:p.jsx(cn,T({ownerState:st,"aria-invalid":Ie.error,"aria-describedby":o,autoComplete:r,autoFocus:s,defaultValue:f,disabled:Ie.disabled,id:k,onAnimationStart:ln,name:x,placeholder:E,readOnly:R,required:Ie.required,rows:L,value:Y,onKeyDown:O,onKeyUp:M,type:ee},qe,!rs(cn)&&{as:Dt,ownerState:T({},st,qe.ownerState)},{ref:It,className:V(xe.input,qe.className,R&&"MuiInputBase-readOnly"),onBlur:qt,onChange:Ct,onFocus:qn}))}),y,z?z(T({},Ie,{startAdornment:W})):null]}))]})}),Qu=nI;function iI(e){return pe("MuiInput",e)}const aI=T({},fa,oe("MuiInput",["root","underline","input"])),Wa=aI,oI=["disableUnderline","components","componentsProps","fullWidth","inputComponent","multiline","slotProps","slots","type"],rI=e=>{const{classes:t,disableUnderline:n}=e,a=me({root:["root",!n&&"underline"],input:["input"]},iI,t);return T({},t,a)},sI=F(ul,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiInput",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[...cl(e,t),!n.disableUnderline&&t.underline]}})(({theme:e,ownerState:t})=>{let i=e.palette.mode==="light"?"rgba(0, 0, 0, 0.42)":"rgba(255, 255, 255, 0.7)";return e.vars&&(i=`rgba(${e.vars.palette.common.onBackgroundChannel} / ${e.vars.opacity.inputUnderline})`),T({position:"relative"},t.formControl&&{"label + &":{marginTop:16}},!t.disableUnderline&&{"&:after":{borderBottom:`2px solid ${(e.vars||e).palette[t.color].main}`,left:0,bottom:0,content:'""',position:"absolute",right:0,transform:"scaleX(0)",transition:e.transitions.create("transform",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),pointerEvents:"none"},[`&.${Wa.focused}:after`]:{transform:"scaleX(1) translateX(0)"},[`&.${Wa.error}`]:{"&:before, &:after":{borderBottomColor:(e.vars||e).palette.error.main}},"&:before":{borderBottom:`1px solid ${i}`,left:0,bottom:0,content:'"\\00a0"',position:"absolute",right:0,transition:e.transitions.create("border-bottom-color",{duration:e.transitions.duration.shorter}),pointerEvents:"none"},[`&:hover:not(.${Wa.disabled}, .${Wa.error}):before`]:{borderBottom:`2px solid ${(e.vars||e).palette.text.primary}`,"@media (hover: none)":{borderBottom:`1px solid ${i}`}},[`&.${Wa.disabled}:before`]:{borderBottomStyle:"dotted"}})}),lI=F(pl,{name:"MuiInput",slot:"Input",overridesResolver:dl})({}),l_=v.forwardRef(function(t,n){var i,a,o,r;const s=fe({props:t,name:"MuiInput"}),{disableUnderline:l,components:c={},componentsProps:d,fullWidth:f=!1,inputComponent:h="input",multiline:u=!1,slotProps:y,slots:m={},type:k="text"}=s,_=U(s,oI),g=rI(s),w={root:{ownerState:{disableUnderline:l}}},I=y??d?Bt(y??d,w):w,q=(i=(a=m.root)!=null?a:c.Root)!=null?i:sI,x=(o=(r=m.input)!=null?r:c.Input)!=null?o:lI;return p.jsx(Qu,T({slots:{root:q,input:x},slotProps:I,fullWidth:f,inputComponent:h,multiline:u,ref:n,type:k},_,{classes:g}))});l_.muiName="Input";const cI=l_;function dI(e){return pe("MuiFilledInput",e)}const uI=T({},fa,oe("MuiFilledInput",["root","underline","input"])),ii=uI,pI=["disableUnderline","components","componentsProps","fullWidth","hiddenLabel","inputComponent","multiline","slotProps","slots","type"],mI=e=>{const{classes:t,disableUnderline:n}=e,a=me({root:["root",!n&&"underline"],input:["input"]},dI,t);return T({},t,a)},fI=F(ul,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiFilledInput",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[...cl(e,t),!n.disableUnderline&&t.underline]}})(({theme:e,ownerState:t})=>{var n;const i=e.palette.mode==="light",a=i?"rgba(0, 0, 0, 0.42)":"rgba(255, 255, 255, 0.7)",o=i?"rgba(0, 0, 0, 0.06)":"rgba(255, 255, 255, 0.09)",r=i?"rgba(0, 0, 0, 0.09)":"rgba(255, 255, 255, 0.13)",s=i?"rgba(0, 0, 0, 0.12)":"rgba(255, 255, 255, 0.12)";return T({position:"relative",backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o,borderTopLeftRadius:(e.vars||e).shape.borderRadius,borderTopRightRadius:(e.vars||e).shape.borderRadius,transition:e.transitions.create("background-color",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),"&:hover":{backgroundColor:e.vars?e.vars.palette.FilledInput.hoverBg:r,"@media (hover: none)":{backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o}},[`&.${ii.focused}`]:{backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o},[`&.${ii.disabled}`]:{backgroundColor:e.vars?e.vars.palette.FilledInput.disabledBg:s}},!t.disableUnderline&&{"&:after":{borderBottom:`2px solid ${(n=(e.vars||e).palette[t.color||"primary"])==null?void 0:n.main}`,left:0,bottom:0,content:'""',position:"absolute",right:0,transform:"scaleX(0)",transition:e.transitions.create("transform",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),pointerEvents:"none"},[`&.${ii.focused}:after`]:{transform:"scaleX(1) translateX(0)"},[`&.${ii.error}`]:{"&:before, &:after":{borderBottomColor:(e.vars||e).palette.error.main}},"&:before":{borderBottom:`1px solid ${e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / ${e.vars.opacity.inputUnderline})`:a}`,left:0,bottom:0,content:'"\\00a0"',position:"absolute",right:0,transition:e.transitions.create("border-bottom-color",{duration:e.transitions.duration.shorter}),pointerEvents:"none"},[`&:hover:not(.${ii.disabled}, .${ii.error}):before`]:{borderBottom:`1px solid ${(e.vars||e).palette.text.primary}`},[`&.${ii.disabled}:before`]:{borderBottomStyle:"dotted"}},t.startAdornment&&{paddingLeft:12},t.endAdornment&&{paddingRight:12},t.multiline&&T({padding:"25px 12px 8px"},t.size==="small"&&{paddingTop:21,paddingBottom:4},t.hiddenLabel&&{paddingTop:16,paddingBottom:17}))}),hI=F(pl,{name:"MuiFilledInput",slot:"Input",overridesResolver:dl})(({theme:e,ownerState:t})=>T({paddingTop:25,paddingRight:12,paddingBottom:8,paddingLeft:12},!e.vars&&{"&:-webkit-autofill":{WebkitBoxShadow:e.palette.mode==="light"?null:"0 0 0 100px #266798 inset",WebkitTextFillColor:e.palette.mode==="light"?null:"#fff",caretColor:e.palette.mode==="light"?null:"#fff",borderTopLeftRadius:"inherit",borderTopRightRadius:"inherit"}},e.vars&&{"&:-webkit-autofill":{borderTopLeftRadius:"inherit",borderTopRightRadius:"inherit"},[e.getColorSchemeSelector("dark")]:{"&:-webkit-autofill":{WebkitBoxShadow:"0 0 0 100px #266798 inset",WebkitTextFillColor:"#fff",caretColor:"#fff"}}},t.size==="small"&&{paddingTop:21,paddingBottom:4},t.hiddenLabel&&{paddingTop:16,paddingBottom:17},t.multiline&&{paddingTop:0,paddingBottom:0,paddingLeft:0,paddingRight:0},t.startAdornment&&{paddingLeft:0},t.endAdornment&&{paddingRight:0},t.hiddenLabel&&t.size==="small"&&{paddingTop:8,paddingBottom:9})),c_=v.forwardRef(function(t,n){var i,a,o,r;const s=fe({props:t,name:"MuiFilledInput"}),{components:l={},componentsProps:c,fullWidth:d=!1,inputComponent:f="input",multiline:h=!1,slotProps:u,slots:y={},type:m="text"}=s,k=U(s,pI),_=T({},s,{fullWidth:d,inputComponent:f,multiline:h,type:m}),g=mI(s),b={root:{ownerState:_},input:{ownerState:_}},w=u??c?Bt(u??c,b):b,I=(i=(a=y.root)!=null?a:l.Root)!=null?i:fI,q=(o=(r=y.input)!=null?r:l.Input)!=null?o:hI;return p.jsx(Qu,T({slots:{root:I,input:q},componentsProps:w,fullWidth:d,inputComponent:f,multiline:h,ref:n,type:m},k,{classes:g}))});c_.muiName="Input";const yI=c_;var yf;const gI=["children","classes","className","label","notched"],_I=F("fieldset")({textAlign:"left",position:"absolute",bottom:0,right:0,top:-5,left:0,margin:0,padding:"0 8px",pointerEvents:"none",borderRadius:"inherit",borderStyle:"solid",borderWidth:1,overflow:"hidden",minWidth:"0%"}),bI=F("legend")(({ownerState:e,theme:t})=>T({float:"unset",width:"auto",overflow:"hidden"},!e.withLabel&&{padding:0,lineHeight:"11px",transition:t.transitions.create("width",{duration:150,easing:t.transitions.easing.easeOut})},e.withLabel&&T({display:"block",padding:0,height:11,fontSize:"0.75em",visibility:"hidden",maxWidth:.01,transition:t.transitions.create("max-width",{duration:50,easing:t.transitions.easing.easeOut}),whiteSpace:"nowrap","& > span":{paddingLeft:5,paddingRight:5,display:"inline-block",opacity:0,visibility:"visible"}},e.notched&&{maxWidth:"100%",transition:t.transitions.create("max-width",{duration:100,easing:t.transitions.easing.easeOut,delay:50})})));function vI(e){const{className:t,label:n,notched:i}=e,a=U(e,gI),o=n!=null&&n!=="",r=T({},e,{notched:i,withLabel:o});return p.jsx(_I,T({"aria-hidden":!0,className:t,ownerState:r},a,{children:p.jsx(bI,{ownerState:r,children:o?p.jsx("span",{children:n}):yf||(yf=p.jsx("span",{className:"notranslate",children:"​"}))})}))}function wI(e){return pe("MuiOutlinedInput",e)}const xI=T({},fa,oe("MuiOutlinedInput",["root","notchedOutline","input"])),Pn=xI,TI=["components","fullWidth","inputComponent","label","multiline","notched","slots","type"],kI=e=>{const{classes:t}=e,i=me({root:["root"],notchedOutline:["notchedOutline"],input:["input"]},wI,t);return T({},t,i)},II=F(ul,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiOutlinedInput",slot:"Root",overridesResolver:cl})(({theme:e,ownerState:t})=>{const n=e.palette.mode==="light"?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)";return T({position:"relative",borderRadius:(e.vars||e).shape.borderRadius,[`&:hover .${Pn.notchedOutline}`]:{borderColor:(e.vars||e).palette.text.primary},"@media (hover: none)":{[`&:hover .${Pn.notchedOutline}`]:{borderColor:e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / 0.23)`:n}},[`&.${Pn.focused} .${Pn.notchedOutline}`]:{borderColor:(e.vars||e).palette[t.color].main,borderWidth:2},[`&.${Pn.error} .${Pn.notchedOutline}`]:{borderColor:(e.vars||e).palette.error.main},[`&.${Pn.disabled} .${Pn.notchedOutline}`]:{borderColor:(e.vars||e).palette.action.disabled}},t.startAdornment&&{paddingLeft:14},t.endAdornment&&{paddingRight:14},t.multiline&&T({padding:"16.5px 14px"},t.size==="small"&&{padding:"8.5px 14px"}))}),qI=F(vI,{name:"MuiOutlinedInput",slot:"NotchedOutline",overridesResolver:(e,t)=>t.notchedOutline})(({theme:e})=>{const t=e.palette.mode==="light"?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)";return{borderColor:e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / 0.23)`:t}}),CI=F(pl,{name:"MuiOutlinedInput",slot:"Input",overridesResolver:dl})(({theme:e,ownerState:t})=>T({padding:"16.5px 14px"},!e.vars&&{"&:-webkit-autofill":{WebkitBoxShadow:e.palette.mode==="light"?null:"0 0 0 100px #266798 inset",WebkitTextFillColor:e.palette.mode==="light"?null:"#fff",caretColor:e.palette.mode==="light"?null:"#fff",borderRadius:"inherit"}},e.vars&&{"&:-webkit-autofill":{borderRadius:"inherit"},[e.getColorSchemeSelector("dark")]:{"&:-webkit-autofill":{WebkitBoxShadow:"0 0 0 100px #266798 inset",WebkitTextFillColor:"#fff",caretColor:"#fff"}}},t.size==="small"&&{padding:"8.5px 14px"},t.multiline&&{padding:0},t.startAdornment&&{paddingLeft:0},t.endAdornment&&{paddingRight:0})),d_=v.forwardRef(function(t,n){var i,a,o,r,s;const l=fe({props:t,name:"MuiOutlinedInput"}),{components:c={},fullWidth:d=!1,inputComponent:f="input",label:h,multiline:u=!1,notched:y,slots:m={},type:k="text"}=l,_=U(l,TI),g=kI(l),b=jo(),w=Wo({props:l,muiFormControl:b,states:["color","disabled","error","focused","hiddenLabel","size","required"]}),I=T({},l,{color:w.color||"primary",disabled:w.disabled,error:w.error,focused:w.focused,formControl:b,fullWidth:d,hiddenLabel:w.hiddenLabel,multiline:u,size:w.size,type:k}),q=(i=(a=m.root)!=null?a:c.Root)!=null?i:II,x=(o=(r=m.input)!=null?r:c.Input)!=null?o:CI;return p.jsx(Qu,T({slots:{root:q,input:x},renderSuffix:C=>p.jsx(qI,{ownerState:I,className:g.notchedOutline,label:h!=null&&h!==""&&w.required?s||(s=p.jsxs(v.Fragment,{children:[h," ","*"]})):h,notched:typeof y<"u"?y:!!(C.startAdornment||C.filled||C.focused)}),fullWidth:d,inputComponent:f,multiline:u,ref:n,type:k},_,{classes:T({},g,{notchedOutline:null})}))});d_.muiName="Input";const DI=d_,PI=["autoWidth","children","classes","className","defaultOpen","displayEmpty","IconComponent","id","input","inputProps","label","labelId","MenuProps","multiple","native","onClose","onOpen","open","renderValue","SelectDisplayProps","variant"],SI=["root"],AI=e=>{const{classes:t}=e;return t},Ku={name:"MuiSelect",overridesResolver:(e,t)=>t.root,shouldForwardProp:e=>Ht(e)&&e!=="variant",slot:"Root"},EI=F(cI,Ku)(""),NI=F(DI,Ku)(""),BI=F(yI,Ku)(""),u_=v.forwardRef(function(t,n){const i=fe({name:"MuiSelect",props:t}),{autoWidth:a=!1,children:o,classes:r={},className:s,defaultOpen:l=!1,displayEmpty:c=!1,IconComponent:d=Qk,id:f,input:h,inputProps:u,label:y,labelId:m,MenuProps:k,multiple:_=!1,native:g=!1,onClose:b,onOpen:w,open:I,renderValue:q,SelectDisplayProps:x,variant:C="outlined"}=i,S=U(i,PI),P=g?Wk:Zk,B=jo(),O=Wo({props:i,muiFormControl:B,states:["variant","error"]}),M=O.variant||C,E=T({},i,{variant:M,classes:r}),R=AI(E),z=U(R,SI),L=h||{standard:p.jsx(EI,{ownerState:E}),outlined:p.jsx(NI,{label:y,ownerState:E}),filled:p.jsx(BI,{ownerState:E})}[M],D=Ke(n,L.ref);return p.jsx(v.Fragment,{children:v.cloneElement(L,T({inputComponent:P,inputProps:T({children:o,error:O.error,IconComponent:d,variant:M,type:void 0,multiple:_},g?{id:f}:{autoWidth:a,defaultOpen:l,displayEmpty:c,labelId:m,MenuProps:k,onClose:b,onOpen:w,open:I,renderValue:q,SelectDisplayProps:T({id:f},x)},u,{classes:u?Bt(z,u.classes):z},h?h.props.inputProps:{})},_&&g&&M==="outlined"?{notched:!0}:{},{ref:D,className:V(L.props.className,s,R.root)},!h&&{variant:M},S))})});u_.muiName="Select";const RI=u_,OI=sn.plugins,p_=v.createContext(),m_=()=>v.useContext(p_),zI=({children:e})=>{const[t,n]=v.useState("release"),[i,a]=v.useState(OI);return p.jsx(p_.Provider,{value:{sortOption:t,setSortOption:n,sortedData:i,setSortedData:a},children:e})},Kl=sn.plugins;function WI(){const{setSearchQuery:e,setIsSearchSubmitted:t}=zo(),{sortOption:n,setSortOption:i,setSortedData:a}=m_();v.useEffect(()=>{document.documentElement.style.scrollBehavior="auto",l(n),o()},[n]);function o(){var c=window.scrollY;window.onscroll=function(){var d=window.scrollY;c>d?document.querySelector("header").style.top="0":c>150&&(document.querySelector("header").style.top="-155px"),c=d}}function r(c){const d=Object.entries(c);return d.sort(([,f],[,h])=>h.commits_count-f.commits_count),Object.fromEntries(d)}function s(c){const d=Object.entries(c);return d.sort(([,f],[,h])=>!f.metadata.release_date&&!h.metadata.release_date?0:f.metadata.release_date?h.metadata.release_date?new Date(h.metadata.release_date)-new Date(f.metadata.release_date):-1:1),Object.fromEntries(d)}const l=c=>{i(c),e(""),t(!1);let d={};c==="commits"?d=r(Kl):c=="alpha"?d=Kl:c=="release"&&(d=s(Kl)),a(d)};return p.jsx(V3,{children:p.jsxs(cT,{children:[p.jsx(s6,{children:"Sort"}),p.jsxs(RI,{value:n,label:"Sort",onChange:c=>l(c.target.value),children:[p.jsx($l,{value:"commits",children:"Commits Count"}),p.jsx($l,{value:"alpha",children:"Alphabetical"}),p.jsx($l,{value:"release",children:"Recent Release"})]})]})})}var Xu={},jI=vu;Object.defineProperty(Xu,"__esModule",{value:!0});var f_=Xu.default=void 0,MI=jI(ju()),LI=p,FI=(0,MI.default)((0,LI.jsx)("path",{d:"M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z"}),"CheckCircle");f_=Xu.default=FI;function UI(e){return pe("MuiDialog",e)}const GI=oe("MuiDialog",["root","scrollPaper","scrollBody","container","paper","paperScrollPaper","paperScrollBody","paperWidthFalse","paperWidthXs","paperWidthSm","paperWidthMd","paperWidthLg","paperWidthXl","paperFullWidth","paperFullScreen"]),Xl=GI,$I=v.createContext({}),h_=$I,VI=["aria-describedby","aria-labelledby","BackdropComponent","BackdropProps","children","className","disableEscapeKeyDown","fullScreen","fullWidth","maxWidth","onBackdropClick","onClose","open","PaperComponent","PaperProps","scroll","TransitionComponent","transitionDuration","TransitionProps"],HI=F(a_,{name:"MuiDialog",slot:"Backdrop",overrides:(e,t)=>t.backdrop})({zIndex:-1}),ZI=e=>{const{classes:t,scroll:n,maxWidth:i,fullWidth:a,fullScreen:o}=e,r={root:["root"],container:["container",`scroll${Z(n)}`],paper:["paper",`paperScroll${Z(n)}`,`paperWidth${Z(String(i))}`,a&&"paperFullWidth",o&&"paperFullScreen"]};return me(r,UI,t)},QI=F(Hu,{name:"MuiDialog",slot:"Root",overridesResolver:(e,t)=>t.root})({"@media print":{position:"absolute !important"}}),KI=F("div",{name:"MuiDialog",slot:"Container",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.container,t[`scroll${Z(n.scroll)}`]]}})(({ownerState:e})=>T({height:"100%","@media print":{height:"auto"},outline:0},e.scroll==="paper"&&{display:"flex",justifyContent:"center",alignItems:"center"},e.scroll==="body"&&{overflowY:"auto",overflowX:"hidden",textAlign:"center","&:after":{content:'""',display:"inline-block",verticalAlign:"middle",height:"100%",width:"0"}})),XI=F(Mo,{name:"MuiDialog",slot:"Paper",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.paper,t[`scrollPaper${Z(n.scroll)}`],t[`paperWidth${Z(String(n.maxWidth))}`],n.fullWidth&&t.paperFullWidth,n.fullScreen&&t.paperFullScreen]}})(({theme:e,ownerState:t})=>T({margin:32,position:"relative",overflowY:"auto","@media print":{overflowY:"visible",boxShadow:"none"}},t.scroll==="paper"&&{display:"flex",flexDirection:"column",maxHeight:"calc(100% - 64px)"},t.scroll==="body"&&{display:"inline-block",verticalAlign:"middle",textAlign:"left"},!t.maxWidth&&{maxWidth:"calc(100% - 64px)"},t.maxWidth==="xs"&&{maxWidth:e.breakpoints.unit==="px"?Math.max(e.breakpoints.values.xs,444):`max(${e.breakpoints.values.xs}${e.breakpoints.unit}, 444px)`,[`&.${Xl.paperScrollBody}`]:{[e.breakpoints.down(Math.max(e.breakpoints.values.xs,444)+32*2)]:{maxWidth:"calc(100% - 64px)"}}},t.maxWidth&&t.maxWidth!=="xs"&&{maxWidth:`${e.breakpoints.values[t.maxWidth]}${e.breakpoints.unit}`,[`&.${Xl.paperScrollBody}`]:{[e.breakpoints.down(e.breakpoints.values[t.maxWidth]+32*2)]:{maxWidth:"calc(100% - 64px)"}}},t.fullWidth&&{width:"calc(100% - 64px)"},t.fullScreen&&{margin:0,width:"100%",maxWidth:"100%",height:"100%",maxHeight:"none",borderRadius:0,[`&.${Xl.paperScrollBody}`]:{margin:0,maxWidth:"100%"}})),YI=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiDialog"}),a=xa(),o={enter:a.transitions.duration.enteringScreen,exit:a.transitions.duration.leavingScreen},{"aria-describedby":r,"aria-labelledby":s,BackdropComponent:l,BackdropProps:c,children:d,className:f,disableEscapeKeyDown:h=!1,fullScreen:u=!1,fullWidth:y=!1,maxWidth:m="sm",onBackdropClick:k,onClose:_,open:g,PaperComponent:b=Mo,PaperProps:w={},scroll:I="paper",TransitionComponent:q=i_,transitionDuration:x=o,TransitionProps:C}=i,S=U(i,VI),P=T({},i,{disableEscapeKeyDown:h,fullScreen:u,fullWidth:y,maxWidth:m,scroll:I}),B=ZI(P),O=v.useRef(),M=L=>{O.current=L.target===L.currentTarget},E=L=>{O.current&&(O.current=null,k&&k(L),_&&_(L,"backdropClick"))},R=og(s),z=v.useMemo(()=>({titleId:R}),[R]);return p.jsx(QI,T({className:V(B.root,f),closeAfterTransition:!0,components:{Backdrop:HI},componentsProps:{backdrop:T({transitionDuration:x,as:l},c)},disableEscapeKeyDown:h,onClose:_,open:g,ref:n,onClick:E,ownerState:P},S,{children:p.jsx(q,T({appear:!0,in:g,timeout:x,role:"presentation"},C,{children:p.jsx(KI,{className:V(B.container),onMouseDown:M,ownerState:P,children:p.jsx(XI,T({as:b,elevation:24,role:"dialog","aria-describedby":r,"aria-labelledby":R},w,{className:V(B.paper,w.className),ownerState:P,children:p.jsx(h_.Provider,{value:z,children:d})}))})}))}))}),JI=YI;function eq(e){return pe("MuiDialogContent",e)}oe("MuiDialogContent",["root","dividers"]);function tq(e){return pe("MuiDialogTitle",e)}const nq=oe("MuiDialogTitle",["root"]),iq=nq,aq=["className","dividers"],oq=e=>{const{classes:t,dividers:n}=e;return me({root:["root",n&&"dividers"]},eq,t)},rq=F("div",{name:"MuiDialogContent",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.dividers&&t.dividers]}})(({theme:e,ownerState:t})=>T({flex:"1 1 auto",WebkitOverflowScrolling:"touch",overflowY:"auto",padding:"20px 24px"},t.dividers?{padding:"16px 24px",borderTop:`1px solid ${(e.vars||e).palette.divider}`,borderBottom:`1px solid ${(e.vars||e).palette.divider}`}:{[`.${iq.root} + &`]:{paddingTop:0}})),sq=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiDialogContent"}),{className:a,dividers:o=!1}=i,r=U(i,aq),s=T({},i,{dividers:o}),l=oq(s);return p.jsx(rq,T({className:V(l.root,a),ownerState:s,ref:n},r))}),lq=sq;function cq(e){return pe("MuiDialogContentText",e)}oe("MuiDialogContentText",["root"]);const dq=["children","className"],uq=e=>{const{classes:t}=e,i=me({root:["root"]},cq,t);return T({},t,i)},pq=F(Jg,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiDialogContentText",slot:"Root",overridesResolver:(e,t)=>t.root})({}),mq=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiDialogContentText"}),{className:a}=i,o=U(i,dq),r=uq(o);return p.jsx(pq,T({component:"p",variant:"body1",color:"text.secondary",ref:n,ownerState:o,className:V(r.root,a)},i,{classes:r}))}),fq=mq,hq=["className","id"],yq=e=>{const{classes:t}=e;return me({root:["root"]},tq,t)},gq=F(Jg,{name:"MuiDialogTitle",slot:"Root",overridesResolver:(e,t)=>t.root})({padding:"16px 24px",flex:"0 0 auto"}),_q=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiDialogTitle"}),{className:a,id:o}=i,r=U(i,hq),s=i,l=yq(s),{titleId:c=o}=v.useContext(h_);return p.jsx(gq,T({component:"h2",className:V(l.root,a),ownerState:s,ref:n,variant:"h6",id:o??c},r))}),bq=_q,y_="data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACMAAAAhCAYAAABTERJSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAFhgAABYYBG6Yz4AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAUbSURBVFiFzZhrbFRVEMd%2Fc%2B5uu6UUbIFC%2FUAUVEQCLbQJBIiBDyiImJiIhmohYNCkqJAQxASLF8tDgYRHBLXRhIcKNtFEhVDgAxBJqgmVh4JEKg3EIn2QYqBlt917xg%2BFss%2ByaDHOtzsz5z%2B%2FuZl7ztmF%2F5HJvxVQN6cPYX8%2FPLnOmsvNAvqfwuib%2FbNIk9cQeQnLcKRL5xLIV%2Fic9eJeunjPYbRs4FjQSpTB3aS1IpRKeeOOewajy%2FKKEO8Q0DuVdKy8IqsbPulxGHUfCBBu%2BwUYGuFuBTK7wQnht6PEbf4tlRomVRjCbXNjQEB0AyrFQOL5ENIJm7dTLZE6DPJCnEtFZVXDLny%2B4Sjv0PmmYu1ZdUek9RiMgoDmJ8V0L7XJqsZ3UW8YsBOwEeHeeFce7jEYXBy0m9m4BbXqSj2%2Bxnkg26MCVrN6DEZcwggtd8pTFx%2Fh3B9B50YLaFOPwXQKUt0tBLegtSomfBlfY13PwijbEnhztGzgJsK5h9W9qeWwBqjvyhB2iBs1Qz0AU974DciRGO8CVN8AJhAeMAdA3KbrKEtvxhsI%2B9emWiJlGBEU680Cfk%2BSsVqXZvcFYGXjF8ABVJ%2BTNfVXehyms1zzn1gmIOxLEB6E31%2FWBe5rnCarmo7elf7dJEeaLh80GasliI5F6Q9cAz1GY1OJVNDxTzQTw7iY%2FHEZRQY7xqJ9RU2LFe%2FYqakdP911ha0XhjjiTVAkDwgatWfCGeYocx8M3glG8g8EXhSrLrHnEFJ5Ymow%2FkhIYv6ttYUW1iFmEqqxdVoUs9FmsDYSqmtmJh3Cl1%2BVtl2s7owDUdocR5bceiyoSivGTT5vzpbzL1uoBpmcAAQgW7ArnKD9ng9rc%2BNgrobSNwpSkkhcRN%2BvmXLjIsDovYHHEfmsYFygPAnIDEQrQPzJYCOaLHLUfIt7Oq0LJn9fxkSgNCb1qEIQ5UKgT%2Fs6gJmVOOroJhQBXVqw118QtWLdyUxEP45sUpSzqP7RDdFYMyB9UReMiF1MzPwoUqHt8hjGFFeP5wZAbZ%2F0%2BcAtAAcji6LeSq%2FMYiAvSsdw3GtrfVSVFUBbIhwRWYR7yOcr%2FBi%2FB1MSJZ16JlgH1AGM3EO2QnmMyrSbTSiACgFBv4yCUapZkt9qwWVL7aeOyHvArJjm8%2Fz9BhdI4XcZgz2%2FvRALosjsk1ODOyMcJn9%2FYI6IrkS5vxMGdUwou2YKfyVqJpn5t9aNs3gbQMbdbkxnGdsr4bTHm2AxWo9yNZK4PXR3uzhAh%2BM0AZejnCrGdy0UvJxl0oMKgWSLR%2B1LH2aE9ViejiFs%2BXn6bTjng3MlIhJ1I1TkuLdg6OcAbD7Xx%2Bc3y9TrWAiSHqVkbZ2v9ilCo6s4AjwZCzFyD9mOL305nV9aonvsQeT2L0gVk4OwOJqXXVRW7naaxswDKVdlYLyMXAnntteYmws2xcVVZzq%2BtHPAooQggmJkc6TLSusOiL4RKgwzzYU1iFQgiUBA1H7E8yPau%2BZl9P7AblVNebtHqTgxLfRqrNvZWjsHZFuqMqKcDWdlFjF7UGvX8Jn24DyEAykJwNcdg0OvJ4p5pQ9tV6SMlP4A0PNh8aYze1ArROyUNTNouy8tNF3Rt0CSXb6bRFl4%2FIfQzNMjaE9WwpYOWQnOdEF%2BTdJNO0iFh7%2BI0kfORzQZb6P2kymS9oTxzBiM9rUqLWr1WE5G6ODhycQd%2FUnNVeMbcH68hYkGycNoUNWc8fxaxfwhDbHpfwM5oeTY7rUX8QAAAABJRU5ErkJggg%3D%3D";const gf=sn.status_dict,vq="/aiida-registry/pr-preview/pr-280/";function wq(){const{sortOption:e,sortedData:t}=m_();return p.jsx(p.Fragment,{children:Object.entries(t).map(([n,i])=>p.jsxs("div",{className:"submenu-entry",children:[p.jsx(Ti,{to:`/${n}`,children:p.jsxs("h2",{style:{display:"inline"},children:[n," "]})}),i.is_installable==="True"&&p.jsx(xq,{}),p.jsxs("p",{className:"currentstate",children:[p.jsx("img",{className:"svg-badge",src:`${vq}${gf[i.development_status][1]}`,title:gf[i.development_status][0]})," ",i.aiida_version&&p.jsx("img",{className:"svg-badge",title:`Compatible with aiida-core ${i.aiida_version}`,src:`https://img.shields.io/badge/AiiDA-${i.aiida_version}-007ec6.svg?logo=${y_}`}),e==="commits"&&p.jsx("img",{className:"svg-badge",style:{padding:"3px"},src:`https://img.shields.io/badge/Yearly%20Commits-${i.commits_count}-007ec6.svg`}),e==="release"&&i.metadata.release_date&&p.jsx("img",{className:"svg-badge",style:{padding:"3px"},src:`https://img.shields.io/badge/Recent%20Release-${i.metadata.release_date.replace(/-/g,"/")}-007ec6.svg`})]}),p.jsx("p",{children:i.metadata.description}),p.jsxs("ul",{className:"plugin-info",children:[p.jsx("li",{children:p.jsx("a",{href:i.code_home,children:"Source Code"})}),i.documentation_url&&p.jsx("li",{children:p.jsx("a",{href:i.documentation_url,children:"Documentation"})}),p.jsx("li",{children:p.jsx(Ti,{to:`/${n}`,children:"Plugin details"})})]}),i.summaryinfo&&p.jsx(p.Fragment,{children:p.jsx("p",{className:"summaryinfo",children:i.summaryinfo.map(a=>p.jsxs("span",{className:"badge",children:[p.jsx("span",{className:`badge-left ${a.colorclass}`,children:a.text}),p.jsx("span",{className:"badge-right",children:a.count})]},a.text))})})]},n))})}function xq(){const[e,t]=v.useState(!1),n=()=>{t(!0)},i=()=>{t(!1)};return p.jsxs(p.Fragment,{children:[p.jsxs("div",{className:"classbox",style:{backgroundColor:"transparent"},children:[p.jsx(f_,{onClick:n,style:{color:"green",cursor:"pointer",marginBottom:"-5"}}),p.jsx("span",{className:"tooltiptext",children:"Plugin successfully installed"})]}),p.jsxs(JI,{open:e,onClose:i,children:[p.jsx(bq,{children:"This plugin can be installed with the latest aiida-core version."}),p.jsx(lq,{children:p.jsxs(fq,{children:["This check mark indicates that this plugin was installed successfully inside the latest",p.jsxs("a",{rel:"noopener noreferrer",target:"_blank",href:"https://hub.docker.com/r/aiidateam/aiida-core",children:[p.jsx("code",{children:" aiida-core"})," docker image"]}),". For in-depth compatibility tests see the source code repository of the plugin."]})})]})]})}const Tq=sn.globalsummary,kq=sn.plugins,Iq=Object.keys(kq).length;function qq(){return p.jsxs(p.Fragment,{children:[p.jsxs("h2",{children:["Registered plugin packages: ",Iq]}),p.jsx("div",{className:"globalsummary-box",children:p.jsx("div",{style:{display:"table"},children:Tq.map(e=>p.jsxs("span",{className:"badge",style:{display:"table-row",lineHeight:2},children:[p.jsx("span",{style:{display:"table-cell",float:"none",textAlign:"right"},children:p.jsxs("span",{className:`badge-left ${e.colorclass} tooltip`,style:{float:"none",display:"inline",textAlign:"right",border:"none"},children:[e.name,e.tooltip&&p.jsx("span",{className:"tooltiptext",children:e.tooltip})]})}),p.jsx("span",{style:{display:"table-cell",float:"none",textAlign:"left"},children:p.jsxs("span",{className:"badge-right",style:{float:"none",display:"inline",textAlign:"left",border:"none"},children:[e.total_num," plugin",e.total_num!==1?"s":""," in ",e.num_entries," package",e.num_entries!==1?"s":""]})})]},e.name))})})]})}function Cq(){const{isSearchSubmitted:e}=zo();return p.jsxs("main",{className:"fade-enter",children:[p.jsx(qq,{}),p.jsxs("div",{id:"entrylist",children:[p.jsx("h1",{children:"Package list"}),p.jsxs("div",{className:"bar-container",children:[p.jsx("div",{style:{flex:"1",marginRight:"10px"},children:p.jsx(L3,{})}),p.jsx(WI,{})]}),e===!0?p.jsx(F3,{}):p.jsx(wq,{})]})]})}function di(){return di=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var i in n)Object.prototype.hasOwnProperty.call(n,i)&&(e[i]=n[i])}return e},di.apply(this,arguments)}const Dq=["children","options"],_f=["allowFullScreen","allowTransparency","autoComplete","autoFocus","autoPlay","cellPadding","cellSpacing","charSet","className","classId","colSpan","contentEditable","contextMenu","crossOrigin","encType","formAction","formEncType","formMethod","formNoValidate","formTarget","frameBorder","hrefLang","inputMode","keyParams","keyType","marginHeight","marginWidth","maxLength","mediaGroup","minLength","noValidate","radioGroup","readOnly","rowSpan","spellCheck","srcDoc","srcLang","srcSet","tabIndex","useMap"].reduce((e,t)=>(e[t.toLowerCase()]=t,e),{for:"htmlFor"}),bf={amp:"&",apos:"'",gt:">",lt:"<",nbsp:" ",quot:"“"},Pq=["style","script"],Sq=/([-A-Z0-9_:]+)(?:\s*=\s*(?:(?:"((?:\\.|[^"])*)")|(?:'((?:\\.|[^'])*)')|(?:\{((?:\\.|{[^}]*?}|[^}])*)\})))?/gi,Aq=/mailto:/i,Eq=/\n{2,}$/,g_=/^( *>[^\n]+(\n[^\n]+)*\n*)+\n{2,}/,Nq=/^ *> ?/gm,Bq=/^ {2,}\n/,Rq=/^(?:( *[-*_])){3,} *(?:\n *)+\n/,__=/^\s*(`{3,}|~{3,}) *(\S+)?([^\n]*?)?\n([\s\S]+?)\s*\1 *(?:\n *)*\n?/,b_=/^(?: {4}[^\n]+\n*)+(?:\n *)+\n?/,Oq=/^(`+)\s*([\s\S]*?[^`])\s*\1(?!`)/,zq=/^(?:\n *)*\n/,Wq=/\r\n?/g,jq=/^\[\^([^\]]+)](:.*)\n/,Mq=/^\[\^([^\]]+)]/,Lq=/\f/g,Fq=/^\s*?\[(x|\s)\]/,v_=/^ *(#{1,6}) *([^\n]+?)(?: +#*)?(?:\n *)*(?:\n|$)/,w_=/^ *(#{1,6}) +([^\n]+?)(?: +#*)?(?:\n *)*(?:\n|$)/,x_=/^([^\n]+)\n *(=|-){3,} *(?:\n *)+\n/,bd=/^ *(?!<[a-z][^ >/]* ?\/>)<([a-z][^ >/]*) ?([^>]*)\/{0}>\n?(\s*(?:<\1[^>]*?>[\s\S]*?<\/\1>|(?!<\1)[\s\S])*?)<\/\1>\n*/i,Uq=/&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-fA-F]{1,6});/gi,T_=/^<!--[\s\S]*?(?:-->)/,Gq=/^(data|aria|x)-[a-z_][a-z\d_.-]*$/,vd=/^ *<([a-z][a-z0-9:]*)(?:\s+((?:<.*?>|[^>])*))?\/?>(?!<\/\1>)(\s*\n)?/i,$q=/^\{.*\}$/,Vq=/^(https?:\/\/[^\s<]+[^<.,:;"')\]\s])/,Hq=/^<([^ >]+@[^ >]+)>/,Zq=/^<([^ >]+:\/[^ >]+)>/,Qq=/-([a-z])?/gi,k_=/^(.*\|?.*)\n *(\|? *[-:]+ *\|[-| :]*)\n((?:.*\|.*\n)*)\n?/,Kq=/^\[([^\]]*)\]:\s+<?([^\s>]+)>?\s*("([^"]*)")?/,Xq=/^!\[([^\]]*)\] ?\[([^\]]*)\]/,Yq=/^\[([^\]]*)\] ?\[([^\]]*)\]/,Jq=/(\[|\])/g,eC=/(\n|^[-*]\s|^#|^ {2,}|^-{2,}|^>\s)/,tC=/\t/g,nC=/^ *\| */,iC=/(^ *\||\| *$)/g,aC=/ *$/,oC=/^ *:-+: *$/,rC=/^ *:-+ *$/,sC=/^ *-+: *$/,lC=/^([*_])\1((?:\[.*?\][([].*?[)\]]|<.*?>(?:.*?<.*?>)?|`.*?`|~+.*?~+|.)*?)\1\1(?!\1)/,cC=/^([*_])((?:\[.*?\][([].*?[)\]]|<.*?>(?:.*?<.*?>)?|`.*?`|~+.*?~+|.)*?)\1(?!\1|\w)/,dC=/^==((?:\[.*?\]|<.*?>(?:.*?<.*?>)?|`.*?`|.)*?)==/,uC=/^~~((?:\[.*?\]|<.*?>(?:.*?<.*?>)?|`.*?`|.)*?)~~/,pC=/^\\([^0-9A-Za-z\s])/,mC=/^[\s\S]+?(?=[^0-9A-Z\s\u00c0-\uffff&#;.()'"]|\d+\.|\n\n| {2,}\n|\w+:\S|$)/i,fC=/^\n+/,hC=/^([ \t]*)/,yC=/\\([^\\])/g,vf=/ *\n+$/,gC=/(?:^|\n)( *)$/,Yu="(?:\\d+\\.)",Ju="(?:[*+-])";function I_(e){return"( *)("+(e===1?Yu:Ju)+") +"}const q_=I_(1),C_=I_(2);function D_(e){return new RegExp("^"+(e===1?q_:C_))}const _C=D_(1),bC=D_(2);function P_(e){return new RegExp("^"+(e===1?q_:C_)+"[^\\n]*(?:\\n(?!\\1"+(e===1?Yu:Ju)+" )[^\\n]*)*(\\n|$)","gm")}const S_=P_(1),A_=P_(2);function E_(e){const t=e===1?Yu:Ju;return new RegExp("^( *)("+t+") [\\s\\S]+?(?:\\n{2,}(?! )(?!\\1"+t+" (?!"+t+" ))\\n*|\\s*\\n*$)")}const N_=E_(1),B_=E_(2);function wf(e,t){const n=t===1,i=n?N_:B_,a=n?S_:A_,o=n?_C:bC;return{t(r,s,l){const c=gC.exec(l);return c&&(s.o||!s._&&!s.u)?i.exec(r=c[1]+r):null},i:J.HIGH,l(r,s,l){const c=n?+r[2]:void 0,d=r[0].replace(Eq,`
`).match(a);let f=!1;return{p:d.map(function(h,u){const y=o.exec(h)[0].length,m=new RegExp("^ {1,"+y+"}","gm"),k=h.replace(m,"").replace(o,""),_=u===d.length-1,g=k.indexOf(`

`)!==-1||_&&f;f=g;const b=l._,w=l.o;let I;l.o=!0,g?(l._=!1,I=k.replace(vf,`

`)):(l._=!0,I=k.replace(vf,""));const q=s(I,l);return l._=b,l.o=w,q}),m:n,g:c}},h:(r,s,l)=>e(r.m?"ol":"ul",{key:l.k,start:r.g},r.p.map(function(c,d){return e("li",{key:d},s(c,l))}))}}const vC=/^\[([^\]]*)]\( *((?:\([^)]*\)|[^() ])*) *"?([^)"]*)?"?\)/,wC=/^!\[([^\]]*)]\( *((?:\([^)]*\)|[^() ])*) *"?([^)"]*)?"?\)/,R_=[g_,__,b_,v_,x_,w_,T_,k_,S_,N_,A_,B_],xC=[...R_,/^[^\n]+(?:  \n|\n{2,})/,bd,vd];function TC(e){return e.replace(/[ÀÁÂÃÄÅàáâãäåæÆ]/g,"a").replace(/[çÇ]/g,"c").replace(/[ðÐ]/g,"d").replace(/[ÈÉÊËéèêë]/g,"e").replace(/[ÏïÎîÍíÌì]/g,"i").replace(/[Ññ]/g,"n").replace(/[øØœŒÕõÔôÓóÒò]/g,"o").replace(/[ÜüÛûÚúÙù]/g,"u").replace(/[ŸÿÝý]/g,"y").replace(/[^a-z0-9- ]/gi,"").replace(/ /gi,"-").toLowerCase()}function kC(e){return sC.test(e)?"right":oC.test(e)?"center":rC.test(e)?"left":null}function xf(e,t,n){const i=n.$;n.$=!0;const a=t(e.trim(),n);n.$=i;let o=[[]];return a.forEach(function(r,s){r.type==="tableSeparator"?s!==0&&s!==a.length-1&&o.push([]):(r.type!=="text"||a[s+1]!=null&&a[s+1].type!=="tableSeparator"||(r.v=r.v.replace(aC,"")),o[o.length-1].push(r))}),o}function IC(e,t,n){n._=!0;const i=xf(e[1],t,n),a=e[2].replace(iC,"").split("|").map(kC),o=function(r,s,l){return r.trim().split(`
`).map(function(c){return xf(c,s,l)})}(e[3],t,n);return n._=!1,{S:a,A:o,L:i,type:"table"}}function Tf(e,t){return e.S[t]==null?{}:{textAlign:e.S[t]}}function Sn(e){return function(t,n){return n._?e.exec(t):null}}function An(e){return function(t,n){return n._||n.u?e.exec(t):null}}function un(e){return function(t,n){return n._||n.u?null:e.exec(t)}}function ja(e){return function(t){return e.exec(t)}}function qC(e,t,n){if(t._||t.u||n&&!n.endsWith(`
`))return null;let i="";e.split(`
`).every(o=>!R_.some(r=>r.test(o))&&(i+=o+`
`,o.trim()));const a=i.trimEnd();return a==""?null:[i,a]}function Oi(e){try{if(decodeURIComponent(e).replace(/[^A-Za-z0-9/:]/g,"").match(/^\s*(javascript|vbscript|data(?!:image)):/i))return}catch{return null}return e}function kf(e){return e.replace(yC,"$1")}function Ir(e,t,n){const i=n._||!1,a=n.u||!1;n._=!0,n.u=!0;const o=e(t,n);return n._=i,n.u=a,o}function CC(e,t,n){const i=n._||!1,a=n.u||!1;n._=!1,n.u=!0;const o=e(t,n);return n._=i,n.u=a,o}function DC(e,t,n){return n._=!1,e(t,n)}const Yl=(e,t,n)=>({v:Ir(t,e[1],n)});function Jl(){return{}}function ec(){return null}function PC(...e){return e.filter(Boolean).join(" ")}function tc(e,t,n){let i=e;const a=t.split(".");for(;a.length&&(i=i[a[0]],i!==void 0);)a.shift();return i||n}var J;function SC(e,t={}){t.overrides=t.overrides||{},t.slugify=t.slugify||TC,t.namedCodesToUnicode=t.namedCodesToUnicode?di({},bf,t.namedCodesToUnicode):bf;const n=t.createElement||v.createElement;function i(u,y,...m){const k=tc(t.overrides,`${u}.props`,{});return n(function(_,g){const b=tc(g,_);return b?typeof b=="function"||typeof b=="object"&&"render"in b?b:tc(g,`${_}.component`,_):_}(u,t.overrides),di({},y,k,{className:PC(y==null?void 0:y.className,k.className)||void 0}),...m)}function a(u){let y=!1;t.forceInline?y=!0:t.forceBlock||(y=eC.test(u)===!1);const m=d(c(y?u:`${u.trimEnd().replace(fC,"")}

`,{_:y}));for(;typeof m[m.length-1]=="string"&&!m[m.length-1].trim();)m.pop();if(t.wrapper===null)return m;const k=t.wrapper||(y?"span":"div");let _;if(m.length>1||t.forceWrapper)_=m;else{if(m.length===1)return _=m[0],typeof _=="string"?i("span",{key:"outer"},_):_;_=null}return v.createElement(k,{key:"outer"},_)}function o(u){const y=u.match(Sq);return y?y.reduce(function(m,k,_){const g=k.indexOf("=");if(g!==-1){const b=function(x){return x.indexOf("-")!==-1&&x.match(Gq)===null&&(x=x.replace(Qq,function(C,S){return S.toUpperCase()})),x}(k.slice(0,g)).trim(),w=function(x){const C=x[0];return(C==='"'||C==="'")&&x.length>=2&&x[x.length-1]===C?x.slice(1,-1):x}(k.slice(g+1).trim()),I=_f[b]||b,q=m[I]=function(x,C){return x==="style"?C.split(/;\s?/).reduce(function(S,P){const B=P.slice(0,P.indexOf(":"));return S[B.replace(/(-[a-z])/g,O=>O[1].toUpperCase())]=P.slice(B.length+1).trim(),S},{}):x==="href"?Oi(C):(C.match($q)&&(C=C.slice(1,C.length-1)),C==="true"||C!=="false"&&C)}(b,w);typeof q=="string"&&(bd.test(q)||vd.test(q))&&(m[I]=v.cloneElement(a(q.trim()),{key:_}))}else k!=="style"&&(m[_f[k]||k]=!0);return m},{}):null}const r=[],s={},l={blockQuote:{t:un(g_),i:J.HIGH,l:(u,y,m)=>({v:y(u[0].replace(Nq,""),m)}),h:(u,y,m)=>i("blockquote",{key:m.k},y(u.v,m))},breakLine:{t:ja(Bq),i:J.HIGH,l:Jl,h:(u,y,m)=>i("br",{key:m.k})},breakThematic:{t:un(Rq),i:J.HIGH,l:Jl,h:(u,y,m)=>i("hr",{key:m.k})},codeBlock:{t:un(b_),i:J.MAX,l:u=>({v:u[0].replace(/^ {4}/gm,"").replace(/\n+$/,""),M:void 0}),h:(u,y,m)=>i("pre",{key:m.k},i("code",di({},u.O,{className:u.M?`lang-${u.M}`:""}),u.v))},codeFenced:{t:un(__),i:J.MAX,l:u=>({O:o(u[3]||""),v:u[4],M:u[2]||void 0,type:"codeBlock"})},codeInline:{t:An(Oq),i:J.LOW,l:u=>({v:u[2]}),h:(u,y,m)=>i("code",{key:m.k},u.v)},footnote:{t:un(jq),i:J.MAX,l:u=>(r.push({I:u[2],j:u[1]}),{}),h:ec},footnoteReference:{t:Sn(Mq),i:J.HIGH,l:u=>({v:u[1],B:`#${t.slugify(u[1])}`}),h:(u,y,m)=>i("a",{key:m.k,href:Oi(u.B)},i("sup",{key:m.k},u.v))},gfmTask:{t:Sn(Fq),i:J.HIGH,l:u=>({R:u[1].toLowerCase()==="x"}),h:(u,y,m)=>i("input",{checked:u.R,key:m.k,readOnly:!0,type:"checkbox"})},heading:{t:un(t.enforceAtxHeadings?w_:v_),i:J.HIGH,l:(u,y,m)=>({v:Ir(y,u[2],m),T:t.slugify(u[2]),C:u[1].length}),h:(u,y,m)=>i(`h${u.C}`,{id:u.T,key:m.k},y(u.v,m))},headingSetext:{t:un(x_),i:J.MAX,l:(u,y,m)=>({v:Ir(y,u[1],m),C:u[2]==="="?1:2,type:"heading"})},htmlComment:{t:ja(T_),i:J.HIGH,l:()=>({}),h:ec},image:{t:An(wC),i:J.HIGH,l:u=>({D:u[1],B:kf(u[2]),F:u[3]}),h:(u,y,m)=>i("img",{key:m.k,alt:u.D||void 0,title:u.F||void 0,src:Oi(u.B)})},link:{t:Sn(vC),i:J.LOW,l:(u,y,m)=>({v:CC(y,u[1],m),B:kf(u[2]),F:u[3]}),h:(u,y,m)=>i("a",{key:m.k,href:Oi(u.B),title:u.F},y(u.v,m))},linkAngleBraceStyleDetector:{t:Sn(Zq),i:J.MAX,l:u=>({v:[{v:u[1],type:"text"}],B:u[1],type:"link"})},linkBareUrlDetector:{t:(u,y)=>y.N?null:Sn(Vq)(u,y),i:J.MAX,l:u=>({v:[{v:u[1],type:"text"}],B:u[1],F:void 0,type:"link"})},linkMailtoDetector:{t:Sn(Hq),i:J.MAX,l(u){let y=u[1],m=u[1];return Aq.test(m)||(m="mailto:"+m),{v:[{v:y.replace("mailto:",""),type:"text"}],B:m,type:"link"}}},orderedList:wf(i,1),unorderedList:wf(i,2),newlineCoalescer:{t:un(zq),i:J.LOW,l:Jl,h:()=>`
`},paragraph:{t:qC,i:J.LOW,l:Yl,h:(u,y,m)=>i("p",{key:m.k},y(u.v,m))},ref:{t:Sn(Kq),i:J.MAX,l:u=>(s[u[1]]={B:u[2],F:u[4]},{}),h:ec},refImage:{t:An(Xq),i:J.MAX,l:u=>({D:u[1]||void 0,P:u[2]}),h:(u,y,m)=>i("img",{key:m.k,alt:u.D,src:Oi(s[u.P].B),title:s[u.P].F})},refLink:{t:Sn(Yq),i:J.MAX,l:(u,y,m)=>({v:y(u[1],m),Z:y(u[0].replace(Jq,"\\$1"),m),P:u[2]}),h:(u,y,m)=>s[u.P]?i("a",{key:m.k,href:Oi(s[u.P].B),title:s[u.P].F},y(u.v,m)):i("span",{key:m.k},y(u.Z,m))},table:{t:un(k_),i:J.HIGH,l:IC,h:(u,y,m)=>i("table",{key:m.k},i("thead",null,i("tr",null,u.L.map(function(k,_){return i("th",{key:_,style:Tf(u,_)},y(k,m))}))),i("tbody",null,u.A.map(function(k,_){return i("tr",{key:_},k.map(function(g,b){return i("td",{key:b,style:Tf(u,b)},y(g,m))}))})))},tableSeparator:{t:function(u,y){return y.$?(y._=!0,nC.exec(u)):null},i:J.HIGH,l:function(){return{type:"tableSeparator"}},h:()=>" | "},text:{t:ja(mC),i:J.MIN,l:u=>({v:u[0].replace(Uq,(y,m)=>t.namedCodesToUnicode[m]?t.namedCodesToUnicode[m]:y)}),h:u=>u.v},textBolded:{t:An(lC),i:J.MED,l:(u,y,m)=>({v:y(u[2],m)}),h:(u,y,m)=>i("strong",{key:m.k},y(u.v,m))},textEmphasized:{t:An(cC),i:J.LOW,l:(u,y,m)=>({v:y(u[2],m)}),h:(u,y,m)=>i("em",{key:m.k},y(u.v,m))},textEscaped:{t:An(pC),i:J.HIGH,l:u=>({v:u[1],type:"text"})},textMarked:{t:An(dC),i:J.LOW,l:Yl,h:(u,y,m)=>i("mark",{key:m.k},y(u.v,m))},textStrikethroughed:{t:An(uC),i:J.LOW,l:Yl,h:(u,y,m)=>i("del",{key:m.k},y(u.v,m))}};t.disableParsingRawHTML!==!0&&(l.htmlBlock={t:ja(bd),i:J.HIGH,l(u,y,m){const[,k]=u[3].match(hC),_=new RegExp(`^${k}`,"gm"),g=u[3].replace(_,""),b=(w=g,xC.some(C=>C.test(w))?DC:Ir);var w;const I=u[1].toLowerCase(),q=Pq.indexOf(I)!==-1;m.N=m.N||I==="a";const x=q?u[3]:b(y,g,m);return m.N=!1,{O:o(u[2]),v:x,G:q,H:q?I:u[1]}},h:(u,y,m)=>i(u.H,di({key:m.k},u.O),u.G?u.v:y(u.v,m))},l.htmlSelfClosing={t:ja(vd),i:J.HIGH,l:u=>({O:o(u[2]||""),H:u[1]}),h:(u,y,m)=>i(u.H,di({},u.O,{key:m.k}))});const c=function(u){let y=Object.keys(u);function m(k,_){let g=[],b="";for(;k;){let w=0;for(;w<y.length;){const I=y[w],q=u[I],x=q.t(k,_,b);if(x){const C=x[0];k=k.substring(C.length);const S=q.l(x,m,_);S.type==null&&(S.type=I),g.push(S),b=C;break}w++}}return g}return y.sort(function(k,_){let g=u[k].i,b=u[_].i;return g!==b?g-b:k<_?-1:1}),function(k,_){return m(function(g){return g.replace(Wq,`
`).replace(Lq,"").replace(tC,"    ")}(k),_)}}(l),d=(f=function(u){return function(y,m,k){return u[y.type].h(y,m,k)}}(l),function u(y,m={}){if(Array.isArray(y)){const k=m.k,_=[];let g=!1;for(let b=0;b<y.length;b++){m.k=b;const w=u(y[b],m),I=typeof w=="string";I&&g?_[_.length-1]+=w:w!==null&&_.push(w),g=I}return m.k=k,_}return f(y,u,m)});var f;const h=a(e);return r.length?i("div",null,h,i("footer",{key:"footer"},r.map(function(u){return i("div",{id:t.slugify(u.j),key:u.j},u.j,d(c(u.I,{_:!0})))}))):h}(function(e){e[e.MAX=0]="MAX",e[e.HIGH=1]="HIGH",e[e.MED=2]="MED",e[e.LOW=3]="LOW",e[e.MIN=4]="MIN"})(J||(J={}));const wd=e=>{let{children:t,options:n}=e,i=function(a,o){if(a==null)return{};var r,s,l={},c=Object.keys(a);for(s=0;s<c.length;s++)o.indexOf(r=c[s])>=0||(l[r]=a[r]);return l}(e,Dq);return v.cloneElement(SC(t,n),i)};function AC(e){return pe("MuiAlert",e)}const EC=oe("MuiAlert",["root","action","icon","message","filled","filledSuccess","filledInfo","filledWarning","filledError","outlined","outlinedSuccess","outlinedInfo","outlinedWarning","outlinedError","standard","standardSuccess","standardInfo","standardWarning","standardError"]),If=EC;function NC(e){return pe("MuiIconButton",e)}const BC=oe("MuiIconButton",["root","disabled","colorInherit","colorPrimary","colorSecondary","colorError","colorInfo","colorSuccess","colorWarning","edgeStart","edgeEnd","sizeSmall","sizeMedium","sizeLarge"]),RC=BC,OC=["edge","children","className","color","disabled","disableFocusRipple","size"],zC=e=>{const{classes:t,disabled:n,color:i,edge:a,size:o}=e,r={root:["root",n&&"disabled",i!=="default"&&`color${Z(i)}`,a&&`edge${Z(a)}`,`size${Z(o)}`]};return me(r,NC,t)},WC=F(Xg,{name:"MuiIconButton",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,n.color!=="default"&&t[`color${Z(n.color)}`],n.edge&&t[`edge${Z(n.edge)}`],t[`size${Z(n.size)}`]]}})(({theme:e,ownerState:t})=>T({textAlign:"center",flex:"0 0 auto",fontSize:e.typography.pxToRem(24),padding:8,borderRadius:"50%",overflow:"visible",color:(e.vars||e).palette.action.active,transition:e.transitions.create("background-color",{duration:e.transitions.duration.shortest})},!t.disableRipple&&{"&:hover":{backgroundColor:e.vars?`rgba(${e.vars.palette.action.activeChannel} / ${e.vars.palette.action.hoverOpacity})`:yn(e.palette.action.active,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"}}},t.edge==="start"&&{marginLeft:t.size==="small"?-3:-12},t.edge==="end"&&{marginRight:t.size==="small"?-3:-12}),({theme:e,ownerState:t})=>{var n;const i=(n=(e.vars||e).palette)==null?void 0:n[t.color];return T({},t.color==="inherit"&&{color:"inherit"},t.color!=="inherit"&&t.color!=="default"&&T({color:i==null?void 0:i.main},!t.disableRipple&&{"&:hover":T({},i&&{backgroundColor:e.vars?`rgba(${i.mainChannel} / ${e.vars.palette.action.hoverOpacity})`:yn(i.main,e.palette.action.hoverOpacity)},{"@media (hover: none)":{backgroundColor:"transparent"}})}),t.size==="small"&&{padding:5,fontSize:e.typography.pxToRem(18)},t.size==="large"&&{padding:12,fontSize:e.typography.pxToRem(28)},{[`&.${RC.disabled}`]:{backgroundColor:"transparent",color:(e.vars||e).palette.action.disabled}})}),jC=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiIconButton"}),{edge:a=!1,children:o,className:r,color:s="default",disabled:l=!1,disableFocusRipple:c=!1,size:d="medium"}=i,f=U(i,OC),h=T({},i,{edge:a,color:s,disabled:l,disableFocusRipple:c,size:d}),u=zC(h);return p.jsx(WC,T({className:V(u.root,r),centerRipple:!0,focusRipple:!c,disabled:l,ref:n,ownerState:h},f,{children:o}))}),MC=jC,LC=Ci(p.jsx("path",{d:"M20,12A8,8 0 0,1 12,20A8,8 0 0,1 4,12A8,8 0 0,1 12,4C12.76,4 13.5,4.11 14.2, 4.31L15.77,2.74C14.61,2.26 13.34,2 12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0, 0 22,12M7.91,10.08L6.5,11.5L11,16L21,6L19.59,4.58L11,13.17L7.91,10.08Z"}),"SuccessOutlined"),FC=Ci(p.jsx("path",{d:"M12 5.99L19.53 19H4.47L12 5.99M12 2L1 21h22L12 2zm1 14h-2v2h2v-2zm0-6h-2v4h2v-4z"}),"ReportProblemOutlined"),UC=Ci(p.jsx("path",{d:"M11 15h2v2h-2zm0-8h2v6h-2zm.99-5C6.47 2 2 6.48 2 12s4.47 10 9.99 10C17.52 22 22 17.52 22 12S17.52 2 11.99 2zM12 20c-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8-3.58 8-8 8z"}),"ErrorOutline"),GC=Ci(p.jsx("path",{d:"M11,9H13V7H11M12,20C7.59,20 4,16.41 4,12C4,7.59 7.59,4 12,4C16.41,4 20,7.59 20, 12C20,16.41 16.41,20 12,20M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12A10, 10 0 0,0 12,2M11,17H13V11H11V17Z"}),"InfoOutlined"),$C=Ci(p.jsx("path",{d:"M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"}),"Close"),VC=["action","children","className","closeText","color","components","componentsProps","icon","iconMapping","onClose","role","severity","slotProps","slots","variant"],HC=e=>{const{variant:t,color:n,severity:i,classes:a}=e,o={root:["root",`${t}${Z(n||i)}`,`${t}`],icon:["icon"],message:["message"],action:["action"]};return me(o,AC,a)},ZC=F(Mo,{name:"MuiAlert",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.root,t[n.variant],t[`${n.variant}${Z(n.color||n.severity)}`]]}})(({theme:e,ownerState:t})=>{const n=e.palette.mode==="light"?rd:sd,i=e.palette.mode==="light"?sd:rd,a=t.color||t.severity;return T({},e.typography.body2,{backgroundColor:"transparent",display:"flex",padding:"6px 16px"},a&&t.variant==="standard"&&{color:e.vars?e.vars.palette.Alert[`${a}Color`]:n(e.palette[a].light,.6),backgroundColor:e.vars?e.vars.palette.Alert[`${a}StandardBg`]:i(e.palette[a].light,.9),[`& .${If.icon}`]:e.vars?{color:e.vars.palette.Alert[`${a}IconColor`]}:{color:e.palette[a].main}},a&&t.variant==="outlined"&&{color:e.vars?e.vars.palette.Alert[`${a}Color`]:n(e.palette[a].light,.6),border:`1px solid ${(e.vars||e).palette[a].light}`,[`& .${If.icon}`]:e.vars?{color:e.vars.palette.Alert[`${a}IconColor`]}:{color:e.palette[a].main}},a&&t.variant==="filled"&&T({fontWeight:e.typography.fontWeightMedium},e.vars?{color:e.vars.palette.Alert[`${a}FilledColor`],backgroundColor:e.vars.palette.Alert[`${a}FilledBg`]}:{backgroundColor:e.palette.mode==="dark"?e.palette[a].dark:e.palette[a].main,color:e.palette.getContrastText(e.palette[a].main)}))}),QC=F("div",{name:"MuiAlert",slot:"Icon",overridesResolver:(e,t)=>t.icon})({marginRight:12,padding:"7px 0",display:"flex",fontSize:22,opacity:.9}),KC=F("div",{name:"MuiAlert",slot:"Message",overridesResolver:(e,t)=>t.message})({padding:"8px 0",minWidth:0,overflow:"auto"}),qf=F("div",{name:"MuiAlert",slot:"Action",overridesResolver:(e,t)=>t.action})({display:"flex",alignItems:"flex-start",padding:"4px 0 0 16px",marginLeft:"auto",marginRight:-8}),Cf={success:p.jsx(LC,{fontSize:"inherit"}),warning:p.jsx(FC,{fontSize:"inherit"}),error:p.jsx(UC,{fontSize:"inherit"}),info:p.jsx(GC,{fontSize:"inherit"})},XC=v.forwardRef(function(t,n){var i,a,o,r,s,l;const c=fe({props:t,name:"MuiAlert"}),{action:d,children:f,className:h,closeText:u="Close",color:y,components:m={},componentsProps:k={},icon:_,iconMapping:g=Cf,onClose:b,role:w="alert",severity:I="success",slotProps:q={},slots:x={},variant:C="standard"}=c,S=U(c,VC),P=T({},c,{color:y,severity:I,variant:C}),B=HC(P),O=(i=(a=x.closeButton)!=null?a:m.CloseButton)!=null?i:MC,M=(o=(r=x.closeIcon)!=null?r:m.CloseIcon)!=null?o:$C,E=(s=q.closeButton)!=null?s:k.closeButton,R=(l=q.closeIcon)!=null?l:k.closeIcon;return p.jsxs(ZC,T({role:w,elevation:0,ownerState:P,className:V(B.root,h),ref:n},S,{children:[_!==!1?p.jsx(QC,{ownerState:P,className:B.icon,children:_||g[I]||Cf[I]}):null,p.jsx(KC,{ownerState:P,className:B.message,children:f}),d!=null?p.jsx(qf,{ownerState:P,className:B.action,children:d}):null,d==null&&b?p.jsx(qf,{ownerState:P,className:B.action,children:p.jsx(O,T({size:"small","aria-label":u,title:u,color:"inherit",onClick:b},E,{children:p.jsx(M,T({fontSize:"small"},R))}))}):null]}))}),nc=XC,Df=sn.entrypointtypes,YC=sn.plugins,Pf=sn.status_dict,JC="/aiida-registry/pr-preview/pr-280/";function e4({pluginKey:e}){const t=YC[e];return v.useEffect(()=>{window.scrollTo(0,0),document.documentElement.style.scrollBehavior="smooth",(()=>{const i=window.location.hash;if(i){let a=window.location.href;window.location.href=a+" ",window.location.href=a;const o=document.getElementById(i);o&&o.scrollIntoView()}})()},[]),p.jsx(p.Fragment,{children:p.jsxs("div",{id:"details",className:"fade-enter",children:[p.jsxs("h1",{className:"plugin-header",children:['AiiDA plugin package "',p.jsx("a",{href:t.code_home,children:t.name}),'"']}),p.jsx(Ti,{to:"/",children:p.jsx("p",{style:{display:"inline"},children:"< back to the registry index"})}),p.jsx("h2",{id:"general.information",children:"General information"}),p.jsxs("div",{children:[p.jsxs("p",{children:[p.jsx("strong",{children:"Current state: "}),p.jsx("img",{className:"svg-badge",src:`${JC}${Pf[t.development_status][1]}`,title:Pf[t.development_status][0]})]}),t.metadata.description&&p.jsxs("p",{children:[p.jsx("strong",{children:"Short description"}),": ",t.metadata.description]}),t.pip_url&&p.jsxs("p",{children:[p.jsx("strong",{children:"How to install"}),": ",p.jsx("code",{children:t.pip_install_cmd})]}),p.jsxs("p",{children:[p.jsx("strong",{children:"Source code"}),": ",p.jsx("a",{href:t.code_home,target:"_blank",children:"Go to the source code repository"})]}),t.documentation_url?p.jsxs("p",{children:[p.jsx("strong",{children:"Documentation"}),": ",p.jsx("a",{href:t.documentation_url,target:"_blank",children:"Go to plugin documentation"})]}):p.jsxs("p",{children:[p.jsx("strong",{children:"Documentation"}),": No documentation provided by the package author"]})]}),p.jsx("h3",{children:"Registry checks"}),t.warnings||t.errors?p.jsxs(p.Fragment,{children:[t.warnings&&p.jsx(p.Fragment,{children:t.warnings.map(n=>p.jsx(nc,{severity:"warning",children:n}))}),t.errors&&p.jsx(p.Fragment,{children:t.errors.map(n=>p.jsx(nc,{severity:"error",children:p.jsx("pre",{children:n})}))})]}):p.jsx(nc,{severity:"success",children:"All checks passed!"}),p.jsx("h2",{id:"detailed.information",children:"Detailed information"}),Object.keys(t.metadata).length!==0?p.jsxs(p.Fragment,{children:[p.jsxs("p",{children:[p.jsx("strong",{children:"Author(s)"}),": ",t.metadata.author]}),t.metadata.author_email&&p.jsxs("p",{children:[p.jsx("strong",{children:"Contact"}),":"," ",p.jsx("a",{href:`mailto:${t.metadata.author_email}`,children:t.metadata.author_email})]}),p.jsxs("p",{children:[p.jsx("strong",{children:"How to use from python"}),":"," ",p.jsxs("code",{children:["import ",t.package_name]})]}),p.jsxs("p",{children:[p.jsx("strong",{children:"Most recent version"}),": ",t.metadata.version]}),t.aiida_version&&p.jsxs("p",{children:[p.jsx("strong",{children:"Compatibility: "}),p.jsx("img",{className:"svg-badge",src:`https://img.shields.io/badge/AiiDA-${t.aiida_version}-007ec6.svg?logo=${y_}`})]}),t.summaryinfo.length!==0&&p.jsxs(p.Fragment,{children:[p.jsx("h3",{id:"plugins",children:"Plugins provided by the package"}),t.summaryinfo.map(n=>p.jsxs("span",{className:"badge",children:[p.jsx("span",{className:`badge-left ${n.colorclass}`,children:n.text}),p.jsx("span",{className:"badge-right",children:n.count})]},n.text))]}),t.entry_points?Object.entries(t.entry_points).map(([n,i])=>p.jsx(p.Fragment,{children:p.jsxs("div",{children:[p.jsx("h2",{style:{color:"black"},id:n,children:n in Df?p.jsxs(p.Fragment,{children:[Df[n]," ",p.jsxs("span",{className:"entrypointraw",children:["(",n,")"]})]}):n}),p.jsx("ul",{children:Object.entries(i).map(([a,o])=>p.jsxs("li",{children:[p.jsx("h2",{style:{color:"black"},id:`${n}.${a}`,children:a}),typeof o=="string"?p.jsxs("div",{className:"classbox",children:["class",p.jsxs("span",{className:"tooltiptext",children:[" ",o]})]}):p.jsx(t4,{entryPoints:o})]},a))})]},n)})):p.jsx("p",{children:"No entry points defined for this plugin."})]}):p.jsx("div",{id:"description",children:p.jsxs("p",{children:["Detailed information for this package could not be obtained. Ask the plugin author to add a ",p.jsx("code",{children:"setup.json"})," file to the plugin source code."]})})]})})}const t4=({entryPoints:e})=>p.jsxs("div",{style:{overflow:"auto"},children:[p.jsx("table",{children:p.jsx("tbody",{children:p.jsxs("tr",{children:[p.jsx("th",{children:"Class"}),p.jsx("td",{children:p.jsx("code",{children:e.class})})]})})}),p.jsxs("table",{children:[p.jsx("tr",{children:p.jsx("th",{children:"Description"})}),e.description.map(t=>p.jsx("tr",{className:"ep_description",children:p.jsx(wd,{children:t.trim()})}))]}),p.jsxs("table",{children:[p.jsxs("tr",{children:[p.jsx("th",{children:"Inputs"}),p.jsx("th",{children:"Required"}),p.jsx("th",{children:"Valid Types"}),p.jsx("th",{children:"Description"})]}),p.jsx(Sf,{spec:e.spec.inputs}),p.jsxs("tr",{children:[p.jsx("th",{children:"Outputs"}),p.jsx("th",{children:"Required"}),p.jsx("th",{children:"Valid Types"}),p.jsx("th",{children:"Description"})]}),p.jsx(Sf,{spec:e.spec.outputs})]}),p.jsxs("table",{children:[p.jsx("tr",{children:p.jsx("th",{children:"Exit Codes"})}),p.jsxs("tr",{children:[p.jsx("th",{children:"Status"}),p.jsx("th",{children:"Message"})]}),e.spec.exit_codes.map(t=>p.jsxs("tr",{className:"ep_description",children:[p.jsx("td",{children:t.status}),p.jsx(wd,{children:t.message})]}))]})]}),Sf=({spec:e})=>p.jsx(p.Fragment,{children:e.map(t=>p.jsxs("tr",{className:"ep_description",children:[p.jsx("td",{children:t.name}),p.jsx("td",{children:t.required.toString()}),p.jsx("td",{children:t.valid_types}),p.jsx(wd,{children:t.info})]}))});const n4=["addEndListener","appear","children","container","direction","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"];function i4(e,t,n){const i=t.getBoundingClientRect(),a=n&&n.getBoundingClientRect(),o=rn(t);let r;if(t.fakeTransform)r=t.fakeTransform;else{const c=o.getComputedStyle(t);r=c.getPropertyValue("-webkit-transform")||c.getPropertyValue("transform")}let s=0,l=0;if(r&&r!=="none"&&typeof r=="string"){const c=r.split("(")[1].split(")")[0].split(",");s=parseInt(c[4],10),l=parseInt(c[5],10)}return e==="left"?a?`translateX(${a.right+s-i.left}px)`:`translateX(${o.innerWidth+s-i.left}px)`:e==="right"?a?`translateX(-${i.right-a.left-s}px)`:`translateX(-${i.left+i.width-s}px)`:e==="up"?a?`translateY(${a.bottom+l-i.top}px)`:`translateY(${o.innerHeight+l-i.top}px)`:a?`translateY(-${i.top-a.top+i.height-l}px)`:`translateY(-${i.top+i.height-l}px)`}function a4(e){return typeof e=="function"?e():e}function lr(e,t,n){const i=a4(n),a=i4(e,t,i);a&&(t.style.webkitTransform=a,t.style.transform=a)}const o4=v.forwardRef(function(t,n){const i=xa(),a={enter:i.transitions.easing.easeOut,exit:i.transitions.easing.sharp},o={enter:i.transitions.duration.enteringScreen,exit:i.transitions.duration.leavingScreen},{addEndListener:r,appear:s=!0,children:l,container:c,direction:d="down",easing:f=a,in:h,onEnter:u,onEntered:y,onEntering:m,onExit:k,onExited:_,onExiting:g,style:b,timeout:w=o,TransitionComponent:I=Uu}=t,q=U(t,n4),x=v.useRef(null),C=Ke(l.ref,x,n),S=D=>N=>{D&&(N===void 0?D(x.current):D(x.current,N))},P=S((D,N)=>{lr(d,D,c),Vu(D),u&&u(D,N)}),B=S((D,N)=>{const W=ma({timeout:w,style:b,easing:f},{mode:"enter"});D.style.webkitTransition=i.transitions.create("-webkit-transform",T({},W)),D.style.transition=i.transitions.create("transform",T({},W)),D.style.webkitTransform="none",D.style.transform="none",m&&m(D,N)}),O=S(y),M=S(g),E=S(D=>{const N=ma({timeout:w,style:b,easing:f},{mode:"exit"});D.style.webkitTransition=i.transitions.create("-webkit-transform",N),D.style.transition=i.transitions.create("transform",N),lr(d,D,c),k&&k(D)}),R=S(D=>{D.style.webkitTransition="",D.style.transition="",_&&_(D)}),z=D=>{r&&r(x.current,D)},L=v.useCallback(()=>{x.current&&lr(d,x.current,c)},[d,c]);return v.useEffect(()=>{if(h||d==="down"||d==="right")return;const D=Os(()=>{x.current&&lr(d,x.current,c)}),N=rn(x.current);return N.addEventListener("resize",D),()=>{D.clear(),N.removeEventListener("resize",D)}},[d,h,c]),v.useEffect(()=>{h||L()},[h,L]),p.jsx(I,T({nodeRef:x,onEnter:P,onEntered:O,onEntering:B,onExit:E,onExited:R,onExiting:M,addEndListener:z,appear:s,in:h,timeout:w},q,{children:(D,N)=>v.cloneElement(l,T({ref:C,style:T({visibility:D==="exited"&&!h?"hidden":void 0},b,l.props.style)},N))}))}),r4=o4;function s4(e){return pe("MuiDrawer",e)}oe("MuiDrawer",["root","docked","paper","paperAnchorLeft","paperAnchorRight","paperAnchorTop","paperAnchorBottom","paperAnchorDockedLeft","paperAnchorDockedRight","paperAnchorDockedTop","paperAnchorDockedBottom","modal"]);const l4=["BackdropProps"],c4=["anchor","BackdropProps","children","className","elevation","hideBackdrop","ModalProps","onClose","open","PaperProps","SlideProps","TransitionComponent","transitionDuration","variant"],O_=(e,t)=>{const{ownerState:n}=e;return[t.root,(n.variant==="permanent"||n.variant==="persistent")&&t.docked,t.modal]},d4=e=>{const{classes:t,anchor:n,variant:i}=e,a={root:["root"],docked:[(i==="permanent"||i==="persistent")&&"docked"],modal:["modal"],paper:["paper",`paperAnchor${Z(n)}`,i!=="temporary"&&`paperAnchorDocked${Z(n)}`]};return me(a,s4,t)},u4=F(Hu,{name:"MuiDrawer",slot:"Root",overridesResolver:O_})(({theme:e})=>({zIndex:(e.vars||e).zIndex.drawer})),Af=F("div",{shouldForwardProp:Ht,name:"MuiDrawer",slot:"Docked",skipVariantsResolver:!1,overridesResolver:O_})({flex:"0 0 auto"}),p4=F(Mo,{name:"MuiDrawer",slot:"Paper",overridesResolver:(e,t)=>{const{ownerState:n}=e;return[t.paper,t[`paperAnchor${Z(n.anchor)}`],n.variant!=="temporary"&&t[`paperAnchorDocked${Z(n.anchor)}`]]}})(({theme:e,ownerState:t})=>T({overflowY:"auto",display:"flex",flexDirection:"column",height:"100%",flex:"1 0 auto",zIndex:(e.vars||e).zIndex.drawer,WebkitOverflowScrolling:"touch",position:"fixed",top:0,outline:0},t.anchor==="left"&&{left:0},t.anchor==="top"&&{top:0,left:0,right:0,height:"auto",maxHeight:"100%"},t.anchor==="right"&&{right:0},t.anchor==="bottom"&&{top:"auto",left:0,bottom:0,right:0,height:"auto",maxHeight:"100%"},t.anchor==="left"&&t.variant!=="temporary"&&{borderRight:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="top"&&t.variant!=="temporary"&&{borderBottom:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="right"&&t.variant!=="temporary"&&{borderLeft:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="bottom"&&t.variant!=="temporary"&&{borderTop:`1px solid ${(e.vars||e).palette.divider}`})),z_={left:"right",right:"left",top:"down",bottom:"up"};function m4(e){return["left","right"].indexOf(e)!==-1}function f4(e,t){return e.direction==="rtl"&&m4(t)?z_[t]:t}const h4=v.forwardRef(function(t,n){const i=fe({props:t,name:"MuiDrawer"}),a=xa(),o={enter:a.transitions.duration.enteringScreen,exit:a.transitions.duration.leavingScreen},{anchor:r="left",BackdropProps:s,children:l,className:c,elevation:d=16,hideBackdrop:f=!1,ModalProps:{BackdropProps:h}={},onClose:u,open:y=!1,PaperProps:m={},SlideProps:k,TransitionComponent:_=r4,transitionDuration:g=o,variant:b="temporary"}=i,w=U(i.ModalProps,l4),I=U(i,c4),q=v.useRef(!1);v.useEffect(()=>{q.current=!0},[]);const x=f4(a,r),S=T({},i,{anchor:r,elevation:d,open:y,variant:b},I),P=d4(S),B=p.jsx(p4,T({elevation:b==="temporary"?d:0,square:!0},m,{className:V(P.paper,m.className),ownerState:S,children:l}));if(b==="permanent")return p.jsx(Af,T({className:V(P.root,P.docked,c),ownerState:S,ref:n},I,{children:B}));const O=p.jsx(_,T({in:y,direction:z_[x],timeout:g,appear:q.current},k,{children:B}));return b==="persistent"?p.jsx(Af,T({className:V(P.root,P.docked,c),ownerState:S,ref:n},I,{children:O})):p.jsx(u4,T({BackdropProps:T({},s,h,{transitionDuration:g}),className:V(P.root,P.modal,c),open:y,ownerState:S,onClose:u,hideBackdrop:f,ref:n},I,w,{children:O}))}),y4=h4,g4=sn.plugins;function _4({pluginKey:e}){const t=g4[e];function n(){function a(){document.querySelector("header").style.top="-155px",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="0"}setTimeout(a,800)}const i=p.jsxs("div",{style:{paddingLeft:"10px"},children:[p.jsx("h1",{children:"Plugin content"}),p.jsx(ef,{}),p.jsx("p",{children:p.jsx("a",{style:{color:"black"},href:"#general.information",onClick:n,children:"General Information"})}),p.jsx("p",{children:p.jsx("a",{style:{color:"black"},href:"#detailed.information",onClick:n,children:"Detailed Information"})}),p.jsx("p",{children:p.jsx("a",{style:{color:"black"},href:"#plugins",onClick:n,children:"Plugins provided by the package"})}),t.entry_points&&Object.entries(t.entry_points).map(([a,o])=>p.jsx(p.Fragment,{children:p.jsx("ul",{children:p.jsxs("li",{children:[p.jsx("a",{style:{color:"black"},href:`#${a}`,onClick:n,children:a}),Object.entries(o).map(([r,s])=>p.jsx("ul",{children:p.jsx("li",{children:p.jsx("a",{style:{color:"black"},href:`#${a}.${r}`,onClick:n,children:r})})},r))]})})})),p.jsx(ef,{})]});return p.jsx(y4,{variant:"permanent",id:"sidebar",anchor:"right",sx:{display:{xs:"none",sm:"block"}},open:!0,children:i})}function b4(){return p.jsxs(p.Fragment,{children:[p.jsx(v4,{}),p.jsx("div",{style:{marginTop:"155px"},children:p.jsx(zI,{children:p.jsx(z3,{children:p.jsxs(J1,{children:[p.jsx(Xc,{path:"/",element:p.jsx(Cq,{})}),p.jsx(Xc,{path:"/:key",element:p.jsx(x4,{})})]})})})}),p.jsx(w4,{})]})}function v4(){return p.jsx("header",{children:p.jsxs("div",{style:{paddingLeft:"20px"},children:[p.jsx("h1",{children:p.jsx("a",{href:"http://aiidateam.github.io/aiida-registry",children:p.jsx("img",{src:cv,height:"70px"})})}),p.jsx("p",{style:{fontSize:"90%"},children:p.jsx("a",{href:"http://github.com/aiidateam/aiida-registry",style:{color:"#999"},children:"[View on GitHub/register your package]"})})]})})}function w4(){return p.jsxs("footer",{className:"footer",children:[p.jsx("hr",{}),"The official ",p.jsx("a",{href:"http://aiidateam.github.io/aiida-registry",children:"registry"})," of ",p.jsx("a",{href:"http://www.aiida.net",children:"AiiDA"})," plugins.",p.jsx("br",{}),"This work is supported by the ",p.jsx("a",{href:"http://nccr-marvel.ch",target:"_blank",children:"MARVEL National Centre for Competence in Research"})," funded by the ",p.jsx("a",{href:"http://www.snf.ch/en",target:"_blank",children:"Swiss National Science Foundation"}),", as well as by the ",p.jsx("a",{href:"http://www.max-centre.eu",target:"_blank",children:"MaX European Centre of Excellence"})," funded by the Horizon 2020 EINFRA-5 program, Grant No. 676598.",p.jsx("br",{}),p.jsx("br",{}),p.jsxs("div",{style:{textAlign:"center"},children:[p.jsx("img",{src:dv,height:"70px"}),"    ",p.jsx("img",{src:uv,height:"70px"})]})]})}function x4(){const{key:e}=j1();v.useEffect(()=>(document.querySelector("footer").style.width="calc(100% - 380px)",()=>{document.querySelector("footer").style.width="calc(100% - 64px)"}),[]);function t(){var n=window.scrollY;window.onscroll=function(){var i=window.scrollY;n>i?(document.querySelector("header").style.top="0",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="155px"):n>150&&(document.querySelector("header").style.top="-155px",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="0"),n=i}}return t(),p.jsx(p.Fragment,{children:p.jsxs("div",{id:"detailsContainer",children:[p.jsx(e4,{pluginKey:e}),p.jsx(_4,{pluginKey:e})]})})}const T4="/aiida-registry/pr-preview/pr-280/";ic.createRoot(document.getElementById("root")).render(p.jsx(Ut.StrictMode,{children:p.jsx(ov,{basename:T4,children:p.jsx(b4,{})})}));
