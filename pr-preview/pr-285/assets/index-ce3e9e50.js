function I_(e,t){for(var i=0;i<t.length;i++){const a=t[i];if(typeof a!="string"&&!Array.isArray(a)){for(const n in a)if(n!=="default"&&!(n in e)){const o=Object.getOwnPropertyDescriptor(a,n);o&&Object.defineProperty(e,n,o.get?o:{enumerable:!0,get:()=>a[n]})}}}return Object.freeze(Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}))}(function(){const t=document.createElement("link").relList;if(t&&t.supports&&t.supports("modulepreload"))return;for(const n of document.querySelectorAll('link[rel="modulepreload"]'))a(n);new MutationObserver(n=>{for(const o of n)if(o.type==="childList")for(const s of o.addedNodes)s.tagName==="LINK"&&s.rel==="modulepreload"&&a(s)}).observe(document,{childList:!0,subtree:!0});function i(n){const o={};return n.integrity&&(o.integrity=n.integrity),n.referrerPolicy&&(o.referrerPolicy=n.referrerPolicy),n.crossOrigin==="use-credentials"?o.credentials="include":n.crossOrigin==="anonymous"?o.credentials="omit":o.credentials="same-origin",o}function a(n){if(n.ep)return;n.ep=!0;const o=i(n);fetch(n.href,o)}})();function Ef(e){return e&&e.__esModule&&Object.prototype.hasOwnProperty.call(e,"default")?e.default:e}function N_(e){if(e.__esModule)return e;var t=e.default;if(typeof t=="function"){var i=function a(){return this instanceof a?Reflect.construct(t,arguments,this.constructor):t.apply(this,arguments)};i.prototype=t.prototype}else i={};return Object.defineProperty(i,"__esModule",{value:!0}),Object.keys(e).forEach(function(a){var n=Object.getOwnPropertyDescriptor(e,a);Object.defineProperty(i,a,n.get?n:{enumerable:!0,get:function(){return e[a]}})}),i}var Bf={exports:{}},rr={},Af={exports:{}},Q={};/**
 * @license React
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Do=Symbol.for("react.element"),O_=Symbol.for("react.portal"),L_=Symbol.for("react.fragment"),W_=Symbol.for("react.strict_mode"),$_=Symbol.for("react.profiler"),G_=Symbol.for("react.provider"),U_=Symbol.for("react.context"),K_=Symbol.for("react.forward_ref"),H_=Symbol.for("react.suspense"),V_=Symbol.for("react.memo"),X_=Symbol.for("react.lazy"),tu=Symbol.iterator;function Y_(e){return e===null||typeof e!="object"?null:(e=tu&&e[tu]||e["@@iterator"],typeof e=="function"?e:null)}var jf={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},Mf=Object.assign,zf={};function hn(e,t,i){this.props=e,this.context=t,this.refs=zf,this.updater=i||jf}hn.prototype.isReactComponent={};hn.prototype.setState=function(e,t){if(typeof e!="object"&&typeof e!="function"&&e!=null)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")};hn.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")};function If(){}If.prototype=hn.prototype;function wp(e,t,i){this.props=e,this.context=t,this.refs=zf,this.updater=i||jf}var qp=wp.prototype=new If;qp.constructor=wp;Mf(qp,hn.prototype);qp.isPureReactComponent=!0;var iu=Array.isArray,Nf=Object.prototype.hasOwnProperty,xp={current:null},Of={key:!0,ref:!0,__self:!0,__source:!0};function Lf(e,t,i){var a,n={},o=null,s=null;if(t!=null)for(a in t.ref!==void 0&&(s=t.ref),t.key!==void 0&&(o=""+t.key),t)Nf.call(t,a)&&!Of.hasOwnProperty(a)&&(n[a]=t[a]);var r=arguments.length-2;if(r===1)n.children=i;else if(1<r){for(var l=Array(r),d=0;d<r;d++)l[d]=arguments[d+2];n.children=l}if(e&&e.defaultProps)for(a in r=e.defaultProps,r)n[a]===void 0&&(n[a]=r[a]);return{$$typeof:Do,type:e,key:o,ref:s,props:n,_owner:xp.current}}function Q_(e,t){return{$$typeof:Do,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}function Fp(e){return typeof e=="object"&&e!==null&&e.$$typeof===Do}function J_(e){var t={"=":"=0",":":"=2"};return"$"+e.replace(/[=:]/g,function(i){return t[i]})}var au=/\/+/g;function ml(e,t){return typeof e=="object"&&e!==null&&e.key!=null?J_(""+e.key):t.toString(36)}function ds(e,t,i,a,n){var o=typeof e;(o==="undefined"||o==="boolean")&&(e=null);var s=!1;if(e===null)s=!0;else switch(o){case"string":case"number":s=!0;break;case"object":switch(e.$$typeof){case Do:case O_:s=!0}}if(s)return s=e,n=n(s),e=a===""?"."+ml(s,0):a,iu(n)?(i="",e!=null&&(i=e.replace(au,"$&/")+"/"),ds(n,t,i,"",function(d){return d})):n!=null&&(Fp(n)&&(n=Q_(n,i+(!n.key||s&&s.key===n.key?"":(""+n.key).replace(au,"$&/")+"/")+e)),t.push(n)),1;if(s=0,a=a===""?".":a+":",iu(e))for(var r=0;r<e.length;r++){o=e[r];var l=a+ml(o,r);s+=ds(o,t,i,l,n)}else if(l=Y_(e),typeof l=="function")for(e=l.call(e),r=0;!(o=e.next()).done;)o=o.value,l=a+ml(o,r++),s+=ds(o,t,i,l,n);else if(o==="object")throw t=String(e),Error("Objects are not valid as a React child (found: "+(t==="[object Object]"?"object with keys {"+Object.keys(e).join(", ")+"}":t)+"). If you meant to render a collection of children, use an array instead.");return s}function Lo(e,t,i){if(e==null)return e;var a=[],n=0;return ds(e,a,"","",function(o){return t.call(i,o,n++)}),a}function Z_(e){if(e._status===-1){var t=e._result;t=t(),t.then(function(i){(e._status===0||e._status===-1)&&(e._status=1,e._result=i)},function(i){(e._status===0||e._status===-1)&&(e._status=2,e._result=i)}),e._status===-1&&(e._status=0,e._result=t)}if(e._status===1)return e._result.default;throw e._result}var nt={current:null},ps={transition:null},eb={ReactCurrentDispatcher:nt,ReactCurrentBatchConfig:ps,ReactCurrentOwner:xp};Q.Children={map:Lo,forEach:function(e,t,i){Lo(e,function(){t.apply(this,arguments)},i)},count:function(e){var t=0;return Lo(e,function(){t++}),t},toArray:function(e){return Lo(e,function(t){return t})||[]},only:function(e){if(!Fp(e))throw Error("React.Children.only expected to receive a single React element child.");return e}};Q.Component=hn;Q.Fragment=L_;Q.Profiler=$_;Q.PureComponent=wp;Q.StrictMode=W_;Q.Suspense=H_;Q.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=eb;Q.cloneElement=function(e,t,i){if(e==null)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+e+".");var a=Mf({},e.props),n=e.key,o=e.ref,s=e._owner;if(t!=null){if(t.ref!==void 0&&(o=t.ref,s=xp.current),t.key!==void 0&&(n=""+t.key),e.type&&e.type.defaultProps)var r=e.type.defaultProps;for(l in t)Nf.call(t,l)&&!Of.hasOwnProperty(l)&&(a[l]=t[l]===void 0&&r!==void 0?r[l]:t[l])}var l=arguments.length-2;if(l===1)a.children=i;else if(1<l){r=Array(l);for(var d=0;d<l;d++)r[d]=arguments[d+2];a.children=r}return{$$typeof:Do,type:e.type,key:n,ref:o,props:a,_owner:s}};Q.createContext=function(e){return e={$$typeof:U_,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null},e.Provider={$$typeof:G_,_context:e},e.Consumer=e};Q.createElement=Lf;Q.createFactory=function(e){var t=Lf.bind(null,e);return t.type=e,t};Q.createRef=function(){return{current:null}};Q.forwardRef=function(e){return{$$typeof:K_,render:e}};Q.isValidElement=Fp;Q.lazy=function(e){return{$$typeof:X_,_payload:{_status:-1,_result:e},_init:Z_}};Q.memo=function(e,t){return{$$typeof:V_,type:e,compare:t===void 0?null:t}};Q.startTransition=function(e){var t=ps.transition;ps.transition={};try{e()}finally{ps.transition=t}};Q.unstable_act=function(){throw Error("act(...) is not supported in production builds of React.")};Q.useCallback=function(e,t){return nt.current.useCallback(e,t)};Q.useContext=function(e){return nt.current.useContext(e)};Q.useDebugValue=function(){};Q.useDeferredValue=function(e){return nt.current.useDeferredValue(e)};Q.useEffect=function(e,t){return nt.current.useEffect(e,t)};Q.useId=function(){return nt.current.useId()};Q.useImperativeHandle=function(e,t,i){return nt.current.useImperativeHandle(e,t,i)};Q.useInsertionEffect=function(e,t){return nt.current.useInsertionEffect(e,t)};Q.useLayoutEffect=function(e,t){return nt.current.useLayoutEffect(e,t)};Q.useMemo=function(e,t){return nt.current.useMemo(e,t)};Q.useReducer=function(e,t,i){return nt.current.useReducer(e,t,i)};Q.useRef=function(e){return nt.current.useRef(e)};Q.useState=function(e){return nt.current.useState(e)};Q.useSyncExternalStore=function(e,t,i){return nt.current.useSyncExternalStore(e,t,i)};Q.useTransition=function(){return nt.current.useTransition()};Q.version="18.2.0";Af.exports=Q;var k=Af.exports;const $t=Ef(k),Ts=I_({__proto__:null,default:$t},[k]);/**
 * @license React
 * react-jsx-runtime.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var tb=k,ib=Symbol.for("react.element"),ab=Symbol.for("react.fragment"),nb=Object.prototype.hasOwnProperty,ob=tb.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,sb={key:!0,ref:!0,__self:!0,__source:!0};function Wf(e,t,i){var a,n={},o=null,s=null;i!==void 0&&(o=""+i),t.key!==void 0&&(o=""+t.key),t.ref!==void 0&&(s=t.ref);for(a in t)nb.call(t,a)&&!sb.hasOwnProperty(a)&&(n[a]=t[a]);if(e&&e.defaultProps)for(a in t=e.defaultProps,t)n[a]===void 0&&(n[a]=t[a]);return{$$typeof:ib,type:e,key:o,ref:s,props:n,_owner:ob.current}}rr.Fragment=ab;rr.jsx=Wf;rr.jsxs=Wf;Bf.exports=rr;var u=Bf.exports,ad={},$f={exports:{}},wt={},Gf={exports:{}},Uf={};/**
 * @license React
 * scheduler.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */(function(e){function t(C,B){var I=C.length;C.push(B);e:for(;0<I;){var ee=I-1>>>1,X=C[ee];if(0<n(X,B))C[ee]=B,C[I]=X,I=ee;else break e}}function i(C){return C.length===0?null:C[0]}function a(C){if(C.length===0)return null;var B=C[0],I=C.pop();if(I!==B){C[0]=I;e:for(var ee=0,X=C.length,Be=X>>>1;ee<Be;){var J=2*(ee+1)-1,ke=C[J],re=J+1,Ge=C[re];if(0>n(ke,I))re<X&&0>n(Ge,ke)?(C[ee]=Ge,C[re]=I,ee=re):(C[ee]=ke,C[J]=I,ee=J);else if(re<X&&0>n(Ge,I))C[ee]=Ge,C[re]=I,ee=re;else break e}}return B}function n(C,B){var I=C.sortIndex-B.sortIndex;return I!==0?I:C.id-B.id}if(typeof performance=="object"&&typeof performance.now=="function"){var o=performance;e.unstable_now=function(){return o.now()}}else{var s=Date,r=s.now();e.unstable_now=function(){return s.now()-r}}var l=[],d=[],p=1,f=null,h=3,c=!1,g=!1,m=!1,x=typeof setTimeout=="function"?setTimeout:null,_=typeof clearTimeout=="function"?clearTimeout:null,y=typeof setImmediate<"u"?setImmediate:null;typeof navigator<"u"&&navigator.scheduling!==void 0&&navigator.scheduling.isInputPending!==void 0&&navigator.scheduling.isInputPending.bind(navigator.scheduling);function b(C){for(var B=i(d);B!==null;){if(B.callback===null)a(d);else if(B.startTime<=C)a(d),B.sortIndex=B.expirationTime,t(l,B);else break;B=i(d)}}function v(C){if(m=!1,b(C),!g)if(i(l)!==null)g=!0,z(F);else{var B=i(d);B!==null&&L(v,B.startTime-C)}}function F(C,B){g=!1,m&&(m=!1,_(D),D=-1),c=!0;var I=h;try{for(b(B),f=i(l);f!==null&&(!(f.expirationTime>B)||C&&!A());){var ee=f.callback;if(typeof ee=="function"){f.callback=null,h=f.priorityLevel;var X=ee(f.expirationTime<=B);B=e.unstable_now(),typeof X=="function"?f.callback=X:f===i(l)&&a(l),b(B)}else a(l);f=i(l)}if(f!==null)var Be=!0;else{var J=i(d);J!==null&&L(v,J.startTime-B),Be=!1}return Be}finally{f=null,h=I,c=!1}}var T=!1,w=null,D=-1,P=5,R=-1;function A(){return!(e.unstable_now()-R<P)}function M(){if(w!==null){var C=e.unstable_now();R=C;var B=!0;try{B=w(!0,C)}finally{B?O():(T=!1,w=null)}}else T=!1}var O;if(typeof y=="function")O=function(){y(M)};else if(typeof MessageChannel<"u"){var E=new MessageChannel,j=E.port2;E.port1.onmessage=M,O=function(){j.postMessage(null)}}else O=function(){x(M,0)};function z(C){w=C,T||(T=!0,O())}function L(C,B){D=x(function(){C(e.unstable_now())},B)}e.unstable_IdlePriority=5,e.unstable_ImmediatePriority=1,e.unstable_LowPriority=4,e.unstable_NormalPriority=3,e.unstable_Profiling=null,e.unstable_UserBlockingPriority=2,e.unstable_cancelCallback=function(C){C.callback=null},e.unstable_continueExecution=function(){g||c||(g=!0,z(F))},e.unstable_forceFrameRate=function(C){0>C||125<C?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):P=0<C?Math.floor(1e3/C):5},e.unstable_getCurrentPriorityLevel=function(){return h},e.unstable_getFirstCallbackNode=function(){return i(l)},e.unstable_next=function(C){switch(h){case 1:case 2:case 3:var B=3;break;default:B=h}var I=h;h=B;try{return C()}finally{h=I}},e.unstable_pauseExecution=function(){},e.unstable_requestPaint=function(){},e.unstable_runWithPriority=function(C,B){switch(C){case 1:case 2:case 3:case 4:case 5:break;default:C=3}var I=h;h=C;try{return B()}finally{h=I}},e.unstable_scheduleCallback=function(C,B,I){var ee=e.unstable_now();switch(typeof I=="object"&&I!==null?(I=I.delay,I=typeof I=="number"&&0<I?ee+I:ee):I=ee,C){case 1:var X=-1;break;case 2:X=250;break;case 5:X=1073741823;break;case 4:X=1e4;break;default:X=5e3}return X=I+X,C={id:p++,callback:B,priorityLevel:C,startTime:I,expirationTime:X,sortIndex:-1},I>ee?(C.sortIndex=I,t(d,C),i(l)===null&&C===i(d)&&(m?(_(D),D=-1):m=!0,L(v,I-ee))):(C.sortIndex=X,t(l,C),g||c||(g=!0,z(F))),C},e.unstable_shouldYield=A,e.unstable_wrapCallback=function(C){var B=h;return function(){var I=h;h=B;try{return C.apply(this,arguments)}finally{h=I}}}})(Uf);Gf.exports=Uf;var rb=Gf.exports;/**
 * @license React
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var Kf=k,vt=rb;function S(e){for(var t="https://reactjs.org/docs/error-decoder.html?invariant="+e,i=1;i<arguments.length;i++)t+="&args[]="+encodeURIComponent(arguments[i]);return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}var Hf=new Set,no={};function xa(e,t){nn(e,t),nn(e+"Capture",t)}function nn(e,t){for(no[e]=t,e=0;e<t.length;e++)Hf.add(t[e])}var yi=!(typeof window>"u"||typeof window.document>"u"||typeof window.document.createElement>"u"),nd=Object.prototype.hasOwnProperty,lb=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,nu={},ou={};function db(e){return nd.call(ou,e)?!0:nd.call(nu,e)?!1:lb.test(e)?ou[e]=!0:(nu[e]=!0,!1)}function pb(e,t,i,a){if(i!==null&&i.type===0)return!1;switch(typeof t){case"function":case"symbol":return!0;case"boolean":return a?!1:i!==null?!i.acceptsBooleans:(e=e.toLowerCase().slice(0,5),e!=="data-"&&e!=="aria-");default:return!1}}function cb(e,t,i,a){if(t===null||typeof t>"u"||pb(e,t,i,a))return!0;if(a)return!1;if(i!==null)switch(i.type){case 3:return!t;case 4:return t===!1;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}function ot(e,t,i,a,n,o,s){this.acceptsBooleans=t===2||t===3||t===4,this.attributeName=a,this.attributeNamespace=n,this.mustUseProperty=i,this.propertyName=e,this.type=t,this.sanitizeURL=o,this.removeEmptyString=s}var Xe={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(e){Xe[e]=new ot(e,0,!1,e,null,!1,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(e){var t=e[0];Xe[t]=new ot(t,1,!1,e[1],null,!1,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(e){Xe[e]=new ot(e,2,!1,e.toLowerCase(),null,!1,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(e){Xe[e]=new ot(e,2,!1,e,null,!1,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(e){Xe[e]=new ot(e,3,!1,e.toLowerCase(),null,!1,!1)});["checked","multiple","muted","selected"].forEach(function(e){Xe[e]=new ot(e,3,!0,e,null,!1,!1)});["capture","download"].forEach(function(e){Xe[e]=new ot(e,4,!1,e,null,!1,!1)});["cols","rows","size","span"].forEach(function(e){Xe[e]=new ot(e,6,!1,e,null,!1,!1)});["rowSpan","start"].forEach(function(e){Xe[e]=new ot(e,5,!1,e.toLowerCase(),null,!1,!1)});var Tp=/[\-:]([a-z])/g;function Dp(e){return e[1].toUpperCase()}"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(e){var t=e.replace(Tp,Dp);Xe[t]=new ot(t,1,!1,e,null,!1,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(e){var t=e.replace(Tp,Dp);Xe[t]=new ot(t,1,!1,e,"http://www.w3.org/1999/xlink",!1,!1)});["xml:base","xml:lang","xml:space"].forEach(function(e){var t=e.replace(Tp,Dp);Xe[t]=new ot(t,1,!1,e,"http://www.w3.org/XML/1998/namespace",!1,!1)});["tabIndex","crossOrigin"].forEach(function(e){Xe[e]=new ot(e,1,!1,e.toLowerCase(),null,!1,!1)});Xe.xlinkHref=new ot("xlinkHref",1,!1,"xlink:href","http://www.w3.org/1999/xlink",!0,!1);["src","href","action","formAction"].forEach(function(e){Xe[e]=new ot(e,1,!1,e.toLowerCase(),null,!0,!0)});function Cp(e,t,i,a){var n=Xe.hasOwnProperty(t)?Xe[t]:null;(n!==null?n.type!==0:a||!(2<t.length)||t[0]!=="o"&&t[0]!=="O"||t[1]!=="n"&&t[1]!=="N")&&(cb(t,i,n,a)&&(i=null),a||n===null?db(t)&&(i===null?e.removeAttribute(t):e.setAttribute(t,""+i)):n.mustUseProperty?e[n.propertyName]=i===null?n.type===3?!1:"":i:(t=n.attributeName,a=n.attributeNamespace,i===null?e.removeAttribute(t):(n=n.type,i=n===3||n===4&&i===!0?"":""+i,a?e.setAttributeNS(a,t,i):e.setAttribute(t,i))))}var qi=Kf.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,Wo=Symbol.for("react.element"),za=Symbol.for("react.portal"),Ia=Symbol.for("react.fragment"),Rp=Symbol.for("react.strict_mode"),od=Symbol.for("react.profiler"),Vf=Symbol.for("react.provider"),Xf=Symbol.for("react.context"),Pp=Symbol.for("react.forward_ref"),sd=Symbol.for("react.suspense"),rd=Symbol.for("react.suspense_list"),Sp=Symbol.for("react.memo"),Si=Symbol.for("react.lazy"),Yf=Symbol.for("react.offscreen"),su=Symbol.iterator;function xn(e){return e===null||typeof e!="object"?null:(e=su&&e[su]||e["@@iterator"],typeof e=="function"?e:null)}var Re=Object.assign,fl;function On(e){if(fl===void 0)try{throw Error()}catch(i){var t=i.stack.trim().match(/\n( *(at )?)/);fl=t&&t[1]||""}return`
`+fl+e}var hl=!1;function gl(e,t){if(!e||hl)return"";hl=!0;var i=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,"props",{set:function(){throw Error()}}),typeof Reflect=="object"&&Reflect.construct){try{Reflect.construct(t,[])}catch(d){var a=d}Reflect.construct(e,[],t)}else{try{t.call()}catch(d){a=d}e.call(t.prototype)}else{try{throw Error()}catch(d){a=d}e()}}catch(d){if(d&&a&&typeof d.stack=="string"){for(var n=d.stack.split(`
`),o=a.stack.split(`
`),s=n.length-1,r=o.length-1;1<=s&&0<=r&&n[s]!==o[r];)r--;for(;1<=s&&0<=r;s--,r--)if(n[s]!==o[r]){if(s!==1||r!==1)do if(s--,r--,0>r||n[s]!==o[r]){var l=`
`+n[s].replace(" at new "," at ");return e.displayName&&l.includes("<anonymous>")&&(l=l.replace("<anonymous>",e.displayName)),l}while(1<=s&&0<=r);break}}}finally{hl=!1,Error.prepareStackTrace=i}return(e=e?e.displayName||e.name:"")?On(e):""}function ub(e){switch(e.tag){case 5:return On(e.type);case 16:return On("Lazy");case 13:return On("Suspense");case 19:return On("SuspenseList");case 0:case 2:case 15:return e=gl(e.type,!1),e;case 11:return e=gl(e.type.render,!1),e;case 1:return e=gl(e.type,!0),e;default:return""}}function ld(e){if(e==null)return null;if(typeof e=="function")return e.displayName||e.name||null;if(typeof e=="string")return e;switch(e){case Ia:return"Fragment";case za:return"Portal";case od:return"Profiler";case Rp:return"StrictMode";case sd:return"Suspense";case rd:return"SuspenseList"}if(typeof e=="object")switch(e.$$typeof){case Xf:return(e.displayName||"Context")+".Consumer";case Vf:return(e._context.displayName||"Context")+".Provider";case Pp:var t=e.render;return e=e.displayName,e||(e=t.displayName||t.name||"",e=e!==""?"ForwardRef("+e+")":"ForwardRef"),e;case Sp:return t=e.displayName||null,t!==null?t:ld(e.type)||"Memo";case Si:t=e._payload,e=e._init;try{return ld(e(t))}catch{}}return null}function mb(e){var t=e.type;switch(e.tag){case 24:return"Cache";case 9:return(t.displayName||"Context")+".Consumer";case 10:return(t._context.displayName||"Context")+".Provider";case 18:return"DehydratedFragment";case 11:return e=t.render,e=e.displayName||e.name||"",t.displayName||(e!==""?"ForwardRef("+e+")":"ForwardRef");case 7:return"Fragment";case 5:return t;case 4:return"Portal";case 3:return"Root";case 6:return"Text";case 16:return ld(t);case 8:return t===Rp?"StrictMode":"Mode";case 22:return"Offscreen";case 12:return"Profiler";case 21:return"Scope";case 13:return"Suspense";case 19:return"SuspenseList";case 25:return"TracingMarker";case 1:case 0:case 17:case 2:case 14:case 15:if(typeof t=="function")return t.displayName||t.name||null;if(typeof t=="string")return t}return null}function Hi(e){switch(typeof e){case"boolean":case"number":case"string":case"undefined":return e;case"object":return e;default:return""}}function Qf(e){var t=e.type;return(e=e.nodeName)&&e.toLowerCase()==="input"&&(t==="checkbox"||t==="radio")}function fb(e){var t=Qf(e)?"checked":"value",i=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),a=""+e[t];if(!e.hasOwnProperty(t)&&typeof i<"u"&&typeof i.get=="function"&&typeof i.set=="function"){var n=i.get,o=i.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return n.call(this)},set:function(s){a=""+s,o.call(this,s)}}),Object.defineProperty(e,t,{enumerable:i.enumerable}),{getValue:function(){return a},setValue:function(s){a=""+s},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}function $o(e){e._valueTracker||(e._valueTracker=fb(e))}function Jf(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var i=t.getValue(),a="";return e&&(a=Qf(e)?e.checked?"true":"false":e.value),e=a,e!==i?(t.setValue(e),!0):!1}function Ds(e){if(e=e||(typeof document<"u"?document:void 0),typeof e>"u")return null;try{return e.activeElement||e.body}catch{return e.body}}function dd(e,t){var i=t.checked;return Re({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:i??e._wrapperState.initialChecked})}function ru(e,t){var i=t.defaultValue==null?"":t.defaultValue,a=t.checked!=null?t.checked:t.defaultChecked;i=Hi(t.value!=null?t.value:i),e._wrapperState={initialChecked:a,initialValue:i,controlled:t.type==="checkbox"||t.type==="radio"?t.checked!=null:t.value!=null}}function Zf(e,t){t=t.checked,t!=null&&Cp(e,"checked",t,!1)}function pd(e,t){Zf(e,t);var i=Hi(t.value),a=t.type;if(i!=null)a==="number"?(i===0&&e.value===""||e.value!=i)&&(e.value=""+i):e.value!==""+i&&(e.value=""+i);else if(a==="submit"||a==="reset"){e.removeAttribute("value");return}t.hasOwnProperty("value")?cd(e,t.type,i):t.hasOwnProperty("defaultValue")&&cd(e,t.type,Hi(t.defaultValue)),t.checked==null&&t.defaultChecked!=null&&(e.defaultChecked=!!t.defaultChecked)}function lu(e,t,i){if(t.hasOwnProperty("value")||t.hasOwnProperty("defaultValue")){var a=t.type;if(!(a!=="submit"&&a!=="reset"||t.value!==void 0&&t.value!==null))return;t=""+e._wrapperState.initialValue,i||t===e.value||(e.value=t),e.defaultValue=t}i=e.name,i!==""&&(e.name=""),e.defaultChecked=!!e._wrapperState.initialChecked,i!==""&&(e.name=i)}function cd(e,t,i){(t!=="number"||Ds(e.ownerDocument)!==e)&&(i==null?e.defaultValue=""+e._wrapperState.initialValue:e.defaultValue!==""+i&&(e.defaultValue=""+i))}var Ln=Array.isArray;function Xa(e,t,i,a){if(e=e.options,t){t={};for(var n=0;n<i.length;n++)t["$"+i[n]]=!0;for(i=0;i<e.length;i++)n=t.hasOwnProperty("$"+e[i].value),e[i].selected!==n&&(e[i].selected=n),n&&a&&(e[i].defaultSelected=!0)}else{for(i=""+Hi(i),t=null,n=0;n<e.length;n++){if(e[n].value===i){e[n].selected=!0,a&&(e[n].defaultSelected=!0);return}t!==null||e[n].disabled||(t=e[n])}t!==null&&(t.selected=!0)}}function ud(e,t){if(t.dangerouslySetInnerHTML!=null)throw Error(S(91));return Re({},t,{value:void 0,defaultValue:void 0,children:""+e._wrapperState.initialValue})}function du(e,t){var i=t.value;if(i==null){if(i=t.children,t=t.defaultValue,i!=null){if(t!=null)throw Error(S(92));if(Ln(i)){if(1<i.length)throw Error(S(93));i=i[0]}t=i}t==null&&(t=""),i=t}e._wrapperState={initialValue:Hi(i)}}function eh(e,t){var i=Hi(t.value),a=Hi(t.defaultValue);i!=null&&(i=""+i,i!==e.value&&(e.value=i),t.defaultValue==null&&e.defaultValue!==i&&(e.defaultValue=i)),a!=null&&(e.defaultValue=""+a)}function pu(e){var t=e.textContent;t===e._wrapperState.initialValue&&t!==""&&t!==null&&(e.value=t)}function th(e){switch(e){case"svg":return"http://www.w3.org/2000/svg";case"math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function md(e,t){return e==null||e==="http://www.w3.org/1999/xhtml"?th(t):e==="http://www.w3.org/2000/svg"&&t==="foreignObject"?"http://www.w3.org/1999/xhtml":e}var Go,ih=function(e){return typeof MSApp<"u"&&MSApp.execUnsafeLocalFunction?function(t,i,a,n){MSApp.execUnsafeLocalFunction(function(){return e(t,i,a,n)})}:e}(function(e,t){if(e.namespaceURI!=="http://www.w3.org/2000/svg"||"innerHTML"in e)e.innerHTML=t;else{for(Go=Go||document.createElement("div"),Go.innerHTML="<svg>"+t.valueOf().toString()+"</svg>",t=Go.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}});function oo(e,t){if(t){var i=e.firstChild;if(i&&i===e.lastChild&&i.nodeType===3){i.nodeValue=t;return}}e.textContent=t}var Un={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},hb=["Webkit","ms","Moz","O"];Object.keys(Un).forEach(function(e){hb.forEach(function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),Un[t]=Un[e]})});function ah(e,t,i){return t==null||typeof t=="boolean"||t===""?"":i||typeof t!="number"||t===0||Un.hasOwnProperty(e)&&Un[e]?(""+t).trim():t+"px"}function nh(e,t){e=e.style;for(var i in t)if(t.hasOwnProperty(i)){var a=i.indexOf("--")===0,n=ah(i,t[i],a);i==="float"&&(i="cssFloat"),a?e.setProperty(i,n):e[i]=n}}var gb=Re({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function fd(e,t){if(t){if(gb[e]&&(t.children!=null||t.dangerouslySetInnerHTML!=null))throw Error(S(137,e));if(t.dangerouslySetInnerHTML!=null){if(t.children!=null)throw Error(S(60));if(typeof t.dangerouslySetInnerHTML!="object"||!("__html"in t.dangerouslySetInnerHTML))throw Error(S(61))}if(t.style!=null&&typeof t.style!="object")throw Error(S(62))}}function hd(e,t){if(e.indexOf("-")===-1)return typeof t.is=="string";switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var gd=null;function Ep(e){return e=e.target||e.srcElement||window,e.correspondingUseElement&&(e=e.correspondingUseElement),e.nodeType===3?e.parentNode:e}var yd=null,Ya=null,Qa=null;function cu(e){if(e=Po(e)){if(typeof yd!="function")throw Error(S(280));var t=e.stateNode;t&&(t=ur(t),yd(e.stateNode,e.type,t))}}function oh(e){Ya?Qa?Qa.push(e):Qa=[e]:Ya=e}function sh(){if(Ya){var e=Ya,t=Qa;if(Qa=Ya=null,cu(e),t)for(e=0;e<t.length;e++)cu(t[e])}}function rh(e,t){return e(t)}function lh(){}var yl=!1;function dh(e,t,i){if(yl)return e(t,i);yl=!0;try{return rh(e,t,i)}finally{yl=!1,(Ya!==null||Qa!==null)&&(lh(),sh())}}function so(e,t){var i=e.stateNode;if(i===null)return null;var a=ur(i);if(a===null)return null;i=a[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(a=!a.disabled)||(e=e.type,a=!(e==="button"||e==="input"||e==="select"||e==="textarea")),e=!a;break e;default:e=!1}if(e)return null;if(i&&typeof i!="function")throw Error(S(231,t,typeof i));return i}var _d=!1;if(yi)try{var Fn={};Object.defineProperty(Fn,"passive",{get:function(){_d=!0}}),window.addEventListener("test",Fn,Fn),window.removeEventListener("test",Fn,Fn)}catch{_d=!1}function yb(e,t,i,a,n,o,s,r,l){var d=Array.prototype.slice.call(arguments,3);try{t.apply(i,d)}catch(p){this.onError(p)}}var Kn=!1,Cs=null,Rs=!1,bd=null,_b={onError:function(e){Kn=!0,Cs=e}};function bb(e,t,i,a,n,o,s,r,l){Kn=!1,Cs=null,yb.apply(_b,arguments)}function kb(e,t,i,a,n,o,s,r,l){if(bb.apply(this,arguments),Kn){if(Kn){var d=Cs;Kn=!1,Cs=null}else throw Error(S(198));Rs||(Rs=!0,bd=d)}}function Fa(e){var t=e,i=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do t=e,t.flags&4098&&(i=t.return),e=t.return;while(e)}return t.tag===3?i:null}function ph(e){if(e.tag===13){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function uu(e){if(Fa(e)!==e)throw Error(S(188))}function vb(e){var t=e.alternate;if(!t){if(t=Fa(e),t===null)throw Error(S(188));return t!==e?null:e}for(var i=e,a=t;;){var n=i.return;if(n===null)break;var o=n.alternate;if(o===null){if(a=n.return,a!==null){i=a;continue}break}if(n.child===o.child){for(o=n.child;o;){if(o===i)return uu(n),e;if(o===a)return uu(n),t;o=o.sibling}throw Error(S(188))}if(i.return!==a.return)i=n,a=o;else{for(var s=!1,r=n.child;r;){if(r===i){s=!0,i=n,a=o;break}if(r===a){s=!0,a=n,i=o;break}r=r.sibling}if(!s){for(r=o.child;r;){if(r===i){s=!0,i=o,a=n;break}if(r===a){s=!0,a=o,i=n;break}r=r.sibling}if(!s)throw Error(S(189))}}if(i.alternate!==a)throw Error(S(190))}if(i.tag!==3)throw Error(S(188));return i.stateNode.current===i?e:t}function ch(e){return e=vb(e),e!==null?uh(e):null}function uh(e){if(e.tag===5||e.tag===6)return e;for(e=e.child;e!==null;){var t=uh(e);if(t!==null)return t;e=e.sibling}return null}var mh=vt.unstable_scheduleCallback,mu=vt.unstable_cancelCallback,wb=vt.unstable_shouldYield,qb=vt.unstable_requestPaint,je=vt.unstable_now,xb=vt.unstable_getCurrentPriorityLevel,Bp=vt.unstable_ImmediatePriority,fh=vt.unstable_UserBlockingPriority,Ps=vt.unstable_NormalPriority,Fb=vt.unstable_LowPriority,hh=vt.unstable_IdlePriority,lr=null,ii=null;function Tb(e){if(ii&&typeof ii.onCommitFiberRoot=="function")try{ii.onCommitFiberRoot(lr,e,void 0,(e.current.flags&128)===128)}catch{}}var Gt=Math.clz32?Math.clz32:Rb,Db=Math.log,Cb=Math.LN2;function Rb(e){return e>>>=0,e===0?32:31-(Db(e)/Cb|0)|0}var Uo=64,Ko=4194304;function Wn(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return e&4194240;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return e&130023424;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function Ss(e,t){var i=e.pendingLanes;if(i===0)return 0;var a=0,n=e.suspendedLanes,o=e.pingedLanes,s=i&268435455;if(s!==0){var r=s&~n;r!==0?a=Wn(r):(o&=s,o!==0&&(a=Wn(o)))}else s=i&~n,s!==0?a=Wn(s):o!==0&&(a=Wn(o));if(a===0)return 0;if(t!==0&&t!==a&&!(t&n)&&(n=a&-a,o=t&-t,n>=o||n===16&&(o&4194240)!==0))return t;if(a&4&&(a|=i&16),t=e.entangledLanes,t!==0)for(e=e.entanglements,t&=a;0<t;)i=31-Gt(t),n=1<<i,a|=e[i],t&=~n;return a}function Pb(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return-1;case 134217728:case 268435456:case 536870912:case 1073741824:return-1;default:return-1}}function Sb(e,t){for(var i=e.suspendedLanes,a=e.pingedLanes,n=e.expirationTimes,o=e.pendingLanes;0<o;){var s=31-Gt(o),r=1<<s,l=n[s];l===-1?(!(r&i)||r&a)&&(n[s]=Pb(r,t)):l<=t&&(e.expiredLanes|=r),o&=~r}}function kd(e){return e=e.pendingLanes&-1073741825,e!==0?e:e&1073741824?1073741824:0}function gh(){var e=Uo;return Uo<<=1,!(Uo&4194240)&&(Uo=64),e}function _l(e){for(var t=[],i=0;31>i;i++)t.push(e);return t}function Co(e,t,i){e.pendingLanes|=t,t!==536870912&&(e.suspendedLanes=0,e.pingedLanes=0),e=e.eventTimes,t=31-Gt(t),e[t]=i}function Eb(e,t){var i=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var a=e.eventTimes;for(e=e.expirationTimes;0<i;){var n=31-Gt(i),o=1<<n;t[n]=0,a[n]=-1,e[n]=-1,i&=~o}}function Ap(e,t){var i=e.entangledLanes|=t;for(e=e.entanglements;i;){var a=31-Gt(i),n=1<<a;n&t|e[a]&t&&(e[a]|=t),i&=~n}}var le=0;function yh(e){return e&=-e,1<e?4<e?e&268435455?16:536870912:4:1}var _h,jp,bh,kh,vh,vd=!1,Ho=[],Ii=null,Ni=null,Oi=null,ro=new Map,lo=new Map,Bi=[],Bb="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit".split(" ");function fu(e,t){switch(e){case"focusin":case"focusout":Ii=null;break;case"dragenter":case"dragleave":Ni=null;break;case"mouseover":case"mouseout":Oi=null;break;case"pointerover":case"pointerout":ro.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":lo.delete(t.pointerId)}}function Tn(e,t,i,a,n,o){return e===null||e.nativeEvent!==o?(e={blockedOn:t,domEventName:i,eventSystemFlags:a,nativeEvent:o,targetContainers:[n]},t!==null&&(t=Po(t),t!==null&&jp(t)),e):(e.eventSystemFlags|=a,t=e.targetContainers,n!==null&&t.indexOf(n)===-1&&t.push(n),e)}function Ab(e,t,i,a,n){switch(t){case"focusin":return Ii=Tn(Ii,e,t,i,a,n),!0;case"dragenter":return Ni=Tn(Ni,e,t,i,a,n),!0;case"mouseover":return Oi=Tn(Oi,e,t,i,a,n),!0;case"pointerover":var o=n.pointerId;return ro.set(o,Tn(ro.get(o)||null,e,t,i,a,n)),!0;case"gotpointercapture":return o=n.pointerId,lo.set(o,Tn(lo.get(o)||null,e,t,i,a,n)),!0}return!1}function wh(e){var t=pa(e.target);if(t!==null){var i=Fa(t);if(i!==null){if(t=i.tag,t===13){if(t=ph(i),t!==null){e.blockedOn=t,vh(e.priority,function(){bh(i)});return}}else if(t===3&&i.stateNode.current.memoizedState.isDehydrated){e.blockedOn=i.tag===3?i.stateNode.containerInfo:null;return}}}e.blockedOn=null}function cs(e){if(e.blockedOn!==null)return!1;for(var t=e.targetContainers;0<t.length;){var i=wd(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(i===null){i=e.nativeEvent;var a=new i.constructor(i.type,i);gd=a,i.target.dispatchEvent(a),gd=null}else return t=Po(i),t!==null&&jp(t),e.blockedOn=i,!1;t.shift()}return!0}function hu(e,t,i){cs(e)&&i.delete(t)}function jb(){vd=!1,Ii!==null&&cs(Ii)&&(Ii=null),Ni!==null&&cs(Ni)&&(Ni=null),Oi!==null&&cs(Oi)&&(Oi=null),ro.forEach(hu),lo.forEach(hu)}function Dn(e,t){e.blockedOn===t&&(e.blockedOn=null,vd||(vd=!0,vt.unstable_scheduleCallback(vt.unstable_NormalPriority,jb)))}function po(e){function t(n){return Dn(n,e)}if(0<Ho.length){Dn(Ho[0],e);for(var i=1;i<Ho.length;i++){var a=Ho[i];a.blockedOn===e&&(a.blockedOn=null)}}for(Ii!==null&&Dn(Ii,e),Ni!==null&&Dn(Ni,e),Oi!==null&&Dn(Oi,e),ro.forEach(t),lo.forEach(t),i=0;i<Bi.length;i++)a=Bi[i],a.blockedOn===e&&(a.blockedOn=null);for(;0<Bi.length&&(i=Bi[0],i.blockedOn===null);)wh(i),i.blockedOn===null&&Bi.shift()}var Ja=qi.ReactCurrentBatchConfig,Es=!0;function Mb(e,t,i,a){var n=le,o=Ja.transition;Ja.transition=null;try{le=1,Mp(e,t,i,a)}finally{le=n,Ja.transition=o}}function zb(e,t,i,a){var n=le,o=Ja.transition;Ja.transition=null;try{le=4,Mp(e,t,i,a)}finally{le=n,Ja.transition=o}}function Mp(e,t,i,a){if(Es){var n=wd(e,t,i,a);if(n===null)Cl(e,t,a,Bs,i),fu(e,a);else if(Ab(n,e,t,i,a))a.stopPropagation();else if(fu(e,a),t&4&&-1<Bb.indexOf(e)){for(;n!==null;){var o=Po(n);if(o!==null&&_h(o),o=wd(e,t,i,a),o===null&&Cl(e,t,a,Bs,i),o===n)break;n=o}n!==null&&a.stopPropagation()}else Cl(e,t,a,null,i)}}var Bs=null;function wd(e,t,i,a){if(Bs=null,e=Ep(a),e=pa(e),e!==null)if(t=Fa(e),t===null)e=null;else if(i=t.tag,i===13){if(e=ph(t),e!==null)return e;e=null}else if(i===3){if(t.stateNode.current.memoizedState.isDehydrated)return t.tag===3?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Bs=e,null}function qh(e){switch(e){case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 1;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"toggle":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 4;case"message":switch(xb()){case Bp:return 1;case fh:return 4;case Ps:case Fb:return 16;case hh:return 536870912;default:return 16}default:return 16}}var ji=null,zp=null,us=null;function xh(){if(us)return us;var e,t=zp,i=t.length,a,n="value"in ji?ji.value:ji.textContent,o=n.length;for(e=0;e<i&&t[e]===n[e];e++);var s=i-e;for(a=1;a<=s&&t[i-a]===n[o-a];a++);return us=n.slice(e,1<a?1-a:void 0)}function ms(e){var t=e.keyCode;return"charCode"in e?(e=e.charCode,e===0&&t===13&&(e=13)):e=t,e===10&&(e=13),32<=e||e===13?e:0}function Vo(){return!0}function gu(){return!1}function qt(e){function t(i,a,n,o,s){this._reactName=i,this._targetInst=n,this.type=a,this.nativeEvent=o,this.target=s,this.currentTarget=null;for(var r in e)e.hasOwnProperty(r)&&(i=e[r],this[r]=i?i(o):o[r]);return this.isDefaultPrevented=(o.defaultPrevented!=null?o.defaultPrevented:o.returnValue===!1)?Vo:gu,this.isPropagationStopped=gu,this}return Re(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var i=this.nativeEvent;i&&(i.preventDefault?i.preventDefault():typeof i.returnValue!="unknown"&&(i.returnValue=!1),this.isDefaultPrevented=Vo)},stopPropagation:function(){var i=this.nativeEvent;i&&(i.stopPropagation?i.stopPropagation():typeof i.cancelBubble!="unknown"&&(i.cancelBubble=!0),this.isPropagationStopped=Vo)},persist:function(){},isPersistent:Vo}),t}var gn={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},Ip=qt(gn),Ro=Re({},gn,{view:0,detail:0}),Ib=qt(Ro),bl,kl,Cn,dr=Re({},Ro,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:Np,button:0,buttons:0,relatedTarget:function(e){return e.relatedTarget===void 0?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==Cn&&(Cn&&e.type==="mousemove"?(bl=e.screenX-Cn.screenX,kl=e.screenY-Cn.screenY):kl=bl=0,Cn=e),bl)},movementY:function(e){return"movementY"in e?e.movementY:kl}}),yu=qt(dr),Nb=Re({},dr,{dataTransfer:0}),Ob=qt(Nb),Lb=Re({},Ro,{relatedTarget:0}),vl=qt(Lb),Wb=Re({},gn,{animationName:0,elapsedTime:0,pseudoElement:0}),$b=qt(Wb),Gb=Re({},gn,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),Ub=qt(Gb),Kb=Re({},gn,{data:0}),_u=qt(Kb),Hb={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},Vb={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},Xb={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function Yb(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):(e=Xb[e])?!!t[e]:!1}function Np(){return Yb}var Qb=Re({},Ro,{key:function(e){if(e.key){var t=Hb[e.key]||e.key;if(t!=="Unidentified")return t}return e.type==="keypress"?(e=ms(e),e===13?"Enter":String.fromCharCode(e)):e.type==="keydown"||e.type==="keyup"?Vb[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:Np,charCode:function(e){return e.type==="keypress"?ms(e):0},keyCode:function(e){return e.type==="keydown"||e.type==="keyup"?e.keyCode:0},which:function(e){return e.type==="keypress"?ms(e):e.type==="keydown"||e.type==="keyup"?e.keyCode:0}}),Jb=qt(Qb),Zb=Re({},dr,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0}),bu=qt(Zb),e0=Re({},Ro,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:Np}),t0=qt(e0),i0=Re({},gn,{propertyName:0,elapsedTime:0,pseudoElement:0}),a0=qt(i0),n0=Re({},dr,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),o0=qt(n0),s0=[9,13,27,32],Op=yi&&"CompositionEvent"in window,Hn=null;yi&&"documentMode"in document&&(Hn=document.documentMode);var r0=yi&&"TextEvent"in window&&!Hn,Fh=yi&&(!Op||Hn&&8<Hn&&11>=Hn),ku=String.fromCharCode(32),vu=!1;function Th(e,t){switch(e){case"keyup":return s0.indexOf(t.keyCode)!==-1;case"keydown":return t.keyCode!==229;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function Dh(e){return e=e.detail,typeof e=="object"&&"data"in e?e.data:null}var Na=!1;function l0(e,t){switch(e){case"compositionend":return Dh(t);case"keypress":return t.which!==32?null:(vu=!0,ku);case"textInput":return e=t.data,e===ku&&vu?null:e;default:return null}}function d0(e,t){if(Na)return e==="compositionend"||!Op&&Th(e,t)?(e=xh(),us=zp=ji=null,Na=!1,e):null;switch(e){case"paste":return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return Fh&&t.locale!=="ko"?null:t.data;default:return null}}var p0={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function wu(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t==="input"?!!p0[e.type]:t==="textarea"}function Ch(e,t,i,a){oh(a),t=As(t,"onChange"),0<t.length&&(i=new Ip("onChange","change",null,i,a),e.push({event:i,listeners:t}))}var Vn=null,co=null;function c0(e){Nh(e,0)}function pr(e){var t=Wa(e);if(Jf(t))return e}function u0(e,t){if(e==="change")return t}var Rh=!1;if(yi){var wl;if(yi){var ql="oninput"in document;if(!ql){var qu=document.createElement("div");qu.setAttribute("oninput","return;"),ql=typeof qu.oninput=="function"}wl=ql}else wl=!1;Rh=wl&&(!document.documentMode||9<document.documentMode)}function xu(){Vn&&(Vn.detachEvent("onpropertychange",Ph),co=Vn=null)}function Ph(e){if(e.propertyName==="value"&&pr(co)){var t=[];Ch(t,co,e,Ep(e)),dh(c0,t)}}function m0(e,t,i){e==="focusin"?(xu(),Vn=t,co=i,Vn.attachEvent("onpropertychange",Ph)):e==="focusout"&&xu()}function f0(e){if(e==="selectionchange"||e==="keyup"||e==="keydown")return pr(co)}function h0(e,t){if(e==="click")return pr(t)}function g0(e,t){if(e==="input"||e==="change")return pr(t)}function y0(e,t){return e===t&&(e!==0||1/e===1/t)||e!==e&&t!==t}var Kt=typeof Object.is=="function"?Object.is:y0;function uo(e,t){if(Kt(e,t))return!0;if(typeof e!="object"||e===null||typeof t!="object"||t===null)return!1;var i=Object.keys(e),a=Object.keys(t);if(i.length!==a.length)return!1;for(a=0;a<i.length;a++){var n=i[a];if(!nd.call(t,n)||!Kt(e[n],t[n]))return!1}return!0}function Fu(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function Tu(e,t){var i=Fu(e);e=0;for(var a;i;){if(i.nodeType===3){if(a=e+i.textContent.length,e<=t&&a>=t)return{node:i,offset:t-e};e=a}e:{for(;i;){if(i.nextSibling){i=i.nextSibling;break e}i=i.parentNode}i=void 0}i=Fu(i)}}function Sh(e,t){return e&&t?e===t?!0:e&&e.nodeType===3?!1:t&&t.nodeType===3?Sh(e,t.parentNode):"contains"in e?e.contains(t):e.compareDocumentPosition?!!(e.compareDocumentPosition(t)&16):!1:!1}function Eh(){for(var e=window,t=Ds();t instanceof e.HTMLIFrameElement;){try{var i=typeof t.contentWindow.location.href=="string"}catch{i=!1}if(i)e=t.contentWindow;else break;t=Ds(e.document)}return t}function Lp(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(t==="input"&&(e.type==="text"||e.type==="search"||e.type==="tel"||e.type==="url"||e.type==="password")||t==="textarea"||e.contentEditable==="true")}function _0(e){var t=Eh(),i=e.focusedElem,a=e.selectionRange;if(t!==i&&i&&i.ownerDocument&&Sh(i.ownerDocument.documentElement,i)){if(a!==null&&Lp(i)){if(t=a.start,e=a.end,e===void 0&&(e=t),"selectionStart"in i)i.selectionStart=t,i.selectionEnd=Math.min(e,i.value.length);else if(e=(t=i.ownerDocument||document)&&t.defaultView||window,e.getSelection){e=e.getSelection();var n=i.textContent.length,o=Math.min(a.start,n);a=a.end===void 0?o:Math.min(a.end,n),!e.extend&&o>a&&(n=a,a=o,o=n),n=Tu(i,o);var s=Tu(i,a);n&&s&&(e.rangeCount!==1||e.anchorNode!==n.node||e.anchorOffset!==n.offset||e.focusNode!==s.node||e.focusOffset!==s.offset)&&(t=t.createRange(),t.setStart(n.node,n.offset),e.removeAllRanges(),o>a?(e.addRange(t),e.extend(s.node,s.offset)):(t.setEnd(s.node,s.offset),e.addRange(t)))}}for(t=[],e=i;e=e.parentNode;)e.nodeType===1&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for(typeof i.focus=="function"&&i.focus(),i=0;i<t.length;i++)e=t[i],e.element.scrollLeft=e.left,e.element.scrollTop=e.top}}var b0=yi&&"documentMode"in document&&11>=document.documentMode,Oa=null,qd=null,Xn=null,xd=!1;function Du(e,t,i){var a=i.window===i?i.document:i.nodeType===9?i:i.ownerDocument;xd||Oa==null||Oa!==Ds(a)||(a=Oa,"selectionStart"in a&&Lp(a)?a={start:a.selectionStart,end:a.selectionEnd}:(a=(a.ownerDocument&&a.ownerDocument.defaultView||window).getSelection(),a={anchorNode:a.anchorNode,anchorOffset:a.anchorOffset,focusNode:a.focusNode,focusOffset:a.focusOffset}),Xn&&uo(Xn,a)||(Xn=a,a=As(qd,"onSelect"),0<a.length&&(t=new Ip("onSelect","select",null,t,i),e.push({event:t,listeners:a}),t.target=Oa)))}function Xo(e,t){var i={};return i[e.toLowerCase()]=t.toLowerCase(),i["Webkit"+e]="webkit"+t,i["Moz"+e]="moz"+t,i}var La={animationend:Xo("Animation","AnimationEnd"),animationiteration:Xo("Animation","AnimationIteration"),animationstart:Xo("Animation","AnimationStart"),transitionend:Xo("Transition","TransitionEnd")},xl={},Bh={};yi&&(Bh=document.createElement("div").style,"AnimationEvent"in window||(delete La.animationend.animation,delete La.animationiteration.animation,delete La.animationstart.animation),"TransitionEvent"in window||delete La.transitionend.transition);function cr(e){if(xl[e])return xl[e];if(!La[e])return e;var t=La[e],i;for(i in t)if(t.hasOwnProperty(i)&&i in Bh)return xl[e]=t[i];return e}var Ah=cr("animationend"),jh=cr("animationiteration"),Mh=cr("animationstart"),zh=cr("transitionend"),Ih=new Map,Cu="abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");function Qi(e,t){Ih.set(e,t),xa(t,[e])}for(var Fl=0;Fl<Cu.length;Fl++){var Tl=Cu[Fl],k0=Tl.toLowerCase(),v0=Tl[0].toUpperCase()+Tl.slice(1);Qi(k0,"on"+v0)}Qi(Ah,"onAnimationEnd");Qi(jh,"onAnimationIteration");Qi(Mh,"onAnimationStart");Qi("dblclick","onDoubleClick");Qi("focusin","onFocus");Qi("focusout","onBlur");Qi(zh,"onTransitionEnd");nn("onMouseEnter",["mouseout","mouseover"]);nn("onMouseLeave",["mouseout","mouseover"]);nn("onPointerEnter",["pointerout","pointerover"]);nn("onPointerLeave",["pointerout","pointerover"]);xa("onChange","change click focusin focusout input keydown keyup selectionchange".split(" "));xa("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" "));xa("onBeforeInput",["compositionend","keypress","textInput","paste"]);xa("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" "));xa("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" "));xa("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var $n="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),w0=new Set("cancel close invalid load scroll toggle".split(" ").concat($n));function Ru(e,t,i){var a=e.type||"unknown-event";e.currentTarget=i,kb(a,t,void 0,e),e.currentTarget=null}function Nh(e,t){t=(t&4)!==0;for(var i=0;i<e.length;i++){var a=e[i],n=a.event;a=a.listeners;e:{var o=void 0;if(t)for(var s=a.length-1;0<=s;s--){var r=a[s],l=r.instance,d=r.currentTarget;if(r=r.listener,l!==o&&n.isPropagationStopped())break e;Ru(n,r,d),o=l}else for(s=0;s<a.length;s++){if(r=a[s],l=r.instance,d=r.currentTarget,r=r.listener,l!==o&&n.isPropagationStopped())break e;Ru(n,r,d),o=l}}}if(Rs)throw e=bd,Rs=!1,bd=null,e}function _e(e,t){var i=t[Rd];i===void 0&&(i=t[Rd]=new Set);var a=e+"__bubble";i.has(a)||(Oh(t,e,2,!1),i.add(a))}function Dl(e,t,i){var a=0;t&&(a|=4),Oh(i,e,a,t)}var Yo="_reactListening"+Math.random().toString(36).slice(2);function mo(e){if(!e[Yo]){e[Yo]=!0,Hf.forEach(function(i){i!=="selectionchange"&&(w0.has(i)||Dl(i,!1,e),Dl(i,!0,e))});var t=e.nodeType===9?e:e.ownerDocument;t===null||t[Yo]||(t[Yo]=!0,Dl("selectionchange",!1,t))}}function Oh(e,t,i,a){switch(qh(t)){case 1:var n=Mb;break;case 4:n=zb;break;default:n=Mp}i=n.bind(null,t,i,e),n=void 0,!_d||t!=="touchstart"&&t!=="touchmove"&&t!=="wheel"||(n=!0),a?n!==void 0?e.addEventListener(t,i,{capture:!0,passive:n}):e.addEventListener(t,i,!0):n!==void 0?e.addEventListener(t,i,{passive:n}):e.addEventListener(t,i,!1)}function Cl(e,t,i,a,n){var o=a;if(!(t&1)&&!(t&2)&&a!==null)e:for(;;){if(a===null)return;var s=a.tag;if(s===3||s===4){var r=a.stateNode.containerInfo;if(r===n||r.nodeType===8&&r.parentNode===n)break;if(s===4)for(s=a.return;s!==null;){var l=s.tag;if((l===3||l===4)&&(l=s.stateNode.containerInfo,l===n||l.nodeType===8&&l.parentNode===n))return;s=s.return}for(;r!==null;){if(s=pa(r),s===null)return;if(l=s.tag,l===5||l===6){a=o=s;continue e}r=r.parentNode}}a=a.return}dh(function(){var d=o,p=Ep(i),f=[];e:{var h=Ih.get(e);if(h!==void 0){var c=Ip,g=e;switch(e){case"keypress":if(ms(i)===0)break e;case"keydown":case"keyup":c=Jb;break;case"focusin":g="focus",c=vl;break;case"focusout":g="blur",c=vl;break;case"beforeblur":case"afterblur":c=vl;break;case"click":if(i.button===2)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":c=yu;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":c=Ob;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":c=t0;break;case Ah:case jh:case Mh:c=$b;break;case zh:c=a0;break;case"scroll":c=Ib;break;case"wheel":c=o0;break;case"copy":case"cut":case"paste":c=Ub;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":c=bu}var m=(t&4)!==0,x=!m&&e==="scroll",_=m?h!==null?h+"Capture":null:h;m=[];for(var y=d,b;y!==null;){b=y;var v=b.stateNode;if(b.tag===5&&v!==null&&(b=v,_!==null&&(v=so(y,_),v!=null&&m.push(fo(y,v,b)))),x)break;y=y.return}0<m.length&&(h=new c(h,g,null,i,p),f.push({event:h,listeners:m}))}}if(!(t&7)){e:{if(h=e==="mouseover"||e==="pointerover",c=e==="mouseout"||e==="pointerout",h&&i!==gd&&(g=i.relatedTarget||i.fromElement)&&(pa(g)||g[_i]))break e;if((c||h)&&(h=p.window===p?p:(h=p.ownerDocument)?h.defaultView||h.parentWindow:window,c?(g=i.relatedTarget||i.toElement,c=d,g=g?pa(g):null,g!==null&&(x=Fa(g),g!==x||g.tag!==5&&g.tag!==6)&&(g=null)):(c=null,g=d),c!==g)){if(m=yu,v="onMouseLeave",_="onMouseEnter",y="mouse",(e==="pointerout"||e==="pointerover")&&(m=bu,v="onPointerLeave",_="onPointerEnter",y="pointer"),x=c==null?h:Wa(c),b=g==null?h:Wa(g),h=new m(v,y+"leave",c,i,p),h.target=x,h.relatedTarget=b,v=null,pa(p)===d&&(m=new m(_,y+"enter",g,i,p),m.target=b,m.relatedTarget=x,v=m),x=v,c&&g)t:{for(m=c,_=g,y=0,b=m;b;b=Ca(b))y++;for(b=0,v=_;v;v=Ca(v))b++;for(;0<y-b;)m=Ca(m),y--;for(;0<b-y;)_=Ca(_),b--;for(;y--;){if(m===_||_!==null&&m===_.alternate)break t;m=Ca(m),_=Ca(_)}m=null}else m=null;c!==null&&Pu(f,h,c,m,!1),g!==null&&x!==null&&Pu(f,x,g,m,!0)}}e:{if(h=d?Wa(d):window,c=h.nodeName&&h.nodeName.toLowerCase(),c==="select"||c==="input"&&h.type==="file")var F=u0;else if(wu(h))if(Rh)F=g0;else{F=f0;var T=m0}else(c=h.nodeName)&&c.toLowerCase()==="input"&&(h.type==="checkbox"||h.type==="radio")&&(F=h0);if(F&&(F=F(e,d))){Ch(f,F,i,p);break e}T&&T(e,h,d),e==="focusout"&&(T=h._wrapperState)&&T.controlled&&h.type==="number"&&cd(h,"number",h.value)}switch(T=d?Wa(d):window,e){case"focusin":(wu(T)||T.contentEditable==="true")&&(Oa=T,qd=d,Xn=null);break;case"focusout":Xn=qd=Oa=null;break;case"mousedown":xd=!0;break;case"contextmenu":case"mouseup":case"dragend":xd=!1,Du(f,i,p);break;case"selectionchange":if(b0)break;case"keydown":case"keyup":Du(f,i,p)}var w;if(Op)e:{switch(e){case"compositionstart":var D="onCompositionStart";break e;case"compositionend":D="onCompositionEnd";break e;case"compositionupdate":D="onCompositionUpdate";break e}D=void 0}else Na?Th(e,i)&&(D="onCompositionEnd"):e==="keydown"&&i.keyCode===229&&(D="onCompositionStart");D&&(Fh&&i.locale!=="ko"&&(Na||D!=="onCompositionStart"?D==="onCompositionEnd"&&Na&&(w=xh()):(ji=p,zp="value"in ji?ji.value:ji.textContent,Na=!0)),T=As(d,D),0<T.length&&(D=new _u(D,e,null,i,p),f.push({event:D,listeners:T}),w?D.data=w:(w=Dh(i),w!==null&&(D.data=w)))),(w=r0?l0(e,i):d0(e,i))&&(d=As(d,"onBeforeInput"),0<d.length&&(p=new _u("onBeforeInput","beforeinput",null,i,p),f.push({event:p,listeners:d}),p.data=w))}Nh(f,t)})}function fo(e,t,i){return{instance:e,listener:t,currentTarget:i}}function As(e,t){for(var i=t+"Capture",a=[];e!==null;){var n=e,o=n.stateNode;n.tag===5&&o!==null&&(n=o,o=so(e,i),o!=null&&a.unshift(fo(e,o,n)),o=so(e,t),o!=null&&a.push(fo(e,o,n))),e=e.return}return a}function Ca(e){if(e===null)return null;do e=e.return;while(e&&e.tag!==5);return e||null}function Pu(e,t,i,a,n){for(var o=t._reactName,s=[];i!==null&&i!==a;){var r=i,l=r.alternate,d=r.stateNode;if(l!==null&&l===a)break;r.tag===5&&d!==null&&(r=d,n?(l=so(i,o),l!=null&&s.unshift(fo(i,l,r))):n||(l=so(i,o),l!=null&&s.push(fo(i,l,r)))),i=i.return}s.length!==0&&e.push({event:t,listeners:s})}var q0=/\r\n?/g,x0=/\u0000|\uFFFD/g;function Su(e){return(typeof e=="string"?e:""+e).replace(q0,`
`).replace(x0,"")}function Qo(e,t,i){if(t=Su(t),Su(e)!==t&&i)throw Error(S(425))}function js(){}var Fd=null,Td=null;function Dd(e,t){return e==="textarea"||e==="noscript"||typeof t.children=="string"||typeof t.children=="number"||typeof t.dangerouslySetInnerHTML=="object"&&t.dangerouslySetInnerHTML!==null&&t.dangerouslySetInnerHTML.__html!=null}var Cd=typeof setTimeout=="function"?setTimeout:void 0,F0=typeof clearTimeout=="function"?clearTimeout:void 0,Eu=typeof Promise=="function"?Promise:void 0,T0=typeof queueMicrotask=="function"?queueMicrotask:typeof Eu<"u"?function(e){return Eu.resolve(null).then(e).catch(D0)}:Cd;function D0(e){setTimeout(function(){throw e})}function Rl(e,t){var i=t,a=0;do{var n=i.nextSibling;if(e.removeChild(i),n&&n.nodeType===8)if(i=n.data,i==="/$"){if(a===0){e.removeChild(n),po(t);return}a--}else i!=="$"&&i!=="$?"&&i!=="$!"||a++;i=n}while(i);po(t)}function Li(e){for(;e!=null;e=e.nextSibling){var t=e.nodeType;if(t===1||t===3)break;if(t===8){if(t=e.data,t==="$"||t==="$!"||t==="$?")break;if(t==="/$")return null}}return e}function Bu(e){e=e.previousSibling;for(var t=0;e;){if(e.nodeType===8){var i=e.data;if(i==="$"||i==="$!"||i==="$?"){if(t===0)return e;t--}else i==="/$"&&t++}e=e.previousSibling}return null}var yn=Math.random().toString(36).slice(2),Zt="__reactFiber$"+yn,ho="__reactProps$"+yn,_i="__reactContainer$"+yn,Rd="__reactEvents$"+yn,C0="__reactListeners$"+yn,R0="__reactHandles$"+yn;function pa(e){var t=e[Zt];if(t)return t;for(var i=e.parentNode;i;){if(t=i[_i]||i[Zt]){if(i=t.alternate,t.child!==null||i!==null&&i.child!==null)for(e=Bu(e);e!==null;){if(i=e[Zt])return i;e=Bu(e)}return t}e=i,i=e.parentNode}return null}function Po(e){return e=e[Zt]||e[_i],!e||e.tag!==5&&e.tag!==6&&e.tag!==13&&e.tag!==3?null:e}function Wa(e){if(e.tag===5||e.tag===6)return e.stateNode;throw Error(S(33))}function ur(e){return e[ho]||null}var Pd=[],$a=-1;function Ji(e){return{current:e}}function be(e){0>$a||(e.current=Pd[$a],Pd[$a]=null,$a--)}function ye(e,t){$a++,Pd[$a]=e.current,e.current=t}var Vi={},tt=Ji(Vi),pt=Ji(!1),ya=Vi;function on(e,t){var i=e.type.contextTypes;if(!i)return Vi;var a=e.stateNode;if(a&&a.__reactInternalMemoizedUnmaskedChildContext===t)return a.__reactInternalMemoizedMaskedChildContext;var n={},o;for(o in i)n[o]=t[o];return a&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=n),n}function ct(e){return e=e.childContextTypes,e!=null}function Ms(){be(pt),be(tt)}function Au(e,t,i){if(tt.current!==Vi)throw Error(S(168));ye(tt,t),ye(pt,i)}function Lh(e,t,i){var a=e.stateNode;if(t=t.childContextTypes,typeof a.getChildContext!="function")return i;a=a.getChildContext();for(var n in a)if(!(n in t))throw Error(S(108,mb(e)||"Unknown",n));return Re({},i,a)}function zs(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||Vi,ya=tt.current,ye(tt,e),ye(pt,pt.current),!0}function ju(e,t,i){var a=e.stateNode;if(!a)throw Error(S(169));i?(e=Lh(e,t,ya),a.__reactInternalMemoizedMergedChildContext=e,be(pt),be(tt),ye(tt,e)):be(pt),ye(pt,i)}var ui=null,mr=!1,Pl=!1;function Wh(e){ui===null?ui=[e]:ui.push(e)}function P0(e){mr=!0,Wh(e)}function Zi(){if(!Pl&&ui!==null){Pl=!0;var e=0,t=le;try{var i=ui;for(le=1;e<i.length;e++){var a=i[e];do a=a(!0);while(a!==null)}ui=null,mr=!1}catch(n){throw ui!==null&&(ui=ui.slice(e+1)),mh(Bp,Zi),n}finally{le=t,Pl=!1}}return null}var Ga=[],Ua=0,Is=null,Ns=0,Pt=[],St=0,_a=null,mi=1,fi="";function aa(e,t){Ga[Ua++]=Ns,Ga[Ua++]=Is,Is=e,Ns=t}function $h(e,t,i){Pt[St++]=mi,Pt[St++]=fi,Pt[St++]=_a,_a=e;var a=mi;e=fi;var n=32-Gt(a)-1;a&=~(1<<n),i+=1;var o=32-Gt(t)+n;if(30<o){var s=n-n%5;o=(a&(1<<s)-1).toString(32),a>>=s,n-=s,mi=1<<32-Gt(t)+n|i<<n|a,fi=o+e}else mi=1<<o|i<<n|a,fi=e}function Wp(e){e.return!==null&&(aa(e,1),$h(e,1,0))}function $p(e){for(;e===Is;)Is=Ga[--Ua],Ga[Ua]=null,Ns=Ga[--Ua],Ga[Ua]=null;for(;e===_a;)_a=Pt[--St],Pt[St]=null,fi=Pt[--St],Pt[St]=null,mi=Pt[--St],Pt[St]=null}var bt=null,_t=null,xe=!1,Wt=null;function Gh(e,t){var i=Et(5,null,null,0);i.elementType="DELETED",i.stateNode=t,i.return=e,t=e.deletions,t===null?(e.deletions=[i],e.flags|=16):t.push(i)}function Mu(e,t){switch(e.tag){case 5:var i=e.type;return t=t.nodeType!==1||i.toLowerCase()!==t.nodeName.toLowerCase()?null:t,t!==null?(e.stateNode=t,bt=e,_t=Li(t.firstChild),!0):!1;case 6:return t=e.pendingProps===""||t.nodeType!==3?null:t,t!==null?(e.stateNode=t,bt=e,_t=null,!0):!1;case 13:return t=t.nodeType!==8?null:t,t!==null?(i=_a!==null?{id:mi,overflow:fi}:null,e.memoizedState={dehydrated:t,treeContext:i,retryLane:1073741824},i=Et(18,null,null,0),i.stateNode=t,i.return=e,e.child=i,bt=e,_t=null,!0):!1;default:return!1}}function Sd(e){return(e.mode&1)!==0&&(e.flags&128)===0}function Ed(e){if(xe){var t=_t;if(t){var i=t;if(!Mu(e,t)){if(Sd(e))throw Error(S(418));t=Li(i.nextSibling);var a=bt;t&&Mu(e,t)?Gh(a,i):(e.flags=e.flags&-4097|2,xe=!1,bt=e)}}else{if(Sd(e))throw Error(S(418));e.flags=e.flags&-4097|2,xe=!1,bt=e}}}function zu(e){for(e=e.return;e!==null&&e.tag!==5&&e.tag!==3&&e.tag!==13;)e=e.return;bt=e}function Jo(e){if(e!==bt)return!1;if(!xe)return zu(e),xe=!0,!1;var t;if((t=e.tag!==3)&&!(t=e.tag!==5)&&(t=e.type,t=t!=="head"&&t!=="body"&&!Dd(e.type,e.memoizedProps)),t&&(t=_t)){if(Sd(e))throw Uh(),Error(S(418));for(;t;)Gh(e,t),t=Li(t.nextSibling)}if(zu(e),e.tag===13){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(S(317));e:{for(e=e.nextSibling,t=0;e;){if(e.nodeType===8){var i=e.data;if(i==="/$"){if(t===0){_t=Li(e.nextSibling);break e}t--}else i!=="$"&&i!=="$!"&&i!=="$?"||t++}e=e.nextSibling}_t=null}}else _t=bt?Li(e.stateNode.nextSibling):null;return!0}function Uh(){for(var e=_t;e;)e=Li(e.nextSibling)}function sn(){_t=bt=null,xe=!1}function Gp(e){Wt===null?Wt=[e]:Wt.push(e)}var S0=qi.ReactCurrentBatchConfig;function Ot(e,t){if(e&&e.defaultProps){t=Re({},t),e=e.defaultProps;for(var i in e)t[i]===void 0&&(t[i]=e[i]);return t}return t}var Os=Ji(null),Ls=null,Ka=null,Up=null;function Kp(){Up=Ka=Ls=null}function Hp(e){var t=Os.current;be(Os),e._currentValue=t}function Bd(e,t,i){for(;e!==null;){var a=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,a!==null&&(a.childLanes|=t)):a!==null&&(a.childLanes&t)!==t&&(a.childLanes|=t),e===i)break;e=e.return}}function Za(e,t){Ls=e,Up=Ka=null,e=e.dependencies,e!==null&&e.firstContext!==null&&(e.lanes&t&&(dt=!0),e.firstContext=null)}function jt(e){var t=e._currentValue;if(Up!==e)if(e={context:e,memoizedValue:t,next:null},Ka===null){if(Ls===null)throw Error(S(308));Ka=e,Ls.dependencies={lanes:0,firstContext:e}}else Ka=Ka.next=e;return t}var ca=null;function Vp(e){ca===null?ca=[e]:ca.push(e)}function Kh(e,t,i,a){var n=t.interleaved;return n===null?(i.next=i,Vp(t)):(i.next=n.next,n.next=i),t.interleaved=i,bi(e,a)}function bi(e,t){e.lanes|=t;var i=e.alternate;for(i!==null&&(i.lanes|=t),i=e,e=e.return;e!==null;)e.childLanes|=t,i=e.alternate,i!==null&&(i.childLanes|=t),i=e,e=e.return;return i.tag===3?i.stateNode:null}var Ei=!1;function Xp(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function Hh(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function gi(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function Wi(e,t,i){var a=e.updateQueue;if(a===null)return null;if(a=a.shared,te&2){var n=a.pending;return n===null?t.next=t:(t.next=n.next,n.next=t),a.pending=t,bi(e,i)}return n=a.interleaved,n===null?(t.next=t,Vp(a)):(t.next=n.next,n.next=t),a.interleaved=t,bi(e,i)}function fs(e,t,i){if(t=t.updateQueue,t!==null&&(t=t.shared,(i&4194240)!==0)){var a=t.lanes;a&=e.pendingLanes,i|=a,t.lanes=i,Ap(e,i)}}function Iu(e,t){var i=e.updateQueue,a=e.alternate;if(a!==null&&(a=a.updateQueue,i===a)){var n=null,o=null;if(i=i.firstBaseUpdate,i!==null){do{var s={eventTime:i.eventTime,lane:i.lane,tag:i.tag,payload:i.payload,callback:i.callback,next:null};o===null?n=o=s:o=o.next=s,i=i.next}while(i!==null);o===null?n=o=t:o=o.next=t}else n=o=t;i={baseState:a.baseState,firstBaseUpdate:n,lastBaseUpdate:o,shared:a.shared,effects:a.effects},e.updateQueue=i;return}e=i.lastBaseUpdate,e===null?i.firstBaseUpdate=t:e.next=t,i.lastBaseUpdate=t}function Ws(e,t,i,a){var n=e.updateQueue;Ei=!1;var o=n.firstBaseUpdate,s=n.lastBaseUpdate,r=n.shared.pending;if(r!==null){n.shared.pending=null;var l=r,d=l.next;l.next=null,s===null?o=d:s.next=d,s=l;var p=e.alternate;p!==null&&(p=p.updateQueue,r=p.lastBaseUpdate,r!==s&&(r===null?p.firstBaseUpdate=d:r.next=d,p.lastBaseUpdate=l))}if(o!==null){var f=n.baseState;s=0,p=d=l=null,r=o;do{var h=r.lane,c=r.eventTime;if((a&h)===h){p!==null&&(p=p.next={eventTime:c,lane:0,tag:r.tag,payload:r.payload,callback:r.callback,next:null});e:{var g=e,m=r;switch(h=t,c=i,m.tag){case 1:if(g=m.payload,typeof g=="function"){f=g.call(c,f,h);break e}f=g;break e;case 3:g.flags=g.flags&-65537|128;case 0:if(g=m.payload,h=typeof g=="function"?g.call(c,f,h):g,h==null)break e;f=Re({},f,h);break e;case 2:Ei=!0}}r.callback!==null&&r.lane!==0&&(e.flags|=64,h=n.effects,h===null?n.effects=[r]:h.push(r))}else c={eventTime:c,lane:h,tag:r.tag,payload:r.payload,callback:r.callback,next:null},p===null?(d=p=c,l=f):p=p.next=c,s|=h;if(r=r.next,r===null){if(r=n.shared.pending,r===null)break;h=r,r=h.next,h.next=null,n.lastBaseUpdate=h,n.shared.pending=null}}while(1);if(p===null&&(l=f),n.baseState=l,n.firstBaseUpdate=d,n.lastBaseUpdate=p,t=n.shared.interleaved,t!==null){n=t;do s|=n.lane,n=n.next;while(n!==t)}else o===null&&(n.shared.lanes=0);ka|=s,e.lanes=s,e.memoizedState=f}}function Nu(e,t,i){if(e=t.effects,t.effects=null,e!==null)for(t=0;t<e.length;t++){var a=e[t],n=a.callback;if(n!==null){if(a.callback=null,a=i,typeof n!="function")throw Error(S(191,n));n.call(a)}}}var Vh=new Kf.Component().refs;function Ad(e,t,i,a){t=e.memoizedState,i=i(a,t),i=i==null?t:Re({},t,i),e.memoizedState=i,e.lanes===0&&(e.updateQueue.baseState=i)}var fr={isMounted:function(e){return(e=e._reactInternals)?Fa(e)===e:!1},enqueueSetState:function(e,t,i){e=e._reactInternals;var a=at(),n=Gi(e),o=gi(a,n);o.payload=t,i!=null&&(o.callback=i),t=Wi(e,o,n),t!==null&&(Ut(t,e,n,a),fs(t,e,n))},enqueueReplaceState:function(e,t,i){e=e._reactInternals;var a=at(),n=Gi(e),o=gi(a,n);o.tag=1,o.payload=t,i!=null&&(o.callback=i),t=Wi(e,o,n),t!==null&&(Ut(t,e,n,a),fs(t,e,n))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var i=at(),a=Gi(e),n=gi(i,a);n.tag=2,t!=null&&(n.callback=t),t=Wi(e,n,a),t!==null&&(Ut(t,e,a,i),fs(t,e,a))}};function Ou(e,t,i,a,n,o,s){return e=e.stateNode,typeof e.shouldComponentUpdate=="function"?e.shouldComponentUpdate(a,o,s):t.prototype&&t.prototype.isPureReactComponent?!uo(i,a)||!uo(n,o):!0}function Xh(e,t,i){var a=!1,n=Vi,o=t.contextType;return typeof o=="object"&&o!==null?o=jt(o):(n=ct(t)?ya:tt.current,a=t.contextTypes,o=(a=a!=null)?on(e,n):Vi),t=new t(i,o),e.memoizedState=t.state!==null&&t.state!==void 0?t.state:null,t.updater=fr,e.stateNode=t,t._reactInternals=e,a&&(e=e.stateNode,e.__reactInternalMemoizedUnmaskedChildContext=n,e.__reactInternalMemoizedMaskedChildContext=o),t}function Lu(e,t,i,a){e=t.state,typeof t.componentWillReceiveProps=="function"&&t.componentWillReceiveProps(i,a),typeof t.UNSAFE_componentWillReceiveProps=="function"&&t.UNSAFE_componentWillReceiveProps(i,a),t.state!==e&&fr.enqueueReplaceState(t,t.state,null)}function jd(e,t,i,a){var n=e.stateNode;n.props=i,n.state=e.memoizedState,n.refs=Vh,Xp(e);var o=t.contextType;typeof o=="object"&&o!==null?n.context=jt(o):(o=ct(t)?ya:tt.current,n.context=on(e,o)),n.state=e.memoizedState,o=t.getDerivedStateFromProps,typeof o=="function"&&(Ad(e,t,o,i),n.state=e.memoizedState),typeof t.getDerivedStateFromProps=="function"||typeof n.getSnapshotBeforeUpdate=="function"||typeof n.UNSAFE_componentWillMount!="function"&&typeof n.componentWillMount!="function"||(t=n.state,typeof n.componentWillMount=="function"&&n.componentWillMount(),typeof n.UNSAFE_componentWillMount=="function"&&n.UNSAFE_componentWillMount(),t!==n.state&&fr.enqueueReplaceState(n,n.state,null),Ws(e,i,n,a),n.state=e.memoizedState),typeof n.componentDidMount=="function"&&(e.flags|=4194308)}function Rn(e,t,i){if(e=i.ref,e!==null&&typeof e!="function"&&typeof e!="object"){if(i._owner){if(i=i._owner,i){if(i.tag!==1)throw Error(S(309));var a=i.stateNode}if(!a)throw Error(S(147,e));var n=a,o=""+e;return t!==null&&t.ref!==null&&typeof t.ref=="function"&&t.ref._stringRef===o?t.ref:(t=function(s){var r=n.refs;r===Vh&&(r=n.refs={}),s===null?delete r[o]:r[o]=s},t._stringRef=o,t)}if(typeof e!="string")throw Error(S(284));if(!i._owner)throw Error(S(290,e))}return e}function Zo(e,t){throw e=Object.prototype.toString.call(t),Error(S(31,e==="[object Object]"?"object with keys {"+Object.keys(t).join(", ")+"}":e))}function Wu(e){var t=e._init;return t(e._payload)}function Yh(e){function t(_,y){if(e){var b=_.deletions;b===null?(_.deletions=[y],_.flags|=16):b.push(y)}}function i(_,y){if(!e)return null;for(;y!==null;)t(_,y),y=y.sibling;return null}function a(_,y){for(_=new Map;y!==null;)y.key!==null?_.set(y.key,y):_.set(y.index,y),y=y.sibling;return _}function n(_,y){return _=Ui(_,y),_.index=0,_.sibling=null,_}function o(_,y,b){return _.index=b,e?(b=_.alternate,b!==null?(b=b.index,b<y?(_.flags|=2,y):b):(_.flags|=2,y)):(_.flags|=1048576,y)}function s(_){return e&&_.alternate===null&&(_.flags|=2),_}function r(_,y,b,v){return y===null||y.tag!==6?(y=zl(b,_.mode,v),y.return=_,y):(y=n(y,b),y.return=_,y)}function l(_,y,b,v){var F=b.type;return F===Ia?p(_,y,b.props.children,v,b.key):y!==null&&(y.elementType===F||typeof F=="object"&&F!==null&&F.$$typeof===Si&&Wu(F)===y.type)?(v=n(y,b.props),v.ref=Rn(_,y,b),v.return=_,v):(v=ks(b.type,b.key,b.props,null,_.mode,v),v.ref=Rn(_,y,b),v.return=_,v)}function d(_,y,b,v){return y===null||y.tag!==4||y.stateNode.containerInfo!==b.containerInfo||y.stateNode.implementation!==b.implementation?(y=Il(b,_.mode,v),y.return=_,y):(y=n(y,b.children||[]),y.return=_,y)}function p(_,y,b,v,F){return y===null||y.tag!==7?(y=ga(b,_.mode,v,F),y.return=_,y):(y=n(y,b),y.return=_,y)}function f(_,y,b){if(typeof y=="string"&&y!==""||typeof y=="number")return y=zl(""+y,_.mode,b),y.return=_,y;if(typeof y=="object"&&y!==null){switch(y.$$typeof){case Wo:return b=ks(y.type,y.key,y.props,null,_.mode,b),b.ref=Rn(_,null,y),b.return=_,b;case za:return y=Il(y,_.mode,b),y.return=_,y;case Si:var v=y._init;return f(_,v(y._payload),b)}if(Ln(y)||xn(y))return y=ga(y,_.mode,b,null),y.return=_,y;Zo(_,y)}return null}function h(_,y,b,v){var F=y!==null?y.key:null;if(typeof b=="string"&&b!==""||typeof b=="number")return F!==null?null:r(_,y,""+b,v);if(typeof b=="object"&&b!==null){switch(b.$$typeof){case Wo:return b.key===F?l(_,y,b,v):null;case za:return b.key===F?d(_,y,b,v):null;case Si:return F=b._init,h(_,y,F(b._payload),v)}if(Ln(b)||xn(b))return F!==null?null:p(_,y,b,v,null);Zo(_,b)}return null}function c(_,y,b,v,F){if(typeof v=="string"&&v!==""||typeof v=="number")return _=_.get(b)||null,r(y,_,""+v,F);if(typeof v=="object"&&v!==null){switch(v.$$typeof){case Wo:return _=_.get(v.key===null?b:v.key)||null,l(y,_,v,F);case za:return _=_.get(v.key===null?b:v.key)||null,d(y,_,v,F);case Si:var T=v._init;return c(_,y,b,T(v._payload),F)}if(Ln(v)||xn(v))return _=_.get(b)||null,p(y,_,v,F,null);Zo(y,v)}return null}function g(_,y,b,v){for(var F=null,T=null,w=y,D=y=0,P=null;w!==null&&D<b.length;D++){w.index>D?(P=w,w=null):P=w.sibling;var R=h(_,w,b[D],v);if(R===null){w===null&&(w=P);break}e&&w&&R.alternate===null&&t(_,w),y=o(R,y,D),T===null?F=R:T.sibling=R,T=R,w=P}if(D===b.length)return i(_,w),xe&&aa(_,D),F;if(w===null){for(;D<b.length;D++)w=f(_,b[D],v),w!==null&&(y=o(w,y,D),T===null?F=w:T.sibling=w,T=w);return xe&&aa(_,D),F}for(w=a(_,w);D<b.length;D++)P=c(w,_,D,b[D],v),P!==null&&(e&&P.alternate!==null&&w.delete(P.key===null?D:P.key),y=o(P,y,D),T===null?F=P:T.sibling=P,T=P);return e&&w.forEach(function(A){return t(_,A)}),xe&&aa(_,D),F}function m(_,y,b,v){var F=xn(b);if(typeof F!="function")throw Error(S(150));if(b=F.call(b),b==null)throw Error(S(151));for(var T=F=null,w=y,D=y=0,P=null,R=b.next();w!==null&&!R.done;D++,R=b.next()){w.index>D?(P=w,w=null):P=w.sibling;var A=h(_,w,R.value,v);if(A===null){w===null&&(w=P);break}e&&w&&A.alternate===null&&t(_,w),y=o(A,y,D),T===null?F=A:T.sibling=A,T=A,w=P}if(R.done)return i(_,w),xe&&aa(_,D),F;if(w===null){for(;!R.done;D++,R=b.next())R=f(_,R.value,v),R!==null&&(y=o(R,y,D),T===null?F=R:T.sibling=R,T=R);return xe&&aa(_,D),F}for(w=a(_,w);!R.done;D++,R=b.next())R=c(w,_,D,R.value,v),R!==null&&(e&&R.alternate!==null&&w.delete(R.key===null?D:R.key),y=o(R,y,D),T===null?F=R:T.sibling=R,T=R);return e&&w.forEach(function(M){return t(_,M)}),xe&&aa(_,D),F}function x(_,y,b,v){if(typeof b=="object"&&b!==null&&b.type===Ia&&b.key===null&&(b=b.props.children),typeof b=="object"&&b!==null){switch(b.$$typeof){case Wo:e:{for(var F=b.key,T=y;T!==null;){if(T.key===F){if(F=b.type,F===Ia){if(T.tag===7){i(_,T.sibling),y=n(T,b.props.children),y.return=_,_=y;break e}}else if(T.elementType===F||typeof F=="object"&&F!==null&&F.$$typeof===Si&&Wu(F)===T.type){i(_,T.sibling),y=n(T,b.props),y.ref=Rn(_,T,b),y.return=_,_=y;break e}i(_,T);break}else t(_,T);T=T.sibling}b.type===Ia?(y=ga(b.props.children,_.mode,v,b.key),y.return=_,_=y):(v=ks(b.type,b.key,b.props,null,_.mode,v),v.ref=Rn(_,y,b),v.return=_,_=v)}return s(_);case za:e:{for(T=b.key;y!==null;){if(y.key===T)if(y.tag===4&&y.stateNode.containerInfo===b.containerInfo&&y.stateNode.implementation===b.implementation){i(_,y.sibling),y=n(y,b.children||[]),y.return=_,_=y;break e}else{i(_,y);break}else t(_,y);y=y.sibling}y=Il(b,_.mode,v),y.return=_,_=y}return s(_);case Si:return T=b._init,x(_,y,T(b._payload),v)}if(Ln(b))return g(_,y,b,v);if(xn(b))return m(_,y,b,v);Zo(_,b)}return typeof b=="string"&&b!==""||typeof b=="number"?(b=""+b,y!==null&&y.tag===6?(i(_,y.sibling),y=n(y,b),y.return=_,_=y):(i(_,y),y=zl(b,_.mode,v),y.return=_,_=y),s(_)):i(_,y)}return x}var rn=Yh(!0),Qh=Yh(!1),So={},ai=Ji(So),go=Ji(So),yo=Ji(So);function ua(e){if(e===So)throw Error(S(174));return e}function Yp(e,t){switch(ye(yo,t),ye(go,e),ye(ai,So),e=t.nodeType,e){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:md(null,"");break;default:e=e===8?t.parentNode:t,t=e.namespaceURI||null,e=e.tagName,t=md(t,e)}be(ai),ye(ai,t)}function ln(){be(ai),be(go),be(yo)}function Jh(e){ua(yo.current);var t=ua(ai.current),i=md(t,e.type);t!==i&&(ye(go,e),ye(ai,i))}function Qp(e){go.current===e&&(be(ai),be(go))}var De=Ji(0);function $s(e){for(var t=e;t!==null;){if(t.tag===13){var i=t.memoizedState;if(i!==null&&(i=i.dehydrated,i===null||i.data==="$?"||i.data==="$!"))return t}else if(t.tag===19&&t.memoizedProps.revealOrder!==void 0){if(t.flags&128)return t}else if(t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var Sl=[];function Jp(){for(var e=0;e<Sl.length;e++)Sl[e]._workInProgressVersionPrimary=null;Sl.length=0}var hs=qi.ReactCurrentDispatcher,El=qi.ReactCurrentBatchConfig,ba=0,Ce=null,Ne=null,Le=null,Gs=!1,Yn=!1,_o=0,E0=0;function Qe(){throw Error(S(321))}function Zp(e,t){if(t===null)return!1;for(var i=0;i<t.length&&i<e.length;i++)if(!Kt(e[i],t[i]))return!1;return!0}function ec(e,t,i,a,n,o){if(ba=o,Ce=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,hs.current=e===null||e.memoizedState===null?M0:z0,e=i(a,n),Yn){o=0;do{if(Yn=!1,_o=0,25<=o)throw Error(S(301));o+=1,Le=Ne=null,t.updateQueue=null,hs.current=I0,e=i(a,n)}while(Yn)}if(hs.current=Us,t=Ne!==null&&Ne.next!==null,ba=0,Le=Ne=Ce=null,Gs=!1,t)throw Error(S(300));return e}function tc(){var e=_o!==0;return _o=0,e}function Yt(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return Le===null?Ce.memoizedState=Le=e:Le=Le.next=e,Le}function Mt(){if(Ne===null){var e=Ce.alternate;e=e!==null?e.memoizedState:null}else e=Ne.next;var t=Le===null?Ce.memoizedState:Le.next;if(t!==null)Le=t,Ne=e;else{if(e===null)throw Error(S(310));Ne=e,e={memoizedState:Ne.memoizedState,baseState:Ne.baseState,baseQueue:Ne.baseQueue,queue:Ne.queue,next:null},Le===null?Ce.memoizedState=Le=e:Le=Le.next=e}return Le}function bo(e,t){return typeof t=="function"?t(e):t}function Bl(e){var t=Mt(),i=t.queue;if(i===null)throw Error(S(311));i.lastRenderedReducer=e;var a=Ne,n=a.baseQueue,o=i.pending;if(o!==null){if(n!==null){var s=n.next;n.next=o.next,o.next=s}a.baseQueue=n=o,i.pending=null}if(n!==null){o=n.next,a=a.baseState;var r=s=null,l=null,d=o;do{var p=d.lane;if((ba&p)===p)l!==null&&(l=l.next={lane:0,action:d.action,hasEagerState:d.hasEagerState,eagerState:d.eagerState,next:null}),a=d.hasEagerState?d.eagerState:e(a,d.action);else{var f={lane:p,action:d.action,hasEagerState:d.hasEagerState,eagerState:d.eagerState,next:null};l===null?(r=l=f,s=a):l=l.next=f,Ce.lanes|=p,ka|=p}d=d.next}while(d!==null&&d!==o);l===null?s=a:l.next=r,Kt(a,t.memoizedState)||(dt=!0),t.memoizedState=a,t.baseState=s,t.baseQueue=l,i.lastRenderedState=a}if(e=i.interleaved,e!==null){n=e;do o=n.lane,Ce.lanes|=o,ka|=o,n=n.next;while(n!==e)}else n===null&&(i.lanes=0);return[t.memoizedState,i.dispatch]}function Al(e){var t=Mt(),i=t.queue;if(i===null)throw Error(S(311));i.lastRenderedReducer=e;var a=i.dispatch,n=i.pending,o=t.memoizedState;if(n!==null){i.pending=null;var s=n=n.next;do o=e(o,s.action),s=s.next;while(s!==n);Kt(o,t.memoizedState)||(dt=!0),t.memoizedState=o,t.baseQueue===null&&(t.baseState=o),i.lastRenderedState=o}return[o,a]}function Zh(){}function eg(e,t){var i=Ce,a=Mt(),n=t(),o=!Kt(a.memoizedState,n);if(o&&(a.memoizedState=n,dt=!0),a=a.queue,ic(ag.bind(null,i,a,e),[e]),a.getSnapshot!==t||o||Le!==null&&Le.memoizedState.tag&1){if(i.flags|=2048,ko(9,ig.bind(null,i,a,n,t),void 0,null),We===null)throw Error(S(349));ba&30||tg(i,t,n)}return n}function tg(e,t,i){e.flags|=16384,e={getSnapshot:t,value:i},t=Ce.updateQueue,t===null?(t={lastEffect:null,stores:null},Ce.updateQueue=t,t.stores=[e]):(i=t.stores,i===null?t.stores=[e]:i.push(e))}function ig(e,t,i,a){t.value=i,t.getSnapshot=a,ng(t)&&og(e)}function ag(e,t,i){return i(function(){ng(t)&&og(e)})}function ng(e){var t=e.getSnapshot;e=e.value;try{var i=t();return!Kt(e,i)}catch{return!0}}function og(e){var t=bi(e,1);t!==null&&Ut(t,e,1,-1)}function $u(e){var t=Yt();return typeof e=="function"&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:bo,lastRenderedState:e},t.queue=e,e=e.dispatch=j0.bind(null,Ce,e),[t.memoizedState,e]}function ko(e,t,i,a){return e={tag:e,create:t,destroy:i,deps:a,next:null},t=Ce.updateQueue,t===null?(t={lastEffect:null,stores:null},Ce.updateQueue=t,t.lastEffect=e.next=e):(i=t.lastEffect,i===null?t.lastEffect=e.next=e:(a=i.next,i.next=e,e.next=a,t.lastEffect=e)),e}function sg(){return Mt().memoizedState}function gs(e,t,i,a){var n=Yt();Ce.flags|=e,n.memoizedState=ko(1|t,i,void 0,a===void 0?null:a)}function hr(e,t,i,a){var n=Mt();a=a===void 0?null:a;var o=void 0;if(Ne!==null){var s=Ne.memoizedState;if(o=s.destroy,a!==null&&Zp(a,s.deps)){n.memoizedState=ko(t,i,o,a);return}}Ce.flags|=e,n.memoizedState=ko(1|t,i,o,a)}function Gu(e,t){return gs(8390656,8,e,t)}function ic(e,t){return hr(2048,8,e,t)}function rg(e,t){return hr(4,2,e,t)}function lg(e,t){return hr(4,4,e,t)}function dg(e,t){if(typeof t=="function")return e=e(),t(e),function(){t(null)};if(t!=null)return e=e(),t.current=e,function(){t.current=null}}function pg(e,t,i){return i=i!=null?i.concat([e]):null,hr(4,4,dg.bind(null,t,e),i)}function ac(){}function cg(e,t){var i=Mt();t=t===void 0?null:t;var a=i.memoizedState;return a!==null&&t!==null&&Zp(t,a[1])?a[0]:(i.memoizedState=[e,t],e)}function ug(e,t){var i=Mt();t=t===void 0?null:t;var a=i.memoizedState;return a!==null&&t!==null&&Zp(t,a[1])?a[0]:(e=e(),i.memoizedState=[e,t],e)}function mg(e,t,i){return ba&21?(Kt(i,t)||(i=gh(),Ce.lanes|=i,ka|=i,e.baseState=!0),t):(e.baseState&&(e.baseState=!1,dt=!0),e.memoizedState=i)}function B0(e,t){var i=le;le=i!==0&&4>i?i:4,e(!0);var a=El.transition;El.transition={};try{e(!1),t()}finally{le=i,El.transition=a}}function fg(){return Mt().memoizedState}function A0(e,t,i){var a=Gi(e);if(i={lane:a,action:i,hasEagerState:!1,eagerState:null,next:null},hg(e))gg(t,i);else if(i=Kh(e,t,i,a),i!==null){var n=at();Ut(i,e,a,n),yg(i,t,a)}}function j0(e,t,i){var a=Gi(e),n={lane:a,action:i,hasEagerState:!1,eagerState:null,next:null};if(hg(e))gg(t,n);else{var o=e.alternate;if(e.lanes===0&&(o===null||o.lanes===0)&&(o=t.lastRenderedReducer,o!==null))try{var s=t.lastRenderedState,r=o(s,i);if(n.hasEagerState=!0,n.eagerState=r,Kt(r,s)){var l=t.interleaved;l===null?(n.next=n,Vp(t)):(n.next=l.next,l.next=n),t.interleaved=n;return}}catch{}finally{}i=Kh(e,t,n,a),i!==null&&(n=at(),Ut(i,e,a,n),yg(i,t,a))}}function hg(e){var t=e.alternate;return e===Ce||t!==null&&t===Ce}function gg(e,t){Yn=Gs=!0;var i=e.pending;i===null?t.next=t:(t.next=i.next,i.next=t),e.pending=t}function yg(e,t,i){if(i&4194240){var a=t.lanes;a&=e.pendingLanes,i|=a,t.lanes=i,Ap(e,i)}}var Us={readContext:jt,useCallback:Qe,useContext:Qe,useEffect:Qe,useImperativeHandle:Qe,useInsertionEffect:Qe,useLayoutEffect:Qe,useMemo:Qe,useReducer:Qe,useRef:Qe,useState:Qe,useDebugValue:Qe,useDeferredValue:Qe,useTransition:Qe,useMutableSource:Qe,useSyncExternalStore:Qe,useId:Qe,unstable_isNewReconciler:!1},M0={readContext:jt,useCallback:function(e,t){return Yt().memoizedState=[e,t===void 0?null:t],e},useContext:jt,useEffect:Gu,useImperativeHandle:function(e,t,i){return i=i!=null?i.concat([e]):null,gs(4194308,4,dg.bind(null,t,e),i)},useLayoutEffect:function(e,t){return gs(4194308,4,e,t)},useInsertionEffect:function(e,t){return gs(4,2,e,t)},useMemo:function(e,t){var i=Yt();return t=t===void 0?null:t,e=e(),i.memoizedState=[e,t],e},useReducer:function(e,t,i){var a=Yt();return t=i!==void 0?i(t):t,a.memoizedState=a.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},a.queue=e,e=e.dispatch=A0.bind(null,Ce,e),[a.memoizedState,e]},useRef:function(e){var t=Yt();return e={current:e},t.memoizedState=e},useState:$u,useDebugValue:ac,useDeferredValue:function(e){return Yt().memoizedState=e},useTransition:function(){var e=$u(!1),t=e[0];return e=B0.bind(null,e[1]),Yt().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,i){var a=Ce,n=Yt();if(xe){if(i===void 0)throw Error(S(407));i=i()}else{if(i=t(),We===null)throw Error(S(349));ba&30||tg(a,t,i)}n.memoizedState=i;var o={value:i,getSnapshot:t};return n.queue=o,Gu(ag.bind(null,a,o,e),[e]),a.flags|=2048,ko(9,ig.bind(null,a,o,i,t),void 0,null),i},useId:function(){var e=Yt(),t=We.identifierPrefix;if(xe){var i=fi,a=mi;i=(a&~(1<<32-Gt(a)-1)).toString(32)+i,t=":"+t+"R"+i,i=_o++,0<i&&(t+="H"+i.toString(32)),t+=":"}else i=E0++,t=":"+t+"r"+i.toString(32)+":";return e.memoizedState=t},unstable_isNewReconciler:!1},z0={readContext:jt,useCallback:cg,useContext:jt,useEffect:ic,useImperativeHandle:pg,useInsertionEffect:rg,useLayoutEffect:lg,useMemo:ug,useReducer:Bl,useRef:sg,useState:function(){return Bl(bo)},useDebugValue:ac,useDeferredValue:function(e){var t=Mt();return mg(t,Ne.memoizedState,e)},useTransition:function(){var e=Bl(bo)[0],t=Mt().memoizedState;return[e,t]},useMutableSource:Zh,useSyncExternalStore:eg,useId:fg,unstable_isNewReconciler:!1},I0={readContext:jt,useCallback:cg,useContext:jt,useEffect:ic,useImperativeHandle:pg,useInsertionEffect:rg,useLayoutEffect:lg,useMemo:ug,useReducer:Al,useRef:sg,useState:function(){return Al(bo)},useDebugValue:ac,useDeferredValue:function(e){var t=Mt();return Ne===null?t.memoizedState=e:mg(t,Ne.memoizedState,e)},useTransition:function(){var e=Al(bo)[0],t=Mt().memoizedState;return[e,t]},useMutableSource:Zh,useSyncExternalStore:eg,useId:fg,unstable_isNewReconciler:!1};function dn(e,t){try{var i="",a=t;do i+=ub(a),a=a.return;while(a);var n=i}catch(o){n=`
Error generating stack: `+o.message+`
`+o.stack}return{value:e,source:t,stack:n,digest:null}}function jl(e,t,i){return{value:e,source:null,stack:i??null,digest:t??null}}function Md(e,t){try{console.error(t.value)}catch(i){setTimeout(function(){throw i})}}var N0=typeof WeakMap=="function"?WeakMap:Map;function _g(e,t,i){i=gi(-1,i),i.tag=3,i.payload={element:null};var a=t.value;return i.callback=function(){Hs||(Hs=!0,Kd=a),Md(e,t)},i}function bg(e,t,i){i=gi(-1,i),i.tag=3;var a=e.type.getDerivedStateFromError;if(typeof a=="function"){var n=t.value;i.payload=function(){return a(n)},i.callback=function(){Md(e,t)}}var o=e.stateNode;return o!==null&&typeof o.componentDidCatch=="function"&&(i.callback=function(){Md(e,t),typeof a!="function"&&($i===null?$i=new Set([this]):$i.add(this));var s=t.stack;this.componentDidCatch(t.value,{componentStack:s!==null?s:""})}),i}function Uu(e,t,i){var a=e.pingCache;if(a===null){a=e.pingCache=new N0;var n=new Set;a.set(t,n)}else n=a.get(t),n===void 0&&(n=new Set,a.set(t,n));n.has(i)||(n.add(i),e=Z0.bind(null,e,t,i),t.then(e,e))}function Ku(e){do{var t;if((t=e.tag===13)&&(t=e.memoizedState,t=t!==null?t.dehydrated!==null:!0),t)return e;e=e.return}while(e!==null);return null}function Hu(e,t,i,a,n){return e.mode&1?(e.flags|=65536,e.lanes=n,e):(e===t?e.flags|=65536:(e.flags|=128,i.flags|=131072,i.flags&=-52805,i.tag===1&&(i.alternate===null?i.tag=17:(t=gi(-1,1),t.tag=2,Wi(i,t,1))),i.lanes|=1),e)}var O0=qi.ReactCurrentOwner,dt=!1;function it(e,t,i,a){t.child=e===null?Qh(t,null,i,a):rn(t,e.child,i,a)}function Vu(e,t,i,a,n){i=i.render;var o=t.ref;return Za(t,n),a=ec(e,t,i,a,o,n),i=tc(),e!==null&&!dt?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~n,ki(e,t,n)):(xe&&i&&Wp(t),t.flags|=1,it(e,t,a,n),t.child)}function Xu(e,t,i,a,n){if(e===null){var o=i.type;return typeof o=="function"&&!cc(o)&&o.defaultProps===void 0&&i.compare===null&&i.defaultProps===void 0?(t.tag=15,t.type=o,kg(e,t,o,a,n)):(e=ks(i.type,null,a,t,t.mode,n),e.ref=t.ref,e.return=t,t.child=e)}if(o=e.child,!(e.lanes&n)){var s=o.memoizedProps;if(i=i.compare,i=i!==null?i:uo,i(s,a)&&e.ref===t.ref)return ki(e,t,n)}return t.flags|=1,e=Ui(o,a),e.ref=t.ref,e.return=t,t.child=e}function kg(e,t,i,a,n){if(e!==null){var o=e.memoizedProps;if(uo(o,a)&&e.ref===t.ref)if(dt=!1,t.pendingProps=a=o,(e.lanes&n)!==0)e.flags&131072&&(dt=!0);else return t.lanes=e.lanes,ki(e,t,n)}return zd(e,t,i,a,n)}function vg(e,t,i){var a=t.pendingProps,n=a.children,o=e!==null?e.memoizedState:null;if(a.mode==="hidden")if(!(t.mode&1))t.memoizedState={baseLanes:0,cachePool:null,transitions:null},ye(Va,ht),ht|=i;else{if(!(i&1073741824))return e=o!==null?o.baseLanes|i:i,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,ye(Va,ht),ht|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},a=o!==null?o.baseLanes:i,ye(Va,ht),ht|=a}else o!==null?(a=o.baseLanes|i,t.memoizedState=null):a=i,ye(Va,ht),ht|=a;return it(e,t,n,i),t.child}function wg(e,t){var i=t.ref;(e===null&&i!==null||e!==null&&e.ref!==i)&&(t.flags|=512,t.flags|=2097152)}function zd(e,t,i,a,n){var o=ct(i)?ya:tt.current;return o=on(t,o),Za(t,n),i=ec(e,t,i,a,o,n),a=tc(),e!==null&&!dt?(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~n,ki(e,t,n)):(xe&&a&&Wp(t),t.flags|=1,it(e,t,i,n),t.child)}function Yu(e,t,i,a,n){if(ct(i)){var o=!0;zs(t)}else o=!1;if(Za(t,n),t.stateNode===null)ys(e,t),Xh(t,i,a),jd(t,i,a,n),a=!0;else if(e===null){var s=t.stateNode,r=t.memoizedProps;s.props=r;var l=s.context,d=i.contextType;typeof d=="object"&&d!==null?d=jt(d):(d=ct(i)?ya:tt.current,d=on(t,d));var p=i.getDerivedStateFromProps,f=typeof p=="function"||typeof s.getSnapshotBeforeUpdate=="function";f||typeof s.UNSAFE_componentWillReceiveProps!="function"&&typeof s.componentWillReceiveProps!="function"||(r!==a||l!==d)&&Lu(t,s,a,d),Ei=!1;var h=t.memoizedState;s.state=h,Ws(t,a,s,n),l=t.memoizedState,r!==a||h!==l||pt.current||Ei?(typeof p=="function"&&(Ad(t,i,p,a),l=t.memoizedState),(r=Ei||Ou(t,i,r,a,h,l,d))?(f||typeof s.UNSAFE_componentWillMount!="function"&&typeof s.componentWillMount!="function"||(typeof s.componentWillMount=="function"&&s.componentWillMount(),typeof s.UNSAFE_componentWillMount=="function"&&s.UNSAFE_componentWillMount()),typeof s.componentDidMount=="function"&&(t.flags|=4194308)):(typeof s.componentDidMount=="function"&&(t.flags|=4194308),t.memoizedProps=a,t.memoizedState=l),s.props=a,s.state=l,s.context=d,a=r):(typeof s.componentDidMount=="function"&&(t.flags|=4194308),a=!1)}else{s=t.stateNode,Hh(e,t),r=t.memoizedProps,d=t.type===t.elementType?r:Ot(t.type,r),s.props=d,f=t.pendingProps,h=s.context,l=i.contextType,typeof l=="object"&&l!==null?l=jt(l):(l=ct(i)?ya:tt.current,l=on(t,l));var c=i.getDerivedStateFromProps;(p=typeof c=="function"||typeof s.getSnapshotBeforeUpdate=="function")||typeof s.UNSAFE_componentWillReceiveProps!="function"&&typeof s.componentWillReceiveProps!="function"||(r!==f||h!==l)&&Lu(t,s,a,l),Ei=!1,h=t.memoizedState,s.state=h,Ws(t,a,s,n);var g=t.memoizedState;r!==f||h!==g||pt.current||Ei?(typeof c=="function"&&(Ad(t,i,c,a),g=t.memoizedState),(d=Ei||Ou(t,i,d,a,h,g,l)||!1)?(p||typeof s.UNSAFE_componentWillUpdate!="function"&&typeof s.componentWillUpdate!="function"||(typeof s.componentWillUpdate=="function"&&s.componentWillUpdate(a,g,l),typeof s.UNSAFE_componentWillUpdate=="function"&&s.UNSAFE_componentWillUpdate(a,g,l)),typeof s.componentDidUpdate=="function"&&(t.flags|=4),typeof s.getSnapshotBeforeUpdate=="function"&&(t.flags|=1024)):(typeof s.componentDidUpdate!="function"||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=4),typeof s.getSnapshotBeforeUpdate!="function"||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=1024),t.memoizedProps=a,t.memoizedState=g),s.props=a,s.state=g,s.context=l,a=d):(typeof s.componentDidUpdate!="function"||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=4),typeof s.getSnapshotBeforeUpdate!="function"||r===e.memoizedProps&&h===e.memoizedState||(t.flags|=1024),a=!1)}return Id(e,t,i,a,o,n)}function Id(e,t,i,a,n,o){wg(e,t);var s=(t.flags&128)!==0;if(!a&&!s)return n&&ju(t,i,!1),ki(e,t,o);a=t.stateNode,O0.current=t;var r=s&&typeof i.getDerivedStateFromError!="function"?null:a.render();return t.flags|=1,e!==null&&s?(t.child=rn(t,e.child,null,o),t.child=rn(t,null,r,o)):it(e,t,r,o),t.memoizedState=a.state,n&&ju(t,i,!0),t.child}function qg(e){var t=e.stateNode;t.pendingContext?Au(e,t.pendingContext,t.pendingContext!==t.context):t.context&&Au(e,t.context,!1),Yp(e,t.containerInfo)}function Qu(e,t,i,a,n){return sn(),Gp(n),t.flags|=256,it(e,t,i,a),t.child}var Nd={dehydrated:null,treeContext:null,retryLane:0};function Od(e){return{baseLanes:e,cachePool:null,transitions:null}}function xg(e,t,i){var a=t.pendingProps,n=De.current,o=!1,s=(t.flags&128)!==0,r;if((r=s)||(r=e!==null&&e.memoizedState===null?!1:(n&2)!==0),r?(o=!0,t.flags&=-129):(e===null||e.memoizedState!==null)&&(n|=1),ye(De,n&1),e===null)return Ed(t),e=t.memoizedState,e!==null&&(e=e.dehydrated,e!==null)?(t.mode&1?e.data==="$!"?t.lanes=8:t.lanes=1073741824:t.lanes=1,null):(s=a.children,e=a.fallback,o?(a=t.mode,o=t.child,s={mode:"hidden",children:s},!(a&1)&&o!==null?(o.childLanes=0,o.pendingProps=s):o=_r(s,a,0,null),e=ga(e,a,i,null),o.return=t,e.return=t,o.sibling=e,t.child=o,t.child.memoizedState=Od(i),t.memoizedState=Nd,e):nc(t,s));if(n=e.memoizedState,n!==null&&(r=n.dehydrated,r!==null))return L0(e,t,s,a,r,n,i);if(o){o=a.fallback,s=t.mode,n=e.child,r=n.sibling;var l={mode:"hidden",children:a.children};return!(s&1)&&t.child!==n?(a=t.child,a.childLanes=0,a.pendingProps=l,t.deletions=null):(a=Ui(n,l),a.subtreeFlags=n.subtreeFlags&14680064),r!==null?o=Ui(r,o):(o=ga(o,s,i,null),o.flags|=2),o.return=t,a.return=t,a.sibling=o,t.child=a,a=o,o=t.child,s=e.child.memoizedState,s=s===null?Od(i):{baseLanes:s.baseLanes|i,cachePool:null,transitions:s.transitions},o.memoizedState=s,o.childLanes=e.childLanes&~i,t.memoizedState=Nd,a}return o=e.child,e=o.sibling,a=Ui(o,{mode:"visible",children:a.children}),!(t.mode&1)&&(a.lanes=i),a.return=t,a.sibling=null,e!==null&&(i=t.deletions,i===null?(t.deletions=[e],t.flags|=16):i.push(e)),t.child=a,t.memoizedState=null,a}function nc(e,t){return t=_r({mode:"visible",children:t},e.mode,0,null),t.return=e,e.child=t}function es(e,t,i,a){return a!==null&&Gp(a),rn(t,e.child,null,i),e=nc(t,t.pendingProps.children),e.flags|=2,t.memoizedState=null,e}function L0(e,t,i,a,n,o,s){if(i)return t.flags&256?(t.flags&=-257,a=jl(Error(S(422))),es(e,t,s,a)):t.memoizedState!==null?(t.child=e.child,t.flags|=128,null):(o=a.fallback,n=t.mode,a=_r({mode:"visible",children:a.children},n,0,null),o=ga(o,n,s,null),o.flags|=2,a.return=t,o.return=t,a.sibling=o,t.child=a,t.mode&1&&rn(t,e.child,null,s),t.child.memoizedState=Od(s),t.memoizedState=Nd,o);if(!(t.mode&1))return es(e,t,s,null);if(n.data==="$!"){if(a=n.nextSibling&&n.nextSibling.dataset,a)var r=a.dgst;return a=r,o=Error(S(419)),a=jl(o,a,void 0),es(e,t,s,a)}if(r=(s&e.childLanes)!==0,dt||r){if(a=We,a!==null){switch(s&-s){case 4:n=2;break;case 16:n=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:n=32;break;case 536870912:n=268435456;break;default:n=0}n=n&(a.suspendedLanes|s)?0:n,n!==0&&n!==o.retryLane&&(o.retryLane=n,bi(e,n),Ut(a,e,n,-1))}return pc(),a=jl(Error(S(421))),es(e,t,s,a)}return n.data==="$?"?(t.flags|=128,t.child=e.child,t=e1.bind(null,e),n._reactRetry=t,null):(e=o.treeContext,_t=Li(n.nextSibling),bt=t,xe=!0,Wt=null,e!==null&&(Pt[St++]=mi,Pt[St++]=fi,Pt[St++]=_a,mi=e.id,fi=e.overflow,_a=t),t=nc(t,a.children),t.flags|=4096,t)}function Ju(e,t,i){e.lanes|=t;var a=e.alternate;a!==null&&(a.lanes|=t),Bd(e.return,t,i)}function Ml(e,t,i,a,n){var o=e.memoizedState;o===null?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:a,tail:i,tailMode:n}:(o.isBackwards=t,o.rendering=null,o.renderingStartTime=0,o.last=a,o.tail=i,o.tailMode=n)}function Fg(e,t,i){var a=t.pendingProps,n=a.revealOrder,o=a.tail;if(it(e,t,a.children,i),a=De.current,a&2)a=a&1|2,t.flags|=128;else{if(e!==null&&e.flags&128)e:for(e=t.child;e!==null;){if(e.tag===13)e.memoizedState!==null&&Ju(e,i,t);else if(e.tag===19)Ju(e,i,t);else if(e.child!==null){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;e.sibling===null;){if(e.return===null||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}a&=1}if(ye(De,a),!(t.mode&1))t.memoizedState=null;else switch(n){case"forwards":for(i=t.child,n=null;i!==null;)e=i.alternate,e!==null&&$s(e)===null&&(n=i),i=i.sibling;i=n,i===null?(n=t.child,t.child=null):(n=i.sibling,i.sibling=null),Ml(t,!1,n,i,o);break;case"backwards":for(i=null,n=t.child,t.child=null;n!==null;){if(e=n.alternate,e!==null&&$s(e)===null){t.child=n;break}e=n.sibling,n.sibling=i,i=n,n=e}Ml(t,!0,i,null,o);break;case"together":Ml(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function ys(e,t){!(t.mode&1)&&e!==null&&(e.alternate=null,t.alternate=null,t.flags|=2)}function ki(e,t,i){if(e!==null&&(t.dependencies=e.dependencies),ka|=t.lanes,!(i&t.childLanes))return null;if(e!==null&&t.child!==e.child)throw Error(S(153));if(t.child!==null){for(e=t.child,i=Ui(e,e.pendingProps),t.child=i,i.return=t;e.sibling!==null;)e=e.sibling,i=i.sibling=Ui(e,e.pendingProps),i.return=t;i.sibling=null}return t.child}function W0(e,t,i){switch(t.tag){case 3:qg(t),sn();break;case 5:Jh(t);break;case 1:ct(t.type)&&zs(t);break;case 4:Yp(t,t.stateNode.containerInfo);break;case 10:var a=t.type._context,n=t.memoizedProps.value;ye(Os,a._currentValue),a._currentValue=n;break;case 13:if(a=t.memoizedState,a!==null)return a.dehydrated!==null?(ye(De,De.current&1),t.flags|=128,null):i&t.child.childLanes?xg(e,t,i):(ye(De,De.current&1),e=ki(e,t,i),e!==null?e.sibling:null);ye(De,De.current&1);break;case 19:if(a=(i&t.childLanes)!==0,e.flags&128){if(a)return Fg(e,t,i);t.flags|=128}if(n=t.memoizedState,n!==null&&(n.rendering=null,n.tail=null,n.lastEffect=null),ye(De,De.current),a)break;return null;case 22:case 23:return t.lanes=0,vg(e,t,i)}return ki(e,t,i)}var Tg,Ld,Dg,Cg;Tg=function(e,t){for(var i=t.child;i!==null;){if(i.tag===5||i.tag===6)e.appendChild(i.stateNode);else if(i.tag!==4&&i.child!==null){i.child.return=i,i=i.child;continue}if(i===t)break;for(;i.sibling===null;){if(i.return===null||i.return===t)return;i=i.return}i.sibling.return=i.return,i=i.sibling}};Ld=function(){};Dg=function(e,t,i,a){var n=e.memoizedProps;if(n!==a){e=t.stateNode,ua(ai.current);var o=null;switch(i){case"input":n=dd(e,n),a=dd(e,a),o=[];break;case"select":n=Re({},n,{value:void 0}),a=Re({},a,{value:void 0}),o=[];break;case"textarea":n=ud(e,n),a=ud(e,a),o=[];break;default:typeof n.onClick!="function"&&typeof a.onClick=="function"&&(e.onclick=js)}fd(i,a);var s;i=null;for(d in n)if(!a.hasOwnProperty(d)&&n.hasOwnProperty(d)&&n[d]!=null)if(d==="style"){var r=n[d];for(s in r)r.hasOwnProperty(s)&&(i||(i={}),i[s]="")}else d!=="dangerouslySetInnerHTML"&&d!=="children"&&d!=="suppressContentEditableWarning"&&d!=="suppressHydrationWarning"&&d!=="autoFocus"&&(no.hasOwnProperty(d)?o||(o=[]):(o=o||[]).push(d,null));for(d in a){var l=a[d];if(r=n!=null?n[d]:void 0,a.hasOwnProperty(d)&&l!==r&&(l!=null||r!=null))if(d==="style")if(r){for(s in r)!r.hasOwnProperty(s)||l&&l.hasOwnProperty(s)||(i||(i={}),i[s]="");for(s in l)l.hasOwnProperty(s)&&r[s]!==l[s]&&(i||(i={}),i[s]=l[s])}else i||(o||(o=[]),o.push(d,i)),i=l;else d==="dangerouslySetInnerHTML"?(l=l?l.__html:void 0,r=r?r.__html:void 0,l!=null&&r!==l&&(o=o||[]).push(d,l)):d==="children"?typeof l!="string"&&typeof l!="number"||(o=o||[]).push(d,""+l):d!=="suppressContentEditableWarning"&&d!=="suppressHydrationWarning"&&(no.hasOwnProperty(d)?(l!=null&&d==="onScroll"&&_e("scroll",e),o||r===l||(o=[])):(o=o||[]).push(d,l))}i&&(o=o||[]).push("style",i);var d=o;(t.updateQueue=d)&&(t.flags|=4)}};Cg=function(e,t,i,a){i!==a&&(t.flags|=4)};function Pn(e,t){if(!xe)switch(e.tailMode){case"hidden":t=e.tail;for(var i=null;t!==null;)t.alternate!==null&&(i=t),t=t.sibling;i===null?e.tail=null:i.sibling=null;break;case"collapsed":i=e.tail;for(var a=null;i!==null;)i.alternate!==null&&(a=i),i=i.sibling;a===null?t||e.tail===null?e.tail=null:e.tail.sibling=null:a.sibling=null}}function Je(e){var t=e.alternate!==null&&e.alternate.child===e.child,i=0,a=0;if(t)for(var n=e.child;n!==null;)i|=n.lanes|n.childLanes,a|=n.subtreeFlags&14680064,a|=n.flags&14680064,n.return=e,n=n.sibling;else for(n=e.child;n!==null;)i|=n.lanes|n.childLanes,a|=n.subtreeFlags,a|=n.flags,n.return=e,n=n.sibling;return e.subtreeFlags|=a,e.childLanes=i,t}function $0(e,t,i){var a=t.pendingProps;switch($p(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return Je(t),null;case 1:return ct(t.type)&&Ms(),Je(t),null;case 3:return a=t.stateNode,ln(),be(pt),be(tt),Jp(),a.pendingContext&&(a.context=a.pendingContext,a.pendingContext=null),(e===null||e.child===null)&&(Jo(t)?t.flags|=4:e===null||e.memoizedState.isDehydrated&&!(t.flags&256)||(t.flags|=1024,Wt!==null&&(Xd(Wt),Wt=null))),Ld(e,t),Je(t),null;case 5:Qp(t);var n=ua(yo.current);if(i=t.type,e!==null&&t.stateNode!=null)Dg(e,t,i,a,n),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!a){if(t.stateNode===null)throw Error(S(166));return Je(t),null}if(e=ua(ai.current),Jo(t)){a=t.stateNode,i=t.type;var o=t.memoizedProps;switch(a[Zt]=t,a[ho]=o,e=(t.mode&1)!==0,i){case"dialog":_e("cancel",a),_e("close",a);break;case"iframe":case"object":case"embed":_e("load",a);break;case"video":case"audio":for(n=0;n<$n.length;n++)_e($n[n],a);break;case"source":_e("error",a);break;case"img":case"image":case"link":_e("error",a),_e("load",a);break;case"details":_e("toggle",a);break;case"input":ru(a,o),_e("invalid",a);break;case"select":a._wrapperState={wasMultiple:!!o.multiple},_e("invalid",a);break;case"textarea":du(a,o),_e("invalid",a)}fd(i,o),n=null;for(var s in o)if(o.hasOwnProperty(s)){var r=o[s];s==="children"?typeof r=="string"?a.textContent!==r&&(o.suppressHydrationWarning!==!0&&Qo(a.textContent,r,e),n=["children",r]):typeof r=="number"&&a.textContent!==""+r&&(o.suppressHydrationWarning!==!0&&Qo(a.textContent,r,e),n=["children",""+r]):no.hasOwnProperty(s)&&r!=null&&s==="onScroll"&&_e("scroll",a)}switch(i){case"input":$o(a),lu(a,o,!0);break;case"textarea":$o(a),pu(a);break;case"select":case"option":break;default:typeof o.onClick=="function"&&(a.onclick=js)}a=n,t.updateQueue=a,a!==null&&(t.flags|=4)}else{s=n.nodeType===9?n:n.ownerDocument,e==="http://www.w3.org/1999/xhtml"&&(e=th(i)),e==="http://www.w3.org/1999/xhtml"?i==="script"?(e=s.createElement("div"),e.innerHTML="<script><\/script>",e=e.removeChild(e.firstChild)):typeof a.is=="string"?e=s.createElement(i,{is:a.is}):(e=s.createElement(i),i==="select"&&(s=e,a.multiple?s.multiple=!0:a.size&&(s.size=a.size))):e=s.createElementNS(e,i),e[Zt]=t,e[ho]=a,Tg(e,t,!1,!1),t.stateNode=e;e:{switch(s=hd(i,a),i){case"dialog":_e("cancel",e),_e("close",e),n=a;break;case"iframe":case"object":case"embed":_e("load",e),n=a;break;case"video":case"audio":for(n=0;n<$n.length;n++)_e($n[n],e);n=a;break;case"source":_e("error",e),n=a;break;case"img":case"image":case"link":_e("error",e),_e("load",e),n=a;break;case"details":_e("toggle",e),n=a;break;case"input":ru(e,a),n=dd(e,a),_e("invalid",e);break;case"option":n=a;break;case"select":e._wrapperState={wasMultiple:!!a.multiple},n=Re({},a,{value:void 0}),_e("invalid",e);break;case"textarea":du(e,a),n=ud(e,a),_e("invalid",e);break;default:n=a}fd(i,n),r=n;for(o in r)if(r.hasOwnProperty(o)){var l=r[o];o==="style"?nh(e,l):o==="dangerouslySetInnerHTML"?(l=l?l.__html:void 0,l!=null&&ih(e,l)):o==="children"?typeof l=="string"?(i!=="textarea"||l!=="")&&oo(e,l):typeof l=="number"&&oo(e,""+l):o!=="suppressContentEditableWarning"&&o!=="suppressHydrationWarning"&&o!=="autoFocus"&&(no.hasOwnProperty(o)?l!=null&&o==="onScroll"&&_e("scroll",e):l!=null&&Cp(e,o,l,s))}switch(i){case"input":$o(e),lu(e,a,!1);break;case"textarea":$o(e),pu(e);break;case"option":a.value!=null&&e.setAttribute("value",""+Hi(a.value));break;case"select":e.multiple=!!a.multiple,o=a.value,o!=null?Xa(e,!!a.multiple,o,!1):a.defaultValue!=null&&Xa(e,!!a.multiple,a.defaultValue,!0);break;default:typeof n.onClick=="function"&&(e.onclick=js)}switch(i){case"button":case"input":case"select":case"textarea":a=!!a.autoFocus;break e;case"img":a=!0;break e;default:a=!1}}a&&(t.flags|=4)}t.ref!==null&&(t.flags|=512,t.flags|=2097152)}return Je(t),null;case 6:if(e&&t.stateNode!=null)Cg(e,t,e.memoizedProps,a);else{if(typeof a!="string"&&t.stateNode===null)throw Error(S(166));if(i=ua(yo.current),ua(ai.current),Jo(t)){if(a=t.stateNode,i=t.memoizedProps,a[Zt]=t,(o=a.nodeValue!==i)&&(e=bt,e!==null))switch(e.tag){case 3:Qo(a.nodeValue,i,(e.mode&1)!==0);break;case 5:e.memoizedProps.suppressHydrationWarning!==!0&&Qo(a.nodeValue,i,(e.mode&1)!==0)}o&&(t.flags|=4)}else a=(i.nodeType===9?i:i.ownerDocument).createTextNode(a),a[Zt]=t,t.stateNode=a}return Je(t),null;case 13:if(be(De),a=t.memoizedState,e===null||e.memoizedState!==null&&e.memoizedState.dehydrated!==null){if(xe&&_t!==null&&t.mode&1&&!(t.flags&128))Uh(),sn(),t.flags|=98560,o=!1;else if(o=Jo(t),a!==null&&a.dehydrated!==null){if(e===null){if(!o)throw Error(S(318));if(o=t.memoizedState,o=o!==null?o.dehydrated:null,!o)throw Error(S(317));o[Zt]=t}else sn(),!(t.flags&128)&&(t.memoizedState=null),t.flags|=4;Je(t),o=!1}else Wt!==null&&(Xd(Wt),Wt=null),o=!0;if(!o)return t.flags&65536?t:null}return t.flags&128?(t.lanes=i,t):(a=a!==null,a!==(e!==null&&e.memoizedState!==null)&&a&&(t.child.flags|=8192,t.mode&1&&(e===null||De.current&1?Oe===0&&(Oe=3):pc())),t.updateQueue!==null&&(t.flags|=4),Je(t),null);case 4:return ln(),Ld(e,t),e===null&&mo(t.stateNode.containerInfo),Je(t),null;case 10:return Hp(t.type._context),Je(t),null;case 17:return ct(t.type)&&Ms(),Je(t),null;case 19:if(be(De),o=t.memoizedState,o===null)return Je(t),null;if(a=(t.flags&128)!==0,s=o.rendering,s===null)if(a)Pn(o,!1);else{if(Oe!==0||e!==null&&e.flags&128)for(e=t.child;e!==null;){if(s=$s(e),s!==null){for(t.flags|=128,Pn(o,!1),a=s.updateQueue,a!==null&&(t.updateQueue=a,t.flags|=4),t.subtreeFlags=0,a=i,i=t.child;i!==null;)o=i,e=a,o.flags&=14680066,s=o.alternate,s===null?(o.childLanes=0,o.lanes=e,o.child=null,o.subtreeFlags=0,o.memoizedProps=null,o.memoizedState=null,o.updateQueue=null,o.dependencies=null,o.stateNode=null):(o.childLanes=s.childLanes,o.lanes=s.lanes,o.child=s.child,o.subtreeFlags=0,o.deletions=null,o.memoizedProps=s.memoizedProps,o.memoizedState=s.memoizedState,o.updateQueue=s.updateQueue,o.type=s.type,e=s.dependencies,o.dependencies=e===null?null:{lanes:e.lanes,firstContext:e.firstContext}),i=i.sibling;return ye(De,De.current&1|2),t.child}e=e.sibling}o.tail!==null&&je()>pn&&(t.flags|=128,a=!0,Pn(o,!1),t.lanes=4194304)}else{if(!a)if(e=$s(s),e!==null){if(t.flags|=128,a=!0,i=e.updateQueue,i!==null&&(t.updateQueue=i,t.flags|=4),Pn(o,!0),o.tail===null&&o.tailMode==="hidden"&&!s.alternate&&!xe)return Je(t),null}else 2*je()-o.renderingStartTime>pn&&i!==1073741824&&(t.flags|=128,a=!0,Pn(o,!1),t.lanes=4194304);o.isBackwards?(s.sibling=t.child,t.child=s):(i=o.last,i!==null?i.sibling=s:t.child=s,o.last=s)}return o.tail!==null?(t=o.tail,o.rendering=t,o.tail=t.sibling,o.renderingStartTime=je(),t.sibling=null,i=De.current,ye(De,a?i&1|2:i&1),t):(Je(t),null);case 22:case 23:return dc(),a=t.memoizedState!==null,e!==null&&e.memoizedState!==null!==a&&(t.flags|=8192),a&&t.mode&1?ht&1073741824&&(Je(t),t.subtreeFlags&6&&(t.flags|=8192)):Je(t),null;case 24:return null;case 25:return null}throw Error(S(156,t.tag))}function G0(e,t){switch($p(t),t.tag){case 1:return ct(t.type)&&Ms(),e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 3:return ln(),be(pt),be(tt),Jp(),e=t.flags,e&65536&&!(e&128)?(t.flags=e&-65537|128,t):null;case 5:return Qp(t),null;case 13:if(be(De),e=t.memoizedState,e!==null&&e.dehydrated!==null){if(t.alternate===null)throw Error(S(340));sn()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 19:return be(De),null;case 4:return ln(),null;case 10:return Hp(t.type._context),null;case 22:case 23:return dc(),null;case 24:return null;default:return null}}var ts=!1,et=!1,U0=typeof WeakSet=="function"?WeakSet:Set,N=null;function Ha(e,t){var i=e.ref;if(i!==null)if(typeof i=="function")try{i(null)}catch(a){Ee(e,t,a)}else i.current=null}function Wd(e,t,i){try{i()}catch(a){Ee(e,t,a)}}var Zu=!1;function K0(e,t){if(Fd=Es,e=Eh(),Lp(e)){if("selectionStart"in e)var i={start:e.selectionStart,end:e.selectionEnd};else e:{i=(i=e.ownerDocument)&&i.defaultView||window;var a=i.getSelection&&i.getSelection();if(a&&a.rangeCount!==0){i=a.anchorNode;var n=a.anchorOffset,o=a.focusNode;a=a.focusOffset;try{i.nodeType,o.nodeType}catch{i=null;break e}var s=0,r=-1,l=-1,d=0,p=0,f=e,h=null;t:for(;;){for(var c;f!==i||n!==0&&f.nodeType!==3||(r=s+n),f!==o||a!==0&&f.nodeType!==3||(l=s+a),f.nodeType===3&&(s+=f.nodeValue.length),(c=f.firstChild)!==null;)h=f,f=c;for(;;){if(f===e)break t;if(h===i&&++d===n&&(r=s),h===o&&++p===a&&(l=s),(c=f.nextSibling)!==null)break;f=h,h=f.parentNode}f=c}i=r===-1||l===-1?null:{start:r,end:l}}else i=null}i=i||{start:0,end:0}}else i=null;for(Td={focusedElem:e,selectionRange:i},Es=!1,N=t;N!==null;)if(t=N,e=t.child,(t.subtreeFlags&1028)!==0&&e!==null)e.return=t,N=e;else for(;N!==null;){t=N;try{var g=t.alternate;if(t.flags&1024)switch(t.tag){case 0:case 11:case 15:break;case 1:if(g!==null){var m=g.memoizedProps,x=g.memoizedState,_=t.stateNode,y=_.getSnapshotBeforeUpdate(t.elementType===t.type?m:Ot(t.type,m),x);_.__reactInternalSnapshotBeforeUpdate=y}break;case 3:var b=t.stateNode.containerInfo;b.nodeType===1?b.textContent="":b.nodeType===9&&b.documentElement&&b.removeChild(b.documentElement);break;case 5:case 6:case 4:case 17:break;default:throw Error(S(163))}}catch(v){Ee(t,t.return,v)}if(e=t.sibling,e!==null){e.return=t.return,N=e;break}N=t.return}return g=Zu,Zu=!1,g}function Qn(e,t,i){var a=t.updateQueue;if(a=a!==null?a.lastEffect:null,a!==null){var n=a=a.next;do{if((n.tag&e)===e){var o=n.destroy;n.destroy=void 0,o!==void 0&&Wd(t,i,o)}n=n.next}while(n!==a)}}function gr(e,t){if(t=t.updateQueue,t=t!==null?t.lastEffect:null,t!==null){var i=t=t.next;do{if((i.tag&e)===e){var a=i.create;i.destroy=a()}i=i.next}while(i!==t)}}function $d(e){var t=e.ref;if(t!==null){var i=e.stateNode;switch(e.tag){case 5:e=i;break;default:e=i}typeof t=="function"?t(e):t.current=e}}function Rg(e){var t=e.alternate;t!==null&&(e.alternate=null,Rg(t)),e.child=null,e.deletions=null,e.sibling=null,e.tag===5&&(t=e.stateNode,t!==null&&(delete t[Zt],delete t[ho],delete t[Rd],delete t[C0],delete t[R0])),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function Pg(e){return e.tag===5||e.tag===3||e.tag===4}function em(e){e:for(;;){for(;e.sibling===null;){if(e.return===null||Pg(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;e.tag!==5&&e.tag!==6&&e.tag!==18;){if(e.flags&2||e.child===null||e.tag===4)continue e;e.child.return=e,e=e.child}if(!(e.flags&2))return e.stateNode}}function Gd(e,t,i){var a=e.tag;if(a===5||a===6)e=e.stateNode,t?i.nodeType===8?i.parentNode.insertBefore(e,t):i.insertBefore(e,t):(i.nodeType===8?(t=i.parentNode,t.insertBefore(e,i)):(t=i,t.appendChild(e)),i=i._reactRootContainer,i!=null||t.onclick!==null||(t.onclick=js));else if(a!==4&&(e=e.child,e!==null))for(Gd(e,t,i),e=e.sibling;e!==null;)Gd(e,t,i),e=e.sibling}function Ud(e,t,i){var a=e.tag;if(a===5||a===6)e=e.stateNode,t?i.insertBefore(e,t):i.appendChild(e);else if(a!==4&&(e=e.child,e!==null))for(Ud(e,t,i),e=e.sibling;e!==null;)Ud(e,t,i),e=e.sibling}var Ke=null,Lt=!1;function Di(e,t,i){for(i=i.child;i!==null;)Sg(e,t,i),i=i.sibling}function Sg(e,t,i){if(ii&&typeof ii.onCommitFiberUnmount=="function")try{ii.onCommitFiberUnmount(lr,i)}catch{}switch(i.tag){case 5:et||Ha(i,t);case 6:var a=Ke,n=Lt;Ke=null,Di(e,t,i),Ke=a,Lt=n,Ke!==null&&(Lt?(e=Ke,i=i.stateNode,e.nodeType===8?e.parentNode.removeChild(i):e.removeChild(i)):Ke.removeChild(i.stateNode));break;case 18:Ke!==null&&(Lt?(e=Ke,i=i.stateNode,e.nodeType===8?Rl(e.parentNode,i):e.nodeType===1&&Rl(e,i),po(e)):Rl(Ke,i.stateNode));break;case 4:a=Ke,n=Lt,Ke=i.stateNode.containerInfo,Lt=!0,Di(e,t,i),Ke=a,Lt=n;break;case 0:case 11:case 14:case 15:if(!et&&(a=i.updateQueue,a!==null&&(a=a.lastEffect,a!==null))){n=a=a.next;do{var o=n,s=o.destroy;o=o.tag,s!==void 0&&(o&2||o&4)&&Wd(i,t,s),n=n.next}while(n!==a)}Di(e,t,i);break;case 1:if(!et&&(Ha(i,t),a=i.stateNode,typeof a.componentWillUnmount=="function"))try{a.props=i.memoizedProps,a.state=i.memoizedState,a.componentWillUnmount()}catch(r){Ee(i,t,r)}Di(e,t,i);break;case 21:Di(e,t,i);break;case 22:i.mode&1?(et=(a=et)||i.memoizedState!==null,Di(e,t,i),et=a):Di(e,t,i);break;default:Di(e,t,i)}}function tm(e){var t=e.updateQueue;if(t!==null){e.updateQueue=null;var i=e.stateNode;i===null&&(i=e.stateNode=new U0),t.forEach(function(a){var n=t1.bind(null,e,a);i.has(a)||(i.add(a),a.then(n,n))})}}function Nt(e,t){var i=t.deletions;if(i!==null)for(var a=0;a<i.length;a++){var n=i[a];try{var o=e,s=t,r=s;e:for(;r!==null;){switch(r.tag){case 5:Ke=r.stateNode,Lt=!1;break e;case 3:Ke=r.stateNode.containerInfo,Lt=!0;break e;case 4:Ke=r.stateNode.containerInfo,Lt=!0;break e}r=r.return}if(Ke===null)throw Error(S(160));Sg(o,s,n),Ke=null,Lt=!1;var l=n.alternate;l!==null&&(l.return=null),n.return=null}catch(d){Ee(n,t,d)}}if(t.subtreeFlags&12854)for(t=t.child;t!==null;)Eg(t,e),t=t.sibling}function Eg(e,t){var i=e.alternate,a=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(Nt(t,e),Xt(e),a&4){try{Qn(3,e,e.return),gr(3,e)}catch(m){Ee(e,e.return,m)}try{Qn(5,e,e.return)}catch(m){Ee(e,e.return,m)}}break;case 1:Nt(t,e),Xt(e),a&512&&i!==null&&Ha(i,i.return);break;case 5:if(Nt(t,e),Xt(e),a&512&&i!==null&&Ha(i,i.return),e.flags&32){var n=e.stateNode;try{oo(n,"")}catch(m){Ee(e,e.return,m)}}if(a&4&&(n=e.stateNode,n!=null)){var o=e.memoizedProps,s=i!==null?i.memoizedProps:o,r=e.type,l=e.updateQueue;if(e.updateQueue=null,l!==null)try{r==="input"&&o.type==="radio"&&o.name!=null&&Zf(n,o),hd(r,s);var d=hd(r,o);for(s=0;s<l.length;s+=2){var p=l[s],f=l[s+1];p==="style"?nh(n,f):p==="dangerouslySetInnerHTML"?ih(n,f):p==="children"?oo(n,f):Cp(n,p,f,d)}switch(r){case"input":pd(n,o);break;case"textarea":eh(n,o);break;case"select":var h=n._wrapperState.wasMultiple;n._wrapperState.wasMultiple=!!o.multiple;var c=o.value;c!=null?Xa(n,!!o.multiple,c,!1):h!==!!o.multiple&&(o.defaultValue!=null?Xa(n,!!o.multiple,o.defaultValue,!0):Xa(n,!!o.multiple,o.multiple?[]:"",!1))}n[ho]=o}catch(m){Ee(e,e.return,m)}}break;case 6:if(Nt(t,e),Xt(e),a&4){if(e.stateNode===null)throw Error(S(162));n=e.stateNode,o=e.memoizedProps;try{n.nodeValue=o}catch(m){Ee(e,e.return,m)}}break;case 3:if(Nt(t,e),Xt(e),a&4&&i!==null&&i.memoizedState.isDehydrated)try{po(t.containerInfo)}catch(m){Ee(e,e.return,m)}break;case 4:Nt(t,e),Xt(e);break;case 13:Nt(t,e),Xt(e),n=e.child,n.flags&8192&&(o=n.memoizedState!==null,n.stateNode.isHidden=o,!o||n.alternate!==null&&n.alternate.memoizedState!==null||(rc=je())),a&4&&tm(e);break;case 22:if(p=i!==null&&i.memoizedState!==null,e.mode&1?(et=(d=et)||p,Nt(t,e),et=d):Nt(t,e),Xt(e),a&8192){if(d=e.memoizedState!==null,(e.stateNode.isHidden=d)&&!p&&e.mode&1)for(N=e,p=e.child;p!==null;){for(f=N=p;N!==null;){switch(h=N,c=h.child,h.tag){case 0:case 11:case 14:case 15:Qn(4,h,h.return);break;case 1:Ha(h,h.return);var g=h.stateNode;if(typeof g.componentWillUnmount=="function"){a=h,i=h.return;try{t=a,g.props=t.memoizedProps,g.state=t.memoizedState,g.componentWillUnmount()}catch(m){Ee(a,i,m)}}break;case 5:Ha(h,h.return);break;case 22:if(h.memoizedState!==null){am(f);continue}}c!==null?(c.return=h,N=c):am(f)}p=p.sibling}e:for(p=null,f=e;;){if(f.tag===5){if(p===null){p=f;try{n=f.stateNode,d?(o=n.style,typeof o.setProperty=="function"?o.setProperty("display","none","important"):o.display="none"):(r=f.stateNode,l=f.memoizedProps.style,s=l!=null&&l.hasOwnProperty("display")?l.display:null,r.style.display=ah("display",s))}catch(m){Ee(e,e.return,m)}}}else if(f.tag===6){if(p===null)try{f.stateNode.nodeValue=d?"":f.memoizedProps}catch(m){Ee(e,e.return,m)}}else if((f.tag!==22&&f.tag!==23||f.memoizedState===null||f===e)&&f.child!==null){f.child.return=f,f=f.child;continue}if(f===e)break e;for(;f.sibling===null;){if(f.return===null||f.return===e)break e;p===f&&(p=null),f=f.return}p===f&&(p=null),f.sibling.return=f.return,f=f.sibling}}break;case 19:Nt(t,e),Xt(e),a&4&&tm(e);break;case 21:break;default:Nt(t,e),Xt(e)}}function Xt(e){var t=e.flags;if(t&2){try{e:{for(var i=e.return;i!==null;){if(Pg(i)){var a=i;break e}i=i.return}throw Error(S(160))}switch(a.tag){case 5:var n=a.stateNode;a.flags&32&&(oo(n,""),a.flags&=-33);var o=em(e);Ud(e,o,n);break;case 3:case 4:var s=a.stateNode.containerInfo,r=em(e);Gd(e,r,s);break;default:throw Error(S(161))}}catch(l){Ee(e,e.return,l)}e.flags&=-3}t&4096&&(e.flags&=-4097)}function H0(e,t,i){N=e,Bg(e)}function Bg(e,t,i){for(var a=(e.mode&1)!==0;N!==null;){var n=N,o=n.child;if(n.tag===22&&a){var s=n.memoizedState!==null||ts;if(!s){var r=n.alternate,l=r!==null&&r.memoizedState!==null||et;r=ts;var d=et;if(ts=s,(et=l)&&!d)for(N=n;N!==null;)s=N,l=s.child,s.tag===22&&s.memoizedState!==null?nm(n):l!==null?(l.return=s,N=l):nm(n);for(;o!==null;)N=o,Bg(o),o=o.sibling;N=n,ts=r,et=d}im(e)}else n.subtreeFlags&8772&&o!==null?(o.return=n,N=o):im(e)}}function im(e){for(;N!==null;){var t=N;if(t.flags&8772){var i=t.alternate;try{if(t.flags&8772)switch(t.tag){case 0:case 11:case 15:et||gr(5,t);break;case 1:var a=t.stateNode;if(t.flags&4&&!et)if(i===null)a.componentDidMount();else{var n=t.elementType===t.type?i.memoizedProps:Ot(t.type,i.memoizedProps);a.componentDidUpdate(n,i.memoizedState,a.__reactInternalSnapshotBeforeUpdate)}var o=t.updateQueue;o!==null&&Nu(t,o,a);break;case 3:var s=t.updateQueue;if(s!==null){if(i=null,t.child!==null)switch(t.child.tag){case 5:i=t.child.stateNode;break;case 1:i=t.child.stateNode}Nu(t,s,i)}break;case 5:var r=t.stateNode;if(i===null&&t.flags&4){i=r;var l=t.memoizedProps;switch(t.type){case"button":case"input":case"select":case"textarea":l.autoFocus&&i.focus();break;case"img":l.src&&(i.src=l.src)}}break;case 6:break;case 4:break;case 12:break;case 13:if(t.memoizedState===null){var d=t.alternate;if(d!==null){var p=d.memoizedState;if(p!==null){var f=p.dehydrated;f!==null&&po(f)}}}break;case 19:case 17:case 21:case 22:case 23:case 25:break;default:throw Error(S(163))}et||t.flags&512&&$d(t)}catch(h){Ee(t,t.return,h)}}if(t===e){N=null;break}if(i=t.sibling,i!==null){i.return=t.return,N=i;break}N=t.return}}function am(e){for(;N!==null;){var t=N;if(t===e){N=null;break}var i=t.sibling;if(i!==null){i.return=t.return,N=i;break}N=t.return}}function nm(e){for(;N!==null;){var t=N;try{switch(t.tag){case 0:case 11:case 15:var i=t.return;try{gr(4,t)}catch(l){Ee(t,i,l)}break;case 1:var a=t.stateNode;if(typeof a.componentDidMount=="function"){var n=t.return;try{a.componentDidMount()}catch(l){Ee(t,n,l)}}var o=t.return;try{$d(t)}catch(l){Ee(t,o,l)}break;case 5:var s=t.return;try{$d(t)}catch(l){Ee(t,s,l)}}}catch(l){Ee(t,t.return,l)}if(t===e){N=null;break}var r=t.sibling;if(r!==null){r.return=t.return,N=r;break}N=t.return}}var V0=Math.ceil,Ks=qi.ReactCurrentDispatcher,oc=qi.ReactCurrentOwner,Bt=qi.ReactCurrentBatchConfig,te=0,We=null,ze=null,Ve=0,ht=0,Va=Ji(0),Oe=0,vo=null,ka=0,yr=0,sc=0,Jn=null,lt=null,rc=0,pn=1/0,ci=null,Hs=!1,Kd=null,$i=null,is=!1,Mi=null,Vs=0,Zn=0,Hd=null,_s=-1,bs=0;function at(){return te&6?je():_s!==-1?_s:_s=je()}function Gi(e){return e.mode&1?te&2&&Ve!==0?Ve&-Ve:S0.transition!==null?(bs===0&&(bs=gh()),bs):(e=le,e!==0||(e=window.event,e=e===void 0?16:qh(e.type)),e):1}function Ut(e,t,i,a){if(50<Zn)throw Zn=0,Hd=null,Error(S(185));Co(e,i,a),(!(te&2)||e!==We)&&(e===We&&(!(te&2)&&(yr|=i),Oe===4&&Ai(e,Ve)),ut(e,a),i===1&&te===0&&!(t.mode&1)&&(pn=je()+500,mr&&Zi()))}function ut(e,t){var i=e.callbackNode;Sb(e,t);var a=Ss(e,e===We?Ve:0);if(a===0)i!==null&&mu(i),e.callbackNode=null,e.callbackPriority=0;else if(t=a&-a,e.callbackPriority!==t){if(i!=null&&mu(i),t===1)e.tag===0?P0(om.bind(null,e)):Wh(om.bind(null,e)),T0(function(){!(te&6)&&Zi()}),i=null;else{switch(yh(a)){case 1:i=Bp;break;case 4:i=fh;break;case 16:i=Ps;break;case 536870912:i=hh;break;default:i=Ps}i=Lg(i,Ag.bind(null,e))}e.callbackPriority=t,e.callbackNode=i}}function Ag(e,t){if(_s=-1,bs=0,te&6)throw Error(S(327));var i=e.callbackNode;if(en()&&e.callbackNode!==i)return null;var a=Ss(e,e===We?Ve:0);if(a===0)return null;if(a&30||a&e.expiredLanes||t)t=Xs(e,a);else{t=a;var n=te;te|=2;var o=Mg();(We!==e||Ve!==t)&&(ci=null,pn=je()+500,ha(e,t));do try{Q0();break}catch(r){jg(e,r)}while(1);Kp(),Ks.current=o,te=n,ze!==null?t=0:(We=null,Ve=0,t=Oe)}if(t!==0){if(t===2&&(n=kd(e),n!==0&&(a=n,t=Vd(e,n))),t===1)throw i=vo,ha(e,0),Ai(e,a),ut(e,je()),i;if(t===6)Ai(e,a);else{if(n=e.current.alternate,!(a&30)&&!X0(n)&&(t=Xs(e,a),t===2&&(o=kd(e),o!==0&&(a=o,t=Vd(e,o))),t===1))throw i=vo,ha(e,0),Ai(e,a),ut(e,je()),i;switch(e.finishedWork=n,e.finishedLanes=a,t){case 0:case 1:throw Error(S(345));case 2:na(e,lt,ci);break;case 3:if(Ai(e,a),(a&130023424)===a&&(t=rc+500-je(),10<t)){if(Ss(e,0)!==0)break;if(n=e.suspendedLanes,(n&a)!==a){at(),e.pingedLanes|=e.suspendedLanes&n;break}e.timeoutHandle=Cd(na.bind(null,e,lt,ci),t);break}na(e,lt,ci);break;case 4:if(Ai(e,a),(a&4194240)===a)break;for(t=e.eventTimes,n=-1;0<a;){var s=31-Gt(a);o=1<<s,s=t[s],s>n&&(n=s),a&=~o}if(a=n,a=je()-a,a=(120>a?120:480>a?480:1080>a?1080:1920>a?1920:3e3>a?3e3:4320>a?4320:1960*V0(a/1960))-a,10<a){e.timeoutHandle=Cd(na.bind(null,e,lt,ci),a);break}na(e,lt,ci);break;case 5:na(e,lt,ci);break;default:throw Error(S(329))}}}return ut(e,je()),e.callbackNode===i?Ag.bind(null,e):null}function Vd(e,t){var i=Jn;return e.current.memoizedState.isDehydrated&&(ha(e,t).flags|=256),e=Xs(e,t),e!==2&&(t=lt,lt=i,t!==null&&Xd(t)),e}function Xd(e){lt===null?lt=e:lt.push.apply(lt,e)}function X0(e){for(var t=e;;){if(t.flags&16384){var i=t.updateQueue;if(i!==null&&(i=i.stores,i!==null))for(var a=0;a<i.length;a++){var n=i[a],o=n.getSnapshot;n=n.value;try{if(!Kt(o(),n))return!1}catch{return!1}}}if(i=t.child,t.subtreeFlags&16384&&i!==null)i.return=t,t=i;else{if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}function Ai(e,t){for(t&=~sc,t&=~yr,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var i=31-Gt(t),a=1<<i;e[i]=-1,t&=~a}}function om(e){if(te&6)throw Error(S(327));en();var t=Ss(e,0);if(!(t&1))return ut(e,je()),null;var i=Xs(e,t);if(e.tag!==0&&i===2){var a=kd(e);a!==0&&(t=a,i=Vd(e,a))}if(i===1)throw i=vo,ha(e,0),Ai(e,t),ut(e,je()),i;if(i===6)throw Error(S(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,na(e,lt,ci),ut(e,je()),null}function lc(e,t){var i=te;te|=1;try{return e(t)}finally{te=i,te===0&&(pn=je()+500,mr&&Zi())}}function va(e){Mi!==null&&Mi.tag===0&&!(te&6)&&en();var t=te;te|=1;var i=Bt.transition,a=le;try{if(Bt.transition=null,le=1,e)return e()}finally{le=a,Bt.transition=i,te=t,!(te&6)&&Zi()}}function dc(){ht=Va.current,be(Va)}function ha(e,t){e.finishedWork=null,e.finishedLanes=0;var i=e.timeoutHandle;if(i!==-1&&(e.timeoutHandle=-1,F0(i)),ze!==null)for(i=ze.return;i!==null;){var a=i;switch($p(a),a.tag){case 1:a=a.type.childContextTypes,a!=null&&Ms();break;case 3:ln(),be(pt),be(tt),Jp();break;case 5:Qp(a);break;case 4:ln();break;case 13:be(De);break;case 19:be(De);break;case 10:Hp(a.type._context);break;case 22:case 23:dc()}i=i.return}if(We=e,ze=e=Ui(e.current,null),Ve=ht=t,Oe=0,vo=null,sc=yr=ka=0,lt=Jn=null,ca!==null){for(t=0;t<ca.length;t++)if(i=ca[t],a=i.interleaved,a!==null){i.interleaved=null;var n=a.next,o=i.pending;if(o!==null){var s=o.next;o.next=n,a.next=s}i.pending=a}ca=null}return e}function jg(e,t){do{var i=ze;try{if(Kp(),hs.current=Us,Gs){for(var a=Ce.memoizedState;a!==null;){var n=a.queue;n!==null&&(n.pending=null),a=a.next}Gs=!1}if(ba=0,Le=Ne=Ce=null,Yn=!1,_o=0,oc.current=null,i===null||i.return===null){Oe=1,vo=t,ze=null;break}e:{var o=e,s=i.return,r=i,l=t;if(t=Ve,r.flags|=32768,l!==null&&typeof l=="object"&&typeof l.then=="function"){var d=l,p=r,f=p.tag;if(!(p.mode&1)&&(f===0||f===11||f===15)){var h=p.alternate;h?(p.updateQueue=h.updateQueue,p.memoizedState=h.memoizedState,p.lanes=h.lanes):(p.updateQueue=null,p.memoizedState=null)}var c=Ku(s);if(c!==null){c.flags&=-257,Hu(c,s,r,o,t),c.mode&1&&Uu(o,d,t),t=c,l=d;var g=t.updateQueue;if(g===null){var m=new Set;m.add(l),t.updateQueue=m}else g.add(l);break e}else{if(!(t&1)){Uu(o,d,t),pc();break e}l=Error(S(426))}}else if(xe&&r.mode&1){var x=Ku(s);if(x!==null){!(x.flags&65536)&&(x.flags|=256),Hu(x,s,r,o,t),Gp(dn(l,r));break e}}o=l=dn(l,r),Oe!==4&&(Oe=2),Jn===null?Jn=[o]:Jn.push(o),o=s;do{switch(o.tag){case 3:o.flags|=65536,t&=-t,o.lanes|=t;var _=_g(o,l,t);Iu(o,_);break e;case 1:r=l;var y=o.type,b=o.stateNode;if(!(o.flags&128)&&(typeof y.getDerivedStateFromError=="function"||b!==null&&typeof b.componentDidCatch=="function"&&($i===null||!$i.has(b)))){o.flags|=65536,t&=-t,o.lanes|=t;var v=bg(o,r,t);Iu(o,v);break e}}o=o.return}while(o!==null)}Ig(i)}catch(F){t=F,ze===i&&i!==null&&(ze=i=i.return);continue}break}while(1)}function Mg(){var e=Ks.current;return Ks.current=Us,e===null?Us:e}function pc(){(Oe===0||Oe===3||Oe===2)&&(Oe=4),We===null||!(ka&268435455)&&!(yr&268435455)||Ai(We,Ve)}function Xs(e,t){var i=te;te|=2;var a=Mg();(We!==e||Ve!==t)&&(ci=null,ha(e,t));do try{Y0();break}catch(n){jg(e,n)}while(1);if(Kp(),te=i,Ks.current=a,ze!==null)throw Error(S(261));return We=null,Ve=0,Oe}function Y0(){for(;ze!==null;)zg(ze)}function Q0(){for(;ze!==null&&!wb();)zg(ze)}function zg(e){var t=Og(e.alternate,e,ht);e.memoizedProps=e.pendingProps,t===null?Ig(e):ze=t,oc.current=null}function Ig(e){var t=e;do{var i=t.alternate;if(e=t.return,t.flags&32768){if(i=G0(i,t),i!==null){i.flags&=32767,ze=i;return}if(e!==null)e.flags|=32768,e.subtreeFlags=0,e.deletions=null;else{Oe=6,ze=null;return}}else if(i=$0(i,t,ht),i!==null){ze=i;return}if(t=t.sibling,t!==null){ze=t;return}ze=t=e}while(t!==null);Oe===0&&(Oe=5)}function na(e,t,i){var a=le,n=Bt.transition;try{Bt.transition=null,le=1,J0(e,t,i,a)}finally{Bt.transition=n,le=a}return null}function J0(e,t,i,a){do en();while(Mi!==null);if(te&6)throw Error(S(327));i=e.finishedWork;var n=e.finishedLanes;if(i===null)return null;if(e.finishedWork=null,e.finishedLanes=0,i===e.current)throw Error(S(177));e.callbackNode=null,e.callbackPriority=0;var o=i.lanes|i.childLanes;if(Eb(e,o),e===We&&(ze=We=null,Ve=0),!(i.subtreeFlags&2064)&&!(i.flags&2064)||is||(is=!0,Lg(Ps,function(){return en(),null})),o=(i.flags&15990)!==0,i.subtreeFlags&15990||o){o=Bt.transition,Bt.transition=null;var s=le;le=1;var r=te;te|=4,oc.current=null,K0(e,i),Eg(i,e),_0(Td),Es=!!Fd,Td=Fd=null,e.current=i,H0(i),qb(),te=r,le=s,Bt.transition=o}else e.current=i;if(is&&(is=!1,Mi=e,Vs=n),o=e.pendingLanes,o===0&&($i=null),Tb(i.stateNode),ut(e,je()),t!==null)for(a=e.onRecoverableError,i=0;i<t.length;i++)n=t[i],a(n.value,{componentStack:n.stack,digest:n.digest});if(Hs)throw Hs=!1,e=Kd,Kd=null,e;return Vs&1&&e.tag!==0&&en(),o=e.pendingLanes,o&1?e===Hd?Zn++:(Zn=0,Hd=e):Zn=0,Zi(),null}function en(){if(Mi!==null){var e=yh(Vs),t=Bt.transition,i=le;try{if(Bt.transition=null,le=16>e?16:e,Mi===null)var a=!1;else{if(e=Mi,Mi=null,Vs=0,te&6)throw Error(S(331));var n=te;for(te|=4,N=e.current;N!==null;){var o=N,s=o.child;if(N.flags&16){var r=o.deletions;if(r!==null){for(var l=0;l<r.length;l++){var d=r[l];for(N=d;N!==null;){var p=N;switch(p.tag){case 0:case 11:case 15:Qn(8,p,o)}var f=p.child;if(f!==null)f.return=p,N=f;else for(;N!==null;){p=N;var h=p.sibling,c=p.return;if(Rg(p),p===d){N=null;break}if(h!==null){h.return=c,N=h;break}N=c}}}var g=o.alternate;if(g!==null){var m=g.child;if(m!==null){g.child=null;do{var x=m.sibling;m.sibling=null,m=x}while(m!==null)}}N=o}}if(o.subtreeFlags&2064&&s!==null)s.return=o,N=s;else e:for(;N!==null;){if(o=N,o.flags&2048)switch(o.tag){case 0:case 11:case 15:Qn(9,o,o.return)}var _=o.sibling;if(_!==null){_.return=o.return,N=_;break e}N=o.return}}var y=e.current;for(N=y;N!==null;){s=N;var b=s.child;if(s.subtreeFlags&2064&&b!==null)b.return=s,N=b;else e:for(s=y;N!==null;){if(r=N,r.flags&2048)try{switch(r.tag){case 0:case 11:case 15:gr(9,r)}}catch(F){Ee(r,r.return,F)}if(r===s){N=null;break e}var v=r.sibling;if(v!==null){v.return=r.return,N=v;break e}N=r.return}}if(te=n,Zi(),ii&&typeof ii.onPostCommitFiberRoot=="function")try{ii.onPostCommitFiberRoot(lr,e)}catch{}a=!0}return a}finally{le=i,Bt.transition=t}}return!1}function sm(e,t,i){t=dn(i,t),t=_g(e,t,1),e=Wi(e,t,1),t=at(),e!==null&&(Co(e,1,t),ut(e,t))}function Ee(e,t,i){if(e.tag===3)sm(e,e,i);else for(;t!==null;){if(t.tag===3){sm(t,e,i);break}else if(t.tag===1){var a=t.stateNode;if(typeof t.type.getDerivedStateFromError=="function"||typeof a.componentDidCatch=="function"&&($i===null||!$i.has(a))){e=dn(i,e),e=bg(t,e,1),t=Wi(t,e,1),e=at(),t!==null&&(Co(t,1,e),ut(t,e));break}}t=t.return}}function Z0(e,t,i){var a=e.pingCache;a!==null&&a.delete(t),t=at(),e.pingedLanes|=e.suspendedLanes&i,We===e&&(Ve&i)===i&&(Oe===4||Oe===3&&(Ve&130023424)===Ve&&500>je()-rc?ha(e,0):sc|=i),ut(e,t)}function Ng(e,t){t===0&&(e.mode&1?(t=Ko,Ko<<=1,!(Ko&130023424)&&(Ko=4194304)):t=1);var i=at();e=bi(e,t),e!==null&&(Co(e,t,i),ut(e,i))}function e1(e){var t=e.memoizedState,i=0;t!==null&&(i=t.retryLane),Ng(e,i)}function t1(e,t){var i=0;switch(e.tag){case 13:var a=e.stateNode,n=e.memoizedState;n!==null&&(i=n.retryLane);break;case 19:a=e.stateNode;break;default:throw Error(S(314))}a!==null&&a.delete(t),Ng(e,i)}var Og;Og=function(e,t,i){if(e!==null)if(e.memoizedProps!==t.pendingProps||pt.current)dt=!0;else{if(!(e.lanes&i)&&!(t.flags&128))return dt=!1,W0(e,t,i);dt=!!(e.flags&131072)}else dt=!1,xe&&t.flags&1048576&&$h(t,Ns,t.index);switch(t.lanes=0,t.tag){case 2:var a=t.type;ys(e,t),e=t.pendingProps;var n=on(t,tt.current);Za(t,i),n=ec(null,t,a,e,n,i);var o=tc();return t.flags|=1,typeof n=="object"&&n!==null&&typeof n.render=="function"&&n.$$typeof===void 0?(t.tag=1,t.memoizedState=null,t.updateQueue=null,ct(a)?(o=!0,zs(t)):o=!1,t.memoizedState=n.state!==null&&n.state!==void 0?n.state:null,Xp(t),n.updater=fr,t.stateNode=n,n._reactInternals=t,jd(t,a,e,i),t=Id(null,t,a,!0,o,i)):(t.tag=0,xe&&o&&Wp(t),it(null,t,n,i),t=t.child),t;case 16:a=t.elementType;e:{switch(ys(e,t),e=t.pendingProps,n=a._init,a=n(a._payload),t.type=a,n=t.tag=a1(a),e=Ot(a,e),n){case 0:t=zd(null,t,a,e,i);break e;case 1:t=Yu(null,t,a,e,i);break e;case 11:t=Vu(null,t,a,e,i);break e;case 14:t=Xu(null,t,a,Ot(a.type,e),i);break e}throw Error(S(306,a,""))}return t;case 0:return a=t.type,n=t.pendingProps,n=t.elementType===a?n:Ot(a,n),zd(e,t,a,n,i);case 1:return a=t.type,n=t.pendingProps,n=t.elementType===a?n:Ot(a,n),Yu(e,t,a,n,i);case 3:e:{if(qg(t),e===null)throw Error(S(387));a=t.pendingProps,o=t.memoizedState,n=o.element,Hh(e,t),Ws(t,a,null,i);var s=t.memoizedState;if(a=s.element,o.isDehydrated)if(o={element:a,isDehydrated:!1,cache:s.cache,pendingSuspenseBoundaries:s.pendingSuspenseBoundaries,transitions:s.transitions},t.updateQueue.baseState=o,t.memoizedState=o,t.flags&256){n=dn(Error(S(423)),t),t=Qu(e,t,a,i,n);break e}else if(a!==n){n=dn(Error(S(424)),t),t=Qu(e,t,a,i,n);break e}else for(_t=Li(t.stateNode.containerInfo.firstChild),bt=t,xe=!0,Wt=null,i=Qh(t,null,a,i),t.child=i;i;)i.flags=i.flags&-3|4096,i=i.sibling;else{if(sn(),a===n){t=ki(e,t,i);break e}it(e,t,a,i)}t=t.child}return t;case 5:return Jh(t),e===null&&Ed(t),a=t.type,n=t.pendingProps,o=e!==null?e.memoizedProps:null,s=n.children,Dd(a,n)?s=null:o!==null&&Dd(a,o)&&(t.flags|=32),wg(e,t),it(e,t,s,i),t.child;case 6:return e===null&&Ed(t),null;case 13:return xg(e,t,i);case 4:return Yp(t,t.stateNode.containerInfo),a=t.pendingProps,e===null?t.child=rn(t,null,a,i):it(e,t,a,i),t.child;case 11:return a=t.type,n=t.pendingProps,n=t.elementType===a?n:Ot(a,n),Vu(e,t,a,n,i);case 7:return it(e,t,t.pendingProps,i),t.child;case 8:return it(e,t,t.pendingProps.children,i),t.child;case 12:return it(e,t,t.pendingProps.children,i),t.child;case 10:e:{if(a=t.type._context,n=t.pendingProps,o=t.memoizedProps,s=n.value,ye(Os,a._currentValue),a._currentValue=s,o!==null)if(Kt(o.value,s)){if(o.children===n.children&&!pt.current){t=ki(e,t,i);break e}}else for(o=t.child,o!==null&&(o.return=t);o!==null;){var r=o.dependencies;if(r!==null){s=o.child;for(var l=r.firstContext;l!==null;){if(l.context===a){if(o.tag===1){l=gi(-1,i&-i),l.tag=2;var d=o.updateQueue;if(d!==null){d=d.shared;var p=d.pending;p===null?l.next=l:(l.next=p.next,p.next=l),d.pending=l}}o.lanes|=i,l=o.alternate,l!==null&&(l.lanes|=i),Bd(o.return,i,t),r.lanes|=i;break}l=l.next}}else if(o.tag===10)s=o.type===t.type?null:o.child;else if(o.tag===18){if(s=o.return,s===null)throw Error(S(341));s.lanes|=i,r=s.alternate,r!==null&&(r.lanes|=i),Bd(s,i,t),s=o.sibling}else s=o.child;if(s!==null)s.return=o;else for(s=o;s!==null;){if(s===t){s=null;break}if(o=s.sibling,o!==null){o.return=s.return,s=o;break}s=s.return}o=s}it(e,t,n.children,i),t=t.child}return t;case 9:return n=t.type,a=t.pendingProps.children,Za(t,i),n=jt(n),a=a(n),t.flags|=1,it(e,t,a,i),t.child;case 14:return a=t.type,n=Ot(a,t.pendingProps),n=Ot(a.type,n),Xu(e,t,a,n,i);case 15:return kg(e,t,t.type,t.pendingProps,i);case 17:return a=t.type,n=t.pendingProps,n=t.elementType===a?n:Ot(a,n),ys(e,t),t.tag=1,ct(a)?(e=!0,zs(t)):e=!1,Za(t,i),Xh(t,a,n),jd(t,a,n,i),Id(null,t,a,!0,e,i);case 19:return Fg(e,t,i);case 22:return vg(e,t,i)}throw Error(S(156,t.tag))};function Lg(e,t){return mh(e,t)}function i1(e,t,i,a){this.tag=e,this.key=i,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=a,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Et(e,t,i,a){return new i1(e,t,i,a)}function cc(e){return e=e.prototype,!(!e||!e.isReactComponent)}function a1(e){if(typeof e=="function")return cc(e)?1:0;if(e!=null){if(e=e.$$typeof,e===Pp)return 11;if(e===Sp)return 14}return 2}function Ui(e,t){var i=e.alternate;return i===null?(i=Et(e.tag,t,e.key,e.mode),i.elementType=e.elementType,i.type=e.type,i.stateNode=e.stateNode,i.alternate=e,e.alternate=i):(i.pendingProps=t,i.type=e.type,i.flags=0,i.subtreeFlags=0,i.deletions=null),i.flags=e.flags&14680064,i.childLanes=e.childLanes,i.lanes=e.lanes,i.child=e.child,i.memoizedProps=e.memoizedProps,i.memoizedState=e.memoizedState,i.updateQueue=e.updateQueue,t=e.dependencies,i.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext},i.sibling=e.sibling,i.index=e.index,i.ref=e.ref,i}function ks(e,t,i,a,n,o){var s=2;if(a=e,typeof e=="function")cc(e)&&(s=1);else if(typeof e=="string")s=5;else e:switch(e){case Ia:return ga(i.children,n,o,t);case Rp:s=8,n|=8;break;case od:return e=Et(12,i,t,n|2),e.elementType=od,e.lanes=o,e;case sd:return e=Et(13,i,t,n),e.elementType=sd,e.lanes=o,e;case rd:return e=Et(19,i,t,n),e.elementType=rd,e.lanes=o,e;case Yf:return _r(i,n,o,t);default:if(typeof e=="object"&&e!==null)switch(e.$$typeof){case Vf:s=10;break e;case Xf:s=9;break e;case Pp:s=11;break e;case Sp:s=14;break e;case Si:s=16,a=null;break e}throw Error(S(130,e==null?e:typeof e,""))}return t=Et(s,i,t,n),t.elementType=e,t.type=a,t.lanes=o,t}function ga(e,t,i,a){return e=Et(7,e,a,t),e.lanes=i,e}function _r(e,t,i,a){return e=Et(22,e,a,t),e.elementType=Yf,e.lanes=i,e.stateNode={isHidden:!1},e}function zl(e,t,i){return e=Et(6,e,null,t),e.lanes=i,e}function Il(e,t,i){return t=Et(4,e.children!==null?e.children:[],e.key,t),t.lanes=i,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function n1(e,t,i,a,n){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=_l(0),this.expirationTimes=_l(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=_l(0),this.identifierPrefix=a,this.onRecoverableError=n,this.mutableSourceEagerHydrationData=null}function uc(e,t,i,a,n,o,s,r,l){return e=new n1(e,t,i,r,l),t===1?(t=1,o===!0&&(t|=8)):t=0,o=Et(3,null,null,t),e.current=o,o.stateNode=e,o.memoizedState={element:a,isDehydrated:i,cache:null,transitions:null,pendingSuspenseBoundaries:null},Xp(o),e}function o1(e,t,i){var a=3<arguments.length&&arguments[3]!==void 0?arguments[3]:null;return{$$typeof:za,key:a==null?null:""+a,children:e,containerInfo:t,implementation:i}}function Wg(e){if(!e)return Vi;e=e._reactInternals;e:{if(Fa(e)!==e||e.tag!==1)throw Error(S(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(ct(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(t!==null);throw Error(S(171))}if(e.tag===1){var i=e.type;if(ct(i))return Lh(e,i,t)}return t}function $g(e,t,i,a,n,o,s,r,l){return e=uc(i,a,!0,e,n,o,s,r,l),e.context=Wg(null),i=e.current,a=at(),n=Gi(i),o=gi(a,n),o.callback=t??null,Wi(i,o,n),e.current.lanes=n,Co(e,n,a),ut(e,a),e}function br(e,t,i,a){var n=t.current,o=at(),s=Gi(n);return i=Wg(i),t.context===null?t.context=i:t.pendingContext=i,t=gi(o,s),t.payload={element:e},a=a===void 0?null:a,a!==null&&(t.callback=a),e=Wi(n,t,s),e!==null&&(Ut(e,n,s,o),fs(e,n,s)),s}function Ys(e){if(e=e.current,!e.child)return null;switch(e.child.tag){case 5:return e.child.stateNode;default:return e.child.stateNode}}function rm(e,t){if(e=e.memoizedState,e!==null&&e.dehydrated!==null){var i=e.retryLane;e.retryLane=i!==0&&i<t?i:t}}function mc(e,t){rm(e,t),(e=e.alternate)&&rm(e,t)}function s1(){return null}var Gg=typeof reportError=="function"?reportError:function(e){console.error(e)};function fc(e){this._internalRoot=e}kr.prototype.render=fc.prototype.render=function(e){var t=this._internalRoot;if(t===null)throw Error(S(409));br(e,t,null,null)};kr.prototype.unmount=fc.prototype.unmount=function(){var e=this._internalRoot;if(e!==null){this._internalRoot=null;var t=e.containerInfo;va(function(){br(null,e,null,null)}),t[_i]=null}};function kr(e){this._internalRoot=e}kr.prototype.unstable_scheduleHydration=function(e){if(e){var t=kh();e={blockedOn:null,target:e,priority:t};for(var i=0;i<Bi.length&&t!==0&&t<Bi[i].priority;i++);Bi.splice(i,0,e),i===0&&wh(e)}};function hc(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11)}function vr(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11&&(e.nodeType!==8||e.nodeValue!==" react-mount-point-unstable "))}function lm(){}function r1(e,t,i,a,n){if(n){if(typeof a=="function"){var o=a;a=function(){var d=Ys(s);o.call(d)}}var s=$g(t,a,e,0,null,!1,!1,"",lm);return e._reactRootContainer=s,e[_i]=s.current,mo(e.nodeType===8?e.parentNode:e),va(),s}for(;n=e.lastChild;)e.removeChild(n);if(typeof a=="function"){var r=a;a=function(){var d=Ys(l);r.call(d)}}var l=uc(e,0,!1,null,null,!1,!1,"",lm);return e._reactRootContainer=l,e[_i]=l.current,mo(e.nodeType===8?e.parentNode:e),va(function(){br(t,l,i,a)}),l}function wr(e,t,i,a,n){var o=i._reactRootContainer;if(o){var s=o;if(typeof n=="function"){var r=n;n=function(){var l=Ys(s);r.call(l)}}br(t,s,e,n)}else s=r1(i,t,e,n,a);return Ys(s)}_h=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var i=Wn(t.pendingLanes);i!==0&&(Ap(t,i|1),ut(t,je()),!(te&6)&&(pn=je()+500,Zi()))}break;case 13:va(function(){var a=bi(e,1);if(a!==null){var n=at();Ut(a,e,1,n)}}),mc(e,1)}};jp=function(e){if(e.tag===13){var t=bi(e,134217728);if(t!==null){var i=at();Ut(t,e,134217728,i)}mc(e,134217728)}};bh=function(e){if(e.tag===13){var t=Gi(e),i=bi(e,t);if(i!==null){var a=at();Ut(i,e,t,a)}mc(e,t)}};kh=function(){return le};vh=function(e,t){var i=le;try{return le=e,t()}finally{le=i}};yd=function(e,t,i){switch(t){case"input":if(pd(e,i),t=i.name,i.type==="radio"&&t!=null){for(i=e;i.parentNode;)i=i.parentNode;for(i=i.querySelectorAll("input[name="+JSON.stringify(""+t)+'][type="radio"]'),t=0;t<i.length;t++){var a=i[t];if(a!==e&&a.form===e.form){var n=ur(a);if(!n)throw Error(S(90));Jf(a),pd(a,n)}}}break;case"textarea":eh(e,i);break;case"select":t=i.value,t!=null&&Xa(e,!!i.multiple,t,!1)}};rh=lc;lh=va;var l1={usingClientEntryPoint:!1,Events:[Po,Wa,ur,oh,sh,lc]},Sn={findFiberByHostInstance:pa,bundleType:0,version:"18.2.0",rendererPackageName:"react-dom"},d1={bundleType:Sn.bundleType,version:Sn.version,rendererPackageName:Sn.rendererPackageName,rendererConfig:Sn.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:qi.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return e=ch(e),e===null?null:e.stateNode},findFiberByHostInstance:Sn.findFiberByHostInstance||s1,findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:"18.2.0-next-9e3b772b8-20220608"};if(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__<"u"){var as=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!as.isDisabled&&as.supportsFiber)try{lr=as.inject(d1),ii=as}catch{}}wt.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=l1;wt.createPortal=function(e,t){var i=2<arguments.length&&arguments[2]!==void 0?arguments[2]:null;if(!hc(t))throw Error(S(200));return o1(e,t,null,i)};wt.createRoot=function(e,t){if(!hc(e))throw Error(S(299));var i=!1,a="",n=Gg;return t!=null&&(t.unstable_strictMode===!0&&(i=!0),t.identifierPrefix!==void 0&&(a=t.identifierPrefix),t.onRecoverableError!==void 0&&(n=t.onRecoverableError)),t=uc(e,1,!1,null,null,i,!1,a,n),e[_i]=t.current,mo(e.nodeType===8?e.parentNode:e),new fc(t)};wt.findDOMNode=function(e){if(e==null)return null;if(e.nodeType===1)return e;var t=e._reactInternals;if(t===void 0)throw typeof e.render=="function"?Error(S(188)):(e=Object.keys(e).join(","),Error(S(268,e)));return e=ch(t),e=e===null?null:e.stateNode,e};wt.flushSync=function(e){return va(e)};wt.hydrate=function(e,t,i){if(!vr(t))throw Error(S(200));return wr(null,e,t,!0,i)};wt.hydrateRoot=function(e,t,i){if(!hc(e))throw Error(S(405));var a=i!=null&&i.hydratedSources||null,n=!1,o="",s=Gg;if(i!=null&&(i.unstable_strictMode===!0&&(n=!0),i.identifierPrefix!==void 0&&(o=i.identifierPrefix),i.onRecoverableError!==void 0&&(s=i.onRecoverableError)),t=$g(t,null,e,1,i??null,n,!1,o,s),e[_i]=t.current,mo(e),a)for(e=0;e<a.length;e++)i=a[e],n=i._getVersion,n=n(i._source),t.mutableSourceEagerHydrationData==null?t.mutableSourceEagerHydrationData=[i,n]:t.mutableSourceEagerHydrationData.push(i,n);return new kr(t)};wt.render=function(e,t,i){if(!vr(t))throw Error(S(200));return wr(null,e,t,!1,i)};wt.unmountComponentAtNode=function(e){if(!vr(e))throw Error(S(40));return e._reactRootContainer?(va(function(){wr(null,null,e,!1,function(){e._reactRootContainer=null,e[_i]=null})}),!0):!1};wt.unstable_batchedUpdates=lc;wt.unstable_renderSubtreeIntoContainer=function(e,t,i,a){if(!vr(i))throw Error(S(200));if(e==null||e._reactInternals===void 0)throw Error(S(38));return wr(e,t,i,!1,a)};wt.version="18.2.0-next-9e3b772b8-20220608";function Ug(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(Ug)}catch(e){console.error(e)}}Ug(),$f.exports=wt;var qr=$f.exports;const ns=Ef(qr);var dm=qr;ad.createRoot=dm.createRoot,ad.hydrateRoot=dm.hydrateRoot;/**
 * @remix-run/router v1.9.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function wo(){return wo=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var i=arguments[t];for(var a in i)Object.prototype.hasOwnProperty.call(i,a)&&(e[a]=i[a])}return e},wo.apply(this,arguments)}var zi;(function(e){e.Pop="POP",e.Push="PUSH",e.Replace="REPLACE"})(zi||(zi={}));const pm="popstate";function p1(e){e===void 0&&(e={});function t(a,n){let{pathname:o,search:s,hash:r}=a.location;return Yd("",{pathname:o,search:s,hash:r},n.state&&n.state.usr||null,n.state&&n.state.key||"default")}function i(a,n){return typeof n=="string"?n:Qs(n)}return u1(t,i,null,e)}function Ie(e,t){if(e===!1||e===null||typeof e>"u")throw new Error(t)}function gc(e,t){if(!e){typeof console<"u"&&console.warn(t);try{throw new Error(t)}catch{}}}function c1(){return Math.random().toString(36).substr(2,8)}function cm(e,t){return{usr:e.state,key:e.key,idx:t}}function Yd(e,t,i,a){return i===void 0&&(i=null),wo({pathname:typeof e=="string"?e:e.pathname,search:"",hash:""},typeof t=="string"?_n(t):t,{state:i,key:t&&t.key||a||c1()})}function Qs(e){let{pathname:t="/",search:i="",hash:a=""}=e;return i&&i!=="?"&&(t+=i.charAt(0)==="?"?i:"?"+i),a&&a!=="#"&&(t+=a.charAt(0)==="#"?a:"#"+a),t}function _n(e){let t={};if(e){let i=e.indexOf("#");i>=0&&(t.hash=e.substr(i),e=e.substr(0,i));let a=e.indexOf("?");a>=0&&(t.search=e.substr(a),e=e.substr(0,a)),e&&(t.pathname=e)}return t}function u1(e,t,i,a){a===void 0&&(a={});let{window:n=document.defaultView,v5Compat:o=!1}=a,s=n.history,r=zi.Pop,l=null,d=p();d==null&&(d=0,s.replaceState(wo({},s.state,{idx:d}),""));function p(){return(s.state||{idx:null}).idx}function f(){r=zi.Pop;let x=p(),_=x==null?null:x-d;d=x,l&&l({action:r,location:m.location,delta:_})}function h(x,_){r=zi.Push;let y=Yd(m.location,x,_);i&&i(y,x),d=p()+1;let b=cm(y,d),v=m.createHref(y);try{s.pushState(b,"",v)}catch(F){if(F instanceof DOMException&&F.name==="DataCloneError")throw F;n.location.assign(v)}o&&l&&l({action:r,location:m.location,delta:1})}function c(x,_){r=zi.Replace;let y=Yd(m.location,x,_);i&&i(y,x),d=p();let b=cm(y,d),v=m.createHref(y);s.replaceState(b,"",v),o&&l&&l({action:r,location:m.location,delta:0})}function g(x){let _=n.location.origin!=="null"?n.location.origin:n.location.href,y=typeof x=="string"?x:Qs(x);return Ie(_,"No window.location.(origin|href) available to create URL for href: "+y),new URL(y,_)}let m={get action(){return r},get location(){return e(n,s)},listen(x){if(l)throw new Error("A history only accepts one active listener");return n.addEventListener(pm,f),l=x,()=>{n.removeEventListener(pm,f),l=null}},createHref(x){return t(n,x)},createURL:g,encodeLocation(x){let _=g(x);return{pathname:_.pathname,search:_.search,hash:_.hash}},push:h,replace:c,go(x){return s.go(x)}};return m}var um;(function(e){e.data="data",e.deferred="deferred",e.redirect="redirect",e.error="error"})(um||(um={}));function m1(e,t,i){i===void 0&&(i="/");let a=typeof t=="string"?_n(t):t,n=yc(a.pathname||"/",i);if(n==null)return null;let o=Kg(e);f1(o);let s=null;for(let r=0;s==null&&r<o.length;++r)s=q1(o[r],T1(n));return s}function Kg(e,t,i,a){t===void 0&&(t=[]),i===void 0&&(i=[]),a===void 0&&(a="");let n=(o,s,r)=>{let l={relativePath:r===void 0?o.path||"":r,caseSensitive:o.caseSensitive===!0,childrenIndex:s,route:o};l.relativePath.startsWith("/")&&(Ie(l.relativePath.startsWith(a),'Absolute route path "'+l.relativePath+'" nested under path '+('"'+a+'" is not valid. An absolute child route path ')+"must start with the combined path of all its parent routes."),l.relativePath=l.relativePath.slice(a.length));let d=Ki([a,l.relativePath]),p=i.concat(l);o.children&&o.children.length>0&&(Ie(o.index!==!0,"Index routes must not have child routes. Please remove "+('all child routes from route path "'+d+'".')),Kg(o.children,t,p,d)),!(o.path==null&&!o.index)&&t.push({path:d,score:v1(d,o.index),routesMeta:p})};return e.forEach((o,s)=>{var r;if(o.path===""||!((r=o.path)!=null&&r.includes("?")))n(o,s);else for(let l of Hg(o.path))n(o,s,l)}),t}function Hg(e){let t=e.split("/");if(t.length===0)return[];let[i,...a]=t,n=i.endsWith("?"),o=i.replace(/\?$/,"");if(a.length===0)return n?[o,""]:[o];let s=Hg(a.join("/")),r=[];return r.push(...s.map(l=>l===""?o:[o,l].join("/"))),n&&r.push(...s),r.map(l=>e.startsWith("/")&&l===""?"/":l)}function f1(e){e.sort((t,i)=>t.score!==i.score?i.score-t.score:w1(t.routesMeta.map(a=>a.childrenIndex),i.routesMeta.map(a=>a.childrenIndex)))}const h1=/^:\w+$/,g1=3,y1=2,_1=1,b1=10,k1=-2,mm=e=>e==="*";function v1(e,t){let i=e.split("/"),a=i.length;return i.some(mm)&&(a+=k1),t&&(a+=y1),i.filter(n=>!mm(n)).reduce((n,o)=>n+(h1.test(o)?g1:o===""?_1:b1),a)}function w1(e,t){return e.length===t.length&&e.slice(0,-1).every((a,n)=>a===t[n])?e[e.length-1]-t[t.length-1]:0}function q1(e,t){let{routesMeta:i}=e,a={},n="/",o=[];for(let s=0;s<i.length;++s){let r=i[s],l=s===i.length-1,d=n==="/"?t:t.slice(n.length)||"/",p=x1({path:r.relativePath,caseSensitive:r.caseSensitive,end:l},d);if(!p)return null;Object.assign(a,p.params);let f=r.route;o.push({params:a,pathname:Ki([n,p.pathname]),pathnameBase:P1(Ki([n,p.pathnameBase])),route:f}),p.pathnameBase!=="/"&&(n=Ki([n,p.pathnameBase]))}return o}function x1(e,t){typeof e=="string"&&(e={path:e,caseSensitive:!1,end:!0});let[i,a]=F1(e.path,e.caseSensitive,e.end),n=t.match(i);if(!n)return null;let o=n[0],s=o.replace(/(.)\/+$/,"$1"),r=n.slice(1);return{params:a.reduce((d,p,f)=>{if(p==="*"){let h=r[f]||"";s=o.slice(0,o.length-h.length).replace(/(.)\/+$/,"$1")}return d[p]=D1(r[f]||"",p),d},{}),pathname:o,pathnameBase:s,pattern:e}}function F1(e,t,i){t===void 0&&(t=!1),i===void 0&&(i=!0),gc(e==="*"||!e.endsWith("*")||e.endsWith("/*"),'Route path "'+e+'" will be treated as if it were '+('"'+e.replace(/\*$/,"/*")+'" because the `*` character must ')+"always follow a `/` in the pattern. To get rid of this warning, "+('please change the route path to "'+e.replace(/\*$/,"/*")+'".'));let a=[],n="^"+e.replace(/\/*\*?$/,"").replace(/^\/*/,"/").replace(/[\\.*+^$?{}|()[\]]/g,"\\$&").replace(/\/:(\w+)/g,(s,r)=>(a.push(r),"/([^\\/]+)"));return e.endsWith("*")?(a.push("*"),n+=e==="*"||e==="/*"?"(.*)$":"(?:\\/(.+)|\\/*)$"):i?n+="\\/*$":e!==""&&e!=="/"&&(n+="(?:(?=\\/|$))"),[new RegExp(n,t?void 0:"i"),a]}function T1(e){try{return decodeURI(e)}catch(t){return gc(!1,'The URL path "'+e+'" could not be decoded because it is is a malformed URL segment. This is probably due to a bad percent '+("encoding ("+t+").")),e}}function D1(e,t){try{return decodeURIComponent(e)}catch(i){return gc(!1,'The value for the URL param "'+t+'" will not be decoded because'+(' the string "'+e+'" is a malformed URL segment. This is probably')+(" due to a bad percent encoding ("+i+").")),e}}function yc(e,t){if(t==="/")return e;if(!e.toLowerCase().startsWith(t.toLowerCase()))return null;let i=t.endsWith("/")?t.length-1:t.length,a=e.charAt(i);return a&&a!=="/"?null:e.slice(i)||"/"}function C1(e,t){t===void 0&&(t="/");let{pathname:i,search:a="",hash:n=""}=typeof e=="string"?_n(e):e;return{pathname:i?i.startsWith("/")?i:R1(i,t):t,search:S1(a),hash:E1(n)}}function R1(e,t){let i=t.replace(/\/+$/,"").split("/");return e.split("/").forEach(n=>{n===".."?i.length>1&&i.pop():n!=="."&&i.push(n)}),i.length>1?i.join("/"):"/"}function Nl(e,t,i,a){return"Cannot include a '"+e+"' character in a manually specified "+("`to."+t+"` field ["+JSON.stringify(a)+"].  Please separate it out to the ")+("`to."+i+"` field. Alternatively you may provide the full path as ")+'a string in <Link to="..."> and the router will parse it for you.'}function Vg(e){return e.filter((t,i)=>i===0||t.route.path&&t.route.path.length>0)}function Xg(e,t,i,a){a===void 0&&(a=!1);let n;typeof e=="string"?n=_n(e):(n=wo({},e),Ie(!n.pathname||!n.pathname.includes("?"),Nl("?","pathname","search",n)),Ie(!n.pathname||!n.pathname.includes("#"),Nl("#","pathname","hash",n)),Ie(!n.search||!n.search.includes("#"),Nl("#","search","hash",n)));let o=e===""||n.pathname==="",s=o?"/":n.pathname,r;if(a||s==null)r=i;else{let f=t.length-1;if(s.startsWith("..")){let h=s.split("/");for(;h[0]==="..";)h.shift(),f-=1;n.pathname=h.join("/")}r=f>=0?t[f]:"/"}let l=C1(n,r),d=s&&s!=="/"&&s.endsWith("/"),p=(o||s===".")&&i.endsWith("/");return!l.pathname.endsWith("/")&&(d||p)&&(l.pathname+="/"),l}const Ki=e=>e.join("/").replace(/\/\/+/g,"/"),P1=e=>e.replace(/\/+$/,"").replace(/^\/*/,"/"),S1=e=>!e||e==="?"?"":e.startsWith("?")?e:"?"+e,E1=e=>!e||e==="#"?"":e.startsWith("#")?e:"#"+e;function B1(e){return e!=null&&typeof e.status=="number"&&typeof e.statusText=="string"&&typeof e.internal=="boolean"&&"data"in e}const Yg=["post","put","patch","delete"];new Set(Yg);const A1=["get",...Yg];new Set(A1);/**
 * React Router v6.16.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function Js(){return Js=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var i=arguments[t];for(var a in i)Object.prototype.hasOwnProperty.call(i,a)&&(e[a]=i[a])}return e},Js.apply(this,arguments)}const _c=k.createContext(null),j1=k.createContext(null),bn=k.createContext(null),xr=k.createContext(null),ea=k.createContext({outlet:null,matches:[],isDataRoute:!1}),Qg=k.createContext(null);function M1(e,t){let{relative:i}=t===void 0?{}:t;Eo()||Ie(!1);let{basename:a,navigator:n}=k.useContext(bn),{hash:o,pathname:s,search:r}=Zg(e,{relative:i}),l=s;return a!=="/"&&(l=s==="/"?a:Ki([a,s])),n.createHref({pathname:l,search:r,hash:o})}function Eo(){return k.useContext(xr)!=null}function Fr(){return Eo()||Ie(!1),k.useContext(xr).location}function Jg(e){k.useContext(bn).static||k.useLayoutEffect(e)}function z1(){let{isDataRoute:e}=k.useContext(ea);return e?Q1():I1()}function I1(){Eo()||Ie(!1);let e=k.useContext(_c),{basename:t,navigator:i}=k.useContext(bn),{matches:a}=k.useContext(ea),{pathname:n}=Fr(),o=JSON.stringify(Vg(a).map(l=>l.pathnameBase)),s=k.useRef(!1);return Jg(()=>{s.current=!0}),k.useCallback(function(l,d){if(d===void 0&&(d={}),!s.current)return;if(typeof l=="number"){i.go(l);return}let p=Xg(l,JSON.parse(o),n,d.relative==="path");e==null&&t!=="/"&&(p.pathname=p.pathname==="/"?t:Ki([t,p.pathname])),(d.replace?i.replace:i.push)(p,d.state,d)},[t,i,o,n,e])}function N1(){let{matches:e}=k.useContext(ea),t=e[e.length-1];return t?t.params:{}}function Zg(e,t){let{relative:i}=t===void 0?{}:t,{matches:a}=k.useContext(ea),{pathname:n}=Fr(),o=JSON.stringify(Vg(a).map(s=>s.pathnameBase));return k.useMemo(()=>Xg(e,JSON.parse(o),n,i==="path"),[e,o,n,i])}function O1(e,t){return L1(e,t)}function L1(e,t,i){Eo()||Ie(!1);let{navigator:a}=k.useContext(bn),{matches:n}=k.useContext(ea),o=n[n.length-1],s=o?o.params:{};o&&o.pathname;let r=o?o.pathnameBase:"/";o&&o.route;let l=Fr(),d;if(t){var p;let m=typeof t=="string"?_n(t):t;r==="/"||(p=m.pathname)!=null&&p.startsWith(r)||Ie(!1),d=m}else d=l;let f=d.pathname||"/",h=r==="/"?f:f.slice(r.length)||"/",c=m1(e,{pathname:h}),g=K1(c&&c.map(m=>Object.assign({},m,{params:Object.assign({},s,m.params),pathname:Ki([r,a.encodeLocation?a.encodeLocation(m.pathname).pathname:m.pathname]),pathnameBase:m.pathnameBase==="/"?r:Ki([r,a.encodeLocation?a.encodeLocation(m.pathnameBase).pathname:m.pathnameBase])})),n,i);return t&&g?k.createElement(xr.Provider,{value:{location:Js({pathname:"/",search:"",hash:"",state:null,key:"default"},d),navigationType:zi.Pop}},g):g}function W1(){let e=Y1(),t=B1(e)?e.status+" "+e.statusText:e instanceof Error?e.message:JSON.stringify(e),i=e instanceof Error?e.stack:null,n={padding:"0.5rem",backgroundColor:"rgba(200,200,200, 0.5)"},o=null;return k.createElement(k.Fragment,null,k.createElement("h2",null,"Unexpected Application Error!"),k.createElement("h3",{style:{fontStyle:"italic"}},t),i?k.createElement("pre",{style:n},i):null,o)}const $1=k.createElement(W1,null);class G1 extends k.Component{constructor(t){super(t),this.state={location:t.location,revalidation:t.revalidation,error:t.error}}static getDerivedStateFromError(t){return{error:t}}static getDerivedStateFromProps(t,i){return i.location!==t.location||i.revalidation!=="idle"&&t.revalidation==="idle"?{error:t.error,location:t.location,revalidation:t.revalidation}:{error:t.error||i.error,location:i.location,revalidation:t.revalidation||i.revalidation}}componentDidCatch(t,i){console.error("React Router caught the following error during render",t,i)}render(){return this.state.error?k.createElement(ea.Provider,{value:this.props.routeContext},k.createElement(Qg.Provider,{value:this.state.error,children:this.props.component})):this.props.children}}function U1(e){let{routeContext:t,match:i,children:a}=e,n=k.useContext(_c);return n&&n.static&&n.staticContext&&(i.route.errorElement||i.route.ErrorBoundary)&&(n.staticContext._deepestRenderedBoundaryId=i.route.id),k.createElement(ea.Provider,{value:t},a)}function K1(e,t,i){var a;if(t===void 0&&(t=[]),i===void 0&&(i=null),e==null){var n;if((n=i)!=null&&n.errors)e=i.matches;else return null}let o=e,s=(a=i)==null?void 0:a.errors;if(s!=null){let r=o.findIndex(l=>l.route.id&&(s==null?void 0:s[l.route.id]));r>=0||Ie(!1),o=o.slice(0,Math.min(o.length,r+1))}return o.reduceRight((r,l,d)=>{let p=l.route.id?s==null?void 0:s[l.route.id]:null,f=null;i&&(f=l.route.errorElement||$1);let h=t.concat(o.slice(0,d+1)),c=()=>{let g;return p?g=f:l.route.Component?g=k.createElement(l.route.Component,null):l.route.element?g=l.route.element:g=r,k.createElement(U1,{match:l,routeContext:{outlet:r,matches:h,isDataRoute:i!=null},children:g})};return i&&(l.route.ErrorBoundary||l.route.errorElement||d===0)?k.createElement(G1,{location:i.location,revalidation:i.revalidation,component:f,error:p,children:c(),routeContext:{outlet:null,matches:h,isDataRoute:!0}}):c()},null)}var ey=function(e){return e.UseBlocker="useBlocker",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e}(ey||{}),Zs=function(e){return e.UseBlocker="useBlocker",e.UseLoaderData="useLoaderData",e.UseActionData="useActionData",e.UseRouteError="useRouteError",e.UseNavigation="useNavigation",e.UseRouteLoaderData="useRouteLoaderData",e.UseMatches="useMatches",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e.UseRouteId="useRouteId",e}(Zs||{});function H1(e){let t=k.useContext(_c);return t||Ie(!1),t}function V1(e){let t=k.useContext(j1);return t||Ie(!1),t}function X1(e){let t=k.useContext(ea);return t||Ie(!1),t}function ty(e){let t=X1(),i=t.matches[t.matches.length-1];return i.route.id||Ie(!1),i.route.id}function Y1(){var e;let t=k.useContext(Qg),i=V1(Zs.UseRouteError),a=ty(Zs.UseRouteError);return t||((e=i.errors)==null?void 0:e[a])}function Q1(){let{router:e}=H1(ey.UseNavigateStable),t=ty(Zs.UseNavigateStable),i=k.useRef(!1);return Jg(()=>{i.current=!0}),k.useCallback(function(n,o){o===void 0&&(o={}),i.current&&(typeof n=="number"?e.navigate(n):e.navigate(n,Js({fromRouteId:t},o)))},[e,t])}function Qd(e){Ie(!1)}function J1(e){let{basename:t="/",children:i=null,location:a,navigationType:n=zi.Pop,navigator:o,static:s=!1}=e;Eo()&&Ie(!1);let r=t.replace(/^\/*/,"/"),l=k.useMemo(()=>({basename:r,navigator:o,static:s}),[r,o,s]);typeof a=="string"&&(a=_n(a));let{pathname:d="/",search:p="",hash:f="",state:h=null,key:c="default"}=a,g=k.useMemo(()=>{let m=yc(d,r);return m==null?null:{location:{pathname:m,search:p,hash:f,state:h,key:c},navigationType:n}},[r,d,p,f,h,c,n]);return g==null?null:k.createElement(bn.Provider,{value:l},k.createElement(xr.Provider,{children:i,value:g}))}function Z1(e){let{children:t,location:i}=e;return O1(Jd(t),i)}new Promise(()=>{});function Jd(e,t){t===void 0&&(t=[]);let i=[];return k.Children.forEach(e,(a,n)=>{if(!k.isValidElement(a))return;let o=[...t,n];if(a.type===k.Fragment){i.push.apply(i,Jd(a.props.children,o));return}a.type!==Qd&&Ie(!1),!a.props.index||!a.props.children||Ie(!1);let s={id:a.props.id||o.join("-"),caseSensitive:a.props.caseSensitive,element:a.props.element,Component:a.props.Component,index:a.props.index,path:a.props.path,loader:a.props.loader,action:a.props.action,errorElement:a.props.errorElement,ErrorBoundary:a.props.ErrorBoundary,hasErrorBoundary:a.props.ErrorBoundary!=null||a.props.errorElement!=null,shouldRevalidate:a.props.shouldRevalidate,handle:a.props.handle,lazy:a.props.lazy};a.props.children&&(s.children=Jd(a.props.children,o)),i.push(s)}),i}/**
 * React Router DOM v6.16.0
 *
 * Copyright (c) Remix Software Inc.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE.md file in the root directory of this source tree.
 *
 * @license MIT
 */function Zd(){return Zd=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var i=arguments[t];for(var a in i)Object.prototype.hasOwnProperty.call(i,a)&&(e[a]=i[a])}return e},Zd.apply(this,arguments)}function ek(e,t){if(e==null)return{};var i={},a=Object.keys(e),n,o;for(o=0;o<a.length;o++)n=a[o],!(t.indexOf(n)>=0)&&(i[n]=e[n]);return i}function tk(e){return!!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey)}function ik(e,t){return e.button===0&&(!t||t==="_self")&&!tk(e)}const ak=["onClick","relative","reloadDocument","replace","state","target","to","preventScrollReset"],nk="startTransition",fm=Ts[nk];function ok(e){let{basename:t,children:i,future:a,window:n}=e,o=k.useRef();o.current==null&&(o.current=p1({window:n,v5Compat:!0}));let s=o.current,[r,l]=k.useState({action:s.action,location:s.location}),{v7_startTransition:d}=a||{},p=k.useCallback(f=>{d&&fm?fm(()=>l(f)):l(f)},[l,d]);return k.useLayoutEffect(()=>s.listen(p),[s,p]),k.createElement(J1,{basename:t,children:i,location:r.location,navigationType:r.action,navigator:s})}const sk=typeof window<"u"&&typeof window.document<"u"&&typeof window.document.createElement<"u",rk=/^(?:[a-z][a-z0-9+.-]*:|\/\/)/i,wa=k.forwardRef(function(t,i){let{onClick:a,relative:n,reloadDocument:o,replace:s,state:r,target:l,to:d,preventScrollReset:p}=t,f=ek(t,ak),{basename:h}=k.useContext(bn),c,g=!1;if(typeof d=="string"&&rk.test(d)&&(c=d,sk))try{let y=new URL(window.location.href),b=d.startsWith("//")?new URL(y.protocol+d):new URL(d),v=yc(b.pathname,h);b.origin===y.origin&&v!=null?d=v+b.search+b.hash:g=!0}catch{}let m=M1(d,{relative:n}),x=lk(d,{replace:s,state:r,target:l,preventScrollReset:p,relative:n});function _(y){a&&a(y),y.defaultPrevented||x(y)}return k.createElement("a",Zd({},f,{href:c||m,onClick:g||o?a:_,ref:i,target:l}))});var hm;(function(e){e.UseScrollRestoration="useScrollRestoration",e.UseSubmit="useSubmit",e.UseSubmitFetcher="useSubmitFetcher",e.UseFetcher="useFetcher"})(hm||(hm={}));var gm;(function(e){e.UseFetchers="useFetchers",e.UseScrollRestoration="useScrollRestoration"})(gm||(gm={}));function lk(e,t){let{target:i,replace:a,state:n,preventScrollReset:o,relative:s}=t===void 0?{}:t,r=z1(),l=Fr(),d=Zg(e,{relative:s});return k.useCallback(p=>{if(ik(p,i)){p.preventDefault();let f=a!==void 0?a:Qs(l)===Qs(d);r(e,{replace:f,state:n,preventScrollReset:o,relative:s})}},[l,r,d,a,n,i,e,o,s])}const dk="/aiida-registry/pr-preview/pr-285/assets/logo-white-text-16948862.svg",pk="/aiida-registry/pr-preview/pr-285/assets/MARVEL-32e738c9.png",ck="/aiida-registry/pr-preview/pr-285/assets/MaX-099f261c.png";const uk={"aiida-QECpWorkChain":{code_home:"https://github.com/rikigigi/aiida-QECpWorkChain",development_status:"beta",entry_point_prefix:"qecpworkchain",pip_url:"git+https://github.com/rikigigi/aiida-QECpWorkChain",name:"aiida-QECpWorkChain",package_name:"aiida_QECpWorkChain",hosted_on:"github.com",metadata:{author:"Riccardo Bertossa",author_email:"rbertoss@sissa.it",version:"0.2.0a0",description:"Car-Parrinello Work Chain with Quantum Espresso. This workchain does a full CP simulation, from the choice of the electronic mass and the timestep, to the choice of the best parallelization options, and then it does the NPT equilibration and a final NVE simulation at the prescribed P and T. Automates as much as possible.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: GNU General Public License v3 (GPLv3)","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.workflows":{"qecpworkchain.cp":{description:["No description available"],spec:{inputs:[{name:"cp_code",required:!0,valid_types:"Code",info:""},{name:"cp_resources_cg_list",required:!0,valid_types:"List",info:"Same as cp_resources_cp_list but when doing a CG. The CG uses a different amount of resource and can use no band or task group parallelization."},{name:"cp_resources_cp_list",required:!0,valid_types:"List",info:`List of dictionary like the following:
{
 'resources' : {
   'num_machines' : 2,
   'num_mpiprocs_per_machine' : 48,
 },
 'wallclock' : 3600,
 'queue' : 'queue_name',
 'account': 'account_name',
}
c,porturrently only the first element of the list is used.
'wallclock' is the maximum time that can be requested to the scheduler. This code can decide to ask for less.
`},{name:"ecutwfc",required:!0,valid_types:"Float",info:"wavefunction cutoff (Ry), like in the QE input"},{name:"pseudo_family",required:!0,valid_types:"Str",info:"pseudopotential family to use, as in usual aiida operations"},{name:"pw_code",required:!0,valid_types:"Code",info:"input pw code (used to calculate force ratio)"},{name:"pw_resources_list",required:!0,valid_types:"List",info:"Same as cp_resources_cp_list but for pw.x code."},{name:"structure",required:!0,valid_types:"StructureData, TrajectoryData",info:"Input structure. If a trajectory is given, the workchain will use its last step to start the CG. If velocities are present, they will be used to initialize the simulation. Note that if you use a trajectory, usually kind information (like mass) are not included, so default values will be used. If you want to include kind information or override those provided with the input structure, use the input structure_kinds"},{name:"thermobarostat_points",required:!0,valid_types:"List",info:'List of dicts, each with the format [ { "temperature_K": 1000, "pressure_KBar": 10 , "equilibration_time_ps": 5.0, "thermostat_time_ps": 5.0} ]. The simulation will loop over this list of dictionaries, in the same order, equilibrating for the specified time at the given P,T point. Every point is repeated if the average T and P are not within the specified ranges'},{name:"additional_parameters_cp",required:!1,valid_types:"Dict",info:"parameters that will be included in the settings input of the QE CP plugin. These settings will be added on top of the default one. Same format as plugin input"},{name:"adjust_ionic_mass",required:!1,valid_types:"Bool",info:"Multiply the mass of the ions by the corresponding force ration between the cp forces and pw forces -- that is less than 1. Note that averages of static properties do not depend on the ionic masses."},{name:"benchmark_emass_dt_walltime_s",required:!1,valid_types:"Float",info:"same as benchmark_parallel_walltime_s but for dermining the best electronic mass and timestep."},{name:"benchmark_parallel_walltime_s",required:!1,valid_types:"Float",info:"time requested to the scheduler during the test for finding the best parallelization parameters."},{name:"cmdline_cp",required:!1,valid_types:"List, NoneType",info:"additional command line parameters of the cp verlet caclulations only (for example parallelization options)"},{name:"default_nose_frequency",required:!1,valid_types:"Float",info:"default nose frequency when a frequency cannot be estimated from the vibrational spectrum"},{name:"dt",required:!1,valid_types:"Float, NoneType",info:"timestep in atomic units, if not automatically chosen."},{name:"dt_start_stop_step",required:!1,valid_types:"List",info:"list of timesteps to try. Timesteps are changed to better integrate the equation of motion. When a new electronic mass is selected by this workchain timesteps are automatically adjusted."},{name:"emass",required:!1,valid_types:"Float, NoneType",info:"electronic mass, atomic mass units, if not automatically chosen"},{name:"emass_list",required:!1,valid_types:"List",info:"list of electronic masses to try. The emass is selected in order to satisfy the requested CP/DFT force ratio."},{name:"initial_atomic_velocities_A_ps",required:!1,valid_types:"ArrayData, NoneType",info:"optional input initial velocities in angstrom over picoseconds"},{name:"max_slope_const",required:!1,valid_types:"Float",info:"max slope in K/ps of the constant of motion linear fit."},{name:"max_slope_ekinc",required:!1,valid_types:"Float",info:"max slope in K/ps of the ekinc linear fit. If not satisfied try to change emass"},{name:"max_slope_min_emass",required:!1,valid_types:"Float",info:"minimum possible value of electronic mass that can be set by the max_slope correction routine. Will not go lower than that."},{name:"max_slope_min_ps",required:!1,valid_types:"Float",info:"minimum required lenght in ps of the last trajectory to do the linear fit on ekinc and const of motion"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_traj_steps_vdos",required:!1,valid_types:"Int",info:"minimum number of steps to consider the calculated vibrational spectrum maximum valid, to set the thermostat frequency"},{name:"minimum_nose_frequency",required:!1,valid_types:"Float",info:"minimum nose frequency: if the frequency estimated from the vibrational spectrum is lower than this value, this value is used"},{name:"nstep_initial_cg",required:!1,valid_types:"Int",info:"At the beginning of the simulation the CP algorithm is not used. This is the number of steps to do using Born-Oppenheimer molecular dynamics algorithm with a conjugate gradient minimization of the electronic ground state."},{name:"nstep_parallel_test",required:!1,valid_types:"Int",info:"the benchmark simulations will be that long, if performed"},{name:"number_of_pw_per_trajectory",required:!1,valid_types:"Int",info:"Number of pw submitted for every trajectory during calculation of force ratio."},{name:"nve_required_picoseconds",required:!1,valid_types:"Float",info:"The equilibrated NVE simulation will last at least this number of picoseconds. How much picoseconds do you want?"},{name:"pressure_tolerance",required:!1,valid_types:"Float",info:"Pressure tolerance in kBar used to say if the npt is equilibrated. If not setted, use the standard deviation of the P time series"},{name:"skip_emass_dt_test",required:!1,valid_types:"Bool",info:""},{name:"skip_parallel_test",required:!1,valid_types:"Bool",info:"do not run run benchmarks to discover a good internal Quantum Espresso parallelization scheme for the current system"},{name:"skip_thermobarostat",required:!1,valid_types:"Bool",info:""},{name:"structure_kinds",required:!1,valid_types:"List, NoneType",info:'These kinds will be used to override or set the masses of the various atomic types. Note that the workflow, if skip_emass_dt_test is True, will calculate the ratio between cp forces and pw forces and adjust the provided masses automatically according to this ratio. So if you provide this input, make sure to set skip_emass_dt_test to True and set also the inputs emass and dt, or "bad things can happen"'},{name:"target_force_ratio",required:!1,valid_types:"Float",info:"The forces calculated by the Car-Parrinello method are affected by two types of error: one is due to the oscillations of the electrons around the DFT energy minimum, and the second is due to the finite mass of the electronic fluid that produces a _sistematic_ error in the forces, as if the electrons add mass to the ionic core. This second kind of error is can be controlled by this parameter, that tries to adjust the electronic mass to obtain the desidered ratio between CP forces and true DFT forces. Then you may want to modify the ionic mass to correct the leading factor of this error."},{name:"temperature_tolerance",required:!1,valid_types:"Float",info:"Temperature tolerance in K used to say if the npt is equilibrated. If not setted, use the standard deviation of the T time series"},{name:"tempw_initial_random",required:!1,valid_types:"Float, NoneType",info:"If provided, sets the initial temperature when randomly initializing the starting velocities."}],outputs:[{name:"cmdline_cp",required:!0,valid_types:"",info:""},{name:"dt",required:!0,valid_types:"",info:""},{name:"emass",required:!0,valid_types:"",info:""},{name:"full_traj",required:!0,valid_types:"",info:""},{name:"kinds",required:!0,valid_types:"",info:""},{name:"nve_prod_traj",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The initial cg steps failed. I cannot start to work."},{status:402,message:"Nose-Hoover thermostat failed."},{status:403,message:"Final cg after Nose-Hoover failed."},{status:404,message:"Error in the NVE simulation"},{status:405,message:"The simulations are calculating very expensive random numbers. There is something wrong (cutoff? metal? boo?)"},{status:406,message:"Wrong input parameters"},{status:407,message:"Parallel test was not succesful, maybe there is something more wrong."},{status:408,message:"Multiple errors in the simulation that cannot fix."},{status:409,message:"This is a bug in the workchain."}]},class:"aiida_QECpWorkChain.workflow:CpWorkChain"}}},commits_count:5,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/rikigigi/aiida-QECpWorkChain",is_installable:"True"},"aiida-abinit":{code_home:"https://github.com/sponce24/aiida-abinit",entry_point_prefix:"abinit",pip_url:"aiida-abinit",plugin_info:"https://raw.github.com/sponce24/aiida-abinit/master/setup.json",name:"aiida-abinit",package_name:"aiida_abinit",hosted_on:"github.com",metadata:{release_date:"2023-02-03",description:"The AiiDA plugin for ABINIT.",author_email:"Samuel Ponce <samuel.pon@gmail.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"0.4.0"},aiida_version:">=1.6.3,<1.7.0",entry_points:{"aiida.calculations":{abinit:{description:["AiiDA calculation plugin wrapping the abinit executable."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The k-point mesh or path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The ABINIT input parameters."},{name:"pseudos",required:!0,valid_types:"Psp8Data, JthXmlData",info:"The pseudopotentials."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData",info:"A remote folder used for restarts."},{name:"settings",required:!1,valid_types:"Dict",info:"Various special settings."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Various output quantities."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Final electronic bands if present."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final structure of the calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:"Trajectory of various output quantities over the calculation if present."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"Calculation did not produce all expected output files."},{status:101,message:"Calculation did not produce the expected `[prefix]o_GSR.nc` output file."},{status:102,message:"Calculation did not produce the expected `[prefix]o_HIST.nc` output file."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the `stdout` output file."},{status:301,message:"The `stdout` output file could not be read."},{status:302,message:"The `stdout` output file could not be parsed."},{status:303,message:"The `abipy` `EventsParser` reports that the runw as not completed."},{status:304,message:"The output file contains one or more error messages."},{status:305,message:"The output file contains one or more warning messages."},{status:312,message:"The output structure could not be parsed."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:500,message:"The SCF minimization cycle did not converge."},{status:501,message:"The ionic minimization cycle did not converge."}]},class:"aiida_abinit.calculations:AbinitCalculation"}},"aiida.parsers":{abinit:"aiida_abinit.parsers:AbinitParser"},"aiida.workflows":{"abinit.base":{description:["Base Abinit Workchain to perform a DFT calculation. Validates parameters and restart."],spec:{inputs:[{name:"abinit",required:!0,valid_types:"",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"An explicit k-points mesh or list. Either this or `kpoints_distance` must be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-point mesh will be generated automatically by a calculation function based on the input structure."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Various output quantities."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Final electronic bands if present."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final structure of the calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:"Trajectory of various output quantities over the calculation if present."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"`pseudos` could not be used to get the necessary pseudos."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:203,message:"Neither the `options` nor `automatic_parallelization` input was specified."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_abinit.workflows.base:AbinitBaseWorkChain"}}},commits_count:11,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-abinit",is_installable:"True"},"aiida-aenet":{code_home:"https://gitlab.com/lattice737/aiida-aenet",development_status:"planning",entry_point_prefix:"aenet",pip_url:"https://gitlab.com/lattice737/aiida-aenet",name:"aiida-aenet",package_name:"aiida_aenet",hosted_on:"gitlab.com",metadata:{author:"Nicholas Martinez",author_email:"nicholasmartinez@my.unt.edu",version:"0.1.0",description:"AiiDA plugin to construct machine-learning potentials using aenet",classifiers:["Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Development Status :: 0 - Alpha"]},aiida_version:"~=1.2",entry_points:{"aiida.data":{"aenet.algorithm":"aiida_aenet.data.algorithm:AenetAlgorithm","aenet.potential":"aiida_aenet.data.potentials:AenetPotential"},"aiida.calculations":{"aenet.cur":"aiida_aenet.calculations.cur:CurCalculation","aenet.generate":"aiida_aenet.calculations.generate:AenetGenerateCalculation","aenet.predict":"aiida_aenet.calculations.predict:AenetPredictCalculation","aenet.simulate":"aiida_aenet.calculations.simulate:AenetLammpsMdCalculation","aenet.train":"aiida_aenet.calculations.train:AenetTrainCalculation","aenet.transform":"aiida_aenet.calculations.transform:TransformCalculation"},"aiida.parsers":{"aenet.generate":"aiida_aenet.parsers.generate:AenetGenerateParser","aenet.predict":"aiida_aenet.parsers.predict:AenetPredictParser","aenet.simulate":"aiida_aenet.parsers.simulate:AenetLammpsMdParser","aenet.train":"aiida_aenet.parsers.train:AenetTrainParser"},"aiida.workflows":{"aenet.build_reference":"aiida_aenet.workflows.build_reference:BuildReferenceWorkChain","aenet.compare_simulations":"aiida_aenet.workflows.compare_simulations:CompareSimulationsWorkChain","aenet.make_potential":"aiida_aenet.workflows.make_potential:MakePotentialWorkChain","aenet.make_structures":"aiida_aenet.workflows.make_structures:MakeStructuresWorkChain"},"aenet.potentials":{"lammps.ann":"aiida_aenet.data.potentials.lammps:ANN"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:4},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:4},{colorclass:"orange",text:"Other (Aenet potentials)",count:1}],pip_install_cmd:"pip install https://gitlab.com/lattice737/aiida-aenet"},"aiida-alloy":{code_home:"https://github.com/DanielMarchand/aiida-alloy",development_status:"beta",entry_point_prefix:"alloy",pip_url:"git+https://github.com/DanielMarchand/aiida-alloy",name:"aiida-alloy",package_name:"aiida_alloy",hosted_on:"github.com",metadata:{author:"The AiiDA developers group",author_email:"",version:"0.1.0a0",description:"Aiida Workflows for Elastic Constants using Quantum Espresso",classifiers:["Programming Language :: Python"]},aiida_version:">=1.0.0a0",entry_points:{"aiida.workflows":{elastic:"aiida_alloy.workflows.ElasticWorkChain:ElasticWorkChain"}},commits_count:1,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'elastic' does not start with prefix 'alloy.'"],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/DanielMarchand/aiida-alloy",is_installable:"False",errors:["Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-alloy",`<pre>Collecting git+https://github.com/DanielMarchand/aiida-alloy
  Cloning https://github.com/DanielMarchand/aiida-alloy to /tmp/pip-req-build-_2sikxx7
  Running command git clone --filter=blob:none --quiet https://github.com/DanielMarchand/aiida-alloy /tmp/pip-req-build-_2sikxx7
  Resolved https://github.com/DanielMarchand/aiida-alloy to commit 076c71f49749fbf2410da41cf175d5e81135659a
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [6 lines of output]
      Traceback (most recent call last):
        File "<string>", line 2, in <module>
        File "<pip-setuptools-caller>", line 34, in <module>
        File "/tmp/pip-req-build-_2sikxx7/setup.py", line 20, in <module>
          long_description=open('README.md').read(),
      FileNotFoundError: [Errno 2] No such file or directory: 'README.md'
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`]},"aiida-ase":{code_home:"https://github.com/aiidateam/aiida-ase",documentation_url:"https://aiida-ase.readthedocs.io/",entry_point_prefix:"ase",pip_url:"aiida-ase",plugin_info:"https://raw.github.com/aiidateam/aiida-ase/master/setup.json",name:"aiida-ase",package_name:"aiida_ase",hosted_on:"github.com",metadata:{release_date:"2023-03-17",description:"The official AiiDA plugin for ASE.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"2.0.0"},aiida_version:">=1.6,<2.0",entry_points:{"aiida.calculations":{"ase.ase":{description:["`CalcJob` implementation that can be used to wrap around the ASE calculators."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the namelists."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The k-points to use for the calculation."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"settings",required:!1,valid_types:"Dict",info:"Optional settings that control the plugin."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array",required:!1,valid_types:"ArrayData",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:""},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"One of the expected output files was missing."},{status:301,message:"The log file from the DFT code was not written out."},{status:302,message:"Relaxation did not complete."},{status:303,message:"SCF Failed."},{status:305,message:"Cannot identify what went wrong."},{status:306,message:"gpaw could not find the PAW potentials."},{status:307,message:"Attribute Error found in the stderr file."},{status:308,message:"Fermi level is infinite."},{status:400,message:"The calculation ran out of walltime."}]},class:"aiida_ase.calculations.ase:AseCalculation"}},"aiida.parsers":{"ase.ase":"aiida_ase.parsers.ase:AseParser","ase.gpaw":"aiida_ase.parsers.gpaw:GpawParser"},"aiida.workflows":{"ase.gpaw.base":{description:["Workchain to run a GPAW calculation with automated error handling and restarts."],spec:{inputs:[{name:"gpaw",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"k-points to use for the calculation."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array",required:!1,valid_types:"ArrayData",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:""},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_ase.workflows.base:GpawBaseWorkChain"}}},commits_count:7,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-ase",is_installable:"True"},"aiida-autocas":{entry_point_prefix:"autocas",code_home:"https://github.com/microsoft/aiida-autocas",version_file:"https://raw.githubusercontent.com/microsoft/aiida-autocas/main/aiida_autocas/__init__.py",pip_url:"git+https://github.com/microsoft/aiida-autocas",name:"aiida-autocas",package_name:"aiida_autocas",hosted_on:"github.com",metadata:{version:"0.1.0",description:"AiiDA AutoCAS Plugin",classifiers:[]},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{autocas:"aiida_autocas.calculations:AutoCASCalculation"},"aiida.parsers":{autocas:"aiida_autocas.parsers:AutoCASParser"}},commits_count:11,development_status:"planning",warnings:["Missing classifier 'Framework :: AiiDA'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/microsoft/aiida-autocas"},"aiida-bands-inspect":{code_home:"https://github.com/greschd/aiida-bands-inspect",documentation_url:"https://aiida-bands-inspect.readthedocs.io",entry_point_prefix:"bands_inspect",pip_url:"aiida-bands-inspect",name:"aiida-bands-inspect",package_name:"aiida_bands_inspect",hosted_on:"github.com",metadata:{release_date:"2020-03-26",description:"AiiDA Plugin for running bands_inspect",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-bands-inspect.readthedocs.io",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.4.0"},aiida_version:null,entry_points:{"aiida.calculations":{"bands_inspect.align":{description:["Calculation class for the ``bands-inspect align`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.data.array.bands.BandsData","        First band structure to compare.","    bands2 : aiida.orm.data.array.bands.BandsData","        Second band structure to compare."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be aligned"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be aligned"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands1_shifted",required:!0,valid_types:"BandsData",info:""},{name:"bands2_shifted",required:!0,valid_types:"BandsData",info:""},{name:"difference",required:!0,valid_types:"Float",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"shift",required:!0,valid_types:"Float",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"At least one of the expected output files is missing from the retrieved folder."},{status:220,message:"The text output file content is not in the expected format."}]},class:"aiida_bands_inspect.calculations.align:AlignCalculation"},"bands_inspect.difference":{description:["Calculation class for the ``bands-inspect difference`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.nodes.data.array.bands.BandsData","        First band structure to compare.","    bands2 : aiida.orm.nodes.data.array.bands.BandsData","        Second band structure to compare."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be compared"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be compared"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"difference",required:!0,valid_types:"Float",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder does not contain the difference output file."}]},class:"aiida_bands_inspect.calculations.difference:DifferenceCalculation"},"bands_inspect.plot":{description:["Calculation class for the ``bands_inspect plot`` command.","","    Arguments","    ---------","    bands1 : aiida.orm.nodes.data.array.bands.BandsData","        First band structure to plot.","    bands2 : aiida.orm.nodes.data.array.bands.BandsData","        Second band structure to plot."],spec:{inputs:[{name:"bands1",required:!0,valid_types:"BandsData",info:"First bandstructure which is to be plotted"},{name:"bands2",required:!0,valid_types:"BandsData",info:"Second bandstructure which is to be plotted"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"plot",required:!0,valid_types:"SinglefileData",info:"The created band-structure comparison plot."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder does not contain the plot output file."}]},class:"aiida_bands_inspect.calculations.plot:PlotCalculation"}},"aiida.parsers":{"bands_inspect.bands":"aiida_bands_inspect.parsers.bands:BandsParser","bands_inspect.difference":"aiida_bands_inspect.parsers.difference:DifferenceParser","bands_inspect.align":"aiida_bands_inspect.parsers.align:AlignParser","bands_inspect.plot":"aiida_bands_inspect.parsers.plot:PlotParser"}},commits_count:0,development_status:"beta",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:4}],pip_install_cmd:"pip install aiida-bands-inspect",is_installable:"True"},"aiida-bigdft":{code_home:"https://github.com/BigDFT-group/aiida-bigdft-plugin",development_status:"beta",entry_point_prefix:"bigdft",pip_url:"aiida-bigdft",plugin_info:"https://raw.github.com/BigDFT-group/aiida-bigdft-plugin/master/setup.json",name:"aiida-bigdft",package_name:"aiida_bigdft",hosted_on:"github.com",metadata:{release_date:"2021-03-16",description:"Aiida plugin for BigDFT code",author:"The BigDFT Team",author_email:"bigdft-developers@lists.launchpad.net",license:"MIT",home_page:"https://github.com/BigDFT-group/aiida-bigdft-plugin",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.6"},aiida_version:">=1.1.1,<2.0.0",entry_points:{"aiida.calculations":{bigdft:{description:["AiiDA calculation plugin wrapping the BigDFT python interface."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"BigDFTParameters",info:"Command line parameters for BigDFT"},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:100,message:"Calculation did not produce all expected output files."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_bigdft.calculations.bigdft:BigDFTCalculation"},"bigdft.postscript":{description:["AiiDA calculation to add post treatments to a computation workcahin.","    post treatment scripts are to be registered as codes in aiida.","    They are python scripts accepting one argument : a remotefolder where data is stored","    Output files are not specified and can be added to the extra_retrieved_files list"],spec:{inputs:[{name:"bigdft_data_folder",required:!0,valid_types:"RemoteData",info:"Folder to the BigDFT data folder"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"retrieved_files",required:!1,valid_types:"List",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"Script execution failed"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_bigdft.calculations.postscript:ScriptCalculation"}},"aiida.cmdline.data":{bigdft:"aiida_bigdft.cli:data_cli"},"aiida.data":{bigdft:"aiida_bigdft.data:BigDFTParameters",bigdft_logfile:"aiida_bigdft.data:BigDFTLogfile"},"aiida.parsers":{bigdft:"aiida_bigdft.parsers:BigDFTParser"},"aiida.workflows":{bigdft:{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"BigDFTParameters",info:"Command line parameters for BigDFT"},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"run_opts",required:!1,valid_types:"Dict",info:"metadata"},{name:"show_warnings",required:!1,valid_types:"Bool",info:"turn the warnings on/off."},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"BigDFT input error"},{status:200,message:"BigDFT runtime error"},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_bigdft.workflows.base:BigDFTBaseWorkChain"},"bigdft.relax":{description:["Structure relaxation workchain."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"relax",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"StructureData struct"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"extra_retrieved_files",required:!1,valid_types:"List",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"Dict",info:"kpoint mesh or kpoint path"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"BigDFTParameters",info:"param dictionary"},{name:"pseudos",required:!1,valid_types:"List",info:""},{name:"run_opts",required:!1,valid_types:"Dict",info:"metadata"},{name:"show_warnings",required:!1,valid_types:"Bool",info:"turn the warnings on/off."},{name:"structurefile",required:!1,valid_types:"Str",info:"xyz file"}],outputs:[{name:"bigdft_logfile",required:!0,valid_types:"BigDFTLogfile",info:"BigDFT log file as a dict"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"forces",required:!1,valid_types:"ArrayData",info:""},{name:"relaxed_structure",required:!1,valid_types:"StructureData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"total_energy",required:!1,valid_types:"Float",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess failed for relaxation"}]},class:"aiida_bigdft.workflows.relax:BigDFTRelaxWorkChain"}}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:2},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-bigdft",is_installable:"True"},"aiida-castep":{code_home:"https://gitlab.com/bz1/aiida-castep",development_status:"stable",documentation_url:"https://aiida-castep.readthedocs.io/",entry_point_prefix:"castep",pip_url:"aiida-castep",plugin_info:"https://gitlab.com/bz1/aiida-castep/raw/master/setup.json",name:"aiida-castep",package_name:"aiida_castep",hosted_on:"gitlab.com",metadata:{release_date:"2022-05-26",description:"AiiDA plugin for CASTEP",author:"Bonan Zhu",author_email:"zhubonan@outlook.com",license:"MIT License",home_page:"https://github.com/zhubonan/aiida-castep",classifiers:["Framework :: AiiDA","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.1"},aiida_version:">=2.0,<3.0",entry_points:{"aiida.calculations":{"castep.castep":{description:["Class representing a generic CASTEP calculation -","    This class should work for all types of calculations."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"A node that defines the input parameters"},{name:"pseudos",required:!0,valid_types:"",info:"Use nodes for the pseudopotentails of one ofthe element in the structure. You should pass aa dictionary specifying the pseudpotential node foreach kind such as {O: <PsudoNode>}"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bs_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: bandstructure"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"elnes_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: elnes"},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Use a node defining the kpoints for the calculation"},{name:"magres_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: magres"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"optics_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: optics"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"phonon_fine_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"phonon_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"A node for additional settings"},{name:"spectral_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: spectral"},{name:"supercell_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Parsed results in a dictionary format."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation terminated gracefully, end found"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"SCF Cycles failed to reach convergence"},{status:103,message:"Stopped execuation due to detection of 'stop ' keyword in param file."},{status:104,message:"CASTEP generate error files. Check them for details"},{status:105,message:"Cannot find the end of calculation"},{status:106,message:"No output .castep files found"},{status:107,message:"Calculation self-terminated due to time limit"},{status:108,message:"No retrieve folder is found"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"UNKOWN ERROR"},{status:501,message:"At least one kpoints/spin has no empty bands - please rerun with increased nextra_bands."}]},class:"aiida_castep.calculations.castep:CastepCalculation"},"castep.ts":{description:["CASTEP calculation for transition state search. Use an extra input product structure."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"A node that defines the input parameters"},{name:"product_structure",required:!0,valid_types:"StructureData",info:"Product structure for transition state search."},{name:"pseudos",required:!0,valid_types:"",info:"Use nodes for the pseudopotentails of one ofthe element in the structure. You should pass aa dictionary specifying the pseudpotential node foreach kind such as {O: <PsudoNode>}"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bs_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: bandstructure"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"elnes_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: elnes"},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Use a node defining the kpoints for the calculation"},{name:"magres_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: magres"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"optics_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: optics"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"phonon_fine_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"phonon_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon, phonon+efield"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"A node for additional settings"},{name:"spectral_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: spectral"},{name:"supercell_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Extra kpoints input for task: phonon"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Parsed results in a dictionary format."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation terminated gracefully, end found"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"SCF Cycles failed to reach convergence"},{status:103,message:"Stopped execuation due to detection of 'stop ' keyword in param file."},{status:104,message:"CASTEP generate error files. Check them for details"},{status:105,message:"Cannot find the end of calculation"},{status:106,message:"No output .castep files found"},{status:107,message:"Calculation self-terminated due to time limit"},{status:108,message:"No retrieve folder is found"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"UNKOWN ERROR"},{status:501,message:"At least one kpoints/spin has no empty bands - please rerun with increased nextra_bands."}]},class:"aiida_castep.calculations.castep:CastepTSCalculation"}},"aiida.cmdline.data":{"castep-helper":"aiida_castep.cmdline.helper_cmd:helper_cmd","castep-pseudos":"aiida_castep.cmdline.otfg_cmd:pseudos_cmd"},"aiida.data":{"castep.otfgdata":"aiida_castep.data.otfg:OTFGData","castep.uspdata":"aiida_castep.data.usp:UspData"},"aiida.groups":{"castep.otfg":"aiida_castep.data.otfg:OTFGGroup"},"aiida.parsers":{"castep.castep":"aiida_castep.parsers.castep:CastepParser"},"aiida.tests":{"castep.calculation":"aiida_castep.tests.dbtests.dbtestcalculation"},"aiida.tools.calculations":{"castep.castep":"aiida_castep.calculations.tools:CastepCalcTools"},"aiida.workflows":{"castep.altrelax":{description:["A relaxation workflow that alternates between fixed cell and unfixed cell","    This is meidate the problem in CASTEP where if the cell is partially constraints","    the convergence would be very slow.","","    To overcome this problem, the structure should be relaxed with cell constraints","    then restart with fixed cell and repeat.","","    Following fields can be used in ``relax_options``","","    :var_cell_iter_max: Maximum iterations in variable cell relaxation, default to 10","","    :fix_cell_iter_max: Maximum iterations in fixed cell relaxation, default to 20"],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:""},{name:"calc",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for relaxation."},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations at the end of the workchain. The default is not performing any cleaning."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax_options",required:!1,valid_types:"Dict, NoneType",info:"Options for relaxation."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess lauched has failed in the relax stage"},{status:102,message:"Geometry optimisation is not converged but the maximum iteration is exceeded."},{status:201,message:"NO cell_constraints find in the input"}]},class:"aiida_castep.workflows.relax:CastepAlterRelaxWorkChain"},"castep.bands":{description:["Workchain for running bands calculation.","","    This workchain does the following:","","    1. Relax the structure if requested (eg. inputs passed to the relax namespace).","    2. Optionally: Do a SCF singlepoint calculation","    3. Do combined SCF + non-SCF calculation for bands and dos.","","    Inputs must be passed for the SCF calculation (dispatched to bands and DOS),","    others are optional.","","    Input for bands and dos calculations are optional. However, if they are needed, the full list of inputs must","    be passed. For the `parameters` node, one may choose to only specify those fields that need to be updated."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:"Inputs for SCF workchain, mandatory. Used as template for bands/dos if not supplied separately"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure"},{name:"bands",required:!1,valid_types:"Data",info:"Inputs for bands calculation, if needed"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Explicit kpoints for the bands"},{name:"bands_kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"Spacing for band distances, used by seekpath"},{name:"clean_children_workdir",required:!1,valid_types:"Str, NoneType",info:"What part of the called children to clean"},{name:"dos",required:!1,valid_types:"Data",info:"Inputs for DOS calculation, if needed"},{name:"dos_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Kpoints for running DOS calculations"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"only_dos",required:!1,valid_types:"",info:"Flag for running only DOS calculations"},{name:"options",required:!1,valid_types:"",info:"Options for this workchain. Supported keywords: dos_smearing, dos_npoints."},{name:"relax",required:!1,valid_types:"Data",info:"Inputs for Relaxation workchain, if needed"},{name:"run_separate_scf",required:!1,valid_types:"",info:"Flag for running a separate SCF calculation, default to False"}],outputs:[{name:"band_structure",required:!0,valid_types:"",info:"Computed band structure with labels"},{name:"dos_bands",required:!1,valid_types:"",info:"Bands from the DOS calculation"},{name:"primitive_structure",required:!1,valid_types:"",info:"Primitive structure used for band structure calculations"},{name:"seekpath_parameters",required:!1,valid_types:"",info:"Parameters used by seekpath"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:501,message:"Relaxation workchain failed"},{status:502,message:"SCF workchain failed"},{status:503,message:"Band structure workchain failed"},{status:504,message:"DOS workchain failed"}]},class:"aiida_castep.workflows.bands:CastepBandsWorkChain"},"castep.base":{description:["A basic workchain for generic CASTEP calculations.","    We try to handle erros such as walltime exceeded or SCF not converged"],spec:{inputs:[{name:"calc",required:!0,valid_types:"Data",info:""},{name:"calc_options",required:!1,valid_types:"Dict, NoneType",info:"Options to be passed to calculations's metadata.options"},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations or not, the default is not clean."},{name:"continuation_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."},{name:"ensure_gamma_centering",required:!1,valid_types:"Bool, NoneType",info:"Ensure the kpoint grid is gamma centred."},{name:"kpoints_spacing",required:!1,valid_types:"Float, NoneType",info:"Kpoint spacing"},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of restarts"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:"Options specific to the workchain.Avaliable options: queue_wallclock_limit, use_castep_bin"},{name:"pseudos_family",required:!1,valid_types:"Str, NoneType",info:"Pseudopotential family to be used"},{name:"reuse_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote folder as the parent folder. Useful for restarts."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"The maximum number of iterations has been exceeded"},{status:201,message:"The maximum length of the wallclocks has been exceeded"},{status:301,message:"CASTEP generated error files and is not recoverable"},{status:302,message:"Cannot reach SCF convergence despite restart efforts"},{status:400,message:"The stop flag has been put in the .param file to request termination of the calculation."},{status:900,message:"Input validate is failed"},{status:901,message:"Completed one iteration but found not calculation returned"},{status:1e3,message:"Error is not known"}]},class:"aiida_castep.workflows.base:CastepBaseWorkChain"},"castep.relax":{description:["WorkChain to relax structures.","    Restart the relaxation calculation until the structure is fully relaxed.","    Each CASTEP relaxation may finish without error with not fully relaxed structure","    if the number of iteration is exceeded (*geom_max_iter*).","    This workchain try to restart such calculations (wrapped in CastepBaseWorkChain)","    until the structure is fully relaxed","","    ``relax_options`` is a Dict of the options avaliable fields are:","","    - restart_mode: mode of restart, choose from ``reuse`` (default), ``structure``,","      ``continuation``.","    - bypass: Bypass relaxation control - e.g. no checking of the convergence.","      Can be used for doing singlepoint calculation."],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:""},{name:"calc",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for relaxation."},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:"Wether to clean the workdir of the calculations at the end of the workchain. The default is not performing any cleaning."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax_options",required:!1,valid_types:"Dict, NoneType",info:"Options for relaxation."}],outputs:[{name:"output_bands",required:!0,valid_types:"BandsData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"output_array",required:!1,valid_types:"ArrayData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"ArrayData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:101,message:"Subprocess lauched has failed in the relax stage"},{status:102,message:"Geometry optimisation is not converged but the maximum iteration is exceeded."}]},class:"aiida_castep.workflows.relax:CastepRelaxWorkChain"}},console_scripts:{"castep.mock":"aiida_castep.cmdline.mock_castep:mock_castep"}},commits_count:4,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:4},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Groups, Tests, ...)",count:5}],pip_install_cmd:"pip install aiida-castep",is_installable:"True"},"aiida-catmap":{code_home:"https://github.com/sudarshanv01/aiida-catmap",entry_point_prefix:"catmap",name:"aiida-catmap",package_name:"aiida_catmap",hosted_on:"github.com",metadata:{author:"Sudarshan Vijay",author_email:"vijays@fysik.dtu.dk",version:"0.2.0a0",description:"AiiDA package that interfaces with Kinetic modelling code CatMAP",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.calculations":{catmap:"aiida_catmap.calculations.catmap:CatMAPCalculation"},"aiida.parsers":{catmap:"aiida_catmap.parsers.catmap:CatMAPParser"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"See source code repository."},"aiida-catmat":{code_home:"https://github.com/pzarabadip/aiida-catmat",entry_point_prefix:"catmat",development_status:"beta",documentation_url:"https://aiida-catmat.readthedocs.io/",pip_url:"aiida-catmat",name:"aiida-catmat",package_name:"aiida_catmat",hosted_on:"github.com",metadata:{release_date:"2022-07-21",description:"Collection of AiiDA WorkChains Developed in Morgan Group",author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",license:"MIT License",home_page:"https://github.com/pzarabadip/aiida-catmat",classifiers:["Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.0.0b0"},aiida_version:null,entry_points:{"aiida.parsers":{vasp_base_parser:"aiida_catmat.parsers:VaspBaseParser"},"aiida.workflows":{"vasp.base":"aiida_catmat.workchains:VaspBaseWorkChain","catmat.vasp_multistage":"aiida_catmat.workchains:VaspMultiStageWorkChain","catmat.vasp_converge":"aiida_catmat.workchains:VaspConvergeWorkChain","catmat.vasp_catmat":"aiida_catmat.workchains:VaspCatMatWorkChain","catmat.vasp_multistage_ddec":"aiida_catmat.workchains:VaspMultiStageDdecWorkChain"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'vasp_base_parser' does not start with prefix 'catmat.'","Entry point 'vasp.base' does not start with prefix 'catmat.'"],summaryinfo:[{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:5}],pip_install_cmd:"pip install --pre aiida-catmat",is_installable:"False",errors:["Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`,"Failed to install plugin aiida-catmat",`<pre>Collecting aiida-catmat
  Downloading aiida-catmat-1.0.0b0.tar.gz (27 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
ERROR: Packages installed from PyPI cannot depend on packages which are not also hosted on PyPI.
aiida-catmat depends on aiida-vasp@ git+https://github.com/aiida-vasp/aiida-vasp.git@14771c14ac5ccb08ac521d5936eb0c4ec5b9337f
</pre>`]},"aiida-ce":{code_home:"https://github.com/unkcpz/aiida-ce",development_status:"beta",entry_point_prefix:"ce",pip_url:"git+https://github.com/unkcpz/aiida-ce",name:"aiida-ce",package_name:"aiida_ce",hosted_on:"github.com",metadata:{author:"unkcpz",author_email:"morty.yu@yahoo.com",version:"0.1.0a0",description:"AiiDA plugin for running cluster expansion using icet.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.0.0,<2.0.0",entry_points:{"aiida.data":{ce:"aiida_ce.data:DiffParameters","ce.structures":"aiida_ce.data.structure_set:StructureSet","ce.cluster":"aiida_ce.data.cluster:ClusterSpaceData"},"aiida.calculations":{"ce.genenum":"aiida_ce.calculations.genenum:EnumCalculation","ce.gensqs":"aiida_ce.calculations.gensqs:SqsCalculation","ce.train":"aiida_ce.calculations.train:TrainCalculation"},"aiida.parsers":{"ce.genenum":"aiida_ce.parsers.genenum:EnumParser","ce.gensqs":"aiida_ce.parsers.gensqs:SqsParser","ce.train":"aiida_ce.parsers.train:TrainParser"},"aiida.cmdline.data":{ce:"aiida_ce.cli:data_cli"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:3},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/unkcpz/aiida-ce",is_installable:"True"},"aiida-champ":{code_home:"https://github.com/TREX-CoE/aiida-champ",development_status:"beta",documentation_url:"http://aiida-champ.readthedocs.io/",entry_point_prefix:"champ",pip_url:"aiida-champ",name:"aiida-champ",package_name:"aiida_champ",hosted_on:"github.com",metadata:{release_date:"2021-12-27",description:"AiiDA plugin that wraps the vmc executable of CHAMP code for computing the total energy and much more stuff.",author:"Ravindra Shinde",author_email:"r.l.shinde@utwente.nl",license:"MIT",home_page:"https://github.com/neelravi/aiida-champ",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"1.2.6"},aiida_version:null,entry_points:{"aiida.data":{CHAMP:"aiida_champ.data:CHAMPParameters"},"aiida.calculations":{CHAMP:{description:["AiiDA calculation plugin wrapping the CHAMP's vmc executable.","","    aiida-champ can be used to manage the workflow of a vmc/dmc calculation of the CHAMP code.","","    Author :: Ravindra Shinde","    Email  :: r.l.shinde@utwente.nl"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"determinants",required:!0,valid_types:"SinglefileData",info:"Input determinants file"},{name:"filemain",required:!0,valid_types:"SinglefileData",info:"Input File"},{name:"molecule",required:!0,valid_types:"SinglefileData",info:"Molecule structure File"},{name:"ecp1",required:!1,valid_types:"SinglefileData",info:"Input ECP file for atom type 1"},{name:"ecp2",required:!1,valid_types:"SinglefileData",info:"Input ECP file for atom type 2"},{name:"jastrow",required:!1,valid_types:"SinglefileData",info:"Input jastrow file"},{name:"jastrowder",required:!1,valid_types:"SinglefileData",info:"Input jastrowder file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"numericalbasis1",required:!1,valid_types:"SinglefileData",info:"Input numerical basis file atom 1"},{name:"numericalbasis2",required:!1,valid_types:"SinglefileData",info:"Input numerical basis file atom 2"},{name:"numericalbasisinfo",required:!1,valid_types:"SinglefileData",info:"Input numerical basis information file"},{name:"orbitals",required:!1,valid_types:"SinglefileData",info:"Input orbitals file"},{name:"symmetry",required:!1,valid_types:"SinglefileData",info:"Input symmetry file"},{name:"trexio",required:!1,valid_types:"SinglefileData",info:"Input trexio hdf5 file"}],outputs:[{name:"Output",required:!0,valid_types:"SinglefileData",info:"Output file of the VMC/DMC calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"Energy",required:!1,valid_types:"Float",info:"Output total energy of the VMC/DMC calculation"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_champ.calculations:CHAMPCalculation"}},"aiida.parsers":{CHAMP:"aiida_champ.parsers:CHAMPParser"},"aiida.cmdline.data":{CHAMP:"aiida_champ.cli:data_cli"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'","Entry point 'CHAMP' does not start with prefix 'champ.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-champ",is_installable:"True"},"aiida-codtools":{code_home:"https://github.com/aiidateam/aiida-codtools",documentation_url:"https://aiida-codtools.readthedocs.io/",entry_point_prefix:"codtools",pip_url:"aiida-codtools",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-codtools/master/setup.json",name:"aiida-codtools",package_name:"aiida_codtools",hosted_on:"github.com",metadata:{release_date:"2023-02-02",description:"The Official AiiDA plugin for the cod-tools package.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"3.1.0"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.calculations":{"codtools.cif_base":{description:["Generic `CalcJob` implementation that can easily be extended to work with any of the `cod-tools` scripts."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_base:CifBaseCalculation"},"codtools.cif_cell_contents":{description:["CalcJob plugin for the `cif_cell_contents` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"formulae",required:!0,valid_types:"Dict",info:"A dictionary of formulae present in the CIF."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cell_contents:CifCellContentsCalculation"},"codtools.cif_cod_check":{description:["CalcJob plugin for the `cif_cod_check` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"messages",required:!0,valid_types:"Dict",info:"Warning and error messages returned by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cod_check:CifCodCheckCalculation"},"codtools.cif_cod_deposit":{description:["CalcJob plugin for the `cif_cod_deposit` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:300,message:"The deposition failed for unknown reasons."},{status:310,message:"The deposition failed because the input was invalid."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."},{status:410,message:"The deposition failed because one or more CIFs already exist in the COD."},{status:420,message:"The structure is unchanged and so deposition is unnecessary."}]},class:"aiida_codtools.calculations.cif_cod_deposit:CifCodDepositCalculation"},"codtools.cif_cod_numbers":{description:["CalcJob plugin for the `cif_cod_numbers` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"numbers",required:!0,valid_types:"Dict",info:"Mapping of COD IDs found with their formula and count."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_cod_numbers:CifCodNumbersCalculation"},"codtools.cif_filter":{description:["CalcJob plugin for the `cif_filter` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_filter:CifFilterCalculation"},"codtools.cif_select":{description:["CalcJob plugin for the `cif_select` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_select:CifSelectCalculation"},"codtools.cif_split_primitive":{description:["CalcJob plugin for the `cif_split_primitive` script of the `cod-tools` package."],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CIF to be processed."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Command line parameters."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cifs",required:!0,valid_types:"CifData",info:"The CIFs produced by the script."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"messages",required:!1,valid_types:"Dict",info:"Warning and error messages returned by script."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Neither the output for the error file could be read from the retrieved folder."},{status:311,message:"The output file could not be read from the retrieved folder."},{status:312,message:"The error file could not be read from the retrieved folder."},{status:313,message:"The output file is empty."},{status:320,message:"Invalid command line option passed."},{status:400,message:"The output file could not be parsed."},{status:410,message:"The output file could not be parsed into a CifData object."}]},class:"aiida_codtools.calculations.cif_split_primitive:CifSplitPrimitiveCalculation"},"codtools.primitive_structure_from_cif":{description:["Attempt to parse the given `CifData` and create a `StructureData` from it.","","    First the raw CIF file is parsed with the given `parse_engine`. The resulting `StructureData` is then passed through","    SeeKpath to try and get the primitive cell. If that is successful, important structural parameters as determined by","    SeeKpath will be set as extras on the structure node which is then returned as output.","","    :param cif: the `CifData` node","    :param parse_engine: the parsing engine, supported libraries 'ase' and 'pymatgen'","    :param symprec: a `Float` node with symmetry precision for determining primitive cell in SeeKpath","    :param site_tolerance: a `Float` node with the fractional coordinate distance tolerance for finding overlapping","        sites. This will only be used if the parse_engine is pymatgen","    :return: the primitive `StructureData` as determined by SeeKpath"],spec:{inputs:[{name:"cif",required:!0,valid_types:"Data",info:"the `CifData` node"},{name:"parse_engine",required:!0,valid_types:"Data",info:"the parsing engine, supported libraries 'ase' and 'pymatgen'"},{name:"site_tolerance",required:!0,valid_types:"Data",info:"a `Float` node with the fractional coordinate distance tolerance for finding overlapping\nsites. This will only be used if the parse_engine is pymatgen"},{name:"symprec",required:!0,valid_types:"Data",info:"a `Float` node with symmetry precision for determining primitive cell in SeeKpath"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_codtools.calculations.functions.primitive_structure_from_cif:primitive_structure_from_cif"}},"aiida.parsers":{"codtools.cif_base":"aiida_codtools.parsers.cif_base:CifBaseParser","codtools.cif_cell_contents":"aiida_codtools.parsers.cif_cell_contents:CifCellContentsParser","codtools.cif_cod_check":"aiida_codtools.parsers.cif_cod_check:CifCodCheckParser","codtools.cif_cod_deposit":"aiida_codtools.parsers.cif_cod_deposit:CifCodDepositParser","codtools.cif_cod_numbers":"aiida_codtools.parsers.cif_cod_numbers:CifCodNumbersParser","codtools.cif_split_primitive":"aiida_codtools.parsers.cif_split_primitive:CifSplitPrimitiveParser"},"aiida.workflows":{"codtools.cif_clean":{description:["WorkChain to clean a `CifData` node using the `cif_filter` and `cif_select` scripts of `cod-tools`.","","    It will first run `cif_filter` to correct syntax errors, followed by `cif_select` which will canonicalize the tags.","    If a group is passed for the `group_structure` input, the atomic structure library defined by the `engine` input","    will be used to parse the final cleaned `CifData` to construct a `StructureData` object, which will then be passed","    to the `SeeKpath` library to analyze it and return the primitive structure"],spec:{inputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The CifData node that is to be cleaned."},{name:"cif_filter",required:!0,valid_types:"Data",info:""},{name:"cif_select",required:!0,valid_types:"Data",info:""},{name:"group_cif",required:!1,valid_types:"Group, NoneType",info:"An optional Group to which the final cleaned CifData node will be added."},{name:"group_structure",required:!1,valid_types:"Group, NoneType",info:"An optional Group to which the final reduced StructureData node will be added."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parse_engine",required:!1,valid_types:"Str",info:"The atomic structure engine to parse the cif and create the structure."},{name:"site_tolerance",required:!1,valid_types:"Float",info:"The fractional coordinate distance tolerance for finding overlapping sites (pymatgen only)."},{name:"symprec",required:!1,valid_types:"Float",info:"The symmetry precision used by SeeKpath for crystal symmetry refinement."}],outputs:[{name:"cif",required:!0,valid_types:"CifData",info:"The cleaned CifData node."},{name:"structure",required:!1,valid_types:"StructureData",info:"The primitive cell structure created with SeeKpath from the cleaned CifData."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The CifFilterCalculation step failed."},{status:402,message:"The CifSelectCalculation step failed."},{status:410,message:"The cleaned CifData contains sites with unknown species."},{status:411,message:"The cleaned CifData defines no atomic sites."},{status:412,message:"The cleaned CifData defines sites with attached hydrogens with incomplete positional data."},{status:413,message:"The cleaned CifData defines sites with invalid atomic occupancies."},{status:414,message:"Failed to parse a StructureData from the cleaned CifData."},{status:420,message:"SeeKpath failed to determine the primitive structure."},{status:421,message:"SeeKpath detected inconsistent symmetry operations."}]},class:"aiida_codtools.workflows.cif_clean:CifCleanWorkChain"}},console_scripts:{"aiida-codtools":"aiida_codtools.cli:cmd_root"}},commits_count:4,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:9},{colorclass:"brown",text:"Parsers",count:6},{colorclass:"green",text:"Workflows",count:1},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-codtools",is_installable:"True"},"aiida-core":{code_home:"https://github.com/aiidateam/aiida-core",development_status:"stable",documentation_url:"https://aiida-core.readthedocs.io/",entry_point_prefix:"",package_name:"aiida",pip_url:"aiida-core",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-core/master/setup.json",name:"aiida-core",hosted_on:"github.com",metadata:{release_date:"2023-06-23",description:"AiiDA is a workflow manager for computational science with a strong focus on provenance, performance and extensibility.",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"2.4.0"},aiida_version:"==2.4.0",entry_points:{"aiida.calculations":{"core.arithmetic.add":{description:["`CalcJob` implementation to add two numbers using bash for testing and demonstration purposes."],spec:{inputs:[{name:"x",required:!0,valid_types:"Int, Float",info:"The left operand."},{name:"y",required:!0,valid_types:"Int, Float",info:"The right operand."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"sum",required:!0,valid_types:"Int, Float",info:"The sum of the left and right operand."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:310,message:"The output file could not be read."},{status:320,message:"The output file contains invalid output."},{status:410,message:"The sum of the operands is a negative number."}]},class:"aiida.calculations.arithmetic.add:ArithmeticAddCalculation"},"core.templatereplacer":{description:["Simple stub of a plugin that can be used to replace some text in a given template.","    Can be used for many different codes, or as a starting point to develop a new plugin.","","    This simple plugin takes two node inputs, both of type Dict, with the labels","    'parameters' and 'template'","","    You can also add other SinglefileData nodes as input, that will be copied according to","    what is written in 'template' (see below).","","    * parameters: a set of parameters that will be used for substitution.","","    * template: can contain the following parameters:","","        * input_file_template: a string with substitutions to be managed with the format()","          function of python, i.e. if you want to substitute a variable called 'varname', you write","          {varname} in the text. See http://www.python.org/dev/peps/pep-3101/ for more","          details. The replaced file will be the input file.","","        * input_file_name: a string with the file name for the input. If it is not provided, no","          file will be created.","","        * output_file_name: a string with the file name for the output. If it is not provided, no","          redirection will be done and the output will go in the scheduler output file.","","        * cmdline_params: a list of strings, to be passed as command line parameters.","          Each one is substituted with the same rule of input_file_template. Optional","","        * input_through_stdin: if True, the input file name is passed via stdin. Default is False if missing.","","        * files_to_copy: if defined, a list of tuple pairs, with format ('link_name', 'dest_rel_path');","            for each tuple, an input link to this calculation is looked for, with link labeled 'link_label',","            and with file type 'Singlefile', and the content is copied to a remote file named 'dest_rel_path'","            Errors are raised in the input links are non-existent, or of the wrong type, or if there are","            unused input files.","","        * retrieve_temporary_files: a list of relative filepaths, that if defined, will be retrieved and","            temporarily stored in an unstored FolderData node that will be available during the","            Parser.parser_with_retrieved call under the key specified by the Parser.retrieved_temporary_folder key"],spec:{inputs:[{name:"template",required:!0,valid_types:"Dict",info:"A template for the input file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"files",required:!1,valid_types:"RemoteData, SinglefileData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters used to replace placeholders in the template."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The temporary retrieved folder data node could not be accessed."},{status:305,message:"The `template` input node did not specify the key `output_file_name`."},{status:310,message:"The output file could not be read from the retrieved folder."},{status:311,message:"A temporary retrieved file could not be read from the temporary retrieved folder."},{status:320,message:"The output file contains invalid output."}]},class:"aiida.calculations.templatereplacer:TemplatereplacerCalculation"},"core.transfer":{description:["Utility to copy files from different FolderData and RemoteData nodes into a single place.","","    The final destination for these files can be either the local repository (by creating a","    new FolderData node to store them) or in the remote computer (by leaving the files in a","    new remote folder saved in a RemoteData node).","","    Only files from the local computer and from remote folders in the same external computer","    can be moved at the same time with a single instance of this CalcJob.","","    The user needs to provide three inputs:","","        * ``instructions``: a dict node specifying which files to copy from which nodes.","        * ``source_nodes``: a dict of nodes, each with a unique identifier label as its key.","        * ``metadata.computer``: the computer that contains the remote files and will contain","          the final RemoteData node.","","    The ``instructions`` dict must have the ``retrieve_files`` flag. The CalcJob will create a","    new folder in the remote machine (``RemoteData``) and put all the files there and will either:","","        (1) leave them there (``retrieve_files = False``) or ...","        (2) retrieve all the files and store them locally in a ``FolderData``  (``retrieve_files = True``)","","    The `instructions` dict must also contain at least one list with specifications of which files","    to copy and from where. All these lists take tuples of 3 that have the following format:","","    .. code-block:: python","","        ( source_node_key, path_to_file_in_source, path_to_file_in_target)","","    where the ``source_node_key`` has to be the respective one used when providing the node in the","    ``source_nodes`` input nodes dictionary.","","","    The two main lists to include are ``local_files`` (for files to be taken from FolderData nodes)","    and ``remote_files`` (for files to be taken from RemoteData nodes). Alternatively, files inside","    of RemoteData nodes can instead be put in the ``symlink_files`` list: the only difference is that","    files from the first list will be fully copied in the target RemoteData folder, whereas for the","    files in second list only a symlink to the original file will be created there. This will only","    affect the content of the final RemoteData target folder, but in both cases the full file will","    be copied back in the local target FolderData (if ``retrieve_files = True``)."],spec:{inputs:[{name:"instructions",required:!0,valid_types:"Dict",info:"A dictionary containing the `retrieve_files` flag and at least one of the file lists:`local_files`, `remote_files` and/or `symlink_files`."},{name:"source_nodes",required:!0,valid_types:"FolderData, RemoteData",info:"All the nodes that contain files referenced in the instructions."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida.calculations.transfer:TransferCalculation"}},"aiida.calculations.importers":{"core.arithmetic.add":"aiida.calculations.importers.arithmetic.add:ArithmeticAddCalculationImporter"},"aiida.calculations.monitors":{"core.always_kill":"aiida.calculations.monitors.base:always_kill"},"aiida.cmdline.computer.configure":{"core.local":"aiida.transports.plugins.local:CONFIGURE_LOCAL_CMD","core.ssh":"aiida.transports.plugins.ssh:CONFIGURE_SSH_CMD"},"aiida.cmdline.data":{"core.array":"aiida.cmdline.commands.cmd_data.cmd_array:array","core.bands":"aiida.cmdline.commands.cmd_data.cmd_bands:bands","core.cif":"aiida.cmdline.commands.cmd_data.cmd_cif:cif","core.dict":"aiida.cmdline.commands.cmd_data.cmd_dict:dictionary","core.remote":"aiida.cmdline.commands.cmd_data.cmd_remote:remote","core.singlefile":"aiida.cmdline.commands.cmd_data.cmd_singlefile:singlefile","core.structure":"aiida.cmdline.commands.cmd_data.cmd_structure:structure","core.trajectory":"aiida.cmdline.commands.cmd_data.cmd_trajectory:trajectory","core.upf":"aiida.cmdline.commands.cmd_data.cmd_upf:upf"},"aiida.cmdline.data.structure.import":{},"aiida.data":{"core.array":"aiida.orm.nodes.data.array.array:ArrayData","core.array.bands":"aiida.orm.nodes.data.array.bands:BandsData","core.array.kpoints":"aiida.orm.nodes.data.array.kpoints:KpointsData","core.array.projection":"aiida.orm.nodes.data.array.projection:ProjectionData","core.array.trajectory":"aiida.orm.nodes.data.array.trajectory:TrajectoryData","core.array.xy":"aiida.orm.nodes.data.array.xy:XyData","core.base":"aiida.orm.nodes.data:BaseType","core.bool":"aiida.orm.nodes.data.bool:Bool","core.cif":"aiida.orm.nodes.data.cif:CifData","core.code":"aiida.orm.nodes.data.code.legacy:Code","core.code.containerized":"aiida.orm.nodes.data.code.containerized:ContainerizedCode","core.code.installed":"aiida.orm.nodes.data.code.installed:InstalledCode","core.code.portable":"aiida.orm.nodes.data.code.portable:PortableCode","core.dict":"aiida.orm.nodes.data.dict:Dict","core.enum":"aiida.orm.nodes.data.enum:EnumData","core.float":"aiida.orm.nodes.data.float:Float","core.folder":"aiida.orm.nodes.data.folder:FolderData","core.int":"aiida.orm.nodes.data.int:Int","core.jsonable":"aiida.orm.nodes.data.jsonable:JsonableData","core.list":"aiida.orm.nodes.data.list:List","core.numeric":"aiida.orm.nodes.data.numeric:NumericType","core.orbital":"aiida.orm.nodes.data.orbital:OrbitalData","core.remote":"aiida.orm.nodes.data.remote.base:RemoteData","core.remote.stash":"aiida.orm.nodes.data.remote.stash.base:RemoteStashData","core.remote.stash.folder":"aiida.orm.nodes.data.remote.stash.folder:RemoteStashFolderData","core.singlefile":"aiida.orm.nodes.data.singlefile:SinglefileData","core.str":"aiida.orm.nodes.data.str:Str","core.structure":"aiida.orm.nodes.data.structure:StructureData","core.upf":"aiida.orm.nodes.data.upf:UpfData"},"aiida.groups":{core:"aiida.orm.groups:Group","core.auto":"aiida.orm.groups:AutoGroup","core.import":"aiida.orm.groups:ImportGroup","core.upf":"aiida.orm.groups:UpfFamily"},"aiida.node":{data:"aiida.orm.nodes.data.data:Data",process:"aiida.orm.nodes.process.process:ProcessNode","process.calculation":"aiida.orm.nodes.process.calculation.calculation:CalculationNode","process.calculation.calcfunction":"aiida.orm.nodes.process.calculation.calcfunction:CalcFunctionNode","process.calculation.calcjob":"aiida.orm.nodes.process.calculation.calcjob:CalcJobNode","process.workflow":"aiida.orm.nodes.process.workflow.workflow:WorkflowNode","process.workflow.workchain":"aiida.orm.nodes.process.workflow.workchain:WorkChainNode","process.workflow.workfunction":"aiida.orm.nodes.process.workflow.workfunction:WorkFunctionNode"},"aiida.parsers":{"core.arithmetic.add":"aiida.parsers.plugins.arithmetic.add:ArithmeticAddParser","core.templatereplacer":"aiida.parsers.plugins.templatereplacer.parser:TemplatereplacerParser"},"aiida.schedulers":{"core.direct":"aiida.schedulers.plugins.direct:DirectScheduler","core.lsf":"aiida.schedulers.plugins.lsf:LsfScheduler","core.pbspro":"aiida.schedulers.plugins.pbspro:PbsproScheduler","core.sge":"aiida.schedulers.plugins.sge:SgeScheduler","core.slurm":"aiida.schedulers.plugins.slurm:SlurmScheduler","core.torque":"aiida.schedulers.plugins.torque:TorqueScheduler"},"aiida.storage":{"core.psql_dos":"aiida.storage.psql_dos.backend:PsqlDosBackend","core.sqlite_temp":"aiida.storage.sqlite_temp.backend:SqliteTempBackend","core.sqlite_zip":"aiida.storage.sqlite_zip.backend:SqliteZipBackend"},"aiida.tools.calculations":{},"aiida.tools.data.orbitals":{"core.orbital":"aiida.tools.data.orbital.orbital:Orbital","core.realhydrogen":"aiida.tools.data.orbital.realhydrogen:RealhydrogenOrbital"},"aiida.tools.dbexporters":{},"aiida.tools.dbimporters":{"core.cod":"aiida.tools.dbimporters.plugins.cod:CodDbImporter","core.icsd":"aiida.tools.dbimporters.plugins.icsd:IcsdDbImporter","core.materialsproject":"aiida.tools.dbimporters.plugins.materialsproject:MaterialsProjectImporter","core.mpds":"aiida.tools.dbimporters.plugins.mpds:MpdsDbImporter","core.mpod":"aiida.tools.dbimporters.plugins.mpod:MpodDbImporter","core.nninc":"aiida.tools.dbimporters.plugins.nninc:NnincDbImporter","core.oqmd":"aiida.tools.dbimporters.plugins.oqmd:OqmdDbImporter","core.pcod":"aiida.tools.dbimporters.plugins.pcod:PcodDbImporter","core.tcod":"aiida.tools.dbimporters.plugins.tcod:TcodDbImporter"},"aiida.transports":{"core.local":"aiida.transports.plugins.local:LocalTransport","core.ssh":"aiida.transports.plugins.ssh:SshTransport"},"aiida.workflows":{"core.arithmetic.add_multiply":{description:["Add two numbers and multiply it with a third."],spec:{inputs:[{name:"x",required:!0,valid_types:"Data",info:""},{name:"y",required:!0,valid_types:"Data",info:""},{name:"z",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida.workflows.arithmetic.add_multiply:add_multiply"},"core.arithmetic.multiply_add":{description:["WorkChain to multiply two numbers and add a third, for testing and demonstration purposes."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode",info:""},{name:"x",required:!0,valid_types:"Int",info:""},{name:"y",required:!0,valid_types:"Int",info:""},{name:"z",required:!0,valid_types:"Int",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"result",required:!0,valid_types:"Int",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The result is a negative number."}]},class:"aiida.workflows.arithmetic.multiply_add:MultiplyAddWorkChain"}},console_scripts:{runaiida:"aiida.cmdline.commands.cmd_run:run",verdi:"aiida.cmdline.commands.cmd_verdi:verdi"}},commits_count:351,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:29},{colorclass:"green",text:"Workflows",count:2},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Calculations importers, Calculations monitors, Cmdline computer configure, ...)",count:47}],pip_install_cmd:"pip install aiida-core",is_installable:"True"},"aiida-cp2k":{code_home:"https://github.com/cp2k/aiida-cp2k",entry_point_prefix:"cp2k",pip_url:"aiida-cp2k",plugin_info:"https://raw.githubusercontent.com/cp2k/aiida-cp2k/master/setup.json",name:"aiida-cp2k",package_name:"aiida_cp2k",hosted_on:"github.com",metadata:{release_date:"2023-03-06",description:"The official AiiDA plugin for CP2K.",author:"The AiiDA team",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3"],version:"2.0.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{cp2k:{description:["This is a Cp2kCalculation, subclass of JobCalculation, to prepare input for an ab-initio CP2K calculation.","","    For information on CP2K, refer to: https://www.cp2k.org."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters."},{name:"basissets",required:!1,valid_types:"",info:"A dictionary of basissets to be used in the calculations: key is the atomic symbol, value is either a single basisset or a list of basissets. If multiple basissets for a single symbol are passed, it is mandatory to specify a KIND section with a BASIS_SET keyword matching the names (or aliases) of the basissets."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"file",required:!1,valid_types:"SinglefileData, StructureData",info:"Additional input files."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Input kpoint mesh."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Working directory of a previously ran calculation to restart from."},{name:"pseudos",required:!1,valid_types:"",info:"A dictionary of pseudopotentials to be used in the calculations: key is the atomic symbol, value is either a single pseudopotential or a list of pseudopotentials. If multiple pseudos for a single symbol are passed, it is mandatory to specify a KIND section with a PSEUDOPOTENTIAL keyword matching the names (or aliases) of the pseudopotentials."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional input parameters."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"The main input structure."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output dictionary containing results of the calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Computed electronic band structure."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required output file."},{status:301,message:"The output file could not be read."},{status:302,message:"The output file could not be parsed."},{status:303,message:"The output file was incomplete."},{status:304,message:'The output file contains the word "ABORT".'},{status:312,message:"The output structure could not be parsed."},{status:350,message:"The parser raised an unexpected exception."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"The maximum number of optimization steps reached."}]},class:"aiida_cp2k.calculations:Cp2kCalculation"}},"aiida.parsers":{cp2k_advanced_parser:"aiida_cp2k.parsers:Cp2kAdvancedParser",cp2k_base_parser:"aiida_cp2k.parsers:Cp2kBaseParser",cp2k_tools_parser:"aiida_cp2k.parsers:Cp2kToolsParser"},"aiida.workflows":{"cp2k.base":{description:["Workchain to run a CP2K calculation with automated error handling and restarts."],spec:{inputs:[{name:"cp2k",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output dictionary containing results of the calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"final_input_parameters",required:!1,valid_types:"Dict",info:"The input parameters used for the final calculation."},{name:"output_bands",required:!1,valid_types:"BandsData",info:"Computed electronic band structure."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed with a known unrecoverable error."},{status:400,message:"The calculation didn't produce any data to restart from."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_cp2k.workchains:Cp2kBaseWorkChain"}}},commits_count:23,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-cp2k",is_installable:"True"},"aiida-crystal-dft":{code_home:"https://github.com/tilde-lab/aiida-crystal-dft",development_status:"beta",documentation_url:"https://github.com/tilde-lab/aiida-crystal-dft",entry_point_prefix:"crystal_dft",pip_url:"git+https://github.com/tilde-lab/aiida-crystal-dft",name:"aiida-crystal-dft",package_name:"aiida_crystal_dft",hosted_on:"github.com",metadata:{description:`Yet another AiiDA plugin for CRYSTAL code, mainly intended for use with the cloud infrastructures
(currently, MPDS)`,classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Intended Audience :: Science/Research","Operating System :: OS Independent","Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Python :: 3.10","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Information Analysis"],author:"Andrey Sobolev, based on aiida-crystal17 plugin by Chris Sewell",author_email:"as@tilde.pro"},aiida_version:">=2.0.2",entry_points:{"aiida.data":{"crystal_dft.basis":"aiida_crystal_dft.data.basis:CrystalBasisData","crystal_dft.basis_family":"aiida_crystal_dft.data.basis_family:CrystalBasisFamilyData"},"aiida.calculations":{"crystal_dft.serial":{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"basis",required:!1,valid_types:"CrystalBasisData",info:""},{name:"basis_family",required:!1,valid_types:"CrystalBasisFamilyData, NoneType",info:""},{name:"guess_oxistates",required:!1,valid_types:"Bool, NoneType",info:""},{name:"high_spin_preferred",required:!1,valid_types:"Bool, NoneType",info:""},{name:"is_magnetic",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"spinlock_steps",required:!1,valid_types:"Int, NoneType",info:""},{name:"use_oxistates",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"oxidation_states",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"SCF calculation not converged"},{status:301,message:"Geometry optimization failed"},{status:302,message:"Unit cell not neutral"},{status:303,message:"Basis set linearly dependent"},{status:304,message:"Neighbour list too large"},{status:305,message:"No G-vectors left"},{status:306,message:"Collapsed geometry"},{status:307,message:"Closed shell run - spin polarization not allowed"},{status:308,message:"Parameters for model hessian not defined"},{status:309,message:"Fermi energy not in interval"},{status:310,message:"Insufficient indices for Madelung sums"},{status:350,message:"Internal memory error"},{status:360,message:"Inadequate elastic calculation: additional optimization needed"},{status:400,message:"Unknown error"},{status:401,message:"The retrieved folder data node could not be accessed"}]},class:"aiida_crystal_dft.calculations.serial:CrystalSerialCalculation"},"crystal_dft.parallel":{description:["No description available"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"basis",required:!1,valid_types:"CrystalBasisData",info:""},{name:"basis_family",required:!1,valid_types:"CrystalBasisFamilyData, NoneType",info:""},{name:"guess_oxistates",required:!1,valid_types:"Bool, NoneType",info:""},{name:"high_spin_preferred",required:!1,valid_types:"Bool, NoneType",info:""},{name:"is_magnetic",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"spinlock_steps",required:!1,valid_types:"Int, NoneType",info:""},{name:"use_oxistates",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"oxidation_states",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"SCF calculation not converged"},{status:301,message:"Geometry optimization failed"},{status:302,message:"Unit cell not neutral"},{status:303,message:"Basis set linearly dependent"},{status:304,message:"Neighbour list too large"},{status:305,message:"No G-vectors left"},{status:306,message:"Collapsed geometry"},{status:307,message:"Closed shell run - spin polarization not allowed"},{status:308,message:"Parameters for model hessian not defined"},{status:309,message:"Fermi energy not in interval"},{status:310,message:"Insufficient indices for Madelung sums"},{status:350,message:"Internal memory error"},{status:360,message:"Inadequate elastic calculation: additional optimization needed"},{status:400,message:"Unknown error"},{status:401,message:"The retrieved folder data node could not be accessed"}]},class:"aiida_crystal_dft.calculations.parallel:CrystalParallelCalculation"},"crystal_dft.properties":{description:["AiiDA calculation plugin wrapping the properties executable."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"wavefunction",required:!0,valid_types:"SinglefileData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_bands",required:!1,valid_types:"BandsData",info:""},{name:"output_bands_down",required:!1,valid_types:"BandsData",info:""},{name:"output_dos",required:!1,valid_types:"ArrayData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed"},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_crystal_dft.calculations.properties:PropertiesCalculation"}},"aiida.parsers":{crystal_dft:"aiida_crystal_dft.parsers.cry_pycrystal:CrystalParser","crystal_dft.properties":"aiida_crystal_dft.parsers.properties:PropertiesParser"},"aiida.workflows":{"crystal_dft.base":{description:["Run CRYSTAL calculation"],spec:{inputs:[{name:"basis_family",required:!0,valid_types:"CrystalBasisFamilyData",info:""},{name:"code",required:!0,valid_types:"Code",info:""},{name:"options",required:!0,valid_types:"Dict",info:"Calculation options"},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_params",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:""},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"output_wavefunction",required:!1,valid_types:"SinglefileData",info:""},{name:"oxidation_states",required:!1,valid_types:"Dict",info:""},{name:"primitive_structure",required:!1,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"CRYSTAL error"},{status:400,message:"Unknown error"}]},class:"aiida_crystal_dft.workflows.base:BaseCrystalWorkChain"}},"aiida.cmdline.data":{crystal_dft:"aiida_crystal_dft.cli.basis:basis_set"}},commits_count:18,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/tilde-lab/aiida-crystal-dft",is_installable:"True"},"aiida-crystal17":{code_home:"https://github.com/aiidaplugins/aiida-crystal17",development_status:"beta",documentation_url:"https://aiida-crystal17.readthedocs.io",entry_point_prefix:"crystal17",pip_url:"aiida-crystal17",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-crystal17/master/setup.json",name:"aiida-crystal17",package_name:"aiida_crystal17",hosted_on:"github.com",metadata:{release_date:"2020-09-29",description:"AiiDA plugin for running the CRYSTAL17 code",author:"Chris Sewell",author_email:"chrisj_sewell@hotmail.com",license:"MIT",home_page:"https://github.com/chrisjsewell/aiida-crystal17",classifiers:["Framework :: AiiDA","Programming Language :: Python","Programming Language :: Python :: 2.7","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"0.11.0"},aiida_version:">=1.4.0,<2.0.0",entry_points:{"aiida.calculations":{"crystal17.basic":{description:["AiiDA calculation plugin to run the crystal17 executable,","    by supplying a normal .d12 input file and (optional) .gui file"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"input_file",required:!0,valid_types:"SinglefileData",info:"the input .d12 file content."},{name:"input_external",required:!1,valid_types:"SinglefileData",info:"optional input fort.34 (gui) file content (for use with EXTERNAL keyword)."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:301,message:"An error occurred parsing the 'opta'/'optc' geometry files"},{status:302,message:"The crystal exec stdout file denoted that the run was a testgeom"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:411,message:"SCF convergence did not finalise (usually due to reaching step limit)"},{status:412,message:"Geometry convergence did not finalise (usually due to reaching step limit)"},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"},{status:510,message:"inconsistency in the input and output symmetry"},{status:520,message:"primitive symmops were not found in the output file"}]},class:"aiida_crystal17.calculations.cry_basic:CryBasicCalculation"},"crystal17.doss":{description:["AiiDA calculation plugin to run the ``properties`` executable,","    for DOSS calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"arrays",required:!1,valid_types:"ArrayData",info:"energies and DoS arrays"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output isovalue (fort.25) file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output isovalue (fort.25) file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_doss:CryDossCalculation"},"crystal17.ech3":{description:["AiiDA calculation plugin to run the ``properties`` executable, for 3D charge density (ECH3)."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"charge",required:!0,valid_types:"GaussianCube",info:"The charge density cube"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"spin",required:!1,valid_types:"GaussianCube",info:"The spin density cube"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output density file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output density file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_ech3:CryEch3Calculation"},"crystal17.main":{description:["AiiDA calculation plugin to run the crystal17 executable,","    by supplying aiida nodes, with data sufficient to create the","    .d12 input file and .gui file"],spec:{inputs:[{name:"basissets",required:!0,valid_types:"BasisSetData",info:"Use a node for the basis set of one of the elements in the structure. You have to pass an additional parameter ('element') specifying the atomic element symbol for which you want to use this basis set."},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"CryInputParamsData",info:"the input parameters to create the .d12 file content."},{name:"structure",required:!0,valid_types:"StructureData",info:"structure used to construct the input fort.34 (gui) file"},{name:"kinds",required:!1,valid_types:"KindData",info:"additional structure kind specific data (e.g. initial spin)"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry of the structure, used to construct the input .gui file (fort.34)"},{name:"wf_folder",required:!1,valid_types:"RemoteData",info:"An optional working directory, of a previously completed calculation, containing a fort.9 wavefunction file to restart from"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"optimisation",required:!1,valid_types:"TrajectoryData",info:"atomic configurations, for each optimisation step"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:301,message:"An error occurred parsing the 'opta'/'optc' geometry files"},{status:302,message:"The crystal exec stdout file denoted that the run was a testgeom"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:411,message:"SCF convergence did not finalise (usually due to reaching step limit)"},{status:412,message:"Geometry convergence did not finalise (usually due to reaching step limit)"},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"},{status:510,message:"inconsistency in the input and output symmetry"},{status:520,message:"primitive symmops were not found in the output file"}]},class:"aiida_crystal17.calculations.cry_main:CryMainCalculation"},"crystal17.newk":{description:["AiiDA calculation plugin to run the properties17 executable,","    for NEWK calculations (to return the fermi energy)"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_newk:CryNewkCalculation"},"crystal17.ppan":{description:["AiiDA calculation plugin to run the ``properties`` executable,","    for PPAN (Mulliken population analysis) calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"the input parameters to create the properties input file."},{name:"wf_folder",required:!0,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"Summary Data extracted from the output file(s)"},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"the main (stdout) output file was not found"},{status:211,message:"the temporary retrieved folder was not found"},{status:300,message:"An error was flagged trying to parse the crystal exec stdout file"},{status:350,message:"the input file could not be read by CRYSTAL"},{status:351,message:"CRYSTAL could not find the required wavefunction file"},{status:352,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:352,message:"parser could not find the output PPAN.dat file"},{status:353,message:"Possibly due to erroneous CHEMOD basis set modification"},{status:353,message:"error parsing output PPAN.dat file"},{status:354,message:"Error in CHEMOD basis set modification"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:401,message:"The calculation stopped prematurely because it ran out of memory."},{status:402,message:"The calculation stopped prematurely because it ran out of virtual memory."},{status:413,message:"an error encountered usually during geometry optimisation"},{status:414,message:"an error was encountered during an SCF computation"},{status:415,message:"an unknown error was encountered, causing the MPI to abort"},{status:499,message:"The main crystal output file flagged an unhandled error"}]},class:"aiida_crystal17.calculations.prop_ppan:CryPpanCalculation"}},"aiida.cmdline.data":{"crystal17.basis":"aiida_crystal17.cmndline.basis_set:basisset","crystal17.parse":"aiida_crystal17.cmndline.cmd_parser:parse","crystal17.symmetry":"aiida_crystal17.cmndline.symmetry:symmetry"},"aiida.data":{"crystal17.basisset":"aiida_crystal17.data.basis_set:BasisSetData","crystal17.gcube":"aiida_crystal17.data.gcube:GaussianCube","crystal17.kinds":"aiida_crystal17.data.kinds:KindData","crystal17.parameters":"aiida_crystal17.data.input_params:CryInputParamsData","crystal17.symmetry":"aiida_crystal17.data.symmetry:SymmetryData"},"aiida.groups":{"crystal17.basisset":"aiida_crystal17.data.basis_set:BasisSetFamily"},"aiida.parsers":{"crystal17.doss":"aiida_crystal17.parsers.cry_doss:CryDossParser","crystal17.ech3":"aiida_crystal17.parsers.cry_ech3:CryEch3Parser","crystal17.main":"aiida_crystal17.parsers.cry_main:CryMainParser","crystal17.newk":"aiida_crystal17.parsers.cry_newk:CryNewkParser","crystal17.ppan":"aiida_crystal17.parsers.cry_ppan:CryPpanParser"},"aiida.workflows":{"crystal17.main.base":{description:["Workchain to run a standard CRYSTAL17 calculation,","    with automated error handling and restarts."],spec:{inputs:[{name:"cry",required:!0,valid_types:"",info:""},{name:"basis_family",required:!1,valid_types:"Str",info:"An alternative to specifying the basis sets manually: one can specify the name of an existing basis set family and the work chain will generate the basis sets automatically based on the input structure."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints_distance",required:!1,valid_types:"Float",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by the input structure, and will replace the SHRINK IS value in the input parameters.Note: This methods assumes the PRIMITIVE unit cell is provided"},{name:"kpoints_force_parity",required:!1,valid_types:"Bool",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"results",required:!0,valid_types:"Dict",info:"the data extracted from the main output file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"the structure output from the calculation"},{name:"symmetry",required:!1,valid_types:"SymmetryData",info:"the symmetry data from the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"The parameters could not be validated against the jsonschema."},{status:202,message:"The explicit `basis_sets` or `basis_family` could not be used to get the necessary basis sets."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:320,message:"The initialization calculation failed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_crystal17.workflows.crystal_main.base:CryMainBaseWorkChain"},"crystal17.properties":{description:["A WorkChain to compute properties of a structure, using CRYSTAL.","","    Either a pre-computed wavefunction (fort.9) file,","    or inputs for a CryMainCalculation, should be supplied.","    Inputs for property calculations can then be added","    (currently available; doss, ech3)."],spec:{inputs:[{name:"check_remote",required:!1,valid_types:"Bool",info:"If a RemoteData wf_folder is input, check it contains the wavefunction file, before launching calculations. Note, this will fail if the remote computer is not immediately available"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"doss",required:!1,valid_types:"",info:""},{name:"ech3",required:!1,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"ppan",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"",info:""},{name:"test_run",required:!1,valid_types:"Bool",info:"break off the workchain before submitting a calculation"},{name:"wf_folder",required:!1,valid_types:"FolderData, RemoteData, SinglefileData",info:"the folder containing the wavefunction fort.9 file"}],outputs:[{name:"doss",required:!1,valid_types:"",info:""},{name:"ech3",required:!1,valid_types:"",info:""},{name:"ppan",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"Workchain ended before submitting calculation."},{status:201,message:"Neither a wf_folder nor scf calculation was supplied."},{status:202,message:"No property calculation inputs were supplied."},{status:203,message:"The supplied folder does contain the wavefunction file."},{status:210,message:"The SCF calculation submission failed."},{status:301,message:"The SCF calculation failed."},{status:302,message:"One or more property calculations failed."}]},class:"aiida_crystal17.workflows.crystal_props.base:CryPropertiesWorkChain"},"crystal17.sym3d":{description:["modify an AiiDa structure instance and compute its symmetry","","    Inequivalent atomic sites are dictated by atom kinds"],spec:{inputs:[{name:"settings",required:!0,valid_types:"Dict",info:""},{name:"cif",required:!1,valid_types:"CifData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"structure",required:!1,valid_types:"StructureData",info:""}],outputs:[{name:"symmetry",required:!0,valid_types:"SymmetryData",info:""},{name:"structure",required:!1,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"one of either a structure or cif input must be supplied"},{status:301,message:'the supplied structure must be 3D (i.e. have all dimensions pbc=True)"'},{status:302,message:"idealize can only be used when standardize=True"},{status:303,message:"the kind names supplied are not compatible with the structure"},{status:304,message:"error creating new structure"},{status:305,message:"error computing symmetry operations"}]},class:"aiida_crystal17.workflows.symmetrise_3d_struct:Symmetrise3DStructure"}},console_scripts:{mock_crystal17:"aiida_crystal17.tests.mock_crystal17:main",mock_properties17:"aiida_crystal17.tests.mock_properties17:main"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:5},{colorclass:"red",text:"Data",count:5},{colorclass:"green",text:"Workflows",count:3},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:4}],pip_install_cmd:"pip install aiida-crystal17",is_installable:"True"},"aiida-cusp":{code_home:"https://github.com/aiida-cusp/aiida-cusp",documentation_url:"https://aiida-cusp.readthedocs.io",entry_point_prefix:"cusp",pip_url:"https://pypi.org/project/aiida-cusp",name:"aiida-cusp",package_name:"aiida_cusp",hosted_on:"github.com",metadata:{author:"Andreas Stamminger",author_email:"stammingera@gmail.com",version:"0.1.0b2",description:"Custodian based VASP Plugin for AiiDA",classifiers:["Development Status :: 4 - Beta","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Chemistry","Environment :: Plugins","Framework :: AiiDA"]},aiida_version:">=1.3.0,<2.0.0",entry_points:{"aiida.data":{"cusp.kpoints":"aiida_cusp.data.inputs.vasp_kpoint:VaspKpointData","cusp.poscar":"aiida_cusp.data.inputs.vasp_poscar:VaspPoscarData","cusp.incar":"aiida_cusp.data.inputs.vasp_incar:VaspIncarData","cusp.potcar":"aiida_cusp.data.inputs.vasp_potcar:VaspPotcarData","cusp.vasprun":"aiida_cusp.data.outputs.vasp_vasprun:VaspVasprunData","cusp.outcar":"aiida_cusp.data.outputs.vasp_outcar:VaspOutcarData","cusp.contcar":"aiida_cusp.data.outputs.vasp_contcar:VaspContcarData","cusp.chgcar":"aiida_cusp.data.outputs.vasp_chgcar:VaspChgcarData","cusp.wavecar":"aiida_cusp.data.outputs.vasp_wavecar:VaspWavecarData","cusp.generic":"aiida_cusp.data.outputs.vasp_generic:VaspGenericData","cusp.potcarfile":"aiida_cusp.data.inputs.vasp_potcar:VaspPotcarFile"},"aiida.calculations":{"cusp.vasp":"aiida_cusp.calculators.vasp_calculation:VaspCalculation"},"aiida.parsers":{"cusp.default":"aiida_cusp.parsers.vasp_file_parser:VaspFileParser"},"aiida.cmdline.data":{potcar:"aiida_cusp.cli.potcar_cmd:potcar"}},commits_count:28,development_status:"beta",warnings:["Entry point 'potcar' does not start with prefix 'cusp.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:11},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install https://pypi.org/project/aiida-cusp",is_installable:"False",errors:["Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`,"Failed to install plugin aiida-cusp",`<pre>Collecting https://pypi.org/project/aiida-cusp
  Downloading https://pypi.org/project/aiida-cusp (50 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.5/50.5 kB 10.1 MB/s eta 0:00:00
  ERROR: Cannot unpack file /tmp/pip-unpack-1sh26k98/aiida-cusp (downloaded from /tmp/pip-req-build-7ggqy2ib, content-type: text/html; charset=UTF-8); cannot detect archive format
ERROR: Cannot determine archive format of /tmp/pip-req-build-7ggqy2ib
</pre>`]},"aiida-dataframe":{entry_point_prefix:"dataframe",plugin_info:"https://raw.github.com/janssenhenning/aiida-dataframe/main/pyproject.toml",code_home:"https://github.com/janssenhenning/aiida-dataframe",version_file:"https://raw.githubusercontent.com/janssenhenning/aiida-dataframe/main/aiida_dataframe/__init__.py",pip_url:"aiida-dataframe",documentation_url:"https://aiida-dataframe.readthedocs.io/en/latest/",name:"aiida-dataframe",package_name:"aiida_dataframe",hosted_on:"github.com",metadata:{release_date:"2023-05-05",description:"AiiDA data plugin for pandas DataFrame objects",author_email:"Henning Janßen <henning.janssen@gmx.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"0.1.3"},aiida_version:">=1.0,<3",entry_points:{"aiida.cmdline.data":{dataframe:"aiida_dataframe.cli:data_cli"},"aiida.data":{"dataframe.frame":"aiida_dataframe.data.dataframe:PandasFrameData"}},commits_count:11,development_status:"beta",summaryinfo:[{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-dataframe",is_installable:"True"},"aiida-ddec":{code_home:"https://github.com/lsmo-epfl/aiida-ddec",entry_point_prefix:"ddec",pip_url:"git+https://github.com/yakutovicha/aiida-ddec",name:"aiida-ddec",package_name:"aiida_ddec",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:13,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/lsmo-epfl/aiida-ddec/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/yakutovicha/aiida-ddec"},"aiida-defects":{code_home:"https://github.com/epfl-theos/aiida-defects",entry_point_prefix:"defects",pip_url:"aiida-defects",plugin_info:"https://raw.githubusercontent.com/epfl-theos/aiida-defects/master/pyproject.toml",name:"aiida-defects",package_name:"aiida_defects",hosted_on:"github.com",metadata:{release_date:"2023-03-29",description:"AiiDA-Defects is a plugin for the AiiDA computational materials science framework, and provides tools and automated workflows for the study of defects in materials.",author:"The AiiDA-Defects developers",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"1.0.1"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{"defects.array.stability":"aiida_defects.data.data:StabilityData"},"aiida.workflows":{"defects.formation_energy.chemical_potential":"aiida_defects.formation_energy.chemical_potential.chemical_potential:ChemicalPotentialWorkchain","defects.formation_energy.corrections.gaussian_countercharge":"aiida_defects.formation_energy.corrections.gaussian_countercharge.gaussian_countercharge:GaussianCounterChargeWorkchain","defects.formation_energy.corrections.gaussian_countercharge.model_potential":"aiida_defects.formation_energy.corrections.gaussian_countercharge.model_potential.model_potential:ModelPotentialWorkchain","defects.formation_energy.corrections.point_countercharge":"aiida_defects.formation_energy.corrections.point_countercharge.point_countercharge:PointCounterChargeWorkchain","defects.formation_energy.potential_alignment":"aiida_defects.formation_energy.potential_alignment.potential_alignment:PotentialAlignmentWorkchain","defects.formation_energy.qe":"aiida_defects.formation_energy.formation_energy_qe:FormationEnergyWorkchainQE","defects.formation_energy.siesta":"aiida_defects.formation_energy.formation_energy_siesta:FormatonEnergyWorkchainSiesta"}},commits_count:10,development_status:"beta",summaryinfo:[{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:7}],pip_install_cmd:"pip install aiida-defects",is_installable:"True",errors:["Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`,"Failed to fetch entry point metadata for package aiida_defects",`<pre>Failed to load entry point 'defects.formation_energy.corrections.point_countercharge':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 207, in load
    module = import_module(match.group('module'))
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_defects/formation_energy/corrections/point_countercharge/point_countercharge.py", line 19, in <module>
    from aiida_defects.tools.structure_manipulation import get_spacegroup
ModuleNotFoundError: No module named 'aiida_defects.tools'

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 87, in document_entry_point
    plugin = load_entry_point(entry_point_group, entry_point)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 236, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/importlib_metadata/__init__.py", line 209, in load
    return functools.reduce(getattr, attrs, module)
AttributeError: module 'aiida_defects.formation_energy.formation_energy_siesta' has no attribute 'FormatonEnergyWorkchainSiesta'
</pre>`]},"aiida-diff":{code_home:"https://github.com/aiidateam/aiida-diff",development_status:"stable",documentation_url:"https://aiida-diff.readthedocs.io/",entry_point_prefix:"diff",pip_url:"git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0",name:"aiida-diff",package_name:"aiida_diff",hosted_on:"github.com",metadata:{description:"AiiDA demo plugin that wraps the `diff` executable for computing the difference between two files.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 3 - Alpha","Framework :: AiiDA"],author:"The AiiDA Team"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{diff:"aiida_diff.data:DiffParameters"},"aiida.calculations":{diff:"aiida_diff.calculations:DiffCalculation"},"aiida.parsers":{diff:"aiida_diff.parsers:DiffParser"},"aiida.cmdline.data":{diff:"aiida_diff.cli:data_cli"}},commits_count:0,warnings:["Development status in classifiers (alpha) does not match development_status in metadata (stable)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0",is_installable:"False",errors:["Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`,"Failed to install plugin aiida-diff",`<pre>Collecting aiida-diff-0.1.0a0
  Cloning https://github.com/aiidateam/aiida-diff to /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Running command git clone --filter=blob:none --quiet https://github.com/aiidateam/aiida-diff /tmp/pip-install-h6ht_lr9/aiida-diff-0-1-0a0_0ca15deff14442d2bec3cfcf87f94b14
  Resolved https://github.com/aiidateam/aiida-diff to commit f47fec9043d942a332a158378828b7d5a3fef2dc
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
  WARNING: Generating metadata for package aiida-diff-0.1.0a0 produced metadata for project name aiida-diff. Fix your #egg=aiida-diff-0.1.0a0 fragments.
Discarding git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0: Requested aiida-diff from git+https://github.com/aiidateam/aiida-diff#egg=aiida-diff-0.1.0a0 has inconsistent name: filename has 'aiida-diff-0-1-0a0', but metadata has 'aiida-diff'
ERROR: Could not find a version that satisfies the requirement aiida-diff-0-1-0a0 (unavailable) (from versions: none)
ERROR: No matching distribution found for aiida-diff-0-1-0a0 (unavailable)
</pre>`]},"aiida-donothing":{code_home:"https://github.com/atztogo/aiida-donothing",entry_point_prefix:"donothing",name:"aiida-donothing",package_name:"aiida_donothing",hosted_on:"github.com",metadata:{author:"Atsushi Togo",author_email:"atz.togo@gmail.com",version:"0.1",description:"AiiDA calculation plugin for doing nothing",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.5,<2.0.0",entry_points:{"aiida.calculations":{"donothing.donothing":"aiida_donothing.calculations.donothing:DoNothingCalculation"},"aiida.parsers":{"donothing.donothing":"aiida_donothing.parsers.donothing:DoNothingParser"}},commits_count:1,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"See source code repository."},"aiida-dynamic-workflows":{code_home:"https://github.com/microsoft/aiida-dynamic-workflows",entry_point_prefix:"dynamic_workflows",name:"aiida-dynamic-workflows",package_name:"aiida_dynamic_workflows",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-environ":{code_home:"https://github.com/environ-developers/aiida-environ",entry_point_prefix:"environ",pip_url:"git+https://github.com/environ-developers/aiida-environ",name:"aiida-environ",package_name:"aiida_environ",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.github.com/environ-developers/aiida-environ/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/environ-developers/aiida-environ"},"aiida-eon":{code_home:"https://github.com/HaoZeke/aiida-eon",entry_point_prefix:"eon",name:"aiida-eon",package_name:"aiida_eon",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-eonclient":{code_home:"https://github.com/HaoZeke/aiida-eonclient",entry_point_prefix:"eonclient",name:"aiida-eonclient",package_name:"aiida_eonclient",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:0,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-fenics":{code_home:"https://github.com/sphuber/aiida-fenics/tree/master",entry_point_prefix:"fenics",pip_url:"git+https://github.com/sphuber/aiida-fenics",name:"aiida-fenics",package_name:"aiida_fenics",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:-1,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.github.com/sphuber/aiida-fenics/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/sphuber/aiida-fenics"},"aiida-firecrest":{code_home:"https://github.com/aiidateam/aiida-firecrest",entry_point_prefix:"firecrest",pip_url:"aiida-firecrest",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-firecrest/main/pyproject.toml",name:"aiida-firecrest",package_name:"aiida_firecrest",hosted_on:"github.com",metadata:{release_date:"2022-01-14",description:"AiiDA Transport/Scheduler plugins for interfacing with FirecREST.",author_email:"Chris Sewell <chrisj_sewell@hotmail.com>",classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Python :: Implementation :: CPython","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.1.0a1"},aiida_version:"<2",entry_points:{"aiida.schedulers":{firecrest:"aiida_firecrest.scheduler:FirecrestScheduler"},"aiida.transports":{firecrest:"aiida_firecrest.transport:FirecrestTransport"},console_scripts:{"aiida-firecrest-cli":"aiida_firecrest.cli:main"}},commits_count:19,development_status:"alpha",summaryinfo:[{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Schedulers, Transports)",count:2}],pip_install_cmd:"pip install --pre aiida-firecrest",is_installable:"True"},"aiida-fireworks-scheduler":{code_home:"https://github.com/zhubonan/aiida-fireworks-scheduler",development_status:"beta",documentation_url:"https://aiida-fireworks-scheduler.readthedocs.io",entry_point_prefix:"fireworks_scheduler",pip_url:"git+https://github.com/zhubonan/aiida-fireworks-scheduler",name:"aiida-fireworks-scheduler",package_name:"aiida_fireworks_scheduler",hosted_on:"github.com",metadata:{author:"Bonan Zhu",author_email:"zhubonan@outlook.com",version:"1.2.0",description:"AiiDA plugin to allow using `fireworks` as the execution engine for `CalcJob`.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:null,entry_points:{"aiida.schedulers":{fireworks:"aiida_fireworks_scheduler.fwscheduler:FwScheduler","fireworks_scheduler.default":"aiida_fireworks_scheduler.fwscheduler:FwScheduler","fireworks_scheduler.keepenv":"aiida_fireworks_scheduler.fwscheduler:FwSchedulerKeepEnv"},"aiida.cmdline.data":{"fireworks-scheduler":"aiida_fireworks_scheduler.cmdline:fw_cli"},console_scripts:{arlaunch:"aiida_fireworks_scheduler.scripts.arlaunch_run:arlaunch"}},commits_count:0,warnings:["AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'fireworks' does not start with prefix 'fireworks_scheduler.'","Entry point 'fireworks-scheduler' does not start with prefix 'fireworks_scheduler.'"],summaryinfo:[{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Schedulers)",count:4}],pip_install_cmd:"pip install git+https://github.com/zhubonan/aiida-fireworks-scheduler",is_installable:"True"},"aiida-fleur":{code_home:"https://github.com/JuDFTteam/aiida-fleur/tree/develop",development_status:"stable",documentation_url:"https://aiida-fleur.readthedocs.io/",entry_point_prefix:"fleur",pip_url:"aiida-fleur",plugin_info:"https://raw.github.com/JuDFTteam/aiida-fleur/develop/setup.json",name:"aiida-fleur",package_name:"aiida_fleur",hosted_on:"github.com",metadata:{release_date:"2023-05-03",description:"AiiDA Plugin for running the FLEUR code and its input generator. Also includes high-level workchains and utilities",author_email:"The JuDFT team <j.broeder@fz-juelich.de>",classifiers:["Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.0.0"},aiida_version:">=2.0.1,<3.0.0",entry_points:{"aiida.calculations":{"fleur.fleur":{description:["A CalcJob class that represents FLEUR DFT calculation.","    For more information about the FLEUR-code family go to http://www.flapw.de/"],spec:{inputs:[{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:"Use a FleurinpData node that specifies the input parametersusually copy from the parent calculation, basically makesthe inp.xml file visible in the db and makes sure it has the files needed."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote or local repository folder as parent folder (also for restarts and similar). It should contain all the needed files for a Fleur calc, only edited files should be uploaded from the repository."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"error_params",required:!1,valid_types:"Dict",info:""},{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_params_complex",required:!1,valid_types:"Dict",info:""},{name:"relax_parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"No retrieved folder found."},{status:301,message:"One of the output files can not be opened."},{status:302,message:"FLEUR calculation failed for unknown reason."},{status:303,message:"XML output file was not found."},{status:304,message:"Parsing of XML output file failed."},{status:305,message:"Parsing of relax XML output file failed."},{status:310,message:"FLEUR calculation failed due to lack of memory."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:312,message:"FLEUR calculation failed due to MT overlap."},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:314,message:"Problem with cdn is suspected. Consider removing cdn"},{status:315,message:"The LDA+U density matrix contains invalid elements."},{status:316,message:"Calculation failed due to time limits."},{status:318,message:"Calculation failed due to missing dependency ({name}) for given calculation."}]},class:"aiida_fleur.calculation.fleur:FleurCalculation"},"fleur.inpgen":{description:["JobCalculationClass for the inpgen, which is a preprocessor for a FLEUR calculation.","    For more information about produced files and the FLEUR-code family, go to http://www.flapw.de/."],spec:{inputs:[{name:"structure",required:!0,valid_types:"StructureData",info:"Choose the input structure to use"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Use a node that specifies the input parameters for the namelists"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"fleurinp",required:!0,valid_types:"FleurinpData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"No retrieved folder found."},{status:301,message:"One of the output files can not be opened."},{status:306,message:"XML input file was not found."},{status:307,message:"Some required files were not retrieved."},{status:308,message:"During parsing: FleurinpData could not be initialized, see log. "},{status:309,message:"During parsing: FleurinpData failed validation."},{status:310,message:"The profile {profile} is not known to the used inpgen code"}]},class:"aiida_fleur.calculation.fleurinputgen:FleurinputgenCalculation"}},"aiida.data":{"fleur.fleurinp":"aiida_fleur.data.fleurinp:FleurinpData"},"aiida.parsers":{"fleur.fleurinpgenparser":"aiida_fleur.parsers.fleur_inputgen:Fleur_inputgenParser","fleur.fleurparser":"aiida_fleur.parsers.fleur:FleurParser"},"aiida.workflows":{"fleur.banddos":{description:["This workflow calculated a bandstructure from a Fleur calculation","","    :Params: a Fleurcalculation node","    :returns: Success, last result node, list with convergence behavior"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"banddos_calc",required:!0,valid_types:"",info:""},{name:"output_banddos_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_banddos_wc_bands",required:!1,valid_types:"BandsData",info:""},{name:"output_banddos_wc_dos",required:!1,valid_types:"XyData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"SCF calculation failed."},{status:335,message:"Found no SCF calculation remote repository."}]},class:"aiida_fleur.workflows.banddos:FleurBandDosWorkChain"},"fleur.base":{description:["Workchain to run a FLEUR calculation with automated error handling and restarts"],spec:{inputs:[{name:"options",required:!0,valid_types:"Dict",info:"Optional parameters to set up computational details."},{name:"add_comp_para",required:!1,valid_types:"Dict",info:"Gives additional control over computational parametersonly_even_MPI: set to true if you want to suppress odd number of MPI processes in parallelisation.This might speedup a calculation for machines having even number of sockets per node.max_queue_nodes: maximal number of nodes allowed on the remote machine. Used only to automatically solve some FLEUR failures.max_queue_wallclock_sec: maximal wallclock time allowed on the remote machine. Used only to automatically solve some FLEUR failures."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"description",required:!1,valid_types:"str, NoneType",info:"Calculation description."},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:"Use a FleurinpData node that specifies the input parametersusually copy from the parent calculation, basically makesthe inp.xml file visible in the db and makes sure it has the files needed."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"label",required:!1,valid_types:"str, NoneType",info:"Calculation label."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Use a remote or local repository folder as parent folder (also for restarts and similar). It should contain all the needed files for a Fleur calc, only edited files should be uploaded from the repository."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"This parameter data node is used to specify for some advanced features how the plugin behaves. You can add filesthe retrieve list, or add command line switches, for all available features here check the documentation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"error_params",required:!1,valid_types:"Dict",info:""},{name:"output_parameters",required:!1,valid_types:"Dict",info:""},{name:"output_params_complex",required:!1,valid_types:"Dict",info:""},{name:"relax_parameters",required:!1,valid_types:"Dict",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:388,message:"Computational resources are not optimal."},{status:389,message:"Computational resources are not optimal."},{status:390,message:"Computational resources are not optimal."},{status:399,message:"FleurCalculation failed and FleurBaseWorkChain has no strategy to resolve this"},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_fleur.workflows.base_fleur:FleurBaseWorkChain"},"fleur.base_relax":{description:["Workchain to run Relax WorkChain with automated error handling and restarts"],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"description",required:!1,valid_types:"str, NoneType",info:"Calculation description."},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"label",required:!1,valid_types:"str, NoneType",info:"Calculation label."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"last_scf",required:!0,valid_types:"",info:""},{name:"optimized_structure",required:!0,valid_types:"StructureData",info:""},{name:"output_relax_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:399,message:"FleurRelaxWorkChain failed and FleurBaseRelaxWorkChain has no strategy to resolve this"},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_fleur.workflows.base_relax:FleurBaseRelaxWorkChain"},"fleur.cfcoeff":{description:["Workflow for calculating rare-earth crystal field coefficients"],spec:{inputs:[{name:"metadata",required:!1,valid_types:"",info:""},{name:"orbcontrol",required:!1,valid_types:"Data",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"scf_rare_earth_analogue",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_cfcoeff_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_cfcoeff_wc_charge_densities",required:!1,valid_types:"XyData",info:""},{name:"output_cfcoeff_wc_potentials",required:!1,valid_types:"XyData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:345,message:"Convergence scf workflow failed."},{status:451,message:"Convergence orbcontrol workflow failed."},{status:452,message:"CF calculation failed."}]},class:"aiida_fleur.workflows.cfcoeff:FleurCFCoeffWorkChain"},"fleur.corehole":{description:["Turn key solution for a corehole calculation with the FLEUR code.","    Has different protocols for different core-hole types (valence, charge).","","    Calculates supercells. Extracts binding energies","    for certain corelevels from the total energy differences a the calculation with","    corehole and without.","","    Documentation:","    See help for details.","","    Two paths are possible:","","    (1) Start from a structure -> workchains run inpgen first (recommended)","    (2) Start from a Fleurinp data object","","    Also it is recommended to provide a calc parameter node for the structure","","    :param wf_parameters: Dict node, specify, resources and what should be calculated","    :param structure: structureData node, crystal structure","    :param calc_parameters: Dict node, inpgen parameters for the crystal structure","    :param fleurinp:  fleurinpData node,","    :param inpgen: Code node,","    :param fleur: Code node,","","    :return: output_corehole_wc_para Dict node,  successful=True if no error","","    :uses workchains: fleur_scf_wc, fleur_relax_wc","    :uses calcfunctions: supercell, create_corehole_result_node, prepare_struc_corehole_wf"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"inpgen",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_corehole_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:1,message:"The input resources are invalid."},{status:2,message:"The process failed with legacy failure mode."},{status:2,message:"Input resources are missing."},{status:3,message:"The code provided is invalid, or not of the right kind."},{status:4,message:"Inpgen calculation FAILED, check output"},{status:5,message:"Changing of the FLEURINP data went wrong, check log."},{status:6,message:"The FLEUR input file for the calculation did not validate."},{status:7,message:"At least one FLEUR calculation FAILED, check the output and log."},{status:8,message:"At least one FLEUR calculation did not/could not reach thedesired convergece Criteria, with the current parameters."},{status:9,message:"Something went wrong in the determiation what coreholes to calculate, probably the input format was not correct. Check log."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.corehole:FleurCoreholeWorkChain"},"fleur.create_magnetic":{description:["This workflow creates relaxed magnetic film on a substrate."],spec:{inputs:[{name:"distance_suggestion",required:!1,valid_types:"Dict, NoneType",info:""},{name:"eos",required:!1,valid_types:"Data",info:""},{name:"eos_output",required:!1,valid_types:"Dict, NoneType",info:""},{name:"interlayer_dist",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"optimized_structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"relax",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"magnetic_structure",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:380,message:"Specified substrate has to be bcc or fcc."},{status:382,message:"Relaxation calculation failed."},{status:383,message:"EOS WorkChain failed."}]},class:"aiida_fleur.workflows.create_magnetic_film:FleurCreateMagneticWorkChain"},"fleur.dmi":{description:["This workflow calculates DMI energy dispersion of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_dmi_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.dmi:FleurDMIWorkChain"},"fleur.dos":{description:["DEPRECATED: Use FleurBandDosWorkChain instead (entrypoint fleur.banddos)","    This workflow calculated a DOS from a Fleur calculation","","    :Params: a Fleurcalculation node","    :returns: Success, last result node, list with convergence behavior","","    wf_parameters: {  'tria', 'nkpts', 'sigma', 'emin', 'emax'}","    defaults : tria = True, nkpts = 800, sigma=0.005, emin= -0.3, emax = 0.8"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_data",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.dos:fleur_dos_wc"},"fleur.eos":{description:["This workflow calculates the equation of states of a structure.","    Calculates several unit cells with different volumes.","    A Birch_Murnaghan  equation of states fit determines the Bulk modulus and the","    groundstate volume of the cell.","","    :params wf_parameters: Dict node, optional 'wf_parameters', protocol specifying parameter dict","    :params structure: StructureData node, 'structure' crystal structure","    :params calc_parameters: Dict node, optional 'calc_parameters' parameters for inpgen","    :params inpgen: Code node,","    :params fleur: Code node,","","","    :return output_eos_wc_para: Dict node, contains relevant output information.","                                about general succeed, fit results and so on."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_eos_wc_para",required:!0,valid_types:"Dict",info:""},{name:"output_eos_wc_structure",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:400,message:"At least one of the SCF sub processes did not finish successfully."}]},class:"aiida_fleur.workflows.eos:FleurEosWorkChain"},"fleur.init_cls":{description:["Turn key solution for the calculation of core level shift"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_initial_cls_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_fleur.workflows.initial_cls:FleurInitialCLSWorkChain"},"fleur.mae":{description:["This workflow calculates the Magnetic Anisotropy Energy of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_mae_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.mae:FleurMaeWorkChain"},"fleur.mae_conv":{description:["This workflow calculates the Magnetic Anisotropy Energy of a structure."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_mae_conv_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:343,message:"Convergence MAE calculation failed for all SQAs."},{status:344,message:"Convergence MAE calculation failed for some SQAs."}]},class:"aiida_fleur.workflows.mae_conv:FleurMaeConvWorkChain"},"fleur.orbcontrol":{description:["Workchain for determining the groundstate density matrix in an DFT+U","    calculation. This is done in 2 or 3 steps:","","        1. Converge the system without DFT+U (a converged calculation can be","           provided to skip this step)","        2. A fixed number of iterations is run with fixed density matrices","           either generated as all distinct permutations for the given occupations","           or the explicitly given configurations","        3. The system and density matrix is relaxed","","    :param wf_parameters: (Dict), Workchain Specifications","    :param scf_no_ldau: (Dict), Inputs to a FleurScfWorkChain providing the initial system","                                either converged or staring from a structure","    :param scf_with_ldau: (Dict), Inputs to a FleurScfWorkChain. Only the wf_parameters are valid","    :param fleurinp: (FleurinpData) FleurinpData to start from if no SCF should be done","    :param remote: (RemoteData) RemoteData to start from if no SCF should be done","    :param structure: (StructureData) Structure to start from if no SCF should be done","    :param calc_parameters: (Dict), Inpgen Parameters","    :param settings: (Dict), additional settings for e.g retrieving files","    :param options: (Dict), Options for the submission of the jobs","    :param inpgen: (Code)","    :param fleur: (Code)"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fixed_remotes",required:!1,valid_types:"RemoteData",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"options_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"relaxed_remotes",required:!1,valid_types:"RemoteData",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf_no_ldau",required:!1,valid_types:"Data",info:"Inputs for SCF Workchain before adding LDA+U"},{name:"scf_with_ldau",required:!1,valid_types:"Data",info:"Inputs for SCF Workchain after the LDA+U matrix was fixed"},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"groundstate_scf",required:!0,valid_types:"",info:""},{name:"output_orbcontrol_wc_para",required:!0,valid_types:"Dict",info:""},{name:"groundstate_denmat",required:!1,valid_types:"SinglefileData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Input codes do not correspond to fleur or inpgen respectively."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:342,message:"Convergence LDA+U calculation failed for some Initial configurations."},{status:343,message:"Convergence LDA+U calculation failed for all Initial configurations."},{status:360,message:"Inpgen calculation failed."},{status:450,message:"Convergence workflow without LDA+U failed."}]},class:"aiida_fleur.workflows.orbcontrol:FleurOrbControlWorkChain"},"fleur.relax":{description:["This workflow performs structure optimization."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"last_scf",required:!0,valid_types:"",info:""},{name:"optimized_structure",required:!0,valid_types:"StructureData",info:""},{name:"output_relax_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"If you want to run a final scf inpgen has to be there."},{status:311,message:"FLEUR calculation failed because an atom spilled to thevacuum during relaxation"},{status:313,message:"Overlapping MT-spheres during relaxation."},{status:350,message:"Optimization cycle did not lead to convergence of forces."},{status:351,message:"SCF Workchains failed for some reason."},{status:352,message:"Found no relaxed structure info in the output of SCF"},{status:353,message:"Found no SCF output"},{status:354,message:"Force is small, switch to BFGS"}]},class:"aiida_fleur.workflows.relax:FleurRelaxWorkChain"},"fleur.relax_torque":{description:["This workflow performs spin structure optimization."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"final_scf",required:!1,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_relax_torque_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"If you want to run a final scf inpgen has to be there."},{status:350,message:"Optimization cycle did not lead to convergence."},{status:351,message:"An SCF Workchain failed for some reason."}]},class:"aiida_fleur.workflows.relax_torque:FleurRelaxTorqueWorkChain"},"fleur.scf":{description:["Workchain for converging a FLEUR calculation (SCF).","","    It converges the charge density, total energy or the largest force.","    Two paths are possible:","","    (1) Start from a structure and run the inpgen first optional with calc_parameters","    (2) Start from a Fleur calculation, with optional remoteData","","    :param wf_parameters: (Dict), Workchain Specifications","    :param structure: (StructureData), Crystal structure","    :param calc_parameters: (Dict), Inpgen Parameters","    :param fleurinp: (FleurinpData), to start with a Fleur calculation","    :param remote_data: (RemoteData), from a Fleur calculation","    :param inpgen: (Code)","    :param fleur: (Code)","","    :return: output_scf_wc_para (Dict), Information of workflow results","        like Success, last result node, list with convergence behavior"],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"inpgen",required:!1,valid_types:"Code, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote_data",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings_inpgen",required:!1,valid_types:"Dict, NoneType",info:""},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"fleurinp",required:!0,valid_types:"FleurinpData",info:""},{name:"last_calc",required:!0,valid_types:"",info:""},{name:"output_scf_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Input codes do not correspond to fleur or inpgen respectively."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:360,message:"Inpgen calculation failed."},{status:361,message:"Fleur calculation failed."},{status:362,message:"SCF cycle did not lead to convergence."}]},class:"aiida_fleur.workflows.scf:FleurScfWorkChain"},"fleur.ssdisp":{description:["This workflow calculates spin spiral dispersion of a structure."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"fleurinp",required:!1,valid_types:"FleurinpData, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"remote",required:!1,valid_types:"RemoteData, NoneType",info:""},{name:"scf",required:!1,valid_types:"Data",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_ssdisp_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:231,message:"Invalid input configuration."},{status:233,message:"Invalid code node specified, check inpgen and fleur code nodes."},{status:235,message:"Input file modification failed."},{status:236,message:"Input file was corrupted after user's modifications."},{status:334,message:"Reference calculation failed."},{status:335,message:"Found no reference calculation remote repository."},{status:336,message:"Force theorem calculation failed."}]},class:"aiida_fleur.workflows.ssdisp:FleurSSDispWorkChain"},"fleur.ssdisp_conv":{description:["This workflow calculates the Spin Spiral Dispersion of a structure."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_ssdisp_conv_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:230,message:"Invalid workchain parameters."},{status:340,message:"Convergence SSDisp calculation failed for all q-vectors."},{status:341,message:"Convergence SSDisp calculation failed for some q-vectors."}]},class:"aiida_fleur.workflows.ssdisp_conv:FleurSSDispConvWorkChain"},"fleur.strain":{description:["This workflow calculates the deformation potential a structure = -BdEg/dP = d(Eg)/d(ln(V)).","    Calculates several unit cells with different volumes.","    A Birch_Murnaghan  equation of states fit determines the Bulk modulus(B) and the","    ground-state volume of the cell.","","    :params wf_parameters: Dict node, optional 'wf_parameters', protocol specifying parameter dict","    :params structure: StructureData node, 'structure' crystal structure","    :params calc_parameters: Dict node, optional 'calc_parameters' parameters for inpgen","    :params inpgen: Code node,","    :params fleur: Code node,","","","    :return output_strain_wc_para: Dict node, contains relevant output information.","                                about general succeed, fit results and so on."],spec:{inputs:[{name:"fleur",required:!0,valid_types:"Code",info:""},{name:"inpgen",required:!0,valid_types:"Code",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"calc_parameters",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict, NoneType",info:""},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""},{name:"wf_parameters",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_strain_wc_para",required:!0,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:331,message:"Invalid code node specified, check inpgen and fleur code nodes."}]},class:"aiida_fleur.workflows.strain:FleurStrainWorkChain"}},console_scripts:{"aiida-fleur":"aiida_fleur.cmdline:cmd_root"}},commits_count:200,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:19},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-fleur",is_installable:"True"},"aiida-flexpart":{code_home:"https://github.com/aiidaplugins/aiida-flexpart",entry_point_prefix:"flexpart",pip_url:"git+https://github.com/aiidaplugins/aiida-flexpart",name:"aiida-flexpart",package_name:"aiida_flexpart",hosted_on:"github.com",metadata:{author:"The AiiDA Team",author_email:"aliaksandr.yakutovich@empa.ch",version:"0.1.0a0",description:"AiiDA plugin for the FLEXPART code (simulation of atmospheric transport processes).",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.5,<3.0.0",entry_points:{"aiida.calculations":{"flexpart.cosmo":"aiida_flexpart.calculations.cosmo:FlexpartCosmoCalculation"},"aiida.parsers":{"flexpart.cosmo":"aiida_flexpart.parsers.cosmo:FlexpartCosmoParser"},"aiida.workflows":{"flexpart.multi_dates":"aiida_flexpart.workflows.multi_dates_workflow:FlexpartMultipleDatesWorkflow"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidaplugins/aiida-flexpart"},"aiida-gaussian":{code_home:"https://github.com/nanotech-empa/aiida-gaussian",entry_point_prefix:"gaussian",pip_url:"aiida-gaussian",plugin_info:"https://raw.githubusercontent.com/nanotech-empa/aiida-gaussian/master/pyproject.toml",name:"aiida-gaussian",package_name:"aiida_gaussian",hosted_on:"github.com",metadata:{release_date:"2023-08-31",description:"AiiDA plugin for the Gaussian quantum chemistry software.",author:"Kristjan Eimre, Pezhman Zarabadi-Poor, Aliaksandr Yakutovich",license:"MIT",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: OS Independent","Programming Language :: Python :: 3","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Software Development :: Libraries :: Python Modules"],version:"2.1.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{gaussian:{description:["AiiDA calculation plugin wrapping Gaussian","","    Template:","","    parameters = Dict(dict={","        'link0_parameters': {","            '%chk':'aiida.chk',","            '%mem': '1024MB',","            '%nprocshared': '2',","        },","        'functional':'PBE1PBE',","        'basis_set':'6-31g',","        'charge': 0,","        'multiplicity': 1,","        'route_parameters': {","            'scf': {'cdiis': None}","            'nosymm': None,","            'opt': 'tight',","        },","    })"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData, NoneType",info:"the folder of a completed gaussian calculation"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"additional input parameters"},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"Input structure; will be converted to pymatgen object"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The result parameters of the calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"energy_ev",required:!1,valid_types:"Float",info:"Final energy in electronvolts"},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Final optimized structure, if available"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the output file."},{status:211,message:"The retrieved output log could not be read."},{status:220,message:"The output file could not be parsed."},{status:301,message:"The SCF did not converge and the calculation was terminated."},{status:302,message:"The calculation was terminated due to a logic error in ASyTop."},{status:303,message:"The calculation was terminated due to an inaccurate quadrature in CalDSu."},{status:390,message:"The calculation was terminated due to an error."},{status:391,message:"The log did not contain 'Normal termination' (probably out of time)."}]},class:"aiida_gaussian.calculations:GaussianCalculation"},"gaussian.cubegen":{description:["Plugin to run the cubegen utility","","    Example:","","    parameters = {",'        "homo-5": {','            "kind": "AMO=16",','            "npts": -2,',"        },",'        "spin": {','            "kind": "Spin=SCF",','            "npts": 0,',"        },","    }","    Each key corresponds to one produced cube.","    key specifies the name of the output node","",'    In case of "npts": -1, you have to use the stencil file input:',"","        IFlag X0 Y0 Z0  # Output unit number and initial point.","        N1 X1 Y1 Z1     # Number of points and step-size in the X-direction.","        N2 X2 Y2 Z2     # Number of points and step-size in the Y-direction.","        N3 X3 Y3 Z3     # Number of points and step-size in the Z-direction.","","    See more details at https://gaussian.com/cubegen/"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"dictionary containing entries for cubes to be printed."},{name:"parent_calc_folder",required:!0,valid_types:"RemoteData",info:"the folder of a containing the .fchk"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"gauss_memdef",required:!1,valid_types:"Int, NoneType",info:"Set the GAUSS_MEMDEF env variable to set the max memory in MB."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieve_cubes",required:!1,valid_types:"Bool, NoneType",info:"should the cubes be retrieved?"},{name:"stencil",required:!1,valid_types:"SinglefileData, NoneType",info:"In case of npts=-1, use this cube specification."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"The retrieved folder could not be accessed."},{status:301,message:"The retrieved temporary folder could not be accessed."}]},class:"aiida_gaussian.calculations:CubegenCalculation"},"gaussian.formchk":{description:["Very simple plugin to run the formchk utility"],spec:{inputs:[{name:"parent_calc_folder",required:!0,valid_types:"RemoteData",info:"the folder of a containing the .chk"},{name:"chk_name",required:!1,valid_types:"Str, NoneType",info:"name of the checkpoint file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieve_fchk",required:!1,valid_types:"Bool, NoneType",info:"retrieve the fchk file"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_gaussian.calculations:FormchkCalculation"}},"aiida.parsers":{"gaussian.advanced":"aiida_gaussian.parsers.gaussian:GaussianAdvancedParser","gaussian.base":"aiida_gaussian.parsers.gaussian:GaussianBaseParser","gaussian.cubegen_base":"aiida_gaussian.parsers.cubegen:CubegenBaseParser"},"aiida.workflows":{"gaussian.base":{description:["Workchain to run a Gaussian calculation with automated error handling and restarts."],spec:{inputs:[{name:"gaussian",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:350,message:"The calculation failed with an unrecoverable SCF convergence error."},{status:399,message:"The calculation failed with an unrecoverable error."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_gaussian.workchains:GaussianBaseWorkChain"},"gaussian.cubes":{description:["No description available"],spec:{inputs:[{name:"cubegen_code",required:!0,valid_types:"Code",info:""},{name:"formchk_code",required:!0,valid_types:"Code",info:""},{name:"gaussian_calc_folder",required:!0,valid_types:"RemoteData",info:"The gaussian calculation output folder."},{name:"gaussian_output_params",required:!0,valid_types:"Dict",info:"The gaussian calculation output parameters."},{name:"cubegen_parser_name",required:!1,valid_types:"str",info:""},{name:"cubegen_parser_params",required:!1,valid_types:"Dict, NoneType",info:"Additional parameters to cubegen parser."},{name:"dx",required:!1,valid_types:"Float, NoneType",info:"Cube file spacing [ang]."},{name:"edge_space",required:!1,valid_types:"Float, NoneType",info:"Extra cube space in addition to molecule bounding box [ang]."},{name:"generate_density",required:!1,valid_types:"Bool, NoneType",info:"Generate density cube."},{name:"generate_spin_density",required:!1,valid_types:"Bool, NoneType",info:"Generate spin density cube (if applicable)."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"natural_orbitals",required:!1,valid_types:"Bool, NoneType",info:"The cube files are natural orbitals."},{name:"orbital_index_ref",required:!1,valid_types:"Str, NoneType",info:"Reference index, possible choices: 'half_num_el', 'abs'."},{name:"orbital_indexes",required:!1,valid_types:"List, NoneType",info:"Indexes of the orbital cubes to generate."},{name:"retrieve_cubes",required:!1,valid_types:"Bool, NoneType",info:"should the cubes be retrieved?"}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:302,message:"Input options are invalid."},{status:390,message:"One or more steps of the work chain failed."}]},class:"aiida_gaussian.workchains:GaussianCubesWorkChain"}}},commits_count:23,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"green",text:"Workflows",count:2}],pip_install_cmd:"pip install aiida-gaussian",is_installable:"True"},"aiida-gaussian-datatypes":{code_home:"https://github.com/dev-zero/aiida-gaussian-datatypes",documentation_url:"https://github.com/dev-zero/aiida-gaussian-datatypes/blob/master/README.md",entry_point_prefix:"gaussian",pip_url:"aiida-gaussian-datatypes",plugin_info:"https://raw.github.com/dev-zero/aiida-gaussian-datatypes/master/setup.json",name:"aiida-gaussian-datatypes",package_name:"aiida_gaussian_datatypes",hosted_on:"github.com",metadata:{release_date:"2022-07-22",description:"AiiDA data plugin to manage gaussian datatypes (basis sets and pseudopotentials) as first-class citizens",author:"Tiziano Müller",author_email:"tiziano.mueller@chem.uzh.ch",license:"MIT License",home_page:"https://github.com/dev-zero/aiida-gaussian-datatypes",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.5.1"},aiida_version:">=1.6.2",entry_points:{"aiida.cmdline.data":{"gaussian.basisset":"aiida_gaussian_datatypes.basisset.cli:cli","gaussian.pseudo":"aiida_gaussian_datatypes.pseudopotential.cli:cli"},"aiida.data":{"gaussian.basisset":"aiida_gaussian_datatypes.basisset.data:BasisSet","gaussian.pseudo":"aiida_gaussian_datatypes.pseudopotential.data:Pseudopotential"},"aiida.groups":{"gaussian.basisset":"aiida_gaussian_datatypes.groups:BasisSetGroup","gaussian.pseudo":"aiida_gaussian_datatypes.groups:PseudopotentialGroup"}},commits_count:0,development_status:"beta",warnings:["Prefix 'gaussian' does not follow naming convention."],summaryinfo:[{colorclass:"red",text:"Data",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:4}],pip_install_cmd:"pip install aiida-gaussian-datatypes",is_installable:"True"},"aiida-gollum":{code_home:"https://github.com/garsua/aiida-gollum/",documentation_url:"https://aiida-gollum.readthedocs.io/",entry_point_prefix:"gollum",pip_url:"git+https://github.com/garsua/aiida-gollum",name:"aiida-gollum",package_name:"aiida_gollum",hosted_on:"github.com",metadata:{author:"Victor M. Garcia-Suarez",author_email:"vm.garcia@cinn.es",version:"0.12.0",description:"A plugin for Gollum functionality within AiiDA framework.",classifiers:["License :: OSI Approved :: MIT License","Framework :: AiiDA","Programming Language :: Python :: 2.7","Development Status :: 1 - Alpha"]},aiida_version:">=0.12.0",entry_points:{"aiida.calculations":{"gollum.gollum":"aiida_gollum.calculations.gollum:GollumCalculation"},"aiida.parsers":{"gollum.parser":"aiida_gollum.parsers.gollum:GollumParser"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/garsua/aiida-gollum"},"aiida-graphql":{code_home:"https://github.com/dev-zero/aiida-graphql",entry_point_prefix:"graphql",pip_url:"aiida-graphql",name:"aiida-graphql",package_name:"aiida_graphql",hosted_on:"github.com",metadata:{release_date:"2019-10-28",description:"Strawberry-based GraphQL API Server for AiiDA",author:"Tiziano Müller",author_email:"tiziano.mueller@chem.uzh.ch",license:"MIT",home_page:"https://github.com/dev-zero/aiida-graphql",classifiers:["Development Status :: 3 - Alpha","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Software Development :: Libraries :: Python Modules"],version:"0.0.2"},aiida_version:">=1.0.0b6,<2.0.0",entry_points:{},commits_count:0,development_status:"alpha",warnings:["Unable to read wheel file from PyPI release: No entry_points.txt found in wheel","Missing classifier 'Framework :: AiiDA'"],summaryinfo:[],pip_install_cmd:"pip install aiida-graphql",is_installable:"True"},"aiida-gromacs":{code_home:"https://github.com/jimboid/aiida-gromacs",documentation_url:"https://aiida-gromacs.readthedocs.io/",entry_point_prefix:"gromacs",pip_url:"git+https://github.com/jimboid/aiida-gromacs",name:"aiida-gromacs",package_name:"aiida_gromacs",hosted_on:"github.com",metadata:{description:"A plugin for using GROMACS with AiiDA for molecular dymanics simulations.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 3 - Alpha","Framework :: AiiDA"],author:"James Gebbie-Rayet",author_email:"james.gebbie@stfc.ac.uk"},aiida_version:">=2.0,<3",entry_points:{"aiida.data":{"gromacs.pdb2gmx":"aiida_gromacs.data.pdb2gmx:Pdb2gmxParameters","gromacs.editconf":"aiida_gromacs.data.editconf:EditconfParameters","gromacs.genion":"aiida_gromacs.data.genion:GenionParameters","gromacs.grompp":"aiida_gromacs.data.grompp:GromppParameters","gromacs.mdrun":"aiida_gromacs.data.mdrun:MdrunParameters","gromacs.solvate":"aiida_gromacs.data.solvate:SolvateParameters"},"aiida.calculations":{"gromacs.pdb2gmx":{description:["AiiDA calculation plugin wrapping the 'gmx pdb2gmx' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Pdb2gmxParameters",info:"Command line parameters for gmx pdb2gmx"},{name:"pdbfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"itpfile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output forcefield compliant file."},{name:"n_file",required:!1,valid_types:"SinglefileData",info:"Output index file"},{name:"q_file",required:!1,valid_types:"SinglefileData",info:"Output Structure file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.pdb2gmx:Pdb2gmxCalculation"},"gromacs.editconf":{description:["AiiDA calculation plugin wrapping the 'gmx editconf' executable.","","    AiiDA plugin wrapper for adding a simulation box to structure file."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure file."},{name:"parameters",required:!0,valid_types:"EditconfParameters",info:"Command line parameters for gmx editconf."},{name:"bf_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Generic data file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output file containing simulation box."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"mead_file",required:!1,valid_types:"SinglefileData",info:"Coordination file for MEAD"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.editconf:EditconfCalculation"},"gromacs.genion":{description:["AiiDA calculation plugin wrapping the 'gmx genion' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"GenionParameters",info:"Command line parameters for gmx genion"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology file."},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Input tpr file."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output gro file with ions added."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output topology with ions added."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.genion:GenionCalculation"},"gromacs.grompp":{description:["AiiDA calculation plugin wrapping the 'gmx grompp' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure"},{name:"mdpfile",required:!0,valid_types:"SinglefileData",info:"grompp run file."},{name:"parameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"e_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Energy file"},{name:"itpfile",required:!1,valid_types:"SinglefileData, NoneType",info:"Restraint file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"n_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file"},{name:"qmi_file",required:!1,valid_types:"SinglefileData, NoneType",info:"QM input file"},{name:"r_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Structure file"},{name:"rb_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Structure file"},{name:"ref_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Full precision trajectory file"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"t_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Full precision trajectory file"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Output gro file ready for adding ions."},{name:"imd_file",required:!1,valid_types:"SinglefileData",info:"Coordinate file in Gromos-87 format"},{name:"po_file",required:!1,valid_types:"SinglefileData",info:"grompp input file with MD parameters"},{name:"pp_file",required:!1,valid_types:"SinglefileData",info:"Topology file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.grompp:GromppCalculation"},"gromacs.mdrun":{description:["AiiDA calculation plugin wrapping the 'gmx mdrun' executable.","","    AiiDA plugin wrapper for converting PDB files to GRO files."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun"},{name:"tprfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"awh_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"cpi_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Checkpoint file"},{name:"ei_file",required:!1,valid_types:"SinglefileData, NoneType",info:"ED sampling input"},{name:"membed_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Generic data file"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"mn_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Index file"},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"mp_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Topology file"},{name:"multidir_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Run directory"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"rerun_file",required:!1,valid_types:"SinglefileData, NoneType",info:"Trajectory: xtc trr cpt gro g96 pdb tng"},{name:"table_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"tableb_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"},{name:"tablep_file",required:!1,valid_types:"SinglefileData, NoneType",info:"xvgr/xmgr file"}],outputs:[{name:"enfile",required:!0,valid_types:"SinglefileData",info:"Output energy file."},{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output structure file."},{name:"logfile",required:!0,valid_types:"SinglefileData",info:"Output log file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"trrfile",required:!0,valid_types:"SinglefileData",info:"Output trajectory."},{name:"cpo_file",required:!1,valid_types:"SinglefileData",info:"Checkpoint file."},{name:"dhdl_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"eo_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"field_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"if_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"mtx_file",required:!1,valid_types:"SinglefileData",info:"Hessian Matrix"},{name:"pf_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"px_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"ra_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"ro_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"rs_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"rt_file",required:!1,valid_types:"SinglefileData",info:"Log file"},{name:"swap_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"tpi_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"tpid_file",required:!1,valid_types:"SinglefileData",info:"xvgr/xmgr file"},{name:"x_file",required:!1,valid_types:"SinglefileData",info:"Compressed trajectory (tng format or portable xdr format)"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.mdrun:MdrunCalculation"},"gromacs.solvate":{description:["AiiDA calculation plugin wrapping the 'gmx solvate' executable.","","    AiiDA plugin wrapper for solvating a molecular system."],spec:{inputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Input structure"},{name:"parameters",required:!0,valid_types:"SolvateParameters",info:"Command line parameters for gmx solvate."},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Input topology"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"grofile",required:!0,valid_types:"SinglefileData",info:"Output solvated gro file."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"stdout"},{name:"topfile",required:!0,valid_types:"SinglefileData",info:"Output topology file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."}]},class:"aiida_gromacs.calculations.solvate:SolvateCalculation"},genericMD:{description:["AiiDA calculation plugin wrapping an executable with user defined","    input and output files."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"command",required:!1,valid_types:"Str, NoneType",info:"The command used to execute the job."},{name:"input_files",required:!1,valid_types:"SinglefileData",info:"Dictionary of input files."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"output_files",required:!1,valid_types:"List, NoneType",info:"List of output file names."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"log",required:!1,valid_types:"SinglefileData",info:"link to the default file.out."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Calculation did not produce all expected output files."},{status:301,message:"Specified output file not produced by command."}]},class:"aiida_gromacs.calculations.genericMD:GenericCalculation"}},"aiida.parsers":{"gromacs.pdb2gmx":"aiida_gromacs.parsers.pdb2gmx:Pdb2gmxParser","gromacs.editconf":"aiida_gromacs.parsers.editconf:EditconfParser","gromacs.genion":"aiida_gromacs.parsers.genion:GenionParser","gromacs.grompp":"aiida_gromacs.parsers.grompp:GromppParser","gromacs.mdrun":"aiida_gromacs.parsers.mdrun:MdrunParser","gromacs.solvate":"aiida_gromacs.parsers.solvate:SolvateParser",genericMD:"aiida_gromacs.parsers.genericMD:GenericParser"},"aiida.workflows":{"gromacs.setup":{description:["WorkChain for setting up a gromacs simulation automatically."],spec:{inputs:[{name:"editconfparameters",required:!0,valid_types:"EditconfParameters",info:"Command line parameters for gmx editconf"},{name:"genionparameters",required:!0,valid_types:"GenionParameters",info:"Command line parameters for gmx genion"},{name:"gromppionsparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp"},{name:"gromppminparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp minimisation run"},{name:"gromppnptparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp npt equilibration run"},{name:"gromppnvtparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp nvt equilibration run"},{name:"gromppprodparameters",required:!0,valid_types:"GromppParameters",info:"Command line parameters for gmx grompp production run"},{name:"ionsmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for adding ions."},{name:"local_code",required:!0,valid_types:"Code",info:""},{name:"mdrunparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun production run"},{name:"minimiseparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun minimisation run"},{name:"minmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for minimisation."},{name:"nptmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for NPT equilibration."},{name:"nptparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun npt equilibration run"},{name:"nvtmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for NVT equilibration."},{name:"nvtparameters",required:!0,valid_types:"MdrunParameters",info:"Command line parameters for gmx mdrun nvt equilibration run"},{name:"pdb2gmxparameters",required:!0,valid_types:"Pdb2gmxParameters",info:"Command line parameters for gmx pdb2gmx"},{name:"pdbfile",required:!0,valid_types:"SinglefileData",info:"Input structure."},{name:"prodmdp",required:!0,valid_types:"SinglefileData",info:"MD parameters for production run."},{name:"solvateparameters",required:!0,valid_types:"SolvateParameters",info:"Command line parameters for gmx solvate"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"remote_code",required:!1,valid_types:"Code, NoneType",info:""}],outputs:[{name:"result",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_gromacs.workflows.simsetup:SetupWorkChain"}}},commits_count:187,development_status:"alpha",warnings:["Entry point 'genericMD' does not start with prefix 'gromacs.'","Entry point 'genericMD' does not start with prefix 'gromacs.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:7},{colorclass:"brown",text:"Parsers",count:7},{colorclass:"red",text:"Data",count:6},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/jimboid/aiida-gromacs",is_installable:"True"},"aiida-grouppathx":{code_home:"https://github.com/zhubonan/aiida-grouppathx",development_status:"beta",entry_point_prefix:"grouppathx",pip_url:"aiida-grouppathx",name:"aiida-grouppathx",package_name:"aiida_grouppathx",hosted_on:"github.com",metadata:{release_date:"2022-05-25",description:"AiiDA plugin provides the GroupPathX class",author_email:"Bonan Zhu <zhubonan@outlook.com>",classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.0"},aiida_version:">=1.6.4,<3",entry_points:{"aiida.cmdline.data":{gpx:"aiida_grouppathx.cli:grouppathx_cli"}},commits_count:3,warnings:["Unable to read wheel file from PyPI release: No entry_points.txt found in wheel","Development status in classifiers (alpha) does not match development_status in metadata (beta)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'gpx' does not start with prefix 'grouppathx.'"],summaryinfo:[{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install aiida-grouppathx",is_installable:"True"},"aiida-gudhi":{code_home:"https://github.com/ltalirz/aiida-gudhi",development_status:"beta",entry_point_prefix:"gudhi",pip_url:"aiida-gudhi",plugin_info:"https://raw.github.com/ltalirz/aiida-gudhi/master/setup.json",name:"aiida-gudhi",package_name:"aiida_gudhi",hosted_on:"github.com",metadata:{release_date:"2018-06-21",description:"AiiDA plugin for the [GUDHI](http://gudhi.gforge.inria.fr/) library for topological data analysis.",author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-gudhi",classifiers:["Programming Language :: Python"],version:"0.1.0a3"},aiida_version:"*",entry_points:{"aiida.calculations":{"gudhi.rdm":"aiida_gudhi.calculations.rips:RipsDistanceMatrixCalculation"},"aiida.data":{"gudhi.rdm":"aiida_gudhi.data.rips:RipsDistanceMatrixParameters"},"aiida.parsers":{"gudhi.rdm":"aiida_gudhi.parsers.rips:RipsParser"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install --pre aiida-gudhi",is_installable:"True"},"aiida-gulp":{code_home:"https://github.com/aiidaplugins/aiida-gulp",development_status:"beta",documentation_url:"https://aiida-gulp.readthedocs.io",entry_point_prefix:"gulp",pip_url:"aiida-gulp",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-gulp/master/setup.json",name:"aiida-gulp",package_name:"aiida_gulp",hosted_on:"github.com",metadata:{release_date:"2019-10-30",description:"AiiDA plugin for running the GULP MD code",author:"Chris Sewell",author_email:"chrisj_sewell@hotmail.com",license:"MIT",home_page:"https://github.com/chrisjsewell/aiida-gulp",classifiers:["Framework :: AiiDA","Programming Language :: Python","Programming Language :: Python :: 2.7","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"0.10.0b5"},aiida_version:"1.0.0b5",entry_points:{"aiida.calculations":{"gulp.fitting":"aiida_gulp.calculations.gulp_fitting:GulpFittingCalculation","gulp.optimize":"aiida_gulp.calculations.gulp_optimize:GulpOptCalculation","gulp.single":"aiida_gulp.calculations.gulp_single:GulpSingleCalculation"},"aiida.cmdline.data":{"gulp.potentials":"aiida_gulp.cmndline.potentials:potentials"},"aiida.data":{"gulp.potential":"aiida_gulp.data.potential:EmpiricalPotential","gulp.symmetry":"aiida_gulp.data.symmetry:SymmetryData"},"aiida.parsers":{"gulp.fitting":"aiida_gulp.parsers.parse_fitting:GulpFittingParser","gulp.optimize":"aiida_gulp.parsers.parse_opt:GulpOptParser","gulp.single":"aiida_gulp.parsers.parse_single:GulpSingleParser"},"aiida.workflows":{},console_scripts:{gulp_mock:"aiida_gulp.tests.mock_gulp:main"},"gulp.potentials":{lj:"aiida_gulp.potentials.lj:PotentialWriterLJ",reaxff:"aiida_gulp.potentials.reaxff:PotentialWriterReaxff"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:3},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:2},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Data commands, Gulp potentials)",count:3}],pip_install_cmd:"pip install --pre aiida-gulp",is_installable:"True",errors:["Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`,"Failed to fetch entry point metadata for package aiida_gulp",`<pre>Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 764, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 717, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 956, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 555, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 83, in document_entry_point
    from aiida.engine import Process
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/__init__.py", line 16, in <module>
    from .launch import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/launch.py", line 17, in <module>
    from .processes.functions import FunctionProcess
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/__init__.py", line 17, in <module>
    from .calcjobs import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/__init__.py", line 16, in <module>
    from .calcjob import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/calcjobs/calcjob.py", line 18, in <module>
    from aiida import orm
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/__init__.py", line 22, in <module>
    from .nodes import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/__init__.py", line 16, in <module>
    from .data import *
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/__init__.py", line 15, in <module>
    from .array import ArrayData, BandsData, KpointsData, ProjectionData, TrajectoryData, XyData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/__init__.py", line 15, in <module>
    from .array import ArrayData
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/array/array.py", line 17, in <module>
    from ..data import Data
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/data.py", line 21, in <module>
    from ..node import Node
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 43, in <module>
    class Node(Entity):
  File "/opt/conda/lib/python3.8/site-packages/six.py", line 849, in wrapper
    return metaclass(cls.__name__, cls.__bases__, orig_vars)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 268, in __new__
    newcls._plugin_type_string = get_type_string_from_class(namespace['__module__'], name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/utils/node.py", line 95, in get_type_string_from_class
    group, entry_point = get_entry_point_from_class(class_module, class_name)
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 252, in get_entry_point_from_class
    for group in ENTRYPOINT_MANAGER.get_entry_map().keys():
  File "/opt/conda/lib/python3.8/site-packages/reentry/default_manager.py", line 69, in get_entry_map
    return self._backend.get_map(dist=dist_names, group=groups, name=ep_names)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 173, in get_map
    dist_list = self._dist_list_from_arg(dist)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 268, in _dist_list_from_arg
    dist_list = _listify(dist_arg)
  File "/opt/conda/lib/python3.8/site-packages/reentry/jsonbackend.py", line 285, in _listify
    from six.moves import collections_abc
ImportError: cannot import name 'collections_abc' from 'six.moves' (unknown location)
</pre>`]},"aiida-kkr":{code_home:"https://github.com/JuDFTteam/aiida-kkr/tree/develop",development_status:"stable",documentation_url:"https://aiida-kkr.readthedocs.io/",entry_point_prefix:"kkr",pip_url:"aiida-kkr",name:"aiida-kkr",package_name:"aiida_kkr",hosted_on:"github.com",metadata:{release_date:"2023-04-05",description:"AiiDA plugin for the JuKKR codes",author_email:"Philipp Ruessmann <p.ruessmann@fz-juelich.de>, Jens Broeder <j.broeder@fz-juelich.de>, Fabian Bertoldo <f.bertoldo@fz-juelich.de>",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.0.0"},aiida_version:null,entry_points:{},commits_count:78,errors:["Unable to retrieve plugin info from: https://raw.github.com/JuDFTteam/aiida-kkr/develop/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","Development status in classifiers (beta) does not match development_status in metadata (stable)","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install aiida-kkr",is_installable:"True"},"aiida-lammps":{code_home:"https://github.com/aiidaplugins/aiida-lammps",development_status:"beta",entry_point_prefix:"lammps",pip_url:"git+https://github.com/aiidaplugins/aiida-lammps",name:"aiida-lammps",package_name:"aiida_lammps",hosted_on:"github.com",metadata:{author:"Abel Carreras, Chris Sewell",author_email:"chrisj_sewell@hotmail.com",version:"0.8.0",description:"AiiDA plugin for LAMMPS",classifiers:["Programming Language :: Python","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Framework :: AiiDA"]},aiida_version:">=1.4.0,<2.0.0",entry_points:{"aiida.calculations":{"lammps.combinate":"aiida_lammps.calculations.lammps.combinate:CombinateCalculation","lammps.force":"aiida_lammps.calculations.lammps.force:ForceCalculation","lammps.md":"aiida_lammps.calculations.lammps.md:MdCalculation","lammps.md.multi":"aiida_lammps.calculations.lammps.md_multi:MdMultiCalculation","lammps.optimize":"aiida_lammps.calculations.lammps.optimize:OptimizeCalculation",dynaphopy:"aiida_lammps.calculations.dynaphopy: DynaphopyCalculation"},"aiida.parsers":{"lammps.force":"aiida_lammps.parsers.lammps.force:ForceParser","lammps.md":"aiida_lammps.parsers.lammps.md:MdParser","lammps.md.multi":"aiida_lammps.parsers.lammps.md_multi:MdMultiParser","lammps.optimize":"aiida_lammps.parsers.lammps.optimize:OptimizeParser",dynaphopy:"aiida_lammps.parsers.dynaphopy: DynaphopyParser"},"aiida.data":{"lammps.potential":"aiida_lammps.data.potential:EmpiricalPotential","lammps.trajectory":"aiida_lammps.data.trajectory:LammpsTrajectory"},"lammps.potentials":{eam:"aiida_lammps.data.pot_plugins.eam:EAM",lennard_jones:"aiida_lammps.data.pot_plugins.lennard_jones:LennardJones",reaxff:"aiida_lammps.data.pot_plugins.reaxff:Reaxff",tersoff:"aiida_lammps.data.pot_plugins.tersoff:Tersoff"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'dynaphopy' does not start with prefix 'lammps.'","Entry point 'dynaphopy' does not start with prefix 'lammps.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:6},{colorclass:"brown",text:"Parsers",count:5},{colorclass:"red",text:"Data",count:2},{colorclass:"orange",text:"Other (Lammps potentials)",count:4}],pip_install_cmd:"pip install git+https://github.com/aiidaplugins/aiida-lammps",is_installable:"True"},"aiida-lsmo":{code_home:"https://github.com/lsmo-epfl/aiida-lsmo",development_status:"stable",entry_point_prefix:"lsmo",pip_url:"git+https://github.com/lsmo-epfl/aiida-lsmo",name:"aiida-lsmo",package_name:"aiida_lsmo",hosted_on:"github.com",metadata:{author:"Aliaksandr Yakutovich, Daniele Ongari, Leopold Talirz",author_email:"aliaksandr.yakutovich@epfl.ch",version:"1.0.0",description:"AiiDA workflows for the LSMO laboratory at EPFL",classifiers:["Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7"]},aiida_version:">=1.0.0",entry_points:{"aiida.calculations":{"lsmo.ff_builder":{description:["AiiDA calcfunction to assemble force filed parameters into SinglefileData for Raspa."],spec:{inputs:[{name:"params",required:!0,valid_types:"Data",info:""},{name:"cif_molecule",required:!1,valid_types:"Data, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.calcfunctions:ff_builder"},"lsmo.calc_ch4_working_cap":{description:["Compute the CH4 working capacity from the output_parameters Dict of IsothermWorkChain.","    This must have run calculations at 5.8 and 65.0 bar (at 298K), which are the standard reference for the evaluation.","","    The results can be compared with Simon2015 (10.1039/C4EE03515A)."],spec:{inputs:[{name:"isot_dict",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.calcfunctions:calc_ch4_working_cap"},"lsmo.calc_h2_working_cap":{description:["Compute the H2 working capacity from the output_parameters Dict of MultiTempIsothermWorkChain.","    This must have run calculations at 1, 5 and 100 bar at 77, 198, 298 K.","    The US DOE Target for the Onboard Storage of Hydrogen Vehicles set the bar to 4.5 wt% and 30 g/L (Kapelewski2018).","    Case-A: near-ambient-T adsorption, 100bar/198K to 5bar/298K (cf. Kapelewski2018, 10.1021/acs.chemmater.8b03276)","    ....... Ni2(m-dobdc), experimental: 23.0 g/L","    Case-B: low T adsorption, 100-5bar at 77K (cf. Ahmed2019, 10.1038/s41467-019-09365-w)","    ....... NU-100, best experimental: 35.5 g/L","    Case-C: low T adsorption at low discharge, 100-1bar at 77K (cf. Thornton2017, 10.1021/acs.chemmater.6b04933)","    ....... hypMOF-5059389, best simulated: 40.0 g/L"],spec:{inputs:[{name:"isotmt_dict",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.calcfunctions:calc_h2_working_cap"},"lsmo.calc_o2_working_cap":{description:["Compute the O2 working capacity from the output_parameters Dict of IsothermWorkChain.","    This must have run calculations at 5 and 140.0 bar (at 298K), to be consistent with the screening of Moghadam2018","    (10.1038/s41467-018-03892-8), for which the MOF ANUGIA (UMCM-152) was found to have a volumetric working capacity","    of 249 vSTP/v (simulations are nearly identical to experiments).","    Consider that, at the same conditions, an empty thank can only store 136 vSTP/v, and a comparable working capacity","    can only br obtained compressing till 300bar."],spec:{inputs:[{name:"isot_dict",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.calcfunctions:calc_o2_working_cap"},"lsmo.calc_selectivity":{description:["Compute the selectivity of gas A on gas B as S = kH_a/kH_b.","    Note that if the material is not porous to one of the materials, the result is simply {'is_porous': False}.","    To maintain the comptaibility with v1, intead of checking 'is_porous', it checks for the henry_coefficient_average","    key in the Dict."],spec:{inputs:[{name:"isot_dict_a",required:!0,valid_types:"Data",info:""},{name:"isot_dict_b",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.calcfunctions:calc_selectivity"}},"aiida.parsers":{"lsmo.cp2k_bsse_parser":"aiida_lsmo.parsers:Cp2kBsseParser","lsmo.cp2k_advanced_parser":"aiida_lsmo.parsers:Cp2kAdvancedParser"},"aiida.workflows":{"lsmo.binding_site":{description:["A workchain that combines SimAnnealing & Cp2kBindingEnergy"],spec:{inputs:[{name:"cp2k_base",required:!0,valid_types:"",info:""},{name:"molecule",required:!0,valid_types:"Str, Dict",info:"Adsorbate molecule: settings to be read from the yaml.Advanced: input a Dict for non-standard settings."},{name:"parameters",required:!0,valid_types:"Dict",info:"Parameters for the SimAnnealing workchain: will be merged with default ones."},{name:"raspa_base",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"CifData",info:"Adsorbent framework CIF."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"protocol_modify",required:!1,valid_types:"Dict",info:"Specify custom settings that overvrite the yaml settings"},{name:"protocol_tag",required:!1,valid_types:"Str",info:"The tag of the protocol tag.yaml. NOTE: only the settings are read, stage is set to GEO_OPT."},{name:"protocol_yaml",required:!1,valid_types:"SinglefileData",info:"Specify a custom yaml file. NOTE: only the settings are read, stage is set to GEO_OPT."},{name:"starting_settings_idx",required:!1,valid_types:"Int",info:"If idx>0 is chosen, jumps directly to overwrite settings_0 with settings_{idx}"}],outputs:[{name:"dft",required:!0,valid_types:"",info:""},{name:"ff",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains:BindingSiteWorkChain"},"lsmo.cp2k_binding_energy":{description:["Submits Cp2kBase work chain for structure + molecule system, first optimizing the geometry of the molecule and","    later computing the BSSE corrected interaction energy.","    This work chain is inspired to Cp2kMultistage, and shares some logics and data from it."],spec:{inputs:[{name:"cp2k_base",required:!0,valid_types:"",info:""},{name:"molecule",required:!0,valid_types:"StructureData",info:"Input molecule in the unit cell of the structure."},{name:"structure",required:!0,valid_types:"StructureData",info:"Input structure that contains the molecule."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"protocol_modify",required:!1,valid_types:"Dict",info:"Specify custom settings that overvrite the yaml settings"},{name:"protocol_tag",required:!1,valid_types:"Str",info:"The tag of the protocol tag.yaml. NOTE: only the settings are read, stage is set to GEO_OPT."},{name:"protocol_yaml",required:!1,valid_types:"SinglefileData",info:"Specify a custom yaml file. NOTE: only the settings are read, stage is set to GEO_OPT."},{name:"starting_settings_idx",required:!1,valid_types:"Int",info:"If idx>0 is chosen, jumps directly to overwrite settings_0 with settings_{idx}"}],outputs:[{name:"loaded_molecule",required:!0,valid_types:"StructureData",info:"Molecule geometry in the unit cell."},{name:"loaded_structure",required:!0,valid_types:"StructureData",info:"Geometry of the system with both fragments."},{name:"output_parameters",required:!0,valid_types:"Dict",info:"Info regarding the binding energy of the system."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:901,message:"Specified starting_settings_idx that is not existing, or any in between 0 and idx is missing"},{status:902,message:"Settings for Stage0 are not ok but there are no more robust settings to try"},{status:903,message:"Something important was not printed correctly and the parsing of the first calculation failed"}]},class:"aiida_lsmo.workchains.cp2k_binding_energy:Cp2kBindingEnergyWorkChain"},"lsmo.cp2k_multistage":{description:["Submits Cp2kBase workchains for ENERGY, GEO_OPT, CELL_OPT and MD jobs iteratively","    The protocol_yaml file contains a series of settings_x and stage_x:","    the workchains starts running the settings_0/stage_0 calculation, and, in case of a failure, changes the settings","    untill the SCF of stage_0 converges. Then it uses the same settings to run the next stages (i.e., stage_1, etc.)."],spec:{inputs:[{name:"cp2k_base",required:!0,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_cell_size",required:!1,valid_types:"Float",info:"To avoid using k-points, extend the cell so that min(perp_width)>min_cell_size"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData",info:"Provide an initial parent folder that contains the wavefunction for restart"},{name:"protocol_modify",required:!1,valid_types:"Dict",info:"Specify custom settings that overvrite the yaml settings"},{name:"protocol_tag",required:!1,valid_types:"Str",info:"The tag of the protocol to be read from {tag}.yaml unless protocol_yaml input is specified"},{name:"protocol_yaml",required:!1,valid_types:"SinglefileData",info:"Specify a custom yaml file with the multistage settings (and ignore protocol_tag)"},{name:"starting_settings_idx",required:!1,valid_types:"Int",info:"If idx>0 is chosen, jumps directly to overwrite settings_0 with settings_{idx}"},{name:"structure",required:!1,valid_types:"StructureData",info:"Input structure"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"last_input_parameters",required:!1,valid_types:"Dict",info:"CP2K input parameters used (and possibly working) used in the last stage"},{name:"output_parameters",required:!1,valid_types:"Dict",info:"Output CP2K parameters of all the stages, merged together"},{name:"output_structure",required:!1,valid_types:"StructureData",info:"Processed structure (missing if only ENERGY calculation is performed)"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:901,message:"Specified starting_settings_idx that is not existing, or any in between 0 and idx is missing"},{status:902,message:"Settings for Stage0 are not ok but there are no more robust settings to try"},{status:903,message:"Something important was not printed correctly and the parsing of the first calculation failed"}]},class:"aiida_lsmo.workchains:Cp2kMultistageWorkChain"},"lsmo.cp2k_multistage_ddec":{description:["A workchain that combines: Cp2kMultistageWorkChain + Cp2kDdecWorkChain"],spec:{inputs:[{name:"cp2k_base",required:!0,valid_types:"",info:""},{name:"ddec",required:!0,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_cell_size",required:!1,valid_types:"Float",info:"To avoid using k-points, extend the cell so that min(perp_width)>min_cell_size"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData",info:"Provide an initial parent folder that contains the wavefunction for restart"},{name:"protocol_modify",required:!1,valid_types:"Dict",info:"Specify custom settings that overvrite the yaml settings"},{name:"protocol_tag",required:!1,valid_types:"Str",info:"The tag of the protocol to be read from {tag}.yaml unless protocol_yaml input is specified"},{name:"protocol_yaml",required:!1,valid_types:"SinglefileData",info:"Specify a custom yaml file with the multistage settings (and ignore protocol_tag)"},{name:"starting_settings_idx",required:!1,valid_types:"Int",info:"If idx>0 is chosen, jumps directly to overwrite settings_0 with settings_{idx}"},{name:"structure",required:!1,valid_types:"StructureData",info:"Input structure"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"structure_ddec",required:!0,valid_types:"CifData",info:"structure with DDEC charges"},{name:"last_input_parameters",required:!1,valid_types:"Dict",info:"CP2K input parameters used (and possibly working) used in the last stage"},{name:"output_parameters",required:!1,valid_types:"Dict",info:"Output CP2K parameters of all the stages, merged together"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains:Cp2kMultistageDdecWorkChain"},"lsmo.isotherm":{description:["Workchain that computes volpo and blocking spheres: if accessible volpo>0","    it also runs a raspa widom calculation for the Henry coefficient."],spec:{inputs:[{name:"molecule",required:!0,valid_types:"Str, Dict",info:"Adsorbate molecule: settings to be read from the yaml.Advanced: input a Dict for non-standard settings."},{name:"parameters",required:!0,valid_types:"Dict",info:"Parameters for the Isotherm workchain (see workchain.schema for default values)."},{name:"raspa_base",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"CifData",info:"Adsorbent framework CIF."},{name:"zeopp",required:!0,valid_types:"",info:""},{name:"geometric",required:!1,valid_types:"Dict",info:"[Only used by IsothermMultiTempWorkChain] Already computed geometric properties"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Results of the single temperature wc: keys can vay depending on is_porous and is_kh_enough booleans."},{name:"block",required:!1,valid_types:"SinglefileData",info:"Blocked pockets fileoutput file."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains:IsothermWorkChain"},"lsmo.isotherm_multi_temp":{description:["Run IsothermWorkChain for multiple temperatures: first compute geometric properties","    and then submit Widom+GCMC at different temperatures in parallel"],spec:{inputs:[{name:"molecule",required:!0,valid_types:"Str, Dict",info:"Adsorbate molecule: settings to be read from the yaml.Advanced: input a Dict for non-standard settings."},{name:"parameters",required:!0,valid_types:"Dict",info:"Parameters for the Isotherm workchain (see workchain.schema for default values)."},{name:"raspa_base",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"CifData",info:"Adsorbent framework CIF."},{name:"zeopp",required:!0,valid_types:"",info:""},{name:"geometric",required:!1,valid_types:"Dict",info:"[Only used by IsothermMultiTempWorkChain] Already computed geometric properties"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"Results of isotherms run at different temperatures."},{name:"block",required:!1,valid_types:"SinglefileData",info:"Blocked pockets fileoutput file."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains:IsothermMultiTempWorkChain"},"lsmo.isotherm_calc_pe":{description:["Compute CO2 parassitic energy (PE) after running IsothermWorkChain for CO2 and N2 at 300K."],spec:{inputs:[{name:"raspa_base",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"CifData",info:"Adsorbent framework CIF."},{name:"zeopp",required:!0,valid_types:"",info:""},{name:"geometric",required:!1,valid_types:"Dict",info:"[Only used by IsothermMultiTempWorkChain] Already computed geometric properties"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:"Parameters for Isotherm work chain"},{name:"pe_parameters",required:!1,valid_types:"Dict",info:"Parameters for PE process modelling"}],outputs:[{name:"co2",required:!0,valid_types:"Data",info:""},{name:"n2",required:!0,valid_types:"Data",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:"Output parmaters of a calc_PE calculations"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains:IsothermCalcPEWorkChain"},"lsmo.zeopp_multistage_ddec":{description:["A workchain that combines: Zeopp + Cp2kMultistageWorkChain + Cp2kDdecWorkChain + Zeopp"],spec:{inputs:[{name:"cp2k_base",required:!0,valid_types:"",info:""},{name:"ddec",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"CifData",info:"input structure"},{name:"zeopp",required:!0,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_cell_size",required:!1,valid_types:"Float",info:"To avoid using k-points, extend the cell so that min(perp_width)>min_cell_size"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData",info:"Provide an initial parent folder that contains the wavefunction for restart"},{name:"protocol_modify",required:!1,valid_types:"Dict",info:"Specify custom settings that overvrite the yaml settings"},{name:"protocol_tag",required:!1,valid_types:"Str",info:"The tag of the protocol to be read from {tag}.yaml unless protocol_yaml input is specified"},{name:"protocol_yaml",required:!1,valid_types:"SinglefileData",info:"Specify a custom yaml file with the multistage settings (and ignore protocol_tag)"},{name:"starting_settings_idx",required:!1,valid_types:"Int",info:"If idx>0 is chosen, jumps directly to overwrite settings_0 with settings_{idx}"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"structure_ddec",required:!0,valid_types:"CifData",info:"structure with DDEC charges"},{name:"zeopp_after_opt",required:!0,valid_types:"Data",info:""},{name:"zeopp_before_opt",required:!0,valid_types:"Data",info:""},{name:"last_input_parameters",required:!1,valid_types:"Dict",info:"CP2K input parameters used (and possibly working) used in the last stage"},{name:"output_parameters",required:!1,valid_types:"Dict",info:"Output CP2K parameters of all the stages, merged together"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains:ZeoppMultistageDdecWorkChain"},"lsmo.sim_annealing":{description:["A work chain to compute the minimum energy geometry of a molecule inside a framework, using simulated annealing,","    i.e., decreasing the temperature of a Monte Carlo simulation and finally running and energy minimization step."],spec:{inputs:[{name:"molecule",required:!0,valid_types:"Str, Dict",info:"Adsorbate molecule: settings to be read from the yaml.Advanced: input a Dict for non-standard settings."},{name:"parameters",required:!0,valid_types:"Dict",info:"Parameters for the SimAnnealing workchain: will be merged with default ones."},{name:"raspa_base",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"CifData",info:"Adsorbent framework CIF."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"loaded_molecule",required:!0,valid_types:"CifData",info:"CIF containing the final postition of the molecule."},{name:"loaded_structure",required:!0,valid_types:"CifData",info:"CIF containing the loaded structure."},{name:"output_parameters",required:!1,valid_types:"Dict",info:"Information about the final configuration."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains.sim_annealing:SimAnnealingWorkChain"},"lsmo.nanoporous_screening_1":{description:["A workchain that combines: ZeoppMultistageDdecWorkChain wc1 and IsothermCalcPEWorkChain wc2.","    In future I will use this to include more applications to run in parallel."],spec:{inputs:[{name:"cp2k_base",required:!0,valid_types:"",info:""},{name:"ddec",required:!0,valid_types:"",info:""},{name:"raspa_base",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"CifData",info:"input structure"},{name:"zeopp",required:!0,valid_types:"",info:""},{name:"geometric",required:!1,valid_types:"Dict",info:"[Only used by IsothermMultiTempWorkChain] Already computed geometric properties"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_cell_size",required:!1,valid_types:"Float",info:"To avoid using k-points, extend the cell so that min(perp_width)>min_cell_size"},{name:"parameters",required:!1,valid_types:"Dict",info:"Parameters for Isotherm work chain"},{name:"parent_calc_folder",required:!1,valid_types:"RemoteData",info:"Provide an initial parent folder that contains the wavefunction for restart"},{name:"pe_parameters",required:!1,valid_types:"Dict",info:"Parameters for PE process modelling"},{name:"protocol_modify",required:!1,valid_types:"Dict",info:"Specify custom settings that overvrite the yaml settings"},{name:"protocol_tag",required:!1,valid_types:"Str",info:"The tag of the protocol to be read from {tag}.yaml unless protocol_yaml input is specified"},{name:"protocol_yaml",required:!1,valid_types:"SinglefileData",info:"Specify a custom yaml file with the multistage settings (and ignore protocol_tag)"},{name:"starting_settings_idx",required:!1,valid_types:"Int",info:"If idx>0 is chosen, jumps directly to overwrite settings_0 with settings_{idx}"}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_lsmo.workchains:NanoporousScreening1WorkChain"}}},commits_count:17,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:5},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:10}],pip_install_cmd:"pip install git+https://github.com/lsmo-epfl/aiida-lsmo",is_installable:"True"},"aiida-metavo-scheduler":{code_home:"https://github.com/pzarabadip/aiida-metavo-scheduler",development_status:"stable",entry_point_prefix:"metavo_scheduler",pip_url:"git+https://github.com/pzarabadip/aiida-metavo-scheduler",name:"aiida-metavo-scheduler",package_name:"aiida_metavo_scheduler",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"1.0.0",description:"",classifiers:["Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering"]},aiida_version:">=1.0.0,<1.6",entry_points:{"aiida.cmdline.computer.configure":{sshmetavo:"aiida_metavo_scheduler.metavo.ssh_metavo:CONFIGURE_SSH_CMD"},"aiida.schedulers":{pbsprometavo:"aiida_metavo_scheduler.metavo.pbspro_metavo:PbsproSchedulerMetaVO"},"aiida.transports":{sshmetavo:"aiida_metavo_scheduler.metavo.ssh_metavo:SshTransport"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'sshmetavo' does not start with prefix 'metavo_scheduler.'","Entry point 'pbsprometavo' does not start with prefix 'metavo_scheduler.'","Entry point 'sshmetavo' does not start with prefix 'metavo_scheduler.'"],summaryinfo:[{colorclass:"orange",text:"Other (Cmdline computer configure, Schedulers, Transports)",count:3}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-metavo-scheduler",is_installable:"False",errors:["Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`,"Failed to install plugin aiida-metavo-scheduler",`<pre>Collecting git+https://github.com/pzarabadip/aiida-metavo-scheduler
  Cloning https://github.com/pzarabadip/aiida-metavo-scheduler to /tmp/pip-req-build-6wns091b
  Running command git clone --filter=blob:none --quiet https://github.com/pzarabadip/aiida-metavo-scheduler /tmp/pip-req-build-6wns091b
  Resolved https://github.com/pzarabadip/aiida-metavo-scheduler to commit 955697497641ca13e997431a8e925df6ec3a9eea
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida_core<1.6,>=1.0.0
  Downloading aiida_core-1.5.3-py3-none-any.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 77.1 MB/s eta 0:00:00
Collecting gssapi~=1.6
  Downloading gssapi-1.8.3.tar.gz (94 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 33.1 MB/s eta 0:00:00
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'error'
  error: subprocess-exited-with-error
  
  × Getting requirements to build wheel did not run successfully.
  │ exit code: 1
  ╰─> [21 lines of output]
      /bin/sh: 1: krb5-config: not found
      Traceback (most recent call last):
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 363, in <module>
          main()
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 345, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File "/opt/conda/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py", line 130, in get_requires_for_build_wheel
          return hook(config_settings)
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 355, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 325, in _get_build_requires
          self.run_setup()
        File "/tmp/pip-build-env-ztsxn_aw/overlay/lib/python3.8/site-packages/setuptools/build_meta.py", line 341, in run_setup
          exec(code, locals())
        File "<string>", line 109, in <module>
        File "<string>", line 22, in get_output
        File "/opt/conda/lib/python3.8/subprocess.py", line 415, in check_output
          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
        File "/opt/conda/lib/python3.8/subprocess.py", line 516, in run
          raise CalledProcessError(retcode, process.args,
      subprocess.CalledProcessError: Command 'krb5-config --libs gssapi' returned non-zero exit status 127.
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

× Getting requirements to build wheel did not run successfully.
│ exit code: 1
╰─> See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</pre>`]},"aiida-mpds":{code_home:"https://github.com/mpds-io/mpds-aiida",development_status:"beta",documentation_url:"https://github.com/mpds-io/mpds-aiida",entry_point_prefix:"mpds",pip_url:"git+https://github.com/mpds-io/mpds-aiida",name:"aiida-mpds",package_name:"aiida_mpds",hosted_on:"github.com",metadata:{author:"Andrey Sobolev",author_email:"as@tilde.pro",version:"",description:"Aiida workflows for MPDS based on CRYSTAL",classifiers:["Programming Language :: Python","Programming Language :: Python :: 3.5","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics","Topic :: Scientific/Engineering :: Information Analysis","Framework :: AiiDA"]},aiida_version:">=1.0.1",entry_points:{"aiida.workflows":{"crystal.mpds":"mpds_aiida.workflows.mpds:MPDSStructureWorkchain","crystal.cif":"mpds_aiida.workflows.cif:CIFStructureWorkchain","crystal.aiida":"mpds_aiida.workflows.aiida:AiidaStructureWorkchain"}},commits_count:6,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'crystal.mpds' does not start with prefix 'mpds.'","Entry point 'crystal.cif' does not start with prefix 'mpds.'","Entry point 'crystal.aiida' does not start with prefix 'mpds.'"],summaryinfo:[{colorclass:"green",text:"Workflows",count:3}],pip_install_cmd:"pip install git+https://github.com/mpds-io/mpds-aiida",is_installable:"False",errors:["Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`,"Failed to install plugin aiida-mpds",`<pre>Collecting git+https://github.com/mpds-io/mpds-aiida
  Cloning https://github.com/mpds-io/mpds-aiida to /tmp/pip-req-build-urm1huhe
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-aiida /tmp/pip-req-build-urm1huhe
  Resolved https://github.com/mpds-io/mpds-aiida to commit a00cdaab14fd25102ce224495256208fca7c00b3
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting mpds-ml-labs@ git+https://github.com/mpds-io/mpds-ml-labs
  Cloning https://github.com/mpds-io/mpds-ml-labs to /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Running command git clone --filter=blob:none --quiet https://github.com/mpds-io/mpds-ml-labs /tmp/pip-install-vb289qdi/mpds-ml-labs_b2866fb4922d448184f7beb524b1c9d7
  Resolved https://github.com/mpds-io/mpds-ml-labs to commit 574c6b08f824b1ab6400442a539fbb6de4b5b43b
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft
  Cloning https://github.com/tilde-lab/aiida-crystal-dft to /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Running command git clone --filter=blob:none --quiet https://github.com/tilde-lab/aiida-crystal-dft /tmp/pip-install-vb289qdi/aiida-crystal-dft_81034a49a0cc4ddbacedbfaf24652787
  Resolved https://github.com/tilde-lab/aiida-crystal-dft to commit cc49b637caeb150a534baacfd8380f47a9aecca2
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Collecting reentry>=1.3.1
  Using cached reentry-1.3.3-py3-none-any.whl (17 kB)
Requirement already satisfied: six>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.16.0)
Requirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (1.24.3)
Requirement already satisfied: ase>=3.19 in /opt/conda/lib/python3.8/site-packages (from mpds-aiida==0.10.0) (3.22.1)
Collecting yascheduler>=1.0.12
  Downloading yascheduler-1.2.0-py3-none-any.whl (67 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.9/67.9 kB 17.4 MB/s eta 0:00:00
Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (1.10.1)
Requirement already satisfied: matplotlib>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from ase>=3.19->mpds-aiida==0.10.0) (3.7.1)
Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (8.1.3)
Requirement already satisfied: setuptools>=36.2 in /opt/conda/lib/python3.8/site-packages (from reentry>=1.3.1->mpds-aiida==0.10.0) (63.2.0)
Collecting backoff~=2.1.2
  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)
Collecting azure-mgmt-compute~=27.2.0
  Downloading azure_mgmt_compute-27.2.0-py3-none-any.whl (5.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 98.2 MB/s eta 0:00:00
Collecting upcloud_api~=2.0
  Downloading upcloud_api-2.5.1-py3-none-any.whl (37 kB)
Collecting hcloud~=1.17
  Downloading hcloud-1.28.0-py3-none-any.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 29.4 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from yascheduler>=1.0.12->mpds-aiida==0.10.0) (4.5.0)
Collecting azure-identity~=1.10.0
  Downloading azure_identity-1.10.0-py3-none-any.whl (134 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.1/134.1 kB 43.5 MB/s eta 0:00:00
Collecting asyncstdlib~=3.10
  Downloading asyncstdlib-3.10.8-py3-none-any.whl (37 kB)
Collecting pg8000~=1.19
  Downloading pg8000-1.30.2-py3-none-any.whl (54 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.2/54.2 kB 22.3 MB/s eta 0:00:00
Collecting attrs~=21.0
  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 25.0 MB/s eta 0:00:00
Collecting azure-mgmt-network~=20.0.0
  Downloading azure_mgmt_network-20.0.0-py3-none-any.whl (8.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 104.0 MB/s eta 0:00:00
Collecting aiohttp~=3.8
  Downloading aiohttp-3.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.2 MB/s eta 0:00:00
Collecting python-daemon~=2.3
  Downloading python_daemon-2.3.2-py3-none-any.whl (34 kB)
Collecting asyncssh~=2.11
  Downloading asyncssh-2.13.2-py3-none-any.whl (349 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 349.3/349.3 kB 66.2 MB/s eta 0:00:00
Requirement already satisfied: aiida-core>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.3.1)
Collecting mpds_client>=0.24
  Downloading mpds_client-0.24.tar.gz (9.7 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: seekpath in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (1.9.7)
Collecting pycrystal>=1.0.10
  Downloading pycrystal-1.0.16.tar.gz (28 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: pyparsing>2.3.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.0.9)
Requirement already satisfied: spglib>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (2.0.2)
Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (23.1)
Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.1.2)
Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from aiida-crystal-dft@ git+https://github.com/tilde-lab/aiida-crystal-dft->mpds-aiida==0.10.0) (3.2.0)
Collecting pycodcif
  Downloading pycodcif-3.0.1.tar.gz (79 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 kB 30.6 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting sklearn
  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [18 lines of output]
      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'
      rather than 'sklearn' for pip commands.
      
      Here is how to fix this error in the main use cases:
      - use 'pip install scikit-learn' rather than 'pip install sklearn'
      - replace 'sklearn' by 'scikit-learn' in your pip requirements files
        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)
      - if the 'sklearn' package is used by one of your dependencies,
        it would be great if you take some time to track which package uses
        'sklearn' instead of 'scikit-learn' and report it to their issue tracker
      - as a last resort, set the environment variable
        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error
      
      More information is available at
      https://github.com/scikit-learn/sklearn-pypi-package
      
      If the previous advice does not cover your use case, feel free to report it at
      https://github.com/scikit-learn/sklearn-pypi-package/issues/new
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</pre>`]},"aiida-muon":{entry_point_prefix:"muon",code_home:"https://github.com/positivemuon/aiida-muon",version_file:"https://raw.githubusercontent.com/positivemuon/aiida-muon/main/aiida_muon/__init__.py",pip_url:"git+https://github.com/positivemuon/aiida-muon",name:"aiida-muon",package_name:"aiida_muon",hosted_on:"github.com",metadata:{description:"aiida-muon is allows to find candiate muon implantation sites and hyperfine field by DFT supercell relaxations and from further symmetry and kinetics analysis.  ",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 2 - Pre-Alpha","Framework :: AiiDA"],author:"Muon  group Parma"},aiida_version:">=2.0,<3",entry_points:{"aiida.workflows":{"muon.find_muon":{description:["FindMuonWorkChain finds the candidate implantation site for a positive muon.","    It first performs DFT relaxation calculations for a set of initial muon sites.","    It then analyzes the results of these calculations and finds candidate muon sites.","    If there are magnetic inequivalent sites not initially, they are recalculated","    It further calculates the muon contact hyperfine field at these candidate sites."],spec:{inputs:[{name:"sc_matrix",required:!0,valid_types:"List",info:" List of length 1 for supercell size "},{name:"structure",required:!0,valid_types:"StructureData",info:"Input initial structure"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"mu_spacing",required:!1,valid_types:"Float, NoneType",info:"Minimum distance in Angstrom between two starting muon positions  generated on a grid."},{name:"qe",required:!1,valid_types:"",info:"Input parameters, settings and options for QE DFT calculations"}],outputs:[{name:"all_index_uuid",required:!0,valid_types:"Dict",info:""},{name:"all_sites",required:!0,valid_types:"Dict",info:""},{name:"unique_sites",required:!0,valid_types:"Dict",info:""},{name:"unique_sites_dipolar",required:!1,valid_types:"List",info:""},{name:"unique_sites_hyperfine",required:!1,valid_types:"Dict",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:405,message:"One of the PwRelaxWorkChain subprocesses failed"},{status:406,message:"One of the PwBaseWorkChain subprocesses failed"},{status:407,message:"One of the PPWorkChain subprocesses failed"}]},class:"aiida_muon.workflows.find_muon:FindMuonWorkChain"}}},commits_count:21,development_status:"pre-alpha",summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/positivemuon/aiida-muon",is_installable:"True"},"aiida-musconv":{entry_point_prefix:"musconv",code_home:"https://github.com/positivemuon/aiida-musconv",version_file:"raw.githubusercontent.com/positivemuon/aiida-musconv/main/aiida_musconv/__init__.py",pip_url:"git+https://github.com/positivemuon/aiida-musconv",name:"aiida-musconv",package_name:"aiida_musconv",hosted_on:"github.com",metadata:{description:"aiida-musconv is a plugin that allows to obtain converged supercell size for an interstitial impurity calculation.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Development Status :: 2 - Pre-Alpha","Framework :: AiiDA"],author:"Muon  group Parma"},aiida_version:">=2.0,<3",entry_points:{"aiida.workflows":{musconv:{description:["WorkChain for finding converged supercell for interstitial impurity calculation"],spec:{inputs:[{name:"pwscf",required:!0,valid_types:"Data",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:"Input initial structure"},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space."},{name:"max_iter_num",required:!1,valid_types:"Int, NoneType",info:"Maximum number of iteration in the supercell convergence loop"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"min_length",required:!1,valid_types:"Float, NoneType",info:"The minimum length of the smallest lattice vector for the first generated supercell "},{name:"pseudofamily",required:!1,valid_types:"Str, NoneType",info:"The label of the pseudo family"}],outputs:[{name:"Converged_SCmatrix",required:!0,valid_types:"ArrayData",info:""},{name:"Converged_supercell",required:!0,valid_types:"StructureData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:402,message:"one of the PwCalculation subprocesses failed"},{status:702,message:"Max number of supercell convergence reached "},{status:704,message:"Error in fitting the forces to an exponential"}]},class:"aiida_musconv.workflows.musconv:MusconvWorkChain"}}},commits_count:43,development_status:"pre-alpha",summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/positivemuon/aiida-musconv",is_installable:"True"},"aiida-nanotech-empa":{code_home:"https://github.com/nanotech-empa/aiida-nanotech-empa",development_status:"beta",entry_point_prefix:"nanotech_empa",pip_url:"git+https://github.com/nanotech-empa/aiida-nanotech-empa",name:"aiida-nanotech-empa",package_name:"aiida_nanotech_empa",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:31,errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/nanotech-empa/aiida-nanotech-empa/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/nanotech-empa/aiida-nanotech-empa",is_installable:"True"},"aiida-nims-scheduler":{code_home:"https://github.com/atztogo/aiida-nims-scheduler",development_status:"stable",documentation_url:"https://github.com/atztogo/aiida-nims-scheduler",entry_point_prefix:"nims_scheduler",pip_url:"git+https://github.com/atztogo/aiida-nims-scheduler",name:"aiida-nims-scheduler",package_name:"aiida_nims_scheduler",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:25,errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/atztogo/aiida-nims-scheduler/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/atztogo/aiida-nims-scheduler",is_installable:"True"},"aiida-nwchem":{code_home:"https://github.com/aiidateam/aiida-nwchem",documentation_url:"https://aiida-nwchem.readthedocs.io/",entry_point_prefix:"nwchem",pip_url:"aiida-nwchem",plugin_info:"https://raw.githubusercontent.com/aiidateam/aiida-nwchem/master/setup.json",name:"aiida-nwchem",package_name:"aiida_nwchem",hosted_on:"github.com",metadata:{release_date:"2023-08-22",description:"The official AiiDA plugin for NWChem",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"3.0.1"},aiida_version:">=2.0,<3.0",entry_points:{"aiida.calculations":{"nwchem.base":{description:["Base calculation class for NWChem."],spec:{inputs:[{name:"input_file",required:!0,valid_types:"SinglefileData",info:"NWChem input file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, FolderData, NoneType",info:"Remote directory of a completed NWChem calculation to restart from."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Required output files are missing."},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"The stdout output file could not be read."},{status:312,message:"The stdout output file was incomplete."},{status:313,message:"The stdout contains multiple calculations"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception."}]},class:"aiida_nwchem.calculations.nwchem:NwchemBaseCalculation"},"nwchem.nwchem":{description:["Base calculation class for NWChem.","","    Synthesizes NWChem input file from parameter dictionary and StructureData."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure, with or without a cell"},{name:"add_cell",required:!1,valid_types:"Bool",info:"The input structure, with or without a cell"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"restart_folder",required:!1,valid_types:"RemoteData, FolderData, NoneType",info:"Remote directory of a completed NWChem calculation to restart from."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Required output files are missing."},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"The stdout output file could not be read."},{status:312,message:"The stdout output file was incomplete."},{status:313,message:"The stdout contains multiple calculations"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception."}]},class:"aiida_nwchem.calculations.nwchem:NwchemCalculation"}},"aiida.parsers":{"nwchem.nwchem":"aiida_nwchem.parsers.nwchem:NwchemBaseParser"},"aiida.workflows":{"nwchem.base":{description:["Workchain to run an NWChem calculation with automated error handling and restarts."],spec:{inputs:[{name:"nwchem",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The relaxed output structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_nwchem.workflows.base:NwchemBaseWorkChain"}}},commits_count:22,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-nwchem",is_installable:"True"},"aiida-open_circuit_voltage":{entry_point_prefix:"quantumespresso.ocv",code_home:"https://github.com/tsthakur/aiida-open_circuit_voltage",name:"aiida-open_circuit_voltage",package_name:"aiida_open_circuit_voltage",hosted_on:"github.com",metadata:{author:"Tushar Thakur",author_email:"tushar.thakur@epfl.ch",version:"0.1.0",description:"The AiiDA plugin to calculate ocv at various charge of states using QE",classifiers:["Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Development Status :: 3 - Alpha","Natural Language :: English","Intended Audience :: Science/Research"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.workflows":{"quantumespresso.ocv.ocvwc":"aiida_open_circuit_voltage.workflows.workchain:OCVWorkChain"}},commits_count:26,development_status:"alpha",warnings:["Prefix 'quantumespresso.ocv' does not follow naming convention."],summaryinfo:[{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"See source code repository."},"aiida-optimize":{code_home:"https://github.com/greschd/aiida-optimize",documentation_url:"https://aiida-optimize.readthedocs.io",entry_point_prefix:"optimize",pip_url:"aiida-optimize",plugin_info:"https://raw.githubusercontent.com/greschd/aiida-optimize/master/setup.json",name:"aiida-optimize",package_name:"aiida_optimize",hosted_on:"github.com",metadata:{release_date:"2023-03-30",description:"AiiDA Plugin for running optimization algorithms.",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-optimize.readthedocs.io/",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"1.0.2"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.workflows":{"optimize.optimize":{description:["Runs an optimization procedure, given an optimization engine that defines the optimization","    algorithm, and a process which evaluates the function to be optimized."],spec:{inputs:[{name:"engine",required:!0,valid_types:"Str",info:"Engine that runs the optimization."},{name:"engine_kwargs",required:!0,valid_types:"Dict",info:"Keyword arguments passed to the optimization engine."},{name:"evaluate_process",required:!0,valid_types:"Str",info:"Process which produces the result to be optimized."},{name:"evaluate",required:!1,valid_types:"",info:"Inputs that are passed to all evaluation processes."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"optimal_process_output",required:!0,valid_types:"",info:"Output value of the optimal evaluation process."},{name:"optimal_process_uuid",required:!0,valid_types:"",info:"UUID of the optimal evaluation process."},{name:"engine_outputs",required:!1,valid_types:"",info:""},{name:"optimal_process_input",required:!1,valid_types:"",info:"Input value of the optimal evaluation process."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Optimization failed because one of the evaluate processes did not finish ok."},{status:202,message:"Optimization failed because the engine did not finish ok."}]},class:"aiida_optimize._optimization_workchain:OptimizationWorkChain"},"optimize.wrappers.add_inputs":{description:["Wrapper workchain that takes inputs as keys and values and passes it","    on to a sub-process. This enables taking a process which was not","    designed to be used in optimization, and optimize with respect to","    some arbitrary input. Inputs which always remain the same can be","    specified in the ``inputs`` namespace, whereas the inputs to be","    optimized are given through the ``added_input_keys`` and","    ``added_input_values`` inputs.","","    The outputs of the wrapper workchain are the same as those of","    the wrapped process.","",'    The "added" inputs can only be BaseType sub-classes, or',"    attributes of a Dict. For each input, its port location is given",'    in the "added_input_keys" input. For example, ``x.y`` would set',"    the ``y`` input in the ``x`` namespace.","","    For cases where the input is a Dict attribute, the (possibly nested) attribute name is given after a colon. That means ``x:a.b`` would","    set the ``['a']['b']`` attribute of the ``Dict`` given in the ``x``","    input.","","    In cases where only a single input needs to be added, they can be","    specified directly instead of wrapped in a List."],spec:{inputs:[{name:"added_input_keys",required:!0,valid_types:"List, Str",info:"Specifies the location of each added input."},{name:"added_input_values",required:!0,valid_types:"List, BaseType",info:"Values of the added inputs to be passed into the sub-process."},{name:"sub_process",required:!0,valid_types:"Str",info:"The class of the process that should be wrapped."},{name:"inputs",required:!1,valid_types:"",info:"Inputs to be passed on to the sub-process."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Workchain failed because the sub-process did not finish ok."}]},class:"aiida_optimize.wrappers._add_inputs:AddInputsWorkChain"},"optimize.wrappers.concatenate":{description:["Allows concatenating an arbitrary number of sub-processes.","","    A wrapper workchain that allows concatenating an arbitrary number","    of sub-processes. Outputs of one processes can be configured to","    be passed to the next one."],spec:{inputs:[{name:"output_input_mappings",required:!0,valid_types:"List",info:"Defines how inputs are passed between sub-processes. Each list entry entry has the form `((process_label_a, process_label_b), mapping)`, and defines outputs of process A to be passed to process B. The `mapping` values are dictionaries `{'output_name': 'input_name'}` giving the output name (in process A) and input name (in process B) for each value to pass."},{name:"process_inputs",required:!0,valid_types:"",info:"Inputs which are passed on to the sub-processes. The inputs should be grouped into a namespace identified by the process label."},{name:"process_labels",required:!0,valid_types:"List",info:"A list of pairs (label, process_name). The labels can be any string, the process_name needs to be loadable by `aiida_optimize.process_inputs.load_object`, and defines which process is being run."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"process_outputs",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:200,message:"Workchain failed because a sub-process failed."}]},class:"aiida_optimize.wrappers._concatenate:ConcatenateWorkChain"},"optimize.wrappers.create_evaluate":{description:["Wrapper workchain to combine two processes: The first process _creates_","    a result, and the second _evaluates_ that result.","","    The purpose of this workchain is to facilitate optimization of processes","    which don't natively produce an output that can be optimized, by only","    having to add the 'evaluation' part."],spec:{inputs:[{name:"create",required:!0,valid_types:"",info:"Inputs which are passed on to the create sub-process."},{name:"create_process",required:!0,valid_types:"Str",info:"The sub-process which performs the create step."},{name:"evaluate_process",required:!0,valid_types:"Str",info:"The sub-process which performs the evaluate step."},{name:"output_input_mapping",required:!0,valid_types:"Dict",info:"A mapping from output names of the create process to input names of the evaluate process. These outputs (if present) are forwarded to the evaluate process."},{name:"evaluate",required:!1,valid_types:"",info:"Inputs which are passed on to the evaluate sub-process."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"create",required:!0,valid_types:"",info:""},{name:"evaluate",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Workchain failed because the 'create' sub-process failed."},{status:202,message:"Workchain failed because the 'evaluate' sub-process failed."}]},class:"aiida_optimize.wrappers._create_evaluate:CreateEvaluateWorkChain"}}},commits_count:2,development_status:"stable",summaryinfo:[{colorclass:"green",text:"Workflows",count:4}],pip_install_cmd:"pip install aiida-optimize",is_installable:"True"},"aiida-orca":{code_home:"https://github.com/pzarabadip/aiida-orca",development_status:"stable",documentation_url:"https://aiida-orca.readthedocs.io/",entry_point_prefix:"orca",pip_url:"git+https://github.com/pzarabadip/aiida-orca",name:"aiida-orca",package_name:"aiida_orca",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"0.5.1",description:"AiiDA plugin for ORCA code",classifiers:["Environment :: Plugins","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Framework :: AiiDA"]},aiida_version:">=1.0.0,<2.0.0",entry_points:{"aiida.calculations":{orca_main:"aiida_orca.calculations:OrcaCalculation",orca_asa:"aiida_orca.calculations:OrcaAsaCalculation"},"aiida.parsers":{orca_base_parser:"aiida_orca.parsers:OrcaBaseParser"},"aiida.workflows":{"orca.base":{description:["Workchain to run a orca calculation with automated error handling and restarts."],spec:{inputs:[{name:"orca",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"the results of the calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"relaxed_structure",required:!1,valid_types:"StructureData",info:"relaxed structure"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:301,message:"The calculation failed with an unrecoverable error coming from aiida-orca."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_orca.workchains:OrcaBaseWorkChain"}}},commits_count:40,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-orca",is_installable:"True"},"aiida-phonopy":{code_home:"https://github.com/aiida-phonopy/aiida-phonopy",documentation_url:"https://aiida-phonopy.readthedocs.io/",entry_point_prefix:"phonopy",pip_url:"aiida-phonopy",plugin_info:"https://raw.githubusercontent.com/aiida-phonopy/aiida-phonopy/master/setup.json",name:"aiida-phonopy",package_name:"aiida_phonopy",hosted_on:"github.com",metadata:{release_date:"2023-05-24",description:"The official AiiDA plugin for Phonopy",author_email:"Lorenzo Bastonero <bastonero.lorenzo@gmail.com>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"1.1.3"},aiida_version:">=2.0.0,<3.0.0",entry_points:{"aiida.calculations":{"phonopy.phonopy":{description:["Base `CalcJob` implementation for Phonopy post-processing."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:`Phonopy parameters (\`setting tags\`) for post processing. The following tags, along their type, are allowed:
PRIMITIVE_AXES
PRIMITIVE_AXIS
EIGENVECTORS
BAND
BAND_PATHS
BAND_POINTS
BAND_LABELS
BAND_CONNECTION
BAND_INDICES
MESH
MP
MESH_NUMBERS
MP_SHIFT
GAMMA_CENTER
WRITE_MESH
DOS
DOS_RANGE
FMIN
FMAX
FPITCH
PDOS
PROJECTION_DIRECTION
XYZ_DIRECTION
SIGMA
DEBYE_MODEL
MOMEMT
MOMENT_ORDER
TPROP
TMIN
TMAX
TSTEP
PRETEND_REAL
CUTOFF_FREQUENCY
TDISP
TDISPMAT
TDISPMAT_CIF
QPOINTS
WRITEDM
NAC_METHOD
Q_DIRECTION
GROUP_VELOCITY
GV_DELTA_Q
SYMMETRY_TOLERANCE
SYMMETRY
MESH_SYMMETRY
FC_SYMMETRY
FULL_FORCE_CONSTANTS
WRITE_FORCE_CONSTANTS
ANIME_TYPE
ANIME
MODULATION
IRREPS
SHOW_IRREPS
LITTLE_COGROUP`},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"force_constants",required:!1,valid_types:"ForceConstantsData, NoneType",info:"Force constants of the input structure."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"phonopy_data",required:!1,valid_types:"PhonopyData, NoneType",info:"The preprocess output info of a previous ForceConstantsWorkChain."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Settings for phonopy calculation."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"irreducible_representations",required:!1,valid_types:"Dict",info:"Irreducible representation output."},{name:"modulation",required:!1,valid_types:"Dict",info:"Modulation information."},{name:"output_force_constants",required:!1,valid_types:"ArrayData",info:"Calculated force constants."},{name:"output_parameters",required:!1,valid_types:"Dict",info:"Sum up info of phonopy calculation."},{name:"phonon_bands",required:!1,valid_types:"BandsData",info:"Calculated phonon band structure."},{name:"projected_phonon_dos",required:!1,valid_types:"XyData",info:"Calculated projected DOS."},{name:"qpoints",required:!1,valid_types:"BandsData",info:"Calculated qpoints."},{name:"qpoints_mesh",required:!1,valid_types:"BandsData",info:"Calculated qpoint mesh."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"thermal_displacement_matrices",required:!1,valid_types:"Dict",info:"Calculated thermal displacements matrices."},{name:"thermal_displacements",required:!1,valid_types:"Dict",info:"Calculated thermal displacements."},{name:"thermal_properties",required:!1,valid_types:"XyData",info:"Calculated thermal properties."},{name:"total_phonon_dos",required:!1,valid_types:"XyData",info:"Calculated total DOS."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required phonopy file."},{status:304,message:"The retrieved folder did not contain one or more expected output files."},{status:305,message:"No run mode has been selected."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The loading of yaml file got an unexpected error."},{status:321,message:"The file loading via numpy got an unexpected error."},{status:350,message:"The parser raised an unexpected exception."},{status:400,message:"The parser was not able to parse one or more files."}]},class:"aiida_phonopy.calculations.phonopy:PhonopyCalculation"}},"aiida.data":{"phonopy.force_constants":"aiida_phonopy.data.force_constants:ForceConstantsData","phonopy.phonopy":"aiida_phonopy.data.phonopy:PhonopyData","phonopy.preprocess":"aiida_phonopy.data.preprocess:PreProcessData","phonopy.raw":"aiida_phonopy.data.raw:RawData"},"aiida.parsers":{"phonopy.phonopy":"aiida_phonopy.parsers.phonopy:PhonopyParser"},"aiida.workflows":{"phonopy.phonopy":{description:["Abstract workflow for automated frozen phonons.","","    Phonopy is used to produce structures with displacements,","    while the forces are calculated with a quantum engine of choice.","","    This workchain is meant to be used as a base for other specific force calculato plugin workchains,","    or as an example on how to set a possible workchain/workflow. For this reason, the outline of","    this class is not defined, while it provides the inputs and a `setup` method, which can be used","    in a specific workflow outline. Ideally, the workflow would look like:","","    1. Setup the preprocess data.","","        This is already provided in this class. It setups a `PreProcessData` node, from where","        supercell, primitive cell and supercells with displacements can be easily extracted using","        the methods of the nodes. This node can be taken from `self.ctx.preprocess_data`, and used","        during the outline of the workflow.","","    2. Run supercells using the selected quantum engine/force calculator code.","","        In specific code implementations, a force calculation on supercells needs to be run.","        To get these supercells, one need simply to run:","","        ```self.ctx.preprocess_data.calcfunctions.get_supercells_with_displacements()```","","        This will return a dictionary with all the supercells as StructureData to run for the phonon calculation.","        The keys of this dictionary are of the type `supercell_{number}`, where `number` is an integer.","        These numbers are essentials since the `phonopy` force sets is generated following these numbers,","        in order to make sure to refer to the correct displacement. Thus, it is required to keep track","        of them.","        Moreover,a calculation over the pristine supercell structure should be run before hand as reference.","        This structure can instead be gotten via:","","        ```self.ctx.preprocess_data.calcfunctions.get_supercell()```","","        This will return a StructureData without any label.","","        For an example of implementation, refer to aiidateam/aiida-common-worfklows.","","        * Note: some type of force calculation needs to map some variables from the unitcell to the supercell","        (and in certain case even the primitive cell), e.g. the atomic spin in VASP. Since this is code dependent,","        you will need to map these parameters before launching the force calculation of a certain supercell","        with displacement. This information can be gotten via:","","        ```self.ctx.preprocess_data.get_cells_mappings()```","","        Moreover, consider that cells in phonopy will always (re)fold the atoms in order to have positive coordinates.","","    3. Inspect all runs and expose the forces and energies (not mandatory) outputs.","","        * Suggested: when the calculation on each supercell has finished (correctly)","        expose the output forces (and energies) in the dynamical `supercells_forces(energies)` namespace(s).","        Provide each supercell forces as an `ArrayData` with the forces stored as `forces`","        (e.g. if your code plugin stores  the forces in `TrajectoryData`, extract them with a `calcfunction`).","        Expose each `ArrayData` choosing a **common prefix**, while as **suffix use","        _{number}**, with `{number}` referring to the correspective supercell label suffix (that you are supposed to","        keep track somewhere, e.g. in the label of the code calculation/workchain).","        Now you can gather all the information in one data noe, i.e. in a `PhonopyData` node.","        To do so, you can simple run:","","        ```self.ctx.preprocess_data.calcfunctions.generate_phonopy_data(**self.outputs.supercells_forces)```","","        and then expose it as output in the `output_phonopy_data` namespace.","","        * Alternatively: instead of exposing the supercell forces as outputs, you can directly gather all the forces","        in a dictionary and run directly to the `generate_phonopy_data` method using this dictionary (always using","        the double *).","","        See the implementation in aiidateam/aiida-common-workflows for an example.","","    4. (optional) Run the non-analytical constants on the primitive cell.","","        Non-analytical constants should be run for polar insulators. These require usually a linear response code","        or a finite difference approach (e.g. using the electric enthalpy). Since this is usually the most expensive","        part, you should run them on the primitive cell. To get it, use:","","        ```self.ctx.preprocess_data.calcfunctions.get_primitive_cell()```","","        If you compute also these, collect the dielectric tensor and the effectic born charges in an ArrayData,","        with the arraynames `dielectric` and `born_charges` (in Cartesian coordinates!).","        Then, gather all the information of nac and forces in a unique `PhonopyData` via:","","        ```","        self.ctx.preprocess_data.calcfunctions.generate_phonopy_data(","            nac_parameters=nac_paramters,","            **self.outputs.supercells_forces","            )","        ```","","        and expose the output.","","        * Note: we require in the input for generating the full phonopy data, to give the nac in the primitive cell.","        The primitive cell of phonopy will just rotate the lattice vectors, thus mantaining the Cartasian coordinate","        system. It can happen, though, that the unitcell is not the primitive cell of the system, meaning that the","        primitive cell will contain less atoms. We expect in input the nac computed on this number of atoms. If you","        want, for some reason, compute the nac on the unitcell, you will need to get the reduced nac.","        To do so, you can consider using a built-in function in phonopy, namely:","","        :py:func:`phonopy.structure.symmetry.elaborate_borns_and_epsilon`"],spec:{inputs:[{name:"options",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"displacement_generator",required:!1,valid_types:"Dict, NoneType",info:`Info for displacements generation. The following flags are allowed:
 distance
 is_plusminus
 is_diagonal
 is_trigonal
 number_of_snapshots
 random_seed
 temperature
 cutoff_frequency`},{name:"fc_options",required:!1,valid_types:"Dict, NoneType",info:`Options for force constants calculation (optional). The following flags are allowed:
 calculate_full_force_constants
 fc_calculator
 fc_calculator_options`},{name:"is_symmetry",required:!1,valid_types:"Bool, NoneType",info:"Whether using or not the space group symmetries."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"nac_parameters",required:!1,valid_types:"ArrayData, NoneType",info:"Non-analytical parameters."},{name:"preprocess_data",required:!1,valid_types:"PhonopyData, PreProcessData, NoneType",info:"The preprocess data for frozen phonon calcualtion."},{name:"primitive_matrix",required:!1,valid_types:"List, NoneType",info:"The matrix used to generate the primitive cell from the input structure in the List format. Allowed shapes are 3x1 and 3x3 lists."},{name:"structure",required:!1,valid_types:"StructureData, NoneType",info:"The structure at equilibrium volume."},{name:"supercell_matrix",required:!1,valid_types:"List, NoneType",info:"The matrix used to generate the supercell from the input structure in the List format. Allowed shapes are 3x1 and 3x3 lists."},{name:"symmetry_tolerance",required:!1,valid_types:"Float, NoneType",info:"Symmetry tolerance for space group analysis on the input structure."}],outputs:[{name:"output_phonopy_data",required:!0,valid_types:"PhonopyData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"supercells_forces",required:!0,valid_types:"ArrayData",info:"The forces acting on the atoms of each supercell."},{name:"output_force_constants",required:!1,valid_types:"ForceConstantsData",info:"The matrix of force constants computed with finite displacements."},{name:"supercells",required:!1,valid_types:"StructureData",info:"The supercells with displacements."},{name:"supercells_energies",required:!1,valid_types:"Float",info:"The total energy of each supercell."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_phonopy.workflows.phonopy:PhonopyWorkChain"}}},commits_count:64,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:4},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-phonopy",is_installable:"True"},"aiida-phtools":{code_home:"https://github.com/ltalirz/aiida-phtools",entry_point_prefix:"phtools",pip_url:"aiida-phtools",plugin_info:"https://raw.github.com/ltalirz/aiida-phtools/master/setup.json",name:"aiida-phtools",package_name:"aiida_phtools",hosted_on:"github.com",metadata:{release_date:"2018-06-21",description:"AiiDA plugin for persistence homology tools, used to analyze nanoporous materials.",author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-phtools",classifiers:["Programming Language :: Python"],version:"0.1.0a1"},aiida_version:"*",entry_points:{"aiida.calculations":{"phtools.dmatrix":"aiida_phtools.calculations.distance_matrix:DistanceMatrixCalculation","phtools.surface":"aiida_phtools.calculations.pore_surface:PoreSurfaceCalculation"},"aiida.data":{"phtools.surface":"aiida_phtools.data.pore_surface:PoreSurfaceParameters"},"aiida.parsers":{"phtools.dmatrix":"aiida_phtools.parsers.distance_matrix:DistanceMatrixParser","phtools.surface":"aiida_phtools.parsers.pore_surface:PoreSurfaceParser"}},commits_count:0,development_status:"planning",warnings:["Missing classifier 'Framework :: AiiDA'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install --pre aiida-phtools"},"aiida-plumed":{code_home:"https://github.com/ConradJohnston/aiida-plumed",entry_point_prefix:"plumed",pip_url:"aiida-plumed",plugin_info:"https://raw.github.com/ConradJohnston/aiida-plumed/AiiDA-v1.0-compatibility/setup.json",name:"aiida-plumed",package_name:"aiida_plumed",hosted_on:"github.com",metadata:{release_date:"2019-09-16",description:"AiiDA plugin providing support for Plumed2",author:"Conrad Johnston",author_email:"conrad.s.johnston@googlemail.com",license:"MIT",home_page:"https://github.com/ConradJohnston/aiida-plumed",classifiers:["Development Status :: 2 - Pre-Alpha","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0a0"},aiida_version:">=1.0.0b3,<2.0.0",entry_points:{"aiida.calculations":{plumed:"aiida_plumed.calculations:DiffCalculation"},"aiida.cmdline.data":{plumed:"aiida_plumed.cli:data_cli"},"aiida.data":{plumed:"aiida_plumed.data:DiffParameters"},"aiida.parsers":{plumed:"aiida_plumed.parsers:DiffParser"}},commits_count:0,development_status:"pre-alpha",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"orange",text:"Other (Data commands)",count:1}],pip_install_cmd:"pip install --pre aiida-plumed",is_installable:"True"},"aiida-porousmaterials":{code_home:"https://github.com/pzarabadip/aiida-porousmaterials",development_status:"stable",entry_point_prefix:"porousmaterials",pip_url:"aiida-porousmaterials",name:"aiida-porousmaterials",package_name:"aiida_porousmaterials",hosted_on:"github.com",metadata:{release_date:"2020-03-05",description:"AiiDA plugin for PorousMaterials code",author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",license:"MIT",home_page:"https://github.com/pzarabadip/aiida-porousmaterials",classifiers:["Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8"],version:"1.0.0a3"},aiida_version:null,entry_points:{"aiida.calculations":{porousmaterials:{description:["This is PorousMaterialsCalculation as the subclass","    of AiiDA CalcJob to prepare input for the PorousMaterials","    suite of Julia codes.","    Please refer to : https://github.com/SimonEnsemble/PorousMaterials.jl"],spec:{inputs:[{name:"acc_voronoi_nodes",required:!0,valid_types:"SinglefileData",info:"Accessible Voronoi nodes calculated by Zeo++"},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"Dict",info:"parameters such as cutoff and mixing rules."},{name:"structure",required:!0,valid_types:"CifData",info:"Framework input file as CIF"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"settings",required:!1,valid_types:"Dict",info:"Additional input parameters"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"dictionary of calculated Voronoi energies"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"ev_output_file",required:!1,valid_types:"SinglefileData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"The retrieved folder does not contain an output file."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_porousmaterials.calculations:PorousMaterialsCalculation"}},"aiida.parsers":{porousmaterials:"aiida_porousmaterials.parser:PorousMaterialsParser"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install --pre aiida-porousmaterials",is_installable:"True"},"aiida-pseudo":{code_home:"https://github.com/aiidateam/aiida-pseudo",entry_point_prefix:"pseudo",pip_url:"aiida-pseudo",plugin_info:"https://raw.github.com/aiidateam/aiida-pseudo/master/setup.cfg",name:"aiida-pseudo",package_name:"aiida_pseudo",hosted_on:"github.com",metadata:{release_date:"2023-08-23",description:"AiiDA plugin that simplifies working with pseudo potentials.",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>',classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.2.0"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.data":{pseudo:"aiida_pseudo.data.pseudo.pseudo:PseudoPotentialData","pseudo.jthxml":"aiida_pseudo.data.pseudo.jthxml:JthXmlData","pseudo.psf":"aiida_pseudo.data.pseudo.psf:PsfData","pseudo.psml":"aiida_pseudo.data.pseudo.psml:PsmlData","pseudo.psp8":"aiida_pseudo.data.pseudo.psp8:Psp8Data","pseudo.upf":"aiida_pseudo.data.pseudo.upf:UpfData","pseudo.vps":"aiida_pseudo.data.pseudo.vps:VpsData"},"aiida.groups":{"pseudo.family":"aiida_pseudo.groups.family.pseudo:PseudoPotentialFamily","pseudo.family.cutoffs":"aiida_pseudo.groups.family.cutoffs:CutoffsPseudoPotentialFamily","pseudo.family.pseudo_dojo":"aiida_pseudo.groups.family.pseudo_dojo:PseudoDojoFamily","pseudo.family.sssp":"aiida_pseudo.groups.family.sssp:SsspFamily"},console_scripts:{"aiida-pseudo":"aiida_pseudo.cli:cmd_root"}},commits_count:27,development_status:"stable",summaryinfo:[{colorclass:"red",text:"Data",count:7},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Groups)",count:4}],pip_install_cmd:"pip install aiida-pseudo",is_installable:"True"},"aiida-psi4":{code_home:"https://github.com/ltalirz/aiida-psi4/tree/master",development_status:"beta",entry_point_prefix:"psi4",pip_url:"git+https://github.com/ltalirz/aiida-psi4",name:"aiida-psi4",package_name:"aiida_psi4",hosted_on:"github.com",metadata:{author:"Leopold Talirz",author_email:"leopold.talirz@gmail.com",version:"0.1.0a0",description:"AiiDA plugin for the Psi4 Quantum Chemistry package.",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.6.4,<2.0.0",entry_points:{"aiida.data":{"psi4.atomic_input":"aiida_psi4.data:AtomicInput"},"aiida.calculations":{psi4:{description:["AiiDA calculation plugin wrapping the psi4 executable."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"psiapi",required:!1,valid_types:"Str, SinglefileData",info:"Psi4 input in PsiAPI python format"},{name:"qcschema",required:!1,valid_types:"Dict, AtomicInput",info:"Psi4 input in QCSchema JSON format"}],outputs:[{name:"qcschema",required:!0,valid_types:"Dict",info:"Psi4 output in QCSchema JSON format"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"stdout",required:!0,valid_types:"SinglefileData",info:"Psi4 logfile"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:100,message:"Calculation did not produce all expected output files."},{status:101,message:"Psi4 reported calculation as unsuccessful."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_psi4.calculations:Psi4Calculation"}},"aiida.parsers":{psi4:"aiida_psi4.parsers:QCSchemaParser"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install git+https://github.com/ltalirz/aiida-psi4",is_installable:"True"},"aiida-pyscf":{code_home:"https://github.com/microsoft/aiida-pyscf",entry_point_prefix:"pyscf",pip_url:"aiida-pyscf",plugin_info:"https://raw.githubusercontent.com/microsoft/aiida-pyscf/main/pyproject.toml",name:"aiida-pyscf",package_name:"aiida_pyscf",hosted_on:"github.com",metadata:{release_date:"2023-08-16",description:"AiiDA plugin for the Python-based Simulations of Chemistry Framework (PySCF).",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>, Adam Grofe <v-adamgrofe@microsoft.com>',classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"0.4.1"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"pyscf.base":{description:["``CalcJob`` plugin for PySCF."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"structure",required:!0,valid_types:"StructureData",info:"Input structure with molecular structure definition."},{name:"checkpoint",required:!1,valid_types:"SinglefileData, NoneType",info:"Checkpoint of a previously completed calculation that failed to converge."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Input parameters used to render the PySCF script template."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"cubegen",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"checkpoint",required:!1,valid_types:"SinglefileData",info:"The checkpoint file in case the calculation did not converge. Can be used as an input for a restart."},{name:"fcidump",required:!1,valid_types:"SinglefileData",info:"Computed fcidump files."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The computed Hessian."},{name:"model",required:!1,valid_types:"PickledData",info:"The model in serialized form. Can be deserialized and used without having to run the kernel again."},{name:"parameters",required:!1,valid_types:"Dict",info:"Various computed properties parsed from the `FILENAME_RESULTS` output file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"The optimized structure if the input parameters contained the `optimizer` key."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The geometry optimization trajectory if the input parameters contained the `optimizer` key."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The stdout output file was not retrieved."},{status:303,message:"The results JSON file was not retrieved."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."}]},class:"aiida_pyscf.calculations.base:PyscfCalculation"}},"aiida.parsers":{"pyscf.base":"aiida_pyscf.parsers.base:PyscfParser"},"aiida.workflows":{"pyscf.base":{description:["Workchain to run a pyscf calculation with automated error handling and restarts."],spec:{inputs:[{name:"pyscf",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"cubegen",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"checkpoint",required:!1,valid_types:"SinglefileData",info:"The checkpoint file in case the calculation did not converge. Can be used as an input for a restart."},{name:"fcidump",required:!1,valid_types:"SinglefileData",info:"Computed fcidump files."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The computed Hessian."},{name:"model",required:!1,valid_types:"PickledData",info:"The model in serialized form. Can be deserialized and used without having to run the kernel again."},{name:"parameters",required:!1,valid_types:"Dict",info:"Various computed properties parsed from the `FILENAME_RESULTS` output file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"structure",required:!1,valid_types:"StructureData",info:"The optimized structure if the input parameters contained the `optimizer` key."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The geometry optimization trajectory if the input parameters contained the `optimizer` key."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed and did not retrieve a checkpoint file from which can be restarted."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_pyscf.workflows.base:PyscfBaseWorkChain"}}},commits_count:67,development_status:"alpha",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-pyscf",is_installable:"True"},"aiida-python":{entry_point_prefix:"aiidapython",code_home:"https://github.com/addman2/aiida-python",name:"aiida-python",package_name:"aiida_python",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:44,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found","Prefix 'aiidapython' does not follow naming convention."],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-qeq":{code_home:"https://github.com/ltalirz/aiida-qeq",development_status:"stable",entry_point_prefix:"qeq",pip_url:"aiida-qeq",plugin_info:"https://raw.githubusercontent.com/ltalirz/aiida-qeq/master/setup.json",name:"aiida-qeq",package_name:"aiida_qeq",hosted_on:"github.com",metadata:{release_date:"2018-11-21",description:"AiiDA plugin for computing electronic charges on atoms using equilibration-type models (QEq, EQEq, ...).",author:"Leopold Talirz, Daniele Ongari",author_email:"leopold.talirz@gmail.com",license:"MIT",home_page:"https://github.com/ltalirz/aiida-qeq",classifiers:["Programming Language :: Python"],version:"0.1.0"},aiida_version:">=0.12.2,<1.0.0",entry_points:{"aiida.calculations":{"qeq.eqeq":{description:["AiiDA calculation plugin for the EQeq code."],spec:{inputs:[{name:"charge_data",required:!0,valid_types:"SinglefileData",info:"File containing information on common oxidation state of the elements."},{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"ionization_data",required:!0,valid_types:"SinglefileData",info:"File containing ionization data on the elements."},{name:"parameters",required:!0,valid_types:"EQeqParameters",info:"Command line parameters for EQEQ"},{name:"structure",required:!0,valid_types:"CifData",info:"Input structure, for which atomic charges are to be computed."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_qeq.calculations.eqeq:EQeqCalculation"},"qeq.qeq":{description:["AiiDA calculation plugin for the Qeq code."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"parameters",required:!0,valid_types:"SinglefileData",info:"File containing electronegativity and Idempotential data of the elements."},{name:"structure",required:!0,valid_types:"CifData",info:"Input structure, for which atomic charges are to be computed."},{name:"configure",required:!1,valid_types:"QeqParameters",info:"Configuration input for QEQ (configure.input file)"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_qeq.calculations.qeq:QeqCalculation"}},"aiida.data":{"qeq.eqeq":"aiida_qeq.data.eqeq:EQeqParameters","qeq.qeq":"aiida_qeq.data.qeq:QeqParameters"},"aiida.parsers":{"qeq.eqeq":"aiida_qeq.parsers.eqeq:EQeqParser","qeq.qeq":"aiida_qeq.parsers.qeq:QeqParser"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"red",text:"Data",count:2}],pip_install_cmd:"pip install aiida-qeq",is_installable:"True"},"aiida-qp2":{code_home:"https://github.com/TREX-CoE/aiida-qp2",entry_point_prefix:"qp2",pip_url:"aiida-qp2",documentation_url:"https://trex-coe.github.io/aiida-qp2/index.html",name:"aiida-qp2",package_name:"aiida_qp2",hosted_on:"github.com",metadata:{release_date:"2022-02-26",description:"AiiDA plugin for the Quantum Package 2.0",author:"Evgeny Posenitskiy",author_email:"posenitskiy@irsamc.ups-tlse.fr",license:"MIT",home_page:"https://github.com/TREX-CoE/aiida-qp2",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.calculations":{qp2:{description:["AiiDA calculation plugin wrapping the Quantum Package code."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters to generate the input file."},{name:"basissets",required:!1,valid_types:"",info:"A dictionary of basissets to be used in the calculations: key is the atomic symbol, value is either a single basisset."},{name:"code",required:!1,valid_types:"Code",info:"The `Code` to use for this job."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pseudos",required:!1,valid_types:"",info:"A dictionary of pseudopotentials to be used in the calculations: key is the atomic symbol, value is a single pseudopotential."},{name:"settings",required:!1,valid_types:"Dict",info:"Additional input parameters."},{name:"structure",required:!1,valid_types:"StructureData",info:"Input structrure"},{name:"wavefunction",required:!1,valid_types:"SinglefileData",info:"The wavefunction file (EZFIO or TREXIO)."}],outputs:[{name:"output_wavefunction",required:!0,valid_types:"SinglefileData",info:"The wave function file (EZFIO or TREXIO)"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_energy",required:!1,valid_types:"Float",info:"The result of the calculation"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"Calculation did not produce all expected output files."},{status:400,message:"Energy value is not present in the output file."}]},class:"aiida_qp2.calculations:QP2Calculation"}},"aiida.parsers":{qp2:"aiida_qp2.parsers:QP2Parser"}},commits_count:0,development_status:"beta",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-qp2",is_installable:"True"},"aiida-quantumespresso":{code_home:"https://github.com/aiidateam/aiida-quantumespresso",documentation_url:"https://aiida-quantumespresso.readthedocs.io/",entry_point_prefix:"quantumespresso",pip_url:"aiida-quantumespresso",plugin_info:"https://raw.github.com/aiidateam/aiida-quantumespresso/master/setup.json",name:"aiida-quantumespresso",package_name:"aiida_quantumespresso",hosted_on:"github.com",metadata:{release_date:"2023-07-24",description:"The official AiiDA plugin for Quantum ESPRESSO",author_email:"The AiiDA team <developers@aiida.net>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"4.4.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"quantumespresso.cp":{description:["`CalcJob` implementation for the cp.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_trajectory",required:!0,valid_types:"TrajectoryData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The required XML file is not present in the retrieved folder."},{status:304,message:"The retrieved folder contains multiple XML files."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The required XML file could not be read."},{status:330,message:"The required POS file could not be read."},{status:340,message:"The required trajectory data could not be read."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."}]},class:"aiida_quantumespresso.calculations.cp:CpCalculation"},"quantumespresso.create_kpoints_from_distance":{description:["Generate a uniformly spaced kpoint mesh for a given structure.","","    The spacing between kpoints in reciprocal space is guaranteed to be at least the defined distance.","","    :param structure: the StructureData to which the mesh should apply","    :param distance: a Float with the desired distance between kpoints in reciprocal space","    :param force_parity: a Bool to specify whether the generated mesh should maintain parity","    :returns: a KpointsData with the generated mesh"],spec:{inputs:[{name:"distance",required:!0,valid_types:"Data",info:"a Float with the desired distance between kpoints in reciprocal space"},{name:"force_parity",required:!0,valid_types:"Data",info:"a Bool to specify whether the generated mesh should maintain parity"},{name:"structure",required:!0,valid_types:"Data",info:"the StructureData to which the mesh should apply"},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.create_kpoints_from_distance:create_kpoints_from_distance"},"quantumespresso.create_magnetic_configuration":{description:["Create a new magnetic configuration from the given structure based on a list of magnetic moments per site.","","    To create the new list of kinds, the algorithm loops over all the elements in the structure and makes a list of the","    sites with that element and their corresponding magnetic moment. Next, it splits this list in three lists:","","    * Zero magnetic moments: Any site that has an absolute magnetic moment lower than ``ztol``","    * Positive magnetic moments","    * Negative magnetic moments","","    The algorithm then sorts the positive and negative lists from large to small absolute value, and loops over each of","    list. New magnetic kinds will be created when the absolute difference between the magnetic moment of the current","    kind and the site exceeds ``atol``.","","    The positive and negative magnetic moments are handled separately to avoid assigning two sites with opposite signs","    in their magnetic moment to the same kind and make sure that each kind has the correct magnetic moment, i.e. the","    largest magnetic moment in absolute value of the sites corresponding to that kind.","","    .. important:: the function currently does not support alloys.","","    :param structure: a `StructureData` instance.","    :param magnetic_moment_per_site: list of magnetic moments for each site in the structure.","    :param atol: the absolute tolerance on determining if two sites have the same magnetic moment.","    :param ztol: threshold for considering a kind to have non-zero magnetic moment."],spec:{inputs:[{name:"magnetic_moment_per_site",required:!0,valid_types:"Data",info:"list of magnetic moments for each site in the structure."},{name:"structure",required:!0,valid_types:"Data",info:"a `StructureData` instance."},{name:"atol",required:!1,valid_types:"Data",info:"the absolute tolerance on determining if two sites have the same magnetic moment."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"ztol",required:!1,valid_types:"Data",info:"threshold for considering a kind to have non-zero magnetic moment."}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.create_magnetic_configuration:create_magnetic_configuration"},"quantumespresso.dos":{description:["`CalcJob` implementation for the dos.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_dos",required:!0,valid_types:"XyData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The dos file could not be read from the retrieved folder."}]},class:"aiida_quantumespresso.calculations.dos:DosCalculation"},"quantumespresso.epw":{description:["`CalcJob` implementation for the epw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"kfpoints",required:!0,valid_types:"KpointsData",info:"fine kpoint mesh"},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"coarse kpoint mesh"},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"parent_folder_nscf",required:!0,valid_types:"RemoteData",info:"the folder of a completed nscf `PwCalculation`"},{name:"parent_folder_ph",required:!0,valid_types:"RemoteData",info:"the folder of a completed `PhCalculation`"},{name:"qfpoints",required:!0,valid_types:"KpointsData",info:"fine qpoint mesh"},{name:"qpoints",required:!0,valid_types:"KpointsData",info:"coarse qpoint mesh"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_quantumespresso.calculations.epw:EpwCalculation"},"quantumespresso.matdyn":{description:["`CalcJob` implementation for the matdyn.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"Kpoints on which to calculate the phonon frequencies."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"parent_folder",required:!1,valid_types:"RemoteData, FolderData, SinglefileData, NoneType",info:"Use a local or remote folder as parent folder (for restarts and similar)"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_phonon_bands",required:!0,valid_types:"BandsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The output frequencies file could not be read from the retrieved folder."},{status:410,message:"Number of kpoints not found in the output data"},{status:411,message:"Number of kpoints in the inputs is not commensurate with those in the output"}]},class:"aiida_quantumespresso.calculations.matdyn:MatdynCalculation"},"quantumespresso.merge_ph_outputs":{description:["Calcfunction to merge outputs from multiple `ph.x` calculations with different q-points."],spec:{inputs:[{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.merge_ph_outputs:merge_ph_outputs"},"quantumespresso.namelists":{description:["`CalcJob` implementation to serve as base class for simple post-processing tools of Quantum ESPRESSO."],spec:{inputs:[{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"parent_folder",required:!1,valid_types:"RemoteData, FolderData, SinglefileData, NoneType",info:"Use a local or remote folder as parent folder (for restarts and similar)"},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."}]},class:"aiida_quantumespresso.calculations.namelists:NamelistsCalculation"},"quantumespresso.neb":{description:["Nudged Elastic Band code (neb.x) of Quantum ESPRESSO distribution."],spec:{inputs:[{name:"first_structure",required:!0,valid_types:"StructureData",info:"Initial structure"},{name:"last_structure",required:!0,valid_types:"StructureData",info:"Final structure"},{name:"parameters",required:!0,valid_types:"Dict",info:"NEB-specific input parameters"},{name:"pw",required:!0,valid_types:"Data",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."}],outputs:[{name:"output_mep",required:!0,valid_types:"ArrayData",info:"The original and interpolated energy profiles along the minimum-energy path (mep)"},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The output parameters dictionary of the NEB calculation"},{name:"output_trajectory",required:!0,valid_types:"TrajectoryData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"iteration_array",required:!1,valid_types:"ArrayData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:303,message:"The required XML file is not present in the retrieved folder."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.neb:NebCalculation"},"quantumespresso.open_grid":{description:["``CalcJob`` implementation for the ``open_grid.x`` code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a completed `PwCalculation` on an irreducible Brillouin zone"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The explicit list of kpoints of the unfolded kmesh"},{name:"kpoints_mesh",required:!0,valid_types:"KpointsData",info:"The dimensions of the unfolded kmesh"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"The retrieved folder data node could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:312,message:"Found rotation or fractional translation not compatible with FFT grid."},{status:350,message:"Mismatch between kmesh dimensions and number of kpoints."}]},class:"aiida_quantumespresso.calculations.open_grid:OpenGridCalculation"},"quantumespresso.ph":{description:["`CalcJob` implementation for the ph.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"the folder of a completed `PwCalculation`"},{name:"qpoints",required:!0,valid_types:"KpointsData",info:"qpoint mesh"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The minimization cycle did not reach self-consistency."},{status:462,message:"The code failed during the cholesky factorization."}]},class:"aiida_quantumespresso.calculations.ph:PhCalculation"},"quantumespresso.pp":{description:["`CalcJob` implementation for the pp.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Use a node that specifies the input parameters for the namelists"},{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"Output folder of a completed `PwCalculation`"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job is performed."}],outputs:[{name:"output_data",required:!0,valid_types:"ArrayData",info:""},{name:"output_data_multiple",required:!0,valid_types:"ArrayData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The parent folder did not contain the required XML output file."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete."},{status:330,message:"The formatted data output file `{filename}` was not present in the retrieved (temporary) folder."},{status:331,message:"The formatted data output file `{filename}` could not be read."},{status:332,message:"The data file format is not supported by the parser"},{status:333,message:"The formatted data output file `{filename}` could not be parsed: {exception}"},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pp:PpCalculation"},"quantumespresso.projwfc":{description:["`CalcJob` implementation for the projwfc.x code of Quantum ESPRESSO.","","    Projwfc.x code of the Quantum ESPRESSO distribution, handles the the computation of projections of bloch","    wavefunctions onto atomic orbitals.","","    <Psi(n,k) | Y(theta,phi)R(r) >. For more information, refer to http://www.quantum-espresso.org/"],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a pw.x calculation"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"Dos",required:!0,valid_types:"XyData",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:""},{name:"bands_down",required:!1,valid_types:"BandsData",info:""},{name:"bands_up",required:!1,valid_types:"BandsData",info:""},{name:"projections",required:!1,valid_types:"ProjectionData",info:""},{name:"projections_down",required:!1,valid_types:"ProjectionData",info:""},{name:"projections_up",required:!1,valid_types:"ProjectionData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:330,message:"The pdos_tot file could not be read from the retrieved folder."},{status:340,message:"An exception was raised parsing bands and projections."}]},class:"aiida_quantumespresso.calculations.projwfc:ProjwfcCalculation"},"quantumespresso.pw":{description:["`CalcJob` implementation for the pw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"kpoint mesh or kpoint path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"hubbard_file",required:!1,valid_types:"SinglefileData, NoneType",info:"SinglefileData node containing the output Hubbard parameters from a HpCalculation"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
npool  : The number of 'pools', each taking care of a group of k-points.
nband  : The number of 'band groups', each taking care of a group of Kohn-Sham orbitals.
ntg    : The number of 'task groups' across which the FFT planes are distributed.
ndiag  : The number of 'linear algebra groups' used when parallelizing the subspace diagonalization / iterative orthonormalization. By default, no parameter is passed to Quantum ESPRESSO, meaning it will use its default.`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:304,message:"The retrieved folder contained multiple XML files."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:360,message:"The code failed in finding a valid reciprocal lattice vector."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:461,message:"The code failed with negative dexx in the exchange calculation."},{status:462,message:"The code failed during the cholesky factorization."},{status:463,message:"Too many bands failed to converge during the diagonalization."},{status:464,message:"The S matrix was found to be not positive definite."},{status:465,message:"The `zhegvd` failed in the PPCG diagonalization."},{status:466,message:"The `[Q, R] = qr(X, 0)` failed in the PPCG diagonalization."},{status:467,message:"The eigenvector failed to converge."},{status:468,message:"The factorization in the Broyden routine failed."},{status:481,message:'The k-point parallelization "npools" is too high, some nodes have no k-points.'},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:502,message:"The ionic minimization cycle did not converge after the maximum number of steps."},{status:503,message:"The ionic minimization cycle did not finish because the calculation was interrupted but a partial trajectory and output structure was successfully parsed which can be used for a restart."},{status:510,message:"The electronic minimization cycle failed during an ionic minimization cycle."},{status:511,message:"The ionic minimization cycle converged, but electronic convergence was not reached in the final SCF."},{status:520,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm."},{status:521,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm and electronic convergence failed in the final SCF."},{status:531,message:"The electronic minimization cycle did not reach self-consistency."},{status:541,message:"The variable cell optimization broke the symmetry of the k-points."},{status:542,message:"The cell relaxation caused a significant volume contraction and there is not enough space allocated for radial FFT."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.calculations.pw:PwCalculation"},"quantumespresso.pw2gw":{description:["`CalcJob` implementation for the pw2gw.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"Output folder of a completed `PwCalculation`"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"eps",required:!0,valid_types:"ArrayData",info:"The `eps` output node containing 5 arrays `energy`, `epsX`, `epsY`, `epsZ`, `epsTOT`"},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation.`"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:305,message:"The eps*.dat output files could not be read or parsed."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The eps*.dat output files do not have the expected shape (N, 2)."},{status:331,message:"The eps*.dat output files contains different values of energies."},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pw2gw:Pw2gwCalculation"},"quantumespresso.pw2wannier90":{description:["`CalcJob` implementation for the pw2wannier.x code of Quantum ESPRESSO.","","    For more information, refer to http://www.quantum-espresso.org/ and http://www.wannier.org/"],spec:{inputs:[{name:"nnkp_file",required:!0,valid_types:"SinglefileData",info:"A SinglefileData containing the .nnkp file generated by wannier90.x -pp"},{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:"The output folder of a pw.x calculation"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:340,message:"Encountered a generic error message"},{status:350,message:"The parser raised an unexpected exception: {exception}"}]},class:"aiida_quantumespresso.calculations.pw2wannier90:Pw2wannier90Calculation"},"quantumespresso.pwimmigrant":{description:["Create a PwCalculation object that can be used to import old jobs.","","    This is a sublass of aiida_quantumespresso.calculations.PwCalculation","    with slight modifications to some of the class variables and additional","    methods that","","        a. parse the job's input file to create the calculation's input","           nodes that would exist if the calculation were submitted using AiiDa,","        b. bypass the functions of the daemon, and prepare the node's attributes","           such that all the processes (copying of the files to the repository,","           results parsing, ect.) can be performed","","    .. note:: The keyword arguments of PwCalculation are also available.","","    :param remote_workdir: Absolute path to the directory where the job was run.","        The transport of the computer you link ask input to the calculation is","        the transport that will be used to retrieve the calculation's files.","        Therefore, ``remote_workdir`` should be the absolute path to the job's","        directory on that computer.","    :type remote_workdir: str","","    :param input_file_name: The file name of the job's input file.","    :type input_file_name: str","","    :param output_file_name: The file name of the job's output file (i.e. the","        file containing the stdout of QE).","    :type output_file_name: str"],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"kpoint mesh or kpoint path"},{name:"parameters",required:!0,valid_types:"Dict",info:"The input parameters that are to be used to construct the input file."},{name:"pseudos",required:!0,valid_types:"UpfData, UpfData",info:"A mapping of `UpfData` nodes onto the kind name to which they should apply."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"hubbard_file",required:!1,valid_types:"SinglefileData, NoneType",info:"SinglefileData node containing the output Hubbard parameters from a HpCalculation"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parallelization",required:!1,valid_types:"Dict, NoneType",info:`Parallelization options. The following flags are allowed:
npool  : The number of 'pools', each taking care of a group of k-points.
nband  : The number of 'band groups', each taking care of a group of Kohn-Sham orbitals.
ntg    : The number of 'task groups' across which the FFT planes are distributed.
ndiag  : The number of 'linear algebra groups' used when parallelizing the subspace diagonalization / iterative orthonormalization. By default, no parameter is passed to Quantum ESPRESSO, meaning it will use its default.`},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"An optional working directory of a previously completed calculation to restart from."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Optional parameters to affect the way the calculation job and the parsing are performed."},{name:"vdw_table",required:!1,valid_types:"SinglefileData, NoneType",info:"Optional van der Waals table contained in a `SinglefileData`."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:301,message:"The retrieved temporary folder could not be accessed."},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:303,message:"The retrieved folder did not contain the required XML file."},{status:304,message:"The retrieved folder contained multiple XML files."},{status:305,message:"Both the stdout and XML output files could not be read or parsed."},{status:310,message:"The stdout output file could not be read."},{status:311,message:"The stdout output file could not be parsed."},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:320,message:"The XML output file could not be read."},{status:321,message:"The XML output file could not be parsed."},{status:322,message:"The XML output file has an unsupported format."},{status:340,message:"The calculation stopped prematurely because it ran out of walltime but the job was killed by the scheduler before the files were safely written to disk for a potential restart."},{status:350,message:"The parser raised an unexpected exception: {exception}"},{status:360,message:"The code failed in finding a valid reciprocal lattice vector."},{status:400,message:"The calculation stopped prematurely because it ran out of walltime."},{status:410,message:"The electronic minimization cycle did not reach self-consistency."},{status:461,message:"The code failed with negative dexx in the exchange calculation."},{status:462,message:"The code failed during the cholesky factorization."},{status:463,message:"Too many bands failed to converge during the diagonalization."},{status:464,message:"The S matrix was found to be not positive definite."},{status:465,message:"The `zhegvd` failed in the PPCG diagonalization."},{status:466,message:"The `[Q, R] = qr(X, 0)` failed in the PPCG diagonalization."},{status:467,message:"The eigenvector failed to converge."},{status:468,message:"The factorization in the Broyden routine failed."},{status:481,message:'The k-point parallelization "npools" is too high, some nodes have no k-points.'},{status:500,message:"The ionic minimization cycle did not converge for the given thresholds."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:502,message:"The ionic minimization cycle did not converge after the maximum number of steps."},{status:503,message:"The ionic minimization cycle did not finish because the calculation was interrupted but a partial trajectory and output structure was successfully parsed which can be used for a restart."},{status:510,message:"The electronic minimization cycle failed during an ionic minimization cycle."},{status:511,message:"The ionic minimization cycle converged, but electronic convergence was not reached in the final SCF."},{status:520,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm."},{status:521,message:"The ionic minimization cycle terminated prematurely because of two consecutive failures in the BFGS algorithm and electronic convergence failed in the final SCF."},{status:531,message:"The electronic minimization cycle did not reach self-consistency."},{status:541,message:"The variable cell optimization broke the symmetry of the k-points."},{status:542,message:"The cell relaxation caused a significant volume contraction and there is not enough space allocated for radial FFT."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.calculations.pwimmigrant:PwimmigrantCalculation"},"quantumespresso.q2r":{description:["`CalcJob` implementation for the q2r.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"parent_folder",required:!0,valid_types:"RemoteData, FolderData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:330,message:"The force constants file could not be read."}]},class:"aiida_quantumespresso.calculations.q2r:Q2rCalculation"},"quantumespresso.seekpath_structure_analysis":{description:["Primitivize the structure with SeeKpath and generate the high symmetry k-point path through its Brillouin zone.","","    This calcfunction will take a structure and pass it through SeeKpath to get the normalized primitive cell and the","    path of high symmetry k-points through its Brillouin zone. Note that the returned primitive cell may differ from the","    original structure in which case the k-points are only congruent with the primitive cell.","","    The keyword arguments can be used to specify various Seekpath parameters, such as:","","        with_time_reversal: True","        reference_distance: 0.025","        recipe: 'hpkot'","        threshold: 1e-07","        symprec: 1e-05","        angle_tolerance: -1.0","","    Note that exact parameters that are available and their defaults will depend on your Seekpath version."],spec:{inputs:[{name:"structure",required:!0,valid_types:"Data",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_quantumespresso.calculations.functions.seekpath_structure_analysis:seekpath_structure_analysis"},"quantumespresso.xspectra":{description:["CalcJob implementation for the xspectra.x code of Quantum ESPRESSO."],spec:{inputs:[{name:"core_wfc_data",required:!0,valid_types:"SinglefileData",info:"Core wavefunction data, generated by the upf2plotcore.sh utility"},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The K-point sampling to be used for the XSpectra calculation"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:""},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"gamma_file",required:!1,valid_types:"SinglefileData, NoneType",info:"An optional file containing the data for the broadening function used when `gamma_mode=file`"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parameters",required:!1,valid_types:"Dict, NoneType",info:"Parameters for the namelists in the input file."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Use an additional node for special settings"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"spectra",required:!0,valid_types:"XyData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:302,message:"The retrieved folder did not contain the required stdout output file."},{status:310,message:"An exception was raised while reading the `stdout` file: {exception}"},{status:311,message:"An exception was raised while parsing the `stdout` file: {exception}"},{status:312,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:313,message:"xiabs was set incorrectly, check and ensure that the index value correctly refers to the atomic species containing the core-hole (where the index starts from 1)."},{status:314,message:"xiabs was either set to 0 or less, or was greater than ntyp."},{status:330,message:"The xspectra output file could not be read from the retrieved folder."},{status:331,message:"The spectrum data file could not be read using NumPy genfromtxt"},{status:400,message:"The time limit set for the calculation was exceeded, and the job wrote a save file before exiting."}]},class:"aiida_quantumespresso.calculations.xspectra:XspectraCalculation"}},"aiida.data":{"quantumespresso.force_constants":"aiida_quantumespresso.data.force_constants:ForceConstantsData","quantumespresso.hubbard_structure":"aiida_quantumespresso.data.hubbard_structure:HubbardStructureData"},"aiida.parsers":{"quantumespresso.cp":"aiida_quantumespresso.parsers.cp:CpParser","quantumespresso.dos":"aiida_quantumespresso.parsers.dos:DosParser","quantumespresso.matdyn":"aiida_quantumespresso.parsers.matdyn:MatdynParser","quantumespresso.neb":"aiida_quantumespresso.parsers.neb:NebParser","quantumespresso.open_grid":"aiida_quantumespresso.parsers.open_grid:OpenGridParser","quantumespresso.ph":"aiida_quantumespresso.parsers.ph:PhParser","quantumespresso.pp":"aiida_quantumespresso.parsers.pp:PpParser","quantumespresso.projwfc":"aiida_quantumespresso.parsers.projwfc:ProjwfcParser","quantumespresso.pw":"aiida_quantumespresso.parsers.pw:PwParser","quantumespresso.pw2gw":"aiida_quantumespresso.parsers.pw2gw:Pw2gwParser","quantumespresso.pw2wannier90":"aiida_quantumespresso.parsers.pw2wannier90:Pw2wannier90Parser","quantumespresso.q2r":"aiida_quantumespresso.parsers.q2r:Q2rParser","quantumespresso.xspectra":"aiida_quantumespresso.parsers.xspectra:XspectraParser"},"aiida.tools.calculations":{"quantumespresso.pw":"aiida_quantumespresso.tools.calculations.pw:PwCalculationTools"},"aiida.tools.data.orbitals":{noncollinearhydrogen:"aiida_quantumespresso.tools.data.orbital.noncollinearhydrogen:NoncollinearHydrogenOrbital",spinorbithydrogen:"aiida_quantumespresso.tools.data.orbital.spinorbithydrogen:SpinorbitHydrogenOrbital"},"aiida.workflows":{"quantumespresso.matdyn.base":{description:["Workchain to run a Quantum ESPRESSO matdyn.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"matdyn",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"output_phonon_bands",required:!0,valid_types:"BandsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.matdyn.base:MatdynBaseWorkChain"},"quantumespresso.pdos":{description:["A WorkChain to compute Total & Partial Density of States of a structure, using Quantum Espresso."],spec:{inputs:[{name:"dos",required:!0,valid_types:"Data",info:"Input parameters for the `dos.x` calculation. Note that the `Emin`, `Emax` and `DeltaE` values have to match with those in the `projwfc` inputs."},{name:"nscf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` of the `nscf` calculation."},{name:"projwfc",required:!0,valid_types:"Data",info:"Input parameters for the `projwfc.x` calculation. Note that the `Emin`, `Emax` and `DeltaE` values have to match with those in the `dos` inputs."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"align_to_fermi",required:!1,valid_types:"Bool",info:"If true, Emin=>Emin-Efermi & Emax=>Emax-Efermi, where Efermi is taken from the `nscf` calculation. Note that it only makes sense to align `Emax` and `Emin` to the fermi level in case they are actually provided by in the `dos` and `projwfc` inputs, since otherwise the "},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If ``True``, work directories of all called calculation will be cleaned at the end of execution."},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"scf",required:!1,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` of the `scf` calculation."},{name:"serial_clean",required:!1,valid_types:"Bool, NoneType",info:"If ``True``, calculations will be run in serial, and work directories will be cleaned before the next step."}],outputs:[{name:"dos",required:!0,valid_types:"",info:""},{name:"nscf",required:!0,valid_types:"",info:""},{name:"projwfc",required:!0,valid_types:"",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified for base or nscf namespaces."},{status:401,message:"the SCF sub process failed"},{status:402,message:"the NSCF sub process failed"},{status:403,message:"the DOS sub process failed"},{status:404,message:"the PROJWFC sub process failed"},{status:404,message:"both the DOS and PROJWFC sub process failed"}]},class:"aiida_quantumespresso.workflows.pdos:PdosWorkChain"},"quantumespresso.ph.base":{description:["Workchain to run a Quantum ESPRESSO ph.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"ph",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"only_initialization",required:!1,valid_types:"Bool",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:401,message:"The work chain failed to merge the q-points data from multiple `PhCalculation`s because not all q-points were parsed."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.ph.base:PhBaseWorkChain"},"quantumespresso.pw.bands":{description:["Workchain to compute a band structure for a given structure using Quantum ESPRESSO pw.x.","","    The logic for the computation of various parameters for the BANDS step is as follows:","","    Number of bands:","        One can specify the number of bands to be used in the BANDS step either directly through the input parameters","        `bands.pw.parameters.SYSTEM.nbnd` or through `nbands_factor`. Note that specifying both is not allowed. When","        neither is specified nothing will be set by the work chain and the default of Quantum ESPRESSO will end up being","        used. If the `nbands_factor` is specified the maximum value of the following values will be used:","","        * `nbnd` of the preceding SCF calculation","        * 0.5 * nelectrons * nbands_factor","        * 0.5 * nelectrons + 4","","    Kpoints:","        There are three options; specify either an existing `KpointsData` through `bands_kpoints`, or specify the","        `bands_kpoint_distance`, or specify neither. For the former those exact kpoints will be used for the BANDS step.","        In the two other cases, the structure will first be normalized using SeekPath and the path along high-symmetry","        k-points will be generated on that structure. The distance between kpoints for the path will be equal to that","        of `bands_kpoints_distance` or the SeekPath default if not specified."],spec:{inputs:[{name:"bands",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the BANDS calculation."},{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the SCF calculation."},{name:"structure",required:!0,valid_types:"StructureData",info:"The inputs structure."},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"Explicit kpoints to use for the BANDS calculation. Specify either this or `bands_kpoints_distance`."},{name:"bands_kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"Minimum kpoints distance for the BANDS calculation. Specify either this or `bands_kpoints`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"nbands_factor",required:!1,valid_types:"Float, NoneType",info:"The number of bands for the BANDS calculation is that used for the SCF multiplied by this factor."},{name:"relax",required:!1,valid_types:"Data",info:"Inputs for the `PwRelaxWorkChain`, if not specified at all, the relaxation step is skipped."}],outputs:[{name:"band_parameters",required:!0,valid_types:"Dict",info:"The output parameters of the BANDS `PwBaseWorkChain`."},{name:"band_structure",required:!0,valid_types:"BandsData",info:"The computed band structure."},{name:"scf_parameters",required:!0,valid_types:"Dict",info:"The output parameters of the SCF `PwBaseWorkChain`."},{name:"primitive_structure",required:!1,valid_types:"StructureData",info:"The normalized and primitivized structure for which the bands are computed."},{name:"seekpath_parameters",required:!1,valid_types:"Dict",info:"The parameters used in the SeeKpath call to normalize the input or relaxed structure."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"Cannot specify both `nbands_factor` and `bands.pw.parameters.SYSTEM.nbnd`."},{status:202,message:"Cannot specify both `bands_kpoints` and `bands_kpoints_distance`."},{status:401,message:"The PwRelaxWorkChain sub process failed"},{status:402,message:"The scf PwBasexWorkChain sub process failed"},{status:403,message:"The bands PwBasexWorkChain sub process failed"}]},class:"aiida_quantumespresso.workflows.pw.bands:PwBandsWorkChain"},"quantumespresso.pw.base":{description:["Workchain to run a Quantum ESPRESSO pw.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"pw",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"An explicit k-points list or mesh. Either this or `kpoints_distance` has to be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by a calculation function based on the input structure."},{name:"kpoints_force_parity",required:!1,valid_types:"Bool, NoneType",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The `output_structure` output node of the successful calculation if present."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:201,message:"The explicit `pseudos` or `pseudo_family` could not be used to get the necessary pseudos."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:203,message:"Neither the `options` nor `automatic_parallelization` input was specified. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:204,message:"The `metadata.options` did not specify both `resources.num_machines` and `max_wallclock_seconds`. This exit status has been deprecated as the check it corresponded to was incorrect."},{status:210,message:"Required key for `automatic_parallelization` was not specified.This exit status has been deprecated as the automatic parallellization feature was removed."},{status:211,message:"Unrecognized keys were specified for `automatic_parallelization`.This exit status has been deprecated as the automatic parallellization feature was removed."},{status:300,message:"The calculation failed with an unidentified unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:310,message:"The calculation failed with a known unrecoverable error."},{status:320,message:"The initialization calculation failed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."},{status:501,message:"Then ionic minimization cycle converged but the thresholds are exceeded in the final SCF."},{status:710,message:"The electronic minimization cycle did not reach self-consistency, but `scf_must_converge` is `False` and/or `electron_maxstep` is 0."}]},class:"aiida_quantumespresso.workflows.pw.base:PwBaseWorkChain"},"quantumespresso.pw.relax":{description:["Workchain to relax a structure using Quantum ESPRESSO pw.x."],spec:{inputs:[{name:"base",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the main relax loop."},{name:"structure",required:!0,valid_types:"StructureData",info:"The inputs structure."},{name:"base_final_scf",required:!1,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` for the final scf."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"max_meta_convergence_iterations",required:!1,valid_types:"Int",info:"The maximum number of variable cell relax iterations in the meta convergence cycle."},{name:"meta_convergence",required:!1,valid_types:"Bool",info:"If `True` the workchain will perform a meta-convergence on the cell volume."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"volume_convergence",required:!1,valid_types:"Float",info:"The volume difference threshold between two consecutive meta convergence iterations."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The `output_parameters` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"output_atomic_occupations",required:!1,valid_types:"Dict",info:""},{name:"output_band",required:!1,valid_types:"BandsData",info:"The `output_band` output node of the successful calculation if present."},{name:"output_kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"output_structure",required:!1,valid_types:"StructureData",info:"The successfully relaxed structure."},{name:"output_trajectory",required:!1,valid_types:"TrajectoryData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"the relax PwBaseWorkChain sub process failed"},{status:402,message:"the final scf PwBaseWorkChain sub process failed"}]},class:"aiida_quantumespresso.workflows.pw.relax:PwRelaxWorkChain"},"quantumespresso.q2r.base":{description:["Workchain to run a Quantum ESPRESSO q2r.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"q2r",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"force_constants",required:!0,valid_types:"ForceConstantsData",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.q2r.base:Q2rBaseWorkChain"},"quantumespresso.xps":{description:["Workchain to compute X-ray photoelectron spectra (XPS) for a given structure.","","    The WorkChain itself firstly calls the PwRelaxWorkChain to relax the input structure if","    required. Then determines the input settings for each XPS calculation automatically using","    ``get_xspectra_structures()``. The input structures are generated from the standardized","    structure by converting each to a supercell with cell dimensions of at least 8.0 angstrom","    in each periodic dimension in order to sufficiently reduce the unphysical interaction","    of the core-hole with neighbouring images. The size of the minimum size requirement can be","    overriden by the user if required. Then the standard Delta-Self-Consistent-Field (ΔSCF)","    method is used to get the XPS binding energy. Finally, the XPS spectrum is calculated","    using the Voigt profile."],spec:{inputs:[{name:"ch_scf",required:!0,valid_types:"Data",info:"Input parameters for the basic xps workflow (core-hole SCF)."},{name:"core_hole_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of excited-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"gipaw_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of ground-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation."},{name:"abs_atom_marker",required:!1,valid_types:"Str",info:"The name for the Kind representing the absorbing atom in the structure. Will be used in all structures generated in ``get_xspectra_structures`` step."},{name:"calc_binding_energy",required:!1,valid_types:"Bool",info:"If `True`, run scf calculation for the supercell."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculations will be cleaned at the end of execution."},{name:"core_hole_treatments",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set core-hole treatment to all elements present. The default full-core-hole treatment will be used if not specified."},{name:"correction_energies",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set the correction energy to all elements present. "},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"elements_list",required:!1,valid_types:"List, NoneType",info:"The list of elements to be considered for analysis, each must be valid elements of the periodic table."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"Data",info:"Input parameters for the relax process. If not specified at all, the relaxation step is skipped."},{name:"spglib_settings",required:!1,valid_types:"Dict, NoneType",info:"Optional settings dictionary for the spglib call within ``get_xspectra_structures``."},{name:"structure_preparation_settings",required:!1,valid_types:"Dict, Float, Int, Bool, Str",info:"Optional settings dictionary for the ``get_xspectra_structures()`` method."},{name:"voight_gamma",required:!1,valid_types:"Float",info:"The gamma parameter for the Lorenzian broadening in the Voight method."},{name:"voight_sigma",required:!1,valid_types:"Float",info:"The sigma parameter for the gaussian broadening in the Voight method."}],outputs:[{name:"binding_energies",required:!0,valid_types:"Dict",info:"All the binding energy values for each element calculated by the WorkChain."},{name:"chemical_shifts",required:!0,valid_types:"Dict",info:"All the chemical shift values for each element calculated by the WorkChain."},{name:"final_spectra_be",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element based on binding energy."},{name:"final_spectra_cls",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element based on chemical shift."},{name:"output_parameters_ch_scf",required:!0,valid_types:"Dict",info:"The output parameters of each ``PwBaseWorkChain`` performed``."},{name:"supercell_structure",required:!0,valid_types:"StructureData",info:"The supercell of ``outputs.standardized_structure`` used to generate structures for XPS sub-processes."},{name:"symmetry_analysis_data",required:!0,valid_types:"Dict",info:"The output parameters from ``get_xspectra_structures()``."},{name:"optimized_structure",required:!1,valid_types:"StructureData",info:"The optimized structure from the ``relax`` process."},{name:"output_parameters_relax",required:!1,valid_types:"Dict",info:"The output_parameters of the relax step."},{name:"output_parameters_scf",required:!1,valid_types:"Dict",info:"The output_parameters of the scf step."},{name:"standardized_structure",required:!1,valid_types:"StructureData",info:"The standardized crystal structure used to generate structures for XPS sub-processes."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The Relax sub process failed"},{status:402,message:"The SCF Pw sub processes failed"},{status:402,message:"One or more CH_SCF Pw sub processes failed"}]},class:"aiida_quantumespresso.workflows.xps:XpsWorkChain"},"quantumespresso.xspectra.base":{description:["Workchain to run a Quantum ESPRESSO xspectra.x calculation with automated error handling and restarts."],spec:{inputs:[{name:"xspectra",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"An explicit k-points mesh. Either this or `kpoints_distance` has to be provided."},{name:"kpoints_distance",required:!1,valid_types:"Float, NoneType",info:"The minimum desired distance in 1/Å between k-points in reciprocal space. The explicit k-points will be generated automatically by a calculation function based on the input structure."},{name:"kpoints_force_parity",required:!1,valid_types:"Bool, NoneType",info:"Optional input when constructing the k-points based on a desired `kpoints_distance`. Setting this to `True` will force the k-point mesh to have an even number of points along each lattice vector except for any non-periodic directions."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"spectra",required:!0,valid_types:"XyData",info:""},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:202,message:"Neither the `kpoints` nor the `kpoints_distance` input was specified."},{status:300,message:"The calculation failed with an unrecoverable error."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_quantumespresso.workflows.xspectra.base:XspectraBaseWorkChain"},"quantumespresso.xspectra.core":{description:["Workchain to compute X-ray absorption spectra for a given structure using Quantum ESPRESSO.","","    The workflow follows the process required to compute the XAS of an input structure: an SCF calculation is performed","    using the provided structure, which is then followed by the calculation of the XAS itself by XSpectra. The","    calculations performed by the WorkChain in a typical run will be:","","    - PwSCF calculation with pw.x of the input structure with a core-hole present.","    - Generation of core-wavefunction data with upf2plotcore.sh (if requested).","    - XAS calculation with xspectra.x to compute the Lanczos coefficients and print the XANES spectra for the","      polarisation vectors requested in the input.","    - Collation of output data from pw.x and xspectra.x calculations, including a combination of XANES dipole spectra","      based on polarisation vectors to represent the powder spectrum of the structure (if requested).","","    If ``run_replot = True`` is set in the inputs (defaults to False), the WorkChain will run a second xspectra.x","    calculation which replots the spectra produced from the ``xs_prod`` step. This option can be very useful for","    obtaining a final spectrum at low levels of broadening (relative to the default of 0.5 eV), particularly as higher","    levels of broadening significantly speed up the convergence of the Lanczos procedure. Inputs for the replot","    calculation are found in the ``xs_plot`` namespace.","","    The core-wavefunction plot derived from the ground-state of the absorbing element can be provided as a top-level","    input or produced by the WorkChain. If left to the WorkChain, the ground-state pseudopotential assigned to the","    absorbing element will be used to generate this data using the upf2plotcore.sh utility script (via the","    ``aiida-shell`` plugin).","","    In its current stage of development, the workflow requires the following:","","    - An input structure where the desired absorbing atom in the system is marked as a separate Kind. The default","      behaviour for the WorkChain is to set the Kind name as 'X', however this can be changed via the `overrides`","      dictionary.","    - A code node for ``upf2plotcore``, configured for the ``aiida-shell`` plugin","      (https://github.com/sphuber/aiida-shell). Alternatively, a ``SinglefileData`` node from a previous ``ShellJob``","      run can be supplied under ``inputs.core_wfc_data``.","    - A suitable pair of pseudopotentials for the element type of the absorbing atom, one for the ground-state occupancy","      which contains GIPAW informtation for the core level of interest for the XAS (e.g. 1s in the case of a K-edge","      calculation) and the other containing a core hole. (For the moment this can be passed either via the","      ``core_hole_pseudos`` field in ``get_builder_from_protocol`` or via the overrides, but will be changed later once","      full families of core-hole pseudopotentials become available)."],spec:{inputs:[{name:"eps_vectors",required:!0,valid_types:"List",info:"The list of 3-vectors to use in XSpectra sub-processes. The number of sub-lists will subsequently define the number of XSpectra calculations to perform"},{name:"scf",required:!0,valid_types:"Data",info:"Input parameters for the `pw.x` calculation."},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation, with at least one site containing the `abs_atom_marker` as the kind label."},{name:"xs_prod",required:!0,valid_types:"Data",info:"Input parameters for the `xspectra.x` calculation to compute the Lanczos."},{name:"abs_atom_marker",required:!1,valid_types:"Str, NoneType",info:"The name for the Kind representing the absorbing atom in the structure. Must corespond to a Kind within the StructureData node supplied to the calculation."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"core_wfc_data",required:!1,valid_types:"SinglefileData, NoneType",info:"The core wavefunction data file extracted from the ground-state pseudo for the absorbing atom."},{name:"dry_run",required:!1,valid_types:"Bool, NoneType",info:"Terminate workchain steps before submitting calculations (test purposes only)."},{name:"get_powder_spectrum",required:!1,valid_types:"Bool",info:"If `True`, the WorkChain will combine XANES dipole spectra computed using the XAS basis vectors defined according to the `get_powder_spectrum` CalcFunction."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"run_replot",required:!1,valid_types:"Bool",info:""},{name:"upf2plotcore_code",required:!1,valid_types:"Code, NoneType",info:"The code node required for upf2plotcore.sh configured for ``aiida-shell``. Must be provided if `core_wfc_data` is not provided."},{name:"xs_plot",required:!1,valid_types:"Data",info:"Input parameters for the re-plot `xspectra.x` calculation of the Lanczos."}],outputs:[{name:"parameters_scf",required:!0,valid_types:"Dict",info:"The output parameters of the SCF `PwBaseWorkChain`."},{name:"parameters_xspectra",required:!0,valid_types:"Dict",info:"The output dictionaries of each `XspectraBaseWorkChain` performed"},{name:"spectra",required:!0,valid_types:"XyData",info:"An XyData node containing all the final spectra produced by the WorkChain."},{name:"powder_spectrum",required:!1,valid_types:"XyData",info:"The simulated powder spectrum"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The SCF sub process failed"},{status:402,message:"One or more XSpectra sub processes failed"},{status:403,message:"The pseudo for the absorbing element contains no GIPAW information."}]},class:"aiida_quantumespresso.workflows.xspectra.core:XspectraCoreWorkChain"},"quantumespresso.xspectra.crystal":{description:["Workchain to compute all X-ray absorption spectra for a given structure using Quantum ESPRESSO.","","    The WorkChain follows the process required to compute all the K-edge XAS spectra for each","    element in a given structure. The WorkChain itself firstly calls the PwRelaxWorkChain to","    relax the input structure, then determines the input settings for each XAS","    calculation automatically using ``get_xspectra_structures()``:","","        - Firstly the input structure is converted to its conventional standard cell using","          ``spglib`` and detects the space group number for the conventional cell.","        - Symmetry analysis of the standardized structure using ``spglib`` is then used to","          determine the number of non-equivalent atomic sites in the structure for each","          element considered for analysis.","","    Using the symmetry data returned from ``get_xspectra_structures``, input structures for","    the XspectraCoreWorkChain are generated from the standardized structure by converting each","    to a supercell with cell dimensions of at least 8.0 angstroms in each periodic dimension -","    required in order to sufficiently reduce the unphysical interaction of the core-hole with","    neighbouring images. The size of the minimum size requirement can be overriden by the","    user if required. The WorkChain then uses the space group number to set the list of","    polarisation vectors for the ``XspectraCoreWorkChain`` to compute for all subsequent","    calculations."],spec:{inputs:[{name:"core",required:!0,valid_types:"Data",info:"Input parameters for the basic xspectra workflow (core-hole SCF + XAS."},{name:"core_hole_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of excited-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}".'},{name:"elements_list",required:!0,valid_types:"List",info:"The list of elements to be considered for analysis, each must be a valid element of the periodic table."},{name:"gipaw_pseudos",required:!0,valid_types:"UpfData, UpfData",info:'Dynamic namespace for pairs of ground-state pseudopotentials for each absorbing element. Must use the mapping "{element}" : {Upf}.'},{name:"structure",required:!0,valid_types:"StructureData",info:"Structure to be used for calculation."},{name:"abs_atom_marker",required:!1,valid_types:"Str",info:"The name for the Kind representing the absorbing atom in the structure. Will be used in all structures generated in ``get_xspectra_structures`` step."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculations will be cleaned at the end of execution."},{name:"core_hole_treatments",required:!1,valid_types:"Dict, NoneType",info:"Optional dictionary to set core-hole treatment to given elements present. The default full-core-hole treatment will be used if not specified."},{name:"core_wfc_data",required:!1,valid_types:"SinglefileData",info:"Input namespace to provide core wavefunction inputs for each element. Must follow the format: ``core_wfc_data__{symbol} = {node}``"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"Data",info:"Input parameters for the relax process. If not specified at all, the relaxation step is skipped."},{name:"return_all_powder_spectra",required:!1,valid_types:"Bool",info:"If ``True``, the WorkChain will return all ``powder_spectrum`` nodes from each ``XspectraCoreWorkChain`` sub-process."},{name:"spglib_settings",required:!1,valid_types:"Dict, NoneType",info:"Optional settings dictionary for the spglib call within ``get_xspectra_structures``."},{name:"structure_preparation_settings",required:!1,valid_types:"Dict, Float, Int, Bool, Str",info:"Optional settings dictionary for the ``get_xspectra_structures()`` method."},{name:"upf2plotcore_code",required:!1,valid_types:"Code, NoneType",info:"Code node for the upf2plotcore.sh ShellJob code."}],outputs:[{name:"final_spectra",required:!0,valid_types:"XyData",info:"The fully-resolved spectra for each element"},{name:"supercell_structure",required:!0,valid_types:"StructureData",info:"The supercell of ``outputs.standardized_structure`` used to generate structures for XSpectra sub-processes."},{name:"symmetry_analysis_data",required:!0,valid_types:"Dict",info:"The output parameters from ``get_xspectra_structures()``."},{name:"optimized_structure",required:!1,valid_types:"StructureData",info:"The optimized structure from the ``relax`` process."},{name:"parameters_relax",required:!1,valid_types:"Dict",info:"The output_parameters of the relax step."},{name:"parameters_scf",required:!1,valid_types:"Dict",info:"The output parameters of each ``PwBaseWorkChain`` performed in each ``XspectraCoreWorkChain``."},{name:"parameters_xspectra",required:!1,valid_types:"Dict",info:"The output dictionaries of each `XspectraCalculation` performed"},{name:"powder_spectra",required:!1,valid_types:"XyData",info:"All the spectra generated by the WorkChain."},{name:"standardized_structure",required:!1,valid_types:"StructureData",info:"The standardized crystal structure used to generate structures for XSpectra sub-processes."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:401,message:"The Relax sub process failed"},{status:402,message:"One or more XSpectra workflows failed"},{status:403,message:"The pseudos for one or more absorbing elements contain no GIPAW information."}]},class:"aiida_quantumespresso.workflows.xspectra.crystal:XspectraCrystalWorkChain"}},console_scripts:{"aiida-quantumespresso":"aiida_quantumespresso.cli:cmd_root"}},commits_count:93,development_status:"stable",warnings:["Entry point 'noncollinearhydrogen' does not start with prefix 'quantumespresso.'","Entry point 'spinorbithydrogen' does not start with prefix 'quantumespresso.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:20},{colorclass:"brown",text:"Parsers",count:13},{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:11},{colorclass:"purple",text:"Console scripts",count:1},{colorclass:"orange",text:"Other (Tools calculations, Tools data orbitals)",count:3}],pip_install_cmd:"pip install aiida-quantumespresso",is_installable:"True"},"aiida-quantumespresso-hp":{code_home:"https://github.com/sphuber/aiida-quantumespresso-hp",entry_point_prefix:"quantumespresso.hp",pip_url:"git+https://github.com/sphuber/aiida-quantumespresso-hp",name:"aiida-quantumespresso-hp",package_name:"aiida_quantumespresso_hp",hosted_on:"github.com",metadata:{author:"Sebastiaan P. Huber",author_email:"mail@sphuber.net",version:"0.1.0",description:"The AiiDA plugin for the Hubbard module of Quantum ESPRESSO",classifiers:["License :: OSI Approved :: MIT License","Programming Language :: Python :: 2.7","Development Status :: 4 - Beta"]},aiida_version:">=1.0.0b6,<2.0",entry_points:{"aiida.calculations":{"quantumespresso.hp":"aiida_quantumespresso_hp.calculations.hp:HpCalculation"},"aiida.parsers":{"quantumespresso.hp":"aiida_quantumespresso_hp.parsers.hp:HpParser"},"aiida.workflows":{"quantumespresso.hp.main":"aiida_quantumespresso_hp.workflows.hp.main:HpWorkChain","quantumespresso.hp.parallelize_atoms":"aiida_quantumespresso_hp.workflows.hp.parallelize_atoms:HpParallelizeAtomsWorkChain","quantumespresso.hp.base":"aiida_quantumespresso_hp.workflows.hp.base:HpBaseWorkChain","quantumespresso.hp.hubbard":"aiida_quantumespresso_hp.workflows.hubbard:SelfConsistentHubbardWorkChain"},console_scripts:{launch_calculation_hp:"aiida_quantumespresso_hp.cli.calculations.hp:launch",launch_workflow_hp_base:"aiida_quantumespresso_hp.cli.workflows.hp.base:launch",launch_workflow_hp_main:"aiida_quantumespresso_hp.cli.workflows.hp.main:launch",launch_workflow_hp_hubbard:"aiida_quantumespresso_hp.cli.workflows.hubbard:launch"}},commits_count:0,development_status:"beta",warnings:["Missing classifier 'Framework :: AiiDA'","Prefix 'quantumespresso.hp' does not follow naming convention."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:4},{colorclass:"purple",text:"Console scripts",count:4}],pip_install_cmd:"pip install git+https://github.com/sphuber/aiida-quantumespresso-hp",is_installable:"True"},"aiida-raspa":{code_home:"https://github.com/yakutovicha/aiida-raspa",entry_point_prefix:"raspa",pip_url:"aiida-raspa",plugin_info:"https://raw.github.com/yakutovicha/aiida-raspa/master/setup.json",name:"aiida-raspa",package_name:"aiida_raspa",hosted_on:"github.com",metadata:{release_date:"2023-08-26",description:"AiiDA plugin for RASPA code",author_email:"Aliaksandr Yakutovich <aliaksandr.yakutovich@epfl.ch>, Miriam Pougin <miriam.pougin@epfl.ch>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{raspa:{description:["This is a RaspaCalculation, subclass of CalcJob, to prepare input for RASPA code.","    For information on RASPA, refer to: https://github.com/iraspa/raspa2."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters"},{name:"block_pocket",required:!1,valid_types:"SinglefileData",info:"Zeo++ block pocket file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"file",required:!1,valid_types:"SinglefileData",info:"Additional input file(s)"},{name:"framework",required:!1,valid_types:"CifData",info:"Input framework(s)"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"parent_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote folder used to continue the same simulation stating from the binary restarts."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"retrieved_parent_folder",required:!1,valid_types:"FolderData, NoneType",info:"To use an old calculation as a starting poing for a new one."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional input parameters"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The results of a calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"warnings",required:!1,valid_types:"List",info:"Warnings that appeared during the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"The retrieved folder does not contain an output file."},{status:102,message:'The output does not contain "Starting simulation".'},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:500,message:"The calculation could not be completed due to the lack of time."}]},class:"aiida_raspa.calculations:RaspaCalculation"}},"aiida.parsers":{raspa:"aiida_raspa.parsers:RaspaParser"},"aiida.workflows":{"raspa.base":{description:["Workchain to run a RASPA calculation with automated error handling and restarts."],spec:{inputs:[{name:"raspa",required:!0,valid_types:"Data",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"handler_overrides",required:!1,valid_types:"Dict, NoneType",info:"Mapping where keys are process handler names and the values are a dictionary, where each dictionary can define the ``enabled`` and ``priority`` key, which can be used to toggle the values set on the original process handler declaration."},{name:"max_iterations",required:!1,valid_types:"Int",info:"Maximum number of iterations the work chain will restart the process to finish successfully."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The results of a calculation"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"warnings",required:!1,valid_types:"List",info:"Warnings that appeared during the calculation"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_raspa.workchains:RaspaBaseWorkChain"}}},commits_count:3,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-raspa",is_installable:"True"},"aiida-shell":{code_home:"https://github.com/sphuber/aiida-shell",entry_point_prefix:"core",pip_url:"aiida-shell",plugin_info:"https://raw.github.com/sphuber/aiida-shell/master/pyproject.toml",name:"aiida-shell",package_name:"aiida_shell",hosted_on:"github.com",metadata:{release_date:"2023-06-14",description:"AiiDA plugin that makes running shell commands easy.",author_email:'"Sebastiaan P. Huber" <mail@sphuber.net>',classifiers:["Development Status :: 3 - Alpha","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],version:"0.5.3"},aiida_version:">=2.1,<3.0",entry_points:{"aiida.calculations":{"core.shell":{description:["Implementation of :class:`aiida.engine.CalcJob` to run a simple shell command."],spec:{inputs:[{name:"code",required:!0,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"arguments",required:!1,valid_types:"List, NoneType",info:""},{name:"filenames",required:!1,valid_types:"Dict, NoneType",info:""},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"nodes",required:!1,valid_types:"Data",info:""},{name:"outputs",required:!1,valid_types:"List, NoneType",info:""},{name:"parser",required:!1,valid_types:"PickledData, NoneType",info:""},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:300,message:"Exit status could not be determined: exit status file was not retrieved."},{status:301,message:"Exit status could not be determined: exit status file does not contain a valid integer."},{status:302,message:"The stdout file was not retrieved."},{status:303,message:"One or more output files defined in the `outputs` input were not retrieved: {missing_filepaths}."},{status:310,message:"Callable specified in the `parser` input excepted: {exception}."},{status:400,message:"The command exited with a non-zero status: {status} {stderr}."},{status:410,message:"The command exited with a zero status but the stderr was not empty."}]},class:"aiida_shell.calculations.shell:ShellJob"}},"aiida.data":{"core.code.installed.shell":"aiida_shell.data.code:ShellCode","core.pickled":"aiida_shell.data.pickled:PickledData"},"aiida.parsers":{"core.shell":"aiida_shell.parsers.shell:ShellParser"}},commits_count:46,development_status:"alpha",warnings:["Prefix 'core' does not follow naming convention."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:2}],pip_install_cmd:"pip install aiida-shell",is_installable:"True"},"aiida-siesta":{code_home:"https://github.com/siesta-project/aiida_siesta_plugin/tree/master",documentation_url:"https://aiida-siesta-plugin.readthedocs.io/",entry_point_prefix:"siesta",pip_url:"aiida-siesta",name:"aiida-siesta",package_name:"aiida_siesta",hosted_on:"github.com",metadata:{release_date:"2022-07-17",description:"A plugin for Siesta's basic functionality within the AiiDA framework.",author_email:'Albero Garcia <albertog@icmab.es>, "Victor M. Garcia-Suarez" <garciavictor@uniovi.es>, Emanuele Bosoni <ebosoni@icmab.es>, Vladimir Dikan <vdikan@icmab.es>, Pol Febrer <pol.febrer@icn2.cat>',classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.0.0,<3.0.0",entry_points:{},commits_count:6,development_status:"stable",errors:["Unable to retrieve plugin info from: https://raw.github.com/siesta-project/aiida_siesta_plugin/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["No bdist_wheel available for PyPI release"],summaryinfo:[],pip_install_cmd:"pip install aiida-siesta",is_installable:"True"},"aiida-spex":{code_home:"https://github.com/JuDFTteam/aiida-spex",entry_point_prefix:"spex",pip_url:"git+https://github.com/JuDFTteam/aiida-spex",name:"aiida-spex",package_name:"aiida_spex",hosted_on:"github.com",metadata:{author:"The SPEX Team",author_email:"a.chandran@fz-juelich.de",version:"1.1.2",description:"AiiDA plugin for SPEX code",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.0.0b3,<3.0.0",entry_points:{"aiida.calculations":{"spex.spex":"aiida_spex.calculations.spex:SpexCalculation"},"aiida.data":{"spex.spexinp":"aiida_spex.data.spexinp:SpexinpData"},"aiida.parsers":{"spex.spexparser":"aiida_spex.parsers.spex:SpexParser"},"aiida.workflows":{"spex.job":"aiida_spex.workflows.job:SpexJobWorkchain"}},commits_count:0,development_status:"planning",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install git+https://github.com/JuDFTteam/aiida-spex"},"aiida-spirit":{code_home:"https://github.com/JuDFTteam/aiida-spirit/tree/main",documentation_url:"https://aiida-spirit.readthedocs.io/",entry_point_prefix:"spirit",name:"aiida-spirit",pip_url:"aiida-spirit",package_name:"aiida_spirit",hosted_on:"github.com",metadata:{release_date:"2023-06-23",description:"AiiDA plugin for the spirit code",author:"The JuDFT Team",author_email:"p.ruessmann@fz-juelich.de",license:"MIT",home_page:"https://github.com/JuDFTteam/aiida-spirit",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.2"},aiida_version:null,entry_points:{"aiida.calculations":{spirit:"aiida_spirit.calculations:SpiritCalculation"},"aiida.parsers":{spirit:"aiida_spirit.parsers:SpiritParser"}},commits_count:9,development_status:"planning",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-spirit"},"aiida-ssh2win":{entry_point_prefix:"ssh2win",code_home:"https://github.com/edan-bainglass/aiida-ssh2win",version_file:"https://raw.githubusercontent.com/edan-bainglass/aiida-ssh2win/develop/aiida_ssh2win/__init__.py",pip_url:"git+https://github.com/edan-bainglass/aiida-ssh2win",name:"aiida-ssh2win",package_name:"aiida_ssh2win",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:13,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/edan-bainglass/aiida-ssh2win"},"aiida-sshonly":{code_home:"https://github.com/adegomme/aiida-sshonly",development_status:"beta",entry_point_prefix:"sshonly",pip_url:"aiida-sshonly",plugin_info:"https://raw.github.com/adegomme/aiida-sshonly/master/setup.json",name:"aiida-sshonly",package_name:"aiida_sshonly",hosted_on:"github.com",metadata:{release_date:"2020-10-07",description:"AiiDA plugin adding a sshonly transport option, using only SSH to transfer files, avoiding SFTP, in case it's blocked or non functional on a remote system",author:"adegomme",license:"MIT",home_page:"https://github.com/adegomme/aiida-sshonly",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0a3"},aiida_version:">=1.3.0,<2.0.0",entry_points:{"aiida.transports":{ssh_only:"aiida_sshonly.transports.sshonly:SshOnlyTransport"}},commits_count:0,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead.","Entry point 'ssh_only' does not start with prefix 'sshonly.'"],summaryinfo:[{colorclass:"orange",text:"Other (Transports)",count:1}],pip_install_cmd:"pip install --pre aiida-sshonly",is_installable:"True"},"aiida-statefile-schedulers":{code_home:"https://github.com/dev-zero/aiida-statefile-schedulers",development_status:"beta",entry_point_prefix:"statefile_schedulers",pip_url:"aiida-statefile-schedulers",name:"aiida-statefile-schedulers",package_name:"aiida_statefile_schedulers",hosted_on:"github.com",metadata:{release_date:"2021-11-23",description:"Simple statefile-driven task schedulers for AiiDA",author:"Tiziano Müller",author_email:"tm@dev-zero.ch",license:"MIT",home_page:"https://github.com/dev-zero/aiida-statefile-schedulers",classifiers:["Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.2.1"},aiida_version:null,entry_points:{"aiida.schedulers":{"statefile_schedulers.direct":"aiida_statefile_schedulers.schedulers.direct:StatefileDirectScheduler"}},commits_count:0,warnings:["No bdist_wheel available for PyPI release","AiiDA version not found","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"orange",text:"Other (Schedulers)",count:1}],pip_install_cmd:"pip install aiida-statefile-schedulers",is_installable:"True"},"aiida-strain":{code_home:"https://github.com/greschd/aiida-strain",documentation_url:"https://aiida-strain.readthedocs.io",entry_point_prefix:"strain",pip_url:"aiida-strain",name:"aiida-strain",package_name:"aiida_strain",hosted_on:"github.com",metadata:{release_date:"2019-11-22",description:"AiiDA Plugin for applying strain to structures",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-strain.readthedocs.io",classifiers:["Development Status :: 3 - Alpha","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.workflows":{"strain.apply_strains":{description:["Workchain to create strained structures from a given input structure."],spec:{inputs:[{name:"strain_kind",required:!0,valid_types:"Str",info:""},{name:"strain_parameters",required:!0,valid_types:"Str",info:""},{name:"strain_strengths",required:!0,valid_types:"List",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_strain:ApplyStrains"},"strain.apply_strains_with_symmetry":{description:["Workchain to create strained structures from an input structure, and select the symmetries which are compatible with the strained structure from a set of given input symmetries."],spec:{inputs:[{name:"strain_kind",required:!0,valid_types:"Str",info:""},{name:"strain_parameters",required:!0,valid_types:"Str",info:""},{name:"strain_strengths",required:!0,valid_types:"List",info:""},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:""},{name:"symmetry_repr_code",required:!0,valid_types:"Code",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_strain:ApplyStrainsWithSymmetry"}}},commits_count:0,development_status:"alpha",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"green",text:"Workflows",count:2}],pip_install_cmd:"pip install aiida-strain",is_installable:"True"},"aiida-supercell":{code_home:"https://github.com/pzarabadip/aiida-supercell",development_status:"stable",documentation_url:"https://aiida-supercell.readthedocs.io/",entry_point_prefix:"supercell",pip_url:"git+https://github.com/pzarabadip/aiida-supercell",name:"aiida-supercell",package_name:"aiida_supercell",hosted_on:"github.com",metadata:{author:"Pezhman Zarabadi-Poor",author_email:"pzarabadip@gmail.com",version:"1.0.1",description:"AiiDA Plugin for Supercell program",classifiers:["Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"]},aiida_version:">=1.0.0,<2.0",entry_points:{"aiida.calculations":{supercell:{description:["This is a SupercellCalculation, subclass of JobCalculation,","    to prepare input for enumerating structures using Supercell program"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"structure",required:!0,valid_types:"StructureData, SinglefileData",info:"Input structure"},{name:"supercell_size",required:!0,valid_types:"List",info:"Supercell size for enumeration"},{name:"calculate_coulomb_energies",required:!1,valid_types:"Bool",info:"Whether to calculate Coulomb energies"},{name:"charge_balance_method",required:!1,valid_types:"Str",info:"Method to use for charge balancing"},{name:"charges",required:!1,valid_types:"Dict",info:"Dictionary of formal charges to be used"},{name:"merge_symmetric",required:!1,valid_types:"Bool",info:"Whether to merge symmetrically distinct configurations"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"random_seed",required:!1,valid_types:"Int",info:"Random seed number"},{name:"sample_structures",required:!1,valid_types:"Dict",info:"How to sample structures from huge configuration space"},{name:"save_as_archive",required:!1,valid_types:"Bool",info:"Whether to save resulting structures as archive"},{name:"tolerance",required:!1,valid_types:"Float",info:"The maximum distance (in Angstroms) between sites that should be contained within the same group."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"the results of the calculation"},{name:"output_structures",required:!0,valid_types:"StructureData",info:"relaxed structure"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The retrieved folder data node could not be accessed."},{status:101,message:"Input structure could not be processed."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."}]},class:"aiida_supercell.calculations:SupercellCalculation"}},"aiida.parsers":{supercell:"aiida_supercell.parsers:SupercellParser"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/pzarabadip/aiida-supercell",is_installable:"True"},"aiida-symmetry-representation":{code_home:"https://github.com/greschd/aiida_symmetry_representation",documentation_url:"https://aiida-symmetry-representation.readthedocs.io",entry_point_prefix:"symmetry_representation",pip_url:"aiida-symmetry-representation",name:"aiida-symmetry-representation",package_name:"aiida_symmetry_representation",hosted_on:"github.com",metadata:{release_date:"2019-11-18",description:"AiiDA Plugin for symmetry representations.",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-symmetry-representation.readthedocs.io",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0"},aiida_version:null,entry_points:{"aiida.calculations":{"symmetry_representation.filter_symmetries":{description:["Calculation class to run the ``symmetry-repr filter_symmetries`` command."],spec:{inputs:[{name:"structure",required:!0,valid_types:"StructureData",info:"Structure with which the filtered symmetries should be compatible."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"File containing the symmetries (in HDF5 format)."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"The HDF5 file containing the symmetries which are compatible with the structure."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_symmetry_representation.calculations.filter_symmetries:FilterSymmetriesCalculation"}},"aiida.parsers":{"symmetry_representation.symmetry":"aiida_symmetry_representation.parsers.symmetries:SymmetriesParser"}},commits_count:0,development_status:"stable",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-symmetry-representation",is_installable:"True"},"aiida-tbextraction":{code_home:"https://github.com/greschd/aiida-tbextraction",documentation_url:"https://aiida-tbextraction.readthedocs.io/",entry_point_prefix:"tbextraction",pip_url:"aiida-tbextraction",name:"aiida-tbextraction",package_name:"aiida_tbextraction",hosted_on:"github.com",metadata:{release_date:"2020-02-25",description:"AiiDA Plugin for extracting tight-binding models",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-tbextraction.readthedocs.io",classifiers:["Development Status :: 4 - Beta","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.2.0b1"},aiida_version:null,entry_points:{"aiida.workflows":{"tbextraction.fp_run.base":"aiida_tbextraction.fp_run:FirstPrinciplesRunBase","tbextraction.fp_run.reference_bands.base":"aiida_tbextraction.fp_run.reference_bands:ReferenceBandsBase","tbextraction.fp_run.wannier_input.base":"aiida_tbextraction.fp_run.wannier_input:WannierInputBase","tbextraction.calculate_tb":"aiida_tbextraction.calculate_tb:TightBindingCalculation","tbextraction.model_evaluation.base":"aiida_tbextraction.model_evaluation:ModelEvaluationBase","tbextraction.model_evaluation.band_difference":"aiida_tbextraction.model_evaluation:BandDifferenceModelEvaluation","tbextraction.energy_windows.run_window":"aiida_tbextraction.energy_windows.run_window:RunWindow","tbextraction.energy_windows.window_search":"aiida_tbextraction.energy_windows.window_search:WindowSearch","tbextraction.optimize_fp_tb":"aiida_tbextraction.optimize_fp_tb:OptimizeFirstPrinciplesTightBinding","tbextraction.optimize_strained_fp_tb":"aiida_tbextraction.optimize_strained_fp_tb:OptimizeStrainedFirstPrinciplesTightBinding"}},commits_count:0,development_status:"beta",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"green",text:"Workflows",count:10}],pip_install_cmd:"pip install --pre aiida-tbextraction",is_installable:"True",errors:["Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`,"Failed to import package aiida_tbextraction",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/__init__.py", line 13, in <module>
    from . import fp_run
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/__init__.py", line 11, in <module>
    from ._base import FirstPrinciplesRunBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/_base.py", line 11, in <module>
    from .reference_bands import ReferenceBandsBase
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/__init__.py", line 10, in <module>
    from ._qe import QuantumEspressoReferenceBands
  File "/opt/conda/lib/python3.8/site-packages/aiida_tbextraction/fp_run/reference_bands/_qe.py", line 13, in <module>
    from aiida_quantumespresso.calculations.pw import PwCalculation
ModuleNotFoundError: No module named 'aiida_quantumespresso'
</pre>`]},"aiida-tbmodels":{code_home:"https://github.com/greschd/aiida-tbmodels",documentation_url:"https://aiida-tbmodels.readthedocs.io",entry_point_prefix:"tbmodels",pip_url:"aiida-tbmodels",name:"aiida-tbmodels",package_name:"aiida_tbmodels",hosted_on:"github.com",metadata:{release_date:"2020-03-03",description:"AiiDA Plugin for running TBmodels",author:"Dominik Gresch",author_email:"greschd@gmx.ch",license:"Apache 2.0",home_page:"https://aiida-tbmodels.readthedocs.io",classifiers:["Development Status :: 3 - Alpha","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Physics"],version:"0.3.0"},aiida_version:null,entry_points:{"aiida.calculations":{"tbmodels.eigenvals":{description:["Calculation class for the 'tbmodels eigenvals' command, which computes the eigenvalues from a given tight-binding model."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"Kpoints for which the eigenvalues are calculated."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"bands",required:!0,valid_types:"BandsData",info:"The calculated eigenvalues of the model at given k-points."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The result HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."}]},class:"aiida_tbmodels.calculations.eigenvals:EigenvalsCalculation"},"tbmodels.parse":{description:["Calculation plugin for the 'tbmodels parse' command, which creates a","    TBmodels tight-binding model from the Wannier90 output."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"wannier_folder",required:!0,valid_types:"FolderData",info:"Folder containing the Wannier90 output data."},{name:"distance_ratio_threshold",required:!1,valid_types:"Float",info:"Determines the minimum ratio between nearest and next-nearest atom when parsing with 'nearest_atom' mode."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"pos_kind",required:!1,valid_types:"Str",info:"Determines how the orbital positions are parsed."},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."},{status:301,message:"The seedname_wsvec.dat file is empty or incomplete."},{status:401,message:"The nearest atom to use for position parsing is ambiguous."}]},class:"aiida_tbmodels.calculations.parse:ParseCalculation"},"tbmodels.slice":{description:["Calculation plugin for the 'tbmodels slice' command, which re-orders or slices orbitals of a tight-binding model."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"slice_idx",required:!0,valid_types:"List",info:"Indices of the orbitals which are sliced from the model."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."}]},class:"aiida_tbmodels.calculations.slice:SliceCalculation"},"tbmodels.symmetrize":{description:["Calculation class for the 'tbmodels symmetrize' command, which creates a symmetrized tight-binding model from a tight-binding model and symmetry representations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"symmetries",required:!0,valid_types:"SinglefileData",info:"File containing the symmetries in HDF5 format."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Input model in TBmodels HDF5 format."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"sparsity",required:!1,valid_types:"Str",info:"Set the sparsity of the output model. Requires TBmodels version >=1.4."}],outputs:[{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"tb_model",required:!0,valid_types:"SinglefileData",info:"Output model in TBmodels HDF5 format."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:300,message:"The output model HDF5 file was not found."},{status:301,message:"The standard error file contains an unknown TBmodels exception."},{status:301,message:"The type of the given symmetries object is incorrect."}]},class:"aiida_tbmodels.calculations.symmetrize:SymmetrizeCalculation"}},"aiida.parsers":{"tbmodels.model":"aiida_tbmodels.parsers.model:ModelParser"}},commits_count:0,development_status:"alpha",warnings:["No bdist_wheel available for PyPI release","AiiDA version not found"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:4},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-tbmodels",is_installable:"True"},"aiida-tcod":{code_home:"https://github.com/aiidateam/aiida-tcod",development_status:"beta",entry_point_prefix:"tcod",pip_url:"git+https://github.com/aiidateam/aiida-tcod",name:"aiida-tcod",package_name:"aiida_tcod",hosted_on:"github.com",metadata:{author:"The AiiDA team",author_email:"developers@aiida.net",version:"0.1.0a0",description:"AiiDA plugin to interact with the TCOD",classifiers:["Programming Language :: Python"]},aiida_version:">=1.0.0b1",entry_points:{"aiida.tools.dbexporters":{tcod:"aiida.tools.dbexporters.tcod"}},commits_count:0,warnings:["Missing classifier 'Framework :: AiiDA'","`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"orange",text:"Other (Database Exporters)",count:1}],pip_install_cmd:"pip install git+https://github.com/aiidateam/aiida-tcod",is_installable:"True"},"aiida-uppasd":{code_home:"https://github.com/uppasd/aiida-uppasd",documentation_url:"https://github.com/uppasd/aiida-uppasd/blob/master/README.md",entry_point_prefix:"uppasd",pip_url:"git+https://github.com/unkcpz/aiida-uppasd",name:"aiida-uppasd",package_name:"aiida_uppasd",hosted_on:"github.com",metadata:{author:"Qichen Xu, Anders Bergman, Anna Delin, Jonathan Chico",author_email:"qichenx@kth.se",version:"0.1.0",description:"Interface for UppASD and AiiDA",classifiers:["Programming Language :: Python","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Framework :: AiiDA"]},aiida_version:">=1.1.0,<2.0.0",entry_points:{"aiida.calculations":{UppASD_core_calculations:"UppASD_AiiDA.calculations.core_calcs:UppASD"},"aiida.parsers":{UppASD_core_parsers:"UppASD_AiiDA.parsers.core_parser:SpinDynamic_core_parser"}},commits_count:0,development_status:"planning",warnings:["Entry point 'UppASD_core_calculations' does not start with prefix 'uppasd.'","Entry point 'UppASD_core_parsers' does not start with prefix 'uppasd.'"],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install git+https://github.com/unkcpz/aiida-uppasd"},"aiida-vasp":{code_home:"https://github.com/aiida-vasp/aiida-vasp",documentation_url:"https://aiida-vasp.readthedocs.io/",entry_point_prefix:"vasp",pip_url:"aiida-vasp",plugin_info:"https://raw.githubusercontent.com/aiida-vasp/aiida-vasp/master/setup.json",name:"aiida-vasp",package_name:"aiida_vasp",hosted_on:"github.com",metadata:{release_date:"2023-07-03",description:"AiiDA plugin for running VASP calculations and workflows.",author_email:"Espen Flage-Larsen <espen.flage-larsen@sigma2.no>",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Physics"],version:"3.0.1"},aiida_version:">=2.4,<3.0",entry_points:{"aiida.calculations":{"vasp.immigrant":{description:["Parse VASP output objects stored in a specified directory.","","    Simulate running the VaspCalculation up to the point where it can be","    retrieved and parsed, then hand over control to the runner for the rest.","","    Usage examples","    --------------","    Immigrant calculation can be perfomed as follows.","","    ::","","       code = Code.get_from_string('vasp@local')","       folder = '/home/username/vasp-calc-dir'","       settings = {'parser_settings': {'add_energies': True,","                                       'add_forces': True,","                                       'electronic_step_energies': True}}","       VaspImmigrant = CalculationFactory('vasp.immigrant')","       builder = VaspImmigrant.get_builder_from_folder(code,","                                                       folder,","                                                       settings=settings)","       submit(builder)","","    Instead of ``builder``, inputs dict is obtained similarly as","","    ::","","       code = Code.get_from_string('vasp@local')","       folder = '/home/username/vasp-calc-dir'","       settings = {'parser_settings': {'add_energies': True,","                                       'add_forces': True,","                                       'electronic_step_energies': True}}","       VaspImmigrant = CalculationFactory('vasp.immigrant')","       inputs = VaspImmigrant.get_inputs_from_folder(code,","                                                     folder,","                                                     settings=settings)","       submit(VaspImmigrant, **inputs)","","    Note","    ----","    The defaul metadata is set automatically as follows::","","       {'options': {'max_wallclock_seconds': 1,","        'resources': {'num_machines': 1, 'num_mpiprocs_per_machine': 1}}}","","    Specific scheduler may require setting ``resources`` differently","    (e.g., sge ``'parallel_env'``).","","    ``get_inputs_from_folder`` and ``get_builder_from_folder`` accept several","    kwargs, see the docstring of ``get_inputs_from_folder``."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"dynamics",required:!1,valid_types:"Dict",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"remote_workdir",required:!1,valid_types:"str",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"},{status:1005,message:"Overflow detected in XML while parsing."}]},class:"aiida_vasp.calcs.immigrant:VaspImmigrant"},"vasp.neb":{description:["NEB calculations using VASP","","    ------------------------------------","    Calculations for performing NEB calculations.","    NEB calculations requires standard VASP inputs, but POSCAR are placed in","    folder names 00, 01, 02... N for N-1 number of images.","","    Input frames should be placed under the ``neb_images`` input namespace as a dictionary like::","      {","          'image_00': structure_1,","          'image_01': structure_2","          ....","      }","","    Output of individual frames are placed in the corresponding namespace under the same convention."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"final_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for the final image."},{name:"initial_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for initial image."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"neb_images",required:!0,valid_types:"StructureData, CifData",info:"Starting structure for the NEB images"},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"dynamics",required:!1,valid_types:"Dict",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"Per-image misc output."},{name:"neb_misc",required:!0,valid_types:"Dict",info:"NEB related data combined for each image"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"structure",required:!0,valid_types:"StructureData",info:"NEB images"},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"Kpoints for each image."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization for each image."},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output file containing the plane wave coefficients."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:333,message:"VASP did not produce any output files and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:352,message:"a file that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure the `neb_data` and `run_status` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1001,message:"parsing a file has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"},{status:1005,message:"Overflow detected in XML while parsing."}]},class:"aiida_vasp.calcs.neb:VaspNEBCalculation"},"vasp.vasp":{description:["General-purpose VASP calculation.","","    ---------------------------------","    By default retrieves only the 'OUTCAR', 'vasprun.xml', 'EIGENVAL', 'DOSCAR'","    and Wannier90 input / output objects. These objects are deleted after parsing.","    Additional retrieve objects can be specified via the","    ``settings['ADDITIONAL_RETRIEVE_TEMPORARY_LIST']`` input. In addition, if you want to keep","    any objects after parsing, put them in ``settings['ADDITIONAL_RETRIEVE_LIST']`` which is empty","    by default.","","    Floating point precision for writing POSCAR objects can be adjusted using","    ``settings['poscar_precision']``, default: 10","","    The following assumes you are familiar with the AiiDA data structures and","    how to set up and run an AiiDA calculation in general.","","    Example usage::","","        from aiida.orm import CalculationFactory, DataFactory","        from aiida.work import submit","","        proc = CalculationFactory('vasp.vasp').process()","        inputs = proc.get_inputs_template()","        inputs.parameter = <Dict with INCAR params>","        inputs.structure = <StructureData>","        inputs.kpoints = <KpointsData>","        inputs.settings = <Dict with parser settings etc.>","        inputs.potential = DataFactory('vasp.potcar').get_potcars_from_structure(structure, ...)","        inputs.code = <Code representing vasp on your cluster>","","        submit(proc, **inputs)","","    Which is very similar to the workchain example.","","    Since we do not want the content parsers to know about the AiiDA infrastructure,","    i.e. processes etc. we have no access to the exit codes defined on the CalcJob.","    We thus have to deal with failures in parsing directly in the write calls here."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"kpoints",required:!0,valid_types:"KpointsData",info:"The kpoints to use (KPOINTS)."},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential",required:!0,valid_types:"PotcarData",info:"The potentials (POTCAR)."},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR)."},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"dynamics",required:!1,valid_types:"Dict",info:"The VASP parameters related to ionic dynamics, e.g. flags to set the selective dynamics"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict",info:"Additional parameters not related to VASP itself."},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:333,message:"VASP did not produce any output and did likely not execute properly."},{status:350,message:"the retrieved folder data node could not be accessed."},{status:351,message:"the retrieved_temporary folder data node could not be accessed."},{status:352,message:"an object that is marked by the parser as critical is missing."},{status:700,message:"Calculation did not reach the end of execution."},{status:701,message:"The electronic structure is not converged."},{status:702,message:"The ionic relaxation is not converged."},{status:703,message:"VASP calculation encountered a critical error: {error_message}."},{status:704,message:"Outputs for diagnosis are missing, please make sure `run_status` and `notifications` quantities are requested for parsing."},{status:1001,message:"parsing an object has failed."},{status:1002,message:"the parser is not able to parse the {quantity} quantity"},{status:1003,message:"the vasprun.xml was truncated and recovery parsing failed to parse at least one of the requested quantities: {quantities}, very likely the VASP calculation did not run properly"},{status:1004,message:"the parser is not able to compose one or more output nodes: {nodes}"},{status:1005,message:"Overflow detected in XML while parsing."}]},class:"aiida_vasp.calcs.vasp:VaspCalculation"},"vasp.vasp2w90":"aiida_vasp.calcs.vasp2w90:Vasp2w90Calculation"},"aiida.cmdline.data":{"vasp-potcar":"aiida_vasp.commands.potcar:potcar"},"aiida.data":{"vasp.archive":"aiida_vasp.data.archive:ArchiveData","vasp.chargedensity":"aiida_vasp.data.chargedensity:ChargedensityData","vasp.potcar":"aiida_vasp.data.potcar:PotcarData","vasp.potcar_file":"aiida_vasp.data.potcar:PotcarFileData","vasp.wavefun":"aiida_vasp.data.wavefun:WavefunData"},"aiida.groups":{"vasp.potcar":"aiida_vasp.data.potcar:PotcarGroup"},"aiida.parsers":{"vasp.neb":"aiida_vasp.parsers.neb:VtstNebParser","vasp.vasp":"aiida_vasp.parsers.vasp:VaspParser","vasp.vasp2w90":"aiida_vasp.parsers.vasp2w90:Vasp2w90Parser"},"aiida.workflows":{"vasp.bands":{description:["Extract the band structure using k-point paths fetched from SeeKpath."],spec:{inputs:[{name:"bands",required:!0,valid_types:"",info:""},{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"restart_folder",required:!0,valid_types:"RemoteData",info:`
            The folder to restart in, which contains the outputs from the prerun to extract the charge density.
            `},{name:"smearing",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:`
            If True, clean the work dir upon the completion of a successfull calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"max_iterations",required:!1,valid_types:"Int",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:""},{name:"settings",required:!1,valid_types:"Dict",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData",info:""}],outputs:[{name:"bands",required:!0,valid_types:"BandsData",info:""},{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the bands workchain"},{status:2001,message:"BandsData not found in exposed_ouputs"}]},class:"aiida_vasp.workchains.bands:BandsWorkChain"},"vasp.converge":{description:["A workchain to perform convergence tests."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"converge",required:!0,valid_types:"",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"verify",required:!0,valid_types:"",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:`
            If True, clean the work dir upon the completion of a successfull calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"max_iterations",required:!1,valid_types:"Int",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData",info:""}],outputs:[{name:"converge",required:!0,valid_types:"",info:""},{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"relax",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the converge workchain"}]},class:"aiida_vasp.workchains.converge:ConvergeWorkChain"},"vasp.immigrant":{description:["Import a VASP run executed in the directory specified by folder_path."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:`
            If True, clean the work dir upon the completion of a successfull calculation.
            `},{name:"folder_path",required:!1,valid_types:"Str",info:"Deprecated."},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"max_iterations",required:!1,valid_types:"Int",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"options",required:!1,valid_types:"Dict",info:""},{name:"potential_family",required:!1,valid_types:"Str",info:""},{name:"potential_mapping",required:!1,valid_types:"Dict",info:""},{name:"remote_workdir",required:!1,valid_types:"str",info:""},{name:"settings",required:!1,valid_types:"Dict",info:""},{name:"use_chgcar",required:!1,valid_types:"Bool",info:`
            If True, WavefunData (of WAVECAR) is attached.
            `},{name:"use_wavecar",required:!1,valid_types:"Bool",info:`
            If True, WavefunData (of WAVECAR) is attached.
            `},{name:"verbose",required:!1,valid_types:"Bool",info:`
            If True, enable more detailed output during workchain execution.
            `}],outputs:[{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."}]},class:"aiida_vasp.workchains.immigrant:VaspImmigrantWorkChain"},"vasp.master":{description:["The master workchain that selects sub workchains to perform necessary calculations."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"converge",required:!0,valid_types:"",info:""},{name:"dos",required:!0,valid_types:"",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"verify",required:!0,valid_types:"",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:""},{name:"extract_bands",required:!1,valid_types:"Bool",info:`
                   Do you want to extract the band structure?
                   `},{name:"extract_dos",required:!1,valid_types:"Bool",info:`
                   Do you want to extract the density of states?
                   `},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"kpoints_distance",required:!1,valid_types:"Float",info:`
                   The maximum distance between k-points in inverse AA.
                   `},{name:"max_iterations",required:!1,valid_types:"Int",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"relax",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData",info:""}],outputs:[{name:"bands",required:!1,valid_types:"",info:""},{name:"dos",required:!1,valid_types:"",info:""}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the master workchain"}]},class:"aiida_vasp.workchains.master:MasterWorkChain"},"vasp.neb":{description:["The NEB workchain.","","    -------------------","    Error handling enriched wrapper around VaspNEBCalculation.","","    Deliberately conserves most of the interface (required inputs) of the VaspNEBCalculation class, but","    makes it possible for a user to interact with a workchain and not a calculation.","","    In addition, implement restarts of calculation when the calculation is net full converged for error handling."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"The `Code` to use for this job."},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"final_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for the final image."},{name:"initial_structure",required:!0,valid_types:"StructureData, CifData",info:"The input structure (POSCAR) for initial image."},{name:"neb_images",required:!0,valid_types:"StructureData, CifData",info:"Starting structure for the NEB images"},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:"The VASP input parameters (INCAR)."},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"charge_density",required:!1,valid_types:"ChargedensityData",info:"The charge density. (CHGCAR)"},{name:"clean_workdir",required:!1,valid_types:"Bool",info:`
            If True, clean the work dir upon the completion of a successfull calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:""},{name:"kpoints_spacing",required:!1,valid_types:"Float",info:"Spacing for the kpoints in units A^-1 * 2pi (CASTEP style `kpoints_mp_spacing`)"},{name:"kpoints_spacing_vasp",required:!1,valid_types:"Float",info:"Spacing for the kpoints in units A^-1 (VASP style)"},{name:"ldau_mapping",required:!1,valid_types:"Dict",info:"Mappings, see the doc string of 'get_ldau_keys'"},{name:"max_iterations",required:!1,valid_types:"Int",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:"A remote folder to restart from if need be"},{name:"settings",required:!1,valid_types:"Dict",info:"Additional parameters not related to VASP itself."},{name:"verbose",required:!1,valid_types:"Bool",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavefunctions",required:!1,valid_types:"WavefunData",info:"The wave function coefficients. (WAVECAR)"}],outputs:[{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"Per-image misc output."},{name:"neb_misc",required:!0,valid_types:"Dict",info:"NEB related data combined for each image"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"structure",required:!0,valid_types:"StructureData",info:"NEB images"},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"Kpoints for each image."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization for each image."},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output file containing the plane wave coefficients."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:401,message:"The maximum number of iterations was exceeded."},{status:402,message:"The process failed for an unknown reason, twice in a row."},{status:501,message:"Unrecoverable error in launched NEB calculations."},{status:700,message:"the user did not supply a potential family name"},{status:701,message:"ValueError was returned from get_potcars_from_structure"},{status:702,message:"the potential does not exist"},{status:703,message:"the exception: {exception} was thrown while massaging the parameters"}]},class:"aiida_vasp.workchains.neb:VaspNEBWorkChain"},"vasp.relax":{description:["Structure relaxation workchain."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"relax",required:!0,valid_types:"",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"verify",required:!0,valid_types:"",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:`
            If True, clean the work dir upon the completion of a successfull calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"max_iterations",required:!1,valid_types:"Int",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData",info:""}],outputs:[{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"relax",required:!0,valid_types:"",info:""},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"the called workchain does not contain the necessary relaxed output structure"},{status:420,message:"no called workchain detected"},{status:500,message:"unknown error detected in the relax workchain"},{status:502,message:"there was an error overriding the parameters"}]},class:"aiida_vasp.workchains.relax:RelaxWorkChain"},"vasp.vasp":{description:["The VASP workchain.","","    -------------------","    Error handling enriched wrapper around VaspCalculation.","","    Deliberately conserves most of the interface (required inputs) of the VaspCalculation class, but","    makes it possible for a user to interact with a workchain and not a calculation.","","    This is intended to be used instead of directly submitting a VaspCalculation,","    so that future features like","    automatic restarting, error checking etc. can be propagated to higher level workchains","    automatically by implementing them here.","","    Handlers are implemented to try fix common problems and improves the robustness.","    Individual handlers can be enabled/disabled by setting the ``handler_overrides`` input port.",'    Additional settings may be passed under the "settings" input, which is also forwarded to the',"    calculations. The avaliable options are:","","    - ``USE_WAVECAR_FOR_RESTART`` wether calculation restarts should use the WAVECAR. The default is ``True``.","","    Usage::","","        from aiida.common.extendeddicts import AttributeDict","        from aiida.work import submit","        basevasp = WorkflowFactory('vasp.vasp')","        inputs = basevasp.get_builder()","        inputs = AttributeDict()","        ## ... set inputs","        submit(basevasp, **inputs)","","    To see a working example, including generation of input nodes from scratch, please","    refer to ``examples/run_vasp_lean.py``."],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:""},{name:"dynamics",required:!0,valid_types:"",info:""},{name:"kpoints",required:!0,valid_types:"KpointsData",info:""},{name:"options",required:!0,valid_types:"Dict",info:""},{name:"parameters",required:!0,valid_types:"Dict",info:""},{name:"potential_family",required:!0,valid_types:"Str",info:""},{name:"potential_mapping",required:!0,valid_types:"Dict",info:""},{name:"structure",required:!0,valid_types:"StructureData, CifData",info:""},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:""},{name:"clean_workdir",required:!1,valid_types:"Bool",info:`
            If True, clean the work dir upon the completion of a successfull calculation.
            `},{name:"handler_overrides",required:!1,valid_types:"Dict",info:"Mapping where keys are process handler names and the values are a boolean, where `True` will enable the corresponding handler and `False` will disable it. This overrides the default value set by the `enabled` keyword of the `process_handler` decorator with which the method is decorated."},{name:"max_iterations",required:!1,valid_types:"Int",info:`
            The maximum number of iterations to perform.
            `},{name:"metadata",required:!1,valid_types:"",info:""},{name:"restart_folder",required:!1,valid_types:"RemoteData",info:`
            The restart folder from a previous workchain run that is going to be used.
            `},{name:"settings",required:!1,valid_types:"Dict",info:""},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"Site magnetization to be used as MAGMOM"},{name:"verbose",required:!1,valid_types:"Bool",info:`
            If True, enable more detailed output during workchain execution.
            `},{name:"wavecar",required:!1,valid_types:"WavefunData",info:""}],outputs:[{name:"custom_outputs",required:!0,valid_types:"",info:""},{name:"misc",required:!0,valid_types:"Dict",info:"The output parameters containing smaller quantities that do not depend on system size."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"bands",required:!1,valid_types:"BandsData",info:"The output band structure."},{name:"born_charges",required:!1,valid_types:"ArrayData",info:"The output Born effective charges."},{name:"charge_density",required:!1,valid_types:"ArrayData",info:"The output charge density."},{name:"chgcar",required:!1,valid_types:"ChargedensityData",info:"The output charge density CHGCAR file."},{name:"dielectrics",required:!1,valid_types:"ArrayData",info:"The output dielectric functions."},{name:"dos",required:!1,valid_types:"ArrayData",info:"The output dos."},{name:"dynmat",required:!1,valid_types:"ArrayData",info:"The output dynamical matrix."},{name:"energies",required:!1,valid_types:"ArrayData",info:"The output total energies."},{name:"forces",required:!1,valid_types:"ArrayData",info:"The output forces."},{name:"hessian",required:!1,valid_types:"ArrayData",info:"The output Hessian matrix."},{name:"kpoints",required:!1,valid_types:"KpointsData",info:"The output k-points."},{name:"magnetization_density",required:!1,valid_types:"ArrayData",info:"The output magnetization density."},{name:"projectors",required:!1,valid_types:"ArrayData",info:"The output projectors of decomposition."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"site_magnetization",required:!1,valid_types:"Dict",info:"The output of the site magnetization"},{name:"stress",required:!1,valid_types:"ArrayData",info:"The output stress."},{name:"structure",required:!1,valid_types:"StructureData",info:"The output structure."},{name:"trajectory",required:!1,valid_types:"TrajectoryData",info:"The output trajectory data."},{name:"wavecar",required:!1,valid_types:"WavefunData",info:"The output plane wave coefficients file."}],exit_codes:[{status:0,message:"the sun is shining"},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:300,message:"the calculation is missing at least one required output in the restart workchain"},{status:301,message:"The sub process excepted."},{status:302,message:"The sub process was killed."},{status:400,message:"the run_calculation step did not successfully add a calculation node to the context"},{status:401,message:"the maximum number of iterations was exceeded"},{status:402,message:"the calculation finished with an unexpected calculation state"},{status:403,message:"the calculation experienced and unexpected failure"},{status:404,message:"the calculation failed to submit, twice in a row"},{status:405,message:"the calculation failed for an unknown reason, twice in a row"},{status:500,message:"Missing critical output for inspecting the status of the calculation."},{status:501,message:"Cannot handle the error - inputs are likely need to be revised manually. Message: {message}"},{status:502,message:"Cannot handle the error - the last calculation did not reach the end of execution."},{status:503,message:"Cannot handle the error - the last calculation did not reach electronic convergence."},{status:504,message:"The ionic relaxation is not converged."},{status:505,message:"At least one of the ionic steps during the relaxation has did not have converged electronic structure."},{status:700,message:"the user did not supply a potential family name"},{status:701,message:"ValueError was returned from get_potcars_from_structure"},{status:702,message:"the potential does not exist"},{status:703,message:"the exception: {exception} was thrown while massaging the parameters"}]},class:"aiida_vasp.workchains.vasp:VaspWorkChain"}},console_scripts:{"mock-vasp":"aiida_vasp.commands.mock_vasp:mock_vasp","mock-vasp-strict":"aiida_vasp.commands.mock_vasp:mock_vasp_strict"}},commits_count:100,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:4},{colorclass:"brown",text:"Parsers",count:3},{colorclass:"red",text:"Data",count:5},{colorclass:"green",text:"Workflows",count:7},{colorclass:"purple",text:"Console scripts",count:2},{colorclass:"orange",text:"Other (Data commands, Groups)",count:2}],pip_install_cmd:"pip install aiida-vasp",is_installable:"True"},"aiida-vibroscopy":{entry_point_prefix:"vibroscopy",plugin_info:"https://raw.githubusercontent.com/bastonero/aiida-vibroscopy/main/pyproject.toml",code_home:"https://github.com/bastonero/aiida-vibroscopy",version_file:"https://raw.githubusercontent.com/bastonero/aiida-vibroscopy/main/src/aiida_vibroscopy/__init__.py",pip_url:"aiida-vibroscopy",documentation_url:"https://aiida-vibroscopy.readthedocs.io/en/latest/",name:"aiida-vibroscopy",package_name:"aiida_vibroscopy",hosted_on:"github.com",metadata:{release_date:"2023-08-10",description:"AiiDA plugin for vibrational spectoscopy using Quantum ESPRESSO.",author_email:"Lorenzo Bastonero <bastonero.lorenzo@gmail.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","License :: Other/Proprietary License","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"1.0.2"},aiida_version:">=2.2.2,<3.0.0",entry_points:{"aiida.data":{"vibroscopy.fp":"aiida_vibroscopy.data.vibro_fp:VibrationalFrozenPhononData","vibroscopy.vibrational":"aiida_vibroscopy.data.vibro_lr:VibrationalData"},"aiida.workflows":{"vibroscopy.dielectric":{description:["Workchain computing different second and third order tensors.","","    It computes the high frequency dielectric tensor, the Born effective charges,","    the non-linear optical susceptibility and Raman tensors","    using homogeneous small electric fields via the electric enthalpy functional."],spec:{inputs:[{name:"central_difference",required:!0,valid_types:"",info:"The inputs for the central difference scheme."},{name:"property",required:!0,valid_types:"str",info:`irValid inputs are: 
 
 * born-chargesValid inputs are: 
 
 * dielectricValid inputs are: 
 
 * nacValid inputs are: 
 
 * becValid inputs are: 
 
 * ramanValid inputs are: 
 
 * susceptibility-derivativeValid inputs are: 
 
 * non-linear-susceptibility`},{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` that will be used to run the electric enthalpy scfs."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"kpoints_parallel_distance",required:!1,valid_types:"Float, NoneType",info:"Distance of the k-points in reciprocal space along the parallel direction of each applied electric field."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parent_scf",required:!1,valid_types:"RemoteData, NoneType",info:"Scf parent folder from where restarting the scfs with electric fields."}],outputs:[{name:"fields_data",required:!0,valid_types:"",info:"Namespace for passing TrajectoryData containing forces and polarization."},{name:"tensors",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric and Born effectivecharges tensors computed in Cartesian coordinates. Depending on the inputs, it can also contain the derivatives of the susceptibility in respect to the atomic positions (called `Raman tensors`) and the non linear optical susceptibility, always expressed in Cartesian coordinates."},{name:"accuracy_order",required:!1,valid_types:"Int",info:""},{name:"critical_electric_field",required:!1,valid_types:"Float",info:""},{name:"electric_field_step",required:!1,valid_types:"Float",info:""},{name:"units",required:!1,valid_types:"Dict",info:"Units of the susceptibility derivatives tensors."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The initial scf work chain failed."},{status:401,message:"The nscf work chain failed."},{status:402,message:"The electric field scf work chain failed for direction {direction}."},{status:403,message:"The numerical derivatives calculation failed."},{status:404,message:"The scf PwBaseWorkChain sub process in iteration returned a non integer total magnetization (threshold exceeded)."}]},class:"aiida_vibroscopy.workflows.dielectric.base:DielectricWorkChain"},"vibroscopy.dielectric.numerical_derivatives":{description:["Workchain carrying out numerical derivatives.","","    It computes the first and second order derivatives","    of forces and polarization in respect to electric field,","    to obtain dielectric tensor, Born effective charges,","    non linear optical susceptibility and Raman tensors.","","    Forces and polarization must be passed as TrajectoryData","    as a dictionary in `data`. Numerical derivatives can have","    different number of evaluation points, depending on order and accuracy.","    The price to pay is the standardization of the structure of","    the dictionary to pass to this namespace.","","    To understand, let's review the approach.In central differencs approach","    we need the evaluation of the function at the value we want","    the derivative (in our case at :math:`\\mathcal{E}=0`,","    E is the electric field), and at","    displaced positions from this value.","    The evaluation of the function at these points will","    have weights (or coefficients), which depend on order and accuracy.","    For example:","","    - :math:`\\frac{df}{dx} = \\frac{ 0.5 \\cdot f(+1.0 \\cdot h) -0.5 \\cdot f(-1.0 \\cdot h) }{h} +\\mathcal{O}(h^2)`","    - :math:`\\frac{d^2 f}{dx^2} = \\frac{ 1.0 \\cdot f(+1.0 \\cdot h) -2.0 \\cdot f(0. \\cdot h) +1.0 \\cdot f(-1.0 \\cdot h) }{h^2} +\\mathcal{O}(h^2)`","","    Referring to the coefficients for each step as :math:`c_i`,","    where `i` is an integer, our convention is","    to put in sequence the Trajectory data with increasing","    numbers as labels, for example:","","    | '0': TrajectoryData for :math:`c_1`,","    | '1': TrajectoryData for :math:`c_{-1}`,","    | '2': TrajectoryData for :math:`c_2`,","    | '3': TrajectoryData for :math:`c_{-2}`,","    | ...","","    This way to creating an analogous of an array with","    coefficients :math:`[c_1,c_{-1},c_2,c_{-2}, \\dots]`.","","    These dictionaries are going to be put as sub-dictionary","    in a general `data` dictionary. Each sub-dict","    has to be put with a key with suffix a number indicating","    which tensor component is referring to.","    In our case, we use a similar Voigt notation.","    Namely we have two cases:","","    * first order derivatives: keys suffices are 0,1,2;","        0 for :math:`[i,x]`, 1 for :math:`[i,y]`, 2 for","        :math:`[i,z]` (with :math:`i={x,y,z}`)","    * second order derivatives: keys suffices are 0,...5;","        0 for :math:`[i,x,x]`, :math:`\\dots` (as in Voigt),","        5 for :math:`[i,x,y]` (with :math:`i={x,y,z}`)","","    The prefix can be anything. Best practice is using ``field_``","    with and underscorre as prefix. The Trajectory data for the","    :math:`c_0` coefficient (i.e. the one with :math:`\\mathcal{E}=0`)","    must be passed with a different key, namely ``null_field``.","    This is to avoid errors and due to the fact that is common","    to the all derivatives."],spec:{inputs:[{name:"central_difference",required:!0,valid_types:"",info:"The inputs for the central difference scheme."},{name:"data",required:!0,valid_types:"",info:"Namespace for passing TrajectoryData containing forces and polarization."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:""},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"tensors",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric and Born effectivecharges tensors computed in Cartesian coordinates. Depending on the inputs, it can also contain the derivatives of the susceptibility in respect to the atomic positions (called `Raman tensors`) and the non linear optical susceptibility, always expressed in Cartesian coordinates."},{name:"units",required:!1,valid_types:"Dict",info:"Units of the susceptibility derivatives tensors."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_vibroscopy.workflows.dielectric.numerical_derivatives:NumericalDerivativesWorkChain"},"vibroscopy.phonons.harmonic":{description:["Workchain for frozen phonons calculations.","","    Non-analytical constants (NAC) and higher order mixed  derivatives are computed","    via finite differences through finite electric fields.","    See :class:`~aiida_vibroscopy.workflows.DielectricWorkChain`","    for more details on how they are carried out."],spec:{inputs:[{name:"phonon",required:!0,valid_types:"Data",info:"Inputs for the `PhononWorkChain` that will beused to calculate the force constants."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"dielectric",required:!1,valid_types:"Data",info:"Inputs for the `DielectricWorkChain` that will beused to calculate the mixed derivatives with electric field."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"phonopy",required:!1,valid_types:"Data",info:"Inputs for the `PhonopyCalculation` that willbe used to calculate the inter-atomic force constants, or for post-processing."}],outputs:[{name:"output_phonon",required:!0,valid_types:"",info:"Outputs of the `PhononWorkChain`."},{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"output_dielectric",required:!1,valid_types:"",info:"Outputs of the `DielectricWorkChain`."},{name:"output_phonopy",required:!1,valid_types:"",info:"Outputs of the post-processing via `phonopy`."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The phonon workchain failed."},{status:401,message:"The dielectric workchain failed."},{status:402,message:"The phonopy calculation failed."}]},class:"aiida_vibroscopy.workflows.phonons.harmonic:HarmonicWorkChain"},"vibroscopy.phonons.phonon":{description:["Class for computing force constants of phonons, without non-analytical corrections."],spec:{inputs:[{name:"scf",required:!0,valid_types:"Data",info:"Inputs for the `PwBaseWorkChain` that will be used to run the electric enthalpy scfs."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"displacement_generator",required:!1,valid_types:"Dict, NoneType",info:`Info for displacements generation. The following flags are allowed:
 distance
 is_plusminus
 is_diagonal
 is_trigonal
 number_of_snapshots
 random_seed
 cutoff_frequency`},{name:"metadata",required:!1,valid_types:"",info:""},{name:"phonopy",required:!1,valid_types:"Data",info:"Inputs for the `PhonopyCalculation` that willbe used to calculate the inter-atomic force constants, or for post-processing."},{name:"primitive_matrix",required:!1,valid_types:"List, NoneType",info:"Primitive matrix that defines the primitive cell from the unitcell."},{name:"supercell_matrix",required:!1,valid_types:"List, NoneType",info:"Supercell matrix that defines the supercell from the unitcell."}],outputs:[{name:"phonopy_data",required:!0,valid_types:"PhonopyData",info:"The phonopy data with supercells displacements, forces to use in the post-processing calculation."},{name:"supercells_forces",required:!0,valid_types:"ArrayData, TrajectoryData",info:"The forces acting on the atoms of each supercell."},{name:"output_phonopy",required:!1,valid_types:"",info:""},{name:"supercells",required:!1,valid_types:"StructureData",info:"The supercells with displacements."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The initial supercell scf work chain failed."},{status:401,message:"The initial PwBaseWorkChain sub process returned a non integer total magnetization."},{status:402,message:"At least one sub processe did not finish successfully."},{status:403,message:"The phonopy calculation did not finish correctly."}]},class:"aiida_vibroscopy.workflows.phonons.base:PhononWorkChain"},"vibroscopy.spectra.intensities_average":{description:["Workchain that computes IR and Raman spatial and q-direction average spectra."],spec:{inputs:[{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"Vibrational data containing force constants or frozen phonons forces, nac parameters and/or susceptibility derivatives."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"parameters",required:!1,valid_types:"Dict",info:"Options for averaging on the non-analytical directions."}],outputs:[{name:"ir_averaged",required:!0,valid_types:"ArrayData",info:"Contains high frequency dielectric tensor computed in Cartesian coordinates."},{name:"raman_averaged",required:!1,valid_types:"ArrayData",info:"Contains Born effective charges tensors computed in Cartesian coordinates."},{name:"units",required:!1,valid_types:"Dict",info:"Units of intensities and frequencies."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_vibroscopy.workflows.spectra.intensities_average:IntensitiesAverageWorkChain"},"vibroscopy.spectra.iraman":{description:["Workchain for automatically compute IR and Raman spectra using finite displacements and fields.","","    For other details of the sub-workchains used, see also:","        * :class:`~aiida_vibroscopy.workflows.dielectric.base.DielectricWorkChain` for finite fields","        * :class:`~aiida_vibroscopy.workflows.phonons.base.PhononWorkChain` for finite displacements"],spec:{inputs:[{name:"dielectric",required:!0,valid_types:"Data",info:"Inputs for the `DielectricWorkChain` that will beused to calculate the mixed derivatives with electric field."},{name:"phonon",required:!0,valid_types:"Data",info:"Inputs for the `PhononWorkChain` that will beused to calculate the force constants."},{name:"settings",required:!0,valid_types:"",info:"Options for how to run the workflow."},{name:"structure",required:!0,valid_types:"StructureData",info:""},{name:"symmetry",required:!0,valid_types:"",info:"Namespace for symmetry related inputs."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation will be cleaned at the end of execution."},{name:"intensities_average",required:!1,valid_types:"Data",info:"Inputs for the `IntensitiesAverageWorkChain` that willbe used to run the average calculation over intensities."},{name:"metadata",required:!1,valid_types:"",info:""}],outputs:[{name:"output_phonon",required:!0,valid_types:"",info:"Outputs of the `PhononWorkChain`."},{name:"vibrational_data",required:!0,valid_types:"VibrationalData, VibrationalFrozenPhononData",info:"The phonopy data with supercells displacements, forces and (optionally)nac parameters to use in the post-processing calculation."},{name:"fake",required:!1,valid_types:"",info:""},{name:"output_dielectric",required:!1,valid_types:"",info:"Outputs of the `DielectricWorkChain`."},{name:"output_intensities_average",required:!1,valid_types:"",info:"Intensities average over space and q-points."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:400,message:"The averaging procedure for intensities had an unexpected error."},{status:401,message:"The averaging procedure for intensities had an unexpected error."}]},class:"aiida_vibroscopy.workflows.spectra.iraman:IRamanSpectraWorkChain"}}},commits_count:71,development_status:"beta",summaryinfo:[{colorclass:"red",text:"Data",count:2},{colorclass:"green",text:"Workflows",count:6}],pip_install_cmd:"pip install aiida-vibroscopy",is_installable:"True"},"aiida-wannier90":{code_home:"https://github.com/aiidateam/aiida-wannier90",documentation_url:"https://aiida-wannier90.readthedocs.io/",entry_point_prefix:"wannier90",pip_url:"aiida-wannier90",plugin_info:"https://raw.github.com/aiidateam/aiida-wannier90/master/setup.json",name:"aiida-wannier90",package_name:"aiida_wannier90",hosted_on:"github.com",metadata:{release_date:"2023-07-03",description:"AiiDA Plugin for the Wannier90 code",author:"Junfeng Qiao, Dominik Gresch, Antimo Marrazzo, Daniel Marchand, Giovanni Pizzi, Norma Rivano, The AiiDA team",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.1.0"},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{"wannier90.postw90":{description:["Plugin for Wannier90.","","    Wannier90 is a code for computing maximally-localized Wannier functions.","    See http://www.wannier.org/ for more details."],spec:{inputs:[{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the Wannier90 code"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``RemoteData`` possibly stored in a remote computer."},{name:"structure",required:!0,valid_types:"StructureData",info:"input crystal structure"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"A list of k-points along a path to be used for bands interpolation; it should contain `labels`. Specify either this or `kpoint_path`."},{name:"clean_workdir",required:!1,valid_types:"Bool",info:"If `True`, work directories of all called calculation jobs will be cleaned at the end of execution."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"kpoint_path",required:!1,valid_types:"Dict, NoneType",info:"Description of the k-points path to be used for bands interpolation; it should contain two properties: a list ``path`` of length-2 tuples with the labels of the endpoints of the path; and a dictionary ``point_coords`` giving the scaled coordinates for each high-symmetry endpoint."},{name:"kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"k-point mesh used in the NSCF calculation."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"projections",required:!1,valid_types:"OrbitalData, Dict, List, NoneType",info:"Starting projections for the Wannierisation procedure."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional settings to manage the Wannier90 calculation."}],outputs:[{name:"boltzwann",required:!0,valid_types:"",info:""},{name:"output_parameters",required:!0,valid_types:"Dict",info:"The ``output_parameters`` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"interpolated_bands",required:!1,valid_types:"BandsData",info:"The interpolated band structure by Wannier90 (if any)."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required stdout output file."},{status:300,message:"A Wannier90 error file (.werr) has been found."},{status:400,message:'The string "Exiting..." has been found in the Wannier90 output (some partial output might have been parsed).'},{status:401,message:"An error related to bvectors has been found in the Wannier90 output."},{status:402,message:"Energy window contains fewer states than number of target WFs."},{status:403,message:"Error plotting Wanier functions in cube format."},{status:404,message:"The stdout output file was incomplete probably because the calculation got interrupted."},{status:405,message:"Some output files were missing probably because the calculation got interrupted."},{status:406,message:"The retrieved temporary folder could not be accessed."}]},class:"aiida_wannier90.calculations:Postw90Calculation"},"wannier90.wannier90":{description:["Plugin for Wannier90.","","    Wannier90 is a code for computing maximally-localized Wannier functions.","    See http://www.wannier.org/ for more details."],spec:{inputs:[{name:"kpoints",required:!0,valid_types:"KpointsData",info:"k-point mesh used in the NSCF calculation."},{name:"parameters",required:!0,valid_types:"Dict",info:"Input parameters for the Wannier90 code"},{name:"structure",required:!0,valid_types:"StructureData",info:"input crystal structure"},{name:"bands_kpoints",required:!1,valid_types:"KpointsData, NoneType",info:"A list of k-points along a path to be used for bands interpolation; it should contain `labels`. Specify either this or `kpoint_path`."},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"kpoint_path",required:!1,valid_types:"Dict, NoneType",info:"Description of the k-points path to be used for bands interpolation; it should contain two properties: a list ``path`` of length-2 tuples with the labels of the endpoints of the path; and a dictionary ``point_coords`` giving the scaled coordinates for each high-symmetry endpoint."},{name:"local_input_folder",required:!1,valid_types:"FolderData, NoneType",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``FolderData`` stored in the AiiDA repository."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"projections",required:!1,valid_types:"OrbitalData, Dict, List, NoneType",info:"Starting projections for the Wannierisation procedure."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."},{name:"remote_input_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Get input files (``.amn``, ``.mmn``, ...) from a class ``RemoteData`` possibly stored in a remote computer."},{name:"settings",required:!1,valid_types:"Dict, NoneType",info:"Additional settings to manage the Wannier90 calculation."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"The ``output_parameters`` output node of the successful calculation."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"interpolated_bands",required:!1,valid_types:"BandsData",info:"The interpolated band structure by Wannier90 (if any)."},{name:"nnkp_file",required:!1,valid_types:"SinglefileData",info:"The ``.nnkp`` file, produced only in -pp (postproc) mode."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"},{status:200,message:"The retrieved folder data node could not be accessed."},{status:210,message:"The retrieved folder did not contain the required stdout output file."},{status:300,message:"A Wannier90 error file (.werr) has been found."},{status:400,message:'The string "Exiting..." has been found in the Wannier90 output (some partial output might have been parsed).'},{status:401,message:"An error related to bvectors has been found in the Wannier90 output."},{status:402,message:"Energy window contains fewer states than number of target WFs."},{status:403,message:"Error plotting Wanier functions in cube format."},{status:404,message:"The stdout output file was incomplete probably because the calculation got interrupted."}]},class:"aiida_wannier90.calculations:Wannier90Calculation"}},"aiida.parsers":{"wannier90.postw90":"aiida_wannier90.parsers:Postw90Parser","wannier90.wannier90":"aiida_wannier90.parsers:Wannier90Parser"},"aiida.workflows":{"wannier90.minimal":{description:["Workchain to run a full stack of Quantum ESPRESSO + Wannier90 for GaAs.","","    Note that this is mostly to be used as an example, as there is no","    error checking and runs directly Quantum ESPRESSO calculations rather","    than the base workflows."],spec:{inputs:[{name:"kpoint_path",required:!0,valid_types:"Dict",info:"The kpoints path for the NSCF run and Wannierisation."},{name:"kpoints_nscf",required:!0,valid_types:"KpointsData",info:"The kpoints for the NSCF run and Wannierisation."},{name:"kpoints_scf",required:!0,valid_types:"KpointsData",info:"The kpoints for the SCF run."},{name:"projections",required:!0,valid_types:"OrbitalData",info:"The projections for the Wannierisation."},{name:"pseudo_family",required:!0,valid_types:"Str",info:"The name of a pseudopotential family to use."},{name:"pw2wannier90_code",required:!0,valid_types:"Code",info:"The `pw2wannier90.x` code to use for the `Pw2Wannier90Calculation`s."},{name:"pw_code",required:!0,valid_types:"Code",info:"The `pw.x` code to use for the `PwCalculation`s."},{name:"structure",required:!0,valid_types:"StructureData",info:"The input structure."},{name:"wannier_code",required:!0,valid_types:"Code",info:"The `wannier90.x` code to use for the `Wannier90Calculation`s."},{name:"max_wallclock_seconds",required:!1,valid_types:"Int, NoneType",info:"Maximum wallclock time in seconds"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"num_machines",required:!1,valid_types:"Int, NoneType",info:"The number of machines (nodes) to use"}],outputs:[{name:"matrices_folder",required:!0,valid_types:"FolderData",info:""},{name:"nnkp_file",required:!0,valid_types:"SinglefileData",info:""},{name:"nscf_output",required:!0,valid_types:"Dict",info:""},{name:"p2wannier_output",required:!0,valid_types:"Dict",info:""},{name:"pw2wan_remote_folder",required:!0,valid_types:"RemoteData",info:""},{name:"scf_output",required:!0,valid_types:"Dict",info:""},{name:"wannier_bands",required:!0,valid_types:"BandsData",info:""}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."}]},class:"aiida_wannier90.workflows.minimal:MinimalW90WorkChain"}}},commits_count:20,development_status:"stable",summaryinfo:[{colorclass:"blue",text:"Calculations",count:2},{colorclass:"brown",text:"Parsers",count:2},{colorclass:"green",text:"Workflows",count:1}],pip_install_cmd:"pip install aiida-wannier90",is_installable:"True"},"aiida-wannier90-workflows":{code_home:"https://github.com/aiidateam/aiida-wannier90-workflows",development_status:"stable",entry_point_prefix:"wannier90_workflows",pip_url:"aiida-wannier90-workflows",plugin_info:"https://raw.github.com/aiidateam/aiida-wannier90-workflows/master/setup.json",name:"aiida-wannier90-workflows",package_name:"aiida_wannier90_workflows",hosted_on:"github.com",metadata:{release_date:"2023-07-04",description:"Advanced AiiDA workflows for Wannier90",author:"Junfeng Qiao, Antimo Marrazzo, Giovanni Pizzi",classifiers:["Development Status :: 5 - Production/Stable","Environment :: Plugins","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: POSIX :: Linux","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Physics"],version:"2.1.0"},aiida_version:">=2.0,<3",entry_points:{"aiida.calculations":{"wannier90_workflows.split":"aiida_wannier90_workflows.calculations.split:Wannier90SplitCalculation"},"aiida.parsers":{"wannier90_workflows.split":"aiida_wannier90_workflows.parsers.split:Wannier90SplitParser"},"aiida.workflows":{"wannier90_workflows.bands":"aiida_wannier90_workflows.workflows.bands:Wannier90BandsWorkChain","wannier90_workflows.base.open_grid":"aiida_wannier90_workflows.workflows.base.open_grid:OpenGridBaseWorkChain","wannier90_workflows.base.projwfc":"aiida_wannier90_workflows.workflows.base.projwfc:ProjwfcBaseWorkChain","wannier90_workflows.base.pw2wannier90":"aiida_wannier90_workflows.workflows.base.pw2wannier90:Pw2wannier90BaseWorkChain","wannier90_workflows.base.wannier90":"aiida_wannier90_workflows.workflows.base.wannier90:Wannier90BaseWorkChain","wannier90_workflows.open_grid":"aiida_wannier90_workflows.workflows.open_grid:Wannier90OpenGridWorkChain","wannier90_workflows.optimize":"aiida_wannier90_workflows.workflows.optimize:Wannier90OptimizeWorkChain","wannier90_workflows.projwfcbands":"aiida_wannier90_workflows.workflows.projwfcbands:ProjwfcBandsWorkChain","wannier90_workflows.split":"aiida_wannier90_workflows.workflows.split:Wannier90SplitWorkChain","wannier90_workflows.wannier90":"aiida_wannier90_workflows.workflows.wannier90:Wannier90WorkChain"},console_scripts:{"aiida-wannier90-workflows":"aiida_wannier90_workflows.cli:cmd_root"}},commits_count:40,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:10},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install aiida-wannier90-workflows",is_installable:"True",errors:["Failed to fetch entry point metadata for package aiida_wannier90_workflows",`<pre>Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'Protect' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 135, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 87, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 187, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/bands.py", line 50, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/open_grid.py", line 45, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier90.py", line 109, in define
    spec.inputs["nscf"]["pw"].validator = PwCalculation.validate_inputs_base
AttributeError: type object 'PwCalculation' has no attribute 'validate_inputs_base'
</pre>`,"Failed to fetch entry point metadata for package aiida_wannier90_workflows",`<pre>Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'Protect' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 135, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 87, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 187, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/bands.py", line 50, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/open_grid.py", line 45, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier90.py", line 109, in define
    spec.inputs["nscf"]["pw"].validator = PwCalculation.validate_inputs_base
AttributeError: type object 'PwCalculation' has no attribute 'validate_inputs_base'
</pre>`,"Failed to fetch entry point metadata for package aiida_wannier90_workflows",`<pre>Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'Protect' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 135, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 87, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 187, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/bands.py", line 50, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/open_grid.py", line 45, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier90.py", line 109, in define
    spec.inputs["nscf"]["pw"].validator = PwCalculation.validate_inputs_base
AttributeError: type object 'PwCalculation' has no attribute 'validate_inputs_base'
</pre>`,"Failed to fetch entry point metadata for package aiida_wannier90_workflows",`<pre>Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'Protect' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 135, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 87, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 187, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/bands.py", line 50, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/open_grid.py", line 45, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier90.py", line 109, in define
    spec.inputs["nscf"]["pw"].validator = PwCalculation.validate_inputs_base
AttributeError: type object 'PwCalculation' has no attribute 'validate_inputs_base'
</pre>`,"Failed to fetch entry point metadata for package aiida_wannier90_workflows",`<pre>Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'Protect' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1130, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1055, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1404, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 760, in invoke
    return __callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 135, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 87, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 187, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/bands.py", line 50, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/open_grid.py", line 45, in define
    super().define(spec)
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier90.py", line 109, in define
    spec.inputs["nscf"]["pw"].validator = PwCalculation.validate_inputs_base
AttributeError: type object 'PwCalculation' has no attribute 'validate_inputs_base'
</pre>`]},"aiida-wien2k":{code_home:"https://github.com/rubel75/aiida-wien2k",entry_point_prefix:"wien2k",name:"aiida-wien2k",package_name:"aiida_wien2k",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:7,development_status:"planning",warnings:["Cannot fetch all data from PyPI and missing plugin_info key!","AiiDA version not found"],summaryinfo:[],pip_install_cmd:"See source code repository."},"aiida-yambo":{code_home:"https://github.com/yambo-code/yambo-aiida/",development_status:"stable",entry_point_prefix:"yambo",pip_url:"aiida-yambo",plugin_info:"https://raw.github.com/yambo-code/yambo-aiida/master/setup.json",name:"aiida-yambo",package_name:"aiida_yambo",hosted_on:"github.com",metadata:{release_date:"2020-11-05",description:"YAMBO plugin and workflows for AiiDA",author:"Miki Bonacci, Michael Atambo, Antimo Marrazzo, Prandini Gianluca",author_email:"miki.bonacci@unimore.it",license:"MIT",home_page:"https://github.com/yambo-code/yambo-aiida",classifiers:["Environment :: Plugins","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Topic :: Scientific/Engineering :: Physics"],version:"1.3.0"},aiida_version:">=1.0.0a2",entry_points:{"aiida.calculations":{"yambo.yambo":{description:["AiiDA plugin for the Yambo code.","    For more information, refer to http://www.yambo-code.org/","    https://github.com/yambo-code/yambo-aiida and http://aiida-yambo.readthedocs.io/en/latest/"],spec:{inputs:[{name:"code",required:!0,valid_types:"Code",info:"Use a main code for yambo calculation"},{name:"parameters",required:!0,valid_types:"Dict",info:"Use a node that specifies the input parameters"},{name:"parent_folder",required:!0,valid_types:"RemoteData",info:'Use a remote folder as parent folder (for "restarts and similar"'},{name:"settings",required:!0,valid_types:"Dict",info:"Use an additional node for special settings"},{name:"metadata",required:!1,valid_types:"",info:""},{name:"precode_parameters",required:!1,valid_types:"Dict",info:"Use a node that specifies the input parameters for the yambo precode"},{name:"preprocessing_code",required:!1,valid_types:"Code",info:"Use a preprocessing code for starting yambo"}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"returns the output parameters"},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"array_alpha",required:!1,valid_types:"ArrayData",info:"returns the alpha array"},{name:"array_alpha_array",required:!1,valid_types:"ArrayData",info:"returns the alpha array"},{name:"array_alpha_bands",required:!1,valid_types:"ArrayData",info:"returns the alpha array bands"},{name:"array_eels",required:!1,valid_types:"ArrayData",info:"returns the eels array"},{name:"array_eps",required:!1,valid_types:"ArrayData",info:"returns the eps array"},{name:"array_ndb",required:!1,valid_types:"ArrayData",info:"returns the array for ndb"},{name:"array_ndb_HFlocXC",required:!1,valid_types:"ArrayData",info:"returns the array ndb for HFlocXC"},{name:"array_ndb_QP",required:!1,valid_types:"ArrayData",info:"returns the array for ndbQP"},{name:"array_qp",required:!1,valid_types:"ArrayData",info:"returns the quasiparticle array band structure"},{name:"bands_quasiparticle",required:!1,valid_types:"BandsData",info:"returns the quasiparticle band structure"},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."},{name:"system_info",required:!1,valid_types:"Dict",info:"returns some system information after a p2y"}],exit_codes:[{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:500,message:"The retrieved folder data node could not be accessed."},{status:501,message:"time exceeded the max walltime"},{status:502,message:"failed calculation for some reason: could be a low number of conduction bands"},{status:503,message:"Unexpected behavior of YamboFolder"},{status:504,message:"parallelization error"},{status:505,message:"general memory error"},{status:506,message:"x_par allocation memory error"}]},class:"aiida_yambo.calculations.yambo:YamboCalculation"}},"aiida.data":{},"aiida.parsers":{"yambo.yambo":"aiida_yambo.parsers.parsers:YamboParser"}},commits_count:75,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1}],pip_install_cmd:"pip install aiida-yambo",is_installable:"True"},"aiida-yambo-wannier90":{code_home:"https://github.com/aiidaplugins/aiida-yambo-wannier90",entry_point_prefix:"yambo_wannier90",pip_url:"aiida-yambo-wannier90",plugin_info:"https://raw.githubusercontent.com/aiidaplugins/aiida-yambo-wannier90/main/pyproject.toml",documentation_url:"https://aiida-yambo-wannier90.readthedocs.io/en/latest/",version_file:"https://raw.githubusercontent.com/aiidaplugins/aiida-yambo-wannier90/main/aiida_yambo_wannier90/__init__.py",name:"aiida-yambo-wannier90",package_name:"aiida_yambo_wannier90",hosted_on:"github.com",metadata:{release_date:"2022-07-06",description:"Plugin to combine Wannier90 interpolations with GW corrections computed by Yambo",author:"The AiiDA Team",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python"],version:"0.1.0b0"},aiida_version:">=1.6.4,<3",entry_points:{"aiida.calculations":{"yambo_wannier90.gw2wannier90":"aiida_yambo_wannier90.calculations.gw2wannier90:Gw2wannier90Calculation"},"aiida.parsers":{"yambo_wannier90.gw2wannier90":"aiida_yambo_wannier90.parsers.gw2wannier90:Gw2wannier90Parser"},"aiida.workflows":{yambo_wannier90:"aiida_yambo_wannier90.workflows:YamboWannier90WorkChain"},console_scripts:{"aiida-yambo-wannier90":"aiida_yambo_wannier90.cli:cmd_root"}},commits_count:0,development_status:"beta",summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"green",text:"Workflows",count:1},{colorclass:"purple",text:"Console scripts",count:1}],pip_install_cmd:"pip install --pre aiida-yambo-wannier90",is_installable:"True",errors:["Failed to fetch entry point metadata for package aiida_yambo_wannier90",`<pre>Failed to load entry point 'yambo_wannier90.gw2wannier90':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 209, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/reentry/entrypoint.py", line 38, in load
    module = import_module(self.module_name)
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_yambo_wannier90/calculations/gw2wannier90.py", line 10, in <module>
    from aiida_wannier90_workflows.utils.str import removesuffix
ModuleNotFoundError: No module named 'aiida_wannier90_workflows.utils'

/opt/conda/lib/python3.8/site-packages/aiida_quantumespresso/workflows/pw/band_structure.py:38: AiidaDeprecationWarning: The \`PwBandStructureWorkChain\` has been deprecated in favor of the \`PwBandsWorkChain\` and will be removed in \`v4.0.0\`
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/aiida_quantumespresso/workflows/functions/seekpath_structure_analysis.py:8: FutureWarning: This module is deprecated and will be removed soon.
Please use instead the new module:
from aiida_quantumespresso.calculations.functions.seekpath_structure_analysis import seekpath_structure_analysis
Or use the entry point with the factory: CalculationFactory('quantumespresso.seekpath_structure_analysis')
  warnings.warn(
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 177, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'ProcessStateMachineMeta' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 78, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 72, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier.py", line 42, in define
    default=orm.Bool(False),
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/base.py", line 33, in __init__
    super().__init__(**kwargs)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 182, in __init__
    backend = backend or get_manager().get_backend()
  File "/opt/conda/lib/python3.8/site-packages/aiida/manage/manager.py", line 188, in get_backend
    self._load_backend()
  File "/opt/conda/lib/python3.8/site-packages/aiida/manage/manager.py", line 120, in _load_backend
    raise ConfigurationError(
aiida.common.exceptions.ConfigurationError: Could not determine the current profile. Consider loading a profile using \`aiida.load_profile()\`.
</pre>`,"Failed to fetch entry point metadata for package aiida_yambo_wannier90",`<pre>Failed to load entry point 'yambo_wannier90.gw2wannier90':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 209, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/reentry/entrypoint.py", line 38, in load
    module = import_module(self.module_name)
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_yambo_wannier90/calculations/gw2wannier90.py", line 10, in <module>
    from aiida_wannier90_workflows.utils.str import removesuffix
ModuleNotFoundError: No module named 'aiida_wannier90_workflows.utils'

/opt/conda/lib/python3.8/site-packages/aiida_quantumespresso/workflows/pw/band_structure.py:38: AiidaDeprecationWarning: The \`PwBandStructureWorkChain\` has been deprecated in favor of the \`PwBandsWorkChain\` and will be removed in \`v4.0.0\`
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/aiida_quantumespresso/workflows/functions/seekpath_structure_analysis.py:8: FutureWarning: This module is deprecated and will be removed soon.
Please use instead the new module:
from aiida_quantumespresso.calculations.functions.seekpath_structure_analysis import seekpath_structure_analysis
Or use the entry point with the factory: CalculationFactory('quantumespresso.seekpath_structure_analysis')
  warnings.warn(
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 177, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'ProcessStateMachineMeta' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 78, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 72, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier.py", line 42, in define
    default=orm.Bool(False),
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/base.py", line 33, in __init__
    super().__init__(**kwargs)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 182, in __init__
    backend = backend or get_manager().get_backend()
  File "/opt/conda/lib/python3.8/site-packages/aiida/manage/manager.py", line 188, in get_backend
    self._load_backend()
  File "/opt/conda/lib/python3.8/site-packages/aiida/manage/manager.py", line 120, in _load_backend
    raise ConfigurationError(
aiida.common.exceptions.ConfigurationError: Could not determine the current profile. Consider loading a profile using \`aiida.load_profile()\`.
</pre>`,"Failed to fetch entry point metadata for package aiida_yambo_wannier90",`<pre>Failed to load entry point 'yambo_wannier90.gw2wannier90':
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/aiida/plugins/entry_point.py", line 209, in load_entry_point
    loaded_entry_point = entry_point.load()
  File "/opt/conda/lib/python3.8/site-packages/reentry/entrypoint.py", line 38, in load
    module = import_module(self.module_name)
  File "/opt/conda/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/conda/lib/python3.8/site-packages/aiida_yambo_wannier90/calculations/gw2wannier90.py", line 10, in <module>
    from aiida_wannier90_workflows.utils.str import removesuffix
ModuleNotFoundError: No module named 'aiida_wannier90_workflows.utils'

/opt/conda/lib/python3.8/site-packages/aiida_quantumespresso/workflows/pw/band_structure.py:38: AiidaDeprecationWarning: The \`PwBandStructureWorkChain\` has been deprecated in favor of the \`PwBandsWorkChain\` and will be removed in \`v4.0.0\`
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/aiida_quantumespresso/workflows/functions/seekpath_structure_analysis.py:8: FutureWarning: This module is deprecated and will be removed soon.
Please use instead the new module:
from aiida_quantumespresso.calculations.functions.seekpath_structure_analysis import seekpath_structure_analysis
Or use the entry point with the factory: CalculationFactory('quantumespresso.seekpath_structure_analysis')
  warnings.warn(
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 177, in spec
    return cls.__getattribute__(cls, '_spec')
AttributeError: 'ProcessStateMachineMeta' object has no attribute '_spec'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./bin/analyze_entrypoints.py", line 189, in <module>
    cli()  # pylint: disable=no-value-for-parameter
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "./bin/analyze_entrypoints.py", line 179, in cli
    result[ep_group] = document_entry_point_group(ep_group)
  File "./bin/analyze_entrypoints.py", line 68, in document_entry_point_group
    process_info = document_entry_point(entry_point_group, entry_point)
  File "./bin/analyze_entrypoints.py", line 94, in document_entry_point
    return document_process_info(plugin)
  File "./bin/analyze_entrypoints.py", line 114, in document_process_info
    spec=document_process_spec(process.spec()), description=docstring
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/workchains/workchain.py", line 78, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/aiida/engine/processes/process.py", line 72, in spec
    return super().spec()  # type: ignore[return-value]
  File "/opt/conda/lib/python3.8/site-packages/plumpy/processes.py", line 182, in spec
    cls.define(cls._spec)  # type: ignore
  File "/opt/conda/lib/python3.8/site-packages/aiida_wannier90_workflows/workflows/wannier.py", line 42, in define
    default=orm.Bool(False),
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/data/base.py", line 33, in __init__
    super().__init__(**kwargs)
  File "/opt/conda/lib/python3.8/site-packages/aiida/orm/nodes/node.py", line 182, in __init__
    backend = backend or get_manager().get_backend()
  File "/opt/conda/lib/python3.8/site-packages/aiida/manage/manager.py", line 188, in get_backend
    self._load_backend()
  File "/opt/conda/lib/python3.8/site-packages/aiida/manage/manager.py", line 120, in _load_backend
    raise ConfigurationError(
aiida.common.exceptions.ConfigurationError: Could not determine the current profile. Consider loading a profile using \`aiida.load_profile()\`.
</pre>`]},"aiida-yascheduler":{code_home:"https://github.com/tilde-lab/yascheduler",documentation_url:"https://github.com/tilde-lab/yascheduler",entry_point_prefix:"yascheduler",pip_url:"yascheduler",plugin_info:"https://raw.githubusercontent.com/tilde-lab/yascheduler/master/setup.json",name:"aiida-yascheduler",package_name:"aiida_yascheduler",hosted_on:"github.com",metadata:{release_date:"2023-07-29",description:"Yet another computing scheduler and cloud orchestration engine",author:"Andrey Sobolev",author_email:"Evgeny Blokhin <eb@tilde.pro>, Sergei Korolev <knopki@duck.com>",classifiers:["Development Status :: 4 - Beta","Framework :: AiiDA","Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Chemistry","Topic :: Scientific/Engineering :: Information Analysis","Topic :: Scientific/Engineering :: Physics","Topic :: Software Development :: Libraries :: Python Modules"],version:"1.2.0"},aiida_version:null,entry_points:{"aiida.schedulers":{yascheduler:"yascheduler.aiida_plugin:YaScheduler"},console_scripts:{yainit:"yascheduler.utils:init",yanodes:"yascheduler.utils:show_nodes",yascheduler:"yascheduler.utils:daemonize",yasetnode:"yascheduler.utils:manage_node",yastatus:"yascheduler.utils:check_status",yasubmit:"yascheduler.utils:submit"}},commits_count:56,development_status:"beta",warnings:["AiiDA version not found"],summaryinfo:[{colorclass:"purple",text:"Console scripts",count:6},{colorclass:"orange",text:"Other (Schedulers)",count:1}],pip_install_cmd:"pip install yascheduler",is_installable:"True",errors:["Failed to import package aiida_yascheduler",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
ModuleNotFoundError: No module named 'aiida_yascheduler'
</pre>`,"Failed to import package aiida_yascheduler",`<pre>Traceback (most recent call last):
  File "<string>", line 1, in <module>
ModuleNotFoundError: No module named 'aiida_yascheduler'
</pre>`]},"aiida-z2pack":{code_home:"https://github.com/AntimoMarrazzo/aiida-z2pack",entry_point_prefix:"z2pack",pip_url:"git+https://github.com/AntimoMarrazzo/aiida-z2pack",name:"aiida-z2pack",package_name:"aiida_z2pack",hosted_on:"github.com",metadata:{},aiida_version:null,entry_points:{},commits_count:18,development_status:"planning",errors:["Unable to retrieve plugin info from: https://raw.githubusercontent.com/antimomarrazzo/aiida-z2pack/master/setup.json.Please check the URL of your plugin in the registry yaml."],warnings:["AiiDA version not found"],summaryinfo:[],pip_install_cmd:"pip install git+https://github.com/AntimoMarrazzo/aiida-z2pack"},"aiida-zeopp":{code_home:"https://github.com/lsmo-epfl/aiida-zeopp",development_status:"stable",entry_point_prefix:"zeopp",pip_url:"aiida-zeopp",plugin_info:"https://raw.github.com/lsmo-epfl/aiida-zeopp/master/setup.json",name:"aiida-zeopp",package_name:"aiida_zeopp",hosted_on:"github.com",metadata:{release_date:"2023-08-26",description:"AiiDA plugin for zeo++",author_email:"Leopold Talirz <leopold.talirz@epfl.ch>, Miriam Pougin <miriam.pougin@epfl.ch>",classifiers:["Development Status :: 5 - Production/Stable","Framework :: AiiDA","License :: OSI Approved :: MIT License","Programming Language :: Python","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],version:"2.0.0"},aiida_version:">=2.3,<3.0",entry_points:{"aiida.calculations":{"zeopp.network":{description:["AiiDA calculation plugin for the zeo++ network binary"],spec:{inputs:[{name:"parameters",required:!0,valid_types:"NetworkParameters",info:"command line parameters for zeo++"},{name:"structure",required:!0,valid_types:"CifData",info:"input structure to be analyzed"},{name:"atomic_radii",required:!1,valid_types:"SinglefileData, NoneType",info:"atomic radii file"},{name:"code",required:!1,valid_types:"AbstractCode, NoneType",info:"The `Code` to use for this job. This input is required, unless the `remote_folder` input is specified, which means an existing job is being imported and no code will actually be run."},{name:"metadata",required:!1,valid_types:"",info:""},{name:"monitors",required:!1,valid_types:"Dict",info:"Add monitoring functions that can inspect output files while the job is running and decide to prematurely terminate the job."},{name:"remote_folder",required:!1,valid_types:"RemoteData, NoneType",info:"Remote directory containing the results of an already completed calculation job without AiiDA. The inputs should be passed to the `CalcJob` as normal but instead of launching the actual job, the engine will recreate the input files and then proceed straight to the retrieve step where the files of this `RemoteData` will be retrieved as if it had been actually launched through AiiDA. If a parser is defined in the inputs, the results are parsed and attached as output nodes as usual."}],outputs:[{name:"output_parameters",required:!0,valid_types:"Dict",info:"key-value pairs parsed from zeo++ output file(s)."},{name:"remote_folder",required:!0,valid_types:"RemoteData",info:"Input files necessary to run the process will be stored in this folder node."},{name:"retrieved",required:!0,valid_types:"FolderData",info:"Files that are retrieved by the daemon will be stored in this node. By default the stdout and stderr of the scheduler will be added, but one can add more by specifying them in `CalcInfo.retrieve_list`."},{name:"block",required:!1,valid_types:"SinglefileData",info:"Blocked pockets fileoutput file."},{name:"remote_stash",required:!1,valid_types:"RemoteStashData",info:"Contents of the `stash.source_list` option are stored in this remote folder after job completion."}],exit_codes:[{status:0,message:"Calculation completed successfully."},{status:1,message:"The process has failed with an unspecified error."},{status:2,message:"The process failed with legacy failure mode."},{status:10,message:"The process returned an invalid output."},{status:11,message:"The process did not register a required output."},{status:100,message:"The process did not have the required `retrieved` output."},{status:101,message:"Not all expected output files were found."},{status:102,message:"Empty block file. This indicates the calculation of blocked pockets did not finish."},{status:110,message:"The job ran out of memory."},{status:120,message:"The job ran out of walltime."},{status:131,message:"The specified account is invalid."},{status:140,message:"The node running the job failed."},{status:150,message:"{message}"}]},class:"aiida_zeopp.calculations.network:NetworkCalculation"}},"aiida.data":{"zeopp.parameters":"aiida_zeopp.data.parameters:NetworkParameters"},"aiida.parsers":{"zeopp.network":"aiida_zeopp.parsers.network:NetworkParser"}},commits_count:4,warnings:["`development_status` key is deprecated. Use PyPI Trove classifiers in the plugin repository instead."],summaryinfo:[{colorclass:"blue",text:"Calculations",count:1},{colorclass:"brown",text:"Parsers",count:1},{colorclass:"red",text:"Data",count:1}],pip_install_cmd:"pip install aiida-zeopp",is_installable:"True"}},mk=[{name:"Calculations",colorclass:"blue",num_entries:53,total_num:131},{name:"Parsers",colorclass:"brown",num_entries:54,total_num:109},{name:"Data",colorclass:"red",num_entries:30,total_num:103},{name:"Workflows",colorclass:"green",num_entries:39,total_num:135},{name:"Console scripts",colorclass:"purple",num_entries:15,total_num:26},{name:"Other",tooltip:"Aenet potentials, Calculations importers, Calculations monitors, ...",colorclass:"orange",num_entries:26,total_num:99}],fk={planning:["Not yet ready to use. Developers welcome!","status-planning-d9644d.svg"],"pre-alpha":["Not yet ready to use. Developers welcome!","status-planning-d9644d.svg"],alpha:["Adds new functionality, not yet ready for production. Testing welcome!","status-alpha-d6af23.svg"],beta:["Adds new functionality, not yet ready for production. Testing welcome!","status-beta-d6af23.svg"],stable:["Ready for production calculations. Bug reports welcome!","status-stable-4cc61e.svg"],mature:["Ready for production calculations. Bug reports welcome!","status-stable-4cc61e.svg"],inactive:["No longer maintained.","status-inactive-bbbbbb.svg"]},hk={"aiida.calculations":"CalcJobs and calculation functions","aiida.parsers":"CalcJob parsers","aiida.data":"Data node types","aiida.cmdline.data":"verdi data commands","aiida.groups":"Group types","aiida.workflows":"WorkChains and work functions","aiida.schedulers":"Job scheduler support","aiida.transports":"Data transport protocols","aiida.tests":"Development test modules","aiida.tools.dbexporters":"Support for exporting to external databases","aiida.tools.dbimporters":"Support for importing from external databases",console_scripts:"Console scripts"},si={plugins:uk,globalsummary:mk,status_dict:fk,entrypointtypes:hk};var bc={},iy={exports:{}};(function(e){function t(i){return i&&i.__esModule?i:{default:i}}e.exports=t,e.exports.__esModule=!0,e.exports.default=e.exports})(iy);var kc=iy.exports,Ol={};function q(){return q=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var i=arguments[t];for(var a in i)Object.prototype.hasOwnProperty.call(i,a)&&(e[a]=i[a])}return e},q.apply(this,arguments)}function ra(e){return e!==null&&typeof e=="object"&&e.constructor===Object}function ay(e){if(!ra(e))return e;const t={};return Object.keys(e).forEach(i=>{t[i]=ay(e[i])}),t}function At(e,t,i={clone:!0}){const a=i.clone?q({},e):e;return ra(e)&&ra(t)&&Object.keys(t).forEach(n=>{n!=="__proto__"&&(ra(t[n])&&n in e&&ra(e[n])?a[n]=At(e[n],t[n],i):i.clone?a[n]=ra(t[n])?ay(t[n]):t[n]:a[n]=t[n])}),a}function Xi(e){let t="https://mui.com/production-error/?code="+e;for(let i=1;i<arguments.length;i+=1)t+="&args[]="+encodeURIComponent(arguments[i]);return"Minified MUI error #"+e+"; visit "+t+" for the full message."}var ce={};/**
 * @license React
 * react-is.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var vc=Symbol.for("react.element"),wc=Symbol.for("react.portal"),Tr=Symbol.for("react.fragment"),Dr=Symbol.for("react.strict_mode"),Cr=Symbol.for("react.profiler"),Rr=Symbol.for("react.provider"),Pr=Symbol.for("react.context"),gk=Symbol.for("react.server_context"),Sr=Symbol.for("react.forward_ref"),Er=Symbol.for("react.suspense"),Br=Symbol.for("react.suspense_list"),Ar=Symbol.for("react.memo"),jr=Symbol.for("react.lazy"),yk=Symbol.for("react.offscreen"),ny;ny=Symbol.for("react.module.reference");function zt(e){if(typeof e=="object"&&e!==null){var t=e.$$typeof;switch(t){case vc:switch(e=e.type,e){case Tr:case Cr:case Dr:case Er:case Br:return e;default:switch(e=e&&e.$$typeof,e){case gk:case Pr:case Sr:case jr:case Ar:case Rr:return e;default:return t}}case wc:return t}}}ce.ContextConsumer=Pr;ce.ContextProvider=Rr;ce.Element=vc;ce.ForwardRef=Sr;ce.Fragment=Tr;ce.Lazy=jr;ce.Memo=Ar;ce.Portal=wc;ce.Profiler=Cr;ce.StrictMode=Dr;ce.Suspense=Er;ce.SuspenseList=Br;ce.isAsyncMode=function(){return!1};ce.isConcurrentMode=function(){return!1};ce.isContextConsumer=function(e){return zt(e)===Pr};ce.isContextProvider=function(e){return zt(e)===Rr};ce.isElement=function(e){return typeof e=="object"&&e!==null&&e.$$typeof===vc};ce.isForwardRef=function(e){return zt(e)===Sr};ce.isFragment=function(e){return zt(e)===Tr};ce.isLazy=function(e){return zt(e)===jr};ce.isMemo=function(e){return zt(e)===Ar};ce.isPortal=function(e){return zt(e)===wc};ce.isProfiler=function(e){return zt(e)===Cr};ce.isStrictMode=function(e){return zt(e)===Dr};ce.isSuspense=function(e){return zt(e)===Er};ce.isSuspenseList=function(e){return zt(e)===Br};ce.isValidElementType=function(e){return typeof e=="string"||typeof e=="function"||e===Tr||e===Cr||e===Dr||e===Er||e===Br||e===yk||typeof e=="object"&&e!==null&&(e.$$typeof===jr||e.$$typeof===Ar||e.$$typeof===Rr||e.$$typeof===Pr||e.$$typeof===Sr||e.$$typeof===ny||e.getModuleId!==void 0)};ce.typeOf=zt;function V(e){if(typeof e!="string")throw new Error(Xi(7));return e.charAt(0).toUpperCase()+e.slice(1)}function ep(...e){return e.reduce((t,i)=>i==null?t:function(...n){t.apply(this,n),i.apply(this,n)},()=>{})}function Mr(e,t=166){let i;function a(...n){const o=()=>{e.apply(this,n)};clearTimeout(i),i=setTimeout(o,t)}return a.clear=()=>{clearTimeout(i)},a}function _k(e,t){return()=>null}function vs(e,t){return k.isValidElement(e)&&t.indexOf(e.type.muiName)!==-1}function mt(e){return e&&e.ownerDocument||document}function oi(e){return mt(e).defaultView||window}function bk(e,t){return()=>null}function er(e,t){typeof e=="function"?e(t):e&&(e.current=t)}const kk=typeof window<"u"?k.useLayoutEffect:k.useEffect,Yi=kk;let ym=0;function vk(e){const[t,i]=k.useState(e),a=e||t;return k.useEffect(()=>{t==null&&(ym+=1,i(`mui-${ym}`))},[t]),a}const _m=Ts["useId".toString()];function oy(e){if(_m!==void 0){const t=_m();return e??t}return vk(e)}function wk(e,t,i,a,n){return null}function tp({controlled:e,default:t,name:i,state:a="value"}){const{current:n}=k.useRef(e!==void 0),[o,s]=k.useState(t),r=n?e:o,l=k.useCallback(d=>{n||s(d)},[]);return[r,l]}function ma(e){const t=k.useRef(e);return Yi(()=>{t.current=e}),k.useCallback((...i)=>(0,t.current)(...i),[])}function Ye(...e){return k.useMemo(()=>e.every(t=>t==null)?null:t=>{e.forEach(i=>{er(i,t)})},e)}let zr=!0,ip=!1,bm;const qk={text:!0,search:!0,url:!0,tel:!0,email:!0,password:!0,number:!0,date:!0,month:!0,week:!0,time:!0,datetime:!0,"datetime-local":!0};function xk(e){const{type:t,tagName:i}=e;return!!(i==="INPUT"&&qk[t]&&!e.readOnly||i==="TEXTAREA"&&!e.readOnly||e.isContentEditable)}function Fk(e){e.metaKey||e.altKey||e.ctrlKey||(zr=!0)}function Ll(){zr=!1}function Tk(){this.visibilityState==="hidden"&&ip&&(zr=!0)}function Dk(e){e.addEventListener("keydown",Fk,!0),e.addEventListener("mousedown",Ll,!0),e.addEventListener("pointerdown",Ll,!0),e.addEventListener("touchstart",Ll,!0),e.addEventListener("visibilitychange",Tk,!0)}function Ck(e){const{target:t}=e;try{return t.matches(":focus-visible")}catch{}return zr||xk(t)}function sy(){const e=k.useCallback(n=>{n!=null&&Dk(n.ownerDocument)},[]),t=k.useRef(!1);function i(){return t.current?(ip=!0,window.clearTimeout(bm),bm=window.setTimeout(()=>{ip=!1},100),t.current=!1,!0):!1}function a(n){return Ck(n)?(t.current=!0,!0):!1}return{isFocusVisibleRef:t,onFocus:a,onBlur:i,ref:e}}function ry(e){const t=e.documentElement.clientWidth;return Math.abs(window.innerWidth-t)}function ly(e,t){const i=q({},t);return Object.keys(e).forEach(a=>{if(a.toString().match(/^(components|slots)$/))i[a]=q({},e[a],i[a]);else if(a.toString().match(/^(componentsProps|slotProps)$/)){const n=e[a]||{},o=t[a];i[a]={},!o||!Object.keys(o)?i[a]=n:!n||!Object.keys(n)?i[a]=o:(i[a]=q({},o),Object.keys(n).forEach(s=>{i[a][s]=ly(n[s],o[s])}))}else i[a]===void 0&&(i[a]=e[a])}),i}function me(e,t,i=void 0){const a={};return Object.keys(e).forEach(n=>{a[n]=e[n].reduce((o,s)=>{if(s){const r=t(s);r!==""&&o.push(r),i&&i[s]&&o.push(i[s])}return o},[]).join(" ")}),a}const km=e=>e,Rk=()=>{let e=km;return{configure(t){e=t},generate(t){return e(t)},reset(){e=km}}},Pk=Rk(),qc=Pk,Sk={active:"active",checked:"checked",completed:"completed",disabled:"disabled",error:"error",expanded:"expanded",focused:"focused",focusVisible:"focusVisible",open:"open",readOnly:"readOnly",required:"required",selected:"selected"};function ue(e,t,i="Mui"){const a=Sk[t];return a?`${i}-${a}`:`${qc.generate(e)}-${t}`}function oe(e,t,i="Mui"){const a={};return t.forEach(n=>{a[n]=ue(e,n,i)}),a}function $(e,t){if(e==null)return{};var i={},a=Object.keys(e),n,o;for(o=0;o<a.length;o++)n=a[o],!(t.indexOf(n)>=0)&&(i[n]=e[n]);return i}function dy(e){var t,i,a="";if(typeof e=="string"||typeof e=="number")a+=e;else if(typeof e=="object")if(Array.isArray(e))for(t=0;t<e.length;t++)e[t]&&(i=dy(e[t]))&&(a&&(a+=" "),a+=i);else for(t in e)e[t]&&(a&&(a+=" "),a+=t);return a}function K(){for(var e,t,i=0,a="";i<arguments.length;)(e=arguments[i++])&&(t=dy(e))&&(a&&(a+=" "),a+=t);return a}function py(e){var t=Object.create(null);return function(i){return t[i]===void 0&&(t[i]=e(i)),t[i]}}var Ek=/^((children|dangerouslySetInnerHTML|key|ref|autoFocus|defaultValue|defaultChecked|innerHTML|suppressContentEditableWarning|suppressHydrationWarning|valueLink|abbr|accept|acceptCharset|accessKey|action|allow|allowUserMedia|allowPaymentRequest|allowFullScreen|allowTransparency|alt|async|autoComplete|autoPlay|capture|cellPadding|cellSpacing|challenge|charSet|checked|cite|classID|className|cols|colSpan|content|contentEditable|contextMenu|controls|controlsList|coords|crossOrigin|data|dateTime|decoding|default|defer|dir|disabled|disablePictureInPicture|download|draggable|encType|enterKeyHint|form|formAction|formEncType|formMethod|formNoValidate|formTarget|frameBorder|headers|height|hidden|high|href|hrefLang|htmlFor|httpEquiv|id|inputMode|integrity|is|keyParams|keyType|kind|label|lang|list|loading|loop|low|marginHeight|marginWidth|max|maxLength|media|mediaGroup|method|min|minLength|multiple|muted|name|nonce|noValidate|open|optimum|pattern|placeholder|playsInline|poster|preload|profile|radioGroup|readOnly|referrerPolicy|rel|required|reversed|role|rows|rowSpan|sandbox|scope|scoped|scrolling|seamless|selected|shape|size|sizes|slot|span|spellCheck|src|srcDoc|srcLang|srcSet|start|step|style|summary|tabIndex|target|title|translate|type|useMap|value|width|wmode|wrap|about|datatype|inlist|prefix|property|resource|typeof|vocab|autoCapitalize|autoCorrect|autoSave|color|incremental|fallback|inert|itemProp|itemScope|itemType|itemID|itemRef|on|option|results|security|unselectable|accentHeight|accumulate|additive|alignmentBaseline|allowReorder|alphabetic|amplitude|arabicForm|ascent|attributeName|attributeType|autoReverse|azimuth|baseFrequency|baselineShift|baseProfile|bbox|begin|bias|by|calcMode|capHeight|clip|clipPathUnits|clipPath|clipRule|colorInterpolation|colorInterpolationFilters|colorProfile|colorRendering|contentScriptType|contentStyleType|cursor|cx|cy|d|decelerate|descent|diffuseConstant|direction|display|divisor|dominantBaseline|dur|dx|dy|edgeMode|elevation|enableBackground|end|exponent|externalResourcesRequired|fill|fillOpacity|fillRule|filter|filterRes|filterUnits|floodColor|floodOpacity|focusable|fontFamily|fontSize|fontSizeAdjust|fontStretch|fontStyle|fontVariant|fontWeight|format|from|fr|fx|fy|g1|g2|glyphName|glyphOrientationHorizontal|glyphOrientationVertical|glyphRef|gradientTransform|gradientUnits|hanging|horizAdvX|horizOriginX|ideographic|imageRendering|in|in2|intercept|k|k1|k2|k3|k4|kernelMatrix|kernelUnitLength|kerning|keyPoints|keySplines|keyTimes|lengthAdjust|letterSpacing|lightingColor|limitingConeAngle|local|markerEnd|markerMid|markerStart|markerHeight|markerUnits|markerWidth|mask|maskContentUnits|maskUnits|mathematical|mode|numOctaves|offset|opacity|operator|order|orient|orientation|origin|overflow|overlinePosition|overlineThickness|panose1|paintOrder|pathLength|patternContentUnits|patternTransform|patternUnits|pointerEvents|points|pointsAtX|pointsAtY|pointsAtZ|preserveAlpha|preserveAspectRatio|primitiveUnits|r|radius|refX|refY|renderingIntent|repeatCount|repeatDur|requiredExtensions|requiredFeatures|restart|result|rotate|rx|ry|scale|seed|shapeRendering|slope|spacing|specularConstant|specularExponent|speed|spreadMethod|startOffset|stdDeviation|stemh|stemv|stitchTiles|stopColor|stopOpacity|strikethroughPosition|strikethroughThickness|string|stroke|strokeDasharray|strokeDashoffset|strokeLinecap|strokeLinejoin|strokeMiterlimit|strokeOpacity|strokeWidth|surfaceScale|systemLanguage|tableValues|targetX|targetY|textAnchor|textDecoration|textRendering|textLength|to|transform|u1|u2|underlinePosition|underlineThickness|unicode|unicodeBidi|unicodeRange|unitsPerEm|vAlphabetic|vHanging|vIdeographic|vMathematical|values|vectorEffect|version|vertAdvY|vertOriginX|vertOriginY|viewBox|viewTarget|visibility|widths|wordSpacing|writingMode|x|xHeight|x1|x2|xChannelSelector|xlinkActuate|xlinkArcrole|xlinkHref|xlinkRole|xlinkShow|xlinkTitle|xlinkType|xmlBase|xmlns|xmlnsXlink|xmlLang|xmlSpace|y|y1|y2|yChannelSelector|z|zoomAndPan|for|class|autofocus)|(([Dd][Aa][Tt][Aa]|[Aa][Rr][Ii][Aa]|x)-.*))$/,Bk=py(function(e){return Ek.test(e)||e.charCodeAt(0)===111&&e.charCodeAt(1)===110&&e.charCodeAt(2)<91});function Ak(e){if(e.sheet)return e.sheet;for(var t=0;t<document.styleSheets.length;t++)if(document.styleSheets[t].ownerNode===e)return document.styleSheets[t]}function jk(e){var t=document.createElement("style");return t.setAttribute("data-emotion",e.key),e.nonce!==void 0&&t.setAttribute("nonce",e.nonce),t.appendChild(document.createTextNode("")),t.setAttribute("data-s",""),t}var Mk=function(){function e(i){var a=this;this._insertTag=function(n){var o;a.tags.length===0?a.insertionPoint?o=a.insertionPoint.nextSibling:a.prepend?o=a.container.firstChild:o=a.before:o=a.tags[a.tags.length-1].nextSibling,a.container.insertBefore(n,o),a.tags.push(n)},this.isSpeedy=i.speedy===void 0?!0:i.speedy,this.tags=[],this.ctr=0,this.nonce=i.nonce,this.key=i.key,this.container=i.container,this.prepend=i.prepend,this.insertionPoint=i.insertionPoint,this.before=null}var t=e.prototype;return t.hydrate=function(a){a.forEach(this._insertTag)},t.insert=function(a){this.ctr%(this.isSpeedy?65e3:1)===0&&this._insertTag(jk(this));var n=this.tags[this.tags.length-1];if(this.isSpeedy){var o=Ak(n);try{o.insertRule(a,o.cssRules.length)}catch{}}else n.appendChild(document.createTextNode(a));this.ctr++},t.flush=function(){this.tags.forEach(function(a){return a.parentNode&&a.parentNode.removeChild(a)}),this.tags=[],this.ctr=0},e}(),Ze="-ms-",tr="-moz-",ie="-webkit-",cy="comm",xc="rule",Fc="decl",zk="@import",uy="@keyframes",Ik="@layer",Nk=Math.abs,Ir=String.fromCharCode,Ok=Object.assign;function Lk(e,t){return He(e,0)^45?(((t<<2^He(e,0))<<2^He(e,1))<<2^He(e,2))<<2^He(e,3):0}function my(e){return e.trim()}function Wk(e,t){return(e=t.exec(e))?e[0]:e}function ae(e,t,i){return e.replace(t,i)}function ap(e,t){return e.indexOf(t)}function He(e,t){return e.charCodeAt(t)|0}function qo(e,t,i){return e.slice(t,i)}function Qt(e){return e.length}function Tc(e){return e.length}function os(e,t){return t.push(e),e}function $k(e,t){return e.map(t).join("")}var Nr=1,cn=1,fy=0,ft=0,Me=0,kn="";function Or(e,t,i,a,n,o,s){return{value:e,root:t,parent:i,type:a,props:n,children:o,line:Nr,column:cn,length:s,return:""}}function En(e,t){return Ok(Or("",null,null,"",null,null,0),e,{length:-e.length},t)}function Gk(){return Me}function Uk(){return Me=ft>0?He(kn,--ft):0,cn--,Me===10&&(cn=1,Nr--),Me}function kt(){return Me=ft<fy?He(kn,ft++):0,cn++,Me===10&&(cn=1,Nr++),Me}function ni(){return He(kn,ft)}function ws(){return ft}function Bo(e,t){return qo(kn,e,t)}function xo(e){switch(e){case 0:case 9:case 10:case 13:case 32:return 5;case 33:case 43:case 44:case 47:case 62:case 64:case 126:case 59:case 123:case 125:return 4;case 58:return 3;case 34:case 39:case 40:case 91:return 2;case 41:case 93:return 1}return 0}function hy(e){return Nr=cn=1,fy=Qt(kn=e),ft=0,[]}function gy(e){return kn="",e}function qs(e){return my(Bo(ft-1,np(e===91?e+2:e===40?e+1:e)))}function Kk(e){for(;(Me=ni())&&Me<33;)kt();return xo(e)>2||xo(Me)>3?"":" "}function Hk(e,t){for(;--t&&kt()&&!(Me<48||Me>102||Me>57&&Me<65||Me>70&&Me<97););return Bo(e,ws()+(t<6&&ni()==32&&kt()==32))}function np(e){for(;kt();)switch(Me){case e:return ft;case 34:case 39:e!==34&&e!==39&&np(Me);break;case 40:e===41&&np(e);break;case 92:kt();break}return ft}function Vk(e,t){for(;kt()&&e+Me!==47+10;)if(e+Me===42+42&&ni()===47)break;return"/*"+Bo(t,ft-1)+"*"+Ir(e===47?e:kt())}function Xk(e){for(;!xo(ni());)kt();return Bo(e,ft)}function Yk(e){return gy(xs("",null,null,null,[""],e=hy(e),0,[0],e))}function xs(e,t,i,a,n,o,s,r,l){for(var d=0,p=0,f=s,h=0,c=0,g=0,m=1,x=1,_=1,y=0,b="",v=n,F=o,T=a,w=b;x;)switch(g=y,y=kt()){case 40:if(g!=108&&He(w,f-1)==58){ap(w+=ae(qs(y),"&","&\f"),"&\f")!=-1&&(_=-1);break}case 34:case 39:case 91:w+=qs(y);break;case 9:case 10:case 13:case 32:w+=Kk(g);break;case 92:w+=Hk(ws()-1,7);continue;case 47:switch(ni()){case 42:case 47:os(Qk(Vk(kt(),ws()),t,i),l);break;default:w+="/"}break;case 123*m:r[d++]=Qt(w)*_;case 125*m:case 59:case 0:switch(y){case 0:case 125:x=0;case 59+p:_==-1&&(w=ae(w,/\f/g,"")),c>0&&Qt(w)-f&&os(c>32?wm(w+";",a,i,f-1):wm(ae(w," ","")+";",a,i,f-2),l);break;case 59:w+=";";default:if(os(T=vm(w,t,i,d,p,n,r,b,v=[],F=[],f),o),y===123)if(p===0)xs(w,t,T,T,v,o,f,r,F);else switch(h===99&&He(w,3)===110?100:h){case 100:case 108:case 109:case 115:xs(e,T,T,a&&os(vm(e,T,T,0,0,n,r,b,n,v=[],f),F),n,F,f,r,a?v:F);break;default:xs(w,T,T,T,[""],F,0,r,F)}}d=p=c=0,m=_=1,b=w="",f=s;break;case 58:f=1+Qt(w),c=g;default:if(m<1){if(y==123)--m;else if(y==125&&m++==0&&Uk()==125)continue}switch(w+=Ir(y),y*m){case 38:_=p>0?1:(w+="\f",-1);break;case 44:r[d++]=(Qt(w)-1)*_,_=1;break;case 64:ni()===45&&(w+=qs(kt())),h=ni(),p=f=Qt(b=w+=Xk(ws())),y++;break;case 45:g===45&&Qt(w)==2&&(m=0)}}return o}function vm(e,t,i,a,n,o,s,r,l,d,p){for(var f=n-1,h=n===0?o:[""],c=Tc(h),g=0,m=0,x=0;g<a;++g)for(var _=0,y=qo(e,f+1,f=Nk(m=s[g])),b=e;_<c;++_)(b=my(m>0?h[_]+" "+y:ae(y,/&\f/g,h[_])))&&(l[x++]=b);return Or(e,t,i,n===0?xc:r,l,d,p)}function Qk(e,t,i){return Or(e,t,i,cy,Ir(Gk()),qo(e,2,-2),0)}function wm(e,t,i,a){return Or(e,t,i,Fc,qo(e,0,a),qo(e,a+1,-1),a)}function tn(e,t){for(var i="",a=Tc(e),n=0;n<a;n++)i+=t(e[n],n,e,t)||"";return i}function Jk(e,t,i,a){switch(e.type){case Ik:if(e.children.length)break;case zk:case Fc:return e.return=e.return||e.value;case cy:return"";case uy:return e.return=e.value+"{"+tn(e.children,a)+"}";case xc:e.value=e.props.join(",")}return Qt(i=tn(e.children,a))?e.return=e.value+"{"+i+"}":""}function Zk(e){var t=Tc(e);return function(i,a,n,o){for(var s="",r=0;r<t;r++)s+=e[r](i,a,n,o)||"";return s}}function ev(e){return function(t){t.root||(t=t.return)&&e(t)}}var tv=function(t,i,a){for(var n=0,o=0;n=o,o=ni(),n===38&&o===12&&(i[a]=1),!xo(o);)kt();return Bo(t,ft)},iv=function(t,i){var a=-1,n=44;do switch(xo(n)){case 0:n===38&&ni()===12&&(i[a]=1),t[a]+=tv(ft-1,i,a);break;case 2:t[a]+=qs(n);break;case 4:if(n===44){t[++a]=ni()===58?"&\f":"",i[a]=t[a].length;break}default:t[a]+=Ir(n)}while(n=kt());return t},av=function(t,i){return gy(iv(hy(t),i))},qm=new WeakMap,nv=function(t){if(!(t.type!=="rule"||!t.parent||t.length<1)){for(var i=t.value,a=t.parent,n=t.column===a.column&&t.line===a.line;a.type!=="rule";)if(a=a.parent,!a)return;if(!(t.props.length===1&&i.charCodeAt(0)!==58&&!qm.get(a))&&!n){qm.set(t,!0);for(var o=[],s=av(i,o),r=a.props,l=0,d=0;l<s.length;l++)for(var p=0;p<r.length;p++,d++)t.props[d]=o[l]?s[l].replace(/&\f/g,r[p]):r[p]+" "+s[l]}}},ov=function(t){if(t.type==="decl"){var i=t.value;i.charCodeAt(0)===108&&i.charCodeAt(2)===98&&(t.return="",t.value="")}};function yy(e,t){switch(Lk(e,t)){case 5103:return ie+"print-"+e+e;case 5737:case 4201:case 3177:case 3433:case 1641:case 4457:case 2921:case 5572:case 6356:case 5844:case 3191:case 6645:case 3005:case 6391:case 5879:case 5623:case 6135:case 4599:case 4855:case 4215:case 6389:case 5109:case 5365:case 5621:case 3829:return ie+e+e;case 5349:case 4246:case 4810:case 6968:case 2756:return ie+e+tr+e+Ze+e+e;case 6828:case 4268:return ie+e+Ze+e+e;case 6165:return ie+e+Ze+"flex-"+e+e;case 5187:return ie+e+ae(e,/(\w+).+(:[^]+)/,ie+"box-$1$2"+Ze+"flex-$1$2")+e;case 5443:return ie+e+Ze+"flex-item-"+ae(e,/flex-|-self/,"")+e;case 4675:return ie+e+Ze+"flex-line-pack"+ae(e,/align-content|flex-|-self/,"")+e;case 5548:return ie+e+Ze+ae(e,"shrink","negative")+e;case 5292:return ie+e+Ze+ae(e,"basis","preferred-size")+e;case 6060:return ie+"box-"+ae(e,"-grow","")+ie+e+Ze+ae(e,"grow","positive")+e;case 4554:return ie+ae(e,/([^-])(transform)/g,"$1"+ie+"$2")+e;case 6187:return ae(ae(ae(e,/(zoom-|grab)/,ie+"$1"),/(image-set)/,ie+"$1"),e,"")+e;case 5495:case 3959:return ae(e,/(image-set\([^]*)/,ie+"$1$`$1");case 4968:return ae(ae(e,/(.+:)(flex-)?(.*)/,ie+"box-pack:$3"+Ze+"flex-pack:$3"),/s.+-b[^;]+/,"justify")+ie+e+e;case 4095:case 3583:case 4068:case 2532:return ae(e,/(.+)-inline(.+)/,ie+"$1$2")+e;case 8116:case 7059:case 5753:case 5535:case 5445:case 5701:case 4933:case 4677:case 5533:case 5789:case 5021:case 4765:if(Qt(e)-1-t>6)switch(He(e,t+1)){case 109:if(He(e,t+4)!==45)break;case 102:return ae(e,/(.+:)(.+)-([^]+)/,"$1"+ie+"$2-$3$1"+tr+(He(e,t+3)==108?"$3":"$2-$3"))+e;case 115:return~ap(e,"stretch")?yy(ae(e,"stretch","fill-available"),t)+e:e}break;case 4949:if(He(e,t+1)!==115)break;case 6444:switch(He(e,Qt(e)-3-(~ap(e,"!important")&&10))){case 107:return ae(e,":",":"+ie)+e;case 101:return ae(e,/(.+:)([^;!]+)(;|!.+)?/,"$1"+ie+(He(e,14)===45?"inline-":"")+"box$3$1"+ie+"$2$3$1"+Ze+"$2box$3")+e}break;case 5936:switch(He(e,t+11)){case 114:return ie+e+Ze+ae(e,/[svh]\w+-[tblr]{2}/,"tb")+e;case 108:return ie+e+Ze+ae(e,/[svh]\w+-[tblr]{2}/,"tb-rl")+e;case 45:return ie+e+Ze+ae(e,/[svh]\w+-[tblr]{2}/,"lr")+e}return ie+e+Ze+e+e}return e}var sv=function(t,i,a,n){if(t.length>-1&&!t.return)switch(t.type){case Fc:t.return=yy(t.value,t.length);break;case uy:return tn([En(t,{value:ae(t.value,"@","@"+ie)})],n);case xc:if(t.length)return $k(t.props,function(o){switch(Wk(o,/(::plac\w+|:read-\w+)/)){case":read-only":case":read-write":return tn([En(t,{props:[ae(o,/:(read-\w+)/,":"+tr+"$1")]})],n);case"::placeholder":return tn([En(t,{props:[ae(o,/:(plac\w+)/,":"+ie+"input-$1")]}),En(t,{props:[ae(o,/:(plac\w+)/,":"+tr+"$1")]}),En(t,{props:[ae(o,/:(plac\w+)/,Ze+"input-$1")]})],n)}return""})}},rv=[sv],lv=function(t){var i=t.key;if(i==="css"){var a=document.querySelectorAll("style[data-emotion]:not([data-s])");Array.prototype.forEach.call(a,function(m){var x=m.getAttribute("data-emotion");x.indexOf(" ")!==-1&&(document.head.appendChild(m),m.setAttribute("data-s",""))})}var n=t.stylisPlugins||rv,o={},s,r=[];s=t.container||document.head,Array.prototype.forEach.call(document.querySelectorAll('style[data-emotion^="'+i+' "]'),function(m){for(var x=m.getAttribute("data-emotion").split(" "),_=1;_<x.length;_++)o[x[_]]=!0;r.push(m)});var l,d=[nv,ov];{var p,f=[Jk,ev(function(m){p.insert(m)})],h=Zk(d.concat(n,f)),c=function(x){return tn(Yk(x),h)};l=function(x,_,y,b){p=y,c(x?x+"{"+_.styles+"}":_.styles),b&&(g.inserted[_.name]=!0)}}var g={key:i,sheet:new Mk({key:i,container:s,nonce:t.nonce,speedy:t.speedy,prepend:t.prepend,insertionPoint:t.insertionPoint}),nonce:t.nonce,inserted:o,registered:{},insert:l};return g.sheet.hydrate(r),g},_y={exports:{}},de={};/** @license React v16.13.1
 * react-is.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */var $e=typeof Symbol=="function"&&Symbol.for,Dc=$e?Symbol.for("react.element"):60103,Cc=$e?Symbol.for("react.portal"):60106,Lr=$e?Symbol.for("react.fragment"):60107,Wr=$e?Symbol.for("react.strict_mode"):60108,$r=$e?Symbol.for("react.profiler"):60114,Gr=$e?Symbol.for("react.provider"):60109,Ur=$e?Symbol.for("react.context"):60110,Rc=$e?Symbol.for("react.async_mode"):60111,Kr=$e?Symbol.for("react.concurrent_mode"):60111,Hr=$e?Symbol.for("react.forward_ref"):60112,Vr=$e?Symbol.for("react.suspense"):60113,dv=$e?Symbol.for("react.suspense_list"):60120,Xr=$e?Symbol.for("react.memo"):60115,Yr=$e?Symbol.for("react.lazy"):60116,pv=$e?Symbol.for("react.block"):60121,cv=$e?Symbol.for("react.fundamental"):60117,uv=$e?Symbol.for("react.responder"):60118,mv=$e?Symbol.for("react.scope"):60119;function xt(e){if(typeof e=="object"&&e!==null){var t=e.$$typeof;switch(t){case Dc:switch(e=e.type,e){case Rc:case Kr:case Lr:case $r:case Wr:case Vr:return e;default:switch(e=e&&e.$$typeof,e){case Ur:case Hr:case Yr:case Xr:case Gr:return e;default:return t}}case Cc:return t}}}function by(e){return xt(e)===Kr}de.AsyncMode=Rc;de.ConcurrentMode=Kr;de.ContextConsumer=Ur;de.ContextProvider=Gr;de.Element=Dc;de.ForwardRef=Hr;de.Fragment=Lr;de.Lazy=Yr;de.Memo=Xr;de.Portal=Cc;de.Profiler=$r;de.StrictMode=Wr;de.Suspense=Vr;de.isAsyncMode=function(e){return by(e)||xt(e)===Rc};de.isConcurrentMode=by;de.isContextConsumer=function(e){return xt(e)===Ur};de.isContextProvider=function(e){return xt(e)===Gr};de.isElement=function(e){return typeof e=="object"&&e!==null&&e.$$typeof===Dc};de.isForwardRef=function(e){return xt(e)===Hr};de.isFragment=function(e){return xt(e)===Lr};de.isLazy=function(e){return xt(e)===Yr};de.isMemo=function(e){return xt(e)===Xr};de.isPortal=function(e){return xt(e)===Cc};de.isProfiler=function(e){return xt(e)===$r};de.isStrictMode=function(e){return xt(e)===Wr};de.isSuspense=function(e){return xt(e)===Vr};de.isValidElementType=function(e){return typeof e=="string"||typeof e=="function"||e===Lr||e===Kr||e===$r||e===Wr||e===Vr||e===dv||typeof e=="object"&&e!==null&&(e.$$typeof===Yr||e.$$typeof===Xr||e.$$typeof===Gr||e.$$typeof===Ur||e.$$typeof===Hr||e.$$typeof===cv||e.$$typeof===uv||e.$$typeof===mv||e.$$typeof===pv)};de.typeOf=xt;_y.exports=de;var fv=_y.exports,ky=fv,hv={$$typeof:!0,render:!0,defaultProps:!0,displayName:!0,propTypes:!0},gv={$$typeof:!0,compare:!0,defaultProps:!0,displayName:!0,propTypes:!0,type:!0},vy={};vy[ky.ForwardRef]=hv;vy[ky.Memo]=gv;var yv=!0;function _v(e,t,i){var a="";return i.split(" ").forEach(function(n){e[n]!==void 0?t.push(e[n]+";"):a+=n+" "}),a}var wy=function(t,i,a){var n=t.key+"-"+i.name;(a===!1||yv===!1)&&t.registered[n]===void 0&&(t.registered[n]=i.styles)},qy=function(t,i,a){wy(t,i,a);var n=t.key+"-"+i.name;if(t.inserted[i.name]===void 0){var o=i;do t.insert(i===o?"."+n:"",o,t.sheet,!0),o=o.next;while(o!==void 0)}};function bv(e){for(var t=0,i,a=0,n=e.length;n>=4;++a,n-=4)i=e.charCodeAt(a)&255|(e.charCodeAt(++a)&255)<<8|(e.charCodeAt(++a)&255)<<16|(e.charCodeAt(++a)&255)<<24,i=(i&65535)*1540483477+((i>>>16)*59797<<16),i^=i>>>24,t=(i&65535)*1540483477+((i>>>16)*59797<<16)^(t&65535)*1540483477+((t>>>16)*59797<<16);switch(n){case 3:t^=(e.charCodeAt(a+2)&255)<<16;case 2:t^=(e.charCodeAt(a+1)&255)<<8;case 1:t^=e.charCodeAt(a)&255,t=(t&65535)*1540483477+((t>>>16)*59797<<16)}return t^=t>>>13,t=(t&65535)*1540483477+((t>>>16)*59797<<16),((t^t>>>15)>>>0).toString(36)}var kv={animationIterationCount:1,aspectRatio:1,borderImageOutset:1,borderImageSlice:1,borderImageWidth:1,boxFlex:1,boxFlexGroup:1,boxOrdinalGroup:1,columnCount:1,columns:1,flex:1,flexGrow:1,flexPositive:1,flexShrink:1,flexNegative:1,flexOrder:1,gridRow:1,gridRowEnd:1,gridRowSpan:1,gridRowStart:1,gridColumn:1,gridColumnEnd:1,gridColumnSpan:1,gridColumnStart:1,msGridRow:1,msGridRowSpan:1,msGridColumn:1,msGridColumnSpan:1,fontWeight:1,lineHeight:1,opacity:1,order:1,orphans:1,tabSize:1,widows:1,zIndex:1,zoom:1,WebkitLineClamp:1,fillOpacity:1,floodOpacity:1,stopOpacity:1,strokeDasharray:1,strokeDashoffset:1,strokeMiterlimit:1,strokeOpacity:1,strokeWidth:1},vv=/[A-Z]|^ms/g,wv=/_EMO_([^_]+?)_([^]*?)_EMO_/g,xy=function(t){return t.charCodeAt(1)===45},xm=function(t){return t!=null&&typeof t!="boolean"},Wl=py(function(e){return xy(e)?e:e.replace(vv,"-$&").toLowerCase()}),Fm=function(t,i){switch(t){case"animation":case"animationName":if(typeof i=="string")return i.replace(wv,function(a,n,o){return Jt={name:n,styles:o,next:Jt},n})}return kv[t]!==1&&!xy(t)&&typeof i=="number"&&i!==0?i+"px":i};function Fo(e,t,i){if(i==null)return"";if(i.__emotion_styles!==void 0)return i;switch(typeof i){case"boolean":return"";case"object":{if(i.anim===1)return Jt={name:i.name,styles:i.styles,next:Jt},i.name;if(i.styles!==void 0){var a=i.next;if(a!==void 0)for(;a!==void 0;)Jt={name:a.name,styles:a.styles,next:Jt},a=a.next;var n=i.styles+";";return n}return qv(e,t,i)}case"function":{if(e!==void 0){var o=Jt,s=i(e);return Jt=o,Fo(e,t,s)}break}}if(t==null)return i;var r=t[i];return r!==void 0?r:i}function qv(e,t,i){var a="";if(Array.isArray(i))for(var n=0;n<i.length;n++)a+=Fo(e,t,i[n])+";";else for(var o in i){var s=i[o];if(typeof s!="object")t!=null&&t[s]!==void 0?a+=o+"{"+t[s]+"}":xm(s)&&(a+=Wl(o)+":"+Fm(o,s)+";");else if(Array.isArray(s)&&typeof s[0]=="string"&&(t==null||t[s[0]]===void 0))for(var r=0;r<s.length;r++)xm(s[r])&&(a+=Wl(o)+":"+Fm(o,s[r])+";");else{var l=Fo(e,t,s);switch(o){case"animation":case"animationName":{a+=Wl(o)+":"+l+";";break}default:a+=o+"{"+l+"}"}}}return a}var Tm=/label:\s*([^\s;\n{]+)\s*(;|$)/g,Jt,Pc=function(t,i,a){if(t.length===1&&typeof t[0]=="object"&&t[0]!==null&&t[0].styles!==void 0)return t[0];var n=!0,o="";Jt=void 0;var s=t[0];s==null||s.raw===void 0?(n=!1,o+=Fo(a,i,s)):o+=s[0];for(var r=1;r<t.length;r++)o+=Fo(a,i,t[r]),n&&(o+=s[r]);Tm.lastIndex=0;for(var l="",d;(d=Tm.exec(o))!==null;)l+="-"+d[1];var p=bv(o)+l;return{name:p,styles:o,next:Jt}},xv=function(t){return t()},Fy=Ts["useInsertionEffect"]?Ts["useInsertionEffect"]:!1,Fv=Fy||xv,Dm=Fy||k.useLayoutEffect,Ty=k.createContext(typeof HTMLElement<"u"?lv({key:"css"}):null);Ty.Provider;var Dy=function(t){return k.forwardRef(function(i,a){var n=k.useContext(Ty);return t(i,n,a)})},Sc=k.createContext({}),Tv=Dy(function(e,t){var i=e.styles,a=Pc([i],void 0,k.useContext(Sc)),n=k.useRef();return Dm(function(){var o=t.key+"-global",s=new t.sheet.constructor({key:o,nonce:t.sheet.nonce,container:t.sheet.container,speedy:t.sheet.isSpeedy}),r=!1,l=document.querySelector('style[data-emotion="'+o+" "+a.name+'"]');return t.sheet.tags.length&&(s.before=t.sheet.tags[0]),l!==null&&(r=!0,l.setAttribute("data-emotion",o),s.hydrate([l])),n.current=[s,r],function(){s.flush()}},[t]),Dm(function(){var o=n.current,s=o[0],r=o[1];if(r){o[1]=!1;return}if(a.next!==void 0&&qy(t,a.next,!0),s.tags.length){var l=s.tags[s.tags.length-1].nextElementSibling;s.before=l,s.flush()}t.insert("",a,s,!1)},[t,a.name]),null});function Dv(){for(var e=arguments.length,t=new Array(e),i=0;i<e;i++)t[i]=arguments[i];return Pc(t)}var Ec=function(){var t=Dv.apply(void 0,arguments),i="animation-"+t.name;return{name:i,styles:"@keyframes "+i+"{"+t.styles+"}",anim:1,toString:function(){return"_EMO_"+this.name+"_"+this.styles+"_EMO_"}}},Cv=Bk,Rv=function(t){return t!=="theme"},Cm=function(t){return typeof t=="string"&&t.charCodeAt(0)>96?Cv:Rv},Rm=function(t,i,a){var n;if(i){var o=i.shouldForwardProp;n=t.__emotion_forwardProp&&o?function(s){return t.__emotion_forwardProp(s)&&o(s)}:o}return typeof n!="function"&&a&&(n=t.__emotion_forwardProp),n},Pv=function(t){var i=t.cache,a=t.serialized,n=t.isStringTag;return wy(i,a,n),Fv(function(){return qy(i,a,n)}),null},Sv=function e(t,i){var a=t.__emotion_real===t,n=a&&t.__emotion_base||t,o,s;i!==void 0&&(o=i.label,s=i.target);var r=Rm(t,i,a),l=r||Cm(n),d=!l("as");return function(){var p=arguments,f=a&&t.__emotion_styles!==void 0?t.__emotion_styles.slice(0):[];if(o!==void 0&&f.push("label:"+o+";"),p[0]==null||p[0].raw===void 0)f.push.apply(f,p);else{f.push(p[0][0]);for(var h=p.length,c=1;c<h;c++)f.push(p[c],p[0][c])}var g=Dy(function(m,x,_){var y=d&&m.as||n,b="",v=[],F=m;if(m.theme==null){F={};for(var T in m)F[T]=m[T];F.theme=k.useContext(Sc)}typeof m.className=="string"?b=_v(x.registered,v,m.className):m.className!=null&&(b=m.className+" ");var w=Pc(f.concat(v),x.registered,F);b+=x.key+"-"+w.name,s!==void 0&&(b+=" "+s);var D=d&&r===void 0?Cm(y):l,P={};for(var R in m)d&&R==="as"||D(R)&&(P[R]=m[R]);return P.className=b,P.ref=_,k.createElement(k.Fragment,null,k.createElement(Pv,{cache:x,serialized:w,isStringTag:typeof y=="string"}),k.createElement(y,P))});return g.displayName=o!==void 0?o:"Styled("+(typeof n=="string"?n:n.displayName||n.name||"Component")+")",g.defaultProps=t.defaultProps,g.__emotion_real=g,g.__emotion_base=n,g.__emotion_styles=f,g.__emotion_forwardProp=r,Object.defineProperty(g,"toString",{value:function(){return"."+s}}),g.withComponent=function(m,x){return e(m,q({},i,x,{shouldForwardProp:Rm(g,x,!0)})).apply(void 0,f)},g}},Ev=["a","abbr","address","area","article","aside","audio","b","base","bdi","bdo","big","blockquote","body","br","button","canvas","caption","cite","code","col","colgroup","data","datalist","dd","del","details","dfn","dialog","div","dl","dt","em","embed","fieldset","figcaption","figure","footer","form","h1","h2","h3","h4","h5","h6","head","header","hgroup","hr","html","i","iframe","img","input","ins","kbd","keygen","label","legend","li","link","main","map","mark","marquee","menu","menuitem","meta","meter","nav","noscript","object","ol","optgroup","option","output","p","param","picture","pre","progress","q","rp","rt","ruby","s","samp","script","section","select","small","source","span","strong","style","sub","summary","sup","table","tbody","td","textarea","tfoot","th","thead","time","title","tr","track","u","ul","var","video","wbr","circle","clipPath","defs","ellipse","foreignObject","g","image","line","linearGradient","mask","path","pattern","polygon","polyline","radialGradient","rect","stop","svg","text","tspan"],op=Sv.bind();Ev.forEach(function(e){op[e]=op(e)});function Bv(e){return e==null||Object.keys(e).length===0}function Av(e){const{styles:t,defaultTheme:i={}}=e,a=typeof t=="function"?n=>t(Bv(n)?i:n):t;return u.jsx(Tv,{styles:a})}/**
 * @mui/styled-engine v5.14.10
 *
 * @license MIT
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */function Cy(e,t){return op(e,t)}const jv=(e,t)=>{Array.isArray(e.__emotion_styles)&&(e.__emotion_styles=t(e.__emotion_styles))},Mv=["values","unit","step"],zv=e=>{const t=Object.keys(e).map(i=>({key:i,val:e[i]}))||[];return t.sort((i,a)=>i.val-a.val),t.reduce((i,a)=>q({},i,{[a.key]:a.val}),{})};function Iv(e){const{values:t={xs:0,sm:600,md:900,lg:1200,xl:1536},unit:i="px",step:a=5}=e,n=$(e,Mv),o=zv(t),s=Object.keys(o);function r(h){return`@media (min-width:${typeof t[h]=="number"?t[h]:h}${i})`}function l(h){return`@media (max-width:${(typeof t[h]=="number"?t[h]:h)-a/100}${i})`}function d(h,c){const g=s.indexOf(c);return`@media (min-width:${typeof t[h]=="number"?t[h]:h}${i}) and (max-width:${(g!==-1&&typeof t[s[g]]=="number"?t[s[g]]:c)-a/100}${i})`}function p(h){return s.indexOf(h)+1<s.length?d(h,s[s.indexOf(h)+1]):r(h)}function f(h){const c=s.indexOf(h);return c===0?r(s[1]):c===s.length-1?l(s[c]):d(h,s[s.indexOf(h)+1]).replace("@media","@media not all and")}return q({keys:s,values:o,up:r,down:l,between:d,only:p,not:f,unit:i},n)}const Nv={borderRadius:4},Ov=Nv;function eo(e,t){return t?At(e,t,{clone:!1}):e}const Bc={xs:0,sm:600,md:900,lg:1200,xl:1536},Pm={keys:["xs","sm","md","lg","xl"],up:e=>`@media (min-width:${Bc[e]}px)`};function vi(e,t,i){const a=e.theme||{};if(Array.isArray(t)){const o=a.breakpoints||Pm;return t.reduce((s,r,l)=>(s[o.up(o.keys[l])]=i(t[l]),s),{})}if(typeof t=="object"){const o=a.breakpoints||Pm;return Object.keys(t).reduce((s,r)=>{if(Object.keys(o.values||Bc).indexOf(r)!==-1){const l=o.up(r);s[l]=i(t[r],r)}else{const l=r;s[l]=t[l]}return s},{})}return i(t)}function Lv(e={}){var t;return((t=e.keys)==null?void 0:t.reduce((a,n)=>{const o=e.up(n);return a[o]={},a},{}))||{}}function Wv(e,t){return e.reduce((i,a)=>{const n=i[a];return(!n||Object.keys(n).length===0)&&delete i[a],i},t)}function Qr(e,t,i=!0){if(!t||typeof t!="string")return null;if(e&&e.vars&&i){const a=`vars.${t}`.split(".").reduce((n,o)=>n&&n[o]?n[o]:null,e);if(a!=null)return a}return t.split(".").reduce((a,n)=>a&&a[n]!=null?a[n]:null,e)}function ir(e,t,i,a=i){let n;return typeof e=="function"?n=e(i):Array.isArray(e)?n=e[i]||a:n=Qr(e,i)||a,t&&(n=t(n,a,e)),n}function se(e){const{prop:t,cssProperty:i=e.prop,themeKey:a,transform:n}=e,o=s=>{if(s[t]==null)return null;const r=s[t],l=s.theme,d=Qr(l,a)||{};return vi(s,r,f=>{let h=ir(d,n,f);return f===h&&typeof f=="string"&&(h=ir(d,n,`${t}${f==="default"?"":V(f)}`,f)),i===!1?h:{[i]:h}})};return o.propTypes={},o.filterProps=[t],o}function $v(e){const t={};return i=>(t[i]===void 0&&(t[i]=e(i)),t[i])}const Gv={m:"margin",p:"padding"},Uv={t:"Top",r:"Right",b:"Bottom",l:"Left",x:["Left","Right"],y:["Top","Bottom"]},Sm={marginX:"mx",marginY:"my",paddingX:"px",paddingY:"py"},Kv=$v(e=>{if(e.length>2)if(Sm[e])e=Sm[e];else return[e];const[t,i]=e.split(""),a=Gv[t],n=Uv[i]||"";return Array.isArray(n)?n.map(o=>a+o):[a+n]}),Ac=["m","mt","mr","mb","ml","mx","my","margin","marginTop","marginRight","marginBottom","marginLeft","marginX","marginY","marginInline","marginInlineStart","marginInlineEnd","marginBlock","marginBlockStart","marginBlockEnd"],jc=["p","pt","pr","pb","pl","px","py","padding","paddingTop","paddingRight","paddingBottom","paddingLeft","paddingX","paddingY","paddingInline","paddingInlineStart","paddingInlineEnd","paddingBlock","paddingBlockStart","paddingBlockEnd"];[...Ac,...jc];function Ao(e,t,i,a){var n;const o=(n=Qr(e,t,!1))!=null?n:i;return typeof o=="number"?s=>typeof s=="string"?s:o*s:Array.isArray(o)?s=>typeof s=="string"?s:o[s]:typeof o=="function"?o:()=>{}}function Ry(e){return Ao(e,"spacing",8)}function jo(e,t){if(typeof t=="string"||t==null)return t;const i=Math.abs(t),a=e(i);return t>=0?a:typeof a=="number"?-a:`-${a}`}function Hv(e,t){return i=>e.reduce((a,n)=>(a[n]=jo(t,i),a),{})}function Vv(e,t,i,a){if(t.indexOf(i)===-1)return null;const n=Kv(i),o=Hv(n,a),s=e[i];return vi(e,s,o)}function Py(e,t){const i=Ry(e.theme);return Object.keys(e).map(a=>Vv(e,t,a,i)).reduce(eo,{})}function Pe(e){return Py(e,Ac)}Pe.propTypes={};Pe.filterProps=Ac;function Se(e){return Py(e,jc)}Se.propTypes={};Se.filterProps=jc;function Xv(e=8){if(e.mui)return e;const t=Ry({spacing:e}),i=(...a)=>(a.length===0?[1]:a).map(o=>{const s=t(o);return typeof s=="number"?`${s}px`:s}).join(" ");return i.mui=!0,i}function Jr(...e){const t=e.reduce((a,n)=>(n.filterProps.forEach(o=>{a[o]=n}),a),{}),i=a=>Object.keys(a).reduce((n,o)=>t[o]?eo(n,t[o](a)):n,{});return i.propTypes={},i.filterProps=e.reduce((a,n)=>a.concat(n.filterProps),[]),i}function ei(e){return typeof e!="number"?e:`${e}px solid`}const Yv=se({prop:"border",themeKey:"borders",transform:ei}),Qv=se({prop:"borderTop",themeKey:"borders",transform:ei}),Jv=se({prop:"borderRight",themeKey:"borders",transform:ei}),Zv=se({prop:"borderBottom",themeKey:"borders",transform:ei}),ew=se({prop:"borderLeft",themeKey:"borders",transform:ei}),tw=se({prop:"borderColor",themeKey:"palette"}),iw=se({prop:"borderTopColor",themeKey:"palette"}),aw=se({prop:"borderRightColor",themeKey:"palette"}),nw=se({prop:"borderBottomColor",themeKey:"palette"}),ow=se({prop:"borderLeftColor",themeKey:"palette"}),Zr=e=>{if(e.borderRadius!==void 0&&e.borderRadius!==null){const t=Ao(e.theme,"shape.borderRadius",4),i=a=>({borderRadius:jo(t,a)});return vi(e,e.borderRadius,i)}return null};Zr.propTypes={};Zr.filterProps=["borderRadius"];Jr(Yv,Qv,Jv,Zv,ew,tw,iw,aw,nw,ow,Zr);const el=e=>{if(e.gap!==void 0&&e.gap!==null){const t=Ao(e.theme,"spacing",8),i=a=>({gap:jo(t,a)});return vi(e,e.gap,i)}return null};el.propTypes={};el.filterProps=["gap"];const tl=e=>{if(e.columnGap!==void 0&&e.columnGap!==null){const t=Ao(e.theme,"spacing",8),i=a=>({columnGap:jo(t,a)});return vi(e,e.columnGap,i)}return null};tl.propTypes={};tl.filterProps=["columnGap"];const il=e=>{if(e.rowGap!==void 0&&e.rowGap!==null){const t=Ao(e.theme,"spacing",8),i=a=>({rowGap:jo(t,a)});return vi(e,e.rowGap,i)}return null};il.propTypes={};il.filterProps=["rowGap"];const sw=se({prop:"gridColumn"}),rw=se({prop:"gridRow"}),lw=se({prop:"gridAutoFlow"}),dw=se({prop:"gridAutoColumns"}),pw=se({prop:"gridAutoRows"}),cw=se({prop:"gridTemplateColumns"}),uw=se({prop:"gridTemplateRows"}),mw=se({prop:"gridTemplateAreas"}),fw=se({prop:"gridArea"});Jr(el,tl,il,sw,rw,lw,dw,pw,cw,uw,mw,fw);function an(e,t){return t==="grey"?t:e}const hw=se({prop:"color",themeKey:"palette",transform:an}),gw=se({prop:"bgcolor",cssProperty:"backgroundColor",themeKey:"palette",transform:an}),yw=se({prop:"backgroundColor",themeKey:"palette",transform:an});Jr(hw,gw,yw);function yt(e){return e<=1&&e!==0?`${e*100}%`:e}const _w=se({prop:"width",transform:yt}),Mc=e=>{if(e.maxWidth!==void 0&&e.maxWidth!==null){const t=i=>{var a,n;const o=((a=e.theme)==null||(a=a.breakpoints)==null||(a=a.values)==null?void 0:a[i])||Bc[i];return o?((n=e.theme)==null||(n=n.breakpoints)==null?void 0:n.unit)!=="px"?{maxWidth:`${o}${e.theme.breakpoints.unit}`}:{maxWidth:o}:{maxWidth:yt(i)}};return vi(e,e.maxWidth,t)}return null};Mc.filterProps=["maxWidth"];const bw=se({prop:"minWidth",transform:yt}),kw=se({prop:"height",transform:yt}),vw=se({prop:"maxHeight",transform:yt}),ww=se({prop:"minHeight",transform:yt});se({prop:"size",cssProperty:"width",transform:yt});se({prop:"size",cssProperty:"height",transform:yt});const qw=se({prop:"boxSizing"});Jr(_w,Mc,bw,kw,vw,ww,qw);const xw={border:{themeKey:"borders",transform:ei},borderTop:{themeKey:"borders",transform:ei},borderRight:{themeKey:"borders",transform:ei},borderBottom:{themeKey:"borders",transform:ei},borderLeft:{themeKey:"borders",transform:ei},borderColor:{themeKey:"palette"},borderTopColor:{themeKey:"palette"},borderRightColor:{themeKey:"palette"},borderBottomColor:{themeKey:"palette"},borderLeftColor:{themeKey:"palette"},borderRadius:{themeKey:"shape.borderRadius",style:Zr},color:{themeKey:"palette",transform:an},bgcolor:{themeKey:"palette",cssProperty:"backgroundColor",transform:an},backgroundColor:{themeKey:"palette",transform:an},p:{style:Se},pt:{style:Se},pr:{style:Se},pb:{style:Se},pl:{style:Se},px:{style:Se},py:{style:Se},padding:{style:Se},paddingTop:{style:Se},paddingRight:{style:Se},paddingBottom:{style:Se},paddingLeft:{style:Se},paddingX:{style:Se},paddingY:{style:Se},paddingInline:{style:Se},paddingInlineStart:{style:Se},paddingInlineEnd:{style:Se},paddingBlock:{style:Se},paddingBlockStart:{style:Se},paddingBlockEnd:{style:Se},m:{style:Pe},mt:{style:Pe},mr:{style:Pe},mb:{style:Pe},ml:{style:Pe},mx:{style:Pe},my:{style:Pe},margin:{style:Pe},marginTop:{style:Pe},marginRight:{style:Pe},marginBottom:{style:Pe},marginLeft:{style:Pe},marginX:{style:Pe},marginY:{style:Pe},marginInline:{style:Pe},marginInlineStart:{style:Pe},marginInlineEnd:{style:Pe},marginBlock:{style:Pe},marginBlockStart:{style:Pe},marginBlockEnd:{style:Pe},displayPrint:{cssProperty:!1,transform:e=>({"@media print":{display:e}})},display:{},overflow:{},textOverflow:{},visibility:{},whiteSpace:{},flexBasis:{},flexDirection:{},flexWrap:{},justifyContent:{},alignItems:{},alignContent:{},order:{},flex:{},flexGrow:{},flexShrink:{},alignSelf:{},justifyItems:{},justifySelf:{},gap:{style:el},rowGap:{style:il},columnGap:{style:tl},gridColumn:{},gridRow:{},gridAutoFlow:{},gridAutoColumns:{},gridAutoRows:{},gridTemplateColumns:{},gridTemplateRows:{},gridTemplateAreas:{},gridArea:{},position:{},zIndex:{themeKey:"zIndex"},top:{},right:{},bottom:{},left:{},boxShadow:{themeKey:"shadows"},width:{transform:yt},maxWidth:{style:Mc},minWidth:{transform:yt},height:{transform:yt},maxHeight:{transform:yt},minHeight:{transform:yt},boxSizing:{},fontFamily:{themeKey:"typography"},fontSize:{themeKey:"typography"},fontStyle:{themeKey:"typography"},fontWeight:{themeKey:"typography"},letterSpacing:{},textTransform:{},lineHeight:{},textAlign:{},typography:{cssProperty:!1,themeKey:"typography"}},al=xw;function Fw(...e){const t=e.reduce((a,n)=>a.concat(Object.keys(n)),[]),i=new Set(t);return e.every(a=>i.size===Object.keys(a).length)}function Tw(e,t){return typeof e=="function"?e(t):e}function Dw(){function e(i,a,n,o){const s={[i]:a,theme:n},r=o[i];if(!r)return{[i]:a};const{cssProperty:l=i,themeKey:d,transform:p,style:f}=r;if(a==null)return null;if(d==="typography"&&a==="inherit")return{[i]:a};const h=Qr(n,d)||{};return f?f(s):vi(s,a,g=>{let m=ir(h,p,g);return g===m&&typeof g=="string"&&(m=ir(h,p,`${i}${g==="default"?"":V(g)}`,g)),l===!1?m:{[l]:m}})}function t(i){var a;const{sx:n,theme:o={}}=i||{};if(!n)return null;const s=(a=o.unstable_sxConfig)!=null?a:al;function r(l){let d=l;if(typeof l=="function")d=l(o);else if(typeof l!="object")return l;if(!d)return null;const p=Lv(o.breakpoints),f=Object.keys(p);let h=p;return Object.keys(d).forEach(c=>{const g=Tw(d[c],o);if(g!=null)if(typeof g=="object")if(s[c])h=eo(h,e(c,g,o,s));else{const m=vi({theme:o},g,x=>({[c]:x}));Fw(m,g)?h[c]=t({sx:g,theme:o}):h=eo(h,m)}else h=eo(h,e(c,g,o,s))}),Wv(f,h)}return Array.isArray(n)?n.map(r):r(n)}return t}const Sy=Dw();Sy.filterProps=["sx"];const nl=Sy,Cw=["breakpoints","palette","spacing","shape"];function zc(e={},...t){const{breakpoints:i={},palette:a={},spacing:n,shape:o={}}=e,s=$(e,Cw),r=Iv(i),l=Xv(n);let d=At({breakpoints:r,direction:"ltr",components:{},palette:q({mode:"light"},a),spacing:l,shape:q({},Ov,o)},s);return d=t.reduce((p,f)=>At(p,f),d),d.unstable_sxConfig=q({},al,s==null?void 0:s.unstable_sxConfig),d.unstable_sx=function(f){return nl({sx:f,theme:this})},d}function Rw(e){return Object.keys(e).length===0}function Pw(e=null){const t=k.useContext(Sc);return!t||Rw(t)?e:t}const Sw=zc();function ol(e=Sw){return Pw(e)}function Ew({styles:e,themeId:t,defaultTheme:i={}}){const a=ol(i),n=typeof e=="function"?e(t&&a[t]||a):e;return u.jsx(Av,{styles:n})}const Bw=["sx"],Aw=e=>{var t,i;const a={systemProps:{},otherProps:{}},n=(t=e==null||(i=e.theme)==null?void 0:i.unstable_sxConfig)!=null?t:al;return Object.keys(e).forEach(o=>{n[o]?a.systemProps[o]=e[o]:a.otherProps[o]=e[o]}),a};function Ey(e){const{sx:t}=e,i=$(e,Bw),{systemProps:a,otherProps:n}=Aw(i);let o;return Array.isArray(t)?o=[a,...t]:typeof t=="function"?o=(...s)=>{const r=t(...s);return ra(r)?q({},a,r):a}:o=q({},a,t),q({},n,{sx:o})}const jw=["className","component"];function Mw(e={}){const{themeId:t,defaultTheme:i,defaultClassName:a="MuiBox-root",generateClassName:n}=e,o=Cy("div",{shouldForwardProp:r=>r!=="theme"&&r!=="sx"&&r!=="as"})(nl);return k.forwardRef(function(l,d){const p=ol(i),f=Ey(l),{className:h,component:c="div"}=f,g=$(f,jw);return u.jsx(o,q({as:c,ref:d,className:K(h,n?n(a):a),theme:t&&p[t]||p},g))})}const zw=["variant"];function Em(e){return e.length===0}function By(e){const{variant:t}=e,i=$(e,zw);let a=t||"";return Object.keys(i).sort().forEach(n=>{n==="color"?a+=Em(a)?e[n]:V(e[n]):a+=`${Em(a)?n:V(n)}${V(e[n].toString())}`}),a}const Iw=["name","slot","skipVariantsResolver","skipSx","overridesResolver"];function Nw(e){return Object.keys(e).length===0}function Ow(e){return typeof e=="string"&&e.charCodeAt(0)>96}const Lw=(e,t)=>t.components&&t.components[e]&&t.components[e].styleOverrides?t.components[e].styleOverrides:null,Ww=(e,t)=>{let i=[];t&&t.components&&t.components[e]&&t.components[e].variants&&(i=t.components[e].variants);const a={};return i.forEach(n=>{const o=By(n.props);a[o]=n.style}),a},$w=(e,t,i,a)=>{var n;const{ownerState:o={}}=e,s=[],r=i==null||(n=i.components)==null||(n=n[a])==null?void 0:n.variants;return r&&r.forEach(l=>{let d=!0;Object.keys(l.props).forEach(p=>{o[p]!==l.props[p]&&e[p]!==l.props[p]&&(d=!1)}),d&&s.push(t[By(l.props)])}),s};function to(e){return e!=="ownerState"&&e!=="theme"&&e!=="sx"&&e!=="as"}const Gw=zc(),Uw=e=>e&&e.charAt(0).toLowerCase()+e.slice(1);function Bn({defaultTheme:e,theme:t,themeId:i}){return Nw(t)?e:t[i]||t}function Kw(e){return e?(t,i)=>i[e]:null}function Hw(e={}){const{themeId:t,defaultTheme:i=Gw,rootShouldForwardProp:a=to,slotShouldForwardProp:n=to}=e,o=s=>nl(q({},s,{theme:Bn(q({},s,{defaultTheme:i,themeId:t}))}));return o.__mui_systemSx=!0,(s,r={})=>{jv(s,v=>v.filter(F=>!(F!=null&&F.__mui_systemSx)));const{name:l,slot:d,skipVariantsResolver:p,skipSx:f,overridesResolver:h=Kw(Uw(d))}=r,c=$(r,Iw),g=p!==void 0?p:d&&d!=="Root"&&d!=="root"||!1,m=f||!1;let x,_=to;d==="Root"||d==="root"?_=a:d?_=n:Ow(s)&&(_=void 0);const y=Cy(s,q({shouldForwardProp:_,label:x},c)),b=(v,...F)=>{const T=F?F.map(R=>typeof R=="function"&&R.__emotion_real!==R?A=>R(q({},A,{theme:Bn(q({},A,{defaultTheme:i,themeId:t}))})):R):[];let w=v;l&&h&&T.push(R=>{const A=Bn(q({},R,{defaultTheme:i,themeId:t})),M=Lw(l,A);if(M){const O={};return Object.entries(M).forEach(([E,j])=>{O[E]=typeof j=="function"?j(q({},R,{theme:A})):j}),h(R,O)}return null}),l&&!g&&T.push(R=>{const A=Bn(q({},R,{defaultTheme:i,themeId:t}));return $w(R,Ww(l,A),A,l)}),m||T.push(o);const D=T.length-F.length;if(Array.isArray(v)&&D>0){const R=new Array(D).fill("");w=[...v,...R],w.raw=[...v.raw,...R]}else typeof v=="function"&&v.__emotion_real!==v&&(w=R=>v(q({},R,{theme:Bn(q({},R,{defaultTheme:i,themeId:t}))})));const P=y(w,...T);return s.muiName&&(P.muiName=s.muiName),P};return y.withConfig&&(b.withConfig=y.withConfig),b}}function Vw(e){const{theme:t,name:i,props:a}=e;return!t||!t.components||!t.components[i]||!t.components[i].defaultProps?a:ly(t.components[i].defaultProps,a)}function Xw({props:e,name:t,defaultTheme:i,themeId:a}){let n=ol(i);return a&&(n=n[a]||n),Vw({theme:n,name:t,props:e})}function Ic(e,t=0,i=1){return Math.min(Math.max(t,e),i)}function Yw(e){e=e.slice(1);const t=new RegExp(`.{1,${e.length>=6?2:1}}`,"g");let i=e.match(t);return i&&i[0].length===1&&(i=i.map(a=>a+a)),i?`rgb${i.length===4?"a":""}(${i.map((a,n)=>n<3?parseInt(a,16):Math.round(parseInt(a,16)/255*1e3)/1e3).join(", ")})`:""}function qa(e){if(e.type)return e;if(e.charAt(0)==="#")return qa(Yw(e));const t=e.indexOf("("),i=e.substring(0,t);if(["rgb","rgba","hsl","hsla","color"].indexOf(i)===-1)throw new Error(Xi(9,e));let a=e.substring(t+1,e.length-1),n;if(i==="color"){if(a=a.split(" "),n=a.shift(),a.length===4&&a[3].charAt(0)==="/"&&(a[3]=a[3].slice(1)),["srgb","display-p3","a98-rgb","prophoto-rgb","rec-2020"].indexOf(n)===-1)throw new Error(Xi(10,n))}else a=a.split(",");return a=a.map(o=>parseFloat(o)),{type:i,values:a,colorSpace:n}}function sl(e){const{type:t,colorSpace:i}=e;let{values:a}=e;return t.indexOf("rgb")!==-1?a=a.map((n,o)=>o<3?parseInt(n,10):n):t.indexOf("hsl")!==-1&&(a[1]=`${a[1]}%`,a[2]=`${a[2]}%`),t.indexOf("color")!==-1?a=`${i} ${a.join(" ")}`:a=`${a.join(", ")}`,`${t}(${a})`}function Qw(e){e=qa(e);const{values:t}=e,i=t[0],a=t[1]/100,n=t[2]/100,o=a*Math.min(n,1-n),s=(d,p=(d+i/30)%12)=>n-o*Math.max(Math.min(p-3,9-p,1),-1);let r="rgb";const l=[Math.round(s(0)*255),Math.round(s(8)*255),Math.round(s(4)*255)];return e.type==="hsla"&&(r+="a",l.push(t[3])),sl({type:r,values:l})}function Bm(e){e=qa(e);let t=e.type==="hsl"||e.type==="hsla"?qa(Qw(e)).values:e.values;return t=t.map(i=>(e.type!=="color"&&(i/=255),i<=.03928?i/12.92:((i+.055)/1.055)**2.4)),Number((.2126*t[0]+.7152*t[1]+.0722*t[2]).toFixed(3))}function Jw(e,t){const i=Bm(e),a=Bm(t);return(Math.max(i,a)+.05)/(Math.min(i,a)+.05)}function hi(e,t){return e=qa(e),t=Ic(t),(e.type==="rgb"||e.type==="hsl")&&(e.type+="a"),e.type==="color"?e.values[3]=`/${t}`:e.values[3]=t,sl(e)}function sp(e,t){if(e=qa(e),t=Ic(t),e.type.indexOf("hsl")!==-1)e.values[2]*=1-t;else if(e.type.indexOf("rgb")!==-1||e.type.indexOf("color")!==-1)for(let i=0;i<3;i+=1)e.values[i]*=1-t;return sl(e)}function rp(e,t){if(e=qa(e),t=Ic(t),e.type.indexOf("hsl")!==-1)e.values[2]+=(100-e.values[2])*t;else if(e.type.indexOf("rgb")!==-1)for(let i=0;i<3;i+=1)e.values[i]+=(255-e.values[i])*t;else if(e.type.indexOf("color")!==-1)for(let i=0;i<3;i+=1)e.values[i]+=(1-e.values[i])*t;return sl(e)}function Zw(e,t){return q({toolbar:{minHeight:56,[e.up("xs")]:{"@media (orientation: landscape)":{minHeight:48}},[e.up("sm")]:{minHeight:64}}},t)}const e3={black:"#000",white:"#fff"},To=e3,t3={50:"#fafafa",100:"#f5f5f5",200:"#eeeeee",300:"#e0e0e0",400:"#bdbdbd",500:"#9e9e9e",600:"#757575",700:"#616161",800:"#424242",900:"#212121",A100:"#f5f5f5",A200:"#eeeeee",A400:"#bdbdbd",A700:"#616161"},i3=t3,a3={50:"#f3e5f5",100:"#e1bee7",200:"#ce93d8",300:"#ba68c8",400:"#ab47bc",500:"#9c27b0",600:"#8e24aa",700:"#7b1fa2",800:"#6a1b9a",900:"#4a148c",A100:"#ea80fc",A200:"#e040fb",A400:"#d500f9",A700:"#aa00ff"},Ra=a3,n3={50:"#ffebee",100:"#ffcdd2",200:"#ef9a9a",300:"#e57373",400:"#ef5350",500:"#f44336",600:"#e53935",700:"#d32f2f",800:"#c62828",900:"#b71c1c",A100:"#ff8a80",A200:"#ff5252",A400:"#ff1744",A700:"#d50000"},Pa=n3,o3={50:"#fff3e0",100:"#ffe0b2",200:"#ffcc80",300:"#ffb74d",400:"#ffa726",500:"#ff9800",600:"#fb8c00",700:"#f57c00",800:"#ef6c00",900:"#e65100",A100:"#ffd180",A200:"#ffab40",A400:"#ff9100",A700:"#ff6d00"},An=o3,s3={50:"#e3f2fd",100:"#bbdefb",200:"#90caf9",300:"#64b5f6",400:"#42a5f5",500:"#2196f3",600:"#1e88e5",700:"#1976d2",800:"#1565c0",900:"#0d47a1",A100:"#82b1ff",A200:"#448aff",A400:"#2979ff",A700:"#2962ff"},Sa=s3,r3={50:"#e1f5fe",100:"#b3e5fc",200:"#81d4fa",300:"#4fc3f7",400:"#29b6f6",500:"#03a9f4",600:"#039be5",700:"#0288d1",800:"#0277bd",900:"#01579b",A100:"#80d8ff",A200:"#40c4ff",A400:"#00b0ff",A700:"#0091ea"},Ea=r3,l3={50:"#e8f5e9",100:"#c8e6c9",200:"#a5d6a7",300:"#81c784",400:"#66bb6a",500:"#4caf50",600:"#43a047",700:"#388e3c",800:"#2e7d32",900:"#1b5e20",A100:"#b9f6ca",A200:"#69f0ae",A400:"#00e676",A700:"#00c853"},Ba=l3,d3=["mode","contrastThreshold","tonalOffset"],Am={text:{primary:"rgba(0, 0, 0, 0.87)",secondary:"rgba(0, 0, 0, 0.6)",disabled:"rgba(0, 0, 0, 0.38)"},divider:"rgba(0, 0, 0, 0.12)",background:{paper:To.white,default:To.white},action:{active:"rgba(0, 0, 0, 0.54)",hover:"rgba(0, 0, 0, 0.04)",hoverOpacity:.04,selected:"rgba(0, 0, 0, 0.08)",selectedOpacity:.08,disabled:"rgba(0, 0, 0, 0.26)",disabledBackground:"rgba(0, 0, 0, 0.12)",disabledOpacity:.38,focus:"rgba(0, 0, 0, 0.12)",focusOpacity:.12,activatedOpacity:.12}},$l={text:{primary:To.white,secondary:"rgba(255, 255, 255, 0.7)",disabled:"rgba(255, 255, 255, 0.5)",icon:"rgba(255, 255, 255, 0.5)"},divider:"rgba(255, 255, 255, 0.12)",background:{paper:"#121212",default:"#121212"},action:{active:To.white,hover:"rgba(255, 255, 255, 0.08)",hoverOpacity:.08,selected:"rgba(255, 255, 255, 0.16)",selectedOpacity:.16,disabled:"rgba(255, 255, 255, 0.3)",disabledBackground:"rgba(255, 255, 255, 0.12)",disabledOpacity:.38,focus:"rgba(255, 255, 255, 0.12)",focusOpacity:.12,activatedOpacity:.24}};function jm(e,t,i,a){const n=a.light||a,o=a.dark||a*1.5;e[t]||(e.hasOwnProperty(i)?e[t]=e[i]:t==="light"?e.light=rp(e.main,n):t==="dark"&&(e.dark=sp(e.main,o)))}function p3(e="light"){return e==="dark"?{main:Sa[200],light:Sa[50],dark:Sa[400]}:{main:Sa[700],light:Sa[400],dark:Sa[800]}}function c3(e="light"){return e==="dark"?{main:Ra[200],light:Ra[50],dark:Ra[400]}:{main:Ra[500],light:Ra[300],dark:Ra[700]}}function u3(e="light"){return e==="dark"?{main:Pa[500],light:Pa[300],dark:Pa[700]}:{main:Pa[700],light:Pa[400],dark:Pa[800]}}function m3(e="light"){return e==="dark"?{main:Ea[400],light:Ea[300],dark:Ea[700]}:{main:Ea[700],light:Ea[500],dark:Ea[900]}}function f3(e="light"){return e==="dark"?{main:Ba[400],light:Ba[300],dark:Ba[700]}:{main:Ba[800],light:Ba[500],dark:Ba[900]}}function h3(e="light"){return e==="dark"?{main:An[400],light:An[300],dark:An[700]}:{main:"#ed6c02",light:An[500],dark:An[900]}}function g3(e){const{mode:t="light",contrastThreshold:i=3,tonalOffset:a=.2}=e,n=$(e,d3),o=e.primary||p3(t),s=e.secondary||c3(t),r=e.error||u3(t),l=e.info||m3(t),d=e.success||f3(t),p=e.warning||h3(t);function f(m){return Jw(m,$l.text.primary)>=i?$l.text.primary:Am.text.primary}const h=({color:m,name:x,mainShade:_=500,lightShade:y=300,darkShade:b=700})=>{if(m=q({},m),!m.main&&m[_]&&(m.main=m[_]),!m.hasOwnProperty("main"))throw new Error(Xi(11,x?` (${x})`:"",_));if(typeof m.main!="string")throw new Error(Xi(12,x?` (${x})`:"",JSON.stringify(m.main)));return jm(m,"light",y,a),jm(m,"dark",b,a),m.contrastText||(m.contrastText=f(m.main)),m},c={dark:$l,light:Am};return At(q({common:q({},To),mode:t,primary:h({color:o,name:"primary"}),secondary:h({color:s,name:"secondary",mainShade:"A400",lightShade:"A200",darkShade:"A700"}),error:h({color:r,name:"error"}),warning:h({color:p,name:"warning"}),info:h({color:l,name:"info"}),success:h({color:d,name:"success"}),grey:i3,contrastThreshold:i,getContrastText:f,augmentColor:h,tonalOffset:a},c[t]),n)}const y3=["fontFamily","fontSize","fontWeightLight","fontWeightRegular","fontWeightMedium","fontWeightBold","htmlFontSize","allVariants","pxToRem"];function _3(e){return Math.round(e*1e5)/1e5}const Mm={textTransform:"uppercase"},zm='"Roboto", "Helvetica", "Arial", sans-serif';function b3(e,t){const i=typeof t=="function"?t(e):t,{fontFamily:a=zm,fontSize:n=14,fontWeightLight:o=300,fontWeightRegular:s=400,fontWeightMedium:r=500,fontWeightBold:l=700,htmlFontSize:d=16,allVariants:p,pxToRem:f}=i,h=$(i,y3),c=n/14,g=f||(_=>`${_/d*c}rem`),m=(_,y,b,v,F)=>q({fontFamily:a,fontWeight:_,fontSize:g(y),lineHeight:b},a===zm?{letterSpacing:`${_3(v/y)}em`}:{},F,p),x={h1:m(o,96,1.167,-1.5),h2:m(o,60,1.2,-.5),h3:m(s,48,1.167,0),h4:m(s,34,1.235,.25),h5:m(s,24,1.334,0),h6:m(r,20,1.6,.15),subtitle1:m(s,16,1.75,.15),subtitle2:m(r,14,1.57,.1),body1:m(s,16,1.5,.15),body2:m(s,14,1.43,.15),button:m(r,14,1.75,.4,Mm),caption:m(s,12,1.66,.4),overline:m(s,12,2.66,1,Mm),inherit:{fontFamily:"inherit",fontWeight:"inherit",fontSize:"inherit",lineHeight:"inherit",letterSpacing:"inherit"}};return At(q({htmlFontSize:d,pxToRem:g,fontFamily:a,fontSize:n,fontWeightLight:o,fontWeightRegular:s,fontWeightMedium:r,fontWeightBold:l},x),h,{clone:!1})}const k3=.2,v3=.14,w3=.12;function qe(...e){return[`${e[0]}px ${e[1]}px ${e[2]}px ${e[3]}px rgba(0,0,0,${k3})`,`${e[4]}px ${e[5]}px ${e[6]}px ${e[7]}px rgba(0,0,0,${v3})`,`${e[8]}px ${e[9]}px ${e[10]}px ${e[11]}px rgba(0,0,0,${w3})`].join(",")}const q3=["none",qe(0,2,1,-1,0,1,1,0,0,1,3,0),qe(0,3,1,-2,0,2,2,0,0,1,5,0),qe(0,3,3,-2,0,3,4,0,0,1,8,0),qe(0,2,4,-1,0,4,5,0,0,1,10,0),qe(0,3,5,-1,0,5,8,0,0,1,14,0),qe(0,3,5,-1,0,6,10,0,0,1,18,0),qe(0,4,5,-2,0,7,10,1,0,2,16,1),qe(0,5,5,-3,0,8,10,1,0,3,14,2),qe(0,5,6,-3,0,9,12,1,0,3,16,2),qe(0,6,6,-3,0,10,14,1,0,4,18,3),qe(0,6,7,-4,0,11,15,1,0,4,20,3),qe(0,7,8,-4,0,12,17,2,0,5,22,4),qe(0,7,8,-4,0,13,19,2,0,5,24,4),qe(0,7,9,-4,0,14,21,2,0,5,26,4),qe(0,8,9,-5,0,15,22,2,0,6,28,5),qe(0,8,10,-5,0,16,24,2,0,6,30,5),qe(0,8,11,-5,0,17,26,2,0,6,32,5),qe(0,9,11,-5,0,18,28,2,0,7,34,6),qe(0,9,12,-6,0,19,29,2,0,7,36,6),qe(0,10,13,-6,0,20,31,3,0,8,38,7),qe(0,10,13,-6,0,21,33,3,0,8,40,7),qe(0,10,14,-6,0,22,35,3,0,8,42,7),qe(0,11,14,-7,0,23,36,3,0,9,44,8),qe(0,11,15,-7,0,24,38,3,0,9,46,8)],x3=q3,F3=["duration","easing","delay"],T3={easeInOut:"cubic-bezier(0.4, 0, 0.2, 1)",easeOut:"cubic-bezier(0.0, 0, 0.2, 1)",easeIn:"cubic-bezier(0.4, 0, 1, 1)",sharp:"cubic-bezier(0.4, 0, 0.6, 1)"},D3={shortest:150,shorter:200,short:250,standard:300,complex:375,enteringScreen:225,leavingScreen:195};function Im(e){return`${Math.round(e)}ms`}function C3(e){if(!e)return 0;const t=e/36;return Math.round((4+15*t**.25+t/5)*10)}function R3(e){const t=q({},T3,e.easing),i=q({},D3,e.duration);return q({getAutoHeightDuration:C3,create:(n=["all"],o={})=>{const{duration:s=i.standard,easing:r=t.easeInOut,delay:l=0}=o;return $(o,F3),(Array.isArray(n)?n:[n]).map(d=>`${d} ${typeof s=="string"?s:Im(s)} ${r} ${typeof l=="string"?l:Im(l)}`).join(",")}},e,{easing:t,duration:i})}const P3={mobileStepper:1e3,fab:1050,speedDial:1050,appBar:1100,drawer:1200,modal:1300,snackbar:1400,tooltip:1500},S3=P3,E3=["breakpoints","mixins","spacing","palette","transitions","typography","shape"];function Ay(e={},...t){const{mixins:i={},palette:a={},transitions:n={},typography:o={}}=e,s=$(e,E3);if(e.vars)throw new Error(Xi(18));const r=g3(a),l=zc(e);let d=At(l,{mixins:Zw(l.breakpoints,i),palette:r,shadows:x3.slice(),typography:b3(r,o),transitions:R3(n),zIndex:q({},S3)});return d=At(d,s),d=t.reduce((p,f)=>At(p,f),d),d.unstable_sxConfig=q({},al,s==null?void 0:s.unstable_sxConfig),d.unstable_sx=function(f){return nl({sx:f,theme:this})},d}const B3=Ay(),rl=B3,Mo="$$material";function fe({props:e,name:t}){return Xw({props:e,name:t,defaultTheme:rl,themeId:Mo})}const Ht=e=>to(e)&&e!=="classes",A3=to,j3=Hw({themeId:Mo,defaultTheme:rl,rootShouldForwardProp:Ht}),W=j3;function M3(e){return ue("MuiSvgIcon",e)}oe("MuiSvgIcon",["root","colorPrimary","colorSecondary","colorAction","colorError","colorDisabled","fontSizeInherit","fontSizeSmall","fontSizeMedium","fontSizeLarge"]);const z3=["children","className","color","component","fontSize","htmlColor","inheritViewBox","titleAccess","viewBox"],I3=e=>{const{color:t,fontSize:i,classes:a}=e,n={root:["root",t!=="inherit"&&`color${V(t)}`,`fontSize${V(i)}`]};return me(n,M3,a)},N3=W("svg",{name:"MuiSvgIcon",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,i.color!=="inherit"&&t[`color${V(i.color)}`],t[`fontSize${V(i.fontSize)}`]]}})(({theme:e,ownerState:t})=>{var i,a,n,o,s,r,l,d,p,f,h,c,g;return{userSelect:"none",width:"1em",height:"1em",display:"inline-block",fill:t.hasSvgAsChild?void 0:"currentColor",flexShrink:0,transition:(i=e.transitions)==null||(a=i.create)==null?void 0:a.call(i,"fill",{duration:(n=e.transitions)==null||(n=n.duration)==null?void 0:n.shorter}),fontSize:{inherit:"inherit",small:((o=e.typography)==null||(s=o.pxToRem)==null?void 0:s.call(o,20))||"1.25rem",medium:((r=e.typography)==null||(l=r.pxToRem)==null?void 0:l.call(r,24))||"1.5rem",large:((d=e.typography)==null||(p=d.pxToRem)==null?void 0:p.call(d,35))||"2.1875rem"}[t.fontSize],color:(f=(h=(e.vars||e).palette)==null||(h=h[t.color])==null?void 0:h.main)!=null?f:{action:(c=(e.vars||e).palette)==null||(c=c.action)==null?void 0:c.active,disabled:(g=(e.vars||e).palette)==null||(g=g.action)==null?void 0:g.disabled,inherit:void 0}[t.color]}}),jy=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiSvgIcon"}),{children:n,className:o,color:s="inherit",component:r="svg",fontSize:l="medium",htmlColor:d,inheritViewBox:p=!1,titleAccess:f,viewBox:h="0 0 24 24"}=a,c=$(a,z3),g=k.isValidElement(n)&&n.type==="svg",m=q({},a,{color:s,component:r,fontSize:l,instanceFontSize:t.fontSize,inheritViewBox:p,viewBox:h,hasSvgAsChild:g}),x={};p||(x.viewBox=h);const _=I3(m);return u.jsxs(N3,q({as:r,className:K(_.root,o),focusable:"false",color:d,"aria-hidden":f?void 0:!0,role:f?"img":void 0,ref:i},x,c,g&&n.props,{ownerState:m,children:[g?n.props.children:n,f?u.jsx("title",{children:f}):null]}))});jy.muiName="SvgIcon";const Nm=jy;function Ta(e,t){function i(a,n){return u.jsx(Nm,q({"data-testid":`${t}Icon`,ref:n},a,{children:e}))}return i.muiName=Nm.muiName,k.memo(k.forwardRef(i))}const O3={configure:e=>{qc.configure(e)}},L3=Object.freeze(Object.defineProperty({__proto__:null,capitalize:V,createChainedFunction:ep,createSvgIcon:Ta,debounce:Mr,deprecatedPropType:_k,isMuiElement:vs,ownerDocument:mt,ownerWindow:oi,requirePropFactory:bk,setRef:er,unstable_ClassNameGenerator:O3,unstable_useEnhancedEffect:Yi,unstable_useId:oy,unsupportedProp:wk,useControlled:tp,useEventCallback:ma,useForkRef:Ye,useIsFocusVisible:sy},Symbol.toStringTag,{value:"Module"})),W3=N_(L3);var Om;function Nc(){return Om||(Om=1,function(e){"use client";Object.defineProperty(e,"__esModule",{value:!0}),Object.defineProperty(e,"default",{enumerable:!0,get:function(){return t.createSvgIcon}});var t=W3}(Ol)),Ol}var $3=kc;Object.defineProperty(bc,"__esModule",{value:!0});var My=bc.default=void 0,G3=$3(Nc()),U3=u,K3=(0,G3.default)((0,U3.jsx)("path",{d:"M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"}),"Search");My=bc.default=K3;var Oc={},H3=kc;Object.defineProperty(Oc,"__esModule",{value:!0});var zy=Oc.default=void 0,V3=H3(Nc()),X3=u,Y3=(0,V3.default)((0,X3.jsx)("path",{d:"M19 7v4H5.83l3.58-3.59L8 6l-6 6 6 6 1.41-1.41L5.83 13H21V7z"}),"KeyboardReturn");zy=Oc.default=Y3;function wi(e){return Array.isArray?Array.isArray(e):Oy(e)==="[object Array]"}const Q3=1/0;function J3(e){if(typeof e=="string")return e;let t=e+"";return t=="0"&&1/e==-Q3?"-0":t}function Z3(e){return e==null?"":J3(e)}function ti(e){return typeof e=="string"}function Iy(e){return typeof e=="number"}function e2(e){return e===!0||e===!1||t2(e)&&Oy(e)=="[object Boolean]"}function Ny(e){return typeof e=="object"}function t2(e){return Ny(e)&&e!==null}function gt(e){return e!=null}function Gl(e){return!e.trim().length}function Oy(e){return e==null?e===void 0?"[object Undefined]":"[object Null]":Object.prototype.toString.call(e)}const i2="Incorrect 'index' type",a2=e=>`Invalid value for key ${e}`,n2=e=>`Pattern length exceeds max of ${e}.`,o2=e=>`Missing ${e} property in key`,s2=e=>`Property 'weight' in key '${e}' must be a positive integer`,Lm=Object.prototype.hasOwnProperty;class r2{constructor(t){this._keys=[],this._keyMap={};let i=0;t.forEach(a=>{let n=Ly(a);i+=n.weight,this._keys.push(n),this._keyMap[n.id]=n,i+=n.weight}),this._keys.forEach(a=>{a.weight/=i})}get(t){return this._keyMap[t]}keys(){return this._keys}toJSON(){return JSON.stringify(this._keys)}}function Ly(e){let t=null,i=null,a=null,n=1,o=null;if(ti(e)||wi(e))a=e,t=Wm(e),i=lp(e);else{if(!Lm.call(e,"name"))throw new Error(o2("name"));const s=e.name;if(a=s,Lm.call(e,"weight")&&(n=e.weight,n<=0))throw new Error(s2(s));t=Wm(s),i=lp(s),o=e.getFn}return{path:t,id:i,weight:n,src:a,getFn:o}}function Wm(e){return wi(e)?e:e.split(".")}function lp(e){return wi(e)?e.join("."):e}function l2(e,t){let i=[],a=!1;const n=(o,s,r)=>{if(gt(o))if(!s[r])i.push(o);else{let l=s[r];const d=o[l];if(!gt(d))return;if(r===s.length-1&&(ti(d)||Iy(d)||e2(d)))i.push(Z3(d));else if(wi(d)){a=!0;for(let p=0,f=d.length;p<f;p+=1)n(d[p],s,r+1)}else s.length&&n(d,s,r+1)}};return n(e,ti(t)?t.split("."):t,0),a?i:i[0]}const d2={includeMatches:!1,findAllMatches:!1,minMatchCharLength:1},p2={isCaseSensitive:!1,includeScore:!1,keys:[],shouldSort:!0,sortFn:(e,t)=>e.score===t.score?e.idx<t.idx?-1:1:e.score<t.score?-1:1},c2={location:0,threshold:.6,distance:100},u2={useExtendedSearch:!1,getFn:l2,ignoreLocation:!1,ignoreFieldNorm:!1,fieldNormWeight:1};var H={...p2,...d2,...c2,...u2};const m2=/[^ ]+/g;function f2(e=1,t=3){const i=new Map,a=Math.pow(10,t);return{get(n){const o=n.match(m2).length;if(i.has(o))return i.get(o);const s=1/Math.pow(o,.5*e),r=parseFloat(Math.round(s*a)/a);return i.set(o,r),r},clear(){i.clear()}}}class Lc{constructor({getFn:t=H.getFn,fieldNormWeight:i=H.fieldNormWeight}={}){this.norm=f2(i,3),this.getFn=t,this.isCreated=!1,this.setIndexRecords()}setSources(t=[]){this.docs=t}setIndexRecords(t=[]){this.records=t}setKeys(t=[]){this.keys=t,this._keysMap={},t.forEach((i,a)=>{this._keysMap[i.id]=a})}create(){this.isCreated||!this.docs.length||(this.isCreated=!0,ti(this.docs[0])?this.docs.forEach((t,i)=>{this._addString(t,i)}):this.docs.forEach((t,i)=>{this._addObject(t,i)}),this.norm.clear())}add(t){const i=this.size();ti(t)?this._addString(t,i):this._addObject(t,i)}removeAt(t){this.records.splice(t,1);for(let i=t,a=this.size();i<a;i+=1)this.records[i].i-=1}getValueForItemAtKeyId(t,i){return t[this._keysMap[i]]}size(){return this.records.length}_addString(t,i){if(!gt(t)||Gl(t))return;let a={v:t,i,n:this.norm.get(t)};this.records.push(a)}_addObject(t,i){let a={i,$:{}};this.keys.forEach((n,o)=>{let s=n.getFn?n.getFn(t):this.getFn(t,n.path);if(gt(s)){if(wi(s)){let r=[];const l=[{nestedArrIndex:-1,value:s}];for(;l.length;){const{nestedArrIndex:d,value:p}=l.pop();if(gt(p))if(ti(p)&&!Gl(p)){let f={v:p,i:d,n:this.norm.get(p)};r.push(f)}else wi(p)&&p.forEach((f,h)=>{l.push({nestedArrIndex:h,value:f})})}a.$[o]=r}else if(ti(s)&&!Gl(s)){let r={v:s,n:this.norm.get(s)};a.$[o]=r}}}),this.records.push(a)}toJSON(){return{keys:this.keys,records:this.records}}}function Wy(e,t,{getFn:i=H.getFn,fieldNormWeight:a=H.fieldNormWeight}={}){const n=new Lc({getFn:i,fieldNormWeight:a});return n.setKeys(e.map(Ly)),n.setSources(t),n.create(),n}function h2(e,{getFn:t=H.getFn,fieldNormWeight:i=H.fieldNormWeight}={}){const{keys:a,records:n}=e,o=new Lc({getFn:t,fieldNormWeight:i});return o.setKeys(a),o.setIndexRecords(n),o}function ss(e,{errors:t=0,currentLocation:i=0,expectedLocation:a=0,distance:n=H.distance,ignoreLocation:o=H.ignoreLocation}={}){const s=t/e.length;if(o)return s;const r=Math.abs(a-i);return n?s+r/n:r?1:s}function g2(e=[],t=H.minMatchCharLength){let i=[],a=-1,n=-1,o=0;for(let s=e.length;o<s;o+=1){let r=e[o];r&&a===-1?a=o:!r&&a!==-1&&(n=o-1,n-a+1>=t&&i.push([a,n]),a=-1)}return e[o-1]&&o-a>=t&&i.push([a,o-1]),i}const la=32;function y2(e,t,i,{location:a=H.location,distance:n=H.distance,threshold:o=H.threshold,findAllMatches:s=H.findAllMatches,minMatchCharLength:r=H.minMatchCharLength,includeMatches:l=H.includeMatches,ignoreLocation:d=H.ignoreLocation}={}){if(t.length>la)throw new Error(n2(la));const p=t.length,f=e.length,h=Math.max(0,Math.min(a,f));let c=o,g=h;const m=r>1||l,x=m?Array(f):[];let _;for(;(_=e.indexOf(t,g))>-1;){let w=ss(t,{currentLocation:_,expectedLocation:h,distance:n,ignoreLocation:d});if(c=Math.min(w,c),g=_+p,m){let D=0;for(;D<p;)x[_+D]=1,D+=1}}g=-1;let y=[],b=1,v=p+f;const F=1<<p-1;for(let w=0;w<p;w+=1){let D=0,P=v;for(;D<P;)ss(t,{errors:w,currentLocation:h+P,expectedLocation:h,distance:n,ignoreLocation:d})<=c?D=P:v=P,P=Math.floor((v-D)/2+D);v=P;let R=Math.max(1,h-P+1),A=s?f:Math.min(h+P,f)+p,M=Array(A+2);M[A+1]=(1<<w)-1;for(let E=A;E>=R;E-=1){let j=E-1,z=i[e.charAt(j)];if(m&&(x[j]=+!!z),M[E]=(M[E+1]<<1|1)&z,w&&(M[E]|=(y[E+1]|y[E])<<1|1|y[E+1]),M[E]&F&&(b=ss(t,{errors:w,currentLocation:j,expectedLocation:h,distance:n,ignoreLocation:d}),b<=c)){if(c=b,g=j,g<=h)break;R=Math.max(1,2*h-g)}}if(ss(t,{errors:w+1,currentLocation:h,expectedLocation:h,distance:n,ignoreLocation:d})>c)break;y=M}const T={isMatch:g>=0,score:Math.max(.001,b)};if(m){const w=g2(x,r);w.length?l&&(T.indices=w):T.isMatch=!1}return T}function _2(e){let t={};for(let i=0,a=e.length;i<a;i+=1){const n=e.charAt(i);t[n]=(t[n]||0)|1<<a-i-1}return t}class $y{constructor(t,{location:i=H.location,threshold:a=H.threshold,distance:n=H.distance,includeMatches:o=H.includeMatches,findAllMatches:s=H.findAllMatches,minMatchCharLength:r=H.minMatchCharLength,isCaseSensitive:l=H.isCaseSensitive,ignoreLocation:d=H.ignoreLocation}={}){if(this.options={location:i,threshold:a,distance:n,includeMatches:o,findAllMatches:s,minMatchCharLength:r,isCaseSensitive:l,ignoreLocation:d},this.pattern=l?t:t.toLowerCase(),this.chunks=[],!this.pattern.length)return;const p=(h,c)=>{this.chunks.push({pattern:h,alphabet:_2(h),startIndex:c})},f=this.pattern.length;if(f>la){let h=0;const c=f%la,g=f-c;for(;h<g;)p(this.pattern.substr(h,la),h),h+=la;if(c){const m=f-la;p(this.pattern.substr(m),m)}}else p(this.pattern,0)}searchIn(t){const{isCaseSensitive:i,includeMatches:a}=this.options;if(i||(t=t.toLowerCase()),this.pattern===t){let g={isMatch:!0,score:0};return a&&(g.indices=[[0,t.length-1]]),g}const{location:n,distance:o,threshold:s,findAllMatches:r,minMatchCharLength:l,ignoreLocation:d}=this.options;let p=[],f=0,h=!1;this.chunks.forEach(({pattern:g,alphabet:m,startIndex:x})=>{const{isMatch:_,score:y,indices:b}=y2(t,g,m,{location:n+x,distance:o,threshold:s,findAllMatches:r,minMatchCharLength:l,includeMatches:a,ignoreLocation:d});_&&(h=!0),f+=y,_&&b&&(p=[...p,...b])});let c={isMatch:h,score:h?f/this.chunks.length:1};return h&&a&&(c.indices=p),c}}class ta{constructor(t){this.pattern=t}static isMultiMatch(t){return $m(t,this.multiRegex)}static isSingleMatch(t){return $m(t,this.singleRegex)}search(){}}function $m(e,t){const i=e.match(t);return i?i[1]:null}class b2 extends ta{constructor(t){super(t)}static get type(){return"exact"}static get multiRegex(){return/^="(.*)"$/}static get singleRegex(){return/^=(.*)$/}search(t){const i=t===this.pattern;return{isMatch:i,score:i?0:1,indices:[0,this.pattern.length-1]}}}class k2 extends ta{constructor(t){super(t)}static get type(){return"inverse-exact"}static get multiRegex(){return/^!"(.*)"$/}static get singleRegex(){return/^!(.*)$/}search(t){const a=t.indexOf(this.pattern)===-1;return{isMatch:a,score:a?0:1,indices:[0,t.length-1]}}}class v2 extends ta{constructor(t){super(t)}static get type(){return"prefix-exact"}static get multiRegex(){return/^\^"(.*)"$/}static get singleRegex(){return/^\^(.*)$/}search(t){const i=t.startsWith(this.pattern);return{isMatch:i,score:i?0:1,indices:[0,this.pattern.length-1]}}}class w2 extends ta{constructor(t){super(t)}static get type(){return"inverse-prefix-exact"}static get multiRegex(){return/^!\^"(.*)"$/}static get singleRegex(){return/^!\^(.*)$/}search(t){const i=!t.startsWith(this.pattern);return{isMatch:i,score:i?0:1,indices:[0,t.length-1]}}}class q2 extends ta{constructor(t){super(t)}static get type(){return"suffix-exact"}static get multiRegex(){return/^"(.*)"\$$/}static get singleRegex(){return/^(.*)\$$/}search(t){const i=t.endsWith(this.pattern);return{isMatch:i,score:i?0:1,indices:[t.length-this.pattern.length,t.length-1]}}}class x2 extends ta{constructor(t){super(t)}static get type(){return"inverse-suffix-exact"}static get multiRegex(){return/^!"(.*)"\$$/}static get singleRegex(){return/^!(.*)\$$/}search(t){const i=!t.endsWith(this.pattern);return{isMatch:i,score:i?0:1,indices:[0,t.length-1]}}}class Gy extends ta{constructor(t,{location:i=H.location,threshold:a=H.threshold,distance:n=H.distance,includeMatches:o=H.includeMatches,findAllMatches:s=H.findAllMatches,minMatchCharLength:r=H.minMatchCharLength,isCaseSensitive:l=H.isCaseSensitive,ignoreLocation:d=H.ignoreLocation}={}){super(t),this._bitapSearch=new $y(t,{location:i,threshold:a,distance:n,includeMatches:o,findAllMatches:s,minMatchCharLength:r,isCaseSensitive:l,ignoreLocation:d})}static get type(){return"fuzzy"}static get multiRegex(){return/^"(.*)"$/}static get singleRegex(){return/^(.*)$/}search(t){return this._bitapSearch.searchIn(t)}}class Uy extends ta{constructor(t){super(t)}static get type(){return"include"}static get multiRegex(){return/^'"(.*)"$/}static get singleRegex(){return/^'(.*)$/}search(t){let i=0,a;const n=[],o=this.pattern.length;for(;(a=t.indexOf(this.pattern,i))>-1;)i=a+o,n.push([a,i-1]);const s=!!n.length;return{isMatch:s,score:s?0:1,indices:n}}}const dp=[b2,Uy,v2,w2,x2,q2,k2,Gy],Gm=dp.length,F2=/ +(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)/,T2="|";function D2(e,t={}){return e.split(T2).map(i=>{let a=i.trim().split(F2).filter(o=>o&&!!o.trim()),n=[];for(let o=0,s=a.length;o<s;o+=1){const r=a[o];let l=!1,d=-1;for(;!l&&++d<Gm;){const p=dp[d];let f=p.isMultiMatch(r);f&&(n.push(new p(f,t)),l=!0)}if(!l)for(d=-1;++d<Gm;){const p=dp[d];let f=p.isSingleMatch(r);if(f){n.push(new p(f,t));break}}}return n})}const C2=new Set([Gy.type,Uy.type]);class R2{constructor(t,{isCaseSensitive:i=H.isCaseSensitive,includeMatches:a=H.includeMatches,minMatchCharLength:n=H.minMatchCharLength,ignoreLocation:o=H.ignoreLocation,findAllMatches:s=H.findAllMatches,location:r=H.location,threshold:l=H.threshold,distance:d=H.distance}={}){this.query=null,this.options={isCaseSensitive:i,includeMatches:a,minMatchCharLength:n,findAllMatches:s,ignoreLocation:o,location:r,threshold:l,distance:d},this.pattern=i?t:t.toLowerCase(),this.query=D2(this.pattern,this.options)}static condition(t,i){return i.useExtendedSearch}searchIn(t){const i=this.query;if(!i)return{isMatch:!1,score:1};const{includeMatches:a,isCaseSensitive:n}=this.options;t=n?t:t.toLowerCase();let o=0,s=[],r=0;for(let l=0,d=i.length;l<d;l+=1){const p=i[l];s.length=0,o=0;for(let f=0,h=p.length;f<h;f+=1){const c=p[f],{isMatch:g,indices:m,score:x}=c.search(t);if(g){if(o+=1,r+=x,a){const _=c.constructor.type;C2.has(_)?s=[...s,...m]:s.push(m)}}else{r=0,o=0,s.length=0;break}}if(o){let f={isMatch:!0,score:r/o};return a&&(f.indices=s),f}}return{isMatch:!1,score:1}}}const pp=[];function P2(...e){pp.push(...e)}function cp(e,t){for(let i=0,a=pp.length;i<a;i+=1){let n=pp[i];if(n.condition(e,t))return new n(e,t)}return new $y(e,t)}const ar={AND:"$and",OR:"$or"},up={PATH:"$path",PATTERN:"$val"},mp=e=>!!(e[ar.AND]||e[ar.OR]),S2=e=>!!e[up.PATH],E2=e=>!wi(e)&&Ny(e)&&!mp(e),Um=e=>({[ar.AND]:Object.keys(e).map(t=>({[t]:e[t]}))});function Ky(e,t,{auto:i=!0}={}){const a=n=>{let o=Object.keys(n);const s=S2(n);if(!s&&o.length>1&&!mp(n))return a(Um(n));if(E2(n)){const l=s?n[up.PATH]:o[0],d=s?n[up.PATTERN]:n[l];if(!ti(d))throw new Error(a2(l));const p={keyId:lp(l),pattern:d};return i&&(p.searcher=cp(d,t)),p}let r={children:[],operator:o[0]};return o.forEach(l=>{const d=n[l];wi(d)&&d.forEach(p=>{r.children.push(a(p))})}),r};return mp(e)||(e=Um(e)),a(e)}function B2(e,{ignoreFieldNorm:t=H.ignoreFieldNorm}){e.forEach(i=>{let a=1;i.matches.forEach(({key:n,norm:o,score:s})=>{const r=n?n.weight:null;a*=Math.pow(s===0&&r?Number.EPSILON:s,(r||1)*(t?1:o))}),i.score=a})}function A2(e,t){const i=e.matches;t.matches=[],gt(i)&&i.forEach(a=>{if(!gt(a.indices)||!a.indices.length)return;const{indices:n,value:o}=a;let s={indices:n,value:o};a.key&&(s.key=a.key.src),a.idx>-1&&(s.refIndex=a.idx),t.matches.push(s)})}function j2(e,t){t.score=e.score}function M2(e,t,{includeMatches:i=H.includeMatches,includeScore:a=H.includeScore}={}){const n=[];return i&&n.push(A2),a&&n.push(j2),e.map(o=>{const{idx:s}=o,r={item:t[s],refIndex:s};return n.length&&n.forEach(l=>{l(o,r)}),r})}class vn{constructor(t,i={},a){this.options={...H,...i},this.options.useExtendedSearch,this._keyStore=new r2(this.options.keys),this.setCollection(t,a)}setCollection(t,i){if(this._docs=t,i&&!(i instanceof Lc))throw new Error(i2);this._myIndex=i||Wy(this.options.keys,this._docs,{getFn:this.options.getFn,fieldNormWeight:this.options.fieldNormWeight})}add(t){gt(t)&&(this._docs.push(t),this._myIndex.add(t))}remove(t=()=>!1){const i=[];for(let a=0,n=this._docs.length;a<n;a+=1){const o=this._docs[a];t(o,a)&&(this.removeAt(a),a-=1,n-=1,i.push(o))}return i}removeAt(t){this._docs.splice(t,1),this._myIndex.removeAt(t)}getIndex(){return this._myIndex}search(t,{limit:i=-1}={}){const{includeMatches:a,includeScore:n,shouldSort:o,sortFn:s,ignoreFieldNorm:r}=this.options;let l=ti(t)?ti(this._docs[0])?this._searchStringList(t):this._searchObjectList(t):this._searchLogical(t);return B2(l,{ignoreFieldNorm:r}),o&&l.sort(s),Iy(i)&&i>-1&&(l=l.slice(0,i)),M2(l,this._docs,{includeMatches:a,includeScore:n})}_searchStringList(t){const i=cp(t,this.options),{records:a}=this._myIndex,n=[];return a.forEach(({v:o,i:s,n:r})=>{if(!gt(o))return;const{isMatch:l,score:d,indices:p}=i.searchIn(o);l&&n.push({item:o,idx:s,matches:[{score:d,value:o,norm:r,indices:p}]})}),n}_searchLogical(t){const i=Ky(t,this.options),a=(r,l,d)=>{if(!r.children){const{keyId:f,searcher:h}=r,c=this._findMatches({key:this._keyStore.get(f),value:this._myIndex.getValueForItemAtKeyId(l,f),searcher:h});return c&&c.length?[{idx:d,item:l,matches:c}]:[]}const p=[];for(let f=0,h=r.children.length;f<h;f+=1){const c=r.children[f],g=a(c,l,d);if(g.length)p.push(...g);else if(r.operator===ar.AND)return[]}return p},n=this._myIndex.records,o={},s=[];return n.forEach(({$:r,i:l})=>{if(gt(r)){let d=a(i,r,l);d.length&&(o[l]||(o[l]={idx:l,item:r,matches:[]},s.push(o[l])),d.forEach(({matches:p})=>{o[l].matches.push(...p)}))}}),s}_searchObjectList(t){const i=cp(t,this.options),{keys:a,records:n}=this._myIndex,o=[];return n.forEach(({$:s,i:r})=>{if(!gt(s))return;let l=[];a.forEach((d,p)=>{l.push(...this._findMatches({key:d,value:s[p],searcher:i}))}),l.length&&o.push({idx:r,item:s,matches:l})}),o}_findMatches({key:t,value:i,searcher:a}){if(!gt(i))return[];let n=[];if(wi(i))i.forEach(({v:o,i:s,n:r})=>{if(!gt(o))return;const{isMatch:l,score:d,indices:p}=a.searchIn(o);l&&n.push({score:d,key:t,value:o,idx:s,norm:r,indices:p})});else{const{v:o,n:s}=i,{isMatch:r,score:l,indices:d}=a.searchIn(o);r&&n.push({score:l,key:t,value:o,norm:s,indices:d})}return n}}vn.version="6.6.2";vn.createIndex=Wy;vn.parseIndex=h2;vn.config=H;vn.parseQuery=Ky;P2(R2);const Hy=k.createContext(),zo=()=>k.useContext(Hy),z2=({children:e})=>{const[t,i]=k.useState(""),[a,n]=k.useState(),[o,s]=k.useState(!1);return u.jsx(Hy.Provider,{value:{searchQuery:t,setSearchQuery:i,searchResults:a,setSearchResults:n,isSearchSubmitted:o,setIsSearchSubmitted:s},children:e})};function Vy(e,t){const i=JSON.parse(e);let a=[];function n(r,l){if(typeof l=="string"&&l.toLowerCase().includes(t.toLowerCase()))return l.trim();if(typeof l=="object")for(const d in l){const p=n(d,l[d]);d>0&&typeof p=="string"?a.push(r+": "+l[(d-"1").toString()]+" "+p):d==0&&l.length>1&&typeof p=="string"?a.push(r+": "+p+" "+l[1]):typeof p=="string"&&a.push(d+": "+p)}}for(const r in i)n(r,i[r]);const o=a[0];let s=[];try{const r=o.toLowerCase(),l=t.toLowerCase(),d=r.indexOf(l);if(d!==-1){const p=o.substring(0,d),f=o.substring(d,d+l.length),h=o.substring(d+l.length);s=[p,f,h]}}catch{s=[null,null,null]}return s}const I2=si.plugins;let Km=["name","metadata.description","entry_point_prefix","metadata.author"];function N2(e){const t=[],i=JSON.parse(JSON.stringify(e));return Object.entries(i).forEach(([n,o])=>{Object.entries(o.entry_points).forEach(([s,r])=>{for(const l in r){let d=["entry_points",s,l];o.entry_points[s][l]=JSON.stringify(o.entry_points[s][l]),Km.push(d)}}),t.push(o)}),new vn(t,{keys:Km,includeScore:!0,ignoreLocation:!0,threshold:.1,includeMatches:!0})}const O2=N2(I2);function L2(){const{searchQuery:e,setSearchQuery:t,setSearchResults:i,isSearchSubmitted:a,setIsSearchSubmitted:n}=zo(),o=l=>{t(l),document.querySelector(".suggestions-list").style.display="block",document.querySelector(".dropdown-search").style.display="block",(l==""||a==!0)&&(n(!1),document.querySelector(".dropdown-search").style.display="none");const d=document.querySelector(".enter-symbol");d&&(d.style.opacity=l?"1":"0")};let s=O2.search(e);const r=l=>{l.preventDefault(),e&&(i(s),n(!0),document.querySelector(".suggestions-list").style.display="none",document.querySelector(".dropdown-search").style.display="none")};return u.jsx(u.Fragment,{children:u.jsxs("div",{className:"search",children:[u.jsxs("form",{className:"search-form",children:[u.jsx("button",{style:{fontSize:"20px",minWidth:"90px",backgroundColor:"white",border:"1px solid #ccc",borderRadius:"4px"},onClick:l=>{r(l)},children:u.jsx(My,{})}),u.jsxs("div",{className:"input-container",children:[u.jsx("input",{type:"text",placeholder:"Search for plugins",value:e,label:"search",onChange:l=>o(l.target.value)}),u.jsx(zy,{className:"enter-symbol"})]})]}),u.jsxs("ul",{className:"suggestions-list",children:[s.slice(0,3).map(l=>u.jsxs(u.Fragment,{children:[u.jsx(wa,{to:`/${l.item.name}`,children:u.jsxs("h3",{className:"suggestion-item",children:[l.item.name," "]},l.item.name)}),u.jsx("ul",{children:l.matches.filter(d=>typeof d.key=="object").slice(0,1).map(d=>u.jsxs(u.Fragment,{children:[u.jsx(wa,{to:`/${l.item.name}#${d.key[1]}.${d.key[2]}`,children:u.jsxs("li",{className:"suggestion-item",children:[d.key[2]," "]},d.key)}),u.jsx(Xy,{match_value:d.value})]}))})]})),u.jsx("button",{className:"dropdown-search",onClick:l=>{r(l)},children:" Search"})]})]})})}function W2(){const{searchResults:e,searchQuery:t}=zo();return u.jsxs(u.Fragment,{children:[u.jsxs("h2",{children:["Showing ",e.length," pages matching the search query."]}),e.length===0&&u.jsx("div",{children:u.jsxs("h3",{className:"submenu-entry",style:{textAlign:"center",color:"black"},children:["Can't find what you're looking for?",u.jsx("br",{}),"Join the AiiDA community on Discourse and request a plugin ",u.jsx("a",{href:"https://aiida.discourse.group/new-topic?title=Request%20for%20Plugin...&category=community/plugin-requests",target:"_blank",children:"here."})]})}),e.map(i=>u.jsx(u.Fragment,{children:u.jsxs("div",{className:"submenu-entry",children:[u.jsx(wa,{to:`/${i.item.name}`,children:u.jsx("h3",{className:"suggestion-item",children:i.item.name},i.item.name)}),u.jsx("ul",{children:i.matches.filter(a=>typeof a.key=="object").map(a=>u.jsx(u.Fragment,{children:Vy(a.value,t)[0]!=null&&u.jsxs(u.Fragment,{children:[u.jsx(wa,{to:`/${i.item.name}#${a.key[1]}.${a.key[2]}`,children:u.jsx("li",{className:"suggestion-item",children:a.key[2]},a.key)}),u.jsx(Xy,{match_value:a.value})]})}))})]})}))]})}function Xy({match_value:e}){const{searchQuery:t}=zo(),[i,a,n]=Vy(e,t);return u.jsx(u.Fragment,{children:i!=null&&u.jsxs("p",{children:[i,u.jsx("span",{style:{backgroundColor:"yellow"},children:a}),n,"..."]})})}function wn(){const e=ol(rl);return e[Mo]||e}const $2=e=>{let t;return e<1?t=5.11916*e**2:t=4.5*Math.log(e+1)+2,(t/100).toFixed(2)},Hm=$2,G2=Ay(),U2=Mw({themeId:Mo,defaultTheme:G2,defaultClassName:"MuiBox-root",generateClassName:qc.generate}),K2=U2;function Io({props:e,states:t,muiFormControl:i}){return t.reduce((a,n)=>(a[n]=e[n],i&&typeof e[n]>"u"&&(a[n]=i[n]),a),{})}const H2=k.createContext(void 0),Wc=H2;function No(){return k.useContext(Wc)}function V2(e){return ue("MuiFormLabel",e)}const X2=oe("MuiFormLabel",["root","colorSecondary","focused","disabled","error","filled","required","asterisk"]),io=X2,Y2=["children","className","color","component","disabled","error","filled","focused","required"],Q2=e=>{const{classes:t,color:i,focused:a,disabled:n,error:o,filled:s,required:r}=e,l={root:["root",`color${V(i)}`,n&&"disabled",o&&"error",s&&"filled",a&&"focused",r&&"required"],asterisk:["asterisk",o&&"error"]};return me(l,V2,t)},J2=W("label",{name:"MuiFormLabel",slot:"Root",overridesResolver:({ownerState:e},t)=>q({},t.root,e.color==="secondary"&&t.colorSecondary,e.filled&&t.filled)})(({theme:e,ownerState:t})=>q({color:(e.vars||e).palette.text.secondary},e.typography.body1,{lineHeight:"1.4375em",padding:0,position:"relative",[`&.${io.focused}`]:{color:(e.vars||e).palette[t.color].main},[`&.${io.disabled}`]:{color:(e.vars||e).palette.text.disabled},[`&.${io.error}`]:{color:(e.vars||e).palette.error.main}})),Z2=W("span",{name:"MuiFormLabel",slot:"Asterisk",overridesResolver:(e,t)=>t.asterisk})(({theme:e})=>({[`&.${io.error}`]:{color:(e.vars||e).palette.error.main}})),e8=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiFormLabel"}),{children:n,className:o,component:s="label"}=a,r=$(a,Y2),l=No(),d=Io({props:a,muiFormControl:l,states:["color","required","focused","disabled","error","filled"]}),p=q({},a,{color:d.color||"primary",component:s,disabled:d.disabled,error:d.error,filled:d.filled,focused:d.focused,required:d.required}),f=Q2(p);return u.jsxs(J2,q({as:s,ownerState:p,className:K(f.root,o),ref:i},r,{children:[n,d.required&&u.jsxs(Z2,{ownerState:p,"aria-hidden":!0,className:f.asterisk,children:[" ","*"]})]}))}),t8=e8;function i8(e){return ue("MuiInputLabel",e)}oe("MuiInputLabel",["root","focused","disabled","error","required","asterisk","formControl","sizeSmall","shrink","animated","standard","filled","outlined"]);const a8=["disableAnimation","margin","shrink","variant","className"],n8=e=>{const{classes:t,formControl:i,size:a,shrink:n,disableAnimation:o,variant:s,required:r}=e,l={root:["root",i&&"formControl",!o&&"animated",n&&"shrink",a&&a!=="normal"&&`size${V(a)}`,s],asterisk:[r&&"asterisk"]},d=me(l,i8,t);return q({},t,d)},o8=W(t8,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiInputLabel",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[{[`& .${io.asterisk}`]:t.asterisk},t.root,i.formControl&&t.formControl,i.size==="small"&&t.sizeSmall,i.shrink&&t.shrink,!i.disableAnimation&&t.animated,t[i.variant]]}})(({theme:e,ownerState:t})=>q({display:"block",transformOrigin:"top left",whiteSpace:"nowrap",overflow:"hidden",textOverflow:"ellipsis",maxWidth:"100%"},t.formControl&&{position:"absolute",left:0,top:0,transform:"translate(0, 20px) scale(1)"},t.size==="small"&&{transform:"translate(0, 17px) scale(1)"},t.shrink&&{transform:"translate(0, -1.5px) scale(0.75)",transformOrigin:"top left",maxWidth:"133%"},!t.disableAnimation&&{transition:e.transitions.create(["color","transform","max-width"],{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut})},t.variant==="filled"&&q({zIndex:1,pointerEvents:"none",transform:"translate(12px, 16px) scale(1)",maxWidth:"calc(100% - 24px)"},t.size==="small"&&{transform:"translate(12px, 13px) scale(1)"},t.shrink&&q({userSelect:"none",pointerEvents:"auto",transform:"translate(12px, 7px) scale(0.75)",maxWidth:"calc(133% - 24px)"},t.size==="small"&&{transform:"translate(12px, 4px) scale(0.75)"})),t.variant==="outlined"&&q({zIndex:1,pointerEvents:"none",transform:"translate(14px, 16px) scale(1)",maxWidth:"calc(100% - 24px)"},t.size==="small"&&{transform:"translate(14px, 9px) scale(1)"},t.shrink&&{userSelect:"none",pointerEvents:"auto",maxWidth:"calc(133% - 32px)",transform:"translate(14px, -9px) scale(0.75)"}))),s8=k.forwardRef(function(t,i){const a=fe({name:"MuiInputLabel",props:t}),{disableAnimation:n=!1,shrink:o,className:s}=a,r=$(a,a8),l=No();let d=o;typeof d>"u"&&l&&(d=l.filled||l.focused||l.adornedStart);const p=Io({props:a,muiFormControl:l,states:["size","variant","required"]}),f=q({},a,{disableAnimation:n,formControl:l,shrink:d,size:p.size,variant:p.variant,required:p.required}),h=n8(f);return u.jsx(o8,q({"data-shrink":d,ownerState:f,ref:i,className:K(h.root,s)},r,{classes:h}))}),r8=s8,l8=k.createContext({}),fp=l8;function hp(e,t){return hp=Object.setPrototypeOf?Object.setPrototypeOf.bind():function(a,n){return a.__proto__=n,a},hp(e,t)}function Yy(e,t){e.prototype=Object.create(t.prototype),e.prototype.constructor=e,hp(e,t)}const Vm={disabled:!1},nr=$t.createContext(null);var d8=function(t){return t.scrollTop},Gn="unmounted",oa="exited",sa="entering",Ma="entered",gp="exiting",xi=function(e){Yy(t,e);function t(a,n){var o;o=e.call(this,a,n)||this;var s=n,r=s&&!s.isMounting?a.enter:a.appear,l;return o.appearStatus=null,a.in?r?(l=oa,o.appearStatus=sa):l=Ma:a.unmountOnExit||a.mountOnEnter?l=Gn:l=oa,o.state={status:l},o.nextCallback=null,o}t.getDerivedStateFromProps=function(n,o){var s=n.in;return s&&o.status===Gn?{status:oa}:null};var i=t.prototype;return i.componentDidMount=function(){this.updateStatus(!0,this.appearStatus)},i.componentDidUpdate=function(n){var o=null;if(n!==this.props){var s=this.state.status;this.props.in?s!==sa&&s!==Ma&&(o=sa):(s===sa||s===Ma)&&(o=gp)}this.updateStatus(!1,o)},i.componentWillUnmount=function(){this.cancelNextCallback()},i.getTimeouts=function(){var n=this.props.timeout,o,s,r;return o=s=r=n,n!=null&&typeof n!="number"&&(o=n.exit,s=n.enter,r=n.appear!==void 0?n.appear:s),{exit:o,enter:s,appear:r}},i.updateStatus=function(n,o){if(n===void 0&&(n=!1),o!==null)if(this.cancelNextCallback(),o===sa){if(this.props.unmountOnExit||this.props.mountOnEnter){var s=this.props.nodeRef?this.props.nodeRef.current:ns.findDOMNode(this);s&&d8(s)}this.performEnter(n)}else this.performExit();else this.props.unmountOnExit&&this.state.status===oa&&this.setState({status:Gn})},i.performEnter=function(n){var o=this,s=this.props.enter,r=this.context?this.context.isMounting:n,l=this.props.nodeRef?[r]:[ns.findDOMNode(this),r],d=l[0],p=l[1],f=this.getTimeouts(),h=r?f.appear:f.enter;if(!n&&!s||Vm.disabled){this.safeSetState({status:Ma},function(){o.props.onEntered(d)});return}this.props.onEnter(d,p),this.safeSetState({status:sa},function(){o.props.onEntering(d,p),o.onTransitionEnd(h,function(){o.safeSetState({status:Ma},function(){o.props.onEntered(d,p)})})})},i.performExit=function(){var n=this,o=this.props.exit,s=this.getTimeouts(),r=this.props.nodeRef?void 0:ns.findDOMNode(this);if(!o||Vm.disabled){this.safeSetState({status:oa},function(){n.props.onExited(r)});return}this.props.onExit(r),this.safeSetState({status:gp},function(){n.props.onExiting(r),n.onTransitionEnd(s.exit,function(){n.safeSetState({status:oa},function(){n.props.onExited(r)})})})},i.cancelNextCallback=function(){this.nextCallback!==null&&(this.nextCallback.cancel(),this.nextCallback=null)},i.safeSetState=function(n,o){o=this.setNextCallback(o),this.setState(n,o)},i.setNextCallback=function(n){var o=this,s=!0;return this.nextCallback=function(r){s&&(s=!1,o.nextCallback=null,n(r))},this.nextCallback.cancel=function(){s=!1},this.nextCallback},i.onTransitionEnd=function(n,o){this.setNextCallback(o);var s=this.props.nodeRef?this.props.nodeRef.current:ns.findDOMNode(this),r=n==null&&!this.props.addEndListener;if(!s||r){setTimeout(this.nextCallback,0);return}if(this.props.addEndListener){var l=this.props.nodeRef?[this.nextCallback]:[s,this.nextCallback],d=l[0],p=l[1];this.props.addEndListener(d,p)}n!=null&&setTimeout(this.nextCallback,n)},i.render=function(){var n=this.state.status;if(n===Gn)return null;var o=this.props,s=o.children;o.in,o.mountOnEnter,o.unmountOnExit,o.appear,o.enter,o.exit,o.timeout,o.addEndListener,o.onEnter,o.onEntering,o.onEntered,o.onExit,o.onExiting,o.onExited,o.nodeRef;var r=$(o,["children","in","mountOnEnter","unmountOnExit","appear","enter","exit","timeout","addEndListener","onEnter","onEntering","onEntered","onExit","onExiting","onExited","nodeRef"]);return $t.createElement(nr.Provider,{value:null},typeof s=="function"?s(n,r):$t.cloneElement($t.Children.only(s),r))},t}($t.Component);xi.contextType=nr;xi.propTypes={};function Aa(){}xi.defaultProps={in:!1,mountOnEnter:!1,unmountOnExit:!1,appear:!1,enter:!0,exit:!0,onEnter:Aa,onEntering:Aa,onEntered:Aa,onExit:Aa,onExiting:Aa,onExited:Aa};xi.UNMOUNTED=Gn;xi.EXITED=oa;xi.ENTERING=sa;xi.ENTERED=Ma;xi.EXITING=gp;const $c=xi;function p8(e){if(e===void 0)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}function Gc(e,t){var i=function(o){return t&&k.isValidElement(o)?t(o):o},a=Object.create(null);return e&&k.Children.map(e,function(n){return n}).forEach(function(n){a[n.key]=i(n)}),a}function c8(e,t){e=e||{},t=t||{};function i(p){return p in t?t[p]:e[p]}var a=Object.create(null),n=[];for(var o in e)o in t?n.length&&(a[o]=n,n=[]):n.push(o);var s,r={};for(var l in t){if(a[l])for(s=0;s<a[l].length;s++){var d=a[l][s];r[a[l][s]]=i(d)}r[l]=i(l)}for(s=0;s<n.length;s++)r[n[s]]=i(n[s]);return r}function fa(e,t,i){return i[t]!=null?i[t]:e.props[t]}function u8(e,t){return Gc(e.children,function(i){return k.cloneElement(i,{onExited:t.bind(null,i),in:!0,appear:fa(i,"appear",e),enter:fa(i,"enter",e),exit:fa(i,"exit",e)})})}function m8(e,t,i){var a=Gc(e.children),n=c8(t,a);return Object.keys(n).forEach(function(o){var s=n[o];if(k.isValidElement(s)){var r=o in t,l=o in a,d=t[o],p=k.isValidElement(d)&&!d.props.in;l&&(!r||p)?n[o]=k.cloneElement(s,{onExited:i.bind(null,s),in:!0,exit:fa(s,"exit",e),enter:fa(s,"enter",e)}):!l&&r&&!p?n[o]=k.cloneElement(s,{in:!1}):l&&r&&k.isValidElement(d)&&(n[o]=k.cloneElement(s,{onExited:i.bind(null,s),in:d.props.in,exit:fa(s,"exit",e),enter:fa(s,"enter",e)}))}}),n}var f8=Object.values||function(e){return Object.keys(e).map(function(t){return e[t]})},h8={component:"div",childFactory:function(t){return t}},Uc=function(e){Yy(t,e);function t(a,n){var o;o=e.call(this,a,n)||this;var s=o.handleExited.bind(p8(o));return o.state={contextValue:{isMounting:!0},handleExited:s,firstRender:!0},o}var i=t.prototype;return i.componentDidMount=function(){this.mounted=!0,this.setState({contextValue:{isMounting:!1}})},i.componentWillUnmount=function(){this.mounted=!1},t.getDerivedStateFromProps=function(n,o){var s=o.children,r=o.handleExited,l=o.firstRender;return{children:l?u8(n,r):m8(n,s,r),firstRender:!1}},i.handleExited=function(n,o){var s=Gc(this.props.children);n.key in s||(n.props.onExited&&n.props.onExited(o),this.mounted&&this.setState(function(r){var l=q({},r.children);return delete l[n.key],{children:l}}))},i.render=function(){var n=this.props,o=n.component,s=n.childFactory,r=$(n,["component","childFactory"]),l=this.state.contextValue,d=f8(this.state.children).map(s);return delete r.appear,delete r.enter,delete r.exit,o===null?$t.createElement(nr.Provider,{value:l},d):$t.createElement(nr.Provider,{value:l},$t.createElement(o,r,d))},t}($t.Component);Uc.propTypes={};Uc.defaultProps=h8;const g8=Uc;function y8(e){const{className:t,classes:i,pulsate:a=!1,rippleX:n,rippleY:o,rippleSize:s,in:r,onExited:l,timeout:d}=e,[p,f]=k.useState(!1),h=K(t,i.ripple,i.rippleVisible,a&&i.ripplePulsate),c={width:s,height:s,top:-(s/2)+o,left:-(s/2)+n},g=K(i.child,p&&i.childLeaving,a&&i.childPulsate);return!r&&!p&&f(!0),k.useEffect(()=>{if(!r&&l!=null){const m=setTimeout(l,d);return()=>{clearTimeout(m)}}},[l,r,d]),u.jsx("span",{className:h,style:c,children:u.jsx("span",{className:g})})}const _8=oe("MuiTouchRipple",["root","ripple","rippleVisible","ripplePulsate","child","childLeaving","childPulsate"]),Rt=_8,b8=["center","classes","className"];let ll=e=>e,Xm,Ym,Qm,Jm;const yp=550,k8=80,v8=Ec(Xm||(Xm=ll`
  0% {
    transform: scale(0);
    opacity: 0.1;
  }

  100% {
    transform: scale(1);
    opacity: 0.3;
  }
`)),w8=Ec(Ym||(Ym=ll`
  0% {
    opacity: 1;
  }

  100% {
    opacity: 0;
  }
`)),q8=Ec(Qm||(Qm=ll`
  0% {
    transform: scale(1);
  }

  50% {
    transform: scale(0.92);
  }

  100% {
    transform: scale(1);
  }
`)),x8=W("span",{name:"MuiTouchRipple",slot:"Root"})({overflow:"hidden",pointerEvents:"none",position:"absolute",zIndex:0,top:0,right:0,bottom:0,left:0,borderRadius:"inherit"}),F8=W(y8,{name:"MuiTouchRipple",slot:"Ripple"})(Jm||(Jm=ll`
  opacity: 0;
  position: absolute;

  &.${0} {
    opacity: 0.3;
    transform: scale(1);
    animation-name: ${0};
    animation-duration: ${0}ms;
    animation-timing-function: ${0};
  }

  &.${0} {
    animation-duration: ${0}ms;
  }

  & .${0} {
    opacity: 1;
    display: block;
    width: 100%;
    height: 100%;
    border-radius: 50%;
    background-color: currentColor;
  }

  & .${0} {
    opacity: 0;
    animation-name: ${0};
    animation-duration: ${0}ms;
    animation-timing-function: ${0};
  }

  & .${0} {
    position: absolute;
    /* @noflip */
    left: 0px;
    top: 0;
    animation-name: ${0};
    animation-duration: 2500ms;
    animation-timing-function: ${0};
    animation-iteration-count: infinite;
    animation-delay: 200ms;
  }
`),Rt.rippleVisible,v8,yp,({theme:e})=>e.transitions.easing.easeInOut,Rt.ripplePulsate,({theme:e})=>e.transitions.duration.shorter,Rt.child,Rt.childLeaving,w8,yp,({theme:e})=>e.transitions.easing.easeInOut,Rt.childPulsate,q8,({theme:e})=>e.transitions.easing.easeInOut),T8=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiTouchRipple"}),{center:n=!1,classes:o={},className:s}=a,r=$(a,b8),[l,d]=k.useState([]),p=k.useRef(0),f=k.useRef(null);k.useEffect(()=>{f.current&&(f.current(),f.current=null)},[l]);const h=k.useRef(!1),c=k.useRef(0),g=k.useRef(null),m=k.useRef(null);k.useEffect(()=>()=>{c.current&&clearTimeout(c.current)},[]);const x=k.useCallback(v=>{const{pulsate:F,rippleX:T,rippleY:w,rippleSize:D,cb:P}=v;d(R=>[...R,u.jsx(F8,{classes:{ripple:K(o.ripple,Rt.ripple),rippleVisible:K(o.rippleVisible,Rt.rippleVisible),ripplePulsate:K(o.ripplePulsate,Rt.ripplePulsate),child:K(o.child,Rt.child),childLeaving:K(o.childLeaving,Rt.childLeaving),childPulsate:K(o.childPulsate,Rt.childPulsate)},timeout:yp,pulsate:F,rippleX:T,rippleY:w,rippleSize:D},p.current)]),p.current+=1,f.current=P},[o]),_=k.useCallback((v={},F={},T=()=>{})=>{const{pulsate:w=!1,center:D=n||F.pulsate,fakeElement:P=!1}=F;if((v==null?void 0:v.type)==="mousedown"&&h.current){h.current=!1;return}(v==null?void 0:v.type)==="touchstart"&&(h.current=!0);const R=P?null:m.current,A=R?R.getBoundingClientRect():{width:0,height:0,left:0,top:0};let M,O,E;if(D||v===void 0||v.clientX===0&&v.clientY===0||!v.clientX&&!v.touches)M=Math.round(A.width/2),O=Math.round(A.height/2);else{const{clientX:j,clientY:z}=v.touches&&v.touches.length>0?v.touches[0]:v;M=Math.round(j-A.left),O=Math.round(z-A.top)}if(D)E=Math.sqrt((2*A.width**2+A.height**2)/3),E%2===0&&(E+=1);else{const j=Math.max(Math.abs((R?R.clientWidth:0)-M),M)*2+2,z=Math.max(Math.abs((R?R.clientHeight:0)-O),O)*2+2;E=Math.sqrt(j**2+z**2)}v!=null&&v.touches?g.current===null&&(g.current=()=>{x({pulsate:w,rippleX:M,rippleY:O,rippleSize:E,cb:T})},c.current=setTimeout(()=>{g.current&&(g.current(),g.current=null)},k8)):x({pulsate:w,rippleX:M,rippleY:O,rippleSize:E,cb:T})},[n,x]),y=k.useCallback(()=>{_({},{pulsate:!0})},[_]),b=k.useCallback((v,F)=>{if(clearTimeout(c.current),(v==null?void 0:v.type)==="touchend"&&g.current){g.current(),g.current=null,c.current=setTimeout(()=>{b(v,F)});return}g.current=null,d(T=>T.length>0?T.slice(1):T),f.current=F},[]);return k.useImperativeHandle(i,()=>({pulsate:y,start:_,stop:b}),[y,_,b]),u.jsx(x8,q({className:K(Rt.root,o.root,s),ref:m},r,{children:u.jsx(g8,{component:null,exit:!0,children:l})}))}),D8=T8;function C8(e){return ue("MuiButtonBase",e)}const R8=oe("MuiButtonBase",["root","disabled","focusVisible"]),P8=R8,S8=["action","centerRipple","children","className","component","disabled","disableRipple","disableTouchRipple","focusRipple","focusVisibleClassName","LinkComponent","onBlur","onClick","onContextMenu","onDragLeave","onFocus","onFocusVisible","onKeyDown","onKeyUp","onMouseDown","onMouseLeave","onMouseUp","onTouchEnd","onTouchMove","onTouchStart","tabIndex","TouchRippleProps","touchRippleRef","type"],E8=e=>{const{disabled:t,focusVisible:i,focusVisibleClassName:a,classes:n}=e,s=me({root:["root",t&&"disabled",i&&"focusVisible"]},C8,n);return i&&a&&(s.root+=` ${a}`),s},B8=W("button",{name:"MuiButtonBase",slot:"Root",overridesResolver:(e,t)=>t.root})({display:"inline-flex",alignItems:"center",justifyContent:"center",position:"relative",boxSizing:"border-box",WebkitTapHighlightColor:"transparent",backgroundColor:"transparent",outline:0,border:0,margin:0,borderRadius:0,padding:0,cursor:"pointer",userSelect:"none",verticalAlign:"middle",MozAppearance:"none",WebkitAppearance:"none",textDecoration:"none",color:"inherit","&::-moz-focus-inner":{borderStyle:"none"},[`&.${P8.disabled}`]:{pointerEvents:"none",cursor:"default"},"@media print":{colorAdjust:"exact"}}),A8=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiButtonBase"}),{action:n,centerRipple:o=!1,children:s,className:r,component:l="button",disabled:d=!1,disableRipple:p=!1,disableTouchRipple:f=!1,focusRipple:h=!1,LinkComponent:c="a",onBlur:g,onClick:m,onContextMenu:x,onDragLeave:_,onFocus:y,onFocusVisible:b,onKeyDown:v,onKeyUp:F,onMouseDown:T,onMouseLeave:w,onMouseUp:D,onTouchEnd:P,onTouchMove:R,onTouchStart:A,tabIndex:M=0,TouchRippleProps:O,touchRippleRef:E,type:j}=a,z=$(a,S8),L=k.useRef(null),C=k.useRef(null),B=Ye(C,E),{isFocusVisibleRef:I,onFocus:ee,onBlur:X,ref:Be}=sy(),[J,ke]=k.useState(!1);d&&J&&ke(!1),k.useImperativeHandle(n,()=>({focusVisible:()=>{ke(!0),L.current.focus()}}),[]);const[re,Ge]=k.useState(!1);k.useEffect(()=>{Ge(!0)},[]);const Ft=re&&!p&&!d;k.useEffect(()=>{J&&h&&!p&&re&&C.current.pulsate()},[p,h,J,re]);function Ae(U,di,qn=f){return ma(G=>(di&&di(G),!qn&&C.current&&C.current[U](G),!0))}const st=Ae("start",T),ne=Ae("stop",x),Fe=Ae("stop",_),Y=Ae("stop",D),pe=Ae("stop",U=>{J&&U.preventDefault(),w&&w(U)}),ve=Ae("start",A),Fi=Ae("stop",P),Tt=Ae("stop",R),Dt=Ae("stop",U=>{X(U),I.current===!1&&ke(!1),g&&g(U)},!1),It=ma(U=>{L.current||(L.current=U.currentTarget),ee(U),I.current===!0&&(ke(!0),b&&b(U)),y&&y(U)}),Ct=()=>{const U=L.current;return l&&l!=="button"&&!(U.tagName==="A"&&U.href)},Te=k.useRef(!1),ri=ma(U=>{h&&!Te.current&&J&&C.current&&U.key===" "&&(Te.current=!0,C.current.stop(U,()=>{C.current.start(U)})),U.target===U.currentTarget&&Ct()&&U.key===" "&&U.preventDefault(),v&&v(U),U.target===U.currentTarget&&Ct()&&U.key==="Enter"&&!d&&(U.preventDefault(),m&&m(U))}),rt=ma(U=>{h&&U.key===" "&&C.current&&J&&!U.defaultPrevented&&(Te.current=!1,C.current.stop(U,()=>{C.current.pulsate(U)})),F&&F(U),m&&U.target===U.currentTarget&&Ct()&&U.key===" "&&!U.defaultPrevented&&m(U)});let we=l;we==="button"&&(z.href||z.to)&&(we=c);const Vt={};we==="button"?(Vt.type=j===void 0?"button":j,Vt.disabled=d):(!z.href&&!z.to&&(Vt.role="button"),d&&(Vt["aria-disabled"]=d));const Ti=Ye(i,Be,L),li=q({},a,{centerRipple:o,component:l,disabled:d,disableRipple:p,disableTouchRipple:f,focusRipple:h,tabIndex:M,focusVisible:J}),he=E8(li);return u.jsxs(B8,q({as:we,className:K(he.root,r),ownerState:li,onBlur:Dt,onClick:m,onContextMenu:ne,onFocus:It,onKeyDown:ri,onKeyUp:rt,onMouseDown:st,onMouseLeave:pe,onMouseUp:Y,onDragLeave:Fe,onTouchEnd:Fi,onTouchMove:Tt,onTouchStart:ve,ref:Ti,tabIndex:d?-1:M,type:j},Vt,z,{children:[s,Ft?u.jsx(D8,q({ref:B,center:o},O)):null]}))}),Qy=A8;function j8(e){return ue("MuiDivider",e)}const M8=oe("MuiDivider",["root","absolute","fullWidth","inset","middle","flexItem","light","vertical","withChildren","withChildrenVertical","textAlignRight","textAlignLeft","wrapper","wrapperVertical"]),Zm=M8,z8=["absolute","children","className","component","flexItem","light","orientation","role","textAlign","variant"],I8=e=>{const{absolute:t,children:i,classes:a,flexItem:n,light:o,orientation:s,textAlign:r,variant:l}=e;return me({root:["root",t&&"absolute",l,o&&"light",s==="vertical"&&"vertical",n&&"flexItem",i&&"withChildren",i&&s==="vertical"&&"withChildrenVertical",r==="right"&&s!=="vertical"&&"textAlignRight",r==="left"&&s!=="vertical"&&"textAlignLeft"],wrapper:["wrapper",s==="vertical"&&"wrapperVertical"]},j8,a)},N8=W("div",{name:"MuiDivider",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,i.absolute&&t.absolute,t[i.variant],i.light&&t.light,i.orientation==="vertical"&&t.vertical,i.flexItem&&t.flexItem,i.children&&t.withChildren,i.children&&i.orientation==="vertical"&&t.withChildrenVertical,i.textAlign==="right"&&i.orientation!=="vertical"&&t.textAlignRight,i.textAlign==="left"&&i.orientation!=="vertical"&&t.textAlignLeft]}})(({theme:e,ownerState:t})=>q({margin:0,flexShrink:0,borderWidth:0,borderStyle:"solid",borderColor:(e.vars||e).palette.divider,borderBottomWidth:"thin"},t.absolute&&{position:"absolute",bottom:0,left:0,width:"100%"},t.light&&{borderColor:e.vars?`rgba(${e.vars.palette.dividerChannel} / 0.08)`:hi(e.palette.divider,.08)},t.variant==="inset"&&{marginLeft:72},t.variant==="middle"&&t.orientation==="horizontal"&&{marginLeft:e.spacing(2),marginRight:e.spacing(2)},t.variant==="middle"&&t.orientation==="vertical"&&{marginTop:e.spacing(1),marginBottom:e.spacing(1)},t.orientation==="vertical"&&{height:"100%",borderBottomWidth:0,borderRightWidth:"thin"},t.flexItem&&{alignSelf:"stretch",height:"auto"}),({ownerState:e})=>q({},e.children&&{display:"flex",whiteSpace:"nowrap",textAlign:"center",border:0,"&::before, &::after":{content:'""',alignSelf:"center"}}),({theme:e,ownerState:t})=>q({},t.children&&t.orientation!=="vertical"&&{"&::before, &::after":{width:"100%",borderTop:`thin solid ${(e.vars||e).palette.divider}`}}),({theme:e,ownerState:t})=>q({},t.children&&t.orientation==="vertical"&&{flexDirection:"column","&::before, &::after":{height:"100%",borderLeft:`thin solid ${(e.vars||e).palette.divider}`}}),({ownerState:e})=>q({},e.textAlign==="right"&&e.orientation!=="vertical"&&{"&::before":{width:"90%"},"&::after":{width:"10%"}},e.textAlign==="left"&&e.orientation!=="vertical"&&{"&::before":{width:"10%"},"&::after":{width:"90%"}})),O8=W("span",{name:"MuiDivider",slot:"Wrapper",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.wrapper,i.orientation==="vertical"&&t.wrapperVertical]}})(({theme:e,ownerState:t})=>q({display:"inline-block",paddingLeft:`calc(${e.spacing(1)} * 1.2)`,paddingRight:`calc(${e.spacing(1)} * 1.2)`},t.orientation==="vertical"&&{paddingTop:`calc(${e.spacing(1)} * 1.2)`,paddingBottom:`calc(${e.spacing(1)} * 1.2)`})),Jy=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiDivider"}),{absolute:n=!1,children:o,className:s,component:r=o?"div":"hr",flexItem:l=!1,light:d=!1,orientation:p="horizontal",role:f=r!=="hr"?"separator":void 0,textAlign:h="center",variant:c="fullWidth"}=a,g=$(a,z8),m=q({},a,{absolute:n,component:r,flexItem:l,light:d,orientation:p,role:f,textAlign:h,variant:c}),x=I8(m);return u.jsx(N8,q({as:r,className:K(x.root,s),role:f,ref:i,ownerState:m},g,{children:o?u.jsx(O8,{className:x.wrapper,ownerState:m,children:o}):null}))});Jy.muiSkipListHighlight=!0;const ef=Jy,L8=oe("MuiListItemIcon",["root","alignItemsFlexStart"]),tf=L8;function W8(e){return ue("MuiTypography",e)}oe("MuiTypography",["root","h1","h2","h3","h4","h5","h6","subtitle1","subtitle2","body1","body2","inherit","button","caption","overline","alignLeft","alignRight","alignCenter","alignJustify","noWrap","gutterBottom","paragraph"]);const $8=["align","className","component","gutterBottom","noWrap","paragraph","variant","variantMapping"],G8=e=>{const{align:t,gutterBottom:i,noWrap:a,paragraph:n,variant:o,classes:s}=e,r={root:["root",o,e.align!=="inherit"&&`align${V(t)}`,i&&"gutterBottom",a&&"noWrap",n&&"paragraph"]};return me(r,W8,s)},U8=W("span",{name:"MuiTypography",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,i.variant&&t[i.variant],i.align!=="inherit"&&t[`align${V(i.align)}`],i.noWrap&&t.noWrap,i.gutterBottom&&t.gutterBottom,i.paragraph&&t.paragraph]}})(({theme:e,ownerState:t})=>q({margin:0},t.variant==="inherit"&&{font:"inherit"},t.variant!=="inherit"&&e.typography[t.variant],t.align!=="inherit"&&{textAlign:t.align},t.noWrap&&{overflow:"hidden",textOverflow:"ellipsis",whiteSpace:"nowrap"},t.gutterBottom&&{marginBottom:"0.35em"},t.paragraph&&{marginBottom:16})),af={h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",h6:"h6",subtitle1:"h6",subtitle2:"h6",body1:"p",body2:"p",inherit:"p"},K8={primary:"primary.main",textPrimary:"text.primary",secondary:"secondary.main",textSecondary:"text.secondary",error:"error.main"},H8=e=>K8[e]||e,V8=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiTypography"}),n=H8(a.color),o=Ey(q({},a,{color:n})),{align:s="inherit",className:r,component:l,gutterBottom:d=!1,noWrap:p=!1,paragraph:f=!1,variant:h="body1",variantMapping:c=af}=o,g=$(o,$8),m=q({},o,{align:s,color:n,className:r,component:l,gutterBottom:d,noWrap:p,paragraph:f,variant:h,variantMapping:c}),x=l||(f?"p":c[h]||af[h])||"span",_=G8(m);return u.jsx(U8,q({as:x,ref:i,ownerState:m,className:K(_.root,r)},g))}),Zy=V8,X8=oe("MuiListItemText",["root","multiline","dense","inset","primary","secondary"]),nf=X8;function Y8(e){return ue("MuiMenuItem",e)}const Q8=oe("MuiMenuItem",["root","focusVisible","dense","disabled","divider","gutters","selected"]),jn=Q8,J8=["autoFocus","component","dense","divider","disableGutters","focusVisibleClassName","role","tabIndex","className"],Z8=(e,t)=>{const{ownerState:i}=e;return[t.root,i.dense&&t.dense,i.divider&&t.divider,!i.disableGutters&&t.gutters]},eq=e=>{const{disabled:t,dense:i,divider:a,disableGutters:n,selected:o,classes:s}=e,l=me({root:["root",i&&"dense",t&&"disabled",!n&&"gutters",a&&"divider",o&&"selected"]},Y8,s);return q({},s,l)},tq=W(Qy,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiMenuItem",slot:"Root",overridesResolver:Z8})(({theme:e,ownerState:t})=>q({},e.typography.body1,{display:"flex",justifyContent:"flex-start",alignItems:"center",position:"relative",textDecoration:"none",minHeight:48,paddingTop:6,paddingBottom:6,boxSizing:"border-box",whiteSpace:"nowrap"},!t.disableGutters&&{paddingLeft:16,paddingRight:16},t.divider&&{borderBottom:`1px solid ${(e.vars||e).palette.divider}`,backgroundClip:"padding-box"},{"&:hover":{textDecoration:"none",backgroundColor:(e.vars||e).palette.action.hover,"@media (hover: none)":{backgroundColor:"transparent"}},[`&.${jn.selected}`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / ${e.vars.palette.action.selectedOpacity})`:hi(e.palette.primary.main,e.palette.action.selectedOpacity),[`&.${jn.focusVisible}`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / calc(${e.vars.palette.action.selectedOpacity} + ${e.vars.palette.action.focusOpacity}))`:hi(e.palette.primary.main,e.palette.action.selectedOpacity+e.palette.action.focusOpacity)}},[`&.${jn.selected}:hover`]:{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / calc(${e.vars.palette.action.selectedOpacity} + ${e.vars.palette.action.hoverOpacity}))`:hi(e.palette.primary.main,e.palette.action.selectedOpacity+e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:e.vars?`rgba(${e.vars.palette.primary.mainChannel} / ${e.vars.palette.action.selectedOpacity})`:hi(e.palette.primary.main,e.palette.action.selectedOpacity)}},[`&.${jn.focusVisible}`]:{backgroundColor:(e.vars||e).palette.action.focus},[`&.${jn.disabled}`]:{opacity:(e.vars||e).palette.action.disabledOpacity},[`& + .${Zm.root}`]:{marginTop:e.spacing(1),marginBottom:e.spacing(1)},[`& + .${Zm.inset}`]:{marginLeft:52},[`& .${nf.root}`]:{marginTop:0,marginBottom:0},[`& .${nf.inset}`]:{paddingLeft:36},[`& .${tf.root}`]:{minWidth:36}},!t.dense&&{[e.breakpoints.up("sm")]:{minHeight:"auto"}},t.dense&&q({minHeight:32,paddingTop:4,paddingBottom:4},e.typography.body2,{[`& .${tf.root} svg`]:{fontSize:"1.25rem"}}))),iq=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiMenuItem"}),{autoFocus:n=!1,component:o="li",dense:s=!1,divider:r=!1,disableGutters:l=!1,focusVisibleClassName:d,role:p="menuitem",tabIndex:f,className:h}=a,c=$(a,J8),g=k.useContext(fp),m=k.useMemo(()=>({dense:s||g.dense||!1,disableGutters:l}),[g.dense,s,l]),x=k.useRef(null);Yi(()=>{n&&x.current&&x.current.focus()},[n]);const _=q({},a,{dense:m.dense,divider:r,disableGutters:l}),y=eq(a),b=Ye(x,i);let v;return a.disabled||(v=f!==void 0?f:-1),u.jsx(fp.Provider,{value:m,children:u.jsx(tq,q({ref:b,role:p,tabIndex:v,component:o,focusVisibleClassName:K(y.focusVisible,d),className:K(y.root,h)},c,{ownerState:_,classes:y}))})}),Ul=iq;function of(e){return e!=null&&!(Array.isArray(e)&&e.length===0)}function or(e,t=!1){return e&&(of(e.value)&&e.value!==""||t&&of(e.defaultValue)&&e.defaultValue!=="")}function aq(e){return e.startAdornment}function nq(e){return ue("MuiFormControl",e)}oe("MuiFormControl",["root","marginNone","marginNormal","marginDense","fullWidth","disabled"]);const oq=["children","className","color","component","disabled","error","focused","fullWidth","hiddenLabel","margin","required","size","variant"],sq=e=>{const{classes:t,margin:i,fullWidth:a}=e,n={root:["root",i!=="none"&&`margin${V(i)}`,a&&"fullWidth"]};return me(n,nq,t)},rq=W("div",{name:"MuiFormControl",slot:"Root",overridesResolver:({ownerState:e},t)=>q({},t.root,t[`margin${V(e.margin)}`],e.fullWidth&&t.fullWidth)})(({ownerState:e})=>q({display:"inline-flex",flexDirection:"column",position:"relative",minWidth:0,padding:0,margin:0,border:0,verticalAlign:"top"},e.margin==="normal"&&{marginTop:16,marginBottom:8},e.margin==="dense"&&{marginTop:8,marginBottom:4},e.fullWidth&&{width:"100%"})),lq=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiFormControl"}),{children:n,className:o,color:s="primary",component:r="div",disabled:l=!1,error:d=!1,focused:p,fullWidth:f=!1,hiddenLabel:h=!1,margin:c="none",required:g=!1,size:m="medium",variant:x="outlined"}=a,_=$(a,oq),y=q({},a,{color:s,component:r,disabled:l,error:d,fullWidth:f,hiddenLabel:h,margin:c,required:g,size:m,variant:x}),b=sq(y),[v,F]=k.useState(()=>{let O=!1;return n&&k.Children.forEach(n,E=>{if(!vs(E,["Input","Select"]))return;const j=vs(E,["Select"])?E.props.input:E;j&&aq(j.props)&&(O=!0)}),O}),[T,w]=k.useState(()=>{let O=!1;return n&&k.Children.forEach(n,E=>{vs(E,["Input","Select"])&&(or(E.props,!0)||or(E.props.inputProps,!0))&&(O=!0)}),O}),[D,P]=k.useState(!1);l&&D&&P(!1);const R=p!==void 0&&!l?p:D;let A;const M=k.useMemo(()=>({adornedStart:v,setAdornedStart:F,color:s,disabled:l,error:d,filled:T,focused:R,fullWidth:f,hiddenLabel:h,size:m,onBlur:()=>{P(!1)},onEmpty:()=>{w(!1)},onFilled:()=>{w(!0)},onFocus:()=>{P(!0)},registerEffect:A,required:g,variant:x}),[v,s,l,d,T,R,f,h,A,g,m,x]);return u.jsx(Wc.Provider,{value:M,children:u.jsx(rq,q({as:r,ownerState:y,className:K(b.root,o),ref:i},_,{children:n}))})}),dq=lq;function sr(e){return typeof e=="string"}function pq(e,t,i){return e===void 0||sr(e)?t:q({},t,{ownerState:q({},t.ownerState,i)})}function e_(e,t=[]){if(e===void 0)return{};const i={};return Object.keys(e).filter(a=>a.match(/^on[A-Z]/)&&typeof e[a]=="function"&&!t.includes(a)).forEach(a=>{i[a]=e[a]}),i}function cq(e,t,i){return typeof e=="function"?e(t,i):e}function sf(e){if(e===void 0)return{};const t={};return Object.keys(e).filter(i=>!(i.match(/^on[A-Z]/)&&typeof e[i]=="function")).forEach(i=>{t[i]=e[i]}),t}function uq(e){const{getSlotProps:t,additionalProps:i,externalSlotProps:a,externalForwardedProps:n,className:o}=e;if(!t){const c=K(n==null?void 0:n.className,a==null?void 0:a.className,o,i==null?void 0:i.className),g=q({},i==null?void 0:i.style,n==null?void 0:n.style,a==null?void 0:a.style),m=q({},i,n,a);return c.length>0&&(m.className=c),Object.keys(g).length>0&&(m.style=g),{props:m,internalRef:void 0}}const s=e_(q({},n,a)),r=sf(a),l=sf(n),d=t(s),p=K(d==null?void 0:d.className,i==null?void 0:i.className,o,n==null?void 0:n.className,a==null?void 0:a.className),f=q({},d==null?void 0:d.style,i==null?void 0:i.style,n==null?void 0:n.style,a==null?void 0:a.style),h=q({},d,i,l,r);return p.length>0&&(h.className=p),Object.keys(f).length>0&&(h.style=f),{props:h,internalRef:d.ref}}const mq=["elementType","externalSlotProps","ownerState","skipResolvingSlotProps"];function un(e){var t;const{elementType:i,externalSlotProps:a,ownerState:n,skipResolvingSlotProps:o=!1}=e,s=$(e,mq),r=o?{}:cq(a,n),{props:l,internalRef:d}=uq(q({},s,{externalSlotProps:r})),p=Ye(d,r==null?void 0:r.ref,(t=e.additionalProps)==null?void 0:t.ref);return pq(i,q({},l,{ref:p}),n)}function fq(e){return ue("MuiList",e)}oe("MuiList",["root","padding","dense","subheader"]);const hq=["children","className","component","dense","disablePadding","subheader"],gq=e=>{const{classes:t,disablePadding:i,dense:a,subheader:n}=e;return me({root:["root",!i&&"padding",a&&"dense",n&&"subheader"]},fq,t)},yq=W("ul",{name:"MuiList",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,!i.disablePadding&&t.padding,i.dense&&t.dense,i.subheader&&t.subheader]}})(({ownerState:e})=>q({listStyle:"none",margin:0,padding:0,position:"relative"},!e.disablePadding&&{paddingTop:8,paddingBottom:8},e.subheader&&{paddingTop:0})),_q=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiList"}),{children:n,className:o,component:s="ul",dense:r=!1,disablePadding:l=!1,subheader:d}=a,p=$(a,hq),f=k.useMemo(()=>({dense:r}),[r]),h=q({},a,{component:s,dense:r,disablePadding:l}),c=gq(h);return u.jsx(fp.Provider,{value:f,children:u.jsxs(yq,q({as:s,className:K(c.root,o),ref:i,ownerState:h},p,{children:[d,n]}))})}),bq=_q,kq=["actions","autoFocus","autoFocusItem","children","className","disabledItemsFocusable","disableListWrap","onKeyDown","variant"];function Kl(e,t,i){return e===t?e.firstChild:t&&t.nextElementSibling?t.nextElementSibling:i?null:e.firstChild}function rf(e,t,i){return e===t?i?e.firstChild:e.lastChild:t&&t.previousElementSibling?t.previousElementSibling:i?null:e.lastChild}function t_(e,t){if(t===void 0)return!0;let i=e.innerText;return i===void 0&&(i=e.textContent),i=i.trim().toLowerCase(),i.length===0?!1:t.repeating?i[0]===t.keys[0]:i.indexOf(t.keys.join(""))===0}function Mn(e,t,i,a,n,o){let s=!1,r=n(e,t,t?i:!1);for(;r;){if(r===e.firstChild){if(s)return!1;s=!0}const l=a?!1:r.disabled||r.getAttribute("aria-disabled")==="true";if(!r.hasAttribute("tabindex")||!t_(r,o)||l)r=n(e,r,i);else return r.focus(),!0}return!1}const vq=k.forwardRef(function(t,i){const{actions:a,autoFocus:n=!1,autoFocusItem:o=!1,children:s,className:r,disabledItemsFocusable:l=!1,disableListWrap:d=!1,onKeyDown:p,variant:f="selectedMenu"}=t,h=$(t,kq),c=k.useRef(null),g=k.useRef({keys:[],repeating:!0,previousKeyMatched:!0,lastTime:null});Yi(()=>{n&&c.current.focus()},[n]),k.useImperativeHandle(a,()=>({adjustStyleForScrollbar:(b,v)=>{const F=!c.current.style.width;if(b.clientHeight<c.current.clientHeight&&F){const T=`${ry(mt(b))}px`;c.current.style[v.direction==="rtl"?"paddingLeft":"paddingRight"]=T,c.current.style.width=`calc(100% + ${T})`}return c.current}}),[]);const m=b=>{const v=c.current,F=b.key,T=mt(v).activeElement;if(F==="ArrowDown")b.preventDefault(),Mn(v,T,d,l,Kl);else if(F==="ArrowUp")b.preventDefault(),Mn(v,T,d,l,rf);else if(F==="Home")b.preventDefault(),Mn(v,null,d,l,Kl);else if(F==="End")b.preventDefault(),Mn(v,null,d,l,rf);else if(F.length===1){const w=g.current,D=F.toLowerCase(),P=performance.now();w.keys.length>0&&(P-w.lastTime>500?(w.keys=[],w.repeating=!0,w.previousKeyMatched=!0):w.repeating&&D!==w.keys[0]&&(w.repeating=!1)),w.lastTime=P,w.keys.push(D);const R=T&&!w.repeating&&t_(T,w);w.previousKeyMatched&&(R||Mn(v,T,!1,l,Kl,w))?b.preventDefault():w.previousKeyMatched=!1}p&&p(b)},x=Ye(c,i);let _=-1;k.Children.forEach(s,(b,v)=>{if(!k.isValidElement(b)){_===v&&(_+=1,_>=s.length&&(_=-1));return}b.props.disabled||(f==="selectedMenu"&&b.props.selected||_===-1)&&(_=v),_===v&&(b.props.disabled||b.props.muiSkipListHighlight||b.type.muiSkipListHighlight)&&(_+=1,_>=s.length&&(_=-1))});const y=k.Children.map(s,(b,v)=>{if(v===_){const F={};return o&&(F.autoFocus=!0),b.props.tabIndex===void 0&&f==="selectedMenu"&&(F.tabIndex=0),k.cloneElement(b,F)}return b});return u.jsx(bq,q({role:"menu",ref:x,className:r,onKeyDown:m,tabIndex:n?0:-1},h,{children:y}))}),wq=vq,qq=["input","select","textarea","a[href]","button","[tabindex]","audio[controls]","video[controls]",'[contenteditable]:not([contenteditable="false"])'].join(",");function xq(e){const t=parseInt(e.getAttribute("tabindex")||"",10);return Number.isNaN(t)?e.contentEditable==="true"||(e.nodeName==="AUDIO"||e.nodeName==="VIDEO"||e.nodeName==="DETAILS")&&e.getAttribute("tabindex")===null?0:e.tabIndex:t}function Fq(e){if(e.tagName!=="INPUT"||e.type!=="radio"||!e.name)return!1;const t=a=>e.ownerDocument.querySelector(`input[type="radio"]${a}`);let i=t(`[name="${e.name}"]:checked`);return i||(i=t(`[name="${e.name}"]`)),i!==e}function Tq(e){return!(e.disabled||e.tagName==="INPUT"&&e.type==="hidden"||Fq(e))}function Dq(e){const t=[],i=[];return Array.from(e.querySelectorAll(qq)).forEach((a,n)=>{const o=xq(a);o===-1||!Tq(a)||(o===0?t.push(a):i.push({documentOrder:n,tabIndex:o,node:a}))}),i.sort((a,n)=>a.tabIndex===n.tabIndex?a.documentOrder-n.documentOrder:a.tabIndex-n.tabIndex).map(a=>a.node).concat(t)}function Cq(){return!0}function Rq(e){const{children:t,disableAutoFocus:i=!1,disableEnforceFocus:a=!1,disableRestoreFocus:n=!1,getTabbable:o=Dq,isEnabled:s=Cq,open:r}=e,l=k.useRef(!1),d=k.useRef(null),p=k.useRef(null),f=k.useRef(null),h=k.useRef(null),c=k.useRef(!1),g=k.useRef(null),m=Ye(t.ref,g),x=k.useRef(null);k.useEffect(()=>{!r||!g.current||(c.current=!i)},[i,r]),k.useEffect(()=>{if(!r||!g.current)return;const b=mt(g.current);return g.current.contains(b.activeElement)||(g.current.hasAttribute("tabIndex")||g.current.setAttribute("tabIndex","-1"),c.current&&g.current.focus()),()=>{n||(f.current&&f.current.focus&&(l.current=!0,f.current.focus()),f.current=null)}},[r]),k.useEffect(()=>{if(!r||!g.current)return;const b=mt(g.current),v=w=>{x.current=w,!(a||!s()||w.key!=="Tab")&&b.activeElement===g.current&&w.shiftKey&&(l.current=!0,p.current&&p.current.focus())},F=()=>{const w=g.current;if(w===null)return;if(!b.hasFocus()||!s()||l.current){l.current=!1;return}if(w.contains(b.activeElement)||a&&b.activeElement!==d.current&&b.activeElement!==p.current)return;if(b.activeElement!==h.current)h.current=null;else if(h.current!==null)return;if(!c.current)return;let D=[];if((b.activeElement===d.current||b.activeElement===p.current)&&(D=o(g.current)),D.length>0){var P,R;const A=!!((P=x.current)!=null&&P.shiftKey&&((R=x.current)==null?void 0:R.key)==="Tab"),M=D[0],O=D[D.length-1];typeof M!="string"&&typeof O!="string"&&(A?O.focus():M.focus())}else w.focus()};b.addEventListener("focusin",F),b.addEventListener("keydown",v,!0);const T=setInterval(()=>{b.activeElement&&b.activeElement.tagName==="BODY"&&F()},50);return()=>{clearInterval(T),b.removeEventListener("focusin",F),b.removeEventListener("keydown",v,!0)}},[i,a,n,s,r,o]);const _=b=>{f.current===null&&(f.current=b.relatedTarget),c.current=!0,h.current=b.target;const v=t.props.onFocus;v&&v(b)},y=b=>{f.current===null&&(f.current=b.relatedTarget),c.current=!0};return u.jsxs(k.Fragment,{children:[u.jsx("div",{tabIndex:r?0:-1,onFocus:y,ref:d,"data-testid":"sentinelStart"}),k.cloneElement(t,{ref:m,onFocus:_}),u.jsx("div",{tabIndex:r?0:-1,onFocus:y,ref:p,"data-testid":"sentinelEnd"})]})}function Pq(e){return typeof e=="function"?e():e}const Sq=k.forwardRef(function(t,i){const{children:a,container:n,disablePortal:o=!1}=t,[s,r]=k.useState(null),l=Ye(k.isValidElement(a)?a.ref:null,i);if(Yi(()=>{o||r(Pq(n)||document.body)},[n,o]),Yi(()=>{if(s&&!o)return er(i,s),()=>{er(i,null)}},[i,s,o]),o){if(k.isValidElement(a)){const d={ref:l};return k.cloneElement(a,d)}return u.jsx(k.Fragment,{children:a})}return u.jsx(k.Fragment,{children:s&&qr.createPortal(a,s)})});function Eq(e){const t=mt(e);return t.body===e?oi(e).innerWidth>t.documentElement.clientWidth:e.scrollHeight>e.clientHeight}function ao(e,t){t?e.setAttribute("aria-hidden","true"):e.removeAttribute("aria-hidden")}function lf(e){return parseInt(oi(e).getComputedStyle(e).paddingRight,10)||0}function Bq(e){const i=["TEMPLATE","SCRIPT","STYLE","LINK","MAP","META","NOSCRIPT","PICTURE","COL","COLGROUP","PARAM","SLOT","SOURCE","TRACK"].indexOf(e.tagName)!==-1,a=e.tagName==="INPUT"&&e.getAttribute("type")==="hidden";return i||a}function df(e,t,i,a,n){const o=[t,i,...a];[].forEach.call(e.children,s=>{const r=o.indexOf(s)===-1,l=!Bq(s);r&&l&&ao(s,n)})}function Hl(e,t){let i=-1;return e.some((a,n)=>t(a)?(i=n,!0):!1),i}function Aq(e,t){const i=[],a=e.container;if(!t.disableScrollLock){if(Eq(a)){const s=ry(mt(a));i.push({value:a.style.paddingRight,property:"padding-right",el:a}),a.style.paddingRight=`${lf(a)+s}px`;const r=mt(a).querySelectorAll(".mui-fixed");[].forEach.call(r,l=>{i.push({value:l.style.paddingRight,property:"padding-right",el:l}),l.style.paddingRight=`${lf(l)+s}px`})}let o;if(a.parentNode instanceof DocumentFragment)o=mt(a).body;else{const s=a.parentElement,r=oi(a);o=(s==null?void 0:s.nodeName)==="HTML"&&r.getComputedStyle(s).overflowY==="scroll"?s:a}i.push({value:o.style.overflow,property:"overflow",el:o},{value:o.style.overflowX,property:"overflow-x",el:o},{value:o.style.overflowY,property:"overflow-y",el:o}),o.style.overflow="hidden"}return()=>{i.forEach(({value:o,el:s,property:r})=>{o?s.style.setProperty(r,o):s.style.removeProperty(r)})}}function jq(e){const t=[];return[].forEach.call(e.children,i=>{i.getAttribute("aria-hidden")==="true"&&t.push(i)}),t}class Mq{constructor(){this.containers=void 0,this.modals=void 0,this.modals=[],this.containers=[]}add(t,i){let a=this.modals.indexOf(t);if(a!==-1)return a;a=this.modals.length,this.modals.push(t),t.modalRef&&ao(t.modalRef,!1);const n=jq(i);df(i,t.mount,t.modalRef,n,!0);const o=Hl(this.containers,s=>s.container===i);return o!==-1?(this.containers[o].modals.push(t),a):(this.containers.push({modals:[t],container:i,restore:null,hiddenSiblings:n}),a)}mount(t,i){const a=Hl(this.containers,o=>o.modals.indexOf(t)!==-1),n=this.containers[a];n.restore||(n.restore=Aq(n,i))}remove(t,i=!0){const a=this.modals.indexOf(t);if(a===-1)return a;const n=Hl(this.containers,s=>s.modals.indexOf(t)!==-1),o=this.containers[n];if(o.modals.splice(o.modals.indexOf(t),1),this.modals.splice(a,1),o.modals.length===0)o.restore&&o.restore(),t.modalRef&&ao(t.modalRef,i),df(o.container,t.mount,t.modalRef,o.hiddenSiblings,!1),this.containers.splice(n,1);else{const s=o.modals[o.modals.length-1];s.modalRef&&ao(s.modalRef,!1)}return a}isTopModal(t){return this.modals.length>0&&this.modals[this.modals.length-1]===t}}function zq(e){return typeof e=="function"?e():e}function Iq(e){return e?e.props.hasOwnProperty("in"):!1}const Nq=new Mq;function Oq(e){const{container:t,disableEscapeKeyDown:i=!1,disableScrollLock:a=!1,manager:n=Nq,closeAfterTransition:o=!1,onTransitionEnter:s,onTransitionExited:r,children:l,onClose:d,open:p,rootRef:f}=e,h=k.useRef({}),c=k.useRef(null),g=k.useRef(null),m=Ye(g,f),[x,_]=k.useState(!p),y=Iq(l);let b=!0;(e["aria-hidden"]==="false"||e["aria-hidden"]===!1)&&(b=!1);const v=()=>mt(c.current),F=()=>(h.current.modalRef=g.current,h.current.mount=c.current,h.current),T=()=>{n.mount(F(),{disableScrollLock:a}),g.current&&(g.current.scrollTop=0)},w=ma(()=>{const z=zq(t)||v().body;n.add(F(),z),g.current&&T()}),D=k.useCallback(()=>n.isTopModal(F()),[n]),P=ma(z=>{c.current=z,z&&(p&&D()?T():g.current&&ao(g.current,b))}),R=k.useCallback(()=>{n.remove(F(),b)},[b,n]);k.useEffect(()=>()=>{R()},[R]),k.useEffect(()=>{p?w():(!y||!o)&&R()},[p,R,y,o,w]);const A=z=>L=>{var C;(C=z.onKeyDown)==null||C.call(z,L),!(L.key!=="Escape"||!D())&&(i||(L.stopPropagation(),d&&d(L,"escapeKeyDown")))},M=z=>L=>{var C;(C=z.onClick)==null||C.call(z,L),L.target===L.currentTarget&&d&&d(L,"backdropClick")};return{getRootProps:(z={})=>{const L=e_(e);delete L.onTransitionEnter,delete L.onTransitionExited;const C=q({},L,z);return q({role:"presentation"},C,{onKeyDown:A(C),ref:m})},getBackdropProps:(z={})=>{const L=z;return q({"aria-hidden":!0},L,{onClick:M(L),open:p})},getTransitionProps:()=>{const z=()=>{_(!1),s&&s()},L=()=>{_(!0),r&&r(),o&&R()};return{onEnter:ep(z,l==null?void 0:l.props.onEnter),onExited:ep(L,l==null?void 0:l.props.onExited)}},rootRef:m,portalRef:P,isTopModal:D,exited:x,hasTransition:y}}const Lq=["onChange","maxRows","minRows","style","value"];function rs(e){return parseInt(e,10)||0}const Wq={shadow:{visibility:"hidden",position:"absolute",overflow:"hidden",height:0,top:0,left:0,transform:"translateZ(0)"}};function pf(e){return e==null||Object.keys(e).length===0||e.outerHeightStyle===0&&!e.overflow}const $q=k.forwardRef(function(t,i){const{onChange:a,maxRows:n,minRows:o=1,style:s,value:r}=t,l=$(t,Lq),{current:d}=k.useRef(r!=null),p=k.useRef(null),f=Ye(i,p),h=k.useRef(null),c=k.useRef(0),[g,m]=k.useState({outerHeightStyle:0}),x=k.useCallback(()=>{const F=p.current,w=oi(F).getComputedStyle(F);if(w.width==="0px")return{outerHeightStyle:0};const D=h.current;D.style.width=w.width,D.value=F.value||t.placeholder||"x",D.value.slice(-1)===`
`&&(D.value+=" ");const P=w.boxSizing,R=rs(w.paddingBottom)+rs(w.paddingTop),A=rs(w.borderBottomWidth)+rs(w.borderTopWidth),M=D.scrollHeight;D.value="x";const O=D.scrollHeight;let E=M;o&&(E=Math.max(Number(o)*O,E)),n&&(E=Math.min(Number(n)*O,E)),E=Math.max(E,O);const j=E+(P==="border-box"?R+A:0),z=Math.abs(E-M)<=1;return{outerHeightStyle:j,overflow:z}},[n,o,t.placeholder]),_=(F,T)=>{const{outerHeightStyle:w,overflow:D}=T;return c.current<20&&(w>0&&Math.abs((F.outerHeightStyle||0)-w)>1||F.overflow!==D)?(c.current+=1,{overflow:D,outerHeightStyle:w}):F},y=k.useCallback(()=>{const F=x();pf(F)||m(T=>_(T,F))},[x]),b=()=>{const F=x();pf(F)||qr.flushSync(()=>{m(T=>_(T,F))})};k.useEffect(()=>{const F=()=>{c.current=0,p.current&&b()},T=Mr(()=>{c.current=0,p.current&&b()});let w;const D=p.current,P=oi(D);return P.addEventListener("resize",T),typeof ResizeObserver<"u"&&(w=new ResizeObserver(F),w.observe(D)),()=>{T.clear(),P.removeEventListener("resize",T),w&&w.disconnect()}}),Yi(()=>{y()}),k.useEffect(()=>{c.current=0},[r]);const v=F=>{c.current=0,d||y(),a&&a(F)};return u.jsxs(k.Fragment,{children:[u.jsx("textarea",q({value:r,onChange:v,ref:f,rows:o,style:q({height:g.outerHeightStyle,overflow:g.overflow?"hidden":void 0},s)},l)),u.jsx("textarea",{"aria-hidden":!0,className:t.className,readOnly:!0,ref:h,tabIndex:-1,style:q({},Wq.shadow,s,{paddingTop:0,paddingBottom:0})})]})}),Kc=e=>e.scrollTop;function mn(e,t){var i,a;const{timeout:n,easing:o,style:s={}}=e;return{duration:(i=s.transitionDuration)!=null?i:typeof n=="number"?n:n[t.mode]||0,easing:(a=s.transitionTimingFunction)!=null?a:typeof o=="object"?o[t.mode]:o,delay:s.transitionDelay}}const Gq=["addEndListener","appear","children","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"];function _p(e){return`scale(${e}, ${e**2})`}const Uq={entering:{opacity:1,transform:_p(1)},entered:{opacity:1,transform:"none"}},Vl=typeof navigator<"u"&&/^((?!chrome|android).)*(safari|mobile)/i.test(navigator.userAgent)&&/(os |version\/)15(.|_)4/i.test(navigator.userAgent),i_=k.forwardRef(function(t,i){const{addEndListener:a,appear:n=!0,children:o,easing:s,in:r,onEnter:l,onEntered:d,onEntering:p,onExit:f,onExited:h,onExiting:c,style:g,timeout:m="auto",TransitionComponent:x=$c}=t,_=$(t,Gq),y=k.useRef(),b=k.useRef(),v=wn(),F=k.useRef(null),T=Ye(F,o.ref,i),w=j=>z=>{if(j){const L=F.current;z===void 0?j(L):j(L,z)}},D=w(p),P=w((j,z)=>{Kc(j);const{duration:L,delay:C,easing:B}=mn({style:g,timeout:m,easing:s},{mode:"enter"});let I;m==="auto"?(I=v.transitions.getAutoHeightDuration(j.clientHeight),b.current=I):I=L,j.style.transition=[v.transitions.create("opacity",{duration:I,delay:C}),v.transitions.create("transform",{duration:Vl?I:I*.666,delay:C,easing:B})].join(","),l&&l(j,z)}),R=w(d),A=w(c),M=w(j=>{const{duration:z,delay:L,easing:C}=mn({style:g,timeout:m,easing:s},{mode:"exit"});let B;m==="auto"?(B=v.transitions.getAutoHeightDuration(j.clientHeight),b.current=B):B=z,j.style.transition=[v.transitions.create("opacity",{duration:B,delay:L}),v.transitions.create("transform",{duration:Vl?B:B*.666,delay:Vl?L:L||B*.333,easing:C})].join(","),j.style.opacity=0,j.style.transform=_p(.75),f&&f(j)}),O=w(h),E=j=>{m==="auto"&&(y.current=setTimeout(j,b.current||0)),a&&a(F.current,j)};return k.useEffect(()=>()=>{clearTimeout(y.current)},[]),u.jsx(x,q({appear:n,in:r,nodeRef:F,onEnter:P,onEntered:R,onEntering:D,onExit:M,onExited:O,onExiting:A,addEndListener:E,timeout:m==="auto"?null:m},_,{children:(j,z)=>k.cloneElement(o,q({style:q({opacity:0,transform:_p(.75),visibility:j==="exited"&&!r?"hidden":void 0},Uq[j],g,o.props.style),ref:T},z))}))});i_.muiSupportAuto=!0;const Kq=i_,Hq=["addEndListener","appear","children","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"],Vq={entering:{opacity:1},entered:{opacity:1}},Xq=k.forwardRef(function(t,i){const a=wn(),n={enter:a.transitions.duration.enteringScreen,exit:a.transitions.duration.leavingScreen},{addEndListener:o,appear:s=!0,children:r,easing:l,in:d,onEnter:p,onEntered:f,onEntering:h,onExit:c,onExited:g,onExiting:m,style:x,timeout:_=n,TransitionComponent:y=$c}=t,b=$(t,Hq),v=k.useRef(null),F=Ye(v,r.ref,i),T=E=>j=>{if(E){const z=v.current;j===void 0?E(z):E(z,j)}},w=T(h),D=T((E,j)=>{Kc(E);const z=mn({style:x,timeout:_,easing:l},{mode:"enter"});E.style.webkitTransition=a.transitions.create("opacity",z),E.style.transition=a.transitions.create("opacity",z),p&&p(E,j)}),P=T(f),R=T(m),A=T(E=>{const j=mn({style:x,timeout:_,easing:l},{mode:"exit"});E.style.webkitTransition=a.transitions.create("opacity",j),E.style.transition=a.transitions.create("opacity",j),c&&c(E)}),M=T(g),O=E=>{o&&o(v.current,E)};return u.jsx(y,q({appear:s,in:d,nodeRef:v,onEnter:D,onEntered:P,onEntering:w,onExit:A,onExited:M,onExiting:R,addEndListener:O,timeout:_},b,{children:(E,j)=>k.cloneElement(r,q({style:q({opacity:0,visibility:E==="exited"&&!d?"hidden":void 0},Vq[E],x,r.props.style),ref:F},j))}))}),a_=Xq;function Yq(e){return ue("MuiBackdrop",e)}oe("MuiBackdrop",["root","invisible"]);const Qq=["children","className","component","components","componentsProps","invisible","open","slotProps","slots","TransitionComponent","transitionDuration"],Jq=e=>{const{classes:t,invisible:i}=e;return me({root:["root",i&&"invisible"]},Yq,t)},Zq=W("div",{name:"MuiBackdrop",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,i.invisible&&t.invisible]}})(({ownerState:e})=>q({position:"fixed",display:"flex",alignItems:"center",justifyContent:"center",right:0,bottom:0,top:0,left:0,backgroundColor:"rgba(0, 0, 0, 0.5)",WebkitTapHighlightColor:"transparent"},e.invisible&&{backgroundColor:"transparent"})),ex=k.forwardRef(function(t,i){var a,n,o;const s=fe({props:t,name:"MuiBackdrop"}),{children:r,className:l,component:d="div",components:p={},componentsProps:f={},invisible:h=!1,open:c,slotProps:g={},slots:m={},TransitionComponent:x=a_,transitionDuration:_}=s,y=$(s,Qq),b=q({},s,{component:d,invisible:h}),v=Jq(b),F=(a=g.root)!=null?a:f.root;return u.jsx(x,q({in:c,timeout:_},y,{children:u.jsx(Zq,q({"aria-hidden":!0},F,{as:(n=(o=m.root)!=null?o:p.Root)!=null?n:d,className:K(v.root,l,F==null?void 0:F.className),ownerState:q({},b,F==null?void 0:F.ownerState),classes:v,ref:i,children:r}))}))}),n_=ex;function tx(e){return ue("MuiModal",e)}oe("MuiModal",["root","hidden","backdrop"]);const ix=["BackdropComponent","BackdropProps","classes","className","closeAfterTransition","children","container","component","components","componentsProps","disableAutoFocus","disableEnforceFocus","disableEscapeKeyDown","disablePortal","disableRestoreFocus","disableScrollLock","hideBackdrop","keepMounted","onBackdropClick","onClose","onTransitionEnter","onTransitionExited","open","slotProps","slots","theme"],ax=e=>{const{open:t,exited:i,classes:a}=e;return me({root:["root",!t&&i&&"hidden"],backdrop:["backdrop"]},tx,a)},nx=W("div",{name:"MuiModal",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,!i.open&&i.exited&&t.hidden]}})(({theme:e,ownerState:t})=>q({position:"fixed",zIndex:(e.vars||e).zIndex.modal,right:0,bottom:0,top:0,left:0},!t.open&&t.exited&&{visibility:"hidden"})),ox=W(n_,{name:"MuiModal",slot:"Backdrop",overridesResolver:(e,t)=>t.backdrop})({zIndex:-1}),sx=k.forwardRef(function(t,i){var a,n,o,s,r,l;const d=fe({name:"MuiModal",props:t}),{BackdropComponent:p=ox,BackdropProps:f,className:h,closeAfterTransition:c=!1,children:g,container:m,component:x,components:_={},componentsProps:y={},disableAutoFocus:b=!1,disableEnforceFocus:v=!1,disableEscapeKeyDown:F=!1,disablePortal:T=!1,disableRestoreFocus:w=!1,disableScrollLock:D=!1,hideBackdrop:P=!1,keepMounted:R=!1,onBackdropClick:A,open:M,slotProps:O,slots:E}=d,j=$(d,ix),z=q({},d,{closeAfterTransition:c,disableAutoFocus:b,disableEnforceFocus:v,disableEscapeKeyDown:F,disablePortal:T,disableRestoreFocus:w,disableScrollLock:D,hideBackdrop:P,keepMounted:R}),{getRootProps:L,getBackdropProps:C,getTransitionProps:B,portalRef:I,isTopModal:ee,exited:X,hasTransition:Be}=Oq(q({},z,{rootRef:i})),J=q({},z,{exited:X}),ke=ax(J),re={};if(g.props.tabIndex===void 0&&(re.tabIndex="-1"),Be){const{onEnter:Y,onExited:pe}=B();re.onEnter=Y,re.onExited=pe}const Ge=(a=(n=E==null?void 0:E.root)!=null?n:_.Root)!=null?a:nx,Ft=(o=(s=E==null?void 0:E.backdrop)!=null?s:_.Backdrop)!=null?o:p,Ae=(r=O==null?void 0:O.root)!=null?r:y.root,st=(l=O==null?void 0:O.backdrop)!=null?l:y.backdrop,ne=un({elementType:Ge,externalSlotProps:Ae,externalForwardedProps:j,getSlotProps:L,additionalProps:{ref:i,as:x},ownerState:J,className:K(h,Ae==null?void 0:Ae.className,ke==null?void 0:ke.root,!J.open&&J.exited&&(ke==null?void 0:ke.hidden))}),Fe=un({elementType:Ft,externalSlotProps:st,additionalProps:f,getSlotProps:Y=>C(q({},Y,{onClick:pe=>{A&&A(pe),Y!=null&&Y.onClick&&Y.onClick(pe)}})),className:K(st==null?void 0:st.className,f==null?void 0:f.className,ke==null?void 0:ke.backdrop),ownerState:J});return!R&&!M&&(!Be||X)?null:u.jsx(Sq,{ref:I,container:m,disablePortal:T,children:u.jsxs(Ge,q({},ne,{children:[!P&&p?u.jsx(Ft,q({},Fe)):null,u.jsx(Rq,{disableEnforceFocus:v,disableAutoFocus:b,disableRestoreFocus:w,isEnabled:ee,open:M,children:k.cloneElement(g,re)})]}))})}),Hc=sx;function rx(e){return ue("MuiPaper",e)}oe("MuiPaper",["root","rounded","outlined","elevation","elevation0","elevation1","elevation2","elevation3","elevation4","elevation5","elevation6","elevation7","elevation8","elevation9","elevation10","elevation11","elevation12","elevation13","elevation14","elevation15","elevation16","elevation17","elevation18","elevation19","elevation20","elevation21","elevation22","elevation23","elevation24"]);const lx=["className","component","elevation","square","variant"],dx=e=>{const{square:t,elevation:i,variant:a,classes:n}=e,o={root:["root",a,!t&&"rounded",a==="elevation"&&`elevation${i}`]};return me(o,rx,n)},px=W("div",{name:"MuiPaper",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,t[i.variant],!i.square&&t.rounded,i.variant==="elevation"&&t[`elevation${i.elevation}`]]}})(({theme:e,ownerState:t})=>{var i;return q({backgroundColor:(e.vars||e).palette.background.paper,color:(e.vars||e).palette.text.primary,transition:e.transitions.create("box-shadow")},!t.square&&{borderRadius:e.shape.borderRadius},t.variant==="outlined"&&{border:`1px solid ${(e.vars||e).palette.divider}`},t.variant==="elevation"&&q({boxShadow:(e.vars||e).shadows[t.elevation]},!e.vars&&e.palette.mode==="dark"&&{backgroundImage:`linear-gradient(${hi("#fff",Hm(t.elevation))}, ${hi("#fff",Hm(t.elevation))})`},e.vars&&{backgroundImage:(i=e.vars.overlays)==null?void 0:i[t.elevation]}))}),cx=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiPaper"}),{className:n,component:o="div",elevation:s=1,square:r=!1,variant:l="elevation"}=a,d=$(a,lx),p=q({},a,{component:o,elevation:s,square:r,variant:l}),f=dx(p);return u.jsx(px,q({as:o,ownerState:p,className:K(f.root,n),ref:i},d))}),Oo=cx;function ux(e){return ue("MuiPopover",e)}oe("MuiPopover",["root","paper"]);const mx=["onEntering"],fx=["action","anchorEl","anchorOrigin","anchorPosition","anchorReference","children","className","container","elevation","marginThreshold","open","PaperProps","slots","slotProps","transformOrigin","TransitionComponent","transitionDuration","TransitionProps","disableScrollLock"],hx=["slotProps"];function cf(e,t){let i=0;return typeof t=="number"?i=t:t==="center"?i=e.height/2:t==="bottom"&&(i=e.height),i}function uf(e,t){let i=0;return typeof t=="number"?i=t:t==="center"?i=e.width/2:t==="right"&&(i=e.width),i}function mf(e){return[e.horizontal,e.vertical].map(t=>typeof t=="number"?`${t}px`:t).join(" ")}function Xl(e){return typeof e=="function"?e():e}const gx=e=>{const{classes:t}=e;return me({root:["root"],paper:["paper"]},ux,t)},yx=W(Hc,{name:"MuiPopover",slot:"Root",overridesResolver:(e,t)=>t.root})({}),o_=W(Oo,{name:"MuiPopover",slot:"Paper",overridesResolver:(e,t)=>t.paper})({position:"absolute",overflowY:"auto",overflowX:"hidden",minWidth:16,minHeight:16,maxWidth:"calc(100% - 32px)",maxHeight:"calc(100% - 32px)",outline:0}),_x=k.forwardRef(function(t,i){var a,n,o;const s=fe({props:t,name:"MuiPopover"}),{action:r,anchorEl:l,anchorOrigin:d={vertical:"top",horizontal:"left"},anchorPosition:p,anchorReference:f="anchorEl",children:h,className:c,container:g,elevation:m=8,marginThreshold:x=16,open:_,PaperProps:y={},slots:b,slotProps:v,transformOrigin:F={vertical:"top",horizontal:"left"},TransitionComponent:T=Kq,transitionDuration:w="auto",TransitionProps:{onEntering:D}={},disableScrollLock:P=!1}=s,R=$(s.TransitionProps,mx),A=$(s,fx),M=(a=v==null?void 0:v.paper)!=null?a:y,O=k.useRef(),E=Ye(O,M.ref),j=q({},s,{anchorOrigin:d,anchorReference:f,elevation:m,marginThreshold:x,externalPaperSlotProps:M,transformOrigin:F,TransitionComponent:T,transitionDuration:w,TransitionProps:R}),z=gx(j),L=k.useCallback(()=>{if(f==="anchorPosition")return p;const Y=Xl(l),ve=(Y&&Y.nodeType===1?Y:mt(O.current).body).getBoundingClientRect();return{top:ve.top+cf(ve,d.vertical),left:ve.left+uf(ve,d.horizontal)}},[l,d.horizontal,d.vertical,p,f]),C=k.useCallback(Y=>({vertical:cf(Y,F.vertical),horizontal:uf(Y,F.horizontal)}),[F.horizontal,F.vertical]),B=k.useCallback(Y=>{const pe={width:Y.offsetWidth,height:Y.offsetHeight},ve=C(pe);if(f==="none")return{top:null,left:null,transformOrigin:mf(ve)};const Fi=L();let Tt=Fi.top-ve.vertical,Dt=Fi.left-ve.horizontal;const It=Tt+pe.height,Ct=Dt+pe.width,Te=oi(Xl(l)),ri=Te.innerHeight-x,rt=Te.innerWidth-x;if(x!==null&&Tt<x){const we=Tt-x;Tt-=we,ve.vertical+=we}else if(x!==null&&It>ri){const we=It-ri;Tt-=we,ve.vertical+=we}if(x!==null&&Dt<x){const we=Dt-x;Dt-=we,ve.horizontal+=we}else if(Ct>rt){const we=Ct-rt;Dt-=we,ve.horizontal+=we}return{top:`${Math.round(Tt)}px`,left:`${Math.round(Dt)}px`,transformOrigin:mf(ve)}},[l,f,L,C,x]),[I,ee]=k.useState(_),X=k.useCallback(()=>{const Y=O.current;if(!Y)return;const pe=B(Y);pe.top!==null&&(Y.style.top=pe.top),pe.left!==null&&(Y.style.left=pe.left),Y.style.transformOrigin=pe.transformOrigin,ee(!0)},[B]);k.useEffect(()=>(P&&window.addEventListener("scroll",X),()=>window.removeEventListener("scroll",X)),[l,P,X]);const Be=(Y,pe)=>{D&&D(Y,pe),X()},J=()=>{ee(!1)};k.useEffect(()=>{_&&X()}),k.useImperativeHandle(r,()=>_?{updatePosition:()=>{X()}}:null,[_,X]),k.useEffect(()=>{if(!_)return;const Y=Mr(()=>{X()}),pe=oi(l);return pe.addEventListener("resize",Y),()=>{Y.clear(),pe.removeEventListener("resize",Y)}},[l,_,X]);let ke=w;w==="auto"&&!T.muiSupportAuto&&(ke=void 0);const re=g||(l?mt(Xl(l)).body:void 0),Ge=(n=b==null?void 0:b.root)!=null?n:yx,Ft=(o=b==null?void 0:b.paper)!=null?o:o_,Ae=un({elementType:Ft,externalSlotProps:q({},M,{style:I?M.style:q({},M.style,{opacity:0})}),additionalProps:{elevation:m,ref:E},ownerState:j,className:K(z.paper,M==null?void 0:M.className)}),st=un({elementType:Ge,externalSlotProps:(v==null?void 0:v.root)||{},externalForwardedProps:A,additionalProps:{ref:i,slotProps:{backdrop:{invisible:!0}},container:re,open:_},ownerState:j,className:K(z.root,c)}),{slotProps:ne}=st,Fe=$(st,hx);return u.jsx(Ge,q({},Fe,!sr(Ge)&&{slotProps:ne,disableScrollLock:P},{children:u.jsx(T,q({appear:!0,in:_,onEntering:Be,onExited:J,timeout:ke},R,{children:u.jsx(Ft,q({},Ae,{children:h}))}))}))}),bx=_x;function kx(e){return ue("MuiMenu",e)}oe("MuiMenu",["root","paper","list"]);const vx=["onEntering"],wx=["autoFocus","children","className","disableAutoFocusItem","MenuListProps","onClose","open","PaperProps","PopoverClasses","transitionDuration","TransitionProps","variant","slots","slotProps"],qx={vertical:"top",horizontal:"right"},xx={vertical:"top",horizontal:"left"},Fx=e=>{const{classes:t}=e;return me({root:["root"],paper:["paper"],list:["list"]},kx,t)},Tx=W(bx,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiMenu",slot:"Root",overridesResolver:(e,t)=>t.root})({}),Dx=W(o_,{name:"MuiMenu",slot:"Paper",overridesResolver:(e,t)=>t.paper})({maxHeight:"calc(100% - 96px)",WebkitOverflowScrolling:"touch"}),Cx=W(wq,{name:"MuiMenu",slot:"List",overridesResolver:(e,t)=>t.list})({outline:0}),Rx=k.forwardRef(function(t,i){var a,n;const o=fe({props:t,name:"MuiMenu"}),{autoFocus:s=!0,children:r,className:l,disableAutoFocusItem:d=!1,MenuListProps:p={},onClose:f,open:h,PaperProps:c={},PopoverClasses:g,transitionDuration:m="auto",TransitionProps:{onEntering:x}={},variant:_="selectedMenu",slots:y={},slotProps:b={}}=o,v=$(o.TransitionProps,vx),F=$(o,wx),T=wn(),w=T.direction==="rtl",D=q({},o,{autoFocus:s,disableAutoFocusItem:d,MenuListProps:p,onEntering:x,PaperProps:c,transitionDuration:m,TransitionProps:v,variant:_}),P=Fx(D),R=s&&!d&&h,A=k.useRef(null),M=(B,I)=>{A.current&&A.current.adjustStyleForScrollbar(B,T),x&&x(B,I)},O=B=>{B.key==="Tab"&&(B.preventDefault(),f&&f(B,"tabKeyDown"))};let E=-1;k.Children.map(r,(B,I)=>{k.isValidElement(B)&&(B.props.disabled||(_==="selectedMenu"&&B.props.selected||E===-1)&&(E=I))});const j=(a=y.paper)!=null?a:Dx,z=(n=b.paper)!=null?n:c,L=un({elementType:y.root,externalSlotProps:b.root,ownerState:D,className:[P.root,l]}),C=un({elementType:j,externalSlotProps:z,ownerState:D,className:P.paper});return u.jsx(Tx,q({onClose:f,anchorOrigin:{vertical:"bottom",horizontal:w?"right":"left"},transformOrigin:w?qx:xx,slots:{paper:j,root:y.root},slotProps:{root:L,paper:C},open:h,ref:i,transitionDuration:m,TransitionProps:q({onEntering:M},v),ownerState:D},F,{classes:g,children:u.jsx(Cx,q({onKeyDown:O,actions:A,autoFocus:s&&(E===-1||d),autoFocusItem:R,variant:_},p,{className:K(P.list,p.className),children:r}))}))}),Px=Rx;function Sx(e){return ue("MuiNativeSelect",e)}const Ex=oe("MuiNativeSelect",["root","select","multiple","filled","outlined","standard","disabled","icon","iconOpen","iconFilled","iconOutlined","iconStandard","nativeInput","error"]),Vc=Ex,Bx=["className","disabled","error","IconComponent","inputRef","variant"],Ax=e=>{const{classes:t,variant:i,disabled:a,multiple:n,open:o,error:s}=e,r={select:["select",i,a&&"disabled",n&&"multiple",s&&"error"],icon:["icon",`icon${V(i)}`,o&&"iconOpen",a&&"disabled"]};return me(r,Sx,t)},s_=({ownerState:e,theme:t})=>q({MozAppearance:"none",WebkitAppearance:"none",userSelect:"none",borderRadius:0,cursor:"pointer","&:focus":q({},t.vars?{backgroundColor:`rgba(${t.vars.palette.common.onBackgroundChannel} / 0.05)`}:{backgroundColor:t.palette.mode==="light"?"rgba(0, 0, 0, 0.05)":"rgba(255, 255, 255, 0.05)"},{borderRadius:0}),"&::-ms-expand":{display:"none"},[`&.${Vc.disabled}`]:{cursor:"default"},"&[multiple]":{height:"auto"},"&:not([multiple]) option, &:not([multiple]) optgroup":{backgroundColor:(t.vars||t).palette.background.paper},"&&&":{paddingRight:24,minWidth:16}},e.variant==="filled"&&{"&&&":{paddingRight:32}},e.variant==="outlined"&&{borderRadius:(t.vars||t).shape.borderRadius,"&:focus":{borderRadius:(t.vars||t).shape.borderRadius},"&&&":{paddingRight:32}}),jx=W("select",{name:"MuiNativeSelect",slot:"Select",shouldForwardProp:Ht,overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.select,t[i.variant],i.error&&t.error,{[`&.${Vc.multiple}`]:t.multiple}]}})(s_),r_=({ownerState:e,theme:t})=>q({position:"absolute",right:0,top:"calc(50% - .5em)",pointerEvents:"none",color:(t.vars||t).palette.action.active,[`&.${Vc.disabled}`]:{color:(t.vars||t).palette.action.disabled}},e.open&&{transform:"rotate(180deg)"},e.variant==="filled"&&{right:7},e.variant==="outlined"&&{right:7}),Mx=W("svg",{name:"MuiNativeSelect",slot:"Icon",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.icon,i.variant&&t[`icon${V(i.variant)}`],i.open&&t.iconOpen]}})(r_),zx=k.forwardRef(function(t,i){const{className:a,disabled:n,error:o,IconComponent:s,inputRef:r,variant:l="standard"}=t,d=$(t,Bx),p=q({},t,{disabled:n,variant:l,error:o}),f=Ax(p);return u.jsxs(k.Fragment,{children:[u.jsx(jx,q({ownerState:p,className:K(f.select,a),disabled:n,ref:r||i},d)),t.multiple?null:u.jsx(Mx,{as:s,ownerState:p,className:f.icon})]})}),Ix=zx;function Nx(e){return ue("MuiSelect",e)}const Ox=oe("MuiSelect",["root","select","multiple","filled","outlined","standard","disabled","focused","icon","iconOpen","iconFilled","iconOutlined","iconStandard","nativeInput","error"]),zn=Ox;var ff;const Lx=["aria-describedby","aria-label","autoFocus","autoWidth","children","className","defaultOpen","defaultValue","disabled","displayEmpty","error","IconComponent","inputRef","labelId","MenuProps","multiple","name","onBlur","onChange","onClose","onFocus","onOpen","open","readOnly","renderValue","SelectDisplayProps","tabIndex","type","value","variant"],Wx=W("div",{name:"MuiSelect",slot:"Select",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[{[`&.${zn.select}`]:t.select},{[`&.${zn.select}`]:t[i.variant]},{[`&.${zn.error}`]:t.error},{[`&.${zn.multiple}`]:t.multiple}]}})(s_,{[`&.${zn.select}`]:{height:"auto",minHeight:"1.4375em",textOverflow:"ellipsis",whiteSpace:"nowrap",overflow:"hidden"}}),$x=W("svg",{name:"MuiSelect",slot:"Icon",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.icon,i.variant&&t[`icon${V(i.variant)}`],i.open&&t.iconOpen]}})(r_),Gx=W("input",{shouldForwardProp:e=>A3(e)&&e!=="classes",name:"MuiSelect",slot:"NativeInput",overridesResolver:(e,t)=>t.nativeInput})({bottom:0,left:0,position:"absolute",opacity:0,pointerEvents:"none",width:"100%",boxSizing:"border-box"});function hf(e,t){return typeof t=="object"&&t!==null?e===t:String(e)===String(t)}function Ux(e){return e==null||typeof e=="string"&&!e.trim()}const Kx=e=>{const{classes:t,variant:i,disabled:a,multiple:n,open:o,error:s}=e,r={select:["select",i,a&&"disabled",n&&"multiple",s&&"error"],icon:["icon",`icon${V(i)}`,o&&"iconOpen",a&&"disabled"],nativeInput:["nativeInput"]};return me(r,Nx,t)},Hx=k.forwardRef(function(t,i){var a;const{"aria-describedby":n,"aria-label":o,autoFocus:s,autoWidth:r,children:l,className:d,defaultOpen:p,defaultValue:f,disabled:h,displayEmpty:c,error:g=!1,IconComponent:m,inputRef:x,labelId:_,MenuProps:y={},multiple:b,name:v,onBlur:F,onChange:T,onClose:w,onFocus:D,onOpen:P,open:R,readOnly:A,renderValue:M,SelectDisplayProps:O={},tabIndex:E,value:j,variant:z="standard"}=t,L=$(t,Lx),[C,B]=tp({controlled:j,default:f,name:"Select"}),[I,ee]=tp({controlled:R,default:p,name:"Select"}),X=k.useRef(null),Be=k.useRef(null),[J,ke]=k.useState(null),{current:re}=k.useRef(R!=null),[Ge,Ft]=k.useState(),Ae=Ye(i,x),st=k.useCallback(G=>{Be.current=G,G&&ke(G)},[]),ne=J==null?void 0:J.parentNode;k.useImperativeHandle(Ae,()=>({focus:()=>{Be.current.focus()},node:X.current,value:C}),[C]),k.useEffect(()=>{p&&I&&J&&!re&&(Ft(r?null:ne.clientWidth),Be.current.focus())},[J,r]),k.useEffect(()=>{s&&Be.current.focus()},[s]),k.useEffect(()=>{if(!_)return;const G=mt(Be.current).getElementById(_);if(G){const ge=()=>{getSelection().isCollapsed&&Be.current.focus()};return G.addEventListener("click",ge),()=>{G.removeEventListener("click",ge)}}},[_]);const Fe=(G,ge)=>{G?P&&P(ge):w&&w(ge),re||(Ft(r?null:ne.clientWidth),ee(G))},Y=G=>{G.button===0&&(G.preventDefault(),Be.current.focus(),Fe(!0,G))},pe=G=>{Fe(!1,G)},ve=k.Children.toArray(l),Fi=G=>{const ge=ve.find(Ue=>Ue.props.value===G.target.value);ge!==void 0&&(B(ge.props.value),T&&T(G,ge))},Tt=G=>ge=>{let Ue;if(ge.currentTarget.hasAttribute("tabindex")){if(b){Ue=Array.isArray(C)?C.slice():[];const Da=C.indexOf(G.props.value);Da===-1?Ue.push(G.props.value):Ue.splice(Da,1)}else Ue=G.props.value;if(G.props.onClick&&G.props.onClick(ge),C!==Ue&&(B(Ue),T)){const Da=ge.nativeEvent||ge,eu=new Da.constructor(Da.type,Da);Object.defineProperty(eu,"target",{writable:!0,value:{value:Ue,name:v}}),T(eu,G)}b||Fe(!1,ge)}},Dt=G=>{A||[" ","ArrowUp","ArrowDown","Enter"].indexOf(G.key)!==-1&&(G.preventDefault(),Fe(!0,G))},It=J!==null&&I,Ct=G=>{!It&&F&&(Object.defineProperty(G,"target",{writable:!0,value:{value:C,name:v}}),F(G))};delete L["aria-invalid"];let Te,ri;const rt=[];let we=!1;(or({value:C})||c)&&(M?Te=M(C):we=!0);const Vt=ve.map(G=>{if(!k.isValidElement(G))return null;let ge;if(b){if(!Array.isArray(C))throw new Error(Xi(2));ge=C.some(Ue=>hf(Ue,G.props.value)),ge&&we&&rt.push(G.props.children)}else ge=hf(C,G.props.value),ge&&we&&(ri=G.props.children);return k.cloneElement(G,{"aria-selected":ge?"true":"false",onClick:Tt(G),onKeyUp:Ue=>{Ue.key===" "&&Ue.preventDefault(),G.props.onKeyUp&&G.props.onKeyUp(Ue)},role:"option",selected:ge,value:void 0,"data-value":G.props.value})});we&&(b?rt.length===0?Te=null:Te=rt.reduce((G,ge,Ue)=>(G.push(ge),Ue<rt.length-1&&G.push(", "),G),[]):Te=ri);let Ti=Ge;!r&&re&&J&&(Ti=ne.clientWidth);let li;typeof E<"u"?li=E:li=h?null:0;const he=O.id||(v?`mui-component-select-${v}`:void 0),U=q({},t,{variant:z,value:C,open:It,error:g}),di=Kx(U),qn=q({},y.PaperProps,(a=y.slotProps)==null?void 0:a.paper);return u.jsxs(k.Fragment,{children:[u.jsx(Wx,q({ref:st,tabIndex:li,role:"button","aria-disabled":h?"true":void 0,"aria-expanded":It?"true":"false","aria-haspopup":"listbox","aria-label":o,"aria-labelledby":[_,he].filter(Boolean).join(" ")||void 0,"aria-describedby":n,onKeyDown:Dt,onMouseDown:h||A?null:Y,onBlur:Ct,onFocus:D},O,{ownerState:U,className:K(O.className,di.select,d),id:he,children:Ux(Te)?ff||(ff=u.jsx("span",{className:"notranslate",children:"​"})):Te})),u.jsx(Gx,q({"aria-invalid":g,value:Array.isArray(C)?C.join(","):C,name:v,ref:X,"aria-hidden":!0,onChange:Fi,tabIndex:-1,disabled:h,className:di.nativeInput,autoFocus:s,ownerState:U},L)),u.jsx($x,{as:m,className:di.icon,ownerState:U}),u.jsx(Px,q({id:`menu-${v||""}`,anchorEl:ne,open:It,onClose:pe,anchorOrigin:{vertical:"bottom",horizontal:"center"},transformOrigin:{vertical:"top",horizontal:"center"}},y,{MenuListProps:q({"aria-labelledby":_,role:"listbox",disableListWrap:!0},y.MenuListProps),slotProps:{paper:q({},qn,{style:q({minWidth:Ti},qn!=null?qn.style:null)})},children:Vt}))]})}),Vx=Hx,Xx=Ta(u.jsx("path",{d:"M7 10l5 5 5-5z"}),"ArrowDropDown");function Yx(e){return u.jsx(Ew,q({},e,{defaultTheme:rl,themeId:Mo}))}function Qx(e){return ue("MuiInputBase",e)}const Jx=oe("MuiInputBase",["root","formControl","focused","disabled","adornedStart","adornedEnd","error","sizeSmall","multiline","colorSecondary","fullWidth","hiddenLabel","readOnly","input","inputSizeSmall","inputMultiline","inputTypeSearch","inputAdornedStart","inputAdornedEnd","inputHiddenLabel"]),fn=Jx,Zx=["aria-describedby","autoComplete","autoFocus","className","color","components","componentsProps","defaultValue","disabled","disableInjectingGlobalStyles","endAdornment","error","fullWidth","id","inputComponent","inputProps","inputRef","margin","maxRows","minRows","multiline","name","onBlur","onChange","onClick","onFocus","onKeyDown","onKeyUp","placeholder","readOnly","renderSuffix","rows","size","slotProps","slots","startAdornment","type","value"],dl=(e,t)=>{const{ownerState:i}=e;return[t.root,i.formControl&&t.formControl,i.startAdornment&&t.adornedStart,i.endAdornment&&t.adornedEnd,i.error&&t.error,i.size==="small"&&t.sizeSmall,i.multiline&&t.multiline,i.color&&t[`color${V(i.color)}`],i.fullWidth&&t.fullWidth,i.hiddenLabel&&t.hiddenLabel]},pl=(e,t)=>{const{ownerState:i}=e;return[t.input,i.size==="small"&&t.inputSizeSmall,i.multiline&&t.inputMultiline,i.type==="search"&&t.inputTypeSearch,i.startAdornment&&t.inputAdornedStart,i.endAdornment&&t.inputAdornedEnd,i.hiddenLabel&&t.inputHiddenLabel]},eF=e=>{const{classes:t,color:i,disabled:a,error:n,endAdornment:o,focused:s,formControl:r,fullWidth:l,hiddenLabel:d,multiline:p,readOnly:f,size:h,startAdornment:c,type:g}=e,m={root:["root",`color${V(i)}`,a&&"disabled",n&&"error",l&&"fullWidth",s&&"focused",r&&"formControl",h&&h!=="medium"&&`size${V(h)}`,p&&"multiline",c&&"adornedStart",o&&"adornedEnd",d&&"hiddenLabel",f&&"readOnly"],input:["input",a&&"disabled",g==="search"&&"inputTypeSearch",p&&"inputMultiline",h==="small"&&"inputSizeSmall",d&&"inputHiddenLabel",c&&"inputAdornedStart",o&&"inputAdornedEnd",f&&"readOnly"]};return me(m,Qx,t)},cl=W("div",{name:"MuiInputBase",slot:"Root",overridesResolver:dl})(({theme:e,ownerState:t})=>q({},e.typography.body1,{color:(e.vars||e).palette.text.primary,lineHeight:"1.4375em",boxSizing:"border-box",position:"relative",cursor:"text",display:"inline-flex",alignItems:"center",[`&.${fn.disabled}`]:{color:(e.vars||e).palette.text.disabled,cursor:"default"}},t.multiline&&q({padding:"4px 0 5px"},t.size==="small"&&{paddingTop:1}),t.fullWidth&&{width:"100%"})),ul=W("input",{name:"MuiInputBase",slot:"Input",overridesResolver:pl})(({theme:e,ownerState:t})=>{const i=e.palette.mode==="light",a=q({color:"currentColor"},e.vars?{opacity:e.vars.opacity.inputPlaceholder}:{opacity:i?.42:.5},{transition:e.transitions.create("opacity",{duration:e.transitions.duration.shorter})}),n={opacity:"0 !important"},o=e.vars?{opacity:e.vars.opacity.inputPlaceholder}:{opacity:i?.42:.5};return q({font:"inherit",letterSpacing:"inherit",color:"currentColor",padding:"4px 0 5px",border:0,boxSizing:"content-box",background:"none",height:"1.4375em",margin:0,WebkitTapHighlightColor:"transparent",display:"block",minWidth:0,width:"100%",animationName:"mui-auto-fill-cancel",animationDuration:"10ms","&::-webkit-input-placeholder":a,"&::-moz-placeholder":a,"&:-ms-input-placeholder":a,"&::-ms-input-placeholder":a,"&:focus":{outline:0},"&:invalid":{boxShadow:"none"},"&::-webkit-search-decoration":{WebkitAppearance:"none"},[`label[data-shrink=false] + .${fn.formControl} &`]:{"&::-webkit-input-placeholder":n,"&::-moz-placeholder":n,"&:-ms-input-placeholder":n,"&::-ms-input-placeholder":n,"&:focus::-webkit-input-placeholder":o,"&:focus::-moz-placeholder":o,"&:focus:-ms-input-placeholder":o,"&:focus::-ms-input-placeholder":o},[`&.${fn.disabled}`]:{opacity:1,WebkitTextFillColor:(e.vars||e).palette.text.disabled},"&:-webkit-autofill":{animationDuration:"5000s",animationName:"mui-auto-fill"}},t.size==="small"&&{paddingTop:1},t.multiline&&{height:"auto",resize:"none",padding:0,paddingTop:0},t.type==="search"&&{MozAppearance:"textfield"})}),tF=u.jsx(Yx,{styles:{"@keyframes mui-auto-fill":{from:{display:"block"}},"@keyframes mui-auto-fill-cancel":{from:{display:"block"}}}}),iF=k.forwardRef(function(t,i){var a;const n=fe({props:t,name:"MuiInputBase"}),{"aria-describedby":o,autoComplete:s,autoFocus:r,className:l,components:d={},componentsProps:p={},defaultValue:f,disabled:h,disableInjectingGlobalStyles:c,endAdornment:g,fullWidth:m=!1,id:x,inputComponent:_="input",inputProps:y={},inputRef:b,maxRows:v,minRows:F,multiline:T=!1,name:w,onBlur:D,onChange:P,onClick:R,onFocus:A,onKeyDown:M,onKeyUp:O,placeholder:E,readOnly:j,renderSuffix:z,rows:L,slotProps:C={},slots:B={},startAdornment:I,type:ee="text",value:X}=n,Be=$(n,Zx),J=y.value!=null?y.value:X,{current:ke}=k.useRef(J!=null),re=k.useRef(),Ge=k.useCallback(he=>{},[]),Ft=Ye(re,b,y.ref,Ge),[Ae,st]=k.useState(!1),ne=No(),Fe=Io({props:n,muiFormControl:ne,states:["color","disabled","error","hiddenLabel","size","required","filled"]});Fe.focused=ne?ne.focused:Ae,k.useEffect(()=>{!ne&&h&&Ae&&(st(!1),D&&D())},[ne,h,Ae,D]);const Y=ne&&ne.onFilled,pe=ne&&ne.onEmpty,ve=k.useCallback(he=>{or(he)?Y&&Y():pe&&pe()},[Y,pe]);Yi(()=>{ke&&ve({value:J})},[J,ve,ke]);const Fi=he=>{if(Fe.disabled){he.stopPropagation();return}A&&A(he),y.onFocus&&y.onFocus(he),ne&&ne.onFocus?ne.onFocus(he):st(!0)},Tt=he=>{D&&D(he),y.onBlur&&y.onBlur(he),ne&&ne.onBlur?ne.onBlur(he):st(!1)},Dt=(he,...U)=>{if(!ke){const di=he.target||re.current;if(di==null)throw new Error(Xi(1));ve({value:di.value})}y.onChange&&y.onChange(he,...U),P&&P(he,...U)};k.useEffect(()=>{ve(re.current)},[]);const It=he=>{re.current&&he.currentTarget===he.target&&re.current.focus(),R&&R(he)};let Ct=_,Te=y;T&&Ct==="input"&&(L?Te=q({type:void 0,minRows:L,maxRows:L},Te):Te=q({type:void 0,maxRows:v,minRows:F},Te),Ct=$q);const ri=he=>{ve(he.animationName==="mui-auto-fill-cancel"?re.current:{value:"x"})};k.useEffect(()=>{ne&&ne.setAdornedStart(!!I)},[ne,I]);const rt=q({},n,{color:Fe.color||"primary",disabled:Fe.disabled,endAdornment:g,error:Fe.error,focused:Fe.focused,formControl:ne,fullWidth:m,hiddenLabel:Fe.hiddenLabel,multiline:T,size:Fe.size,startAdornment:I,type:ee}),we=eF(rt),Vt=B.root||d.Root||cl,Ti=C.root||p.root||{},li=B.input||d.Input||ul;return Te=q({},Te,(a=C.input)!=null?a:p.input),u.jsxs(k.Fragment,{children:[!c&&tF,u.jsxs(Vt,q({},Ti,!sr(Vt)&&{ownerState:q({},rt,Ti.ownerState)},{ref:i,onClick:It},Be,{className:K(we.root,Ti.className,l,j&&"MuiInputBase-readOnly"),children:[I,u.jsx(Wc.Provider,{value:null,children:u.jsx(li,q({ownerState:rt,"aria-invalid":Fe.error,"aria-describedby":o,autoComplete:s,autoFocus:r,defaultValue:f,disabled:Fe.disabled,id:x,onAnimationStart:ri,name:w,placeholder:E,readOnly:j,required:Fe.required,rows:L,value:J,onKeyDown:M,onKeyUp:O,type:ee},Te,!sr(li)&&{as:Ct,ownerState:q({},rt,Te.ownerState)},{ref:Ft,className:K(we.input,Te.className,j&&"MuiInputBase-readOnly"),onBlur:Tt,onChange:Dt,onFocus:Fi}))}),g,z?z(q({},Fe,{startAdornment:I})):null]}))]})}),Xc=iF;function aF(e){return ue("MuiInput",e)}const nF=q({},fn,oe("MuiInput",["root","underline","input"])),In=nF,oF=["disableUnderline","components","componentsProps","fullWidth","inputComponent","multiline","slotProps","slots","type"],sF=e=>{const{classes:t,disableUnderline:i}=e,n=me({root:["root",!i&&"underline"],input:["input"]},aF,t);return q({},t,n)},rF=W(cl,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiInput",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[...dl(e,t),!i.disableUnderline&&t.underline]}})(({theme:e,ownerState:t})=>{let a=e.palette.mode==="light"?"rgba(0, 0, 0, 0.42)":"rgba(255, 255, 255, 0.7)";return e.vars&&(a=`rgba(${e.vars.palette.common.onBackgroundChannel} / ${e.vars.opacity.inputUnderline})`),q({position:"relative"},t.formControl&&{"label + &":{marginTop:16}},!t.disableUnderline&&{"&:after":{borderBottom:`2px solid ${(e.vars||e).palette[t.color].main}`,left:0,bottom:0,content:'""',position:"absolute",right:0,transform:"scaleX(0)",transition:e.transitions.create("transform",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),pointerEvents:"none"},[`&.${In.focused}:after`]:{transform:"scaleX(1) translateX(0)"},[`&.${In.error}`]:{"&:before, &:after":{borderBottomColor:(e.vars||e).palette.error.main}},"&:before":{borderBottom:`1px solid ${a}`,left:0,bottom:0,content:'"\\00a0"',position:"absolute",right:0,transition:e.transitions.create("border-bottom-color",{duration:e.transitions.duration.shorter}),pointerEvents:"none"},[`&:hover:not(.${In.disabled}, .${In.error}):before`]:{borderBottom:`2px solid ${(e.vars||e).palette.text.primary}`,"@media (hover: none)":{borderBottom:`1px solid ${a}`}},[`&.${In.disabled}:before`]:{borderBottomStyle:"dotted"}})}),lF=W(ul,{name:"MuiInput",slot:"Input",overridesResolver:pl})({}),l_=k.forwardRef(function(t,i){var a,n,o,s;const r=fe({props:t,name:"MuiInput"}),{disableUnderline:l,components:d={},componentsProps:p,fullWidth:f=!1,inputComponent:h="input",multiline:c=!1,slotProps:g,slots:m={},type:x="text"}=r,_=$(r,oF),y=sF(r),v={root:{ownerState:{disableUnderline:l}}},F=g??p?At(g??p,v):v,T=(a=(n=m.root)!=null?n:d.Root)!=null?a:rF,w=(o=(s=m.input)!=null?s:d.Input)!=null?o:lF;return u.jsx(Xc,q({slots:{root:T,input:w},slotProps:F,fullWidth:f,inputComponent:h,multiline:c,ref:i,type:x},_,{classes:y}))});l_.muiName="Input";const dF=l_;function pF(e){return ue("MuiFilledInput",e)}const cF=q({},fn,oe("MuiFilledInput",["root","underline","input"])),ia=cF,uF=["disableUnderline","components","componentsProps","fullWidth","hiddenLabel","inputComponent","multiline","slotProps","slots","type"],mF=e=>{const{classes:t,disableUnderline:i}=e,n=me({root:["root",!i&&"underline"],input:["input"]},pF,t);return q({},t,n)},fF=W(cl,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiFilledInput",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[...dl(e,t),!i.disableUnderline&&t.underline]}})(({theme:e,ownerState:t})=>{var i;const a=e.palette.mode==="light",n=a?"rgba(0, 0, 0, 0.42)":"rgba(255, 255, 255, 0.7)",o=a?"rgba(0, 0, 0, 0.06)":"rgba(255, 255, 255, 0.09)",s=a?"rgba(0, 0, 0, 0.09)":"rgba(255, 255, 255, 0.13)",r=a?"rgba(0, 0, 0, 0.12)":"rgba(255, 255, 255, 0.12)";return q({position:"relative",backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o,borderTopLeftRadius:(e.vars||e).shape.borderRadius,borderTopRightRadius:(e.vars||e).shape.borderRadius,transition:e.transitions.create("background-color",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),"&:hover":{backgroundColor:e.vars?e.vars.palette.FilledInput.hoverBg:s,"@media (hover: none)":{backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o}},[`&.${ia.focused}`]:{backgroundColor:e.vars?e.vars.palette.FilledInput.bg:o},[`&.${ia.disabled}`]:{backgroundColor:e.vars?e.vars.palette.FilledInput.disabledBg:r}},!t.disableUnderline&&{"&:after":{borderBottom:`2px solid ${(i=(e.vars||e).palette[t.color||"primary"])==null?void 0:i.main}`,left:0,bottom:0,content:'""',position:"absolute",right:0,transform:"scaleX(0)",transition:e.transitions.create("transform",{duration:e.transitions.duration.shorter,easing:e.transitions.easing.easeOut}),pointerEvents:"none"},[`&.${ia.focused}:after`]:{transform:"scaleX(1) translateX(0)"},[`&.${ia.error}`]:{"&:before, &:after":{borderBottomColor:(e.vars||e).palette.error.main}},"&:before":{borderBottom:`1px solid ${e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / ${e.vars.opacity.inputUnderline})`:n}`,left:0,bottom:0,content:'"\\00a0"',position:"absolute",right:0,transition:e.transitions.create("border-bottom-color",{duration:e.transitions.duration.shorter}),pointerEvents:"none"},[`&:hover:not(.${ia.disabled}, .${ia.error}):before`]:{borderBottom:`1px solid ${(e.vars||e).palette.text.primary}`},[`&.${ia.disabled}:before`]:{borderBottomStyle:"dotted"}},t.startAdornment&&{paddingLeft:12},t.endAdornment&&{paddingRight:12},t.multiline&&q({padding:"25px 12px 8px"},t.size==="small"&&{paddingTop:21,paddingBottom:4},t.hiddenLabel&&{paddingTop:16,paddingBottom:17}))}),hF=W(ul,{name:"MuiFilledInput",slot:"Input",overridesResolver:pl})(({theme:e,ownerState:t})=>q({paddingTop:25,paddingRight:12,paddingBottom:8,paddingLeft:12},!e.vars&&{"&:-webkit-autofill":{WebkitBoxShadow:e.palette.mode==="light"?null:"0 0 0 100px #266798 inset",WebkitTextFillColor:e.palette.mode==="light"?null:"#fff",caretColor:e.palette.mode==="light"?null:"#fff",borderTopLeftRadius:"inherit",borderTopRightRadius:"inherit"}},e.vars&&{"&:-webkit-autofill":{borderTopLeftRadius:"inherit",borderTopRightRadius:"inherit"},[e.getColorSchemeSelector("dark")]:{"&:-webkit-autofill":{WebkitBoxShadow:"0 0 0 100px #266798 inset",WebkitTextFillColor:"#fff",caretColor:"#fff"}}},t.size==="small"&&{paddingTop:21,paddingBottom:4},t.hiddenLabel&&{paddingTop:16,paddingBottom:17},t.multiline&&{paddingTop:0,paddingBottom:0,paddingLeft:0,paddingRight:0},t.startAdornment&&{paddingLeft:0},t.endAdornment&&{paddingRight:0},t.hiddenLabel&&t.size==="small"&&{paddingTop:8,paddingBottom:9})),d_=k.forwardRef(function(t,i){var a,n,o,s;const r=fe({props:t,name:"MuiFilledInput"}),{components:l={},componentsProps:d,fullWidth:p=!1,inputComponent:f="input",multiline:h=!1,slotProps:c,slots:g={},type:m="text"}=r,x=$(r,uF),_=q({},r,{fullWidth:p,inputComponent:f,multiline:h,type:m}),y=mF(r),b={root:{ownerState:_},input:{ownerState:_}},v=c??d?At(c??d,b):b,F=(a=(n=g.root)!=null?n:l.Root)!=null?a:fF,T=(o=(s=g.input)!=null?s:l.Input)!=null?o:hF;return u.jsx(Xc,q({slots:{root:F,input:T},componentsProps:v,fullWidth:p,inputComponent:f,multiline:h,ref:i,type:m},x,{classes:y}))});d_.muiName="Input";const gF=d_;var gf;const yF=["children","classes","className","label","notched"],_F=W("fieldset")({textAlign:"left",position:"absolute",bottom:0,right:0,top:-5,left:0,margin:0,padding:"0 8px",pointerEvents:"none",borderRadius:"inherit",borderStyle:"solid",borderWidth:1,overflow:"hidden",minWidth:"0%"}),bF=W("legend")(({ownerState:e,theme:t})=>q({float:"unset",width:"auto",overflow:"hidden"},!e.withLabel&&{padding:0,lineHeight:"11px",transition:t.transitions.create("width",{duration:150,easing:t.transitions.easing.easeOut})},e.withLabel&&q({display:"block",padding:0,height:11,fontSize:"0.75em",visibility:"hidden",maxWidth:.01,transition:t.transitions.create("max-width",{duration:50,easing:t.transitions.easing.easeOut}),whiteSpace:"nowrap","& > span":{paddingLeft:5,paddingRight:5,display:"inline-block",opacity:0,visibility:"visible"}},e.notched&&{maxWidth:"100%",transition:t.transitions.create("max-width",{duration:100,easing:t.transitions.easing.easeOut,delay:50})})));function kF(e){const{className:t,label:i,notched:a}=e,n=$(e,yF),o=i!=null&&i!=="",s=q({},e,{notched:a,withLabel:o});return u.jsx(_F,q({"aria-hidden":!0,className:t,ownerState:s},n,{children:u.jsx(bF,{ownerState:s,children:o?u.jsx("span",{children:i}):gf||(gf=u.jsx("span",{className:"notranslate",children:"​"}))})}))}function vF(e){return ue("MuiOutlinedInput",e)}const wF=q({},fn,oe("MuiOutlinedInput",["root","notchedOutline","input"])),Ci=wF,qF=["components","fullWidth","inputComponent","label","multiline","notched","slots","type"],xF=e=>{const{classes:t}=e,a=me({root:["root"],notchedOutline:["notchedOutline"],input:["input"]},vF,t);return q({},t,a)},FF=W(cl,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiOutlinedInput",slot:"Root",overridesResolver:dl})(({theme:e,ownerState:t})=>{const i=e.palette.mode==="light"?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)";return q({position:"relative",borderRadius:(e.vars||e).shape.borderRadius,[`&:hover .${Ci.notchedOutline}`]:{borderColor:(e.vars||e).palette.text.primary},"@media (hover: none)":{[`&:hover .${Ci.notchedOutline}`]:{borderColor:e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / 0.23)`:i}},[`&.${Ci.focused} .${Ci.notchedOutline}`]:{borderColor:(e.vars||e).palette[t.color].main,borderWidth:2},[`&.${Ci.error} .${Ci.notchedOutline}`]:{borderColor:(e.vars||e).palette.error.main},[`&.${Ci.disabled} .${Ci.notchedOutline}`]:{borderColor:(e.vars||e).palette.action.disabled}},t.startAdornment&&{paddingLeft:14},t.endAdornment&&{paddingRight:14},t.multiline&&q({padding:"16.5px 14px"},t.size==="small"&&{padding:"8.5px 14px"}))}),TF=W(kF,{name:"MuiOutlinedInput",slot:"NotchedOutline",overridesResolver:(e,t)=>t.notchedOutline})(({theme:e})=>{const t=e.palette.mode==="light"?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)";return{borderColor:e.vars?`rgba(${e.vars.palette.common.onBackgroundChannel} / 0.23)`:t}}),DF=W(ul,{name:"MuiOutlinedInput",slot:"Input",overridesResolver:pl})(({theme:e,ownerState:t})=>q({padding:"16.5px 14px"},!e.vars&&{"&:-webkit-autofill":{WebkitBoxShadow:e.palette.mode==="light"?null:"0 0 0 100px #266798 inset",WebkitTextFillColor:e.palette.mode==="light"?null:"#fff",caretColor:e.palette.mode==="light"?null:"#fff",borderRadius:"inherit"}},e.vars&&{"&:-webkit-autofill":{borderRadius:"inherit"},[e.getColorSchemeSelector("dark")]:{"&:-webkit-autofill":{WebkitBoxShadow:"0 0 0 100px #266798 inset",WebkitTextFillColor:"#fff",caretColor:"#fff"}}},t.size==="small"&&{padding:"8.5px 14px"},t.multiline&&{padding:0},t.startAdornment&&{paddingLeft:0},t.endAdornment&&{paddingRight:0})),p_=k.forwardRef(function(t,i){var a,n,o,s,r;const l=fe({props:t,name:"MuiOutlinedInput"}),{components:d={},fullWidth:p=!1,inputComponent:f="input",label:h,multiline:c=!1,notched:g,slots:m={},type:x="text"}=l,_=$(l,qF),y=xF(l),b=No(),v=Io({props:l,muiFormControl:b,states:["color","disabled","error","focused","hiddenLabel","size","required"]}),F=q({},l,{color:v.color||"primary",disabled:v.disabled,error:v.error,focused:v.focused,formControl:b,fullWidth:p,hiddenLabel:v.hiddenLabel,multiline:c,size:v.size,type:x}),T=(a=(n=m.root)!=null?n:d.Root)!=null?a:FF,w=(o=(s=m.input)!=null?s:d.Input)!=null?o:DF;return u.jsx(Xc,q({slots:{root:T,input:w},renderSuffix:D=>u.jsx(TF,{ownerState:F,className:y.notchedOutline,label:h!=null&&h!==""&&v.required?r||(r=u.jsxs(k.Fragment,{children:[h," ","*"]})):h,notched:typeof g<"u"?g:!!(D.startAdornment||D.filled||D.focused)}),fullWidth:p,inputComponent:f,multiline:c,ref:i,type:x},_,{classes:q({},y,{notchedOutline:null})}))});p_.muiName="Input";const CF=p_,RF=["autoWidth","children","classes","className","defaultOpen","displayEmpty","IconComponent","id","input","inputProps","label","labelId","MenuProps","multiple","native","onClose","onOpen","open","renderValue","SelectDisplayProps","variant"],PF=["root"],SF=e=>{const{classes:t}=e;return t},Yc={name:"MuiSelect",overridesResolver:(e,t)=>t.root,shouldForwardProp:e=>Ht(e)&&e!=="variant",slot:"Root"},EF=W(dF,Yc)(""),BF=W(CF,Yc)(""),AF=W(gF,Yc)(""),c_=k.forwardRef(function(t,i){const a=fe({name:"MuiSelect",props:t}),{autoWidth:n=!1,children:o,classes:s={},className:r,defaultOpen:l=!1,displayEmpty:d=!1,IconComponent:p=Xx,id:f,input:h,inputProps:c,label:g,labelId:m,MenuProps:x,multiple:_=!1,native:y=!1,onClose:b,onOpen:v,open:F,renderValue:T,SelectDisplayProps:w,variant:D="outlined"}=a,P=$(a,RF),R=y?Ix:Vx,A=No(),M=Io({props:a,muiFormControl:A,states:["variant","error"]}),O=M.variant||D,E=q({},a,{variant:O,classes:s}),j=SF(E),z=$(j,PF),L=h||{standard:u.jsx(EF,{ownerState:E}),outlined:u.jsx(BF,{label:g,ownerState:E}),filled:u.jsx(AF,{ownerState:E})}[O],C=Ye(i,L.ref);return u.jsx(k.Fragment,{children:k.cloneElement(L,q({inputComponent:R,inputProps:q({children:o,error:M.error,IconComponent:p,variant:O,type:void 0,multiple:_},y?{id:f}:{autoWidth:n,defaultOpen:l,displayEmpty:d,labelId:m,MenuProps:x,onClose:b,onOpen:v,open:F,renderValue:T,SelectDisplayProps:q({id:f},w)},c,{classes:c?At(z,c.classes):z},h?h.props.inputProps:{})},_&&y&&O==="outlined"?{notched:!0}:{},{ref:C,className:K(L.props.className,r,j.root)},!h&&{variant:O},P))})});c_.muiName="Select";const jF=c_,MF=si.plugins,u_=k.createContext(),m_=()=>k.useContext(u_),zF=({children:e})=>{const[t,i]=k.useState("release"),[a,n]=k.useState(MF);return u.jsx(u_.Provider,{value:{sortOption:t,setSortOption:i,sortedData:a,setSortedData:n},children:e})},Yl=si.plugins;function IF(){const{setSearchQuery:e,setIsSearchSubmitted:t}=zo(),{sortOption:i,setSortOption:a,setSortedData:n}=m_();k.useEffect(()=>{document.documentElement.style.scrollBehavior="auto",l(i),o()},[i]);function o(){var d=window.scrollY;window.onscroll=function(){var p=window.scrollY;d>p?document.querySelector("header").style.top="0":d>150&&(document.querySelector("header").style.top="-155px"),d=p}}function s(d){const p=Object.entries(d);return p.sort(([,f],[,h])=>h.commits_count-f.commits_count),Object.fromEntries(p)}function r(d){const p=Object.entries(d);return p.sort(([,f],[,h])=>!f.metadata.release_date&&!h.metadata.release_date?0:f.metadata.release_date?h.metadata.release_date?new Date(h.metadata.release_date)-new Date(f.metadata.release_date):-1:1),Object.fromEntries(p)}const l=d=>{a(d),e(""),t(!1);let p={};d==="commits"?p=s(Yl):d=="alpha"?p=Yl:d=="release"&&(p=r(Yl)),n(p)};return u.jsx(K2,{children:u.jsxs(dq,{children:[u.jsx(r8,{children:"Sort"}),u.jsxs(jF,{value:i,label:"Sort",onChange:d=>l(d.target.value),children:[u.jsx(Ul,{value:"commits",children:"Commits Count"}),u.jsx(Ul,{value:"alpha",children:"Alphabetical"}),u.jsx(Ul,{value:"release",children:"Recent Release"})]})]})})}var Qc={},NF=kc;Object.defineProperty(Qc,"__esModule",{value:!0});var f_=Qc.default=void 0,OF=NF(Nc()),LF=u,WF=(0,OF.default)((0,LF.jsx)("path",{d:"M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z"}),"CheckCircle");f_=Qc.default=WF;function $F(e){return ue("MuiDialog",e)}const GF=oe("MuiDialog",["root","scrollPaper","scrollBody","container","paper","paperScrollPaper","paperScrollBody","paperWidthFalse","paperWidthXs","paperWidthSm","paperWidthMd","paperWidthLg","paperWidthXl","paperFullWidth","paperFullScreen"]),Ql=GF,UF=k.createContext({}),h_=UF,KF=["aria-describedby","aria-labelledby","BackdropComponent","BackdropProps","children","className","disableEscapeKeyDown","fullScreen","fullWidth","maxWidth","onBackdropClick","onClose","open","PaperComponent","PaperProps","scroll","TransitionComponent","transitionDuration","TransitionProps"],HF=W(n_,{name:"MuiDialog",slot:"Backdrop",overrides:(e,t)=>t.backdrop})({zIndex:-1}),VF=e=>{const{classes:t,scroll:i,maxWidth:a,fullWidth:n,fullScreen:o}=e,s={root:["root"],container:["container",`scroll${V(i)}`],paper:["paper",`paperScroll${V(i)}`,`paperWidth${V(String(a))}`,n&&"paperFullWidth",o&&"paperFullScreen"]};return me(s,$F,t)},XF=W(Hc,{name:"MuiDialog",slot:"Root",overridesResolver:(e,t)=>t.root})({"@media print":{position:"absolute !important"}}),YF=W("div",{name:"MuiDialog",slot:"Container",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.container,t[`scroll${V(i.scroll)}`]]}})(({ownerState:e})=>q({height:"100%","@media print":{height:"auto"},outline:0},e.scroll==="paper"&&{display:"flex",justifyContent:"center",alignItems:"center"},e.scroll==="body"&&{overflowY:"auto",overflowX:"hidden",textAlign:"center","&:after":{content:'""',display:"inline-block",verticalAlign:"middle",height:"100%",width:"0"}})),QF=W(Oo,{name:"MuiDialog",slot:"Paper",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.paper,t[`scrollPaper${V(i.scroll)}`],t[`paperWidth${V(String(i.maxWidth))}`],i.fullWidth&&t.paperFullWidth,i.fullScreen&&t.paperFullScreen]}})(({theme:e,ownerState:t})=>q({margin:32,position:"relative",overflowY:"auto","@media print":{overflowY:"visible",boxShadow:"none"}},t.scroll==="paper"&&{display:"flex",flexDirection:"column",maxHeight:"calc(100% - 64px)"},t.scroll==="body"&&{display:"inline-block",verticalAlign:"middle",textAlign:"left"},!t.maxWidth&&{maxWidth:"calc(100% - 64px)"},t.maxWidth==="xs"&&{maxWidth:e.breakpoints.unit==="px"?Math.max(e.breakpoints.values.xs,444):`max(${e.breakpoints.values.xs}${e.breakpoints.unit}, 444px)`,[`&.${Ql.paperScrollBody}`]:{[e.breakpoints.down(Math.max(e.breakpoints.values.xs,444)+32*2)]:{maxWidth:"calc(100% - 64px)"}}},t.maxWidth&&t.maxWidth!=="xs"&&{maxWidth:`${e.breakpoints.values[t.maxWidth]}${e.breakpoints.unit}`,[`&.${Ql.paperScrollBody}`]:{[e.breakpoints.down(e.breakpoints.values[t.maxWidth]+32*2)]:{maxWidth:"calc(100% - 64px)"}}},t.fullWidth&&{width:"calc(100% - 64px)"},t.fullScreen&&{margin:0,width:"100%",maxWidth:"100%",height:"100%",maxHeight:"none",borderRadius:0,[`&.${Ql.paperScrollBody}`]:{margin:0,maxWidth:"100%"}})),JF=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiDialog"}),n=wn(),o={enter:n.transitions.duration.enteringScreen,exit:n.transitions.duration.leavingScreen},{"aria-describedby":s,"aria-labelledby":r,BackdropComponent:l,BackdropProps:d,children:p,className:f,disableEscapeKeyDown:h=!1,fullScreen:c=!1,fullWidth:g=!1,maxWidth:m="sm",onBackdropClick:x,onClose:_,open:y,PaperComponent:b=Oo,PaperProps:v={},scroll:F="paper",TransitionComponent:T=a_,transitionDuration:w=o,TransitionProps:D}=a,P=$(a,KF),R=q({},a,{disableEscapeKeyDown:h,fullScreen:c,fullWidth:g,maxWidth:m,scroll:F}),A=VF(R),M=k.useRef(),O=L=>{M.current=L.target===L.currentTarget},E=L=>{M.current&&(M.current=null,x&&x(L),_&&_(L,"backdropClick"))},j=oy(r),z=k.useMemo(()=>({titleId:j}),[j]);return u.jsx(XF,q({className:K(A.root,f),closeAfterTransition:!0,components:{Backdrop:HF},componentsProps:{backdrop:q({transitionDuration:w,as:l},d)},disableEscapeKeyDown:h,onClose:_,open:y,ref:i,onClick:E,ownerState:R},P,{children:u.jsx(T,q({appear:!0,in:y,timeout:w,role:"presentation"},D,{children:u.jsx(YF,{className:K(A.container),onMouseDown:O,ownerState:R,children:u.jsx(QF,q({as:b,elevation:24,role:"dialog","aria-describedby":s,"aria-labelledby":j},v,{className:K(A.paper,v.className),ownerState:R,children:u.jsx(h_.Provider,{value:z,children:p})}))})}))}))}),ZF=JF;function e4(e){return ue("MuiDialogContent",e)}oe("MuiDialogContent",["root","dividers"]);function t4(e){return ue("MuiDialogTitle",e)}const i4=oe("MuiDialogTitle",["root"]),a4=i4,n4=["className","dividers"],o4=e=>{const{classes:t,dividers:i}=e;return me({root:["root",i&&"dividers"]},e4,t)},s4=W("div",{name:"MuiDialogContent",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,i.dividers&&t.dividers]}})(({theme:e,ownerState:t})=>q({flex:"1 1 auto",WebkitOverflowScrolling:"touch",overflowY:"auto",padding:"20px 24px"},t.dividers?{padding:"16px 24px",borderTop:`1px solid ${(e.vars||e).palette.divider}`,borderBottom:`1px solid ${(e.vars||e).palette.divider}`}:{[`.${a4.root} + &`]:{paddingTop:0}})),r4=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiDialogContent"}),{className:n,dividers:o=!1}=a,s=$(a,n4),r=q({},a,{dividers:o}),l=o4(r);return u.jsx(s4,q({className:K(l.root,n),ownerState:r,ref:i},s))}),l4=r4;function d4(e){return ue("MuiDialogContentText",e)}oe("MuiDialogContentText",["root"]);const p4=["children","className"],c4=e=>{const{classes:t}=e,a=me({root:["root"]},d4,t);return q({},t,a)},u4=W(Zy,{shouldForwardProp:e=>Ht(e)||e==="classes",name:"MuiDialogContentText",slot:"Root",overridesResolver:(e,t)=>t.root})({}),m4=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiDialogContentText"}),{className:n}=a,o=$(a,p4),s=c4(o);return u.jsx(u4,q({component:"p",variant:"body1",color:"text.secondary",ref:i,ownerState:o,className:K(s.root,n)},a,{classes:s}))}),f4=m4,h4=["className","id"],g4=e=>{const{classes:t}=e;return me({root:["root"]},t4,t)},y4=W(Zy,{name:"MuiDialogTitle",slot:"Root",overridesResolver:(e,t)=>t.root})({padding:"16px 24px",flex:"0 0 auto"}),_4=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiDialogTitle"}),{className:n,id:o}=a,s=$(a,h4),r=a,l=g4(r),{titleId:d=o}=k.useContext(h_);return u.jsx(y4,q({component:"h2",className:K(l.root,n),ownerState:r,ref:i,variant:"h6",id:o??d},s))}),b4=_4,g_="data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACMAAAAhCAYAAABTERJSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAFhgAABYYBG6Yz4AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAUbSURBVFiFzZhrbFRVEMd%2Fc%2B5uu6UUbIFC%2FUAUVEQCLbQJBIiBDyiImJiIhmohYNCkqJAQxASLF8tDgYRHBLXRhIcKNtFEhVDgAxBJqgmVh4JEKg3EIn2QYqBlt917xg%2BFss%2ByaDHOtzsz5z%2B%2FuZl7ztmF%2F5HJvxVQN6cPYX8%2FPLnOmsvNAvqfwuib%2FbNIk9cQeQnLcKRL5xLIV%2Fic9eJeunjPYbRs4FjQSpTB3aS1IpRKeeOOewajy%2FKKEO8Q0DuVdKy8IqsbPulxGHUfCBBu%2BwUYGuFuBTK7wQnht6PEbf4tlRomVRjCbXNjQEB0AyrFQOL5ENIJm7dTLZE6DPJCnEtFZVXDLny%2B4Sjv0PmmYu1ZdUek9RiMgoDmJ8V0L7XJqsZ3UW8YsBOwEeHeeFce7jEYXBy0m9m4BbXqSj2%2Bxnkg26MCVrN6DEZcwggtd8pTFx%2Fh3B9B50YLaFOPwXQKUt0tBLegtSomfBlfY13PwijbEnhztGzgJsK5h9W9qeWwBqjvyhB2iBs1Qz0AU974DciRGO8CVN8AJhAeMAdA3KbrKEtvxhsI%2B9emWiJlGBEU680Cfk%2BSsVqXZvcFYGXjF8ABVJ%2BTNfVXehyms1zzn1gmIOxLEB6E31%2FWBe5rnCarmo7elf7dJEeaLh80GasliI5F6Q9cAz1GY1OJVNDxTzQTw7iY%2FHEZRQY7xqJ9RU2LFe%2FYqakdP911ha0XhjjiTVAkDwgatWfCGeYocx8M3glG8g8EXhSrLrHnEFJ5Ymow%2FkhIYv6ttYUW1iFmEqqxdVoUs9FmsDYSqmtmJh3Cl1%2BVtl2s7owDUdocR5bceiyoSivGTT5vzpbzL1uoBpmcAAQgW7ArnKD9ng9rc%2BNgrobSNwpSkkhcRN%2BvmXLjIsDovYHHEfmsYFygPAnIDEQrQPzJYCOaLHLUfIt7Oq0LJn9fxkSgNCb1qEIQ5UKgT%2Fs6gJmVOOroJhQBXVqw118QtWLdyUxEP45sUpSzqP7RDdFYMyB9UReMiF1MzPwoUqHt8hjGFFeP5wZAbZ%2F0%2BcAtAAcji6LeSq%2FMYiAvSsdw3GtrfVSVFUBbIhwRWYR7yOcr%2FBi%2FB1MSJZ16JlgH1AGM3EO2QnmMyrSbTSiACgFBv4yCUapZkt9qwWVL7aeOyHvArJjm8%2Fz9BhdI4XcZgz2%2FvRALosjsk1ODOyMcJn9%2FYI6IrkS5vxMGdUwou2YKfyVqJpn5t9aNs3gbQMbdbkxnGdsr4bTHm2AxWo9yNZK4PXR3uzhAh%2BM0AZejnCrGdy0UvJxl0oMKgWSLR%2B1LH2aE9ViejiFs%2BXn6bTjng3MlIhJ1I1TkuLdg6OcAbD7Xx%2Bc3y9TrWAiSHqVkbZ2v9ilCo6s4AjwZCzFyD9mOL305nV9aonvsQeT2L0gVk4OwOJqXXVRW7naaxswDKVdlYLyMXAnntteYmws2xcVVZzq%2BtHPAooQggmJkc6TLSusOiL4RKgwzzYU1iFQgiUBA1H7E8yPau%2BZl9P7AblVNebtHqTgxLfRqrNvZWjsHZFuqMqKcDWdlFjF7UGvX8Jn24DyEAykJwNcdg0OvJ4p5pQ9tV6SMlP4A0PNh8aYze1ArROyUNTNouy8tNF3Rt0CSXb6bRFl4%2FIfQzNMjaE9WwpYOWQnOdEF%2BTdJNO0iFh7%2BI0kfORzQZb6P2kymS9oTxzBiM9rUqLWr1WE5G6ODhycQd%2FUnNVeMbcH68hYkGycNoUNWc8fxaxfwhDbHpfwM5oeTY7rUX8QAAAABJRU5ErkJggg%3D%3D";const yf=si.status_dict,k4="/aiida-registry/pr-preview/pr-285/";function v4(){const{sortOption:e,sortedData:t}=m_();return u.jsx(u.Fragment,{children:Object.entries(t).map(([i,a])=>u.jsxs("div",{className:"submenu-entry",children:[u.jsx(wa,{to:`/${i}`,children:u.jsxs("h2",{style:{display:"inline"},children:[i," "]})}),a.is_installable==="True"&&u.jsx(w4,{}),u.jsxs("p",{className:"currentstate",children:[u.jsx("img",{className:"svg-badge",src:`${k4}${yf[a.development_status][1]}`,title:yf[a.development_status][0]})," ",a.aiida_version&&u.jsx("img",{className:"svg-badge",title:`Compatible with aiida-core ${a.aiida_version}`,src:`https://img.shields.io/badge/AiiDA-${a.aiida_version}-007ec6.svg?logo=${g_}`}),e==="commits"&&u.jsx("img",{className:"svg-badge",style:{padding:"3px"},src:`https://img.shields.io/badge/Yearly%20Commits-${a.commits_count}-007ec6.svg`}),e==="release"&&a.metadata.release_date&&u.jsx("img",{className:"svg-badge",style:{padding:"3px"},src:`https://img.shields.io/badge/Recent%20Release-${a.metadata.release_date.replace(/-/g,"/")}-007ec6.svg`})]}),u.jsx("p",{children:a.metadata.description}),u.jsxs("ul",{className:"plugin-info",children:[u.jsx("li",{children:u.jsx("a",{href:a.code_home,children:"Source Code"})}),a.documentation_url&&u.jsx("li",{children:u.jsx("a",{href:a.documentation_url,children:"Documentation"})}),u.jsx("li",{children:u.jsx(wa,{to:`/${i}`,children:"Plugin details"})})]}),a.summaryinfo&&u.jsx(u.Fragment,{children:u.jsx("p",{className:"summaryinfo",children:a.summaryinfo.map(n=>u.jsxs("span",{className:"badge",children:[u.jsx("span",{className:`badge-left ${n.colorclass}`,children:n.text}),u.jsx("span",{className:"badge-right",children:n.count})]},n.text))})})]},i))})}function w4(){const[e,t]=k.useState(!1),i=()=>{t(!0)},a=()=>{t(!1)};return u.jsxs(u.Fragment,{children:[u.jsxs("div",{className:"classbox",style:{backgroundColor:"transparent"},children:[u.jsx(f_,{onClick:i,style:{color:"green",cursor:"pointer",marginBottom:"-5"}}),u.jsx("span",{className:"tooltiptext",children:"Plugin successfully installed"})]}),u.jsxs(ZF,{open:e,onClose:a,children:[u.jsx(b4,{children:"This plugin can be installed with the latest aiida-core version."}),u.jsx(l4,{children:u.jsxs(f4,{children:["This check mark indicates that this plugin was installed successfully inside the latest",u.jsxs("a",{rel:"noopener noreferrer",target:"_blank",href:"https://hub.docker.com/r/aiidateam/aiida-core",children:[u.jsx("code",{children:" aiida-core"})," docker image"]}),". For in-depth compatibility tests see the source code repository of the plugin."]})})]})]})}const q4=si.globalsummary,x4=si.plugins,F4=Object.keys(x4).length;function T4(){return u.jsxs(u.Fragment,{children:[u.jsxs("h2",{children:["Registered plugin packages: ",F4]}),u.jsx("div",{className:"globalsummary-box",children:u.jsx("div",{style:{display:"table"},children:q4.map(e=>u.jsxs("span",{className:"badge",style:{display:"table-row",lineHeight:2},children:[u.jsx("span",{style:{display:"table-cell",float:"none",textAlign:"right"},children:u.jsxs("span",{className:`badge-left ${e.colorclass} tooltip`,style:{float:"none",display:"inline",textAlign:"right",border:"none"},children:[e.name,e.tooltip&&u.jsx("span",{className:"tooltiptext",children:e.tooltip})]})}),u.jsx("span",{style:{display:"table-cell",float:"none",textAlign:"left"},children:u.jsxs("span",{className:"badge-right",style:{float:"none",display:"inline",textAlign:"left",border:"none"},children:[e.total_num," plugin",e.total_num!==1?"s":""," in ",e.num_entries," package",e.num_entries!==1?"s":""]})})]},e.name))})})]})}function D4(){const{isSearchSubmitted:e}=zo();return u.jsxs("main",{className:"fade-enter",children:[u.jsx(T4,{}),u.jsxs("div",{id:"entrylist",children:[u.jsx("h1",{children:"Package list"}),u.jsxs("div",{className:"bar-container",children:[u.jsx("div",{style:{flex:"1",marginRight:"10px"},children:u.jsx(L2,{})}),u.jsx(IF,{})]}),e===!0?u.jsx(W2,{}):u.jsx(v4,{})]})]})}function da(){return da=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var i=arguments[t];for(var a in i)Object.prototype.hasOwnProperty.call(i,a)&&(e[a]=i[a])}return e},da.apply(this,arguments)}const C4=["children","options"],_f=["allowFullScreen","allowTransparency","autoComplete","autoFocus","autoPlay","cellPadding","cellSpacing","charSet","className","classId","colSpan","contentEditable","contextMenu","crossOrigin","encType","formAction","formEncType","formMethod","formNoValidate","formTarget","frameBorder","hrefLang","inputMode","keyParams","keyType","marginHeight","marginWidth","maxLength","mediaGroup","minLength","noValidate","radioGroup","readOnly","rowSpan","spellCheck","srcDoc","srcLang","srcSet","tabIndex","useMap"].reduce((e,t)=>(e[t.toLowerCase()]=t,e),{for:"htmlFor"}),bf={amp:"&",apos:"'",gt:">",lt:"<",nbsp:" ",quot:"“"},R4=["style","script"],P4=/([-A-Z0-9_:]+)(?:\s*=\s*(?:(?:"((?:\\.|[^"])*)")|(?:'((?:\\.|[^'])*)')|(?:\{((?:\\.|{[^}]*?}|[^}])*)\})))?/gi,S4=/mailto:/i,E4=/\n{2,}$/,y_=/^( *>[^\n]+(\n[^\n]+)*\n*)+\n{2,}/,B4=/^ *> ?/gm,A4=/^ {2,}\n/,j4=/^(?:( *[-*_])){3,} *(?:\n *)+\n/,__=/^\s*(`{3,}|~{3,}) *(\S+)?([^\n]*?)?\n([\s\S]+?)\s*\1 *(?:\n *)*\n?/,b_=/^(?: {4}[^\n]+\n*)+(?:\n *)+\n?/,M4=/^(`+)\s*([\s\S]*?[^`])\s*\1(?!`)/,z4=/^(?:\n *)*\n/,I4=/\r\n?/g,N4=/^\[\^([^\]]+)](:.*)\n/,O4=/^\[\^([^\]]+)]/,L4=/\f/g,W4=/^\s*?\[(x|\s)\]/,k_=/^ *(#{1,6}) *([^\n]+?)(?: +#*)?(?:\n *)*(?:\n|$)/,v_=/^ *(#{1,6}) +([^\n]+?)(?: +#*)?(?:\n *)*(?:\n|$)/,w_=/^([^\n]+)\n *(=|-){3,} *(?:\n *)+\n/,bp=/^ *(?!<[a-z][^ >/]* ?\/>)<([a-z][^ >/]*) ?([^>]*)\/{0}>\n?(\s*(?:<\1[^>]*?>[\s\S]*?<\/\1>|(?!<\1)[\s\S])*?)<\/\1>\n*/i,$4=/&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-fA-F]{1,6});/gi,q_=/^<!--[\s\S]*?(?:-->)/,G4=/^(data|aria|x)-[a-z_][a-z\d_.-]*$/,kp=/^ *<([a-z][a-z0-9:]*)(?:\s+((?:<.*?>|[^>])*))?\/?>(?!<\/\1>)(\s*\n)?/i,U4=/^\{.*\}$/,K4=/^(https?:\/\/[^\s<]+[^<.,:;"')\]\s])/,H4=/^<([^ >]+@[^ >]+)>/,V4=/^<([^ >]+:\/[^ >]+)>/,X4=/-([a-z])?/gi,x_=/^(.*\|?.*)\n *(\|? *[-:]+ *\|[-| :]*)\n((?:.*\|.*\n)*)\n?/,Y4=/^\[([^\]]*)\]:\s+<?([^\s>]+)>?\s*("([^"]*)")?/,Q4=/^!\[([^\]]*)\] ?\[([^\]]*)\]/,J4=/^\[([^\]]*)\] ?\[([^\]]*)\]/,Z4=/(\[|\])/g,eT=/(\n|^[-*]\s|^#|^ {2,}|^-{2,}|^>\s)/,tT=/\t/g,iT=/^ *\| */,aT=/(^ *\||\| *$)/g,nT=/ *$/,oT=/^ *:-+: *$/,sT=/^ *:-+ *$/,rT=/^ *-+: *$/,lT=/^([*_])\1((?:\[.*?\][([].*?[)\]]|<.*?>(?:.*?<.*?>)?|`.*?`|~+.*?~+|.)*?)\1\1(?!\1)/,dT=/^([*_])((?:\[.*?\][([].*?[)\]]|<.*?>(?:.*?<.*?>)?|`.*?`|~+.*?~+|.)*?)\1(?!\1|\w)/,pT=/^==((?:\[.*?\]|<.*?>(?:.*?<.*?>)?|`.*?`|.)*?)==/,cT=/^~~((?:\[.*?\]|<.*?>(?:.*?<.*?>)?|`.*?`|.)*?)~~/,uT=/^\\([^0-9A-Za-z\s])/,mT=/^[\s\S]+?(?=[^0-9A-Z\s\u00c0-\uffff&#;.()'"]|\d+\.|\n\n| {2,}\n|\w+:\S|$)/i,fT=/^\n+/,hT=/^([ \t]*)/,gT=/\\([^\\])/g,kf=/ *\n+$/,yT=/(?:^|\n)( *)$/,Jc="(?:\\d+\\.)",Zc="(?:[*+-])";function F_(e){return"( *)("+(e===1?Jc:Zc)+") +"}const T_=F_(1),D_=F_(2);function C_(e){return new RegExp("^"+(e===1?T_:D_))}const _T=C_(1),bT=C_(2);function R_(e){return new RegExp("^"+(e===1?T_:D_)+"[^\\n]*(?:\\n(?!\\1"+(e===1?Jc:Zc)+" )[^\\n]*)*(\\n|$)","gm")}const P_=R_(1),S_=R_(2);function E_(e){const t=e===1?Jc:Zc;return new RegExp("^( *)("+t+") [\\s\\S]+?(?:\\n{2,}(?! )(?!\\1"+t+" (?!"+t+" ))\\n*|\\s*\\n*$)")}const B_=E_(1),A_=E_(2);function vf(e,t){const i=t===1,a=i?B_:A_,n=i?P_:S_,o=i?_T:bT;return{t(s,r,l){const d=yT.exec(l);return d&&(r.o||!r._&&!r.u)?a.exec(s=d[1]+s):null},i:Z.HIGH,l(s,r,l){const d=i?+s[2]:void 0,p=s[0].replace(E4,`
`).match(n);let f=!1;return{p:p.map(function(h,c){const g=o.exec(h)[0].length,m=new RegExp("^ {1,"+g+"}","gm"),x=h.replace(m,"").replace(o,""),_=c===p.length-1,y=x.indexOf(`

`)!==-1||_&&f;f=y;const b=l._,v=l.o;let F;l.o=!0,y?(l._=!1,F=x.replace(kf,`

`)):(l._=!0,F=x.replace(kf,""));const T=r(F,l);return l._=b,l.o=v,T}),m:i,g:d}},h:(s,r,l)=>e(s.m?"ol":"ul",{key:l.k,start:s.g},s.p.map(function(d,p){return e("li",{key:p},r(d,l))}))}}const kT=/^\[([^\]]*)]\( *((?:\([^)]*\)|[^() ])*) *"?([^)"]*)?"?\)/,vT=/^!\[([^\]]*)]\( *((?:\([^)]*\)|[^() ])*) *"?([^)"]*)?"?\)/,j_=[y_,__,b_,k_,w_,v_,q_,x_,P_,B_,S_,A_],wT=[...j_,/^[^\n]+(?:  \n|\n{2,})/,bp,kp];function qT(e){return e.replace(/[ÀÁÂÃÄÅàáâãäåæÆ]/g,"a").replace(/[çÇ]/g,"c").replace(/[ðÐ]/g,"d").replace(/[ÈÉÊËéèêë]/g,"e").replace(/[ÏïÎîÍíÌì]/g,"i").replace(/[Ññ]/g,"n").replace(/[øØœŒÕõÔôÓóÒò]/g,"o").replace(/[ÜüÛûÚúÙù]/g,"u").replace(/[ŸÿÝý]/g,"y").replace(/[^a-z0-9- ]/gi,"").replace(/ /gi,"-").toLowerCase()}function xT(e){return rT.test(e)?"right":oT.test(e)?"center":sT.test(e)?"left":null}function wf(e,t,i){const a=i.$;i.$=!0;const n=t(e.trim(),i);i.$=a;let o=[[]];return n.forEach(function(s,r){s.type==="tableSeparator"?r!==0&&r!==n.length-1&&o.push([]):(s.type!=="text"||n[r+1]!=null&&n[r+1].type!=="tableSeparator"||(s.v=s.v.replace(nT,"")),o[o.length-1].push(s))}),o}function FT(e,t,i){i._=!0;const a=wf(e[1],t,i),n=e[2].replace(aT,"").split("|").map(xT),o=function(s,r,l){return s.trim().split(`
`).map(function(d){return wf(d,r,l)})}(e[3],t,i);return i._=!1,{S:n,A:o,L:a,type:"table"}}function qf(e,t){return e.S[t]==null?{}:{textAlign:e.S[t]}}function Ri(e){return function(t,i){return i._?e.exec(t):null}}function Pi(e){return function(t,i){return i._||i.u?e.exec(t):null}}function pi(e){return function(t,i){return i._||i.u?null:e.exec(t)}}function Nn(e){return function(t){return e.exec(t)}}function TT(e,t,i){if(t._||t.u||i&&!i.endsWith(`
`))return null;let a="";e.split(`
`).every(o=>!j_.some(s=>s.test(o))&&(a+=o+`
`,o.trim()));const n=a.trimEnd();return n==""?null:[a,n]}function ja(e){try{if(decodeURIComponent(e).replace(/[^A-Za-z0-9/:]/g,"").match(/^\s*(javascript|vbscript|data(?!:image)):/i))return}catch{return null}return e}function xf(e){return e.replace(gT,"$1")}function Fs(e,t,i){const a=i._||!1,n=i.u||!1;i._=!0,i.u=!0;const o=e(t,i);return i._=a,i.u=n,o}function DT(e,t,i){const a=i._||!1,n=i.u||!1;i._=!1,i.u=!0;const o=e(t,i);return i._=a,i.u=n,o}function CT(e,t,i){return i._=!1,e(t,i)}const Jl=(e,t,i)=>({v:Fs(t,e[1],i)});function Zl(){return{}}function ed(){return null}function RT(...e){return e.filter(Boolean).join(" ")}function td(e,t,i){let a=e;const n=t.split(".");for(;n.length&&(a=a[n[0]],a!==void 0);)n.shift();return a||i}var Z;function PT(e,t={}){t.overrides=t.overrides||{},t.slugify=t.slugify||qT,t.namedCodesToUnicode=t.namedCodesToUnicode?da({},bf,t.namedCodesToUnicode):bf;const i=t.createElement||k.createElement;function a(c,g,...m){const x=td(t.overrides,`${c}.props`,{});return i(function(_,y){const b=td(y,_);return b?typeof b=="function"||typeof b=="object"&&"render"in b?b:td(y,`${_}.component`,_):_}(c,t.overrides),da({},g,x,{className:RT(g==null?void 0:g.className,x.className)||void 0}),...m)}function n(c){let g=!1;t.forceInline?g=!0:t.forceBlock||(g=eT.test(c)===!1);const m=p(d(g?c:`${c.trimEnd().replace(fT,"")}

`,{_:g}));for(;typeof m[m.length-1]=="string"&&!m[m.length-1].trim();)m.pop();if(t.wrapper===null)return m;const x=t.wrapper||(g?"span":"div");let _;if(m.length>1||t.forceWrapper)_=m;else{if(m.length===1)return _=m[0],typeof _=="string"?a("span",{key:"outer"},_):_;_=null}return k.createElement(x,{key:"outer"},_)}function o(c){const g=c.match(P4);return g?g.reduce(function(m,x,_){const y=x.indexOf("=");if(y!==-1){const b=function(w){return w.indexOf("-")!==-1&&w.match(G4)===null&&(w=w.replace(X4,function(D,P){return P.toUpperCase()})),w}(x.slice(0,y)).trim(),v=function(w){const D=w[0];return(D==='"'||D==="'")&&w.length>=2&&w[w.length-1]===D?w.slice(1,-1):w}(x.slice(y+1).trim()),F=_f[b]||b,T=m[F]=function(w,D){return w==="style"?D.split(/;\s?/).reduce(function(P,R){const A=R.slice(0,R.indexOf(":"));return P[A.replace(/(-[a-z])/g,M=>M[1].toUpperCase())]=R.slice(A.length+1).trim(),P},{}):w==="href"?ja(D):(D.match(U4)&&(D=D.slice(1,D.length-1)),D==="true"||D!=="false"&&D)}(b,v);typeof T=="string"&&(bp.test(T)||kp.test(T))&&(m[F]=k.cloneElement(n(T.trim()),{key:_}))}else x!=="style"&&(m[_f[x]||x]=!0);return m},{}):null}const s=[],r={},l={blockQuote:{t:pi(y_),i:Z.HIGH,l:(c,g,m)=>({v:g(c[0].replace(B4,""),m)}),h:(c,g,m)=>a("blockquote",{key:m.k},g(c.v,m))},breakLine:{t:Nn(A4),i:Z.HIGH,l:Zl,h:(c,g,m)=>a("br",{key:m.k})},breakThematic:{t:pi(j4),i:Z.HIGH,l:Zl,h:(c,g,m)=>a("hr",{key:m.k})},codeBlock:{t:pi(b_),i:Z.MAX,l:c=>({v:c[0].replace(/^ {4}/gm,"").replace(/\n+$/,""),M:void 0}),h:(c,g,m)=>a("pre",{key:m.k},a("code",da({},c.O,{className:c.M?`lang-${c.M}`:""}),c.v))},codeFenced:{t:pi(__),i:Z.MAX,l:c=>({O:o(c[3]||""),v:c[4],M:c[2]||void 0,type:"codeBlock"})},codeInline:{t:Pi(M4),i:Z.LOW,l:c=>({v:c[2]}),h:(c,g,m)=>a("code",{key:m.k},c.v)},footnote:{t:pi(N4),i:Z.MAX,l:c=>(s.push({I:c[2],j:c[1]}),{}),h:ed},footnoteReference:{t:Ri(O4),i:Z.HIGH,l:c=>({v:c[1],B:`#${t.slugify(c[1])}`}),h:(c,g,m)=>a("a",{key:m.k,href:ja(c.B)},a("sup",{key:m.k},c.v))},gfmTask:{t:Ri(W4),i:Z.HIGH,l:c=>({R:c[1].toLowerCase()==="x"}),h:(c,g,m)=>a("input",{checked:c.R,key:m.k,readOnly:!0,type:"checkbox"})},heading:{t:pi(t.enforceAtxHeadings?v_:k_),i:Z.HIGH,l:(c,g,m)=>({v:Fs(g,c[2],m),T:t.slugify(c[2]),C:c[1].length}),h:(c,g,m)=>a(`h${c.C}`,{id:c.T,key:m.k},g(c.v,m))},headingSetext:{t:pi(w_),i:Z.MAX,l:(c,g,m)=>({v:Fs(g,c[1],m),C:c[2]==="="?1:2,type:"heading"})},htmlComment:{t:Nn(q_),i:Z.HIGH,l:()=>({}),h:ed},image:{t:Pi(vT),i:Z.HIGH,l:c=>({D:c[1],B:xf(c[2]),F:c[3]}),h:(c,g,m)=>a("img",{key:m.k,alt:c.D||void 0,title:c.F||void 0,src:ja(c.B)})},link:{t:Ri(kT),i:Z.LOW,l:(c,g,m)=>({v:DT(g,c[1],m),B:xf(c[2]),F:c[3]}),h:(c,g,m)=>a("a",{key:m.k,href:ja(c.B),title:c.F},g(c.v,m))},linkAngleBraceStyleDetector:{t:Ri(V4),i:Z.MAX,l:c=>({v:[{v:c[1],type:"text"}],B:c[1],type:"link"})},linkBareUrlDetector:{t:(c,g)=>g.N?null:Ri(K4)(c,g),i:Z.MAX,l:c=>({v:[{v:c[1],type:"text"}],B:c[1],F:void 0,type:"link"})},linkMailtoDetector:{t:Ri(H4),i:Z.MAX,l(c){let g=c[1],m=c[1];return S4.test(m)||(m="mailto:"+m),{v:[{v:g.replace("mailto:",""),type:"text"}],B:m,type:"link"}}},orderedList:vf(a,1),unorderedList:vf(a,2),newlineCoalescer:{t:pi(z4),i:Z.LOW,l:Zl,h:()=>`
`},paragraph:{t:TT,i:Z.LOW,l:Jl,h:(c,g,m)=>a("p",{key:m.k},g(c.v,m))},ref:{t:Ri(Y4),i:Z.MAX,l:c=>(r[c[1]]={B:c[2],F:c[4]},{}),h:ed},refImage:{t:Pi(Q4),i:Z.MAX,l:c=>({D:c[1]||void 0,P:c[2]}),h:(c,g,m)=>a("img",{key:m.k,alt:c.D,src:ja(r[c.P].B),title:r[c.P].F})},refLink:{t:Ri(J4),i:Z.MAX,l:(c,g,m)=>({v:g(c[1],m),Z:g(c[0].replace(Z4,"\\$1"),m),P:c[2]}),h:(c,g,m)=>r[c.P]?a("a",{key:m.k,href:ja(r[c.P].B),title:r[c.P].F},g(c.v,m)):a("span",{key:m.k},g(c.Z,m))},table:{t:pi(x_),i:Z.HIGH,l:FT,h:(c,g,m)=>a("table",{key:m.k},a("thead",null,a("tr",null,c.L.map(function(x,_){return a("th",{key:_,style:qf(c,_)},g(x,m))}))),a("tbody",null,c.A.map(function(x,_){return a("tr",{key:_},x.map(function(y,b){return a("td",{key:b,style:qf(c,b)},g(y,m))}))})))},tableSeparator:{t:function(c,g){return g.$?(g._=!0,iT.exec(c)):null},i:Z.HIGH,l:function(){return{type:"tableSeparator"}},h:()=>" | "},text:{t:Nn(mT),i:Z.MIN,l:c=>({v:c[0].replace($4,(g,m)=>t.namedCodesToUnicode[m]?t.namedCodesToUnicode[m]:g)}),h:c=>c.v},textBolded:{t:Pi(lT),i:Z.MED,l:(c,g,m)=>({v:g(c[2],m)}),h:(c,g,m)=>a("strong",{key:m.k},g(c.v,m))},textEmphasized:{t:Pi(dT),i:Z.LOW,l:(c,g,m)=>({v:g(c[2],m)}),h:(c,g,m)=>a("em",{key:m.k},g(c.v,m))},textEscaped:{t:Pi(uT),i:Z.HIGH,l:c=>({v:c[1],type:"text"})},textMarked:{t:Pi(pT),i:Z.LOW,l:Jl,h:(c,g,m)=>a("mark",{key:m.k},g(c.v,m))},textStrikethroughed:{t:Pi(cT),i:Z.LOW,l:Jl,h:(c,g,m)=>a("del",{key:m.k},g(c.v,m))}};t.disableParsingRawHTML!==!0&&(l.htmlBlock={t:Nn(bp),i:Z.HIGH,l(c,g,m){const[,x]=c[3].match(hT),_=new RegExp(`^${x}`,"gm"),y=c[3].replace(_,""),b=(v=y,wT.some(D=>D.test(v))?CT:Fs);var v;const F=c[1].toLowerCase(),T=R4.indexOf(F)!==-1;m.N=m.N||F==="a";const w=T?c[3]:b(g,y,m);return m.N=!1,{O:o(c[2]),v:w,G:T,H:T?F:c[1]}},h:(c,g,m)=>a(c.H,da({key:m.k},c.O),c.G?c.v:g(c.v,m))},l.htmlSelfClosing={t:Nn(kp),i:Z.HIGH,l:c=>({O:o(c[2]||""),H:c[1]}),h:(c,g,m)=>a(c.H,da({},c.O,{key:m.k}))});const d=function(c){let g=Object.keys(c);function m(x,_){let y=[],b="";for(;x;){let v=0;for(;v<g.length;){const F=g[v],T=c[F],w=T.t(x,_,b);if(w){const D=w[0];x=x.substring(D.length);const P=T.l(w,m,_);P.type==null&&(P.type=F),y.push(P),b=D;break}v++}}return y}return g.sort(function(x,_){let y=c[x].i,b=c[_].i;return y!==b?y-b:x<_?-1:1}),function(x,_){return m(function(y){return y.replace(I4,`
`).replace(L4,"").replace(tT,"    ")}(x),_)}}(l),p=(f=function(c){return function(g,m,x){return c[g.type].h(g,m,x)}}(l),function c(g,m={}){if(Array.isArray(g)){const x=m.k,_=[];let y=!1;for(let b=0;b<g.length;b++){m.k=b;const v=c(g[b],m),F=typeof v=="string";F&&y?_[_.length-1]+=v:v!==null&&_.push(v),y=F}return m.k=x,_}return f(g,c,m)});var f;const h=n(e);return s.length?a("div",null,h,a("footer",{key:"footer"},s.map(function(c){return a("div",{id:t.slugify(c.j),key:c.j},c.j,p(d(c.I,{_:!0})))}))):h}(function(e){e[e.MAX=0]="MAX",e[e.HIGH=1]="HIGH",e[e.MED=2]="MED",e[e.LOW=3]="LOW",e[e.MIN=4]="MIN"})(Z||(Z={}));const vp=e=>{let{children:t,options:i}=e,a=function(n,o){if(n==null)return{};var s,r,l={},d=Object.keys(n);for(r=0;r<d.length;r++)o.indexOf(s=d[r])>=0||(l[s]=n[s]);return l}(e,C4);return k.cloneElement(PT(t,i),a)};function ST(e){return ue("MuiAlert",e)}const ET=oe("MuiAlert",["root","action","icon","message","filled","filledSuccess","filledInfo","filledWarning","filledError","outlined","outlinedSuccess","outlinedInfo","outlinedWarning","outlinedError","standard","standardSuccess","standardInfo","standardWarning","standardError"]),Ff=ET;function BT(e){return ue("MuiIconButton",e)}const AT=oe("MuiIconButton",["root","disabled","colorInherit","colorPrimary","colorSecondary","colorError","colorInfo","colorSuccess","colorWarning","edgeStart","edgeEnd","sizeSmall","sizeMedium","sizeLarge"]),jT=AT,MT=["edge","children","className","color","disabled","disableFocusRipple","size"],zT=e=>{const{classes:t,disabled:i,color:a,edge:n,size:o}=e,s={root:["root",i&&"disabled",a!=="default"&&`color${V(a)}`,n&&`edge${V(n)}`,`size${V(o)}`]};return me(s,BT,t)},IT=W(Qy,{name:"MuiIconButton",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,i.color!=="default"&&t[`color${V(i.color)}`],i.edge&&t[`edge${V(i.edge)}`],t[`size${V(i.size)}`]]}})(({theme:e,ownerState:t})=>q({textAlign:"center",flex:"0 0 auto",fontSize:e.typography.pxToRem(24),padding:8,borderRadius:"50%",overflow:"visible",color:(e.vars||e).palette.action.active,transition:e.transitions.create("background-color",{duration:e.transitions.duration.shortest})},!t.disableRipple&&{"&:hover":{backgroundColor:e.vars?`rgba(${e.vars.palette.action.activeChannel} / ${e.vars.palette.action.hoverOpacity})`:hi(e.palette.action.active,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"}}},t.edge==="start"&&{marginLeft:t.size==="small"?-3:-12},t.edge==="end"&&{marginRight:t.size==="small"?-3:-12}),({theme:e,ownerState:t})=>{var i;const a=(i=(e.vars||e).palette)==null?void 0:i[t.color];return q({},t.color==="inherit"&&{color:"inherit"},t.color!=="inherit"&&t.color!=="default"&&q({color:a==null?void 0:a.main},!t.disableRipple&&{"&:hover":q({},a&&{backgroundColor:e.vars?`rgba(${a.mainChannel} / ${e.vars.palette.action.hoverOpacity})`:hi(a.main,e.palette.action.hoverOpacity)},{"@media (hover: none)":{backgroundColor:"transparent"}})}),t.size==="small"&&{padding:5,fontSize:e.typography.pxToRem(18)},t.size==="large"&&{padding:12,fontSize:e.typography.pxToRem(28)},{[`&.${jT.disabled}`]:{backgroundColor:"transparent",color:(e.vars||e).palette.action.disabled}})}),NT=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiIconButton"}),{edge:n=!1,children:o,className:s,color:r="default",disabled:l=!1,disableFocusRipple:d=!1,size:p="medium"}=a,f=$(a,MT),h=q({},a,{edge:n,color:r,disabled:l,disableFocusRipple:d,size:p}),c=zT(h);return u.jsx(IT,q({className:K(c.root,s),centerRipple:!0,focusRipple:!d,disabled:l,ref:i,ownerState:h},f,{children:o}))}),OT=NT,LT=Ta(u.jsx("path",{d:"M20,12A8,8 0 0,1 12,20A8,8 0 0,1 4,12A8,8 0 0,1 12,4C12.76,4 13.5,4.11 14.2, 4.31L15.77,2.74C14.61,2.26 13.34,2 12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0, 0 22,12M7.91,10.08L6.5,11.5L11,16L21,6L19.59,4.58L11,13.17L7.91,10.08Z"}),"SuccessOutlined"),WT=Ta(u.jsx("path",{d:"M12 5.99L19.53 19H4.47L12 5.99M12 2L1 21h22L12 2zm1 14h-2v2h2v-2zm0-6h-2v4h2v-4z"}),"ReportProblemOutlined"),$T=Ta(u.jsx("path",{d:"M11 15h2v2h-2zm0-8h2v6h-2zm.99-5C6.47 2 2 6.48 2 12s4.47 10 9.99 10C17.52 22 22 17.52 22 12S17.52 2 11.99 2zM12 20c-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8-3.58 8-8 8z"}),"ErrorOutline"),GT=Ta(u.jsx("path",{d:"M11,9H13V7H11M12,20C7.59,20 4,16.41 4,12C4,7.59 7.59,4 12,4C16.41,4 20,7.59 20, 12C20,16.41 16.41,20 12,20M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12A10, 10 0 0,0 12,2M11,17H13V11H11V17Z"}),"InfoOutlined"),UT=Ta(u.jsx("path",{d:"M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"}),"Close"),KT=["action","children","className","closeText","color","components","componentsProps","icon","iconMapping","onClose","role","severity","slotProps","slots","variant"],HT=e=>{const{variant:t,color:i,severity:a,classes:n}=e,o={root:["root",`${t}${V(i||a)}`,`${t}`],icon:["icon"],message:["message"],action:["action"]};return me(o,ST,n)},VT=W(Oo,{name:"MuiAlert",slot:"Root",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.root,t[i.variant],t[`${i.variant}${V(i.color||i.severity)}`]]}})(({theme:e,ownerState:t})=>{const i=e.palette.mode==="light"?sp:rp,a=e.palette.mode==="light"?rp:sp,n=t.color||t.severity;return q({},e.typography.body2,{backgroundColor:"transparent",display:"flex",padding:"6px 16px"},n&&t.variant==="standard"&&{color:e.vars?e.vars.palette.Alert[`${n}Color`]:i(e.palette[n].light,.6),backgroundColor:e.vars?e.vars.palette.Alert[`${n}StandardBg`]:a(e.palette[n].light,.9),[`& .${Ff.icon}`]:e.vars?{color:e.vars.palette.Alert[`${n}IconColor`]}:{color:e.palette[n].main}},n&&t.variant==="outlined"&&{color:e.vars?e.vars.palette.Alert[`${n}Color`]:i(e.palette[n].light,.6),border:`1px solid ${(e.vars||e).palette[n].light}`,[`& .${Ff.icon}`]:e.vars?{color:e.vars.palette.Alert[`${n}IconColor`]}:{color:e.palette[n].main}},n&&t.variant==="filled"&&q({fontWeight:e.typography.fontWeightMedium},e.vars?{color:e.vars.palette.Alert[`${n}FilledColor`],backgroundColor:e.vars.palette.Alert[`${n}FilledBg`]}:{backgroundColor:e.palette.mode==="dark"?e.palette[n].dark:e.palette[n].main,color:e.palette.getContrastText(e.palette[n].main)}))}),XT=W("div",{name:"MuiAlert",slot:"Icon",overridesResolver:(e,t)=>t.icon})({marginRight:12,padding:"7px 0",display:"flex",fontSize:22,opacity:.9}),YT=W("div",{name:"MuiAlert",slot:"Message",overridesResolver:(e,t)=>t.message})({padding:"8px 0",minWidth:0,overflow:"auto"}),Tf=W("div",{name:"MuiAlert",slot:"Action",overridesResolver:(e,t)=>t.action})({display:"flex",alignItems:"flex-start",padding:"4px 0 0 16px",marginLeft:"auto",marginRight:-8}),Df={success:u.jsx(LT,{fontSize:"inherit"}),warning:u.jsx(WT,{fontSize:"inherit"}),error:u.jsx($T,{fontSize:"inherit"}),info:u.jsx(GT,{fontSize:"inherit"})},QT=k.forwardRef(function(t,i){var a,n,o,s,r,l;const d=fe({props:t,name:"MuiAlert"}),{action:p,children:f,className:h,closeText:c="Close",color:g,components:m={},componentsProps:x={},icon:_,iconMapping:y=Df,onClose:b,role:v="alert",severity:F="success",slotProps:T={},slots:w={},variant:D="standard"}=d,P=$(d,KT),R=q({},d,{color:g,severity:F,variant:D}),A=HT(R),M=(a=(n=w.closeButton)!=null?n:m.CloseButton)!=null?a:OT,O=(o=(s=w.closeIcon)!=null?s:m.CloseIcon)!=null?o:UT,E=(r=T.closeButton)!=null?r:x.closeButton,j=(l=T.closeIcon)!=null?l:x.closeIcon;return u.jsxs(VT,q({role:v,elevation:0,ownerState:R,className:K(A.root,h),ref:i},P,{children:[_!==!1?u.jsx(XT,{ownerState:R,className:A.icon,children:_||y[F]||Df[F]}):null,u.jsx(YT,{ownerState:R,className:A.message,children:f}),p!=null?u.jsx(Tf,{ownerState:R,className:A.action,children:p}):null,p==null&&b?u.jsx(Tf,{ownerState:R,className:A.action,children:u.jsx(M,q({size:"small","aria-label":c,title:c,color:"inherit",onClick:b},E,{children:u.jsx(O,q({fontSize:"small"},j))}))}):null]}))}),id=QT,Cf=si.entrypointtypes,JT=si.plugins,Rf=si.status_dict,ZT="/aiida-registry/pr-preview/pr-285/";function eD({pluginKey:e}){const t=JT[e];return k.useEffect(()=>{window.scrollTo(0,0),document.documentElement.style.scrollBehavior="smooth",(()=>{const a=window.location.hash;if(a){let n=window.location.href;window.location.href=n+" ",window.location.href=n;const o=document.getElementById(a);o&&o.scrollIntoView()}})()},[]),u.jsx(u.Fragment,{children:u.jsxs("div",{id:"details",className:"fade-enter",children:[u.jsxs("h1",{className:"plugin-header",children:['AiiDA plugin package "',u.jsx("a",{href:t.code_home,children:t.name}),'"']}),u.jsx(wa,{to:"/",children:u.jsx("p",{style:{display:"inline"},children:"< back to the registry index"})}),u.jsx("h2",{id:"general.information",children:"General information"}),u.jsxs("div",{children:[u.jsxs("p",{children:[u.jsx("strong",{children:"Current state: "}),u.jsx("img",{className:"svg-badge",src:`${ZT}${Rf[t.development_status][1]}`,title:Rf[t.development_status][0]})]}),t.metadata.description&&u.jsxs("p",{children:[u.jsx("strong",{children:"Short description"}),": ",t.metadata.description]}),t.pip_url&&u.jsxs("p",{children:[u.jsx("strong",{children:"How to install"}),": ",u.jsx("code",{children:t.pip_install_cmd})]}),u.jsxs("p",{children:[u.jsx("strong",{children:"Source code"}),": ",u.jsx("a",{href:t.code_home,target:"_blank",children:"Go to the source code repository"})]}),t.documentation_url?u.jsxs("p",{children:[u.jsx("strong",{children:"Documentation"}),": ",u.jsx("a",{href:t.documentation_url,target:"_blank",children:"Go to plugin documentation"})]}):u.jsxs("p",{children:[u.jsx("strong",{children:"Documentation"}),": No documentation provided by the package author"]})]}),u.jsx("h3",{children:"Registry checks"}),t.warnings||t.errors?u.jsxs(u.Fragment,{children:[t.warnings&&u.jsx(u.Fragment,{children:t.warnings.map(i=>u.jsx(id,{severity:"warning",children:i}))}),t.errors&&u.jsx(u.Fragment,{children:t.errors.map(i=>u.jsx(id,{severity:"error",children:i}))})]}):u.jsx(id,{severity:"success",children:"All checks passed!"}),u.jsx("h2",{id:"detailed.information",children:"Detailed information"}),Object.keys(t.metadata).length!==0?u.jsxs(u.Fragment,{children:[u.jsxs("p",{children:[u.jsx("strong",{children:"Author(s)"}),": ",t.metadata.author]}),t.metadata.author_email&&u.jsxs("p",{children:[u.jsx("strong",{children:"Contact"}),":"," ",u.jsx("a",{href:`mailto:${t.metadata.author_email}`,children:t.metadata.author_email})]}),u.jsxs("p",{children:[u.jsx("strong",{children:"How to use from python"}),":"," ",u.jsxs("code",{children:["import ",t.package_name]})]}),u.jsxs("p",{children:[u.jsx("strong",{children:"Most recent version"}),": ",t.metadata.version]}),t.aiida_version&&u.jsxs("p",{children:[u.jsx("strong",{children:"Compatibility: "}),u.jsx("img",{className:"svg-badge",src:`https://img.shields.io/badge/AiiDA-${t.aiida_version}-007ec6.svg?logo=${g_}`})]}),t.summaryinfo.length!==0&&u.jsxs(u.Fragment,{children:[u.jsx("h3",{id:"plugins",children:"Plugins provided by the package"}),t.summaryinfo.map(i=>u.jsxs("span",{className:"badge",children:[u.jsx("span",{className:`badge-left ${i.colorclass}`,children:i.text}),u.jsx("span",{className:"badge-right",children:i.count})]},i.text))]}),t.entry_points?Object.entries(t.entry_points).map(([i,a])=>u.jsx(u.Fragment,{children:u.jsxs("div",{children:[u.jsx("h2",{style:{color:"black"},id:i,children:i in Cf?u.jsxs(u.Fragment,{children:[Cf[i]," ",u.jsxs("span",{className:"entrypointraw",children:["(",i,")"]})]}):i}),u.jsx("ul",{children:Object.entries(a).map(([n,o])=>u.jsxs("li",{children:[u.jsx("h2",{style:{color:"black"},id:`${i}.${n}`,children:n}),typeof o=="string"?u.jsxs("div",{className:"classbox",children:["class",u.jsxs("span",{className:"tooltiptext",children:[" ",o]})]}):u.jsx(tD,{entryPoints:o})]},n))})]},i)})):u.jsx("p",{children:"No entry points defined for this plugin."})]}):u.jsx("div",{id:"description",children:u.jsxs("p",{children:["Detailed information for this package could not be obtained. Ask the plugin author to add a ",u.jsx("code",{children:"setup.json"})," file to the plugin source code."]})})]})})}const tD=({entryPoints:e})=>u.jsxs("div",{style:{overflow:"auto"},children:[u.jsx("table",{children:u.jsx("tbody",{children:u.jsxs("tr",{children:[u.jsx("th",{children:"Class"}),u.jsx("td",{children:u.jsx("code",{children:e.class})})]})})}),u.jsxs("table",{children:[u.jsx("tr",{children:u.jsx("th",{children:"Description"})}),e.description.map(t=>u.jsx("tr",{className:"ep_description",children:u.jsx(vp,{children:t.trim()})}))]}),u.jsxs("table",{children:[u.jsxs("tr",{children:[u.jsx("th",{children:"Inputs"}),u.jsx("th",{children:"Required"}),u.jsx("th",{children:"Valid Types"}),u.jsx("th",{children:"Description"})]}),u.jsx(Pf,{spec:e.spec.inputs}),u.jsxs("tr",{children:[u.jsx("th",{children:"Outputs"}),u.jsx("th",{children:"Required"}),u.jsx("th",{children:"Valid Types"}),u.jsx("th",{children:"Description"})]}),u.jsx(Pf,{spec:e.spec.outputs})]}),u.jsxs("table",{children:[u.jsx("tr",{children:u.jsx("th",{children:"Exit Codes"})}),u.jsxs("tr",{children:[u.jsx("th",{children:"Status"}),u.jsx("th",{children:"Message"})]}),e.spec.exit_codes.map(t=>u.jsxs("tr",{className:"ep_description",children:[u.jsx("td",{children:t.status}),u.jsx(vp,{children:t.message})]}))]})]}),Pf=({spec:e})=>u.jsx(u.Fragment,{children:e.map(t=>u.jsxs("tr",{className:"ep_description",children:[u.jsx("td",{children:t.name}),u.jsx("td",{children:t.required.toString()}),u.jsx("td",{children:t.valid_types}),u.jsx(vp,{children:t.info})]}))});const iD=["addEndListener","appear","children","container","direction","easing","in","onEnter","onEntered","onEntering","onExit","onExited","onExiting","style","timeout","TransitionComponent"];function aD(e,t,i){const a=t.getBoundingClientRect(),n=i&&i.getBoundingClientRect(),o=oi(t);let s;if(t.fakeTransform)s=t.fakeTransform;else{const d=o.getComputedStyle(t);s=d.getPropertyValue("-webkit-transform")||d.getPropertyValue("transform")}let r=0,l=0;if(s&&s!=="none"&&typeof s=="string"){const d=s.split("(")[1].split(")")[0].split(",");r=parseInt(d[4],10),l=parseInt(d[5],10)}return e==="left"?n?`translateX(${n.right+r-a.left}px)`:`translateX(${o.innerWidth+r-a.left}px)`:e==="right"?n?`translateX(-${a.right-n.left-r}px)`:`translateX(-${a.left+a.width-r}px)`:e==="up"?n?`translateY(${n.bottom+l-a.top}px)`:`translateY(${o.innerHeight+l-a.top}px)`:n?`translateY(-${a.top-n.top+a.height-l}px)`:`translateY(-${a.top+a.height-l}px)`}function nD(e){return typeof e=="function"?e():e}function ls(e,t,i){const a=nD(i),n=aD(e,t,a);n&&(t.style.webkitTransform=n,t.style.transform=n)}const oD=k.forwardRef(function(t,i){const a=wn(),n={enter:a.transitions.easing.easeOut,exit:a.transitions.easing.sharp},o={enter:a.transitions.duration.enteringScreen,exit:a.transitions.duration.leavingScreen},{addEndListener:s,appear:r=!0,children:l,container:d,direction:p="down",easing:f=n,in:h,onEnter:c,onEntered:g,onEntering:m,onExit:x,onExited:_,onExiting:y,style:b,timeout:v=o,TransitionComponent:F=$c}=t,T=$(t,iD),w=k.useRef(null),D=Ye(l.ref,w,i),P=C=>B=>{C&&(B===void 0?C(w.current):C(w.current,B))},R=P((C,B)=>{ls(p,C,d),Kc(C),c&&c(C,B)}),A=P((C,B)=>{const I=mn({timeout:v,style:b,easing:f},{mode:"enter"});C.style.webkitTransition=a.transitions.create("-webkit-transform",q({},I)),C.style.transition=a.transitions.create("transform",q({},I)),C.style.webkitTransform="none",C.style.transform="none",m&&m(C,B)}),M=P(g),O=P(y),E=P(C=>{const B=mn({timeout:v,style:b,easing:f},{mode:"exit"});C.style.webkitTransition=a.transitions.create("-webkit-transform",B),C.style.transition=a.transitions.create("transform",B),ls(p,C,d),x&&x(C)}),j=P(C=>{C.style.webkitTransition="",C.style.transition="",_&&_(C)}),z=C=>{s&&s(w.current,C)},L=k.useCallback(()=>{w.current&&ls(p,w.current,d)},[p,d]);return k.useEffect(()=>{if(h||p==="down"||p==="right")return;const C=Mr(()=>{w.current&&ls(p,w.current,d)}),B=oi(w.current);return B.addEventListener("resize",C),()=>{C.clear(),B.removeEventListener("resize",C)}},[p,h,d]),k.useEffect(()=>{h||L()},[h,L]),u.jsx(F,q({nodeRef:w,onEnter:R,onEntered:M,onEntering:A,onExit:E,onExited:j,onExiting:O,addEndListener:z,appear:r,in:h,timeout:v},T,{children:(C,B)=>k.cloneElement(l,q({ref:D,style:q({visibility:C==="exited"&&!h?"hidden":void 0},b,l.props.style)},B))}))}),sD=oD;function rD(e){return ue("MuiDrawer",e)}oe("MuiDrawer",["root","docked","paper","paperAnchorLeft","paperAnchorRight","paperAnchorTop","paperAnchorBottom","paperAnchorDockedLeft","paperAnchorDockedRight","paperAnchorDockedTop","paperAnchorDockedBottom","modal"]);const lD=["BackdropProps"],dD=["anchor","BackdropProps","children","className","elevation","hideBackdrop","ModalProps","onClose","open","PaperProps","SlideProps","TransitionComponent","transitionDuration","variant"],M_=(e,t)=>{const{ownerState:i}=e;return[t.root,(i.variant==="permanent"||i.variant==="persistent")&&t.docked,t.modal]},pD=e=>{const{classes:t,anchor:i,variant:a}=e,n={root:["root"],docked:[(a==="permanent"||a==="persistent")&&"docked"],modal:["modal"],paper:["paper",`paperAnchor${V(i)}`,a!=="temporary"&&`paperAnchorDocked${V(i)}`]};return me(n,rD,t)},cD=W(Hc,{name:"MuiDrawer",slot:"Root",overridesResolver:M_})(({theme:e})=>({zIndex:(e.vars||e).zIndex.drawer})),Sf=W("div",{shouldForwardProp:Ht,name:"MuiDrawer",slot:"Docked",skipVariantsResolver:!1,overridesResolver:M_})({flex:"0 0 auto"}),uD=W(Oo,{name:"MuiDrawer",slot:"Paper",overridesResolver:(e,t)=>{const{ownerState:i}=e;return[t.paper,t[`paperAnchor${V(i.anchor)}`],i.variant!=="temporary"&&t[`paperAnchorDocked${V(i.anchor)}`]]}})(({theme:e,ownerState:t})=>q({overflowY:"auto",display:"flex",flexDirection:"column",height:"100%",flex:"1 0 auto",zIndex:(e.vars||e).zIndex.drawer,WebkitOverflowScrolling:"touch",position:"fixed",top:0,outline:0},t.anchor==="left"&&{left:0},t.anchor==="top"&&{top:0,left:0,right:0,height:"auto",maxHeight:"100%"},t.anchor==="right"&&{right:0},t.anchor==="bottom"&&{top:"auto",left:0,bottom:0,right:0,height:"auto",maxHeight:"100%"},t.anchor==="left"&&t.variant!=="temporary"&&{borderRight:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="top"&&t.variant!=="temporary"&&{borderBottom:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="right"&&t.variant!=="temporary"&&{borderLeft:`1px solid ${(e.vars||e).palette.divider}`},t.anchor==="bottom"&&t.variant!=="temporary"&&{borderTop:`1px solid ${(e.vars||e).palette.divider}`})),z_={left:"right",right:"left",top:"down",bottom:"up"};function mD(e){return["left","right"].indexOf(e)!==-1}function fD(e,t){return e.direction==="rtl"&&mD(t)?z_[t]:t}const hD=k.forwardRef(function(t,i){const a=fe({props:t,name:"MuiDrawer"}),n=wn(),o={enter:n.transitions.duration.enteringScreen,exit:n.transitions.duration.leavingScreen},{anchor:s="left",BackdropProps:r,children:l,className:d,elevation:p=16,hideBackdrop:f=!1,ModalProps:{BackdropProps:h}={},onClose:c,open:g=!1,PaperProps:m={},SlideProps:x,TransitionComponent:_=sD,transitionDuration:y=o,variant:b="temporary"}=a,v=$(a.ModalProps,lD),F=$(a,dD),T=k.useRef(!1);k.useEffect(()=>{T.current=!0},[]);const w=fD(n,s),P=q({},a,{anchor:s,elevation:p,open:g,variant:b},F),R=pD(P),A=u.jsx(uD,q({elevation:b==="temporary"?p:0,square:!0},m,{className:K(R.paper,m.className),ownerState:P,children:l}));if(b==="permanent")return u.jsx(Sf,q({className:K(R.root,R.docked,d),ownerState:P,ref:i},F,{children:A}));const M=u.jsx(_,q({in:g,direction:z_[w],timeout:y,appear:T.current},x,{children:A}));return b==="persistent"?u.jsx(Sf,q({className:K(R.root,R.docked,d),ownerState:P,ref:i},F,{children:M})):u.jsx(cD,q({BackdropProps:q({},r,h,{transitionDuration:y}),className:K(R.root,R.modal,d),open:g,ownerState:P,onClose:c,hideBackdrop:f,ref:i},F,v,{children:M}))}),gD=hD,yD=si.plugins;function _D({pluginKey:e}){const t=yD[e];function i(){function n(){document.querySelector("header").style.top="-155px",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="0"}setTimeout(n,800)}const a=u.jsxs("div",{style:{paddingLeft:"10px"},children:[u.jsx("h1",{children:"Plugin content"}),u.jsx(ef,{}),u.jsx("p",{children:u.jsx("a",{style:{color:"black"},href:"#general.information",onClick:i,children:"General Information"})}),u.jsx("p",{children:u.jsx("a",{style:{color:"black"},href:"#detailed.information",onClick:i,children:"Detailed Information"})}),u.jsx("p",{children:u.jsx("a",{style:{color:"black"},href:"#plugins",onClick:i,children:"Plugins provided by the package"})}),t.entry_points&&Object.entries(t.entry_points).map(([n,o])=>u.jsx(u.Fragment,{children:u.jsx("ul",{children:u.jsxs("li",{children:[u.jsx("a",{style:{color:"black"},href:`#${n}`,onClick:i,children:n}),Object.entries(o).map(([s,r])=>u.jsx("ul",{children:u.jsx("li",{children:u.jsx("a",{style:{color:"black"},href:`#${n}.${s}`,onClick:i,children:s})})},s))]})})})),u.jsx(ef,{})]});return u.jsx(gD,{variant:"permanent",id:"sidebar",anchor:"right",sx:{display:{xs:"none",sm:"block"}},open:!0,children:a})}function bD(){return u.jsxs(u.Fragment,{children:[u.jsx(kD,{}),u.jsx("div",{style:{marginTop:"155px"},children:u.jsx(zF,{children:u.jsx(z2,{children:u.jsxs(Z1,{children:[u.jsx(Qd,{path:"/",element:u.jsx(D4,{})}),u.jsx(Qd,{path:"/:key",element:u.jsx(wD,{})})]})})})}),u.jsx(vD,{})]})}function kD(){return u.jsx("header",{children:u.jsxs("div",{style:{paddingLeft:"20px"},children:[u.jsx("h1",{children:u.jsx("a",{href:"http://aiidateam.github.io/aiida-registry",children:u.jsx("img",{src:dk,height:"70px"})})}),u.jsx("p",{style:{fontSize:"90%"},children:u.jsx("a",{href:"http://github.com/aiidateam/aiida-registry",style:{color:"#999"},children:"[View on GitHub/register your package]"})})]})})}function vD(){return u.jsxs("footer",{className:"footer",children:[u.jsx("hr",{}),"The official ",u.jsx("a",{href:"http://aiidateam.github.io/aiida-registry",children:"registry"})," of ",u.jsx("a",{href:"http://www.aiida.net",children:"AiiDA"})," plugins.",u.jsx("br",{}),"This work is supported by the ",u.jsx("a",{href:"http://nccr-marvel.ch",target:"_blank",children:"MARVEL National Centre for Competence in Research"})," funded by the ",u.jsx("a",{href:"http://www.snf.ch/en",target:"_blank",children:"Swiss National Science Foundation"}),", as well as by the ",u.jsx("a",{href:"http://www.max-centre.eu",target:"_blank",children:"MaX European Centre of Excellence"})," funded by the Horizon 2020 EINFRA-5 program, Grant No. 676598.",u.jsx("br",{}),u.jsx("br",{}),u.jsxs("div",{style:{textAlign:"center"},children:[u.jsx("img",{src:pk,height:"70px"}),"    ",u.jsx("img",{src:ck,height:"70px"})]})]})}function wD(){const{key:e}=N1();k.useEffect(()=>(document.querySelector("footer").style.width="calc(100% - 380px)",()=>{document.querySelector("footer").style.width="calc(100% - 64px)"}),[]);function t(){var i=window.scrollY;window.onscroll=function(){var a=window.scrollY;i>a?(document.querySelector("header").style.top="0",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="155px"):i>150&&(document.querySelector("header").style.top="-155px",document.querySelector("#sidebar .MuiDrawer-paper").style.marginTop="0"),i=a}}return t(),u.jsx(u.Fragment,{children:u.jsxs("div",{id:"detailsContainer",children:[u.jsx(eD,{pluginKey:e}),u.jsx(_D,{pluginKey:e})]})})}const qD="/aiida-registry/pr-preview/pr-285/";ad.createRoot(document.getElementById("root")).render(u.jsx($t.StrictMode,{children:u.jsx(ok,{basename:qD,children:u.jsx(bD,{})})}));
